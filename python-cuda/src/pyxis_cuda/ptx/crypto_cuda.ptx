//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35583870
// Cuda compilation tools, release 12.8, V12.8.93
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_52
.address_size 64

	// .globl	bd09_to_gcj02_cuda_float
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0
)
;
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry bd09_to_gcj02_cuda_float(
	.param .u32 bd09_to_gcj02_cuda_float_param_0,
	.param .u64 bd09_to_gcj02_cuda_float_param_1,
	.param .u64 bd09_to_gcj02_cuda_float_param_2,
	.param .u64 bd09_to_gcj02_cuda_float_param_3,
	.param .u64 bd09_to_gcj02_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<100>;
	.reg .f32 	%f<179>;
	.reg .b32 	%r<287>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<119>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r81, [bd09_to_gcj02_cuda_float_param_0];
	ld.param.u64 	%rd30, [bd09_to_gcj02_cuda_float_param_1];
	ld.param.u64 	%rd31, [bd09_to_gcj02_cuda_float_param_2];
	ld.param.u64 	%rd32, [bd09_to_gcj02_cuda_float_param_3];
	ld.param.u64 	%rd33, [bd09_to_gcj02_cuda_float_param_4];
	mov.u32 	%r82, %ntid.x;
	mov.u32 	%r83, %ctaid.x;
	mov.u32 	%r84, %tid.x;
	mad.lo.s32 	%r1, %r83, %r82, %r84;
	setp.ge.s32 	%p3, %r1, %r81;
	@%p3 bra 	$L__BB0_83;

	cvta.to.global.u64 	%rd34, %rd30;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	cvta.to.global.u64 	%rd37, %rd31;
	add.s64 	%rd38, %rd37, %rd35;
	ld.global.f32 	%f59, [%rd36];
	cvt.f64.f32 	%fd24, %f59;
	add.rn.f64 	%fd25, %fd24, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f1, %fd25;
	ld.global.f32 	%f60, [%rd38];
	cvt.f64.f32 	%fd26, %f60;
	add.rn.f64 	%fd27, %fd26, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f2, %fd27;
	cvt.f64.f32 	%fd1, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd28, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd28;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p4, %r4, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd61, [retval0+0];
	} // callseq 0
	setp.lt.s32 	%p5, %r2, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB0_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd61;
	}
	xor.b32  	%r86, %r85, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd61;
	}
	mov.b64 	%fd61, {%r87, %r86};

$L__BB0_3:
	setp.eq.f32 	%p7, %f1, 0f00000000;
	@%p7 bra 	$L__BB0_7;
	bra.uni 	$L__BB0_4;

$L__BB0_7:
	selp.b32 	%r88, %r2, 0, %p4;
	mov.u32 	%r89, 0;
	or.b32  	%r90, %r88, 2146435072;
	setp.lt.s32 	%p11, %r3, 0;
	selp.b32 	%r91, %r90, %r88, %p11;
	mov.b64 	%fd61, {%r89, %r91};
	bra.uni 	$L__BB0_8;

$L__BB0_4:
	setp.gt.s32 	%p8, %r2, -1;
	@%p8 bra 	$L__BB0_8;

	mov.f64 	%fd29, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd30, %fd29;
	setp.eq.f64 	%p9, %fd30, 0d4000000000000000;
	@%p9 bra 	$L__BB0_8;

	mov.f64 	%fd61, 0dFFF8000000000000;

$L__BB0_8:
	add.rn.f64 	%fd32, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd32;
	}
	and.b32  	%r93, %r92, 2146435072;
	setp.ne.s32 	%p12, %r93, 2146435072;
	@%p12 bra 	$L__BB0_15;

	setp.gtu.f64 	%p13, %fd2, 0d7FF0000000000000;
	@%p13 bra 	$L__BB0_14;
	bra.uni 	$L__BB0_10;

$L__BB0_14:
	mov.f64 	%fd34, 0d4000000000000000;
	add.rn.f64 	%fd61, %fd1, %fd34;
	bra.uni 	$L__BB0_15;

$L__BB0_10:
	mov.f64 	%fd33, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd33;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p14, %r5, 2146435072;
	setp.eq.s32 	%p15, %r94, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_11;

$L__BB0_13:
	setp.gt.f64 	%p23, %fd2, 0d3FF0000000000000;
	selp.b32 	%r101, 2146435072, 0, %p23;
	mov.u32 	%r102, 0;
	xor.b32  	%r103, %r101, 2146435072;
	setp.lt.s32 	%p24, %r3, 0;
	selp.b32 	%r104, %r103, %r101, %p24;
	setp.eq.f32 	%p25, %f1, 0fBF800000;
	selp.b32 	%r105, 1072693248, %r104, %p25;
	mov.b64 	%fd61, {%r102, %r105};
	bra.uni 	$L__BB0_15;

$L__BB0_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r95, %temp}, %fd1;
	}
	and.b32  	%r96, %r2, 2147483647;
	setp.ne.s32 	%p17, %r96, 2146435072;
	setp.ne.s32 	%p18, %r95, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB0_15;

	setp.gt.s32 	%p20, %r3, -1;
	selp.b32 	%r97, 2146435072, 0, %p20;
	mov.u32 	%r98, 0;
	setp.ne.s32 	%p21, %r5, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r99, %r97, -2147483648;
	selp.b32 	%r100, %r99, %r97, %p22;
	mov.b64 	%fd61, {%r98, %r100};

$L__BB0_15:
	cvt.f64.f32 	%fd12, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 1
	setp.lt.s32 	%p26, %r6, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB0_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd64;
	}
	xor.b32  	%r107, %r106, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %fd64;
	}
	mov.b64 	%fd64, {%r108, %r107};

$L__BB0_17:
	setp.eq.f32 	%p29, %f2, 0f00000000;
	@%p29 bra 	$L__BB0_21;
	bra.uni 	$L__BB0_18;

$L__BB0_21:
	selp.b32 	%r109, %r6, 0, %p4;
	mov.u32 	%r110, 0;
	or.b32  	%r111, %r109, 2146435072;
	setp.lt.s32 	%p33, %r3, 0;
	selp.b32 	%r112, %r111, %r109, %p33;
	mov.b64 	%fd64, {%r110, %r112};
	bra.uni 	$L__BB0_22;

$L__BB0_18:
	setp.gt.s32 	%p30, %r6, -1;
	@%p30 bra 	$L__BB0_22;

	mov.f64 	%fd35, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd36, %fd35;
	setp.eq.f64 	%p31, %fd36, 0d4000000000000000;
	@%p31 bra 	$L__BB0_22;

	mov.f64 	%fd64, 0dFFF8000000000000;

$L__BB0_22:
	add.rn.f64 	%fd38, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd38;
	}
	and.b32  	%r114, %r113, 2146435072;
	setp.ne.s32 	%p34, %r114, 2146435072;
	@%p34 bra 	$L__BB0_29;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB0_28;
	bra.uni 	$L__BB0_24;

$L__BB0_28:
	mov.f64 	%fd40, 0d4000000000000000;
	add.rn.f64 	%fd64, %fd12, %fd40;
	bra.uni 	$L__BB0_29;

$L__BB0_24:
	mov.f64 	%fd39, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd39;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p36, %r7, 2146435072;
	setp.eq.s32 	%p37, %r115, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_25;

$L__BB0_27:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r122, 2146435072, 0, %p45;
	mov.u32 	%r123, 0;
	xor.b32  	%r124, %r122, 2146435072;
	setp.lt.s32 	%p46, %r3, 0;
	selp.b32 	%r125, %r124, %r122, %p46;
	setp.eq.f32 	%p47, %f2, 0fBF800000;
	selp.b32 	%r126, 1072693248, %r125, %p47;
	mov.b64 	%fd64, {%r123, %r126};
	bra.uni 	$L__BB0_29;

$L__BB0_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd12;
	}
	and.b32  	%r117, %r6, 2147483647;
	setp.ne.s32 	%p39, %r117, 2146435072;
	setp.ne.s32 	%p40, %r116, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB0_29;

	setp.gt.s32 	%p42, %r3, -1;
	selp.b32 	%r118, 2146435072, 0, %p42;
	mov.u32 	%r119, 0;
	setp.ne.s32 	%p43, %r7, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r120, %r118, -2147483648;
	selp.b32 	%r121, %r120, %r118, %p44;
	mov.b64 	%fd64, {%r119, %r121};

$L__BB0_29:
	setp.eq.f32 	%p48, %f2, 0f3F800000;
	selp.f64 	%fd41, 0d3FF0000000000000, %fd64, %p48;
	setp.eq.f32 	%p49, %f1, 0f3F800000;
	selp.f64 	%fd42, 0d3FF0000000000000, %fd61, %p49;
	add.rn.f64 	%fd23, %fd42, %fd41;
	mul.rn.f32 	%f3, %f2, 0f42517084;
	mul.rn.f32 	%f61, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r274, %f61;
	cvt.rn.f32.s32 	%f62, %r274;
	mov.f32 	%f63, 0fBFC90FDA;
	fma.rn.f32 	%f64, %f62, %f63, %f3;
	mov.f32 	%f65, 0fB3A22168;
	fma.rn.f32 	%f66, %f62, %f65, %f64;
	mov.f32 	%f67, 0fA7C234C5;
	fma.rn.f32 	%f166, %f62, %f67, %f66;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p50, %f5, 0f47CE4780;
	add.u64 	%rd39, %SP, 0;
	add.u64 	%rd116, %SPL, 0;
	add.s64 	%rd1, %rd116, 24;
	@%p50 bra 	$L__BB0_37;

	setp.eq.f32 	%p51, %f5, 0f7F800000;
	@%p51 bra 	$L__BB0_36;
	bra.uni 	$L__BB0_31;

$L__BB0_36:
	mov.f32 	%f70, 0f00000000;
	mul.rn.f32 	%f166, %f3, %f70;
	mov.u32 	%r274, 0;
	bra.uni 	$L__BB0_37;

$L__BB0_31:
	mov.b32 	%r9, %f3;
	bfe.u32 	%r128, %r9, 23, 8;
	add.s32 	%r10, %r128, -128;
	shl.b32 	%r129, %r9, 8;
	or.b32  	%r11, %r129, -2147483648;
	shr.u32 	%r12, %r10, 5;
	cvta.to.local.u64 	%rd107, %rd39;
	mov.u64 	%rd109, 0;
	mov.u32 	%r271, 0;
	mov.u64 	%rd108, __cudart_i2opi_f;

$L__BB0_32:
	.pragma "nounroll";
	ld.global.nc.u32 	%r130, [%rd108];
	mad.wide.u32 	%rd44, %r130, %r11, %rd109;
	shr.u64 	%rd109, %rd44, 32;
	st.local.u32 	[%rd107], %rd44;
	add.s64 	%rd108, %rd108, 4;
	add.s64 	%rd107, %rd107, 4;
	add.s32 	%r271, %r271, 1;
	setp.ne.s32 	%p52, %r271, 6;
	@%p52 bra 	$L__BB0_32;

	st.local.u32 	[%rd1], %rd109;
	mov.u32 	%r131, 4;
	sub.s32 	%r15, %r131, %r12;
	mov.u32 	%r132, 6;
	sub.s32 	%r133, %r132, %r12;
	cvta.to.local.u64 	%rd46, %rd39;
	mul.wide.s32 	%rd47, %r133, 4;
	add.s64 	%rd48, %rd46, %rd47;
	ld.local.u32 	%r272, [%rd48];
	ld.local.u32 	%r273, [%rd48+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p53, %r18, 0;
	@%p53 bra 	$L__BB0_35;

	mov.u32 	%r134, 32;
	sub.s32 	%r135, %r134, %r18;
	shr.u32 	%r136, %r273, %r135;
	shl.b32 	%r137, %r272, %r18;
	add.s32 	%r272, %r136, %r137;
	mul.wide.s32 	%rd51, %r15, 4;
	add.s64 	%rd52, %rd46, %rd51;
	ld.local.u32 	%r138, [%rd52];
	shr.u32 	%r139, %r138, %r135;
	shl.b32 	%r140, %r273, %r18;
	add.s32 	%r273, %r139, %r140;

$L__BB0_35:
	and.b32  	%r141, %r9, -2147483648;
	shr.u32 	%r142, %r273, 30;
	shl.b32 	%r143, %r272, 2;
	or.b32  	%r144, %r142, %r143;
	shr.u32 	%r145, %r144, 31;
	shr.u32 	%r146, %r272, 30;
	add.s32 	%r147, %r145, %r146;
	neg.s32 	%r148, %r147;
	setp.eq.s32 	%p54, %r141, 0;
	selp.b32 	%r274, %r147, %r148, %p54;
	setp.ne.s32 	%p55, %r145, 0;
	xor.b32  	%r149, %r141, -2147483648;
	selp.b32 	%r150, %r149, %r141, %p55;
	selp.b32 	%r151, -1, 0, %p55;
	xor.b32  	%r152, %r144, %r151;
	shl.b32 	%r153, %r273, 2;
	xor.b32  	%r154, %r153, %r151;
	cvt.u64.u32 	%rd53, %r152;
	cvt.u64.u32 	%rd54, %r154;
	bfi.b64 	%rd55, %rd53, %rd54, 32, 32;
	cvt.rn.f64.s64 	%fd43, %rd55;
	mul.rn.f64 	%fd44, %fd43, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f68, %fd44;
	setp.eq.s32 	%p56, %r150, 0;
	neg.f32 	%f69, %f68;
	selp.f32 	%f166, %f68, %f69, %p56;

$L__BB0_37:
	and.b32  	%r25, %r274, 1;
	setp.eq.s32 	%p57, %r25, 0;
	selp.f32 	%f9, %f166, 0f3F800000, %p57;
	mul.rn.f32 	%f10, %f166, %f166;
	mov.f32 	%f167, 0fB94D4153;
	@%p57 bra 	$L__BB0_39;

	mov.f32 	%f72, 0fBAB607ED;
	mov.f32 	%f73, 0f37CBAC00;
	fma.rn.f32 	%f167, %f73, %f10, %f72;

$L__BB0_39:
	selp.f32 	%f74, 0f3C0885E4, 0f3D2AAABB, %p57;
	fma.rn.f32 	%f75, %f167, %f10, %f74;
	selp.f32 	%f76, 0fBE2AAAA8, 0fBEFFFFFF, %p57;
	fma.rn.f32 	%f77, %f75, %f10, %f76;
	mov.f32 	%f78, 0f00000000;
	fma.rn.f32 	%f79, %f10, %f9, %f78;
	fma.rn.f32 	%f168, %f77, %f79, %f9;
	and.b32  	%r156, %r274, 2;
	setp.eq.s32 	%p59, %r156, 0;
	@%p59 bra 	$L__BB0_41;

	mov.f32 	%f81, 0fBF800000;
	fma.rn.f32 	%f168, %f168, %f81, %f78;

$L__BB0_41:
	cvt.f64.f32 	%fd45, %f168;
	mul.rn.f64 	%fd46, %fd45, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd47, %fd23;
	add.rn.f64 	%fd48, %fd47, %fd46;
	cvt.rn.f32.f64 	%f16, %fd48;
	abs.f32 	%f17, %f1;
	setp.eq.f32 	%p60, %f17, 0f00000000;
	abs.f32 	%f18, %f2;
	setp.eq.f32 	%p61, %f18, 0f00000000;
	and.pred  	%p62, %p60, %p61;
	@%p62 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_42;

$L__BB0_45:
	mov.b32 	%r167, %f1;
	shr.s32 	%r168, %r167, 31;
	and.b32  	%r169, %r168, 1078530011;
	mov.b32 	%r170, %f2;
	and.b32  	%r171, %r170, -2147483648;
	or.b32  	%r172, %r169, %r171;
	mov.b32 	%f169, %r172;
	bra.uni 	$L__BB0_46;

$L__BB0_42:
	setp.eq.f32 	%p63, %f17, 0f7F800000;
	setp.eq.f32 	%p64, %f18, 0f7F800000;
	and.pred  	%p65, %p63, %p64;
	@%p65 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_43;

$L__BB0_44:
	mov.b32 	%r162, %f1;
	setp.lt.s32 	%p69, %r162, 0;
	selp.b32 	%r163, 1075235812, 1061752795, %p69;
	mov.b32 	%r164, %f2;
	and.b32  	%r165, %r164, -2147483648;
	or.b32  	%r166, %r163, %r165;
	mov.b32 	%f169, %r166;
	bra.uni 	$L__BB0_46;

$L__BB0_43:
	max.f32 	%f82, %f18, %f17;
	min.f32 	%f83, %f18, %f17;
	div.rn.f32 	%f84, %f83, %f82;
	mul.rn.f32 	%f85, %f84, %f84;
	mov.f32 	%f86, 0fC0B59883;
	mov.f32 	%f87, 0fBF52C7EA;
	fma.rn.f32 	%f88, %f85, %f87, %f86;
	mov.f32 	%f89, 0fC0D21907;
	fma.rn.f32 	%f90, %f88, %f85, %f89;
	mul.rn.f32 	%f91, %f85, %f90;
	mul.rn.f32 	%f92, %f84, %f91;
	add.rn.f32 	%f93, %f85, 0f41355DC0;
	mov.f32 	%f94, 0f41E6BD60;
	fma.rn.f32 	%f95, %f93, %f85, %f94;
	mov.f32 	%f96, 0f419D92C8;
	fma.rn.f32 	%f97, %f95, %f85, %f96;
	rcp.rn.f32 	%f98, %f97;
	fma.rn.f32 	%f99, %f92, %f98, %f84;
	mov.f32 	%f100, 0f3FC90FDB;
	sub.rn.f32 	%f101, %f100, %f99;
	setp.gt.f32 	%p66, %f18, %f17;
	selp.f32 	%f102, %f101, %f99, %p66;
	mov.b32 	%r157, %f1;
	setp.lt.s32 	%p67, %r157, 0;
	mov.f32 	%f103, 0f40490FDB;
	sub.rn.f32 	%f104, %f103, %f102;
	selp.f32 	%f105, %f104, %f102, %p67;
	mov.b32 	%r158, %f105;
	mov.b32 	%r159, %f2;
	and.b32  	%r160, %r159, -2147483648;
	or.b32  	%r161, %r160, %r158;
	mov.b32 	%f106, %r161;
	add.rn.f32 	%f107, %f17, %f18;
	setp.le.f32 	%p68, %f107, 0f7F800000;
	selp.f32 	%f169, %f106, %f107, %p68;

$L__BB0_46:
	mul.rn.f32 	%f23, %f1, 0f42517084;
	mul.rn.f32 	%f108, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r278, %f108;
	cvt.rn.f32.s32 	%f109, %r278;
	mov.f32 	%f110, 0fBFC90FDA;
	fma.rn.f32 	%f111, %f109, %f110, %f23;
	mov.f32 	%f112, 0fB3A22168;
	fma.rn.f32 	%f113, %f109, %f112, %f111;
	mov.f32 	%f114, 0fA7C234C5;
	fma.rn.f32 	%f170, %f109, %f114, %f113;
	abs.f32 	%f25, %f23;
	setp.ltu.f32 	%p70, %f25, 0f47CE4780;
	@%p70 bra 	$L__BB0_54;

	setp.eq.f32 	%p71, %f25, 0f7F800000;
	@%p71 bra 	$L__BB0_53;
	bra.uni 	$L__BB0_48;

$L__BB0_53:
	mov.f32 	%f117, 0f00000000;
	mul.rn.f32 	%f170, %f23, %f117;
	mov.u32 	%r278, 0;
	bra.uni 	$L__BB0_54;

$L__BB0_48:
	mov.b32 	%r27, %f23;
	bfe.u32 	%r174, %r27, 23, 8;
	add.s32 	%r28, %r174, -128;
	shl.b32 	%r175, %r27, 8;
	or.b32  	%r29, %r175, -2147483648;
	shr.u32 	%r30, %r28, 5;
	cvta.to.local.u64 	%rd110, %rd39;
	mov.u64 	%rd112, 0;
	mov.u32 	%r275, 0;
	mov.u64 	%rd111, __cudart_i2opi_f;

$L__BB0_49:
	.pragma "nounroll";
	ld.global.nc.u32 	%r176, [%rd111];
	mad.wide.u32 	%rd59, %r176, %r29, %rd112;
	shr.u64 	%rd112, %rd59, 32;
	st.local.u32 	[%rd110], %rd59;
	add.s64 	%rd111, %rd111, 4;
	add.s64 	%rd110, %rd110, 4;
	add.s32 	%r275, %r275, 1;
	setp.ne.s32 	%p72, %r275, 6;
	@%p72 bra 	$L__BB0_49;

	st.local.u32 	[%rd1], %rd112;
	mov.u32 	%r177, 4;
	sub.s32 	%r33, %r177, %r30;
	mov.u32 	%r178, 6;
	sub.s32 	%r179, %r178, %r30;
	cvta.to.local.u64 	%rd61, %rd39;
	mul.wide.s32 	%rd62, %r179, 4;
	add.s64 	%rd63, %rd61, %rd62;
	ld.local.u32 	%r276, [%rd63];
	ld.local.u32 	%r277, [%rd63+-4];
	and.b32  	%r36, %r28, 31;
	setp.eq.s32 	%p73, %r36, 0;
	@%p73 bra 	$L__BB0_52;

	mov.u32 	%r180, 32;
	sub.s32 	%r181, %r180, %r36;
	shr.u32 	%r182, %r277, %r181;
	shl.b32 	%r183, %r276, %r36;
	add.s32 	%r276, %r182, %r183;
	mul.wide.s32 	%rd66, %r33, 4;
	add.s64 	%rd67, %rd61, %rd66;
	ld.local.u32 	%r184, [%rd67];
	shr.u32 	%r185, %r184, %r181;
	shl.b32 	%r186, %r277, %r36;
	add.s32 	%r277, %r185, %r186;

$L__BB0_52:
	and.b32  	%r187, %r27, -2147483648;
	shr.u32 	%r188, %r277, 30;
	shl.b32 	%r189, %r276, 2;
	or.b32  	%r190, %r188, %r189;
	shr.u32 	%r191, %r190, 31;
	shr.u32 	%r192, %r276, 30;
	add.s32 	%r193, %r191, %r192;
	neg.s32 	%r194, %r193;
	setp.eq.s32 	%p74, %r187, 0;
	selp.b32 	%r278, %r193, %r194, %p74;
	setp.ne.s32 	%p75, %r191, 0;
	xor.b32  	%r195, %r187, -2147483648;
	selp.b32 	%r196, %r195, %r187, %p75;
	selp.b32 	%r197, -1, 0, %p75;
	xor.b32  	%r198, %r190, %r197;
	shl.b32 	%r199, %r277, 2;
	xor.b32  	%r200, %r199, %r197;
	cvt.u64.u32 	%rd68, %r198;
	cvt.u64.u32 	%rd69, %r200;
	bfi.b64 	%rd70, %rd68, %rd69, 32, 32;
	cvt.rn.f64.s64 	%fd49, %rd70;
	mul.rn.f64 	%fd50, %fd49, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f115, %fd50;
	setp.eq.s32 	%p76, %r196, 0;
	neg.f32 	%f116, %f115;
	selp.f32 	%f170, %f115, %f116, %p76;

$L__BB0_54:
	add.s32 	%r43, %r278, 1;
	and.b32  	%r44, %r43, 1;
	setp.eq.s32 	%p77, %r44, 0;
	selp.f32 	%f29, %f170, 0f3F800000, %p77;
	mul.rn.f32 	%f30, %f170, %f170;
	mov.f32 	%f171, 0fB94D4153;
	@%p77 bra 	$L__BB0_56;

	mov.f32 	%f119, 0fBAB607ED;
	mov.f32 	%f120, 0f37CBAC00;
	fma.rn.f32 	%f171, %f120, %f30, %f119;

$L__BB0_56:
	selp.f32 	%f121, 0f3C0885E4, 0f3D2AAABB, %p77;
	fma.rn.f32 	%f122, %f171, %f30, %f121;
	selp.f32 	%f123, 0fBE2AAAA8, 0fBEFFFFFF, %p77;
	fma.rn.f32 	%f124, %f122, %f30, %f123;
	mov.f32 	%f125, 0f00000000;
	fma.rn.f32 	%f126, %f30, %f29, %f125;
	fma.rn.f32 	%f172, %f124, %f126, %f29;
	and.b32  	%r202, %r43, 2;
	setp.eq.s32 	%p79, %r202, 0;
	@%p79 bra 	$L__BB0_58;

	mov.f32 	%f128, 0fBF800000;
	fma.rn.f32 	%f172, %f172, %f128, %f125;

$L__BB0_58:
	cvt.f64.f32 	%fd51, %f172;
	mul.rn.f64 	%fd52, %fd51, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd53, %f169;
	add.rn.f64 	%fd54, %fd53, %fd52;
	cvt.rn.f32.f64 	%f36, %fd54;
	mul.rn.f32 	%f129, %f36, 0f3F22F983;
	cvt.rni.s32.f32 	%r286, %f129;
	cvt.rn.f32.s32 	%f130, %r286;
	mov.f32 	%f131, 0fBFC90FDA;
	fma.rn.f32 	%f132, %f130, %f131, %f36;
	mov.f32 	%f133, 0fB3A22168;
	fma.rn.f32 	%f134, %f130, %f133, %f132;
	mov.f32 	%f135, 0fA7C234C5;
	fma.rn.f32 	%f176, %f130, %f135, %f134;
	abs.f32 	%f38, %f36;
	setp.ltu.f32 	%p80, %f38, 0f47CE4780;
	mov.u32 	%r282, %r286;
	mov.f32 	%f173, %f176;
	@%p80 bra 	$L__BB0_66;

	setp.eq.f32 	%p81, %f38, 0f7F800000;
	@%p81 bra 	$L__BB0_65;
	bra.uni 	$L__BB0_60;

$L__BB0_65:
	mov.f32 	%f138, 0f00000000;
	mul.rn.f32 	%f173, %f36, %f138;
	mov.u32 	%r282, 0;
	bra.uni 	$L__BB0_66;

$L__BB0_60:
	mov.b32 	%r46, %f36;
	bfe.u32 	%r204, %r46, 23, 8;
	add.s32 	%r47, %r204, -128;
	shl.b32 	%r205, %r46, 8;
	or.b32  	%r48, %r205, -2147483648;
	shr.u32 	%r49, %r47, 5;
	cvta.to.local.u64 	%rd113, %rd39;
	mov.u64 	%rd115, 0;
	mov.u32 	%r279, 0;
	mov.u64 	%rd114, __cudart_i2opi_f;

$L__BB0_61:
	.pragma "nounroll";
	ld.global.nc.u32 	%r206, [%rd114];
	mad.wide.u32 	%rd74, %r206, %r48, %rd115;
	shr.u64 	%rd115, %rd74, 32;
	st.local.u32 	[%rd113], %rd74;
	add.s64 	%rd114, %rd114, 4;
	add.s64 	%rd113, %rd113, 4;
	add.s32 	%r279, %r279, 1;
	setp.ne.s32 	%p82, %r279, 6;
	@%p82 bra 	$L__BB0_61;

	st.local.u32 	[%rd1], %rd115;
	mov.u32 	%r207, 4;
	sub.s32 	%r52, %r207, %r49;
	mov.u32 	%r208, 6;
	sub.s32 	%r209, %r208, %r49;
	cvta.to.local.u64 	%rd76, %rd39;
	mul.wide.s32 	%rd77, %r209, 4;
	add.s64 	%rd78, %rd76, %rd77;
	ld.local.u32 	%r280, [%rd78];
	ld.local.u32 	%r281, [%rd78+-4];
	and.b32  	%r55, %r47, 31;
	setp.eq.s32 	%p83, %r55, 0;
	@%p83 bra 	$L__BB0_64;

	mov.u32 	%r210, 32;
	sub.s32 	%r211, %r210, %r55;
	shr.u32 	%r212, %r281, %r211;
	shl.b32 	%r213, %r280, %r55;
	add.s32 	%r280, %r212, %r213;
	mul.wide.s32 	%rd81, %r52, 4;
	add.s64 	%rd82, %rd76, %rd81;
	ld.local.u32 	%r214, [%rd82];
	shr.u32 	%r215, %r214, %r211;
	shl.b32 	%r216, %r281, %r55;
	add.s32 	%r281, %r215, %r216;

$L__BB0_64:
	and.b32  	%r217, %r46, -2147483648;
	shr.u32 	%r218, %r281, 30;
	shl.b32 	%r219, %r280, 2;
	or.b32  	%r220, %r218, %r219;
	shr.u32 	%r221, %r220, 31;
	shr.u32 	%r222, %r280, 30;
	add.s32 	%r223, %r221, %r222;
	neg.s32 	%r224, %r223;
	setp.eq.s32 	%p84, %r217, 0;
	selp.b32 	%r282, %r223, %r224, %p84;
	setp.ne.s32 	%p85, %r221, 0;
	xor.b32  	%r225, %r217, -2147483648;
	selp.b32 	%r226, %r225, %r217, %p85;
	selp.b32 	%r227, -1, 0, %p85;
	xor.b32  	%r228, %r220, %r227;
	shl.b32 	%r229, %r281, 2;
	xor.b32  	%r230, %r229, %r227;
	cvt.u64.u32 	%rd83, %r228;
	cvt.u64.u32 	%rd84, %r230;
	bfi.b64 	%rd85, %rd83, %rd84, 32, 32;
	cvt.rn.f64.s64 	%fd55, %rd85;
	mul.rn.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f136, %fd56;
	setp.eq.s32 	%p86, %r226, 0;
	neg.f32 	%f137, %f136;
	selp.f32 	%f173, %f136, %f137, %p86;

$L__BB0_66:
	add.s32 	%r62, %r282, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p87, %r63, 0;
	selp.f32 	%f42, %f173, 0f3F800000, %p87;
	mul.rn.f32 	%f43, %f173, %f173;
	mov.f32 	%f174, 0fB94D4153;
	@%p87 bra 	$L__BB0_68;

	mov.f32 	%f140, 0fBAB607ED;
	mov.f32 	%f141, 0f37CBAC00;
	fma.rn.f32 	%f174, %f141, %f43, %f140;

$L__BB0_68:
	selp.f32 	%f142, 0f3C0885E4, 0f3D2AAABB, %p87;
	fma.rn.f32 	%f143, %f174, %f43, %f142;
	selp.f32 	%f144, 0fBE2AAAA8, 0fBEFFFFFF, %p87;
	fma.rn.f32 	%f145, %f143, %f43, %f144;
	mov.f32 	%f146, 0f00000000;
	fma.rn.f32 	%f147, %f43, %f42, %f146;
	fma.rn.f32 	%f175, %f145, %f147, %f42;
	and.b32  	%r232, %r62, 2;
	setp.eq.s32 	%p89, %r232, 0;
	@%p89 bra 	$L__BB0_70;

	mov.f32 	%f149, 0fBF800000;
	fma.rn.f32 	%f175, %f175, %f149, %f146;

$L__BB0_70:
	cvta.to.global.u64 	%rd86, %rd32;
	add.s64 	%rd88, %rd86, %rd35;
	mul.rn.f32 	%f150, %f175, %f16;
	st.global.f32 	[%rd88], %f150;
	@%p80 bra 	$L__BB0_78;

	setp.eq.f32 	%p91, %f38, 0f7F800000;
	@%p91 bra 	$L__BB0_77;
	bra.uni 	$L__BB0_72;

$L__BB0_77:
	mov.f32 	%f153, 0f00000000;
	mul.rn.f32 	%f176, %f36, %f153;
	mov.u32 	%r286, 0;
	bra.uni 	$L__BB0_78;

$L__BB0_72:
	mov.b32 	%r64, %f36;
	bfe.u32 	%r238, %r64, 23, 8;
	add.s32 	%r65, %r238, -128;
	shl.b32 	%r239, %r64, 8;
	or.b32  	%r66, %r239, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd118, 0;
	mov.u32 	%r283, 0;
	mov.u64 	%rd117, __cudart_i2opi_f;

$L__BB0_73:
	.pragma "nounroll";
	ld.global.nc.u32 	%r240, [%rd117];
	mad.wide.u32 	%rd92, %r240, %r66, %rd118;
	shr.u64 	%rd118, %rd92, 32;
	st.local.u32 	[%rd116], %rd92;
	add.s64 	%rd117, %rd117, 4;
	add.s64 	%rd116, %rd116, 4;
	add.s32 	%r283, %r283, 1;
	setp.ne.s32 	%p92, %r283, 6;
	@%p92 bra 	$L__BB0_73;

	st.local.u32 	[%rd1], %rd118;
	mov.u32 	%r241, 4;
	sub.s32 	%r70, %r241, %r67;
	mov.u32 	%r242, 6;
	sub.s32 	%r243, %r242, %r67;
	cvta.to.local.u64 	%rd94, %rd39;
	mul.wide.s32 	%rd95, %r243, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.local.u32 	%r284, [%rd96];
	ld.local.u32 	%r285, [%rd96+-4];
	and.b32  	%r73, %r65, 31;
	setp.eq.s32 	%p93, %r73, 0;
	@%p93 bra 	$L__BB0_76;

	mov.u32 	%r244, 32;
	sub.s32 	%r245, %r244, %r73;
	shr.u32 	%r246, %r285, %r245;
	shl.b32 	%r247, %r284, %r73;
	add.s32 	%r284, %r246, %r247;
	mul.wide.s32 	%rd99, %r70, 4;
	add.s64 	%rd100, %rd94, %rd99;
	ld.local.u32 	%r248, [%rd100];
	shr.u32 	%r249, %r248, %r245;
	shl.b32 	%r250, %r285, %r73;
	add.s32 	%r285, %r249, %r250;

$L__BB0_76:
	and.b32  	%r251, %r64, -2147483648;
	shr.u32 	%r252, %r285, 30;
	shl.b32 	%r253, %r284, 2;
	or.b32  	%r254, %r252, %r253;
	shr.u32 	%r255, %r254, 31;
	shr.u32 	%r256, %r284, 30;
	add.s32 	%r257, %r255, %r256;
	neg.s32 	%r258, %r257;
	setp.eq.s32 	%p94, %r251, 0;
	selp.b32 	%r286, %r257, %r258, %p94;
	setp.ne.s32 	%p95, %r255, 0;
	xor.b32  	%r259, %r251, -2147483648;
	selp.b32 	%r260, %r259, %r251, %p95;
	selp.b32 	%r261, -1, 0, %p95;
	xor.b32  	%r262, %r254, %r261;
	shl.b32 	%r263, %r285, 2;
	xor.b32  	%r264, %r263, %r261;
	cvt.u64.u32 	%rd101, %r262;
	cvt.u64.u32 	%rd102, %r264;
	bfi.b64 	%rd103, %rd101, %rd102, 32, 32;
	cvt.rn.f64.s64 	%fd57, %rd103;
	mul.rn.f64 	%fd58, %fd57, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f151, %fd58;
	setp.eq.s32 	%p96, %r260, 0;
	neg.f32 	%f152, %f151;
	selp.f32 	%f176, %f151, %f152, %p96;

$L__BB0_78:
	and.b32  	%r80, %r286, 1;
	setp.eq.s32 	%p97, %r80, 0;
	selp.f32 	%f52, %f176, 0f3F800000, %p97;
	mul.rn.f32 	%f53, %f176, %f176;
	mov.f32 	%f177, 0fB94D4153;
	@%p97 bra 	$L__BB0_80;

	mov.f32 	%f155, 0fBAB607ED;
	mov.f32 	%f156, 0f37CBAC00;
	fma.rn.f32 	%f177, %f156, %f53, %f155;

$L__BB0_80:
	selp.f32 	%f157, 0f3C0885E4, 0f3D2AAABB, %p97;
	fma.rn.f32 	%f158, %f177, %f53, %f157;
	selp.f32 	%f159, 0fBE2AAAA8, 0fBEFFFFFF, %p97;
	fma.rn.f32 	%f160, %f158, %f53, %f159;
	mov.f32 	%f161, 0f00000000;
	fma.rn.f32 	%f162, %f53, %f52, %f161;
	fma.rn.f32 	%f178, %f160, %f162, %f52;
	and.b32  	%r266, %r286, 2;
	setp.eq.s32 	%p99, %r266, 0;
	@%p99 bra 	$L__BB0_82;

	mov.f32 	%f164, 0fBF800000;
	fma.rn.f32 	%f178, %f178, %f164, %f161;

$L__BB0_82:
	cvta.to.global.u64 	%rd104, %rd33;
	add.s64 	%rd106, %rd104, %rd35;
	mul.rn.f32 	%f165, %f178, %f16;
	st.global.f32 	[%rd106], %f165;

$L__BB0_83:
	ret;

}
	// .globl	gcj02_to_bd09_cuda_float
.visible .entry gcj02_to_bd09_cuda_float(
	.param .u32 gcj02_to_bd09_cuda_float_param_0,
	.param .u64 gcj02_to_bd09_cuda_float_param_1,
	.param .u64 gcj02_to_bd09_cuda_float_param_2,
	.param .u64 gcj02_to_bd09_cuda_float_param_3,
	.param .u64 gcj02_to_bd09_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot1[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<100>;
	.reg .f32 	%f<179>;
	.reg .b32 	%r<287>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<119>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r81, [gcj02_to_bd09_cuda_float_param_0];
	ld.param.u64 	%rd30, [gcj02_to_bd09_cuda_float_param_1];
	ld.param.u64 	%rd31, [gcj02_to_bd09_cuda_float_param_2];
	ld.param.u64 	%rd32, [gcj02_to_bd09_cuda_float_param_3];
	ld.param.u64 	%rd33, [gcj02_to_bd09_cuda_float_param_4];
	mov.u32 	%r82, %ntid.x;
	mov.u32 	%r83, %ctaid.x;
	mov.u32 	%r84, %tid.x;
	mad.lo.s32 	%r1, %r83, %r82, %r84;
	setp.ge.s32 	%p3, %r1, %r81;
	@%p3 bra 	$L__BB1_83;

	cvta.to.global.u64 	%rd34, %rd30;
	mul.wide.s32 	%rd35, %r1, 4;
	add.s64 	%rd36, %rd34, %rd35;
	cvta.to.global.u64 	%rd37, %rd31;
	add.s64 	%rd38, %rd37, %rd35;
	ld.global.f32 	%f1, [%rd38];
	ld.global.f32 	%f2, [%rd36];
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd24;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p4, %r4, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd61, [retval0+0];
	} // callseq 2
	setp.lt.s32 	%p5, %r2, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB1_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd61;
	}
	xor.b32  	%r86, %r85, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd61;
	}
	mov.b64 	%fd61, {%r87, %r86};

$L__BB1_3:
	setp.eq.f32 	%p7, %f2, 0f00000000;
	@%p7 bra 	$L__BB1_7;
	bra.uni 	$L__BB1_4;

$L__BB1_7:
	selp.b32 	%r88, %r2, 0, %p4;
	mov.u32 	%r89, 0;
	or.b32  	%r90, %r88, 2146435072;
	setp.lt.s32 	%p11, %r3, 0;
	selp.b32 	%r91, %r90, %r88, %p11;
	mov.b64 	%fd61, {%r89, %r91};
	bra.uni 	$L__BB1_8;

$L__BB1_4:
	setp.gt.s32 	%p8, %r2, -1;
	@%p8 bra 	$L__BB1_8;

	mov.f64 	%fd25, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd26, %fd25;
	setp.eq.f64 	%p9, %fd26, 0d4000000000000000;
	@%p9 bra 	$L__BB1_8;

	mov.f64 	%fd61, 0dFFF8000000000000;

$L__BB1_8:
	add.rn.f64 	%fd28, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd28;
	}
	and.b32  	%r93, %r92, 2146435072;
	setp.ne.s32 	%p12, %r93, 2146435072;
	@%p12 bra 	$L__BB1_15;

	setp.gtu.f64 	%p13, %fd2, 0d7FF0000000000000;
	@%p13 bra 	$L__BB1_14;
	bra.uni 	$L__BB1_10;

$L__BB1_14:
	mov.f64 	%fd30, 0d4000000000000000;
	add.rn.f64 	%fd61, %fd1, %fd30;
	bra.uni 	$L__BB1_15;

$L__BB1_10:
	mov.f64 	%fd29, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd29;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p14, %r5, 2146435072;
	setp.eq.s32 	%p15, %r94, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB1_13;
	bra.uni 	$L__BB1_11;

$L__BB1_13:
	setp.gt.f64 	%p23, %fd2, 0d3FF0000000000000;
	selp.b32 	%r101, 2146435072, 0, %p23;
	mov.u32 	%r102, 0;
	xor.b32  	%r103, %r101, 2146435072;
	setp.lt.s32 	%p24, %r3, 0;
	selp.b32 	%r104, %r103, %r101, %p24;
	setp.eq.f32 	%p25, %f2, 0fBF800000;
	selp.b32 	%r105, 1072693248, %r104, %p25;
	mov.b64 	%fd61, {%r102, %r105};
	bra.uni 	$L__BB1_15;

$L__BB1_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r95, %temp}, %fd1;
	}
	and.b32  	%r96, %r2, 2147483647;
	setp.ne.s32 	%p17, %r96, 2146435072;
	setp.ne.s32 	%p18, %r95, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB1_15;

	setp.gt.s32 	%p20, %r3, -1;
	selp.b32 	%r97, 2146435072, 0, %p20;
	mov.u32 	%r98, 0;
	setp.ne.s32 	%p21, %r5, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r99, %r97, -2147483648;
	selp.b32 	%r100, %r99, %r97, %p22;
	mov.b64 	%fd61, {%r98, %r100};

$L__BB1_15:
	cvt.f64.f32 	%fd12, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 3
	setp.lt.s32 	%p26, %r6, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB1_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd64;
	}
	xor.b32  	%r107, %r106, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %fd64;
	}
	mov.b64 	%fd64, {%r108, %r107};

$L__BB1_17:
	setp.eq.f32 	%p29, %f1, 0f00000000;
	@%p29 bra 	$L__BB1_21;
	bra.uni 	$L__BB1_18;

$L__BB1_21:
	selp.b32 	%r109, %r6, 0, %p4;
	mov.u32 	%r110, 0;
	or.b32  	%r111, %r109, 2146435072;
	setp.lt.s32 	%p33, %r3, 0;
	selp.b32 	%r112, %r111, %r109, %p33;
	mov.b64 	%fd64, {%r110, %r112};
	bra.uni 	$L__BB1_22;

$L__BB1_18:
	setp.gt.s32 	%p30, %r6, -1;
	@%p30 bra 	$L__BB1_22;

	mov.f64 	%fd31, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd32, %fd31;
	setp.eq.f64 	%p31, %fd32, 0d4000000000000000;
	@%p31 bra 	$L__BB1_22;

	mov.f64 	%fd64, 0dFFF8000000000000;

$L__BB1_22:
	add.rn.f64 	%fd34, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd34;
	}
	and.b32  	%r114, %r113, 2146435072;
	setp.ne.s32 	%p34, %r114, 2146435072;
	@%p34 bra 	$L__BB1_29;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB1_28;
	bra.uni 	$L__BB1_24;

$L__BB1_28:
	mov.f64 	%fd36, 0d4000000000000000;
	add.rn.f64 	%fd64, %fd12, %fd36;
	bra.uni 	$L__BB1_29;

$L__BB1_24:
	mov.f64 	%fd35, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd35;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p36, %r7, 2146435072;
	setp.eq.s32 	%p37, %r115, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_25;

$L__BB1_27:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r122, 2146435072, 0, %p45;
	mov.u32 	%r123, 0;
	xor.b32  	%r124, %r122, 2146435072;
	setp.lt.s32 	%p46, %r3, 0;
	selp.b32 	%r125, %r124, %r122, %p46;
	setp.eq.f32 	%p47, %f1, 0fBF800000;
	selp.b32 	%r126, 1072693248, %r125, %p47;
	mov.b64 	%fd64, {%r123, %r126};
	bra.uni 	$L__BB1_29;

$L__BB1_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd12;
	}
	and.b32  	%r117, %r6, 2147483647;
	setp.ne.s32 	%p39, %r117, 2146435072;
	setp.ne.s32 	%p40, %r116, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB1_29;

	setp.gt.s32 	%p42, %r3, -1;
	selp.b32 	%r118, 2146435072, 0, %p42;
	mov.u32 	%r119, 0;
	setp.ne.s32 	%p43, %r7, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r120, %r118, -2147483648;
	selp.b32 	%r121, %r120, %r118, %p44;
	mov.b64 	%fd64, {%r119, %r121};

$L__BB1_29:
	setp.eq.f32 	%p48, %f1, 0f3F800000;
	selp.f64 	%fd37, 0d3FF0000000000000, %fd64, %p48;
	setp.eq.f32 	%p49, %f2, 0f3F800000;
	selp.f64 	%fd38, 0d3FF0000000000000, %fd61, %p49;
	add.rn.f64 	%fd23, %fd38, %fd37;
	mul.rn.f32 	%f3, %f1, 0f42517084;
	mul.rn.f32 	%f59, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r274, %f59;
	cvt.rn.f32.s32 	%f60, %r274;
	mov.f32 	%f61, 0fBFC90FDA;
	fma.rn.f32 	%f62, %f60, %f61, %f3;
	mov.f32 	%f63, 0fB3A22168;
	fma.rn.f32 	%f64, %f60, %f63, %f62;
	mov.f32 	%f65, 0fA7C234C5;
	fma.rn.f32 	%f166, %f60, %f65, %f64;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p50, %f5, 0f47CE4780;
	add.u64 	%rd39, %SP, 0;
	add.u64 	%rd116, %SPL, 0;
	add.s64 	%rd1, %rd116, 24;
	@%p50 bra 	$L__BB1_37;

	setp.eq.f32 	%p51, %f5, 0f7F800000;
	@%p51 bra 	$L__BB1_36;
	bra.uni 	$L__BB1_31;

$L__BB1_36:
	mov.f32 	%f68, 0f00000000;
	mul.rn.f32 	%f166, %f3, %f68;
	mov.u32 	%r274, 0;
	bra.uni 	$L__BB1_37;

$L__BB1_31:
	mov.b32 	%r9, %f3;
	bfe.u32 	%r128, %r9, 23, 8;
	add.s32 	%r10, %r128, -128;
	shl.b32 	%r129, %r9, 8;
	or.b32  	%r11, %r129, -2147483648;
	shr.u32 	%r12, %r10, 5;
	cvta.to.local.u64 	%rd107, %rd39;
	mov.u64 	%rd109, 0;
	mov.u32 	%r271, 0;
	mov.u64 	%rd108, __cudart_i2opi_f;

$L__BB1_32:
	.pragma "nounroll";
	ld.global.nc.u32 	%r130, [%rd108];
	mad.wide.u32 	%rd44, %r130, %r11, %rd109;
	shr.u64 	%rd109, %rd44, 32;
	st.local.u32 	[%rd107], %rd44;
	add.s64 	%rd108, %rd108, 4;
	add.s64 	%rd107, %rd107, 4;
	add.s32 	%r271, %r271, 1;
	setp.ne.s32 	%p52, %r271, 6;
	@%p52 bra 	$L__BB1_32;

	st.local.u32 	[%rd1], %rd109;
	mov.u32 	%r131, 4;
	sub.s32 	%r15, %r131, %r12;
	mov.u32 	%r132, 6;
	sub.s32 	%r133, %r132, %r12;
	cvta.to.local.u64 	%rd46, %rd39;
	mul.wide.s32 	%rd47, %r133, 4;
	add.s64 	%rd48, %rd46, %rd47;
	ld.local.u32 	%r272, [%rd48];
	ld.local.u32 	%r273, [%rd48+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p53, %r18, 0;
	@%p53 bra 	$L__BB1_35;

	mov.u32 	%r134, 32;
	sub.s32 	%r135, %r134, %r18;
	shr.u32 	%r136, %r273, %r135;
	shl.b32 	%r137, %r272, %r18;
	add.s32 	%r272, %r136, %r137;
	mul.wide.s32 	%rd51, %r15, 4;
	add.s64 	%rd52, %rd46, %rd51;
	ld.local.u32 	%r138, [%rd52];
	shr.u32 	%r139, %r138, %r135;
	shl.b32 	%r140, %r273, %r18;
	add.s32 	%r273, %r139, %r140;

$L__BB1_35:
	and.b32  	%r141, %r9, -2147483648;
	shr.u32 	%r142, %r273, 30;
	shl.b32 	%r143, %r272, 2;
	or.b32  	%r144, %r142, %r143;
	shr.u32 	%r145, %r144, 31;
	shr.u32 	%r146, %r272, 30;
	add.s32 	%r147, %r145, %r146;
	neg.s32 	%r148, %r147;
	setp.eq.s32 	%p54, %r141, 0;
	selp.b32 	%r274, %r147, %r148, %p54;
	setp.ne.s32 	%p55, %r145, 0;
	xor.b32  	%r149, %r141, -2147483648;
	selp.b32 	%r150, %r149, %r141, %p55;
	selp.b32 	%r151, -1, 0, %p55;
	xor.b32  	%r152, %r144, %r151;
	shl.b32 	%r153, %r273, 2;
	xor.b32  	%r154, %r153, %r151;
	cvt.u64.u32 	%rd53, %r152;
	cvt.u64.u32 	%rd54, %r154;
	bfi.b64 	%rd55, %rd53, %rd54, 32, 32;
	cvt.rn.f64.s64 	%fd39, %rd55;
	mul.rn.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f66, %fd40;
	setp.eq.s32 	%p56, %r150, 0;
	neg.f32 	%f67, %f66;
	selp.f32 	%f166, %f66, %f67, %p56;

$L__BB1_37:
	and.b32  	%r25, %r274, 1;
	setp.eq.s32 	%p57, %r25, 0;
	selp.f32 	%f9, %f166, 0f3F800000, %p57;
	mul.rn.f32 	%f10, %f166, %f166;
	mov.f32 	%f167, 0fB94D4153;
	@%p57 bra 	$L__BB1_39;

	mov.f32 	%f70, 0fBAB607ED;
	mov.f32 	%f71, 0f37CBAC00;
	fma.rn.f32 	%f167, %f71, %f10, %f70;

$L__BB1_39:
	selp.f32 	%f72, 0f3C0885E4, 0f3D2AAABB, %p57;
	fma.rn.f32 	%f73, %f167, %f10, %f72;
	selp.f32 	%f74, 0fBE2AAAA8, 0fBEFFFFFF, %p57;
	fma.rn.f32 	%f75, %f73, %f10, %f74;
	mov.f32 	%f76, 0f00000000;
	fma.rn.f32 	%f77, %f10, %f9, %f76;
	fma.rn.f32 	%f168, %f75, %f77, %f9;
	and.b32  	%r156, %r274, 2;
	setp.eq.s32 	%p59, %r156, 0;
	@%p59 bra 	$L__BB1_41;

	mov.f32 	%f79, 0fBF800000;
	fma.rn.f32 	%f168, %f168, %f79, %f76;

$L__BB1_41:
	cvt.f64.f32 	%fd41, %f168;
	mul.rn.f64 	%fd42, %fd41, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd43, %fd23;
	add.rn.f64 	%fd44, %fd43, %fd42;
	cvt.rn.f32.f64 	%f16, %fd44;
	abs.f32 	%f17, %f2;
	setp.eq.f32 	%p60, %f17, 0f00000000;
	abs.f32 	%f18, %f1;
	setp.eq.f32 	%p61, %f18, 0f00000000;
	and.pred  	%p62, %p60, %p61;
	@%p62 bra 	$L__BB1_45;
	bra.uni 	$L__BB1_42;

$L__BB1_45:
	mov.b32 	%r167, %f2;
	shr.s32 	%r168, %r167, 31;
	and.b32  	%r169, %r168, 1078530011;
	mov.b32 	%r170, %f1;
	and.b32  	%r171, %r170, -2147483648;
	or.b32  	%r172, %r169, %r171;
	mov.b32 	%f169, %r172;
	bra.uni 	$L__BB1_46;

$L__BB1_42:
	setp.eq.f32 	%p63, %f17, 0f7F800000;
	setp.eq.f32 	%p64, %f18, 0f7F800000;
	and.pred  	%p65, %p63, %p64;
	@%p65 bra 	$L__BB1_44;
	bra.uni 	$L__BB1_43;

$L__BB1_44:
	mov.b32 	%r162, %f2;
	setp.lt.s32 	%p69, %r162, 0;
	selp.b32 	%r163, 1075235812, 1061752795, %p69;
	mov.b32 	%r164, %f1;
	and.b32  	%r165, %r164, -2147483648;
	or.b32  	%r166, %r163, %r165;
	mov.b32 	%f169, %r166;
	bra.uni 	$L__BB1_46;

$L__BB1_43:
	max.f32 	%f80, %f18, %f17;
	min.f32 	%f81, %f18, %f17;
	div.rn.f32 	%f82, %f81, %f80;
	mul.rn.f32 	%f83, %f82, %f82;
	mov.f32 	%f84, 0fC0B59883;
	mov.f32 	%f85, 0fBF52C7EA;
	fma.rn.f32 	%f86, %f83, %f85, %f84;
	mov.f32 	%f87, 0fC0D21907;
	fma.rn.f32 	%f88, %f86, %f83, %f87;
	mul.rn.f32 	%f89, %f83, %f88;
	mul.rn.f32 	%f90, %f82, %f89;
	add.rn.f32 	%f91, %f83, 0f41355DC0;
	mov.f32 	%f92, 0f41E6BD60;
	fma.rn.f32 	%f93, %f91, %f83, %f92;
	mov.f32 	%f94, 0f419D92C8;
	fma.rn.f32 	%f95, %f93, %f83, %f94;
	rcp.rn.f32 	%f96, %f95;
	fma.rn.f32 	%f97, %f90, %f96, %f82;
	mov.f32 	%f98, 0f3FC90FDB;
	sub.rn.f32 	%f99, %f98, %f97;
	setp.gt.f32 	%p66, %f18, %f17;
	selp.f32 	%f100, %f99, %f97, %p66;
	mov.b32 	%r157, %f2;
	setp.lt.s32 	%p67, %r157, 0;
	mov.f32 	%f101, 0f40490FDB;
	sub.rn.f32 	%f102, %f101, %f100;
	selp.f32 	%f103, %f102, %f100, %p67;
	mov.b32 	%r158, %f103;
	mov.b32 	%r159, %f1;
	and.b32  	%r160, %r159, -2147483648;
	or.b32  	%r161, %r160, %r158;
	mov.b32 	%f104, %r161;
	add.rn.f32 	%f105, %f17, %f18;
	setp.le.f32 	%p68, %f105, 0f7F800000;
	selp.f32 	%f169, %f104, %f105, %p68;

$L__BB1_46:
	mul.rn.f32 	%f23, %f2, 0f42517084;
	mul.rn.f32 	%f106, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r278, %f106;
	cvt.rn.f32.s32 	%f107, %r278;
	mov.f32 	%f108, 0fBFC90FDA;
	fma.rn.f32 	%f109, %f107, %f108, %f23;
	mov.f32 	%f110, 0fB3A22168;
	fma.rn.f32 	%f111, %f107, %f110, %f109;
	mov.f32 	%f112, 0fA7C234C5;
	fma.rn.f32 	%f170, %f107, %f112, %f111;
	abs.f32 	%f25, %f23;
	setp.ltu.f32 	%p70, %f25, 0f47CE4780;
	@%p70 bra 	$L__BB1_54;

	setp.eq.f32 	%p71, %f25, 0f7F800000;
	@%p71 bra 	$L__BB1_53;
	bra.uni 	$L__BB1_48;

$L__BB1_53:
	mov.f32 	%f115, 0f00000000;
	mul.rn.f32 	%f170, %f23, %f115;
	mov.u32 	%r278, 0;
	bra.uni 	$L__BB1_54;

$L__BB1_48:
	mov.b32 	%r27, %f23;
	bfe.u32 	%r174, %r27, 23, 8;
	add.s32 	%r28, %r174, -128;
	shl.b32 	%r175, %r27, 8;
	or.b32  	%r29, %r175, -2147483648;
	shr.u32 	%r30, %r28, 5;
	cvta.to.local.u64 	%rd110, %rd39;
	mov.u64 	%rd112, 0;
	mov.u32 	%r275, 0;
	mov.u64 	%rd111, __cudart_i2opi_f;

$L__BB1_49:
	.pragma "nounroll";
	ld.global.nc.u32 	%r176, [%rd111];
	mad.wide.u32 	%rd59, %r176, %r29, %rd112;
	shr.u64 	%rd112, %rd59, 32;
	st.local.u32 	[%rd110], %rd59;
	add.s64 	%rd111, %rd111, 4;
	add.s64 	%rd110, %rd110, 4;
	add.s32 	%r275, %r275, 1;
	setp.ne.s32 	%p72, %r275, 6;
	@%p72 bra 	$L__BB1_49;

	st.local.u32 	[%rd1], %rd112;
	mov.u32 	%r177, 4;
	sub.s32 	%r33, %r177, %r30;
	mov.u32 	%r178, 6;
	sub.s32 	%r179, %r178, %r30;
	cvta.to.local.u64 	%rd61, %rd39;
	mul.wide.s32 	%rd62, %r179, 4;
	add.s64 	%rd63, %rd61, %rd62;
	ld.local.u32 	%r276, [%rd63];
	ld.local.u32 	%r277, [%rd63+-4];
	and.b32  	%r36, %r28, 31;
	setp.eq.s32 	%p73, %r36, 0;
	@%p73 bra 	$L__BB1_52;

	mov.u32 	%r180, 32;
	sub.s32 	%r181, %r180, %r36;
	shr.u32 	%r182, %r277, %r181;
	shl.b32 	%r183, %r276, %r36;
	add.s32 	%r276, %r182, %r183;
	mul.wide.s32 	%rd66, %r33, 4;
	add.s64 	%rd67, %rd61, %rd66;
	ld.local.u32 	%r184, [%rd67];
	shr.u32 	%r185, %r184, %r181;
	shl.b32 	%r186, %r277, %r36;
	add.s32 	%r277, %r185, %r186;

$L__BB1_52:
	and.b32  	%r187, %r27, -2147483648;
	shr.u32 	%r188, %r277, 30;
	shl.b32 	%r189, %r276, 2;
	or.b32  	%r190, %r188, %r189;
	shr.u32 	%r191, %r190, 31;
	shr.u32 	%r192, %r276, 30;
	add.s32 	%r193, %r191, %r192;
	neg.s32 	%r194, %r193;
	setp.eq.s32 	%p74, %r187, 0;
	selp.b32 	%r278, %r193, %r194, %p74;
	setp.ne.s32 	%p75, %r191, 0;
	xor.b32  	%r195, %r187, -2147483648;
	selp.b32 	%r196, %r195, %r187, %p75;
	selp.b32 	%r197, -1, 0, %p75;
	xor.b32  	%r198, %r190, %r197;
	shl.b32 	%r199, %r277, 2;
	xor.b32  	%r200, %r199, %r197;
	cvt.u64.u32 	%rd68, %r198;
	cvt.u64.u32 	%rd69, %r200;
	bfi.b64 	%rd70, %rd68, %rd69, 32, 32;
	cvt.rn.f64.s64 	%fd45, %rd70;
	mul.rn.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f113, %fd46;
	setp.eq.s32 	%p76, %r196, 0;
	neg.f32 	%f114, %f113;
	selp.f32 	%f170, %f113, %f114, %p76;

$L__BB1_54:
	add.s32 	%r43, %r278, 1;
	and.b32  	%r44, %r43, 1;
	setp.eq.s32 	%p77, %r44, 0;
	selp.f32 	%f29, %f170, 0f3F800000, %p77;
	mul.rn.f32 	%f30, %f170, %f170;
	mov.f32 	%f171, 0fB94D4153;
	@%p77 bra 	$L__BB1_56;

	mov.f32 	%f117, 0fBAB607ED;
	mov.f32 	%f118, 0f37CBAC00;
	fma.rn.f32 	%f171, %f118, %f30, %f117;

$L__BB1_56:
	selp.f32 	%f119, 0f3C0885E4, 0f3D2AAABB, %p77;
	fma.rn.f32 	%f120, %f171, %f30, %f119;
	selp.f32 	%f121, 0fBE2AAAA8, 0fBEFFFFFF, %p77;
	fma.rn.f32 	%f122, %f120, %f30, %f121;
	mov.f32 	%f123, 0f00000000;
	fma.rn.f32 	%f124, %f30, %f29, %f123;
	fma.rn.f32 	%f172, %f122, %f124, %f29;
	and.b32  	%r202, %r43, 2;
	setp.eq.s32 	%p79, %r202, 0;
	@%p79 bra 	$L__BB1_58;

	mov.f32 	%f126, 0fBF800000;
	fma.rn.f32 	%f172, %f172, %f126, %f123;

$L__BB1_58:
	cvt.f64.f32 	%fd47, %f172;
	mul.rn.f64 	%fd48, %fd47, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd49, %f169;
	add.rn.f64 	%fd50, %fd48, %fd49;
	cvt.rn.f32.f64 	%f36, %fd50;
	mul.rn.f32 	%f127, %f36, 0f3F22F983;
	cvt.rni.s32.f32 	%r286, %f127;
	cvt.rn.f32.s32 	%f128, %r286;
	mov.f32 	%f129, 0fBFC90FDA;
	fma.rn.f32 	%f130, %f128, %f129, %f36;
	mov.f32 	%f131, 0fB3A22168;
	fma.rn.f32 	%f132, %f128, %f131, %f130;
	mov.f32 	%f133, 0fA7C234C5;
	fma.rn.f32 	%f176, %f128, %f133, %f132;
	abs.f32 	%f38, %f36;
	setp.ltu.f32 	%p80, %f38, 0f47CE4780;
	mov.u32 	%r282, %r286;
	mov.f32 	%f173, %f176;
	@%p80 bra 	$L__BB1_66;

	setp.eq.f32 	%p81, %f38, 0f7F800000;
	@%p81 bra 	$L__BB1_65;
	bra.uni 	$L__BB1_60;

$L__BB1_65:
	mov.f32 	%f136, 0f00000000;
	mul.rn.f32 	%f173, %f36, %f136;
	mov.u32 	%r282, 0;
	bra.uni 	$L__BB1_66;

$L__BB1_60:
	mov.b32 	%r46, %f36;
	bfe.u32 	%r204, %r46, 23, 8;
	add.s32 	%r47, %r204, -128;
	shl.b32 	%r205, %r46, 8;
	or.b32  	%r48, %r205, -2147483648;
	shr.u32 	%r49, %r47, 5;
	cvta.to.local.u64 	%rd113, %rd39;
	mov.u64 	%rd115, 0;
	mov.u32 	%r279, 0;
	mov.u64 	%rd114, __cudart_i2opi_f;

$L__BB1_61:
	.pragma "nounroll";
	ld.global.nc.u32 	%r206, [%rd114];
	mad.wide.u32 	%rd74, %r206, %r48, %rd115;
	shr.u64 	%rd115, %rd74, 32;
	st.local.u32 	[%rd113], %rd74;
	add.s64 	%rd114, %rd114, 4;
	add.s64 	%rd113, %rd113, 4;
	add.s32 	%r279, %r279, 1;
	setp.ne.s32 	%p82, %r279, 6;
	@%p82 bra 	$L__BB1_61;

	st.local.u32 	[%rd1], %rd115;
	mov.u32 	%r207, 4;
	sub.s32 	%r52, %r207, %r49;
	mov.u32 	%r208, 6;
	sub.s32 	%r209, %r208, %r49;
	cvta.to.local.u64 	%rd76, %rd39;
	mul.wide.s32 	%rd77, %r209, 4;
	add.s64 	%rd78, %rd76, %rd77;
	ld.local.u32 	%r280, [%rd78];
	ld.local.u32 	%r281, [%rd78+-4];
	and.b32  	%r55, %r47, 31;
	setp.eq.s32 	%p83, %r55, 0;
	@%p83 bra 	$L__BB1_64;

	mov.u32 	%r210, 32;
	sub.s32 	%r211, %r210, %r55;
	shr.u32 	%r212, %r281, %r211;
	shl.b32 	%r213, %r280, %r55;
	add.s32 	%r280, %r212, %r213;
	mul.wide.s32 	%rd81, %r52, 4;
	add.s64 	%rd82, %rd76, %rd81;
	ld.local.u32 	%r214, [%rd82];
	shr.u32 	%r215, %r214, %r211;
	shl.b32 	%r216, %r281, %r55;
	add.s32 	%r281, %r215, %r216;

$L__BB1_64:
	and.b32  	%r217, %r46, -2147483648;
	shr.u32 	%r218, %r281, 30;
	shl.b32 	%r219, %r280, 2;
	or.b32  	%r220, %r218, %r219;
	shr.u32 	%r221, %r220, 31;
	shr.u32 	%r222, %r280, 30;
	add.s32 	%r223, %r221, %r222;
	neg.s32 	%r224, %r223;
	setp.eq.s32 	%p84, %r217, 0;
	selp.b32 	%r282, %r223, %r224, %p84;
	setp.ne.s32 	%p85, %r221, 0;
	xor.b32  	%r225, %r217, -2147483648;
	selp.b32 	%r226, %r225, %r217, %p85;
	selp.b32 	%r227, -1, 0, %p85;
	xor.b32  	%r228, %r220, %r227;
	shl.b32 	%r229, %r281, 2;
	xor.b32  	%r230, %r229, %r227;
	cvt.u64.u32 	%rd83, %r228;
	cvt.u64.u32 	%rd84, %r230;
	bfi.b64 	%rd85, %rd83, %rd84, 32, 32;
	cvt.rn.f64.s64 	%fd51, %rd85;
	mul.rn.f64 	%fd52, %fd51, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f134, %fd52;
	setp.eq.s32 	%p86, %r226, 0;
	neg.f32 	%f135, %f134;
	selp.f32 	%f173, %f134, %f135, %p86;

$L__BB1_66:
	add.s32 	%r62, %r282, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p87, %r63, 0;
	selp.f32 	%f42, %f173, 0f3F800000, %p87;
	mul.rn.f32 	%f43, %f173, %f173;
	mov.f32 	%f174, 0fB94D4153;
	@%p87 bra 	$L__BB1_68;

	mov.f32 	%f138, 0fBAB607ED;
	mov.f32 	%f139, 0f37CBAC00;
	fma.rn.f32 	%f174, %f139, %f43, %f138;

$L__BB1_68:
	selp.f32 	%f140, 0f3C0885E4, 0f3D2AAABB, %p87;
	fma.rn.f32 	%f141, %f174, %f43, %f140;
	selp.f32 	%f142, 0fBE2AAAA8, 0fBEFFFFFF, %p87;
	fma.rn.f32 	%f143, %f141, %f43, %f142;
	mov.f32 	%f144, 0f00000000;
	fma.rn.f32 	%f145, %f43, %f42, %f144;
	fma.rn.f32 	%f175, %f143, %f145, %f42;
	and.b32  	%r232, %r62, 2;
	setp.eq.s32 	%p89, %r232, 0;
	@%p89 bra 	$L__BB1_70;

	mov.f32 	%f147, 0fBF800000;
	fma.rn.f32 	%f175, %f175, %f147, %f144;

$L__BB1_70:
	mul.rn.f32 	%f148, %f175, %f16;
	cvt.f64.f32 	%fd53, %f148;
	add.rn.f64 	%fd54, %fd53, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f149, %fd54;
	cvta.to.global.u64 	%rd86, %rd32;
	add.s64 	%rd88, %rd86, %rd35;
	st.global.f32 	[%rd88], %f149;
	@%p80 bra 	$L__BB1_78;

	setp.eq.f32 	%p91, %f38, 0f7F800000;
	@%p91 bra 	$L__BB1_77;
	bra.uni 	$L__BB1_72;

$L__BB1_77:
	mov.f32 	%f152, 0f00000000;
	mul.rn.f32 	%f176, %f36, %f152;
	mov.u32 	%r286, 0;
	bra.uni 	$L__BB1_78;

$L__BB1_72:
	mov.b32 	%r64, %f36;
	bfe.u32 	%r238, %r64, 23, 8;
	add.s32 	%r65, %r238, -128;
	shl.b32 	%r239, %r64, 8;
	or.b32  	%r66, %r239, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd118, 0;
	mov.u32 	%r283, 0;
	mov.u64 	%rd117, __cudart_i2opi_f;

$L__BB1_73:
	.pragma "nounroll";
	ld.global.nc.u32 	%r240, [%rd117];
	mad.wide.u32 	%rd92, %r240, %r66, %rd118;
	shr.u64 	%rd118, %rd92, 32;
	st.local.u32 	[%rd116], %rd92;
	add.s64 	%rd117, %rd117, 4;
	add.s64 	%rd116, %rd116, 4;
	add.s32 	%r283, %r283, 1;
	setp.ne.s32 	%p92, %r283, 6;
	@%p92 bra 	$L__BB1_73;

	st.local.u32 	[%rd1], %rd118;
	mov.u32 	%r241, 4;
	sub.s32 	%r70, %r241, %r67;
	mov.u32 	%r242, 6;
	sub.s32 	%r243, %r242, %r67;
	cvta.to.local.u64 	%rd94, %rd39;
	mul.wide.s32 	%rd95, %r243, 4;
	add.s64 	%rd96, %rd94, %rd95;
	ld.local.u32 	%r284, [%rd96];
	ld.local.u32 	%r285, [%rd96+-4];
	and.b32  	%r73, %r65, 31;
	setp.eq.s32 	%p93, %r73, 0;
	@%p93 bra 	$L__BB1_76;

	mov.u32 	%r244, 32;
	sub.s32 	%r245, %r244, %r73;
	shr.u32 	%r246, %r285, %r245;
	shl.b32 	%r247, %r284, %r73;
	add.s32 	%r284, %r246, %r247;
	mul.wide.s32 	%rd99, %r70, 4;
	add.s64 	%rd100, %rd94, %rd99;
	ld.local.u32 	%r248, [%rd100];
	shr.u32 	%r249, %r248, %r245;
	shl.b32 	%r250, %r285, %r73;
	add.s32 	%r285, %r249, %r250;

$L__BB1_76:
	and.b32  	%r251, %r64, -2147483648;
	shr.u32 	%r252, %r285, 30;
	shl.b32 	%r253, %r284, 2;
	or.b32  	%r254, %r252, %r253;
	shr.u32 	%r255, %r254, 31;
	shr.u32 	%r256, %r284, 30;
	add.s32 	%r257, %r255, %r256;
	neg.s32 	%r258, %r257;
	setp.eq.s32 	%p94, %r251, 0;
	selp.b32 	%r286, %r257, %r258, %p94;
	setp.ne.s32 	%p95, %r255, 0;
	xor.b32  	%r259, %r251, -2147483648;
	selp.b32 	%r260, %r259, %r251, %p95;
	selp.b32 	%r261, -1, 0, %p95;
	xor.b32  	%r262, %r254, %r261;
	shl.b32 	%r263, %r285, 2;
	xor.b32  	%r264, %r263, %r261;
	cvt.u64.u32 	%rd101, %r262;
	cvt.u64.u32 	%rd102, %r264;
	bfi.b64 	%rd103, %rd101, %rd102, 32, 32;
	cvt.rn.f64.s64 	%fd55, %rd103;
	mul.rn.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f150, %fd56;
	setp.eq.s32 	%p96, %r260, 0;
	neg.f32 	%f151, %f150;
	selp.f32 	%f176, %f150, %f151, %p96;

$L__BB1_78:
	and.b32  	%r80, %r286, 1;
	setp.eq.s32 	%p97, %r80, 0;
	selp.f32 	%f52, %f176, 0f3F800000, %p97;
	mul.rn.f32 	%f53, %f176, %f176;
	mov.f32 	%f177, 0fB94D4153;
	@%p97 bra 	$L__BB1_80;

	mov.f32 	%f154, 0fBAB607ED;
	mov.f32 	%f155, 0f37CBAC00;
	fma.rn.f32 	%f177, %f155, %f53, %f154;

$L__BB1_80:
	selp.f32 	%f156, 0f3C0885E4, 0f3D2AAABB, %p97;
	fma.rn.f32 	%f157, %f177, %f53, %f156;
	selp.f32 	%f158, 0fBE2AAAA8, 0fBEFFFFFF, %p97;
	fma.rn.f32 	%f159, %f157, %f53, %f158;
	mov.f32 	%f160, 0f00000000;
	fma.rn.f32 	%f161, %f53, %f52, %f160;
	fma.rn.f32 	%f178, %f159, %f161, %f52;
	and.b32  	%r266, %r286, 2;
	setp.eq.s32 	%p99, %r266, 0;
	@%p99 bra 	$L__BB1_82;

	mov.f32 	%f163, 0fBF800000;
	fma.rn.f32 	%f178, %f178, %f163, %f160;

$L__BB1_82:
	mul.rn.f32 	%f164, %f178, %f16;
	cvt.f64.f32 	%fd57, %f164;
	add.rn.f64 	%fd58, %fd57, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f165, %fd58;
	cvta.to.global.u64 	%rd104, %rd33;
	add.s64 	%rd106, %rd104, %rd35;
	st.global.f32 	[%rd106], %f165;

$L__BB1_83:
	ret;

}
	// .globl	gcj02_to_wgs84_cuda_float
.visible .entry gcj02_to_wgs84_cuda_float(
	.param .u32 gcj02_to_wgs84_cuda_float_param_0,
	.param .u64 gcj02_to_wgs84_cuda_float_param_1,
	.param .u64 gcj02_to_wgs84_cuda_float_param_2,
	.param .u64 gcj02_to_wgs84_cuda_float_param_3,
	.param .u64 gcj02_to_wgs84_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot2[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<138>;
	.reg .f32 	%f<163>;
	.reg .b32 	%r<362>;
	.reg .f64 	%fd<445>;
	.reg .b64 	%rd<152>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r104, [gcj02_to_wgs84_cuda_float_param_0];
	ld.param.u64 	%rd36, [gcj02_to_wgs84_cuda_float_param_1];
	ld.param.u64 	%rd37, [gcj02_to_wgs84_cuda_float_param_2];
	add.u64 	%rd40, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r105, %ntid.x;
	mov.u32 	%r106, %ctaid.x;
	mov.u32 	%r107, %tid.x;
	mad.lo.s32 	%r1, %r106, %r105, %r107;
	setp.ge.s32 	%p4, %r1, %r104;
	@%p4 bra 	$L__BB2_142;

	cvta.to.global.u64 	%rd49, %rd36;
	mul.wide.s32 	%rd50, %r1, 4;
	add.s64 	%rd51, %rd49, %rd50;
	cvta.to.global.u64 	%rd52, %rd37;
	add.s64 	%rd53, %rd52, %rd50;
	ld.global.f32 	%f1, [%rd51];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd53];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd136, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd136;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd137, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd137;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd4;
	}
	and.b32  	%r110, %r109, 2147483647;
	setp.eq.s32 	%p5, %r110, 2146435072;
	setp.eq.s32 	%p6, %r108, 0;
	and.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB2_4;
	bra.uni 	$L__BB2_2;

$L__BB2_4:
	mov.f64 	%fd147, 0d0000000000000000;
	mul.rn.f64 	%fd415, %fd4, %fd147;
	mov.u32 	%r338, 0;
	bra.uni 	$L__BB2_5;

$L__BB2_2:
	mul.rn.f64 	%fd138, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd138;
	st.local.u32 	[%rd8], %r338;
	cvt.rn.f64.s32 	%fd139, %r338;
	neg.f64 	%fd140, %fd139;
	mov.f64 	%fd141, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd142, %fd140, %fd141, %fd4;
	mov.f64 	%fd143, 0d3C91A62633145C00;
	fma.rn.f64 	%fd144, %fd140, %fd143, %fd142;
	mov.f64 	%fd145, 0d397B839A252049C0;
	fma.rn.f64 	%fd415, %fd140, %fd145, %fd144;
	abs.f64 	%fd146, %fd4;
	setp.ltu.f64 	%p8, %fd146, 0d41E0000000000000;
	@%p8 bra 	$L__BB2_5;

	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd415, [retval0+0];
	} // callseq 4
	ld.local.u32 	%r338, [%rd8];

$L__BB2_5:
	and.b32  	%r112, %r338, 1;
	shl.b32 	%r113, %r338, 3;
	and.b32  	%r114, %r113, 8;
	setp.eq.s32 	%p9, %r112, 0;
	selp.f64 	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p9;
	mul.wide.s32 	%rd55, %r114, 8;
	mov.u64 	%rd56, __cudart_sin_cos_coeffs;
	add.s64 	%rd57, %rd56, %rd55;
	ld.global.nc.f64 	%fd149, [%rd57+8];
	mul.rn.f64 	%fd9, %fd415, %fd415;
	fma.rn.f64 	%fd150, %fd148, %fd9, %fd149;
	ld.global.nc.f64 	%fd151, [%rd57+16];
	fma.rn.f64 	%fd152, %fd150, %fd9, %fd151;
	ld.global.nc.f64 	%fd153, [%rd57+24];
	fma.rn.f64 	%fd154, %fd152, %fd9, %fd153;
	ld.global.nc.f64 	%fd155, [%rd57+32];
	fma.rn.f64 	%fd156, %fd154, %fd9, %fd155;
	ld.global.nc.f64 	%fd157, [%rd57+40];
	fma.rn.f64 	%fd158, %fd156, %fd9, %fd157;
	ld.global.nc.f64 	%fd159, [%rd57+48];
	fma.rn.f64 	%fd10, %fd158, %fd9, %fd159;
	fma.rn.f64 	%fd417, %fd10, %fd415, %fd415;
	@%p9 bra 	$L__BB2_7;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd417, %fd10, %fd9, %fd160;

$L__BB2_7:
	and.b32  	%r115, %r338, 2;
	setp.eq.s32 	%p10, %r115, 0;
	@%p10 bra 	$L__BB2_9;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd417, %fd417, %fd162, %fd161;

$L__BB2_9:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd16;
	}
	and.b32  	%r118, %r117, 2147483647;
	setp.eq.s32 	%p11, %r118, 2146435072;
	setp.eq.s32 	%p12, %r116, 0;
	and.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB2_12;
	bra.uni 	$L__BB2_10;

$L__BB2_12:
	mov.f64 	%fd172, 0d0000000000000000;
	mul.rn.f64 	%fd418, %fd16, %fd172;
	mov.u32 	%r339, 0;
	bra.uni 	$L__BB2_13;

$L__BB2_10:
	mul.rn.f64 	%fd163, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r339, %fd163;
	st.local.u32 	[%rd8], %r339;
	cvt.rn.f64.s32 	%fd164, %r339;
	neg.f64 	%fd165, %fd164;
	mov.f64 	%fd166, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd167, %fd165, %fd166, %fd16;
	mov.f64 	%fd168, 0d3C91A62633145C00;
	fma.rn.f64 	%fd169, %fd165, %fd168, %fd167;
	mov.f64 	%fd170, 0d397B839A252049C0;
	fma.rn.f64 	%fd418, %fd165, %fd170, %fd169;
	abs.f64 	%fd171, %fd16;
	setp.ltu.f64 	%p14, %fd171, 0d41E0000000000000;
	@%p14 bra 	$L__BB2_13;

	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd418, [retval0+0];
	} // callseq 5
	ld.local.u32 	%r339, [%rd8];

$L__BB2_13:
	and.b32  	%r120, %r339, 1;
	shl.b32 	%r121, %r339, 3;
	and.b32  	%r122, %r121, 8;
	setp.eq.s32 	%p15, %r120, 0;
	selp.f64 	%fd173, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p15;
	mul.wide.s32 	%rd59, %r122, 8;
	add.s64 	%rd61, %rd56, %rd59;
	ld.global.nc.f64 	%fd174, [%rd61+8];
	mul.rn.f64 	%fd21, %fd418, %fd418;
	fma.rn.f64 	%fd175, %fd173, %fd21, %fd174;
	ld.global.nc.f64 	%fd176, [%rd61+16];
	fma.rn.f64 	%fd177, %fd175, %fd21, %fd176;
	ld.global.nc.f64 	%fd178, [%rd61+24];
	fma.rn.f64 	%fd179, %fd177, %fd21, %fd178;
	ld.global.nc.f64 	%fd180, [%rd61+32];
	fma.rn.f64 	%fd181, %fd179, %fd21, %fd180;
	ld.global.nc.f64 	%fd182, [%rd61+40];
	fma.rn.f64 	%fd183, %fd181, %fd21, %fd182;
	ld.global.nc.f64 	%fd184, [%rd61+48];
	fma.rn.f64 	%fd22, %fd183, %fd21, %fd184;
	fma.rn.f64 	%fd420, %fd22, %fd418, %fd418;
	@%p15 bra 	$L__BB2_15;

	mov.f64 	%fd185, 0d3FF0000000000000;
	fma.rn.f64 	%fd420, %fd22, %fd21, %fd185;

$L__BB2_15:
	and.b32  	%r123, %r339, 2;
	setp.eq.s32 	%p16, %r123, 0;
	@%p16 bra 	$L__BB2_17;

	mov.f64 	%fd186, 0d0000000000000000;
	mov.f64 	%fd187, 0dBFF0000000000000;
	fma.rn.f64 	%fd420, %fd420, %fd187, %fd186;

$L__BB2_17:
	mul.rn.f64 	%fd188, %fd420, 0d4034000000000000;
	mul.rn.f64 	%fd189, %fd417, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd189, %fd188;
	mul.rn.f32 	%f53, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r343, %f53;
	cvt.rn.f32.s32 	%f54, %r343;
	mov.f32 	%f55, 0fBFC90FDA;
	fma.rn.f32 	%f56, %f54, %f55, %f6;
	mov.f32 	%f57, 0fB3A22168;
	fma.rn.f32 	%f58, %f54, %f57, %f56;
	mov.f32 	%f59, 0fA7C234C5;
	fma.rn.f32 	%f151, %f54, %f59, %f58;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p17, %f8, 0f47CE4780;
	add.s64 	%rd11, %rd1, 24;
	@%p17 bra 	$L__BB2_25;

	setp.eq.f32 	%p18, %f8, 0f7F800000;
	@%p18 bra 	$L__BB2_24;
	bra.uni 	$L__BB2_19;

$L__BB2_24:
	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f151, %f6, %f62;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB2_25;

$L__BB2_19:
	mov.b32 	%r9, %f6;
	bfe.u32 	%r125, %r9, 23, 8;
	add.s32 	%r10, %r125, -128;
	shl.b32 	%r126, %r9, 8;
	or.b32  	%r11, %r126, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd142, 0;
	mov.u32 	%r340, 0;
	mov.u64 	%rd141, __cudart_i2opi_f;
	mov.u64 	%rd140, %rd1;

$L__BB2_20:
	.pragma "nounroll";
	ld.global.nc.u32 	%r127, [%rd141];
	mad.wide.u32 	%rd64, %r127, %r11, %rd142;
	shr.u64 	%rd142, %rd64, 32;
	st.local.u32 	[%rd140], %rd64;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r340, %r340, 1;
	setp.ne.s32 	%p19, %r340, 6;
	@%p19 bra 	$L__BB2_20;

	st.local.u32 	[%rd11], %rd142;
	mov.u32 	%r128, 4;
	sub.s32 	%r15, %r128, %r12;
	mov.u32 	%r129, 6;
	sub.s32 	%r130, %r129, %r12;
	mul.wide.s32 	%rd65, %r130, 4;
	add.s64 	%rd66, %rd1, %rd65;
	ld.local.u32 	%r341, [%rd66];
	ld.local.u32 	%r342, [%rd66+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p20, %r18, 0;
	@%p20 bra 	$L__BB2_23;

	mov.u32 	%r131, 32;
	sub.s32 	%r132, %r131, %r18;
	shr.u32 	%r133, %r342, %r132;
	shl.b32 	%r134, %r341, %r18;
	add.s32 	%r341, %r133, %r134;
	mul.wide.s32 	%rd67, %r15, 4;
	add.s64 	%rd68, %rd1, %rd67;
	ld.local.u32 	%r135, [%rd68];
	shr.u32 	%r136, %r135, %r132;
	shl.b32 	%r137, %r342, %r18;
	add.s32 	%r342, %r136, %r137;

$L__BB2_23:
	and.b32  	%r138, %r9, -2147483648;
	shr.u32 	%r139, %r342, 30;
	shl.b32 	%r140, %r341, 2;
	or.b32  	%r141, %r139, %r140;
	shr.u32 	%r142, %r141, 31;
	shr.u32 	%r143, %r341, 30;
	add.s32 	%r144, %r142, %r143;
	neg.s32 	%r145, %r144;
	setp.eq.s32 	%p21, %r138, 0;
	selp.b32 	%r343, %r144, %r145, %p21;
	setp.ne.s32 	%p22, %r142, 0;
	xor.b32  	%r146, %r138, -2147483648;
	selp.b32 	%r147, %r146, %r138, %p22;
	selp.b32 	%r148, -1, 0, %p22;
	xor.b32  	%r149, %r141, %r148;
	shl.b32 	%r150, %r342, 2;
	xor.b32  	%r151, %r150, %r148;
	cvt.u64.u32 	%rd69, %r149;
	cvt.u64.u32 	%rd70, %r151;
	bfi.b64 	%rd71, %rd69, %rd70, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd71;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f60, %fd191;
	setp.eq.s32 	%p23, %r147, 0;
	neg.f32 	%f61, %f60;
	selp.f32 	%f151, %f60, %f61, %p23;

$L__BB2_25:
	and.b32  	%r25, %r343, 1;
	setp.eq.s32 	%p24, %r25, 0;
	selp.f32 	%f12, %f151, 0f3F800000, %p24;
	mul.rn.f32 	%f13, %f151, %f151;
	mov.f32 	%f152, 0fB94D4153;
	@%p24 bra 	$L__BB2_27;

	mov.f32 	%f64, 0fBAB607ED;
	mov.f32 	%f65, 0f37CBAC00;
	fma.rn.f32 	%f152, %f65, %f13, %f64;

$L__BB2_27:
	selp.f32 	%f66, 0f3C0885E4, 0f3D2AAABB, %p24;
	fma.rn.f32 	%f67, %f152, %f13, %f66;
	selp.f32 	%f68, 0fBE2AAAA8, 0fBEFFFFFF, %p24;
	fma.rn.f32 	%f69, %f67, %f13, %f68;
	mov.f32 	%f70, 0f00000000;
	fma.rn.f32 	%f71, %f13, %f12, %f70;
	fma.rn.f32 	%f153, %f69, %f71, %f12;
	and.b32  	%r153, %r343, 2;
	setp.eq.s32 	%p26, %r153, 0;
	@%p26 bra 	$L__BB2_29;

	mov.f32 	%f73, 0fBF800000;
	fma.rn.f32 	%f153, %f153, %f73, %f70;

$L__BB2_29:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r154, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r155}, %fd30;
	}
	and.b32  	%r156, %r155, 2147483647;
	setp.eq.s32 	%p27, %r156, 2146435072;
	setp.eq.s32 	%p28, %r154, 0;
	and.pred  	%p29, %p28, %p27;
	@%p29 bra 	$L__BB2_32;
	bra.uni 	$L__BB2_30;

$L__BB2_32:
	mov.f64 	%fd201, 0d0000000000000000;
	mul.rn.f64 	%fd421, %fd30, %fd201;
	mov.u32 	%r344, 0;
	bra.uni 	$L__BB2_33;

$L__BB2_30:
	mul.rn.f64 	%fd192, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd192;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd193, %r344;
	neg.f64 	%fd194, %fd193;
	mov.f64 	%fd195, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd196, %fd194, %fd195, %fd30;
	mov.f64 	%fd197, 0d3C91A62633145C00;
	fma.rn.f64 	%fd198, %fd194, %fd197, %fd196;
	mov.f64 	%fd199, 0d397B839A252049C0;
	fma.rn.f64 	%fd421, %fd194, %fd199, %fd198;
	abs.f64 	%fd200, %fd30;
	setp.ltu.f64 	%p30, %fd200, 0d41E0000000000000;
	@%p30 bra 	$L__BB2_33;

	add.u64 	%rd134, %SP, 0;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd421, [retval0+0];
	} // callseq 6
	ld.local.u32 	%r344, [%rd1];

$L__BB2_33:
	and.b32  	%r158, %r344, 1;
	shl.b32 	%r159, %r344, 3;
	and.b32  	%r160, %r159, 8;
	setp.eq.s32 	%p31, %r158, 0;
	selp.f64 	%fd202, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p31;
	mul.wide.s32 	%rd73, %r160, 8;
	add.s64 	%rd75, %rd56, %rd73;
	ld.global.nc.f64 	%fd203, [%rd75+8];
	mul.rn.f64 	%fd35, %fd421, %fd421;
	fma.rn.f64 	%fd204, %fd202, %fd35, %fd203;
	ld.global.nc.f64 	%fd205, [%rd75+16];
	fma.rn.f64 	%fd206, %fd204, %fd35, %fd205;
	ld.global.nc.f64 	%fd207, [%rd75+24];
	fma.rn.f64 	%fd208, %fd206, %fd35, %fd207;
	ld.global.nc.f64 	%fd209, [%rd75+32];
	fma.rn.f64 	%fd210, %fd208, %fd35, %fd209;
	ld.global.nc.f64 	%fd211, [%rd75+40];
	fma.rn.f64 	%fd212, %fd210, %fd35, %fd211;
	ld.global.nc.f64 	%fd213, [%rd75+48];
	fma.rn.f64 	%fd36, %fd212, %fd35, %fd213;
	fma.rn.f64 	%fd423, %fd36, %fd421, %fd421;
	@%p31 bra 	$L__BB2_35;

	mov.f64 	%fd214, 0d3FF0000000000000;
	fma.rn.f64 	%fd423, %fd36, %fd35, %fd214;

$L__BB2_35:
	and.b32  	%r161, %r344, 2;
	setp.eq.s32 	%p32, %r161, 0;
	@%p32 bra 	$L__BB2_37;

	mov.f64 	%fd215, 0d0000000000000000;
	mov.f64 	%fd216, 0dBFF0000000000000;
	fma.rn.f64 	%fd423, %fd423, %fd216, %fd215;

$L__BB2_37:
	mul.rn.f64 	%fd217, %fd423, 0d4044000000000000;
	cvt.f64.f32 	%fd218, %f153;
	mul.rn.f64 	%fd219, %fd218, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd219, %fd217;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r162, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r163}, %fd43;
	}
	and.b32  	%r164, %r163, 2147483647;
	setp.eq.s32 	%p33, %r164, 2146435072;
	setp.eq.s32 	%p34, %r162, 0;
	and.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB2_40;
	bra.uni 	$L__BB2_38;

$L__BB2_40:
	mov.f64 	%fd229, 0d0000000000000000;
	mul.rn.f64 	%fd424, %fd43, %fd229;
	mov.u32 	%r345, 0;
	bra.uni 	$L__BB2_41;

$L__BB2_38:
	mul.rn.f64 	%fd220, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r345, %fd220;
	st.local.u32 	[%rd1], %r345;
	cvt.rn.f64.s32 	%fd221, %r345;
	neg.f64 	%fd222, %fd221;
	mov.f64 	%fd223, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd224, %fd222, %fd223, %fd43;
	mov.f64 	%fd225, 0d3C91A62633145C00;
	fma.rn.f64 	%fd226, %fd222, %fd225, %fd224;
	mov.f64 	%fd227, 0d397B839A252049C0;
	fma.rn.f64 	%fd424, %fd222, %fd227, %fd226;
	abs.f64 	%fd228, %fd43;
	setp.ltu.f64 	%p36, %fd228, 0d41E0000000000000;
	@%p36 bra 	$L__BB2_41;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd424, [retval0+0];
	} // callseq 7
	ld.local.u32 	%r345, [%rd1];

$L__BB2_41:
	and.b32  	%r166, %r345, 1;
	shl.b32 	%r167, %r345, 3;
	and.b32  	%r168, %r167, 8;
	setp.eq.s32 	%p37, %r166, 0;
	selp.f64 	%fd230, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	mul.wide.s32 	%rd77, %r168, 8;
	add.s64 	%rd79, %rd56, %rd77;
	ld.global.nc.f64 	%fd231, [%rd79+8];
	mul.rn.f64 	%fd48, %fd424, %fd424;
	fma.rn.f64 	%fd232, %fd230, %fd48, %fd231;
	ld.global.nc.f64 	%fd233, [%rd79+16];
	fma.rn.f64 	%fd234, %fd232, %fd48, %fd233;
	ld.global.nc.f64 	%fd235, [%rd79+24];
	fma.rn.f64 	%fd236, %fd234, %fd48, %fd235;
	ld.global.nc.f64 	%fd237, [%rd79+32];
	fma.rn.f64 	%fd238, %fd236, %fd48, %fd237;
	ld.global.nc.f64 	%fd239, [%rd79+40];
	fma.rn.f64 	%fd240, %fd238, %fd48, %fd239;
	ld.global.nc.f64 	%fd241, [%rd79+48];
	fma.rn.f64 	%fd49, %fd240, %fd48, %fd241;
	fma.rn.f64 	%fd426, %fd49, %fd424, %fd424;
	@%p37 bra 	$L__BB2_43;

	mov.f64 	%fd242, 0d3FF0000000000000;
	fma.rn.f64 	%fd426, %fd49, %fd48, %fd242;

$L__BB2_43:
	and.b32  	%r169, %r345, 2;
	setp.eq.s32 	%p38, %r169, 0;
	@%p38 bra 	$L__BB2_45;

	mov.f64 	%fd243, 0d0000000000000000;
	mov.f64 	%fd244, 0dBFF0000000000000;
	fma.rn.f64 	%fd426, %fd426, %fd244, %fd243;

$L__BB2_45:
	mul.rn.f64 	%fd245, %fd426, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd245;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r170, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd56;
	}
	and.b32  	%r172, %r171, 2147483647;
	setp.eq.s32 	%p39, %r172, 2146435072;
	setp.eq.s32 	%p40, %r170, 0;
	and.pred  	%p41, %p40, %p39;
	@%p41 bra 	$L__BB2_48;
	bra.uni 	$L__BB2_46;

$L__BB2_48:
	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd427, %fd56, %fd255;
	mov.u32 	%r346, 0;
	bra.uni 	$L__BB2_49;

$L__BB2_46:
	mul.rn.f64 	%fd246, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r346, %fd246;
	st.local.u32 	[%rd1], %r346;
	cvt.rn.f64.s32 	%fd247, %r346;
	neg.f64 	%fd248, %fd247;
	mov.f64 	%fd249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd250, %fd248, %fd249, %fd56;
	mov.f64 	%fd251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd252, %fd248, %fd251, %fd250;
	mov.f64 	%fd253, 0d397B839A252049C0;
	fma.rn.f64 	%fd427, %fd248, %fd253, %fd252;
	abs.f64 	%fd254, %fd56;
	setp.ltu.f64 	%p42, %fd254, 0d41E0000000000000;
	@%p42 bra 	$L__BB2_49;

	add.u64 	%rd136, %SP, 0;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd427, [retval0+0];
	} // callseq 8
	ld.local.u32 	%r346, [%rd1];

$L__BB2_49:
	and.b32  	%r174, %r346, 1;
	shl.b32 	%r175, %r346, 3;
	and.b32  	%r176, %r175, 8;
	setp.eq.s32 	%p43, %r174, 0;
	selp.f64 	%fd256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p43;
	mul.wide.s32 	%rd81, %r176, 8;
	add.s64 	%rd83, %rd56, %rd81;
	ld.global.nc.f64 	%fd257, [%rd83+8];
	mul.rn.f64 	%fd61, %fd427, %fd427;
	fma.rn.f64 	%fd258, %fd256, %fd61, %fd257;
	ld.global.nc.f64 	%fd259, [%rd83+16];
	fma.rn.f64 	%fd260, %fd258, %fd61, %fd259;
	ld.global.nc.f64 	%fd261, [%rd83+24];
	fma.rn.f64 	%fd262, %fd260, %fd61, %fd261;
	ld.global.nc.f64 	%fd263, [%rd83+32];
	fma.rn.f64 	%fd264, %fd262, %fd61, %fd263;
	ld.global.nc.f64 	%fd265, [%rd83+40];
	fma.rn.f64 	%fd266, %fd264, %fd61, %fd265;
	ld.global.nc.f64 	%fd267, [%rd83+48];
	fma.rn.f64 	%fd62, %fd266, %fd61, %fd267;
	fma.rn.f64 	%fd429, %fd62, %fd427, %fd427;
	@%p43 bra 	$L__BB2_51;

	mov.f64 	%fd268, 0d3FF0000000000000;
	fma.rn.f64 	%fd429, %fd62, %fd61, %fd268;

$L__BB2_51:
	and.b32  	%r177, %r346, 2;
	setp.eq.s32 	%p44, %r177, 0;
	@%p44 bra 	$L__BB2_53;

	mov.f64 	%fd269, 0d0000000000000000;
	mov.f64 	%fd270, 0dBFF0000000000000;
	fma.rn.f64 	%fd429, %fd429, %fd270, %fd269;

$L__BB2_53:
	mul.rn.f64 	%fd271, %fd429, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd271;
	mul.rn.f32 	%f74, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r350, %f74;
	cvt.rn.f32.s32 	%f75, %r350;
	mov.f32 	%f76, 0fBFC90FDA;
	fma.rn.f32 	%f77, %f75, %f76, %f5;
	mov.f32 	%f78, 0fB3A22168;
	fma.rn.f32 	%f79, %f75, %f78, %f77;
	mov.f32 	%f80, 0fA7C234C5;
	fma.rn.f32 	%f154, %f75, %f80, %f79;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p45, %f20, 0f47CE4780;
	@%p45 bra 	$L__BB2_61;

	setp.eq.f32 	%p46, %f20, 0f7F800000;
	@%p46 bra 	$L__BB2_60;
	bra.uni 	$L__BB2_55;

$L__BB2_60:
	mov.f32 	%f83, 0f00000000;
	mul.rn.f32 	%f154, %f5, %f83;
	mov.u32 	%r350, 0;
	bra.uni 	$L__BB2_61;

$L__BB2_55:
	mov.b32 	%r36, %f5;
	bfe.u32 	%r179, %r36, 23, 8;
	add.s32 	%r37, %r179, -128;
	shl.b32 	%r180, %r36, 8;
	or.b32  	%r38, %r180, -2147483648;
	shr.u32 	%r39, %r37, 5;
	mov.u64 	%rd145, 0;
	mov.u32 	%r347, 0;
	mov.u64 	%rd144, __cudart_i2opi_f;
	mov.u64 	%rd143, %rd1;

$L__BB2_56:
	.pragma "nounroll";
	ld.global.nc.u32 	%r181, [%rd144];
	mad.wide.u32 	%rd86, %r181, %r38, %rd145;
	shr.u64 	%rd145, %rd86, 32;
	st.local.u32 	[%rd143], %rd86;
	add.s64 	%rd144, %rd144, 4;
	add.s64 	%rd143, %rd143, 4;
	add.s32 	%r347, %r347, 1;
	setp.ne.s32 	%p47, %r347, 6;
	@%p47 bra 	$L__BB2_56;

	st.local.u32 	[%rd11], %rd145;
	mov.u32 	%r182, 4;
	sub.s32 	%r42, %r182, %r39;
	mov.u32 	%r183, 6;
	sub.s32 	%r184, %r183, %r39;
	mul.wide.s32 	%rd87, %r184, 4;
	add.s64 	%rd88, %rd1, %rd87;
	ld.local.u32 	%r348, [%rd88];
	ld.local.u32 	%r349, [%rd88+-4];
	and.b32  	%r45, %r37, 31;
	setp.eq.s32 	%p48, %r45, 0;
	@%p48 bra 	$L__BB2_59;

	mov.u32 	%r185, 32;
	sub.s32 	%r186, %r185, %r45;
	shr.u32 	%r187, %r349, %r186;
	shl.b32 	%r188, %r348, %r45;
	add.s32 	%r348, %r187, %r188;
	mul.wide.s32 	%rd89, %r42, 4;
	add.s64 	%rd90, %rd1, %rd89;
	ld.local.u32 	%r189, [%rd90];
	shr.u32 	%r190, %r189, %r186;
	shl.b32 	%r191, %r349, %r45;
	add.s32 	%r349, %r190, %r191;

$L__BB2_59:
	and.b32  	%r192, %r36, -2147483648;
	shr.u32 	%r193, %r349, 30;
	shl.b32 	%r194, %r348, 2;
	or.b32  	%r195, %r193, %r194;
	shr.u32 	%r196, %r195, 31;
	shr.u32 	%r197, %r348, 30;
	add.s32 	%r198, %r196, %r197;
	neg.s32 	%r199, %r198;
	setp.eq.s32 	%p49, %r192, 0;
	selp.b32 	%r350, %r198, %r199, %p49;
	setp.ne.s32 	%p50, %r196, 0;
	xor.b32  	%r200, %r192, -2147483648;
	selp.b32 	%r201, %r200, %r192, %p50;
	selp.b32 	%r202, -1, 0, %p50;
	xor.b32  	%r203, %r195, %r202;
	shl.b32 	%r204, %r349, 2;
	xor.b32  	%r205, %r204, %r202;
	cvt.u64.u32 	%rd91, %r203;
	cvt.u64.u32 	%rd92, %r205;
	bfi.b64 	%rd93, %rd91, %rd92, 32, 32;
	cvt.rn.f64.s64 	%fd272, %rd93;
	mul.rn.f64 	%fd273, %fd272, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f81, %fd273;
	setp.eq.s32 	%p51, %r201, 0;
	neg.f32 	%f82, %f81;
	selp.f32 	%f154, %f81, %f82, %p51;

$L__BB2_61:
	cvt.rn.f32.f64 	%f85, %fd28;
	cvt.f64.f32 	%fd69, %f85;
	and.b32  	%r52, %r350, 1;
	setp.eq.s32 	%p52, %r52, 0;
	selp.f32 	%f24, %f154, 0f3F800000, %p52;
	mul.rn.f32 	%f25, %f154, %f154;
	mov.f32 	%f155, 0fB94D4153;
	@%p52 bra 	$L__BB2_63;

	mov.f32 	%f86, 0fBAB607ED;
	mov.f32 	%f87, 0f37CBAC00;
	fma.rn.f32 	%f155, %f87, %f25, %f86;

$L__BB2_63:
	selp.f32 	%f88, 0f3C0885E4, 0f3D2AAABB, %p52;
	fma.rn.f32 	%f89, %f155, %f25, %f88;
	selp.f32 	%f90, 0fBE2AAAA8, 0fBEFFFFFF, %p52;
	fma.rn.f32 	%f91, %f89, %f25, %f90;
	mov.f32 	%f92, 0f00000000;
	fma.rn.f32 	%f93, %f25, %f24, %f92;
	fma.rn.f32 	%f156, %f91, %f93, %f24;
	and.b32  	%r207, %r350, 2;
	setp.eq.s32 	%p54, %r207, 0;
	@%p54 bra 	$L__BB2_65;

	mov.f32 	%f95, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f95, %f92;

$L__BB2_65:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd70;
	}
	and.b32  	%r210, %r209, 2147483647;
	setp.eq.s32 	%p55, %r210, 2146435072;
	setp.eq.s32 	%p56, %r208, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB2_68;
	bra.uni 	$L__BB2_66;

$L__BB2_68:
	mov.f64 	%fd283, 0d0000000000000000;
	mul.rn.f64 	%fd430, %fd70, %fd283;
	mov.u32 	%r351, 0;
	bra.uni 	$L__BB2_69;

$L__BB2_66:
	mul.rn.f64 	%fd274, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r351, %fd274;
	st.local.u32 	[%rd1], %r351;
	cvt.rn.f64.s32 	%fd275, %r351;
	neg.f64 	%fd276, %fd275;
	mov.f64 	%fd277, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd278, %fd276, %fd277, %fd70;
	mov.f64 	%fd279, 0d3C91A62633145C00;
	fma.rn.f64 	%fd280, %fd276, %fd279, %fd278;
	mov.f64 	%fd281, 0d397B839A252049C0;
	fma.rn.f64 	%fd430, %fd276, %fd281, %fd280;
	abs.f64 	%fd282, %fd70;
	setp.ltu.f64 	%p58, %fd282, 0d41E0000000000000;
	@%p58 bra 	$L__BB2_69;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd430, [retval0+0];
	} // callseq 9
	ld.local.u32 	%r351, [%rd1];

$L__BB2_69:
	and.b32  	%r212, %r351, 1;
	shl.b32 	%r213, %r351, 3;
	and.b32  	%r214, %r213, 8;
	setp.eq.s32 	%p59, %r212, 0;
	selp.f64 	%fd284, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd95, %r214, 8;
	add.s64 	%rd97, %rd56, %rd95;
	ld.global.nc.f64 	%fd285, [%rd97+8];
	mul.rn.f64 	%fd75, %fd430, %fd430;
	fma.rn.f64 	%fd286, %fd284, %fd75, %fd285;
	ld.global.nc.f64 	%fd287, [%rd97+16];
	fma.rn.f64 	%fd288, %fd286, %fd75, %fd287;
	ld.global.nc.f64 	%fd289, [%rd97+24];
	fma.rn.f64 	%fd290, %fd288, %fd75, %fd289;
	ld.global.nc.f64 	%fd291, [%rd97+32];
	fma.rn.f64 	%fd292, %fd290, %fd75, %fd291;
	ld.global.nc.f64 	%fd293, [%rd97+40];
	fma.rn.f64 	%fd294, %fd292, %fd75, %fd293;
	ld.global.nc.f64 	%fd295, [%rd97+48];
	fma.rn.f64 	%fd76, %fd294, %fd75, %fd295;
	fma.rn.f64 	%fd432, %fd76, %fd430, %fd430;
	@%p59 bra 	$L__BB2_71;

	mov.f64 	%fd296, 0d3FF0000000000000;
	fma.rn.f64 	%fd432, %fd76, %fd75, %fd296;

$L__BB2_71:
	and.b32  	%r215, %r351, 2;
	setp.eq.s32 	%p60, %r215, 0;
	@%p60 bra 	$L__BB2_73;

	mov.f64 	%fd297, 0d0000000000000000;
	mov.f64 	%fd298, 0dBFF0000000000000;
	fma.rn.f64 	%fd432, %fd432, %fd298, %fd297;

$L__BB2_73:
	mul.rn.f64 	%fd299, %fd432, 0d4044000000000000;
	cvt.f64.f32 	%fd300, %f156;
	mul.rn.f64 	%fd301, %fd300, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd301, %fd299;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd83;
	}
	and.b32  	%r218, %r217, 2147483647;
	setp.eq.s32 	%p61, %r218, 2146435072;
	setp.eq.s32 	%p62, %r216, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB2_76;
	bra.uni 	$L__BB2_74;

$L__BB2_76:
	mov.f64 	%fd311, 0d0000000000000000;
	mul.rn.f64 	%fd433, %fd83, %fd311;
	mov.u32 	%r352, 0;
	bra.uni 	$L__BB2_77;

$L__BB2_74:
	mul.rn.f64 	%fd302, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r352, %fd302;
	st.local.u32 	[%rd1], %r352;
	cvt.rn.f64.s32 	%fd303, %r352;
	neg.f64 	%fd304, %fd303;
	mov.f64 	%fd305, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd306, %fd304, %fd305, %fd83;
	mov.f64 	%fd307, 0d3C91A62633145C00;
	fma.rn.f64 	%fd308, %fd304, %fd307, %fd306;
	mov.f64 	%fd309, 0d397B839A252049C0;
	fma.rn.f64 	%fd433, %fd304, %fd309, %fd308;
	abs.f64 	%fd310, %fd83;
	setp.ltu.f64 	%p64, %fd310, 0d41E0000000000000;
	@%p64 bra 	$L__BB2_77;

	add.u64 	%rd138, %SP, 0;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd138;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd433, [retval0+0];
	} // callseq 10
	ld.local.u32 	%r352, [%rd1];

$L__BB2_77:
	and.b32  	%r220, %r352, 1;
	shl.b32 	%r221, %r352, 3;
	and.b32  	%r222, %r221, 8;
	setp.eq.s32 	%p65, %r220, 0;
	selp.f64 	%fd312, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd99, %r222, 8;
	add.s64 	%rd101, %rd56, %rd99;
	ld.global.nc.f64 	%fd313, [%rd101+8];
	mul.rn.f64 	%fd88, %fd433, %fd433;
	fma.rn.f64 	%fd314, %fd312, %fd88, %fd313;
	ld.global.nc.f64 	%fd315, [%rd101+16];
	fma.rn.f64 	%fd316, %fd314, %fd88, %fd315;
	ld.global.nc.f64 	%fd317, [%rd101+24];
	fma.rn.f64 	%fd318, %fd316, %fd88, %fd317;
	ld.global.nc.f64 	%fd319, [%rd101+32];
	fma.rn.f64 	%fd320, %fd318, %fd88, %fd319;
	ld.global.nc.f64 	%fd321, [%rd101+40];
	fma.rn.f64 	%fd322, %fd320, %fd88, %fd321;
	ld.global.nc.f64 	%fd323, [%rd101+48];
	fma.rn.f64 	%fd89, %fd322, %fd88, %fd323;
	fma.rn.f64 	%fd435, %fd89, %fd433, %fd433;
	@%p65 bra 	$L__BB2_79;

	mov.f64 	%fd324, 0d3FF0000000000000;
	fma.rn.f64 	%fd435, %fd89, %fd88, %fd324;

$L__BB2_79:
	and.b32  	%r223, %r352, 2;
	setp.eq.s32 	%p66, %r223, 0;
	@%p66 bra 	$L__BB2_81;

	mov.f64 	%fd325, 0d0000000000000000;
	mov.f64 	%fd326, 0dBFF0000000000000;
	fma.rn.f64 	%fd435, %fd435, %fd326, %fd325;

$L__BB2_81:
	mul.rn.f64 	%fd327, %fd435, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd327;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd96;
	}
	and.b32  	%r226, %r225, 2147483647;
	setp.eq.s32 	%p67, %r226, 2146435072;
	setp.eq.s32 	%p68, %r224, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB2_84;
	bra.uni 	$L__BB2_82;

$L__BB2_84:
	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd436, %fd96, %fd337;
	mov.u32 	%r353, 0;
	bra.uni 	$L__BB2_85;

$L__BB2_82:
	mul.rn.f64 	%fd328, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r353, %fd328;
	st.local.u32 	[%rd1], %r353;
	cvt.rn.f64.s32 	%fd329, %r353;
	neg.f64 	%fd330, %fd329;
	mov.f64 	%fd331, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd332, %fd330, %fd331, %fd96;
	mov.f64 	%fd333, 0d3C91A62633145C00;
	fma.rn.f64 	%fd334, %fd330, %fd333, %fd332;
	mov.f64 	%fd335, 0d397B839A252049C0;
	fma.rn.f64 	%fd436, %fd330, %fd335, %fd334;
	abs.f64 	%fd336, %fd96;
	setp.ltu.f64 	%p70, %fd336, 0d41E0000000000000;
	@%p70 bra 	$L__BB2_85;

	add.u64 	%rd139, %SP, 0;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd139;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd436, [retval0+0];
	} // callseq 11
	ld.local.u32 	%r353, [%rd1];

$L__BB2_85:
	and.b32  	%r228, %r353, 1;
	shl.b32 	%r229, %r353, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p71, %r228, 0;
	selp.f64 	%fd338, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd103, %r230, 8;
	add.s64 	%rd105, %rd56, %rd103;
	ld.global.nc.f64 	%fd339, [%rd105+8];
	mul.rn.f64 	%fd101, %fd436, %fd436;
	fma.rn.f64 	%fd340, %fd338, %fd101, %fd339;
	ld.global.nc.f64 	%fd341, [%rd105+16];
	fma.rn.f64 	%fd342, %fd340, %fd101, %fd341;
	ld.global.nc.f64 	%fd343, [%rd105+24];
	fma.rn.f64 	%fd344, %fd342, %fd101, %fd343;
	ld.global.nc.f64 	%fd345, [%rd105+32];
	fma.rn.f64 	%fd346, %fd344, %fd101, %fd345;
	ld.global.nc.f64 	%fd347, [%rd105+40];
	fma.rn.f64 	%fd348, %fd346, %fd101, %fd347;
	ld.global.nc.f64 	%fd349, [%rd105+48];
	fma.rn.f64 	%fd102, %fd348, %fd101, %fd349;
	fma.rn.f64 	%fd438, %fd102, %fd436, %fd436;
	@%p71 bra 	$L__BB2_87;

	mov.f64 	%fd350, 0d3FF0000000000000;
	fma.rn.f64 	%fd438, %fd102, %fd101, %fd350;

$L__BB2_87:
	and.b32  	%r231, %r353, 2;
	setp.eq.s32 	%p72, %r231, 0;
	@%p72 bra 	$L__BB2_89;

	mov.f64 	%fd351, 0d0000000000000000;
	mov.f64 	%fd352, 0dBFF0000000000000;
	fma.rn.f64 	%fd438, %fd438, %fd352, %fd351;

$L__BB2_89:
	mul.rn.f64 	%fd353, %fd438, 0d4072C00000000000;
	add.rn.f64 	%fd354, %fd95, %fd353;
	add.rn.f64 	%fd108, %fd354, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd355, %fd1, %fd1;
	mov.f64 	%fd356, 0d4000000000000000;
	add.rn.f64 	%fd357, %fd355, 0dC059000000000000;
	mul.rn.f64 	%fd358, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd357, %fd358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd356;
	}
	and.b32  	%r63, %r62, 2146435072;
	setp.eq.s32 	%p73, %r63, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd441, [retval0+0];
	} // callseq 12
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd2;
	}
	setp.lt.s32 	%p74, %r64, 0;
	and.pred  	%p1, %p74, %p73;
	not.pred 	%p75, %p1;
	@%p75 bra 	$L__BB2_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd441;
	}
	xor.b32  	%r233, %r232, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd441;
	}
	mov.b64 	%fd441, {%r234, %r233};

$L__BB2_91:
	setp.eq.f32 	%p76, %f4, 0f00000000;
	@%p76 bra 	$L__BB2_95;
	bra.uni 	$L__BB2_92;

$L__BB2_95:
	selp.b32 	%r235, %r64, 0, %p73;
	mov.u32 	%r236, 0;
	or.b32  	%r237, %r235, 2146435072;
	setp.lt.s32 	%p80, %r62, 0;
	selp.b32 	%r238, %r237, %r235, %p80;
	mov.b64 	%fd441, {%r236, %r238};
	bra.uni 	$L__BB2_96;

$L__BB2_92:
	setp.gt.s32 	%p77, %r64, -1;
	@%p77 bra 	$L__BB2_96;

	mov.f64 	%fd359, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd360, %fd359;
	setp.eq.f64 	%p78, %fd360, 0d4000000000000000;
	@%p78 bra 	$L__BB2_96;

	mov.f64 	%fd441, 0dFFF8000000000000;

$L__BB2_96:
	add.rn.f64 	%fd362, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r239}, %fd362;
	}
	and.b32  	%r240, %r239, 2146435072;
	setp.ne.s32 	%p81, %r240, 2146435072;
	@%p81 bra 	$L__BB2_103;

	setp.gtu.f64 	%p82, %fd111, 0d7FF0000000000000;
	@%p82 bra 	$L__BB2_102;
	bra.uni 	$L__BB2_98;

$L__BB2_102:
	mov.f64 	%fd364, 0d4000000000000000;
	add.rn.f64 	%fd441, %fd2, %fd364;
	bra.uni 	$L__BB2_103;

$L__BB2_98:
	mov.f64 	%fd363, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd363;
	}
	and.b32  	%r65, %r62, 2147483647;
	setp.eq.s32 	%p83, %r65, 2146435072;
	setp.eq.s32 	%p84, %r241, 0;
	and.pred  	%p85, %p83, %p84;
	@%p85 bra 	$L__BB2_101;
	bra.uni 	$L__BB2_99;

$L__BB2_101:
	setp.gt.f64 	%p92, %fd111, 0d3FF0000000000000;
	selp.b32 	%r248, 2146435072, 0, %p92;
	mov.u32 	%r249, 0;
	xor.b32  	%r250, %r248, 2146435072;
	setp.lt.s32 	%p93, %r62, 0;
	selp.b32 	%r251, %r250, %r248, %p93;
	setp.eq.f32 	%p94, %f4, 0fBF800000;
	selp.b32 	%r252, 1072693248, %r251, %p94;
	mov.b64 	%fd441, {%r249, %r252};
	bra.uni 	$L__BB2_103;

$L__BB2_99:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd2;
	}
	and.b32  	%r243, %r64, 2147483647;
	setp.ne.s32 	%p86, %r243, 2146435072;
	setp.ne.s32 	%p87, %r242, 0;
	or.pred  	%p88, %p86, %p87;
	@%p88 bra 	$L__BB2_103;

	setp.gt.s32 	%p89, %r62, -1;
	selp.b32 	%r244, 2146435072, 0, %p89;
	mov.u32 	%r245, 0;
	setp.ne.s32 	%p90, %r65, 1071644672;
	and.pred  	%p91, %p90, %p1;
	or.b32  	%r246, %r244, -2147483648;
	selp.b32 	%r247, %r246, %r244, %p91;
	mov.b64 	%fd441, {%r245, %r247};

$L__BB2_103:
	mul.rn.f64 	%fd365, %fd441, 0d3FC999999999999A;
	setp.eq.f32 	%p95, %f4, 0f3F800000;
	selp.f64 	%fd366, 0d3FC999999999999A, %fd365, %p95;
	add.rn.f64 	%fd367, %fd110, %fd366;
	mul.rn.f32 	%f96, %f2, %f4;
	cvt.f64.f32 	%fd368, %f96;
	mul.rn.f64 	%fd121, %fd368, 0d3FB999999999999A;
	add.rn.f64 	%fd369, %fd121, %fd367;
	abs.f32 	%f97, %f2;
	sqrt.rn.f32 	%f98, %f97;
	cvt.f64.f32 	%fd122, %f98;
	mul.rn.f64 	%fd370, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd371, %fd370, %fd369;
	cvt.rn.f32.f64 	%f99, %fd109;
	cvt.f64.f32 	%fd372, %f99;
	mul.rn.f64 	%fd373, %fd372, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f100, %fd373;
	cvt.f64.f32 	%fd374, %f100;
	add.rn.f64 	%fd123, %fd371, %fd374;
	add.rn.f64 	%fd375, %fd2, %fd2;
	add.rn.f64 	%fd376, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd376, %fd375;
	abs.f64 	%fd125, %fd1;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 13
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd1;
	}
	setp.lt.s32 	%p96, %r66, 0;
	and.pred  	%p2, %p96, %p73;
	not.pred 	%p98, %p2;
	@%p98 bra 	$L__BB2_105;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r253}, %fd444;
	}
	xor.b32  	%r254, %r253, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %fd444;
	}
	mov.b64 	%fd444, {%r255, %r254};

$L__BB2_105:
	setp.eq.f32 	%p99, %f2, 0f00000000;
	@%p99 bra 	$L__BB2_109;
	bra.uni 	$L__BB2_106;

$L__BB2_109:
	selp.b32 	%r256, %r66, 0, %p73;
	mov.u32 	%r257, 0;
	or.b32  	%r258, %r256, 2146435072;
	setp.lt.s32 	%p103, %r62, 0;
	selp.b32 	%r259, %r258, %r256, %p103;
	mov.b64 	%fd444, {%r257, %r259};
	bra.uni 	$L__BB2_110;

$L__BB2_106:
	setp.gt.s32 	%p100, %r66, -1;
	@%p100 bra 	$L__BB2_110;

	mov.f64 	%fd377, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd378, %fd377;
	setp.eq.f64 	%p101, %fd378, 0d4000000000000000;
	@%p101 bra 	$L__BB2_110;

	mov.f64 	%fd444, 0dFFF8000000000000;

$L__BB2_110:
	add.rn.f64 	%fd380, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd380;
	}
	and.b32  	%r261, %r260, 2146435072;
	setp.ne.s32 	%p104, %r261, 2146435072;
	@%p104 bra 	$L__BB2_117;

	setp.gtu.f64 	%p105, %fd125, 0d7FF0000000000000;
	@%p105 bra 	$L__BB2_116;
	bra.uni 	$L__BB2_112;

$L__BB2_116:
	mov.f64 	%fd382, 0d4000000000000000;
	add.rn.f64 	%fd444, %fd1, %fd382;
	bra.uni 	$L__BB2_117;

$L__BB2_112:
	mov.f64 	%fd381, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd381;
	}
	and.b32  	%r67, %r62, 2147483647;
	setp.eq.s32 	%p106, %r67, 2146435072;
	setp.eq.s32 	%p107, %r262, 0;
	and.pred  	%p108, %p106, %p107;
	@%p108 bra 	$L__BB2_115;
	bra.uni 	$L__BB2_113;

$L__BB2_115:
	setp.gt.f64 	%p115, %fd125, 0d3FF0000000000000;
	selp.b32 	%r269, 2146435072, 0, %p115;
	mov.u32 	%r270, 0;
	xor.b32  	%r271, %r269, 2146435072;
	setp.lt.s32 	%p116, %r62, 0;
	selp.b32 	%r272, %r271, %r269, %p116;
	setp.eq.f32 	%p117, %f2, 0fBF800000;
	selp.b32 	%r273, 1072693248, %r272, %p117;
	mov.b64 	%fd444, {%r270, %r273};
	bra.uni 	$L__BB2_117;

$L__BB2_113:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd1;
	}
	and.b32  	%r264, %r66, 2147483647;
	setp.ne.s32 	%p109, %r264, 2146435072;
	setp.ne.s32 	%p110, %r263, 0;
	or.pred  	%p111, %p109, %p110;
	@%p111 bra 	$L__BB2_117;

	setp.gt.s32 	%p112, %r62, -1;
	selp.b32 	%r265, 2146435072, 0, %p112;
	mov.u32 	%r266, 0;
	setp.ne.s32 	%p113, %r67, 1071644672;
	and.pred  	%p114, %p113, %p2;
	or.b32  	%r267, %r265, -2147483648;
	selp.b32 	%r268, %r267, %r265, %p114;
	mov.b64 	%fd444, {%r266, %r268};

$L__BB2_117:
	mul.rn.f64 	%fd383, %fd444, 0d3FB999999999999A;
	setp.eq.f32 	%p118, %f2, 0f3F800000;
	selp.f64 	%fd384, 0d3FB999999999999A, %fd383, %p118;
	add.rn.f64 	%fd385, %fd124, %fd384;
	add.rn.f64 	%fd386, %fd121, %fd385;
	mul.rn.f64 	%fd387, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd388, %fd387, %fd386;
	cvt.rn.f32.f64 	%f101, %fd108;
	cvt.f64.f32 	%fd389, %f101;
	mul.rn.f64 	%fd390, %fd389, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f102, %fd390;
	cvt.f64.f32 	%fd391, %f102;
	add.rn.f64 	%fd135, %fd388, %fd391;
	cvt.f64.f32 	%fd392, %f3;
	div.rn.f64 	%fd393, %fd392, 0d4066800000000000;
	mul.rn.f64 	%fd394, %fd393, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd394;
	mul.rn.f32 	%f103, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r361, %f103;
	cvt.rn.f32.s32 	%f104, %r361;
	mov.f32 	%f105, 0fBFC90FDA;
	fma.rn.f32 	%f106, %f104, %f105, %f31;
	mov.f32 	%f107, 0fB3A22168;
	fma.rn.f32 	%f108, %f104, %f107, %f106;
	mov.f32 	%f109, 0fA7C234C5;
	fma.rn.f32 	%f160, %f104, %f109, %f108;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p119, %f33, 0f47CE4780;
	mov.u32 	%r357, %r361;
	mov.f32 	%f157, %f160;
	@%p119 bra 	$L__BB2_125;

	setp.eq.f32 	%p120, %f33, 0f7F800000;
	@%p120 bra 	$L__BB2_124;
	bra.uni 	$L__BB2_119;

$L__BB2_124:
	mov.f32 	%f112, 0f00000000;
	mul.rn.f32 	%f157, %f31, %f112;
	mov.u32 	%r357, 0;
	bra.uni 	$L__BB2_125;

$L__BB2_119:
	mov.b32 	%r69, %f31;
	bfe.u32 	%r275, %r69, 23, 8;
	add.s32 	%r70, %r275, -128;
	shl.b32 	%r276, %r69, 8;
	or.b32  	%r71, %r276, -2147483648;
	shr.u32 	%r72, %r70, 5;
	mov.u64 	%rd148, 0;
	mov.u32 	%r354, 0;
	mov.u64 	%rd147, __cudart_i2opi_f;
	mov.u64 	%rd146, %rd1;

$L__BB2_120:
	.pragma "nounroll";
	ld.global.nc.u32 	%r277, [%rd147];
	mad.wide.u32 	%rd108, %r277, %r71, %rd148;
	shr.u64 	%rd148, %rd108, 32;
	st.local.u32 	[%rd146], %rd108;
	add.s64 	%rd147, %rd147, 4;
	add.s64 	%rd146, %rd146, 4;
	add.s32 	%r354, %r354, 1;
	setp.ne.s32 	%p121, %r354, 6;
	@%p121 bra 	$L__BB2_120;

	st.local.u32 	[%rd11], %rd148;
	mov.u32 	%r278, 4;
	sub.s32 	%r75, %r278, %r72;
	mov.u32 	%r279, 6;
	sub.s32 	%r280, %r279, %r72;
	mul.wide.s32 	%rd109, %r280, 4;
	add.s64 	%rd110, %rd1, %rd109;
	ld.local.u32 	%r355, [%rd110];
	ld.local.u32 	%r356, [%rd110+-4];
	and.b32  	%r78, %r70, 31;
	setp.eq.s32 	%p122, %r78, 0;
	@%p122 bra 	$L__BB2_123;

	mov.u32 	%r281, 32;
	sub.s32 	%r282, %r281, %r78;
	shr.u32 	%r283, %r356, %r282;
	shl.b32 	%r284, %r355, %r78;
	add.s32 	%r355, %r283, %r284;
	mul.wide.s32 	%rd111, %r75, 4;
	add.s64 	%rd112, %rd1, %rd111;
	ld.local.u32 	%r285, [%rd112];
	shr.u32 	%r286, %r285, %r282;
	shl.b32 	%r287, %r356, %r78;
	add.s32 	%r356, %r286, %r287;

$L__BB2_123:
	and.b32  	%r288, %r69, -2147483648;
	shr.u32 	%r289, %r356, 30;
	shl.b32 	%r290, %r355, 2;
	or.b32  	%r291, %r289, %r290;
	shr.u32 	%r292, %r291, 31;
	shr.u32 	%r293, %r355, 30;
	add.s32 	%r294, %r292, %r293;
	neg.s32 	%r295, %r294;
	setp.eq.s32 	%p123, %r288, 0;
	selp.b32 	%r357, %r294, %r295, %p123;
	setp.ne.s32 	%p124, %r292, 0;
	xor.b32  	%r296, %r288, -2147483648;
	selp.b32 	%r297, %r296, %r288, %p124;
	selp.b32 	%r298, -1, 0, %p124;
	xor.b32  	%r299, %r291, %r298;
	shl.b32 	%r300, %r356, 2;
	xor.b32  	%r301, %r300, %r298;
	cvt.u64.u32 	%rd113, %r299;
	cvt.u64.u32 	%rd114, %r301;
	bfi.b64 	%rd115, %rd113, %rd114, 32, 32;
	cvt.rn.f64.s64 	%fd395, %rd115;
	mul.rn.f64 	%fd396, %fd395, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd396;
	setp.eq.s32 	%p125, %r297, 0;
	neg.f32 	%f111, %f110;
	selp.f32 	%f157, %f110, %f111, %p125;

$L__BB2_125:
	and.b32  	%r85, %r357, 1;
	setp.eq.s32 	%p126, %r85, 0;
	selp.f32 	%f37, %f157, 0f3F800000, %p126;
	mul.rn.f32 	%f38, %f157, %f157;
	mov.f32 	%f158, 0fB94D4153;
	@%p126 bra 	$L__BB2_127;

	mov.f32 	%f114, 0fBAB607ED;
	mov.f32 	%f115, 0f37CBAC00;
	fma.rn.f32 	%f158, %f115, %f38, %f114;

$L__BB2_127:
	selp.f32 	%f116, 0f3C0885E4, 0f3D2AAABB, %p126;
	fma.rn.f32 	%f117, %f158, %f38, %f116;
	selp.f32 	%f118, 0fBE2AAAA8, 0fBEFFFFFF, %p126;
	fma.rn.f32 	%f119, %f117, %f38, %f118;
	mov.f32 	%f120, 0f00000000;
	fma.rn.f32 	%f121, %f38, %f37, %f120;
	fma.rn.f32 	%f159, %f119, %f121, %f37;
	and.b32  	%r303, %r357, 2;
	setp.eq.s32 	%p128, %r303, 0;
	@%p128 bra 	$L__BB2_129;

	mov.f32 	%f123, 0fBF800000;
	fma.rn.f32 	%f159, %f159, %f123, %f120;

$L__BB2_129:
	@%p119 bra 	$L__BB2_137;

	setp.eq.f32 	%p130, %f33, 0f7F800000;
	@%p130 bra 	$L__BB2_136;
	bra.uni 	$L__BB2_131;

$L__BB2_136:
	mov.f32 	%f126, 0f00000000;
	mul.rn.f32 	%f160, %f31, %f126;
	mov.u32 	%r361, 0;
	bra.uni 	$L__BB2_137;

$L__BB2_131:
	mov.b32 	%r86, %f31;
	bfe.u32 	%r305, %r86, 23, 8;
	add.s32 	%r87, %r305, -128;
	shl.b32 	%r306, %r86, 8;
	or.b32  	%r88, %r306, -2147483648;
	shr.u32 	%r89, %r87, 5;
	mov.u64 	%rd151, 0;
	mov.u32 	%r358, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
	mov.u64 	%rd149, %rd1;

$L__BB2_132:
	.pragma "nounroll";
	ld.global.nc.u32 	%r307, [%rd150];
	mad.wide.u32 	%rd118, %r307, %r88, %rd151;
	shr.u64 	%rd151, %rd118, 32;
	st.local.u32 	[%rd149], %rd118;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r358, %r358, 1;
	setp.ne.s32 	%p131, %r358, 6;
	@%p131 bra 	$L__BB2_132;

	st.local.u32 	[%rd11], %rd151;
	mov.u32 	%r308, 4;
	sub.s32 	%r92, %r308, %r89;
	mov.u32 	%r309, 6;
	sub.s32 	%r310, %r309, %r89;
	mul.wide.s32 	%rd119, %r310, 4;
	add.s64 	%rd120, %rd1, %rd119;
	ld.local.u32 	%r359, [%rd120];
	ld.local.u32 	%r360, [%rd120+-4];
	and.b32  	%r95, %r87, 31;
	setp.eq.s32 	%p132, %r95, 0;
	@%p132 bra 	$L__BB2_135;

	mov.u32 	%r311, 32;
	sub.s32 	%r312, %r311, %r95;
	shr.u32 	%r313, %r360, %r312;
	shl.b32 	%r314, %r359, %r95;
	add.s32 	%r359, %r313, %r314;
	mul.wide.s32 	%rd121, %r92, 4;
	add.s64 	%rd122, %rd1, %rd121;
	ld.local.u32 	%r315, [%rd122];
	shr.u32 	%r316, %r315, %r312;
	shl.b32 	%r317, %r360, %r95;
	add.s32 	%r360, %r316, %r317;

$L__BB2_135:
	and.b32  	%r318, %r86, -2147483648;
	shr.u32 	%r319, %r360, 30;
	shl.b32 	%r320, %r359, 2;
	or.b32  	%r321, %r319, %r320;
	shr.u32 	%r322, %r321, 31;
	shr.u32 	%r323, %r359, 30;
	add.s32 	%r324, %r322, %r323;
	neg.s32 	%r325, %r324;
	setp.eq.s32 	%p133, %r318, 0;
	selp.b32 	%r361, %r324, %r325, %p133;
	setp.ne.s32 	%p134, %r322, 0;
	xor.b32  	%r326, %r318, -2147483648;
	selp.b32 	%r327, %r326, %r318, %p134;
	selp.b32 	%r328, -1, 0, %p134;
	xor.b32  	%r329, %r321, %r328;
	shl.b32 	%r330, %r360, 2;
	xor.b32  	%r331, %r330, %r328;
	cvt.u64.u32 	%rd123, %r329;
	cvt.u64.u32 	%rd124, %r331;
	bfi.b64 	%rd125, %rd123, %rd124, 32, 32;
	cvt.rn.f64.s64 	%fd397, %rd125;
	mul.rn.f64 	%fd398, %fd397, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd398;
	setp.eq.s32 	%p135, %r327, 0;
	neg.f32 	%f125, %f124;
	selp.f32 	%f160, %f124, %f125, %p135;

$L__BB2_137:
	add.s32 	%r102, %r361, 1;
	and.b32  	%r103, %r102, 1;
	setp.eq.s32 	%p3, %r103, 0;
	mul.rn.f32 	%f47, %f160, %f160;
	mov.f32 	%f161, 0fB94D4153;
	@%p3 bra 	$L__BB2_139;

	mov.f32 	%f128, 0fBAB607ED;
	mov.f32 	%f129, 0f37CBAC00;
	fma.rn.f32 	%f161, %f129, %f47, %f128;

$L__BB2_139:
	selp.f32 	%f130, %f160, 0f3F800000, %p3;
	selp.f32 	%f131, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f132, %f161, %f47, %f131;
	selp.f32 	%f133, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f134, %f132, %f47, %f133;
	mov.f32 	%f135, 0f00000000;
	fma.rn.f32 	%f136, %f47, %f130, %f135;
	fma.rn.f32 	%f162, %f134, %f136, %f130;
	and.b32  	%r333, %r102, 2;
	setp.eq.s32 	%p137, %r333, 0;
	@%p137 bra 	$L__BB2_141;

	mov.f32 	%f138, 0fBF800000;
	fma.rn.f32 	%f162, %f162, %f138, %f135;

$L__BB2_141:
	ld.param.u64 	%rd133, [gcj02_to_wgs84_cuda_float_param_4];
	mov.u32 	%r337, %tid.x;
	mov.u32 	%r336, %ntid.x;
	mov.u32 	%r335, %ctaid.x;
	mad.lo.s32 	%r334, %r335, %r336, %r337;
	cvt.s64.s32 	%rd132, %r334;
	ld.param.u64 	%rd131, [gcj02_to_wgs84_cuda_float_param_3];
	cvt.f64.f32 	%fd399, %f159;
	mul.rn.f64 	%fd400, %fd399, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd401, %fd400, %fd399;
	add.rn.f64 	%fd402, %fd401, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f139, %fd402;
	sqrt.rn.f32 	%f140, %f139;
	mov.f32 	%f141, 0fCAC2A60A;
	div.rn.f32 	%f142, %f141, %f140;
	mul.rn.f32 	%f143, %f142, %f162;
	cvt.f64.f32 	%fd403, %f143;
	mul.rn.f64 	%fd404, %fd403, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f144, %fd135;
	cvt.f64.f32 	%fd405, %f144;
	mul.rn.f64 	%fd406, %fd405, 0d4066800000000000;
	div.rn.f64 	%fd407, %fd406, %fd404;
	cvt.rn.f32.f64 	%f145, %fd407;
	add.rn.f32 	%f146, %f1, %f145;
	cvta.to.global.u64 	%rd126, %rd131;
	shl.b64 	%rd127, %rd132, 2;
	add.s64 	%rd128, %rd126, %rd127;
	st.global.f32 	[%rd128], %f146;
	mul.rn.f32 	%f147, %f140, %f139;
	cvt.f64.f32 	%fd408, %f147;
	mov.f64 	%fd409, 0dC1582B102DE355C1;
	div.rn.f64 	%fd410, %fd409, %fd408;
	mul.rn.f64 	%fd411, %fd410, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f148, %fd123;
	cvt.f64.f32 	%fd412, %f148;
	mul.rn.f64 	%fd413, %fd412, 0d4066800000000000;
	div.rn.f64 	%fd414, %fd413, %fd411;
	cvt.rn.f32.f64 	%f149, %fd414;
	add.rn.f32 	%f150, %f3, %f149;
	cvta.to.global.u64 	%rd129, %rd133;
	add.s64 	%rd130, %rd129, %rd127;
	st.global.f32 	[%rd130], %f150;

$L__BB2_142:
	ret;

}
	// .globl	wgs84_to_gcj02_cuda_float
.visible .entry wgs84_to_gcj02_cuda_float(
	.param .u32 wgs84_to_gcj02_cuda_float_param_0,
	.param .u64 wgs84_to_gcj02_cuda_float_param_1,
	.param .u64 wgs84_to_gcj02_cuda_float_param_2,
	.param .u64 wgs84_to_gcj02_cuda_float_param_3,
	.param .u64 wgs84_to_gcj02_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot3[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<138>;
	.reg .f32 	%f<163>;
	.reg .b32 	%r<362>;
	.reg .f64 	%fd<445>;
	.reg .b64 	%rd<152>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r104, [wgs84_to_gcj02_cuda_float_param_0];
	ld.param.u64 	%rd36, [wgs84_to_gcj02_cuda_float_param_1];
	ld.param.u64 	%rd37, [wgs84_to_gcj02_cuda_float_param_2];
	add.u64 	%rd40, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r105, %ntid.x;
	mov.u32 	%r106, %ctaid.x;
	mov.u32 	%r107, %tid.x;
	mad.lo.s32 	%r1, %r106, %r105, %r107;
	setp.ge.s32 	%p4, %r1, %r104;
	@%p4 bra 	$L__BB3_142;

	cvta.to.global.u64 	%rd49, %rd36;
	mul.wide.s32 	%rd50, %r1, 4;
	add.s64 	%rd51, %rd49, %rd50;
	cvta.to.global.u64 	%rd52, %rd37;
	add.s64 	%rd53, %rd52, %rd50;
	ld.global.f32 	%f1, [%rd51];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd53];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd136, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd136;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd137, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd137;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r108, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd4;
	}
	and.b32  	%r110, %r109, 2147483647;
	setp.eq.s32 	%p5, %r110, 2146435072;
	setp.eq.s32 	%p6, %r108, 0;
	and.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB3_4;
	bra.uni 	$L__BB3_2;

$L__BB3_4:
	mov.f64 	%fd147, 0d0000000000000000;
	mul.rn.f64 	%fd415, %fd4, %fd147;
	mov.u32 	%r338, 0;
	bra.uni 	$L__BB3_5;

$L__BB3_2:
	mul.rn.f64 	%fd138, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd138;
	st.local.u32 	[%rd8], %r338;
	cvt.rn.f64.s32 	%fd139, %r338;
	neg.f64 	%fd140, %fd139;
	mov.f64 	%fd141, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd142, %fd140, %fd141, %fd4;
	mov.f64 	%fd143, 0d3C91A62633145C00;
	fma.rn.f64 	%fd144, %fd140, %fd143, %fd142;
	mov.f64 	%fd145, 0d397B839A252049C0;
	fma.rn.f64 	%fd415, %fd140, %fd145, %fd144;
	abs.f64 	%fd146, %fd4;
	setp.ltu.f64 	%p8, %fd146, 0d41E0000000000000;
	@%p8 bra 	$L__BB3_5;

	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd415, [retval0+0];
	} // callseq 14
	ld.local.u32 	%r338, [%rd8];

$L__BB3_5:
	and.b32  	%r112, %r338, 1;
	shl.b32 	%r113, %r338, 3;
	and.b32  	%r114, %r113, 8;
	setp.eq.s32 	%p9, %r112, 0;
	selp.f64 	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p9;
	mul.wide.s32 	%rd55, %r114, 8;
	mov.u64 	%rd56, __cudart_sin_cos_coeffs;
	add.s64 	%rd57, %rd56, %rd55;
	ld.global.nc.f64 	%fd149, [%rd57+8];
	mul.rn.f64 	%fd9, %fd415, %fd415;
	fma.rn.f64 	%fd150, %fd148, %fd9, %fd149;
	ld.global.nc.f64 	%fd151, [%rd57+16];
	fma.rn.f64 	%fd152, %fd150, %fd9, %fd151;
	ld.global.nc.f64 	%fd153, [%rd57+24];
	fma.rn.f64 	%fd154, %fd152, %fd9, %fd153;
	ld.global.nc.f64 	%fd155, [%rd57+32];
	fma.rn.f64 	%fd156, %fd154, %fd9, %fd155;
	ld.global.nc.f64 	%fd157, [%rd57+40];
	fma.rn.f64 	%fd158, %fd156, %fd9, %fd157;
	ld.global.nc.f64 	%fd159, [%rd57+48];
	fma.rn.f64 	%fd10, %fd158, %fd9, %fd159;
	fma.rn.f64 	%fd417, %fd10, %fd415, %fd415;
	@%p9 bra 	$L__BB3_7;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd417, %fd10, %fd9, %fd160;

$L__BB3_7:
	and.b32  	%r115, %r338, 2;
	setp.eq.s32 	%p10, %r115, 0;
	@%p10 bra 	$L__BB3_9;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd417, %fd417, %fd162, %fd161;

$L__BB3_9:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r116, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd16;
	}
	and.b32  	%r118, %r117, 2147483647;
	setp.eq.s32 	%p11, %r118, 2146435072;
	setp.eq.s32 	%p12, %r116, 0;
	and.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB3_12;
	bra.uni 	$L__BB3_10;

$L__BB3_12:
	mov.f64 	%fd172, 0d0000000000000000;
	mul.rn.f64 	%fd418, %fd16, %fd172;
	mov.u32 	%r339, 0;
	bra.uni 	$L__BB3_13;

$L__BB3_10:
	mul.rn.f64 	%fd163, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r339, %fd163;
	st.local.u32 	[%rd8], %r339;
	cvt.rn.f64.s32 	%fd164, %r339;
	neg.f64 	%fd165, %fd164;
	mov.f64 	%fd166, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd167, %fd165, %fd166, %fd16;
	mov.f64 	%fd168, 0d3C91A62633145C00;
	fma.rn.f64 	%fd169, %fd165, %fd168, %fd167;
	mov.f64 	%fd170, 0d397B839A252049C0;
	fma.rn.f64 	%fd418, %fd165, %fd170, %fd169;
	abs.f64 	%fd171, %fd16;
	setp.ltu.f64 	%p14, %fd171, 0d41E0000000000000;
	@%p14 bra 	$L__BB3_13;

	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd418, [retval0+0];
	} // callseq 15
	ld.local.u32 	%r339, [%rd8];

$L__BB3_13:
	and.b32  	%r120, %r339, 1;
	shl.b32 	%r121, %r339, 3;
	and.b32  	%r122, %r121, 8;
	setp.eq.s32 	%p15, %r120, 0;
	selp.f64 	%fd173, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p15;
	mul.wide.s32 	%rd59, %r122, 8;
	add.s64 	%rd61, %rd56, %rd59;
	ld.global.nc.f64 	%fd174, [%rd61+8];
	mul.rn.f64 	%fd21, %fd418, %fd418;
	fma.rn.f64 	%fd175, %fd173, %fd21, %fd174;
	ld.global.nc.f64 	%fd176, [%rd61+16];
	fma.rn.f64 	%fd177, %fd175, %fd21, %fd176;
	ld.global.nc.f64 	%fd178, [%rd61+24];
	fma.rn.f64 	%fd179, %fd177, %fd21, %fd178;
	ld.global.nc.f64 	%fd180, [%rd61+32];
	fma.rn.f64 	%fd181, %fd179, %fd21, %fd180;
	ld.global.nc.f64 	%fd182, [%rd61+40];
	fma.rn.f64 	%fd183, %fd181, %fd21, %fd182;
	ld.global.nc.f64 	%fd184, [%rd61+48];
	fma.rn.f64 	%fd22, %fd183, %fd21, %fd184;
	fma.rn.f64 	%fd420, %fd22, %fd418, %fd418;
	@%p15 bra 	$L__BB3_15;

	mov.f64 	%fd185, 0d3FF0000000000000;
	fma.rn.f64 	%fd420, %fd22, %fd21, %fd185;

$L__BB3_15:
	and.b32  	%r123, %r339, 2;
	setp.eq.s32 	%p16, %r123, 0;
	@%p16 bra 	$L__BB3_17;

	mov.f64 	%fd186, 0d0000000000000000;
	mov.f64 	%fd187, 0dBFF0000000000000;
	fma.rn.f64 	%fd420, %fd420, %fd187, %fd186;

$L__BB3_17:
	mul.rn.f64 	%fd188, %fd420, 0d4034000000000000;
	mul.rn.f64 	%fd189, %fd417, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd189, %fd188;
	mul.rn.f32 	%f53, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r343, %f53;
	cvt.rn.f32.s32 	%f54, %r343;
	mov.f32 	%f55, 0fBFC90FDA;
	fma.rn.f32 	%f56, %f54, %f55, %f6;
	mov.f32 	%f57, 0fB3A22168;
	fma.rn.f32 	%f58, %f54, %f57, %f56;
	mov.f32 	%f59, 0fA7C234C5;
	fma.rn.f32 	%f151, %f54, %f59, %f58;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p17, %f8, 0f47CE4780;
	add.s64 	%rd11, %rd1, 24;
	@%p17 bra 	$L__BB3_25;

	setp.eq.f32 	%p18, %f8, 0f7F800000;
	@%p18 bra 	$L__BB3_24;
	bra.uni 	$L__BB3_19;

$L__BB3_24:
	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f151, %f6, %f62;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB3_25;

$L__BB3_19:
	mov.b32 	%r9, %f6;
	bfe.u32 	%r125, %r9, 23, 8;
	add.s32 	%r10, %r125, -128;
	shl.b32 	%r126, %r9, 8;
	or.b32  	%r11, %r126, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd142, 0;
	mov.u32 	%r340, 0;
	mov.u64 	%rd141, __cudart_i2opi_f;
	mov.u64 	%rd140, %rd1;

$L__BB3_20:
	.pragma "nounroll";
	ld.global.nc.u32 	%r127, [%rd141];
	mad.wide.u32 	%rd64, %r127, %r11, %rd142;
	shr.u64 	%rd142, %rd64, 32;
	st.local.u32 	[%rd140], %rd64;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r340, %r340, 1;
	setp.ne.s32 	%p19, %r340, 6;
	@%p19 bra 	$L__BB3_20;

	st.local.u32 	[%rd11], %rd142;
	mov.u32 	%r128, 4;
	sub.s32 	%r15, %r128, %r12;
	mov.u32 	%r129, 6;
	sub.s32 	%r130, %r129, %r12;
	mul.wide.s32 	%rd65, %r130, 4;
	add.s64 	%rd66, %rd1, %rd65;
	ld.local.u32 	%r341, [%rd66];
	ld.local.u32 	%r342, [%rd66+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p20, %r18, 0;
	@%p20 bra 	$L__BB3_23;

	mov.u32 	%r131, 32;
	sub.s32 	%r132, %r131, %r18;
	shr.u32 	%r133, %r342, %r132;
	shl.b32 	%r134, %r341, %r18;
	add.s32 	%r341, %r133, %r134;
	mul.wide.s32 	%rd67, %r15, 4;
	add.s64 	%rd68, %rd1, %rd67;
	ld.local.u32 	%r135, [%rd68];
	shr.u32 	%r136, %r135, %r132;
	shl.b32 	%r137, %r342, %r18;
	add.s32 	%r342, %r136, %r137;

$L__BB3_23:
	and.b32  	%r138, %r9, -2147483648;
	shr.u32 	%r139, %r342, 30;
	shl.b32 	%r140, %r341, 2;
	or.b32  	%r141, %r139, %r140;
	shr.u32 	%r142, %r141, 31;
	shr.u32 	%r143, %r341, 30;
	add.s32 	%r144, %r142, %r143;
	neg.s32 	%r145, %r144;
	setp.eq.s32 	%p21, %r138, 0;
	selp.b32 	%r343, %r144, %r145, %p21;
	setp.ne.s32 	%p22, %r142, 0;
	xor.b32  	%r146, %r138, -2147483648;
	selp.b32 	%r147, %r146, %r138, %p22;
	selp.b32 	%r148, -1, 0, %p22;
	xor.b32  	%r149, %r141, %r148;
	shl.b32 	%r150, %r342, 2;
	xor.b32  	%r151, %r150, %r148;
	cvt.u64.u32 	%rd69, %r149;
	cvt.u64.u32 	%rd70, %r151;
	bfi.b64 	%rd71, %rd69, %rd70, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd71;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f60, %fd191;
	setp.eq.s32 	%p23, %r147, 0;
	neg.f32 	%f61, %f60;
	selp.f32 	%f151, %f60, %f61, %p23;

$L__BB3_25:
	and.b32  	%r25, %r343, 1;
	setp.eq.s32 	%p24, %r25, 0;
	selp.f32 	%f12, %f151, 0f3F800000, %p24;
	mul.rn.f32 	%f13, %f151, %f151;
	mov.f32 	%f152, 0fB94D4153;
	@%p24 bra 	$L__BB3_27;

	mov.f32 	%f64, 0fBAB607ED;
	mov.f32 	%f65, 0f37CBAC00;
	fma.rn.f32 	%f152, %f65, %f13, %f64;

$L__BB3_27:
	selp.f32 	%f66, 0f3C0885E4, 0f3D2AAABB, %p24;
	fma.rn.f32 	%f67, %f152, %f13, %f66;
	selp.f32 	%f68, 0fBE2AAAA8, 0fBEFFFFFF, %p24;
	fma.rn.f32 	%f69, %f67, %f13, %f68;
	mov.f32 	%f70, 0f00000000;
	fma.rn.f32 	%f71, %f13, %f12, %f70;
	fma.rn.f32 	%f153, %f69, %f71, %f12;
	and.b32  	%r153, %r343, 2;
	setp.eq.s32 	%p26, %r153, 0;
	@%p26 bra 	$L__BB3_29;

	mov.f32 	%f73, 0fBF800000;
	fma.rn.f32 	%f153, %f153, %f73, %f70;

$L__BB3_29:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r154, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r155}, %fd30;
	}
	and.b32  	%r156, %r155, 2147483647;
	setp.eq.s32 	%p27, %r156, 2146435072;
	setp.eq.s32 	%p28, %r154, 0;
	and.pred  	%p29, %p28, %p27;
	@%p29 bra 	$L__BB3_32;
	bra.uni 	$L__BB3_30;

$L__BB3_32:
	mov.f64 	%fd201, 0d0000000000000000;
	mul.rn.f64 	%fd421, %fd30, %fd201;
	mov.u32 	%r344, 0;
	bra.uni 	$L__BB3_33;

$L__BB3_30:
	mul.rn.f64 	%fd192, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd192;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd193, %r344;
	neg.f64 	%fd194, %fd193;
	mov.f64 	%fd195, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd196, %fd194, %fd195, %fd30;
	mov.f64 	%fd197, 0d3C91A62633145C00;
	fma.rn.f64 	%fd198, %fd194, %fd197, %fd196;
	mov.f64 	%fd199, 0d397B839A252049C0;
	fma.rn.f64 	%fd421, %fd194, %fd199, %fd198;
	abs.f64 	%fd200, %fd30;
	setp.ltu.f64 	%p30, %fd200, 0d41E0000000000000;
	@%p30 bra 	$L__BB3_33;

	add.u64 	%rd134, %SP, 0;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd421, [retval0+0];
	} // callseq 16
	ld.local.u32 	%r344, [%rd1];

$L__BB3_33:
	and.b32  	%r158, %r344, 1;
	shl.b32 	%r159, %r344, 3;
	and.b32  	%r160, %r159, 8;
	setp.eq.s32 	%p31, %r158, 0;
	selp.f64 	%fd202, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p31;
	mul.wide.s32 	%rd73, %r160, 8;
	add.s64 	%rd75, %rd56, %rd73;
	ld.global.nc.f64 	%fd203, [%rd75+8];
	mul.rn.f64 	%fd35, %fd421, %fd421;
	fma.rn.f64 	%fd204, %fd202, %fd35, %fd203;
	ld.global.nc.f64 	%fd205, [%rd75+16];
	fma.rn.f64 	%fd206, %fd204, %fd35, %fd205;
	ld.global.nc.f64 	%fd207, [%rd75+24];
	fma.rn.f64 	%fd208, %fd206, %fd35, %fd207;
	ld.global.nc.f64 	%fd209, [%rd75+32];
	fma.rn.f64 	%fd210, %fd208, %fd35, %fd209;
	ld.global.nc.f64 	%fd211, [%rd75+40];
	fma.rn.f64 	%fd212, %fd210, %fd35, %fd211;
	ld.global.nc.f64 	%fd213, [%rd75+48];
	fma.rn.f64 	%fd36, %fd212, %fd35, %fd213;
	fma.rn.f64 	%fd423, %fd36, %fd421, %fd421;
	@%p31 bra 	$L__BB3_35;

	mov.f64 	%fd214, 0d3FF0000000000000;
	fma.rn.f64 	%fd423, %fd36, %fd35, %fd214;

$L__BB3_35:
	and.b32  	%r161, %r344, 2;
	setp.eq.s32 	%p32, %r161, 0;
	@%p32 bra 	$L__BB3_37;

	mov.f64 	%fd215, 0d0000000000000000;
	mov.f64 	%fd216, 0dBFF0000000000000;
	fma.rn.f64 	%fd423, %fd423, %fd216, %fd215;

$L__BB3_37:
	mul.rn.f64 	%fd217, %fd423, 0d4044000000000000;
	cvt.f64.f32 	%fd218, %f153;
	mul.rn.f64 	%fd219, %fd218, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd219, %fd217;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r162, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r163}, %fd43;
	}
	and.b32  	%r164, %r163, 2147483647;
	setp.eq.s32 	%p33, %r164, 2146435072;
	setp.eq.s32 	%p34, %r162, 0;
	and.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB3_40;
	bra.uni 	$L__BB3_38;

$L__BB3_40:
	mov.f64 	%fd229, 0d0000000000000000;
	mul.rn.f64 	%fd424, %fd43, %fd229;
	mov.u32 	%r345, 0;
	bra.uni 	$L__BB3_41;

$L__BB3_38:
	mul.rn.f64 	%fd220, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r345, %fd220;
	st.local.u32 	[%rd1], %r345;
	cvt.rn.f64.s32 	%fd221, %r345;
	neg.f64 	%fd222, %fd221;
	mov.f64 	%fd223, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd224, %fd222, %fd223, %fd43;
	mov.f64 	%fd225, 0d3C91A62633145C00;
	fma.rn.f64 	%fd226, %fd222, %fd225, %fd224;
	mov.f64 	%fd227, 0d397B839A252049C0;
	fma.rn.f64 	%fd424, %fd222, %fd227, %fd226;
	abs.f64 	%fd228, %fd43;
	setp.ltu.f64 	%p36, %fd228, 0d41E0000000000000;
	@%p36 bra 	$L__BB3_41;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd424, [retval0+0];
	} // callseq 17
	ld.local.u32 	%r345, [%rd1];

$L__BB3_41:
	and.b32  	%r166, %r345, 1;
	shl.b32 	%r167, %r345, 3;
	and.b32  	%r168, %r167, 8;
	setp.eq.s32 	%p37, %r166, 0;
	selp.f64 	%fd230, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	mul.wide.s32 	%rd77, %r168, 8;
	add.s64 	%rd79, %rd56, %rd77;
	ld.global.nc.f64 	%fd231, [%rd79+8];
	mul.rn.f64 	%fd48, %fd424, %fd424;
	fma.rn.f64 	%fd232, %fd230, %fd48, %fd231;
	ld.global.nc.f64 	%fd233, [%rd79+16];
	fma.rn.f64 	%fd234, %fd232, %fd48, %fd233;
	ld.global.nc.f64 	%fd235, [%rd79+24];
	fma.rn.f64 	%fd236, %fd234, %fd48, %fd235;
	ld.global.nc.f64 	%fd237, [%rd79+32];
	fma.rn.f64 	%fd238, %fd236, %fd48, %fd237;
	ld.global.nc.f64 	%fd239, [%rd79+40];
	fma.rn.f64 	%fd240, %fd238, %fd48, %fd239;
	ld.global.nc.f64 	%fd241, [%rd79+48];
	fma.rn.f64 	%fd49, %fd240, %fd48, %fd241;
	fma.rn.f64 	%fd426, %fd49, %fd424, %fd424;
	@%p37 bra 	$L__BB3_43;

	mov.f64 	%fd242, 0d3FF0000000000000;
	fma.rn.f64 	%fd426, %fd49, %fd48, %fd242;

$L__BB3_43:
	and.b32  	%r169, %r345, 2;
	setp.eq.s32 	%p38, %r169, 0;
	@%p38 bra 	$L__BB3_45;

	mov.f64 	%fd243, 0d0000000000000000;
	mov.f64 	%fd244, 0dBFF0000000000000;
	fma.rn.f64 	%fd426, %fd426, %fd244, %fd243;

$L__BB3_45:
	mul.rn.f64 	%fd245, %fd426, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd245;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r170, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd56;
	}
	and.b32  	%r172, %r171, 2147483647;
	setp.eq.s32 	%p39, %r172, 2146435072;
	setp.eq.s32 	%p40, %r170, 0;
	and.pred  	%p41, %p40, %p39;
	@%p41 bra 	$L__BB3_48;
	bra.uni 	$L__BB3_46;

$L__BB3_48:
	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd427, %fd56, %fd255;
	mov.u32 	%r346, 0;
	bra.uni 	$L__BB3_49;

$L__BB3_46:
	mul.rn.f64 	%fd246, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r346, %fd246;
	st.local.u32 	[%rd1], %r346;
	cvt.rn.f64.s32 	%fd247, %r346;
	neg.f64 	%fd248, %fd247;
	mov.f64 	%fd249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd250, %fd248, %fd249, %fd56;
	mov.f64 	%fd251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd252, %fd248, %fd251, %fd250;
	mov.f64 	%fd253, 0d397B839A252049C0;
	fma.rn.f64 	%fd427, %fd248, %fd253, %fd252;
	abs.f64 	%fd254, %fd56;
	setp.ltu.f64 	%p42, %fd254, 0d41E0000000000000;
	@%p42 bra 	$L__BB3_49;

	add.u64 	%rd136, %SP, 0;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd427, [retval0+0];
	} // callseq 18
	ld.local.u32 	%r346, [%rd1];

$L__BB3_49:
	and.b32  	%r174, %r346, 1;
	shl.b32 	%r175, %r346, 3;
	and.b32  	%r176, %r175, 8;
	setp.eq.s32 	%p43, %r174, 0;
	selp.f64 	%fd256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p43;
	mul.wide.s32 	%rd81, %r176, 8;
	add.s64 	%rd83, %rd56, %rd81;
	ld.global.nc.f64 	%fd257, [%rd83+8];
	mul.rn.f64 	%fd61, %fd427, %fd427;
	fma.rn.f64 	%fd258, %fd256, %fd61, %fd257;
	ld.global.nc.f64 	%fd259, [%rd83+16];
	fma.rn.f64 	%fd260, %fd258, %fd61, %fd259;
	ld.global.nc.f64 	%fd261, [%rd83+24];
	fma.rn.f64 	%fd262, %fd260, %fd61, %fd261;
	ld.global.nc.f64 	%fd263, [%rd83+32];
	fma.rn.f64 	%fd264, %fd262, %fd61, %fd263;
	ld.global.nc.f64 	%fd265, [%rd83+40];
	fma.rn.f64 	%fd266, %fd264, %fd61, %fd265;
	ld.global.nc.f64 	%fd267, [%rd83+48];
	fma.rn.f64 	%fd62, %fd266, %fd61, %fd267;
	fma.rn.f64 	%fd429, %fd62, %fd427, %fd427;
	@%p43 bra 	$L__BB3_51;

	mov.f64 	%fd268, 0d3FF0000000000000;
	fma.rn.f64 	%fd429, %fd62, %fd61, %fd268;

$L__BB3_51:
	and.b32  	%r177, %r346, 2;
	setp.eq.s32 	%p44, %r177, 0;
	@%p44 bra 	$L__BB3_53;

	mov.f64 	%fd269, 0d0000000000000000;
	mov.f64 	%fd270, 0dBFF0000000000000;
	fma.rn.f64 	%fd429, %fd429, %fd270, %fd269;

$L__BB3_53:
	mul.rn.f64 	%fd271, %fd429, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd271;
	mul.rn.f32 	%f74, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r350, %f74;
	cvt.rn.f32.s32 	%f75, %r350;
	mov.f32 	%f76, 0fBFC90FDA;
	fma.rn.f32 	%f77, %f75, %f76, %f5;
	mov.f32 	%f78, 0fB3A22168;
	fma.rn.f32 	%f79, %f75, %f78, %f77;
	mov.f32 	%f80, 0fA7C234C5;
	fma.rn.f32 	%f154, %f75, %f80, %f79;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p45, %f20, 0f47CE4780;
	@%p45 bra 	$L__BB3_61;

	setp.eq.f32 	%p46, %f20, 0f7F800000;
	@%p46 bra 	$L__BB3_60;
	bra.uni 	$L__BB3_55;

$L__BB3_60:
	mov.f32 	%f83, 0f00000000;
	mul.rn.f32 	%f154, %f5, %f83;
	mov.u32 	%r350, 0;
	bra.uni 	$L__BB3_61;

$L__BB3_55:
	mov.b32 	%r36, %f5;
	bfe.u32 	%r179, %r36, 23, 8;
	add.s32 	%r37, %r179, -128;
	shl.b32 	%r180, %r36, 8;
	or.b32  	%r38, %r180, -2147483648;
	shr.u32 	%r39, %r37, 5;
	mov.u64 	%rd145, 0;
	mov.u32 	%r347, 0;
	mov.u64 	%rd144, __cudart_i2opi_f;
	mov.u64 	%rd143, %rd1;

$L__BB3_56:
	.pragma "nounroll";
	ld.global.nc.u32 	%r181, [%rd144];
	mad.wide.u32 	%rd86, %r181, %r38, %rd145;
	shr.u64 	%rd145, %rd86, 32;
	st.local.u32 	[%rd143], %rd86;
	add.s64 	%rd144, %rd144, 4;
	add.s64 	%rd143, %rd143, 4;
	add.s32 	%r347, %r347, 1;
	setp.ne.s32 	%p47, %r347, 6;
	@%p47 bra 	$L__BB3_56;

	st.local.u32 	[%rd11], %rd145;
	mov.u32 	%r182, 4;
	sub.s32 	%r42, %r182, %r39;
	mov.u32 	%r183, 6;
	sub.s32 	%r184, %r183, %r39;
	mul.wide.s32 	%rd87, %r184, 4;
	add.s64 	%rd88, %rd1, %rd87;
	ld.local.u32 	%r348, [%rd88];
	ld.local.u32 	%r349, [%rd88+-4];
	and.b32  	%r45, %r37, 31;
	setp.eq.s32 	%p48, %r45, 0;
	@%p48 bra 	$L__BB3_59;

	mov.u32 	%r185, 32;
	sub.s32 	%r186, %r185, %r45;
	shr.u32 	%r187, %r349, %r186;
	shl.b32 	%r188, %r348, %r45;
	add.s32 	%r348, %r187, %r188;
	mul.wide.s32 	%rd89, %r42, 4;
	add.s64 	%rd90, %rd1, %rd89;
	ld.local.u32 	%r189, [%rd90];
	shr.u32 	%r190, %r189, %r186;
	shl.b32 	%r191, %r349, %r45;
	add.s32 	%r349, %r190, %r191;

$L__BB3_59:
	and.b32  	%r192, %r36, -2147483648;
	shr.u32 	%r193, %r349, 30;
	shl.b32 	%r194, %r348, 2;
	or.b32  	%r195, %r193, %r194;
	shr.u32 	%r196, %r195, 31;
	shr.u32 	%r197, %r348, 30;
	add.s32 	%r198, %r196, %r197;
	neg.s32 	%r199, %r198;
	setp.eq.s32 	%p49, %r192, 0;
	selp.b32 	%r350, %r198, %r199, %p49;
	setp.ne.s32 	%p50, %r196, 0;
	xor.b32  	%r200, %r192, -2147483648;
	selp.b32 	%r201, %r200, %r192, %p50;
	selp.b32 	%r202, -1, 0, %p50;
	xor.b32  	%r203, %r195, %r202;
	shl.b32 	%r204, %r349, 2;
	xor.b32  	%r205, %r204, %r202;
	cvt.u64.u32 	%rd91, %r203;
	cvt.u64.u32 	%rd92, %r205;
	bfi.b64 	%rd93, %rd91, %rd92, 32, 32;
	cvt.rn.f64.s64 	%fd272, %rd93;
	mul.rn.f64 	%fd273, %fd272, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f81, %fd273;
	setp.eq.s32 	%p51, %r201, 0;
	neg.f32 	%f82, %f81;
	selp.f32 	%f154, %f81, %f82, %p51;

$L__BB3_61:
	cvt.rn.f32.f64 	%f85, %fd28;
	cvt.f64.f32 	%fd69, %f85;
	and.b32  	%r52, %r350, 1;
	setp.eq.s32 	%p52, %r52, 0;
	selp.f32 	%f24, %f154, 0f3F800000, %p52;
	mul.rn.f32 	%f25, %f154, %f154;
	mov.f32 	%f155, 0fB94D4153;
	@%p52 bra 	$L__BB3_63;

	mov.f32 	%f86, 0fBAB607ED;
	mov.f32 	%f87, 0f37CBAC00;
	fma.rn.f32 	%f155, %f87, %f25, %f86;

$L__BB3_63:
	selp.f32 	%f88, 0f3C0885E4, 0f3D2AAABB, %p52;
	fma.rn.f32 	%f89, %f155, %f25, %f88;
	selp.f32 	%f90, 0fBE2AAAA8, 0fBEFFFFFF, %p52;
	fma.rn.f32 	%f91, %f89, %f25, %f90;
	mov.f32 	%f92, 0f00000000;
	fma.rn.f32 	%f93, %f25, %f24, %f92;
	fma.rn.f32 	%f156, %f91, %f93, %f24;
	and.b32  	%r207, %r350, 2;
	setp.eq.s32 	%p54, %r207, 0;
	@%p54 bra 	$L__BB3_65;

	mov.f32 	%f95, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f95, %f92;

$L__BB3_65:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd70;
	}
	and.b32  	%r210, %r209, 2147483647;
	setp.eq.s32 	%p55, %r210, 2146435072;
	setp.eq.s32 	%p56, %r208, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB3_68;
	bra.uni 	$L__BB3_66;

$L__BB3_68:
	mov.f64 	%fd283, 0d0000000000000000;
	mul.rn.f64 	%fd430, %fd70, %fd283;
	mov.u32 	%r351, 0;
	bra.uni 	$L__BB3_69;

$L__BB3_66:
	mul.rn.f64 	%fd274, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r351, %fd274;
	st.local.u32 	[%rd1], %r351;
	cvt.rn.f64.s32 	%fd275, %r351;
	neg.f64 	%fd276, %fd275;
	mov.f64 	%fd277, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd278, %fd276, %fd277, %fd70;
	mov.f64 	%fd279, 0d3C91A62633145C00;
	fma.rn.f64 	%fd280, %fd276, %fd279, %fd278;
	mov.f64 	%fd281, 0d397B839A252049C0;
	fma.rn.f64 	%fd430, %fd276, %fd281, %fd280;
	abs.f64 	%fd282, %fd70;
	setp.ltu.f64 	%p58, %fd282, 0d41E0000000000000;
	@%p58 bra 	$L__BB3_69;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd430, [retval0+0];
	} // callseq 19
	ld.local.u32 	%r351, [%rd1];

$L__BB3_69:
	and.b32  	%r212, %r351, 1;
	shl.b32 	%r213, %r351, 3;
	and.b32  	%r214, %r213, 8;
	setp.eq.s32 	%p59, %r212, 0;
	selp.f64 	%fd284, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd95, %r214, 8;
	add.s64 	%rd97, %rd56, %rd95;
	ld.global.nc.f64 	%fd285, [%rd97+8];
	mul.rn.f64 	%fd75, %fd430, %fd430;
	fma.rn.f64 	%fd286, %fd284, %fd75, %fd285;
	ld.global.nc.f64 	%fd287, [%rd97+16];
	fma.rn.f64 	%fd288, %fd286, %fd75, %fd287;
	ld.global.nc.f64 	%fd289, [%rd97+24];
	fma.rn.f64 	%fd290, %fd288, %fd75, %fd289;
	ld.global.nc.f64 	%fd291, [%rd97+32];
	fma.rn.f64 	%fd292, %fd290, %fd75, %fd291;
	ld.global.nc.f64 	%fd293, [%rd97+40];
	fma.rn.f64 	%fd294, %fd292, %fd75, %fd293;
	ld.global.nc.f64 	%fd295, [%rd97+48];
	fma.rn.f64 	%fd76, %fd294, %fd75, %fd295;
	fma.rn.f64 	%fd432, %fd76, %fd430, %fd430;
	@%p59 bra 	$L__BB3_71;

	mov.f64 	%fd296, 0d3FF0000000000000;
	fma.rn.f64 	%fd432, %fd76, %fd75, %fd296;

$L__BB3_71:
	and.b32  	%r215, %r351, 2;
	setp.eq.s32 	%p60, %r215, 0;
	@%p60 bra 	$L__BB3_73;

	mov.f64 	%fd297, 0d0000000000000000;
	mov.f64 	%fd298, 0dBFF0000000000000;
	fma.rn.f64 	%fd432, %fd432, %fd298, %fd297;

$L__BB3_73:
	mul.rn.f64 	%fd299, %fd432, 0d4044000000000000;
	cvt.f64.f32 	%fd300, %f156;
	mul.rn.f64 	%fd301, %fd300, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd301, %fd299;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd83;
	}
	and.b32  	%r218, %r217, 2147483647;
	setp.eq.s32 	%p61, %r218, 2146435072;
	setp.eq.s32 	%p62, %r216, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB3_76;
	bra.uni 	$L__BB3_74;

$L__BB3_76:
	mov.f64 	%fd311, 0d0000000000000000;
	mul.rn.f64 	%fd433, %fd83, %fd311;
	mov.u32 	%r352, 0;
	bra.uni 	$L__BB3_77;

$L__BB3_74:
	mul.rn.f64 	%fd302, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r352, %fd302;
	st.local.u32 	[%rd1], %r352;
	cvt.rn.f64.s32 	%fd303, %r352;
	neg.f64 	%fd304, %fd303;
	mov.f64 	%fd305, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd306, %fd304, %fd305, %fd83;
	mov.f64 	%fd307, 0d3C91A62633145C00;
	fma.rn.f64 	%fd308, %fd304, %fd307, %fd306;
	mov.f64 	%fd309, 0d397B839A252049C0;
	fma.rn.f64 	%fd433, %fd304, %fd309, %fd308;
	abs.f64 	%fd310, %fd83;
	setp.ltu.f64 	%p64, %fd310, 0d41E0000000000000;
	@%p64 bra 	$L__BB3_77;

	add.u64 	%rd138, %SP, 0;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd138;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd433, [retval0+0];
	} // callseq 20
	ld.local.u32 	%r352, [%rd1];

$L__BB3_77:
	and.b32  	%r220, %r352, 1;
	shl.b32 	%r221, %r352, 3;
	and.b32  	%r222, %r221, 8;
	setp.eq.s32 	%p65, %r220, 0;
	selp.f64 	%fd312, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd99, %r222, 8;
	add.s64 	%rd101, %rd56, %rd99;
	ld.global.nc.f64 	%fd313, [%rd101+8];
	mul.rn.f64 	%fd88, %fd433, %fd433;
	fma.rn.f64 	%fd314, %fd312, %fd88, %fd313;
	ld.global.nc.f64 	%fd315, [%rd101+16];
	fma.rn.f64 	%fd316, %fd314, %fd88, %fd315;
	ld.global.nc.f64 	%fd317, [%rd101+24];
	fma.rn.f64 	%fd318, %fd316, %fd88, %fd317;
	ld.global.nc.f64 	%fd319, [%rd101+32];
	fma.rn.f64 	%fd320, %fd318, %fd88, %fd319;
	ld.global.nc.f64 	%fd321, [%rd101+40];
	fma.rn.f64 	%fd322, %fd320, %fd88, %fd321;
	ld.global.nc.f64 	%fd323, [%rd101+48];
	fma.rn.f64 	%fd89, %fd322, %fd88, %fd323;
	fma.rn.f64 	%fd435, %fd89, %fd433, %fd433;
	@%p65 bra 	$L__BB3_79;

	mov.f64 	%fd324, 0d3FF0000000000000;
	fma.rn.f64 	%fd435, %fd89, %fd88, %fd324;

$L__BB3_79:
	and.b32  	%r223, %r352, 2;
	setp.eq.s32 	%p66, %r223, 0;
	@%p66 bra 	$L__BB3_81;

	mov.f64 	%fd325, 0d0000000000000000;
	mov.f64 	%fd326, 0dBFF0000000000000;
	fma.rn.f64 	%fd435, %fd435, %fd326, %fd325;

$L__BB3_81:
	mul.rn.f64 	%fd327, %fd435, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd327;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd96;
	}
	and.b32  	%r226, %r225, 2147483647;
	setp.eq.s32 	%p67, %r226, 2146435072;
	setp.eq.s32 	%p68, %r224, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB3_84;
	bra.uni 	$L__BB3_82;

$L__BB3_84:
	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd436, %fd96, %fd337;
	mov.u32 	%r353, 0;
	bra.uni 	$L__BB3_85;

$L__BB3_82:
	mul.rn.f64 	%fd328, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r353, %fd328;
	st.local.u32 	[%rd1], %r353;
	cvt.rn.f64.s32 	%fd329, %r353;
	neg.f64 	%fd330, %fd329;
	mov.f64 	%fd331, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd332, %fd330, %fd331, %fd96;
	mov.f64 	%fd333, 0d3C91A62633145C00;
	fma.rn.f64 	%fd334, %fd330, %fd333, %fd332;
	mov.f64 	%fd335, 0d397B839A252049C0;
	fma.rn.f64 	%fd436, %fd330, %fd335, %fd334;
	abs.f64 	%fd336, %fd96;
	setp.ltu.f64 	%p70, %fd336, 0d41E0000000000000;
	@%p70 bra 	$L__BB3_85;

	add.u64 	%rd139, %SP, 0;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd139;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd436, [retval0+0];
	} // callseq 21
	ld.local.u32 	%r353, [%rd1];

$L__BB3_85:
	and.b32  	%r228, %r353, 1;
	shl.b32 	%r229, %r353, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p71, %r228, 0;
	selp.f64 	%fd338, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd103, %r230, 8;
	add.s64 	%rd105, %rd56, %rd103;
	ld.global.nc.f64 	%fd339, [%rd105+8];
	mul.rn.f64 	%fd101, %fd436, %fd436;
	fma.rn.f64 	%fd340, %fd338, %fd101, %fd339;
	ld.global.nc.f64 	%fd341, [%rd105+16];
	fma.rn.f64 	%fd342, %fd340, %fd101, %fd341;
	ld.global.nc.f64 	%fd343, [%rd105+24];
	fma.rn.f64 	%fd344, %fd342, %fd101, %fd343;
	ld.global.nc.f64 	%fd345, [%rd105+32];
	fma.rn.f64 	%fd346, %fd344, %fd101, %fd345;
	ld.global.nc.f64 	%fd347, [%rd105+40];
	fma.rn.f64 	%fd348, %fd346, %fd101, %fd347;
	ld.global.nc.f64 	%fd349, [%rd105+48];
	fma.rn.f64 	%fd102, %fd348, %fd101, %fd349;
	fma.rn.f64 	%fd438, %fd102, %fd436, %fd436;
	@%p71 bra 	$L__BB3_87;

	mov.f64 	%fd350, 0d3FF0000000000000;
	fma.rn.f64 	%fd438, %fd102, %fd101, %fd350;

$L__BB3_87:
	and.b32  	%r231, %r353, 2;
	setp.eq.s32 	%p72, %r231, 0;
	@%p72 bra 	$L__BB3_89;

	mov.f64 	%fd351, 0d0000000000000000;
	mov.f64 	%fd352, 0dBFF0000000000000;
	fma.rn.f64 	%fd438, %fd438, %fd352, %fd351;

$L__BB3_89:
	mul.rn.f64 	%fd353, %fd438, 0d4072C00000000000;
	add.rn.f64 	%fd354, %fd95, %fd353;
	add.rn.f64 	%fd108, %fd354, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd355, %fd1, %fd1;
	mov.f64 	%fd356, 0d4000000000000000;
	add.rn.f64 	%fd357, %fd355, 0dC059000000000000;
	mul.rn.f64 	%fd358, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd357, %fd358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd356;
	}
	and.b32  	%r63, %r62, 2146435072;
	setp.eq.s32 	%p73, %r63, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd441, [retval0+0];
	} // callseq 22
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd2;
	}
	setp.lt.s32 	%p74, %r64, 0;
	and.pred  	%p1, %p74, %p73;
	not.pred 	%p75, %p1;
	@%p75 bra 	$L__BB3_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd441;
	}
	xor.b32  	%r233, %r232, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd441;
	}
	mov.b64 	%fd441, {%r234, %r233};

$L__BB3_91:
	setp.eq.f32 	%p76, %f4, 0f00000000;
	@%p76 bra 	$L__BB3_95;
	bra.uni 	$L__BB3_92;

$L__BB3_95:
	selp.b32 	%r235, %r64, 0, %p73;
	mov.u32 	%r236, 0;
	or.b32  	%r237, %r235, 2146435072;
	setp.lt.s32 	%p80, %r62, 0;
	selp.b32 	%r238, %r237, %r235, %p80;
	mov.b64 	%fd441, {%r236, %r238};
	bra.uni 	$L__BB3_96;

$L__BB3_92:
	setp.gt.s32 	%p77, %r64, -1;
	@%p77 bra 	$L__BB3_96;

	mov.f64 	%fd359, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd360, %fd359;
	setp.eq.f64 	%p78, %fd360, 0d4000000000000000;
	@%p78 bra 	$L__BB3_96;

	mov.f64 	%fd441, 0dFFF8000000000000;

$L__BB3_96:
	add.rn.f64 	%fd362, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r239}, %fd362;
	}
	and.b32  	%r240, %r239, 2146435072;
	setp.ne.s32 	%p81, %r240, 2146435072;
	@%p81 bra 	$L__BB3_103;

	setp.gtu.f64 	%p82, %fd111, 0d7FF0000000000000;
	@%p82 bra 	$L__BB3_102;
	bra.uni 	$L__BB3_98;

$L__BB3_102:
	mov.f64 	%fd364, 0d4000000000000000;
	add.rn.f64 	%fd441, %fd2, %fd364;
	bra.uni 	$L__BB3_103;

$L__BB3_98:
	mov.f64 	%fd363, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd363;
	}
	and.b32  	%r65, %r62, 2147483647;
	setp.eq.s32 	%p83, %r65, 2146435072;
	setp.eq.s32 	%p84, %r241, 0;
	and.pred  	%p85, %p83, %p84;
	@%p85 bra 	$L__BB3_101;
	bra.uni 	$L__BB3_99;

$L__BB3_101:
	setp.gt.f64 	%p92, %fd111, 0d3FF0000000000000;
	selp.b32 	%r248, 2146435072, 0, %p92;
	mov.u32 	%r249, 0;
	xor.b32  	%r250, %r248, 2146435072;
	setp.lt.s32 	%p93, %r62, 0;
	selp.b32 	%r251, %r250, %r248, %p93;
	setp.eq.f32 	%p94, %f4, 0fBF800000;
	selp.b32 	%r252, 1072693248, %r251, %p94;
	mov.b64 	%fd441, {%r249, %r252};
	bra.uni 	$L__BB3_103;

$L__BB3_99:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd2;
	}
	and.b32  	%r243, %r64, 2147483647;
	setp.ne.s32 	%p86, %r243, 2146435072;
	setp.ne.s32 	%p87, %r242, 0;
	or.pred  	%p88, %p86, %p87;
	@%p88 bra 	$L__BB3_103;

	setp.gt.s32 	%p89, %r62, -1;
	selp.b32 	%r244, 2146435072, 0, %p89;
	mov.u32 	%r245, 0;
	setp.ne.s32 	%p90, %r65, 1071644672;
	and.pred  	%p91, %p90, %p1;
	or.b32  	%r246, %r244, -2147483648;
	selp.b32 	%r247, %r246, %r244, %p91;
	mov.b64 	%fd441, {%r245, %r247};

$L__BB3_103:
	mul.rn.f64 	%fd365, %fd441, 0d3FC999999999999A;
	setp.eq.f32 	%p95, %f4, 0f3F800000;
	selp.f64 	%fd366, 0d3FC999999999999A, %fd365, %p95;
	add.rn.f64 	%fd367, %fd110, %fd366;
	mul.rn.f32 	%f96, %f2, %f4;
	cvt.f64.f32 	%fd368, %f96;
	mul.rn.f64 	%fd121, %fd368, 0d3FB999999999999A;
	add.rn.f64 	%fd369, %fd121, %fd367;
	abs.f32 	%f97, %f2;
	sqrt.rn.f32 	%f98, %f97;
	cvt.f64.f32 	%fd122, %f98;
	mul.rn.f64 	%fd370, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd371, %fd370, %fd369;
	cvt.rn.f32.f64 	%f99, %fd109;
	cvt.f64.f32 	%fd372, %f99;
	mul.rn.f64 	%fd373, %fd372, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f100, %fd373;
	cvt.f64.f32 	%fd374, %f100;
	add.rn.f64 	%fd123, %fd371, %fd374;
	add.rn.f64 	%fd375, %fd2, %fd2;
	add.rn.f64 	%fd376, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd376, %fd375;
	abs.f64 	%fd125, %fd1;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 23
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd1;
	}
	setp.lt.s32 	%p96, %r66, 0;
	and.pred  	%p2, %p96, %p73;
	not.pred 	%p98, %p2;
	@%p98 bra 	$L__BB3_105;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r253}, %fd444;
	}
	xor.b32  	%r254, %r253, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %fd444;
	}
	mov.b64 	%fd444, {%r255, %r254};

$L__BB3_105:
	setp.eq.f32 	%p99, %f2, 0f00000000;
	@%p99 bra 	$L__BB3_109;
	bra.uni 	$L__BB3_106;

$L__BB3_109:
	selp.b32 	%r256, %r66, 0, %p73;
	mov.u32 	%r257, 0;
	or.b32  	%r258, %r256, 2146435072;
	setp.lt.s32 	%p103, %r62, 0;
	selp.b32 	%r259, %r258, %r256, %p103;
	mov.b64 	%fd444, {%r257, %r259};
	bra.uni 	$L__BB3_110;

$L__BB3_106:
	setp.gt.s32 	%p100, %r66, -1;
	@%p100 bra 	$L__BB3_110;

	mov.f64 	%fd377, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd378, %fd377;
	setp.eq.f64 	%p101, %fd378, 0d4000000000000000;
	@%p101 bra 	$L__BB3_110;

	mov.f64 	%fd444, 0dFFF8000000000000;

$L__BB3_110:
	add.rn.f64 	%fd380, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd380;
	}
	and.b32  	%r261, %r260, 2146435072;
	setp.ne.s32 	%p104, %r261, 2146435072;
	@%p104 bra 	$L__BB3_117;

	setp.gtu.f64 	%p105, %fd125, 0d7FF0000000000000;
	@%p105 bra 	$L__BB3_116;
	bra.uni 	$L__BB3_112;

$L__BB3_116:
	mov.f64 	%fd382, 0d4000000000000000;
	add.rn.f64 	%fd444, %fd1, %fd382;
	bra.uni 	$L__BB3_117;

$L__BB3_112:
	mov.f64 	%fd381, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd381;
	}
	and.b32  	%r67, %r62, 2147483647;
	setp.eq.s32 	%p106, %r67, 2146435072;
	setp.eq.s32 	%p107, %r262, 0;
	and.pred  	%p108, %p106, %p107;
	@%p108 bra 	$L__BB3_115;
	bra.uni 	$L__BB3_113;

$L__BB3_115:
	setp.gt.f64 	%p115, %fd125, 0d3FF0000000000000;
	selp.b32 	%r269, 2146435072, 0, %p115;
	mov.u32 	%r270, 0;
	xor.b32  	%r271, %r269, 2146435072;
	setp.lt.s32 	%p116, %r62, 0;
	selp.b32 	%r272, %r271, %r269, %p116;
	setp.eq.f32 	%p117, %f2, 0fBF800000;
	selp.b32 	%r273, 1072693248, %r272, %p117;
	mov.b64 	%fd444, {%r270, %r273};
	bra.uni 	$L__BB3_117;

$L__BB3_113:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd1;
	}
	and.b32  	%r264, %r66, 2147483647;
	setp.ne.s32 	%p109, %r264, 2146435072;
	setp.ne.s32 	%p110, %r263, 0;
	or.pred  	%p111, %p109, %p110;
	@%p111 bra 	$L__BB3_117;

	setp.gt.s32 	%p112, %r62, -1;
	selp.b32 	%r265, 2146435072, 0, %p112;
	mov.u32 	%r266, 0;
	setp.ne.s32 	%p113, %r67, 1071644672;
	and.pred  	%p114, %p113, %p2;
	or.b32  	%r267, %r265, -2147483648;
	selp.b32 	%r268, %r267, %r265, %p114;
	mov.b64 	%fd444, {%r266, %r268};

$L__BB3_117:
	mul.rn.f64 	%fd383, %fd444, 0d3FB999999999999A;
	setp.eq.f32 	%p118, %f2, 0f3F800000;
	selp.f64 	%fd384, 0d3FB999999999999A, %fd383, %p118;
	add.rn.f64 	%fd385, %fd124, %fd384;
	add.rn.f64 	%fd386, %fd121, %fd385;
	mul.rn.f64 	%fd387, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd388, %fd387, %fd386;
	cvt.rn.f32.f64 	%f101, %fd108;
	cvt.f64.f32 	%fd389, %f101;
	mul.rn.f64 	%fd390, %fd389, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f102, %fd390;
	cvt.f64.f32 	%fd391, %f102;
	add.rn.f64 	%fd135, %fd388, %fd391;
	cvt.f64.f32 	%fd392, %f3;
	div.rn.f64 	%fd393, %fd392, 0d4066800000000000;
	mul.rn.f64 	%fd394, %fd393, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd394;
	mul.rn.f32 	%f103, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r361, %f103;
	cvt.rn.f32.s32 	%f104, %r361;
	mov.f32 	%f105, 0fBFC90FDA;
	fma.rn.f32 	%f106, %f104, %f105, %f31;
	mov.f32 	%f107, 0fB3A22168;
	fma.rn.f32 	%f108, %f104, %f107, %f106;
	mov.f32 	%f109, 0fA7C234C5;
	fma.rn.f32 	%f160, %f104, %f109, %f108;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p119, %f33, 0f47CE4780;
	mov.u32 	%r357, %r361;
	mov.f32 	%f157, %f160;
	@%p119 bra 	$L__BB3_125;

	setp.eq.f32 	%p120, %f33, 0f7F800000;
	@%p120 bra 	$L__BB3_124;
	bra.uni 	$L__BB3_119;

$L__BB3_124:
	mov.f32 	%f112, 0f00000000;
	mul.rn.f32 	%f157, %f31, %f112;
	mov.u32 	%r357, 0;
	bra.uni 	$L__BB3_125;

$L__BB3_119:
	mov.b32 	%r69, %f31;
	bfe.u32 	%r275, %r69, 23, 8;
	add.s32 	%r70, %r275, -128;
	shl.b32 	%r276, %r69, 8;
	or.b32  	%r71, %r276, -2147483648;
	shr.u32 	%r72, %r70, 5;
	mov.u64 	%rd148, 0;
	mov.u32 	%r354, 0;
	mov.u64 	%rd147, __cudart_i2opi_f;
	mov.u64 	%rd146, %rd1;

$L__BB3_120:
	.pragma "nounroll";
	ld.global.nc.u32 	%r277, [%rd147];
	mad.wide.u32 	%rd108, %r277, %r71, %rd148;
	shr.u64 	%rd148, %rd108, 32;
	st.local.u32 	[%rd146], %rd108;
	add.s64 	%rd147, %rd147, 4;
	add.s64 	%rd146, %rd146, 4;
	add.s32 	%r354, %r354, 1;
	setp.ne.s32 	%p121, %r354, 6;
	@%p121 bra 	$L__BB3_120;

	st.local.u32 	[%rd11], %rd148;
	mov.u32 	%r278, 4;
	sub.s32 	%r75, %r278, %r72;
	mov.u32 	%r279, 6;
	sub.s32 	%r280, %r279, %r72;
	mul.wide.s32 	%rd109, %r280, 4;
	add.s64 	%rd110, %rd1, %rd109;
	ld.local.u32 	%r355, [%rd110];
	ld.local.u32 	%r356, [%rd110+-4];
	and.b32  	%r78, %r70, 31;
	setp.eq.s32 	%p122, %r78, 0;
	@%p122 bra 	$L__BB3_123;

	mov.u32 	%r281, 32;
	sub.s32 	%r282, %r281, %r78;
	shr.u32 	%r283, %r356, %r282;
	shl.b32 	%r284, %r355, %r78;
	add.s32 	%r355, %r283, %r284;
	mul.wide.s32 	%rd111, %r75, 4;
	add.s64 	%rd112, %rd1, %rd111;
	ld.local.u32 	%r285, [%rd112];
	shr.u32 	%r286, %r285, %r282;
	shl.b32 	%r287, %r356, %r78;
	add.s32 	%r356, %r286, %r287;

$L__BB3_123:
	and.b32  	%r288, %r69, -2147483648;
	shr.u32 	%r289, %r356, 30;
	shl.b32 	%r290, %r355, 2;
	or.b32  	%r291, %r289, %r290;
	shr.u32 	%r292, %r291, 31;
	shr.u32 	%r293, %r355, 30;
	add.s32 	%r294, %r292, %r293;
	neg.s32 	%r295, %r294;
	setp.eq.s32 	%p123, %r288, 0;
	selp.b32 	%r357, %r294, %r295, %p123;
	setp.ne.s32 	%p124, %r292, 0;
	xor.b32  	%r296, %r288, -2147483648;
	selp.b32 	%r297, %r296, %r288, %p124;
	selp.b32 	%r298, -1, 0, %p124;
	xor.b32  	%r299, %r291, %r298;
	shl.b32 	%r300, %r356, 2;
	xor.b32  	%r301, %r300, %r298;
	cvt.u64.u32 	%rd113, %r299;
	cvt.u64.u32 	%rd114, %r301;
	bfi.b64 	%rd115, %rd113, %rd114, 32, 32;
	cvt.rn.f64.s64 	%fd395, %rd115;
	mul.rn.f64 	%fd396, %fd395, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd396;
	setp.eq.s32 	%p125, %r297, 0;
	neg.f32 	%f111, %f110;
	selp.f32 	%f157, %f110, %f111, %p125;

$L__BB3_125:
	and.b32  	%r85, %r357, 1;
	setp.eq.s32 	%p126, %r85, 0;
	selp.f32 	%f37, %f157, 0f3F800000, %p126;
	mul.rn.f32 	%f38, %f157, %f157;
	mov.f32 	%f158, 0fB94D4153;
	@%p126 bra 	$L__BB3_127;

	mov.f32 	%f114, 0fBAB607ED;
	mov.f32 	%f115, 0f37CBAC00;
	fma.rn.f32 	%f158, %f115, %f38, %f114;

$L__BB3_127:
	selp.f32 	%f116, 0f3C0885E4, 0f3D2AAABB, %p126;
	fma.rn.f32 	%f117, %f158, %f38, %f116;
	selp.f32 	%f118, 0fBE2AAAA8, 0fBEFFFFFF, %p126;
	fma.rn.f32 	%f119, %f117, %f38, %f118;
	mov.f32 	%f120, 0f00000000;
	fma.rn.f32 	%f121, %f38, %f37, %f120;
	fma.rn.f32 	%f159, %f119, %f121, %f37;
	and.b32  	%r303, %r357, 2;
	setp.eq.s32 	%p128, %r303, 0;
	@%p128 bra 	$L__BB3_129;

	mov.f32 	%f123, 0fBF800000;
	fma.rn.f32 	%f159, %f159, %f123, %f120;

$L__BB3_129:
	@%p119 bra 	$L__BB3_137;

	setp.eq.f32 	%p130, %f33, 0f7F800000;
	@%p130 bra 	$L__BB3_136;
	bra.uni 	$L__BB3_131;

$L__BB3_136:
	mov.f32 	%f126, 0f00000000;
	mul.rn.f32 	%f160, %f31, %f126;
	mov.u32 	%r361, 0;
	bra.uni 	$L__BB3_137;

$L__BB3_131:
	mov.b32 	%r86, %f31;
	bfe.u32 	%r305, %r86, 23, 8;
	add.s32 	%r87, %r305, -128;
	shl.b32 	%r306, %r86, 8;
	or.b32  	%r88, %r306, -2147483648;
	shr.u32 	%r89, %r87, 5;
	mov.u64 	%rd151, 0;
	mov.u32 	%r358, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
	mov.u64 	%rd149, %rd1;

$L__BB3_132:
	.pragma "nounroll";
	ld.global.nc.u32 	%r307, [%rd150];
	mad.wide.u32 	%rd118, %r307, %r88, %rd151;
	shr.u64 	%rd151, %rd118, 32;
	st.local.u32 	[%rd149], %rd118;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r358, %r358, 1;
	setp.ne.s32 	%p131, %r358, 6;
	@%p131 bra 	$L__BB3_132;

	st.local.u32 	[%rd11], %rd151;
	mov.u32 	%r308, 4;
	sub.s32 	%r92, %r308, %r89;
	mov.u32 	%r309, 6;
	sub.s32 	%r310, %r309, %r89;
	mul.wide.s32 	%rd119, %r310, 4;
	add.s64 	%rd120, %rd1, %rd119;
	ld.local.u32 	%r359, [%rd120];
	ld.local.u32 	%r360, [%rd120+-4];
	and.b32  	%r95, %r87, 31;
	setp.eq.s32 	%p132, %r95, 0;
	@%p132 bra 	$L__BB3_135;

	mov.u32 	%r311, 32;
	sub.s32 	%r312, %r311, %r95;
	shr.u32 	%r313, %r360, %r312;
	shl.b32 	%r314, %r359, %r95;
	add.s32 	%r359, %r313, %r314;
	mul.wide.s32 	%rd121, %r92, 4;
	add.s64 	%rd122, %rd1, %rd121;
	ld.local.u32 	%r315, [%rd122];
	shr.u32 	%r316, %r315, %r312;
	shl.b32 	%r317, %r360, %r95;
	add.s32 	%r360, %r316, %r317;

$L__BB3_135:
	and.b32  	%r318, %r86, -2147483648;
	shr.u32 	%r319, %r360, 30;
	shl.b32 	%r320, %r359, 2;
	or.b32  	%r321, %r319, %r320;
	shr.u32 	%r322, %r321, 31;
	shr.u32 	%r323, %r359, 30;
	add.s32 	%r324, %r322, %r323;
	neg.s32 	%r325, %r324;
	setp.eq.s32 	%p133, %r318, 0;
	selp.b32 	%r361, %r324, %r325, %p133;
	setp.ne.s32 	%p134, %r322, 0;
	xor.b32  	%r326, %r318, -2147483648;
	selp.b32 	%r327, %r326, %r318, %p134;
	selp.b32 	%r328, -1, 0, %p134;
	xor.b32  	%r329, %r321, %r328;
	shl.b32 	%r330, %r360, 2;
	xor.b32  	%r331, %r330, %r328;
	cvt.u64.u32 	%rd123, %r329;
	cvt.u64.u32 	%rd124, %r331;
	bfi.b64 	%rd125, %rd123, %rd124, 32, 32;
	cvt.rn.f64.s64 	%fd397, %rd125;
	mul.rn.f64 	%fd398, %fd397, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd398;
	setp.eq.s32 	%p135, %r327, 0;
	neg.f32 	%f125, %f124;
	selp.f32 	%f160, %f124, %f125, %p135;

$L__BB3_137:
	add.s32 	%r102, %r361, 1;
	and.b32  	%r103, %r102, 1;
	setp.eq.s32 	%p3, %r103, 0;
	mul.rn.f32 	%f47, %f160, %f160;
	mov.f32 	%f161, 0fB94D4153;
	@%p3 bra 	$L__BB3_139;

	mov.f32 	%f128, 0fBAB607ED;
	mov.f32 	%f129, 0f37CBAC00;
	fma.rn.f32 	%f161, %f129, %f47, %f128;

$L__BB3_139:
	selp.f32 	%f130, %f160, 0f3F800000, %p3;
	selp.f32 	%f131, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f132, %f161, %f47, %f131;
	selp.f32 	%f133, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f134, %f132, %f47, %f133;
	mov.f32 	%f135, 0f00000000;
	fma.rn.f32 	%f136, %f47, %f130, %f135;
	fma.rn.f32 	%f162, %f134, %f136, %f130;
	and.b32  	%r333, %r102, 2;
	setp.eq.s32 	%p137, %r333, 0;
	@%p137 bra 	$L__BB3_141;

	mov.f32 	%f138, 0fBF800000;
	fma.rn.f32 	%f162, %f162, %f138, %f135;

$L__BB3_141:
	ld.param.u64 	%rd133, [wgs84_to_gcj02_cuda_float_param_4];
	mov.u32 	%r337, %tid.x;
	mov.u32 	%r336, %ntid.x;
	mov.u32 	%r335, %ctaid.x;
	mad.lo.s32 	%r334, %r335, %r336, %r337;
	cvt.s64.s32 	%rd132, %r334;
	ld.param.u64 	%rd131, [wgs84_to_gcj02_cuda_float_param_3];
	cvt.f64.f32 	%fd399, %f159;
	mul.rn.f64 	%fd400, %fd399, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd401, %fd400, %fd399;
	add.rn.f64 	%fd402, %fd401, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f139, %fd402;
	sqrt.rn.f32 	%f140, %f139;
	mov.f32 	%f141, 0f4AC2A60A;
	div.rn.f32 	%f142, %f141, %f140;
	mul.rn.f32 	%f143, %f142, %f162;
	cvt.f64.f32 	%fd403, %f143;
	mul.rn.f64 	%fd404, %fd403, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f144, %fd135;
	cvt.f64.f32 	%fd405, %f144;
	mul.rn.f64 	%fd406, %fd405, 0d4066800000000000;
	div.rn.f64 	%fd407, %fd406, %fd404;
	cvt.rn.f32.f64 	%f145, %fd407;
	add.rn.f32 	%f146, %f1, %f145;
	cvta.to.global.u64 	%rd126, %rd131;
	shl.b64 	%rd127, %rd132, 2;
	add.s64 	%rd128, %rd126, %rd127;
	st.global.f32 	[%rd128], %f146;
	mul.rn.f32 	%f147, %f140, %f139;
	cvt.f64.f32 	%fd408, %f147;
	mov.f64 	%fd409, 0d41582B102DE355C1;
	div.rn.f64 	%fd410, %fd409, %fd408;
	mul.rn.f64 	%fd411, %fd410, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f148, %fd123;
	cvt.f64.f32 	%fd412, %f148;
	mul.rn.f64 	%fd413, %fd412, 0d4066800000000000;
	div.rn.f64 	%fd414, %fd413, %fd411;
	cvt.rn.f32.f64 	%f149, %fd414;
	add.rn.f32 	%f150, %f3, %f149;
	cvta.to.global.u64 	%rd129, %rd133;
	add.s64 	%rd130, %rd129, %rd127;
	st.global.f32 	[%rd130], %f150;

$L__BB3_142:
	ret;

}
	// .globl	wgs84_to_bd09_cuda_float
.visible .entry wgs84_to_bd09_cuda_float(
	.param .u32 wgs84_to_bd09_cuda_float_param_0,
	.param .u64 wgs84_to_bd09_cuda_float_param_1,
	.param .u64 wgs84_to_bd09_cuda_float_param_2,
	.param .u64 wgs84_to_bd09_cuda_float_param_3,
	.param .u64 wgs84_to_bd09_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot4[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<236>;
	.reg .f32 	%f<347>;
	.reg .b32 	%r<629>;
	.reg .f64 	%fd<508>;
	.reg .b64 	%rd<242>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r181, [wgs84_to_bd09_cuda_float_param_0];
	ld.param.u64 	%rd62, [wgs84_to_bd09_cuda_float_param_1];
	ld.param.u64 	%rd63, [wgs84_to_bd09_cuda_float_param_2];
	add.u64 	%rd66, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r182, %ntid.x;
	mov.u32 	%r183, %ctaid.x;
	mov.u32 	%r184, %tid.x;
	mad.lo.s32 	%r1, %r183, %r182, %r184;
	setp.ge.s32 	%p9, %r1, %r181;
	@%p9 bra 	$L__BB4_223;

	cvta.to.global.u64 	%rd75, %rd62;
	cvt.s64.s32 	%rd10, %r1;
	mul.wide.s32 	%rd76, %r1, 4;
	add.s64 	%rd77, %rd75, %rd76;
	cvta.to.global.u64 	%rd78, %rd63;
	add.s64 	%rd79, %rd78, %rd76;
	ld.global.f32 	%f1, [%rd77];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd79];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd162, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd162;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd163, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd163;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r185, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %fd4;
	}
	and.b32  	%r187, %r186, 2147483647;
	setp.eq.s32 	%p10, %r187, 2146435072;
	setp.eq.s32 	%p11, %r185, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB4_4;
	bra.uni 	$L__BB4_2;

$L__BB4_4:
	mov.f64 	%fd173, 0d0000000000000000;
	mul.rn.f64 	%fd472, %fd4, %fd173;
	mov.u32 	%r589, 0;
	bra.uni 	$L__BB4_5;

$L__BB4_2:
	mul.rn.f64 	%fd164, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r589, %fd164;
	st.local.u32 	[%rd8], %r589;
	cvt.rn.f64.s32 	%fd165, %r589;
	neg.f64 	%fd166, %fd165;
	mov.f64 	%fd167, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd168, %fd166, %fd167, %fd4;
	mov.f64 	%fd169, 0d3C91A62633145C00;
	fma.rn.f64 	%fd170, %fd166, %fd169, %fd168;
	mov.f64 	%fd171, 0d397B839A252049C0;
	fma.rn.f64 	%fd472, %fd166, %fd171, %fd170;
	abs.f64 	%fd172, %fd4;
	setp.ltu.f64 	%p13, %fd172, 0d41E0000000000000;
	@%p13 bra 	$L__BB4_5;

	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd66;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd472, [retval0+0];
	} // callseq 24
	ld.local.u32 	%r589, [%rd8];

$L__BB4_5:
	and.b32  	%r189, %r589, 1;
	shl.b32 	%r190, %r589, 3;
	and.b32  	%r191, %r190, 8;
	setp.eq.s32 	%p14, %r189, 0;
	selp.f64 	%fd174, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd81, %r191, 8;
	mov.u64 	%rd82, __cudart_sin_cos_coeffs;
	add.s64 	%rd83, %rd82, %rd81;
	ld.global.nc.f64 	%fd175, [%rd83+8];
	mul.rn.f64 	%fd9, %fd472, %fd472;
	fma.rn.f64 	%fd176, %fd174, %fd9, %fd175;
	ld.global.nc.f64 	%fd177, [%rd83+16];
	fma.rn.f64 	%fd178, %fd176, %fd9, %fd177;
	ld.global.nc.f64 	%fd179, [%rd83+24];
	fma.rn.f64 	%fd180, %fd178, %fd9, %fd179;
	ld.global.nc.f64 	%fd181, [%rd83+32];
	fma.rn.f64 	%fd182, %fd180, %fd9, %fd181;
	ld.global.nc.f64 	%fd183, [%rd83+40];
	fma.rn.f64 	%fd184, %fd182, %fd9, %fd183;
	ld.global.nc.f64 	%fd185, [%rd83+48];
	fma.rn.f64 	%fd10, %fd184, %fd9, %fd185;
	fma.rn.f64 	%fd474, %fd10, %fd472, %fd472;
	@%p14 bra 	$L__BB4_7;

	mov.f64 	%fd186, 0d3FF0000000000000;
	fma.rn.f64 	%fd474, %fd10, %fd9, %fd186;

$L__BB4_7:
	and.b32  	%r192, %r589, 2;
	setp.eq.s32 	%p15, %r192, 0;
	@%p15 bra 	$L__BB4_9;

	mov.f64 	%fd187, 0d0000000000000000;
	mov.f64 	%fd188, 0dBFF0000000000000;
	fma.rn.f64 	%fd474, %fd474, %fd188, %fd187;

$L__BB4_9:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd16;
	}
	and.b32  	%r195, %r194, 2147483647;
	setp.eq.s32 	%p16, %r195, 2146435072;
	setp.eq.s32 	%p17, %r193, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB4_12;
	bra.uni 	$L__BB4_10;

$L__BB4_12:
	mov.f64 	%fd198, 0d0000000000000000;
	mul.rn.f64 	%fd475, %fd16, %fd198;
	mov.u32 	%r590, 0;
	bra.uni 	$L__BB4_13;

$L__BB4_10:
	mul.rn.f64 	%fd189, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r590, %fd189;
	st.local.u32 	[%rd8], %r590;
	cvt.rn.f64.s32 	%fd190, %r590;
	neg.f64 	%fd191, %fd190;
	mov.f64 	%fd192, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd193, %fd191, %fd192, %fd16;
	mov.f64 	%fd194, 0d3C91A62633145C00;
	fma.rn.f64 	%fd195, %fd191, %fd194, %fd193;
	mov.f64 	%fd196, 0d397B839A252049C0;
	fma.rn.f64 	%fd475, %fd191, %fd196, %fd195;
	abs.f64 	%fd197, %fd16;
	setp.ltu.f64 	%p19, %fd197, 0d41E0000000000000;
	@%p19 bra 	$L__BB4_13;

	add.u64 	%rd207, %SP, 0;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd475, [retval0+0];
	} // callseq 25
	ld.local.u32 	%r590, [%rd8];

$L__BB4_13:
	mov.u64 	%rd208, __cudart_sin_cos_coeffs;
	and.b32  	%r197, %r590, 1;
	shl.b32 	%r198, %r590, 3;
	and.b32  	%r199, %r198, 8;
	setp.eq.s32 	%p20, %r197, 0;
	selp.f64 	%fd199, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd85, %r199, 8;
	add.s64 	%rd87, %rd208, %rd85;
	ld.global.nc.f64 	%fd200, [%rd87+8];
	mul.rn.f64 	%fd21, %fd475, %fd475;
	fma.rn.f64 	%fd201, %fd199, %fd21, %fd200;
	ld.global.nc.f64 	%fd202, [%rd87+16];
	fma.rn.f64 	%fd203, %fd201, %fd21, %fd202;
	ld.global.nc.f64 	%fd204, [%rd87+24];
	fma.rn.f64 	%fd205, %fd203, %fd21, %fd204;
	ld.global.nc.f64 	%fd206, [%rd87+32];
	fma.rn.f64 	%fd207, %fd205, %fd21, %fd206;
	ld.global.nc.f64 	%fd208, [%rd87+40];
	fma.rn.f64 	%fd209, %fd207, %fd21, %fd208;
	ld.global.nc.f64 	%fd210, [%rd87+48];
	fma.rn.f64 	%fd22, %fd209, %fd21, %fd210;
	fma.rn.f64 	%fd477, %fd22, %fd475, %fd475;
	@%p20 bra 	$L__BB4_15;

	mov.f64 	%fd211, 0d3FF0000000000000;
	fma.rn.f64 	%fd477, %fd22, %fd21, %fd211;

$L__BB4_15:
	and.b32  	%r200, %r590, 2;
	setp.eq.s32 	%p21, %r200, 0;
	@%p21 bra 	$L__BB4_17;

	mov.f64 	%fd212, 0d0000000000000000;
	mov.f64 	%fd213, 0dBFF0000000000000;
	fma.rn.f64 	%fd477, %fd477, %fd213, %fd212;

$L__BB4_17:
	mul.rn.f64 	%fd214, %fd477, 0d4034000000000000;
	mul.rn.f64 	%fd215, %fd474, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd215, %fd214;
	mul.rn.f32 	%f108, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r594, %f108;
	cvt.rn.f32.s32 	%f109, %r594;
	mov.f32 	%f110, 0fBFC90FDA;
	fma.rn.f32 	%f111, %f109, %f110, %f6;
	mov.f32 	%f112, 0fB3A22168;
	fma.rn.f32 	%f113, %f109, %f112, %f111;
	mov.f32 	%f114, 0fA7C234C5;
	fma.rn.f32 	%f322, %f109, %f114, %f113;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p22, %f8, 0f47CE4780;
	add.s64 	%rd11, %rd1, 24;
	@%p22 bra 	$L__BB4_25;

	setp.eq.f32 	%p23, %f8, 0f7F800000;
	@%p23 bra 	$L__BB4_24;
	bra.uni 	$L__BB4_19;

$L__BB4_24:
	mov.f32 	%f117, 0f00000000;
	mul.rn.f32 	%f322, %f6, %f117;
	mov.u32 	%r594, 0;
	bra.uni 	$L__BB4_25;

$L__BB4_19:
	mov.b32 	%r9, %f6;
	bfe.u32 	%r202, %r9, 23, 8;
	add.s32 	%r10, %r202, -128;
	shl.b32 	%r203, %r9, 8;
	or.b32  	%r11, %r203, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd220, 0;
	mov.u32 	%r591, 0;
	mov.u64 	%rd219, __cudart_i2opi_f;
	mov.u64 	%rd218, %rd1;

$L__BB4_20:
	.pragma "nounroll";
	ld.global.nc.u32 	%r204, [%rd219];
	mad.wide.u32 	%rd90, %r204, %r11, %rd220;
	shr.u64 	%rd220, %rd90, 32;
	st.local.u32 	[%rd218], %rd90;
	add.s64 	%rd219, %rd219, 4;
	add.s64 	%rd218, %rd218, 4;
	add.s32 	%r591, %r591, 1;
	setp.ne.s32 	%p24, %r591, 6;
	@%p24 bra 	$L__BB4_20;

	st.local.u32 	[%rd11], %rd220;
	mov.u32 	%r205, 4;
	sub.s32 	%r15, %r205, %r12;
	mov.u32 	%r206, 6;
	sub.s32 	%r207, %r206, %r12;
	mul.wide.s32 	%rd91, %r207, 4;
	add.s64 	%rd92, %rd1, %rd91;
	ld.local.u32 	%r592, [%rd92];
	ld.local.u32 	%r593, [%rd92+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p25, %r18, 0;
	@%p25 bra 	$L__BB4_23;

	mov.u32 	%r208, 32;
	sub.s32 	%r209, %r208, %r18;
	shr.u32 	%r210, %r593, %r209;
	shl.b32 	%r211, %r592, %r18;
	add.s32 	%r592, %r210, %r211;
	mul.wide.s32 	%rd93, %r15, 4;
	add.s64 	%rd94, %rd1, %rd93;
	ld.local.u32 	%r212, [%rd94];
	shr.u32 	%r213, %r212, %r209;
	shl.b32 	%r214, %r593, %r18;
	add.s32 	%r593, %r213, %r214;

$L__BB4_23:
	and.b32  	%r215, %r9, -2147483648;
	shr.u32 	%r216, %r593, 30;
	shl.b32 	%r217, %r592, 2;
	or.b32  	%r218, %r216, %r217;
	shr.u32 	%r219, %r218, 31;
	shr.u32 	%r220, %r592, 30;
	add.s32 	%r221, %r219, %r220;
	neg.s32 	%r222, %r221;
	setp.eq.s32 	%p26, %r215, 0;
	selp.b32 	%r594, %r221, %r222, %p26;
	setp.ne.s32 	%p27, %r219, 0;
	xor.b32  	%r223, %r215, -2147483648;
	selp.b32 	%r224, %r223, %r215, %p27;
	selp.b32 	%r225, -1, 0, %p27;
	xor.b32  	%r226, %r218, %r225;
	shl.b32 	%r227, %r593, 2;
	xor.b32  	%r228, %r227, %r225;
	cvt.u64.u32 	%rd95, %r226;
	cvt.u64.u32 	%rd96, %r228;
	bfi.b64 	%rd97, %rd95, %rd96, 32, 32;
	cvt.rn.f64.s64 	%fd216, %rd97;
	mul.rn.f64 	%fd217, %fd216, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f115, %fd217;
	setp.eq.s32 	%p28, %r224, 0;
	neg.f32 	%f116, %f115;
	selp.f32 	%f322, %f115, %f116, %p28;

$L__BB4_25:
	and.b32  	%r25, %r594, 1;
	setp.eq.s32 	%p1, %r25, 0;
	mul.rn.f32 	%f12, %f322, %f322;
	mov.f32 	%f323, 0fB94D4153;
	@%p1 bra 	$L__BB4_27;

	mov.f32 	%f119, 0fBAB607ED;
	mov.f32 	%f120, 0f37CBAC00;
	fma.rn.f32 	%f323, %f120, %f12, %f119;

$L__BB4_27:
	selp.f32 	%f121, %f322, 0f3F800000, %p1;
	selp.f32 	%f122, 0f3C0885E4, 0f3D2AAABB, %p1;
	fma.rn.f32 	%f123, %f323, %f12, %f122;
	selp.f32 	%f124, 0fBE2AAAA8, 0fBEFFFFFF, %p1;
	fma.rn.f32 	%f125, %f123, %f12, %f124;
	mov.f32 	%f126, 0f00000000;
	fma.rn.f32 	%f127, %f12, %f121, %f126;
	fma.rn.f32 	%f324, %f125, %f127, %f121;
	and.b32  	%r230, %r594, 2;
	setp.eq.s32 	%p30, %r230, 0;
	@%p30 bra 	$L__BB4_29;

	mov.f32 	%f129, 0fBF800000;
	fma.rn.f32 	%f324, %f324, %f129, %f126;

$L__BB4_29:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r231, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd30;
	}
	and.b32  	%r233, %r232, 2147483647;
	setp.eq.s32 	%p31, %r233, 2146435072;
	setp.eq.s32 	%p32, %r231, 0;
	and.pred  	%p33, %p32, %p31;
	@%p33 bra 	$L__BB4_32;
	bra.uni 	$L__BB4_30;

$L__BB4_32:
	mov.f64 	%fd227, 0d0000000000000000;
	mul.rn.f64 	%fd478, %fd30, %fd227;
	mov.u32 	%r595, 0;
	bra.uni 	$L__BB4_33;

$L__BB4_30:
	mul.rn.f64 	%fd218, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r595, %fd218;
	st.local.u32 	[%rd1], %r595;
	cvt.rn.f64.s32 	%fd219, %r595;
	neg.f64 	%fd220, %fd219;
	mov.f64 	%fd221, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd222, %fd220, %fd221, %fd30;
	mov.f64 	%fd223, 0d3C91A62633145C00;
	fma.rn.f64 	%fd224, %fd220, %fd223, %fd222;
	mov.f64 	%fd225, 0d397B839A252049C0;
	fma.rn.f64 	%fd478, %fd220, %fd225, %fd224;
	abs.f64 	%fd226, %fd30;
	setp.ltu.f64 	%p34, %fd226, 0d41E0000000000000;
	@%p34 bra 	$L__BB4_33;

	add.u64 	%rd209, %SP, 0;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd209;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd478, [retval0+0];
	} // callseq 26
	ld.local.u32 	%r595, [%rd1];

$L__BB4_33:
	mov.u64 	%rd210, __cudart_sin_cos_coeffs;
	and.b32  	%r235, %r595, 1;
	shl.b32 	%r236, %r595, 3;
	and.b32  	%r237, %r236, 8;
	setp.eq.s32 	%p35, %r235, 0;
	selp.f64 	%fd228, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p35;
	mul.wide.s32 	%rd99, %r237, 8;
	add.s64 	%rd101, %rd210, %rd99;
	ld.global.nc.f64 	%fd229, [%rd101+8];
	mul.rn.f64 	%fd35, %fd478, %fd478;
	fma.rn.f64 	%fd230, %fd228, %fd35, %fd229;
	ld.global.nc.f64 	%fd231, [%rd101+16];
	fma.rn.f64 	%fd232, %fd230, %fd35, %fd231;
	ld.global.nc.f64 	%fd233, [%rd101+24];
	fma.rn.f64 	%fd234, %fd232, %fd35, %fd233;
	ld.global.nc.f64 	%fd235, [%rd101+32];
	fma.rn.f64 	%fd236, %fd234, %fd35, %fd235;
	ld.global.nc.f64 	%fd237, [%rd101+40];
	fma.rn.f64 	%fd238, %fd236, %fd35, %fd237;
	ld.global.nc.f64 	%fd239, [%rd101+48];
	fma.rn.f64 	%fd36, %fd238, %fd35, %fd239;
	fma.rn.f64 	%fd480, %fd36, %fd478, %fd478;
	@%p35 bra 	$L__BB4_35;

	mov.f64 	%fd240, 0d3FF0000000000000;
	fma.rn.f64 	%fd480, %fd36, %fd35, %fd240;

$L__BB4_35:
	and.b32  	%r238, %r595, 2;
	setp.eq.s32 	%p36, %r238, 0;
	@%p36 bra 	$L__BB4_37;

	mov.f64 	%fd241, 0d0000000000000000;
	mov.f64 	%fd242, 0dBFF0000000000000;
	fma.rn.f64 	%fd480, %fd480, %fd242, %fd241;

$L__BB4_37:
	mul.rn.f64 	%fd243, %fd480, 0d4044000000000000;
	cvt.f64.f32 	%fd244, %f324;
	mul.rn.f64 	%fd245, %fd244, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd245, %fd243;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r239, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %fd43;
	}
	and.b32  	%r241, %r240, 2147483647;
	setp.eq.s32 	%p37, %r241, 2146435072;
	setp.eq.s32 	%p38, %r239, 0;
	and.pred  	%p39, %p38, %p37;
	@%p39 bra 	$L__BB4_40;
	bra.uni 	$L__BB4_38;

$L__BB4_40:
	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd481, %fd43, %fd255;
	mov.u32 	%r596, 0;
	bra.uni 	$L__BB4_41;

$L__BB4_38:
	mul.rn.f64 	%fd246, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r596, %fd246;
	st.local.u32 	[%rd1], %r596;
	cvt.rn.f64.s32 	%fd247, %r596;
	neg.f64 	%fd248, %fd247;
	mov.f64 	%fd249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd250, %fd248, %fd249, %fd43;
	mov.f64 	%fd251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd252, %fd248, %fd251, %fd250;
	mov.f64 	%fd253, 0d397B839A252049C0;
	fma.rn.f64 	%fd481, %fd248, %fd253, %fd252;
	abs.f64 	%fd254, %fd43;
	setp.ltu.f64 	%p40, %fd254, 0d41E0000000000000;
	@%p40 bra 	$L__BB4_41;

	add.u64 	%rd195, %SP, 0;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd195;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd481, [retval0+0];
	} // callseq 27
	ld.local.u32 	%r596, [%rd1];

$L__BB4_41:
	mov.u64 	%rd196, __cudart_sin_cos_coeffs;
	and.b32  	%r243, %r596, 1;
	shl.b32 	%r244, %r596, 3;
	and.b32  	%r245, %r244, 8;
	setp.eq.s32 	%p41, %r243, 0;
	selp.f64 	%fd256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p41;
	mul.wide.s32 	%rd103, %r245, 8;
	add.s64 	%rd105, %rd196, %rd103;
	ld.global.nc.f64 	%fd257, [%rd105+8];
	mul.rn.f64 	%fd48, %fd481, %fd481;
	fma.rn.f64 	%fd258, %fd256, %fd48, %fd257;
	ld.global.nc.f64 	%fd259, [%rd105+16];
	fma.rn.f64 	%fd260, %fd258, %fd48, %fd259;
	ld.global.nc.f64 	%fd261, [%rd105+24];
	fma.rn.f64 	%fd262, %fd260, %fd48, %fd261;
	ld.global.nc.f64 	%fd263, [%rd105+32];
	fma.rn.f64 	%fd264, %fd262, %fd48, %fd263;
	ld.global.nc.f64 	%fd265, [%rd105+40];
	fma.rn.f64 	%fd266, %fd264, %fd48, %fd265;
	ld.global.nc.f64 	%fd267, [%rd105+48];
	fma.rn.f64 	%fd49, %fd266, %fd48, %fd267;
	fma.rn.f64 	%fd483, %fd49, %fd481, %fd481;
	@%p41 bra 	$L__BB4_43;

	mov.f64 	%fd268, 0d3FF0000000000000;
	fma.rn.f64 	%fd483, %fd49, %fd48, %fd268;

$L__BB4_43:
	and.b32  	%r246, %r596, 2;
	setp.eq.s32 	%p42, %r246, 0;
	@%p42 bra 	$L__BB4_45;

	mov.f64 	%fd269, 0d0000000000000000;
	mov.f64 	%fd270, 0dBFF0000000000000;
	fma.rn.f64 	%fd483, %fd483, %fd270, %fd269;

$L__BB4_45:
	mul.rn.f64 	%fd271, %fd483, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd271;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r247, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %fd56;
	}
	and.b32  	%r249, %r248, 2147483647;
	setp.eq.s32 	%p43, %r249, 2146435072;
	setp.eq.s32 	%p44, %r247, 0;
	and.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB4_48;
	bra.uni 	$L__BB4_46;

$L__BB4_48:
	mov.f64 	%fd281, 0d0000000000000000;
	mul.rn.f64 	%fd484, %fd56, %fd281;
	mov.u32 	%r597, 0;
	bra.uni 	$L__BB4_49;

$L__BB4_46:
	mul.rn.f64 	%fd272, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r597, %fd272;
	st.local.u32 	[%rd1], %r597;
	cvt.rn.f64.s32 	%fd273, %r597;
	neg.f64 	%fd274, %fd273;
	mov.f64 	%fd275, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd276, %fd274, %fd275, %fd56;
	mov.f64 	%fd277, 0d3C91A62633145C00;
	fma.rn.f64 	%fd278, %fd274, %fd277, %fd276;
	mov.f64 	%fd279, 0d397B839A252049C0;
	fma.rn.f64 	%fd484, %fd274, %fd279, %fd278;
	abs.f64 	%fd280, %fd56;
	setp.ltu.f64 	%p46, %fd280, 0d41E0000000000000;
	@%p46 bra 	$L__BB4_49;

	add.u64 	%rd197, %SP, 0;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd197;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd484, [retval0+0];
	} // callseq 28
	ld.local.u32 	%r597, [%rd1];

$L__BB4_49:
	mov.u64 	%rd198, __cudart_sin_cos_coeffs;
	and.b32  	%r251, %r597, 1;
	shl.b32 	%r252, %r597, 3;
	and.b32  	%r253, %r252, 8;
	setp.eq.s32 	%p47, %r251, 0;
	selp.f64 	%fd282, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p47;
	mul.wide.s32 	%rd107, %r253, 8;
	add.s64 	%rd109, %rd198, %rd107;
	ld.global.nc.f64 	%fd283, [%rd109+8];
	mul.rn.f64 	%fd61, %fd484, %fd484;
	fma.rn.f64 	%fd284, %fd282, %fd61, %fd283;
	ld.global.nc.f64 	%fd285, [%rd109+16];
	fma.rn.f64 	%fd286, %fd284, %fd61, %fd285;
	ld.global.nc.f64 	%fd287, [%rd109+24];
	fma.rn.f64 	%fd288, %fd286, %fd61, %fd287;
	ld.global.nc.f64 	%fd289, [%rd109+32];
	fma.rn.f64 	%fd290, %fd288, %fd61, %fd289;
	ld.global.nc.f64 	%fd291, [%rd109+40];
	fma.rn.f64 	%fd292, %fd290, %fd61, %fd291;
	ld.global.nc.f64 	%fd293, [%rd109+48];
	fma.rn.f64 	%fd62, %fd292, %fd61, %fd293;
	fma.rn.f64 	%fd486, %fd62, %fd484, %fd484;
	@%p47 bra 	$L__BB4_51;

	mov.f64 	%fd294, 0d3FF0000000000000;
	fma.rn.f64 	%fd486, %fd62, %fd61, %fd294;

$L__BB4_51:
	and.b32  	%r254, %r597, 2;
	setp.eq.s32 	%p48, %r254, 0;
	@%p48 bra 	$L__BB4_53;

	mov.f64 	%fd295, 0d0000000000000000;
	mov.f64 	%fd296, 0dBFF0000000000000;
	fma.rn.f64 	%fd486, %fd486, %fd296, %fd295;

$L__BB4_53:
	mul.rn.f64 	%fd297, %fd486, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd297;
	cvt.rn.f32.f64 	%f130, %fd28;
	cvt.f64.f32 	%fd69, %f130;
	mul.rn.f32 	%f131, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r601, %f131;
	cvt.rn.f32.s32 	%f132, %r601;
	mov.f32 	%f133, 0fBFC90FDA;
	fma.rn.f32 	%f134, %f132, %f133, %f5;
	mov.f32 	%f135, 0fB3A22168;
	fma.rn.f32 	%f136, %f132, %f135, %f134;
	mov.f32 	%f137, 0fA7C234C5;
	fma.rn.f32 	%f325, %f132, %f137, %f136;
	abs.f32 	%f19, %f5;
	setp.ltu.f32 	%p49, %f19, 0f47CE4780;
	@%p49 bra 	$L__BB4_61;

	setp.eq.f32 	%p50, %f19, 0f7F800000;
	@%p50 bra 	$L__BB4_60;
	bra.uni 	$L__BB4_55;

$L__BB4_60:
	mov.f32 	%f140, 0f00000000;
	mul.rn.f32 	%f325, %f5, %f140;
	mov.u32 	%r601, 0;
	bra.uni 	$L__BB4_61;

$L__BB4_55:
	mov.b32 	%r36, %f5;
	bfe.u32 	%r256, %r36, 23, 8;
	add.s32 	%r37, %r256, -128;
	shl.b32 	%r257, %r36, 8;
	or.b32  	%r38, %r257, -2147483648;
	shr.u32 	%r39, %r37, 5;
	mov.u64 	%rd223, 0;
	mov.u32 	%r598, 0;
	mov.u64 	%rd222, __cudart_i2opi_f;
	mov.u64 	%rd221, %rd1;

$L__BB4_56:
	.pragma "nounroll";
	ld.global.nc.u32 	%r258, [%rd222];
	mad.wide.u32 	%rd112, %r258, %r38, %rd223;
	shr.u64 	%rd223, %rd112, 32;
	st.local.u32 	[%rd221], %rd112;
	add.s64 	%rd222, %rd222, 4;
	add.s64 	%rd221, %rd221, 4;
	add.s32 	%r598, %r598, 1;
	setp.ne.s32 	%p51, %r598, 6;
	@%p51 bra 	$L__BB4_56;

	add.s64 	%rd211, %rd1, 24;
	st.local.u32 	[%rd211], %rd223;
	mov.u32 	%r259, 4;
	sub.s32 	%r42, %r259, %r39;
	mov.u32 	%r260, 6;
	sub.s32 	%r261, %r260, %r39;
	mul.wide.s32 	%rd113, %r261, 4;
	add.s64 	%rd114, %rd1, %rd113;
	ld.local.u32 	%r599, [%rd114];
	ld.local.u32 	%r600, [%rd114+-4];
	and.b32  	%r45, %r37, 31;
	setp.eq.s32 	%p52, %r45, 0;
	@%p52 bra 	$L__BB4_59;

	mov.u32 	%r262, 32;
	sub.s32 	%r263, %r262, %r45;
	shr.u32 	%r264, %r600, %r263;
	shl.b32 	%r265, %r599, %r45;
	add.s32 	%r599, %r264, %r265;
	mul.wide.s32 	%rd115, %r42, 4;
	add.s64 	%rd116, %rd1, %rd115;
	ld.local.u32 	%r266, [%rd116];
	shr.u32 	%r267, %r266, %r263;
	shl.b32 	%r268, %r600, %r45;
	add.s32 	%r600, %r267, %r268;

$L__BB4_59:
	and.b32  	%r269, %r36, -2147483648;
	shr.u32 	%r270, %r600, 30;
	shl.b32 	%r271, %r599, 2;
	or.b32  	%r272, %r270, %r271;
	shr.u32 	%r273, %r272, 31;
	shr.u32 	%r274, %r599, 30;
	add.s32 	%r275, %r273, %r274;
	neg.s32 	%r276, %r275;
	setp.eq.s32 	%p53, %r269, 0;
	selp.b32 	%r601, %r275, %r276, %p53;
	setp.ne.s32 	%p54, %r273, 0;
	xor.b32  	%r277, %r269, -2147483648;
	selp.b32 	%r278, %r277, %r269, %p54;
	selp.b32 	%r279, -1, 0, %p54;
	xor.b32  	%r280, %r272, %r279;
	shl.b32 	%r281, %r600, 2;
	xor.b32  	%r282, %r281, %r279;
	cvt.u64.u32 	%rd117, %r280;
	cvt.u64.u32 	%rd118, %r282;
	bfi.b64 	%rd119, %rd117, %rd118, 32, 32;
	cvt.rn.f64.s64 	%fd298, %rd119;
	mul.rn.f64 	%fd299, %fd298, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f138, %fd299;
	setp.eq.s32 	%p55, %r278, 0;
	neg.f32 	%f139, %f138;
	selp.f32 	%f325, %f138, %f139, %p55;

$L__BB4_61:
	and.b32  	%r52, %r601, 1;
	setp.eq.s32 	%p2, %r52, 0;
	mul.rn.f32 	%f23, %f325, %f325;
	mov.f32 	%f326, 0fB94D4153;
	@%p2 bra 	$L__BB4_63;

	mov.f32 	%f142, 0fBAB607ED;
	mov.f32 	%f143, 0f37CBAC00;
	fma.rn.f32 	%f326, %f143, %f23, %f142;

$L__BB4_63:
	selp.f32 	%f144, %f325, 0f3F800000, %p2;
	selp.f32 	%f145, 0f3C0885E4, 0f3D2AAABB, %p2;
	fma.rn.f32 	%f146, %f326, %f23, %f145;
	selp.f32 	%f147, 0fBE2AAAA8, 0fBEFFFFFF, %p2;
	fma.rn.f32 	%f148, %f146, %f23, %f147;
	mov.f32 	%f149, 0f00000000;
	fma.rn.f32 	%f150, %f23, %f144, %f149;
	fma.rn.f32 	%f327, %f148, %f150, %f144;
	and.b32  	%r284, %r601, 2;
	setp.eq.s32 	%p57, %r284, 0;
	@%p57 bra 	$L__BB4_65;

	mov.f32 	%f152, 0fBF800000;
	fma.rn.f32 	%f327, %f327, %f152, %f149;

$L__BB4_65:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r286}, %fd70;
	}
	and.b32  	%r287, %r286, 2147483647;
	setp.eq.s32 	%p58, %r287, 2146435072;
	setp.eq.s32 	%p59, %r285, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB4_68;
	bra.uni 	$L__BB4_66;

$L__BB4_68:
	mov.f64 	%fd309, 0d0000000000000000;
	mul.rn.f64 	%fd487, %fd70, %fd309;
	mov.u32 	%r602, 0;
	bra.uni 	$L__BB4_69;

$L__BB4_66:
	mul.rn.f64 	%fd300, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r602, %fd300;
	st.local.u32 	[%rd1], %r602;
	cvt.rn.f64.s32 	%fd301, %r602;
	neg.f64 	%fd302, %fd301;
	mov.f64 	%fd303, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd304, %fd302, %fd303, %fd70;
	mov.f64 	%fd305, 0d3C91A62633145C00;
	fma.rn.f64 	%fd306, %fd302, %fd305, %fd304;
	mov.f64 	%fd307, 0d397B839A252049C0;
	fma.rn.f64 	%fd487, %fd302, %fd307, %fd306;
	abs.f64 	%fd308, %fd70;
	setp.ltu.f64 	%p61, %fd308, 0d41E0000000000000;
	@%p61 bra 	$L__BB4_69;

	add.u64 	%rd199, %SP, 0;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd199;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd487, [retval0+0];
	} // callseq 29
	ld.local.u32 	%r602, [%rd1];

$L__BB4_69:
	mov.u64 	%rd200, __cudart_sin_cos_coeffs;
	and.b32  	%r289, %r602, 1;
	shl.b32 	%r290, %r602, 3;
	and.b32  	%r291, %r290, 8;
	setp.eq.s32 	%p62, %r289, 0;
	selp.f64 	%fd310, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd121, %r291, 8;
	add.s64 	%rd123, %rd200, %rd121;
	ld.global.nc.f64 	%fd311, [%rd123+8];
	mul.rn.f64 	%fd75, %fd487, %fd487;
	fma.rn.f64 	%fd312, %fd310, %fd75, %fd311;
	ld.global.nc.f64 	%fd313, [%rd123+16];
	fma.rn.f64 	%fd314, %fd312, %fd75, %fd313;
	ld.global.nc.f64 	%fd315, [%rd123+24];
	fma.rn.f64 	%fd316, %fd314, %fd75, %fd315;
	ld.global.nc.f64 	%fd317, [%rd123+32];
	fma.rn.f64 	%fd318, %fd316, %fd75, %fd317;
	ld.global.nc.f64 	%fd319, [%rd123+40];
	fma.rn.f64 	%fd320, %fd318, %fd75, %fd319;
	ld.global.nc.f64 	%fd321, [%rd123+48];
	fma.rn.f64 	%fd76, %fd320, %fd75, %fd321;
	fma.rn.f64 	%fd489, %fd76, %fd487, %fd487;
	@%p62 bra 	$L__BB4_71;

	mov.f64 	%fd322, 0d3FF0000000000000;
	fma.rn.f64 	%fd489, %fd76, %fd75, %fd322;

$L__BB4_71:
	and.b32  	%r292, %r602, 2;
	setp.eq.s32 	%p63, %r292, 0;
	@%p63 bra 	$L__BB4_73;

	mov.f64 	%fd323, 0d0000000000000000;
	mov.f64 	%fd324, 0dBFF0000000000000;
	fma.rn.f64 	%fd489, %fd489, %fd324, %fd323;

$L__BB4_73:
	mul.rn.f64 	%fd325, %fd489, 0d4044000000000000;
	cvt.f64.f32 	%fd326, %f327;
	mul.rn.f64 	%fd327, %fd326, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd327, %fd325;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r293, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r294}, %fd83;
	}
	and.b32  	%r295, %r294, 2147483647;
	setp.eq.s32 	%p64, %r295, 2146435072;
	setp.eq.s32 	%p65, %r293, 0;
	and.pred  	%p66, %p65, %p64;
	@%p66 bra 	$L__BB4_76;
	bra.uni 	$L__BB4_74;

$L__BB4_76:
	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd490, %fd83, %fd337;
	mov.u32 	%r603, 0;
	bra.uni 	$L__BB4_77;

$L__BB4_74:
	mul.rn.f64 	%fd328, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r603, %fd328;
	st.local.u32 	[%rd1], %r603;
	cvt.rn.f64.s32 	%fd329, %r603;
	neg.f64 	%fd330, %fd329;
	mov.f64 	%fd331, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd332, %fd330, %fd331, %fd83;
	mov.f64 	%fd333, 0d3C91A62633145C00;
	fma.rn.f64 	%fd334, %fd330, %fd333, %fd332;
	mov.f64 	%fd335, 0d397B839A252049C0;
	fma.rn.f64 	%fd490, %fd330, %fd335, %fd334;
	abs.f64 	%fd336, %fd83;
	setp.ltu.f64 	%p67, %fd336, 0d41E0000000000000;
	@%p67 bra 	$L__BB4_77;

	add.u64 	%rd201, %SP, 0;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd490, [retval0+0];
	} // callseq 30
	ld.local.u32 	%r603, [%rd1];

$L__BB4_77:
	mov.u64 	%rd202, __cudart_sin_cos_coeffs;
	and.b32  	%r297, %r603, 1;
	shl.b32 	%r298, %r603, 3;
	and.b32  	%r299, %r298, 8;
	setp.eq.s32 	%p68, %r297, 0;
	selp.f64 	%fd338, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p68;
	mul.wide.s32 	%rd125, %r299, 8;
	add.s64 	%rd127, %rd202, %rd125;
	ld.global.nc.f64 	%fd339, [%rd127+8];
	mul.rn.f64 	%fd88, %fd490, %fd490;
	fma.rn.f64 	%fd340, %fd338, %fd88, %fd339;
	ld.global.nc.f64 	%fd341, [%rd127+16];
	fma.rn.f64 	%fd342, %fd340, %fd88, %fd341;
	ld.global.nc.f64 	%fd343, [%rd127+24];
	fma.rn.f64 	%fd344, %fd342, %fd88, %fd343;
	ld.global.nc.f64 	%fd345, [%rd127+32];
	fma.rn.f64 	%fd346, %fd344, %fd88, %fd345;
	ld.global.nc.f64 	%fd347, [%rd127+40];
	fma.rn.f64 	%fd348, %fd346, %fd88, %fd347;
	ld.global.nc.f64 	%fd349, [%rd127+48];
	fma.rn.f64 	%fd89, %fd348, %fd88, %fd349;
	fma.rn.f64 	%fd492, %fd89, %fd490, %fd490;
	@%p68 bra 	$L__BB4_79;

	mov.f64 	%fd350, 0d3FF0000000000000;
	fma.rn.f64 	%fd492, %fd89, %fd88, %fd350;

$L__BB4_79:
	and.b32  	%r300, %r603, 2;
	setp.eq.s32 	%p69, %r300, 0;
	@%p69 bra 	$L__BB4_81;

	mov.f64 	%fd351, 0d0000000000000000;
	mov.f64 	%fd352, 0dBFF0000000000000;
	fma.rn.f64 	%fd492, %fd492, %fd352, %fd351;

$L__BB4_81:
	mul.rn.f64 	%fd353, %fd492, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd353;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r301, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r302}, %fd96;
	}
	and.b32  	%r303, %r302, 2147483647;
	setp.eq.s32 	%p70, %r303, 2146435072;
	setp.eq.s32 	%p71, %r301, 0;
	and.pred  	%p72, %p71, %p70;
	@%p72 bra 	$L__BB4_84;
	bra.uni 	$L__BB4_82;

$L__BB4_84:
	mov.f64 	%fd363, 0d0000000000000000;
	mul.rn.f64 	%fd493, %fd96, %fd363;
	mov.u32 	%r604, 0;
	bra.uni 	$L__BB4_85;

$L__BB4_82:
	mul.rn.f64 	%fd354, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r604, %fd354;
	st.local.u32 	[%rd1], %r604;
	cvt.rn.f64.s32 	%fd355, %r604;
	neg.f64 	%fd356, %fd355;
	mov.f64 	%fd357, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd358, %fd356, %fd357, %fd96;
	mov.f64 	%fd359, 0d3C91A62633145C00;
	fma.rn.f64 	%fd360, %fd356, %fd359, %fd358;
	mov.f64 	%fd361, 0d397B839A252049C0;
	fma.rn.f64 	%fd493, %fd356, %fd361, %fd360;
	abs.f64 	%fd362, %fd96;
	setp.ltu.f64 	%p73, %fd362, 0d41E0000000000000;
	@%p73 bra 	$L__BB4_85;

	add.u64 	%rd203, %SP, 0;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd203;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd493, [retval0+0];
	} // callseq 31
	ld.local.u32 	%r604, [%rd1];

$L__BB4_85:
	mov.u64 	%rd204, __cudart_sin_cos_coeffs;
	and.b32  	%r305, %r604, 1;
	shl.b32 	%r306, %r604, 3;
	and.b32  	%r307, %r306, 8;
	setp.eq.s32 	%p74, %r305, 0;
	selp.f64 	%fd364, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p74;
	mul.wide.s32 	%rd129, %r307, 8;
	add.s64 	%rd131, %rd204, %rd129;
	ld.global.nc.f64 	%fd365, [%rd131+8];
	mul.rn.f64 	%fd101, %fd493, %fd493;
	fma.rn.f64 	%fd366, %fd364, %fd101, %fd365;
	ld.global.nc.f64 	%fd367, [%rd131+16];
	fma.rn.f64 	%fd368, %fd366, %fd101, %fd367;
	ld.global.nc.f64 	%fd369, [%rd131+24];
	fma.rn.f64 	%fd370, %fd368, %fd101, %fd369;
	ld.global.nc.f64 	%fd371, [%rd131+32];
	fma.rn.f64 	%fd372, %fd370, %fd101, %fd371;
	ld.global.nc.f64 	%fd373, [%rd131+40];
	fma.rn.f64 	%fd374, %fd372, %fd101, %fd373;
	ld.global.nc.f64 	%fd375, [%rd131+48];
	fma.rn.f64 	%fd102, %fd374, %fd101, %fd375;
	fma.rn.f64 	%fd495, %fd102, %fd493, %fd493;
	@%p74 bra 	$L__BB4_87;

	mov.f64 	%fd376, 0d3FF0000000000000;
	fma.rn.f64 	%fd495, %fd102, %fd101, %fd376;

$L__BB4_87:
	and.b32  	%r308, %r604, 2;
	setp.eq.s32 	%p75, %r308, 0;
	@%p75 bra 	$L__BB4_89;

	mov.f64 	%fd377, 0d0000000000000000;
	mov.f64 	%fd378, 0dBFF0000000000000;
	fma.rn.f64 	%fd495, %fd495, %fd378, %fd377;

$L__BB4_89:
	mul.rn.f64 	%fd379, %fd495, 0d4072C00000000000;
	add.rn.f64 	%fd108, %fd95, %fd379;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd380, %fd1, %fd1;
	mov.f64 	%fd381, 0d4000000000000000;
	add.rn.f64 	%fd382, %fd380, 0dC059000000000000;
	mul.rn.f64 	%fd383, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd382, %fd383;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd381;
	}
	and.b32  	%r63, %r62, 2146435072;
	setp.eq.s32 	%p76, %r63, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd498, [retval0+0];
	} // callseq 32
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd2;
	}
	setp.lt.s32 	%p77, %r64, 0;
	and.pred  	%p3, %p77, %p76;
	not.pred 	%p78, %p3;
	@%p78 bra 	$L__BB4_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r309}, %fd498;
	}
	xor.b32  	%r310, %r309, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r311, %temp}, %fd498;
	}
	mov.b64 	%fd498, {%r311, %r310};

$L__BB4_91:
	add.rn.f32 	%f315, %f3, 0fC20C0000;
	setp.eq.f32 	%p79, %f315, 0f00000000;
	add.rn.f64 	%fd115, %fd108, %fd69;
	@%p79 bra 	$L__BB4_95;
	bra.uni 	$L__BB4_92;

$L__BB4_95:
	selp.b32 	%r312, %r64, 0, %p76;
	mov.u32 	%r313, 0;
	or.b32  	%r314, %r312, 2146435072;
	setp.lt.s32 	%p83, %r62, 0;
	selp.b32 	%r315, %r314, %r312, %p83;
	mov.b64 	%fd498, {%r313, %r315};
	bra.uni 	$L__BB4_96;

$L__BB4_92:
	setp.gt.s32 	%p80, %r64, -1;
	@%p80 bra 	$L__BB4_96;

	mov.f64 	%fd384, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd385, %fd384;
	setp.eq.f64 	%p81, %fd385, 0d4000000000000000;
	@%p81 bra 	$L__BB4_96;

	mov.f64 	%fd498, 0dFFF8000000000000;

$L__BB4_96:
	add.rn.f64 	%fd387, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r316}, %fd387;
	}
	and.b32  	%r317, %r316, 2146435072;
	setp.ne.s32 	%p84, %r317, 2146435072;
	@%p84 bra 	$L__BB4_103;

	setp.gtu.f64 	%p85, %fd111, 0d7FF0000000000000;
	@%p85 bra 	$L__BB4_102;
	bra.uni 	$L__BB4_98;

$L__BB4_102:
	mov.f64 	%fd389, 0d4000000000000000;
	add.rn.f64 	%fd498, %fd2, %fd389;
	bra.uni 	$L__BB4_103;

$L__BB4_98:
	mov.f64 	%fd388, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r318, %temp}, %fd388;
	}
	and.b32  	%r65, %r62, 2147483647;
	setp.eq.s32 	%p86, %r65, 2146435072;
	setp.eq.s32 	%p87, %r318, 0;
	and.pred  	%p88, %p86, %p87;
	@%p88 bra 	$L__BB4_101;
	bra.uni 	$L__BB4_99;

$L__BB4_101:
	add.rn.f32 	%f317, %f3, 0fC20C0000;
	setp.gt.f64 	%p95, %fd111, 0d3FF0000000000000;
	selp.b32 	%r325, 2146435072, 0, %p95;
	mov.u32 	%r326, 0;
	xor.b32  	%r327, %r325, 2146435072;
	setp.lt.s32 	%p96, %r62, 0;
	selp.b32 	%r328, %r327, %r325, %p96;
	setp.eq.f32 	%p97, %f317, 0fBF800000;
	selp.b32 	%r329, 1072693248, %r328, %p97;
	mov.b64 	%fd498, {%r326, %r329};
	bra.uni 	$L__BB4_103;

$L__BB4_99:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r319, %temp}, %fd2;
	}
	and.b32  	%r320, %r64, 2147483647;
	setp.ne.s32 	%p89, %r320, 2146435072;
	setp.ne.s32 	%p90, %r319, 0;
	or.pred  	%p91, %p89, %p90;
	@%p91 bra 	$L__BB4_103;

	setp.gt.s32 	%p92, %r62, -1;
	selp.b32 	%r321, 2146435072, 0, %p92;
	mov.u32 	%r322, 0;
	setp.ne.s32 	%p93, %r65, 1071644672;
	and.pred  	%p94, %p93, %p3;
	or.b32  	%r323, %r321, -2147483648;
	selp.b32 	%r324, %r323, %r321, %p94;
	mov.b64 	%fd498, {%r322, %r324};

$L__BB4_103:
	add.rn.f32 	%f318, %f1, 0fC2D20000;
	add.rn.f32 	%f316, %f3, 0fC20C0000;
	mul.rn.f64 	%fd390, %fd498, 0d3FC999999999999A;
	setp.eq.f32 	%p98, %f316, 0f3F800000;
	selp.f64 	%fd391, 0d3FC999999999999A, %fd390, %p98;
	add.rn.f64 	%fd392, %fd110, %fd391;
	mul.rn.f32 	%f153, %f318, %f316;
	cvt.f64.f32 	%fd393, %f153;
	mul.rn.f64 	%fd122, %fd393, 0d3FB999999999999A;
	add.rn.f64 	%fd394, %fd122, %fd392;
	abs.f32 	%f154, %f318;
	sqrt.rn.f32 	%f155, %f154;
	cvt.f64.f32 	%fd123, %f155;
	mul.rn.f64 	%fd395, %fd123, 0d3FC999999999999A;
	add.rn.f64 	%fd124, %fd395, %fd394;
	add.rn.f64 	%fd396, %fd2, %fd2;
	add.rn.f64 	%fd397, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd125, %fd397, %fd396;
	abs.f64 	%fd126, %fd1;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd126;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd501, [retval0+0];
	} // callseq 33
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd1;
	}
	setp.lt.s32 	%p99, %r66, 0;
	and.pred  	%p4, %p99, %p76;
	not.pred 	%p101, %p4;
	@%p101 bra 	$L__BB4_105;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r330}, %fd501;
	}
	xor.b32  	%r331, %r330, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r332, %temp}, %fd501;
	}
	mov.b64 	%fd501, {%r332, %r331};

$L__BB4_105:
	add.rn.f32 	%f319, %f1, 0fC2D20000;
	setp.eq.f32 	%p102, %f319, 0f00000000;
	cvt.rn.f32.f64 	%f156, %fd109;
	cvt.f64.f32 	%fd398, %f156;
	mul.rn.f64 	%fd399, %fd398, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f157, %fd399;
	cvt.f64.f32 	%fd400, %f157;
	add.rn.f64 	%fd130, %fd124, %fd400;
	@%p102 bra 	$L__BB4_109;
	bra.uni 	$L__BB4_106;

$L__BB4_109:
	selp.b32 	%r333, %r66, 0, %p76;
	mov.u32 	%r334, 0;
	or.b32  	%r335, %r333, 2146435072;
	setp.lt.s32 	%p106, %r62, 0;
	selp.b32 	%r336, %r335, %r333, %p106;
	mov.b64 	%fd501, {%r334, %r336};
	bra.uni 	$L__BB4_110;

$L__BB4_106:
	setp.gt.s32 	%p103, %r66, -1;
	@%p103 bra 	$L__BB4_110;

	mov.f64 	%fd401, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd402, %fd401;
	setp.eq.f64 	%p104, %fd402, 0d4000000000000000;
	@%p104 bra 	$L__BB4_110;

	mov.f64 	%fd501, 0dFFF8000000000000;

$L__BB4_110:
	add.rn.f64 	%fd404, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r337}, %fd404;
	}
	and.b32  	%r338, %r337, 2146435072;
	setp.ne.s32 	%p107, %r338, 2146435072;
	@%p107 bra 	$L__BB4_117;

	setp.gtu.f64 	%p108, %fd126, 0d7FF0000000000000;
	@%p108 bra 	$L__BB4_116;
	bra.uni 	$L__BB4_112;

$L__BB4_116:
	mov.f64 	%fd406, 0d4000000000000000;
	add.rn.f64 	%fd501, %fd1, %fd406;
	bra.uni 	$L__BB4_117;

$L__BB4_112:
	mov.f64 	%fd405, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd405;
	}
	and.b32  	%r67, %r62, 2147483647;
	setp.eq.s32 	%p109, %r67, 2146435072;
	setp.eq.s32 	%p110, %r339, 0;
	and.pred  	%p111, %p109, %p110;
	@%p111 bra 	$L__BB4_115;
	bra.uni 	$L__BB4_113;

$L__BB4_115:
	add.rn.f32 	%f321, %f1, 0fC2D20000;
	setp.gt.f64 	%p118, %fd126, 0d3FF0000000000000;
	selp.b32 	%r346, 2146435072, 0, %p118;
	mov.u32 	%r347, 0;
	xor.b32  	%r348, %r346, 2146435072;
	setp.lt.s32 	%p119, %r62, 0;
	selp.b32 	%r349, %r348, %r346, %p119;
	setp.eq.f32 	%p120, %f321, 0fBF800000;
	selp.b32 	%r350, 1072693248, %r349, %p120;
	mov.b64 	%fd501, {%r347, %r350};
	bra.uni 	$L__BB4_117;

$L__BB4_113:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r340, %temp}, %fd1;
	}
	and.b32  	%r341, %r66, 2147483647;
	setp.ne.s32 	%p112, %r341, 2146435072;
	setp.ne.s32 	%p113, %r340, 0;
	or.pred  	%p114, %p112, %p113;
	@%p114 bra 	$L__BB4_117;

	setp.gt.s32 	%p115, %r62, -1;
	selp.b32 	%r342, 2146435072, 0, %p115;
	mov.u32 	%r343, 0;
	setp.ne.s32 	%p116, %r67, 1071644672;
	and.pred  	%p117, %p116, %p4;
	or.b32  	%r344, %r342, -2147483648;
	selp.b32 	%r345, %r344, %r342, %p117;
	mov.b64 	%fd501, {%r343, %r345};

$L__BB4_117:
	add.rn.f32 	%f320, %f1, 0fC2D20000;
	mul.rn.f64 	%fd407, %fd501, 0d3FB999999999999A;
	setp.eq.f32 	%p121, %f320, 0f3F800000;
	selp.f64 	%fd408, 0d3FB999999999999A, %fd407, %p121;
	add.rn.f64 	%fd409, %fd125, %fd408;
	add.rn.f64 	%fd410, %fd122, %fd409;
	mul.rn.f64 	%fd411, %fd123, 0d3FB999999999999A;
	add.rn.f64 	%fd137, %fd411, %fd410;
	cvt.f64.f32 	%fd412, %f3;
	div.rn.f64 	%fd413, %fd412, 0d4066800000000000;
	mul.rn.f64 	%fd414, %fd413, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f29, %fd414;
	mul.rn.f32 	%f158, %f29, 0f3F22F983;
	cvt.rni.s32.f32 	%r612, %f158;
	cvt.rn.f32.s32 	%f159, %r612;
	mov.f32 	%f160, 0fBFC90FDA;
	fma.rn.f32 	%f161, %f159, %f160, %f29;
	mov.f32 	%f162, 0fB3A22168;
	fma.rn.f32 	%f163, %f159, %f162, %f161;
	mov.f32 	%f164, 0fA7C234C5;
	fma.rn.f32 	%f331, %f159, %f164, %f163;
	abs.f32 	%f31, %f29;
	setp.ltu.f32 	%p122, %f31, 0f47CE4780;
	mov.u32 	%r608, %r612;
	mov.f32 	%f328, %f331;
	@%p122 bra 	$L__BB4_125;

	setp.eq.f32 	%p123, %f31, 0f7F800000;
	@%p123 bra 	$L__BB4_124;
	bra.uni 	$L__BB4_119;

$L__BB4_124:
	mov.f32 	%f167, 0f00000000;
	mul.rn.f32 	%f328, %f29, %f167;
	mov.u32 	%r608, 0;
	bra.uni 	$L__BB4_125;

$L__BB4_119:
	mov.b32 	%r69, %f29;
	bfe.u32 	%r352, %r69, 23, 8;
	add.s32 	%r70, %r352, -128;
	shl.b32 	%r353, %r69, 8;
	or.b32  	%r71, %r353, -2147483648;
	shr.u32 	%r72, %r70, 5;
	mov.u64 	%rd226, 0;
	mov.u32 	%r605, 0;
	mov.u64 	%rd225, __cudart_i2opi_f;
	mov.u64 	%rd224, %rd1;

$L__BB4_120:
	.pragma "nounroll";
	ld.global.nc.u32 	%r354, [%rd225];
	mad.wide.u32 	%rd134, %r354, %r71, %rd226;
	shr.u64 	%rd226, %rd134, 32;
	st.local.u32 	[%rd224], %rd134;
	add.s64 	%rd225, %rd225, 4;
	add.s64 	%rd224, %rd224, 4;
	add.s32 	%r605, %r605, 1;
	setp.ne.s32 	%p124, %r605, 6;
	@%p124 bra 	$L__BB4_120;

	add.s64 	%rd212, %rd1, 24;
	st.local.u32 	[%rd212], %rd226;
	mov.u32 	%r355, 4;
	sub.s32 	%r75, %r355, %r72;
	mov.u32 	%r356, 6;
	sub.s32 	%r357, %r356, %r72;
	mul.wide.s32 	%rd135, %r357, 4;
	add.s64 	%rd136, %rd1, %rd135;
	ld.local.u32 	%r606, [%rd136];
	ld.local.u32 	%r607, [%rd136+-4];
	and.b32  	%r78, %r70, 31;
	setp.eq.s32 	%p125, %r78, 0;
	@%p125 bra 	$L__BB4_123;

	mov.u32 	%r358, 32;
	sub.s32 	%r359, %r358, %r78;
	shr.u32 	%r360, %r607, %r359;
	shl.b32 	%r361, %r606, %r78;
	add.s32 	%r606, %r360, %r361;
	mul.wide.s32 	%rd137, %r75, 4;
	add.s64 	%rd138, %rd1, %rd137;
	ld.local.u32 	%r362, [%rd138];
	shr.u32 	%r363, %r362, %r359;
	shl.b32 	%r364, %r607, %r78;
	add.s32 	%r607, %r363, %r364;

$L__BB4_123:
	and.b32  	%r365, %r69, -2147483648;
	shr.u32 	%r366, %r607, 30;
	shl.b32 	%r367, %r606, 2;
	or.b32  	%r368, %r366, %r367;
	shr.u32 	%r369, %r368, 31;
	shr.u32 	%r370, %r606, 30;
	add.s32 	%r371, %r369, %r370;
	neg.s32 	%r372, %r371;
	setp.eq.s32 	%p126, %r365, 0;
	selp.b32 	%r608, %r371, %r372, %p126;
	setp.ne.s32 	%p127, %r369, 0;
	xor.b32  	%r373, %r365, -2147483648;
	selp.b32 	%r374, %r373, %r365, %p127;
	selp.b32 	%r375, -1, 0, %p127;
	xor.b32  	%r376, %r368, %r375;
	shl.b32 	%r377, %r607, 2;
	xor.b32  	%r378, %r377, %r375;
	cvt.u64.u32 	%rd139, %r376;
	cvt.u64.u32 	%rd140, %r378;
	bfi.b64 	%rd141, %rd139, %rd140, 32, 32;
	cvt.rn.f64.s64 	%fd415, %rd141;
	mul.rn.f64 	%fd416, %fd415, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f165, %fd416;
	setp.eq.s32 	%p128, %r374, 0;
	neg.f32 	%f166, %f165;
	selp.f32 	%f328, %f165, %f166, %p128;

$L__BB4_125:
	and.b32  	%r85, %r608, 1;
	setp.eq.s32 	%p5, %r85, 0;
	mul.rn.f32 	%f35, %f328, %f328;
	cvt.rn.f32.f64 	%f169, %fd115;
	cvt.f64.f32 	%fd417, %f169;
	mul.rn.f64 	%fd418, %fd417, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f170, %fd418;
	cvt.f64.f32 	%fd419, %f170;
	add.rn.f64 	%fd138, %fd137, %fd419;
	mov.f32 	%f329, 0fB94D4153;
	@%p5 bra 	$L__BB4_127;

	mov.f32 	%f171, 0fBAB607ED;
	mov.f32 	%f172, 0f37CBAC00;
	fma.rn.f32 	%f329, %f172, %f35, %f171;

$L__BB4_127:
	selp.f32 	%f173, %f328, 0f3F800000, %p5;
	selp.f32 	%f174, 0f3C0885E4, 0f3D2AAABB, %p5;
	fma.rn.f32 	%f175, %f329, %f35, %f174;
	selp.f32 	%f176, 0fBE2AAAA8, 0fBEFFFFFF, %p5;
	fma.rn.f32 	%f177, %f175, %f35, %f176;
	mov.f32 	%f178, 0f00000000;
	fma.rn.f32 	%f179, %f35, %f173, %f178;
	fma.rn.f32 	%f330, %f177, %f179, %f173;
	and.b32  	%r380, %r608, 2;
	setp.eq.s32 	%p130, %r380, 0;
	@%p130 bra 	$L__BB4_129;

	mov.f32 	%f181, 0fBF800000;
	fma.rn.f32 	%f330, %f330, %f181, %f178;

$L__BB4_129:
	@%p122 bra 	$L__BB4_137;

	setp.eq.f32 	%p132, %f31, 0f7F800000;
	@%p132 bra 	$L__BB4_136;
	bra.uni 	$L__BB4_131;

$L__BB4_136:
	mov.f32 	%f184, 0f00000000;
	mul.rn.f32 	%f331, %f29, %f184;
	mov.u32 	%r612, 0;
	bra.uni 	$L__BB4_137;

$L__BB4_131:
	mov.b32 	%r86, %f29;
	bfe.u32 	%r382, %r86, 23, 8;
	add.s32 	%r87, %r382, -128;
	shl.b32 	%r383, %r86, 8;
	or.b32  	%r88, %r383, -2147483648;
	shr.u32 	%r89, %r87, 5;
	mov.u64 	%rd229, 0;
	mov.u32 	%r609, 0;
	mov.u64 	%rd228, __cudart_i2opi_f;
	mov.u64 	%rd227, %rd1;

$L__BB4_132:
	.pragma "nounroll";
	ld.global.nc.u32 	%r384, [%rd228];
	mad.wide.u32 	%rd144, %r384, %r88, %rd229;
	shr.u64 	%rd229, %rd144, 32;
	st.local.u32 	[%rd227], %rd144;
	add.s64 	%rd228, %rd228, 4;
	add.s64 	%rd227, %rd227, 4;
	add.s32 	%r609, %r609, 1;
	setp.ne.s32 	%p133, %r609, 6;
	@%p133 bra 	$L__BB4_132;

	add.s64 	%rd213, %rd1, 24;
	st.local.u32 	[%rd213], %rd229;
	mov.u32 	%r385, 4;
	sub.s32 	%r92, %r385, %r89;
	mov.u32 	%r386, 6;
	sub.s32 	%r387, %r386, %r89;
	mul.wide.s32 	%rd145, %r387, 4;
	add.s64 	%rd146, %rd1, %rd145;
	ld.local.u32 	%r610, [%rd146];
	ld.local.u32 	%r611, [%rd146+-4];
	and.b32  	%r95, %r87, 31;
	setp.eq.s32 	%p134, %r95, 0;
	@%p134 bra 	$L__BB4_135;

	mov.u32 	%r388, 32;
	sub.s32 	%r389, %r388, %r95;
	shr.u32 	%r390, %r611, %r389;
	shl.b32 	%r391, %r610, %r95;
	add.s32 	%r610, %r390, %r391;
	mul.wide.s32 	%rd147, %r92, 4;
	add.s64 	%rd148, %rd1, %rd147;
	ld.local.u32 	%r392, [%rd148];
	shr.u32 	%r393, %r392, %r389;
	shl.b32 	%r394, %r611, %r95;
	add.s32 	%r611, %r393, %r394;

$L__BB4_135:
	and.b32  	%r395, %r86, -2147483648;
	shr.u32 	%r396, %r611, 30;
	shl.b32 	%r397, %r610, 2;
	or.b32  	%r398, %r396, %r397;
	shr.u32 	%r399, %r398, 31;
	shr.u32 	%r400, %r610, 30;
	add.s32 	%r401, %r399, %r400;
	neg.s32 	%r402, %r401;
	setp.eq.s32 	%p135, %r395, 0;
	selp.b32 	%r612, %r401, %r402, %p135;
	setp.ne.s32 	%p136, %r399, 0;
	xor.b32  	%r403, %r395, -2147483648;
	selp.b32 	%r404, %r403, %r395, %p136;
	selp.b32 	%r405, -1, 0, %p136;
	xor.b32  	%r406, %r398, %r405;
	shl.b32 	%r407, %r611, 2;
	xor.b32  	%r408, %r407, %r405;
	cvt.u64.u32 	%rd149, %r406;
	cvt.u64.u32 	%rd150, %r408;
	bfi.b64 	%rd151, %rd149, %rd150, 32, 32;
	cvt.rn.f64.s64 	%fd420, %rd151;
	mul.rn.f64 	%fd421, %fd420, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f182, %fd421;
	setp.eq.s32 	%p137, %r404, 0;
	neg.f32 	%f183, %f182;
	selp.f32 	%f331, %f182, %f183, %p137;

$L__BB4_137:
	add.s32 	%r102, %r612, 1;
	and.b32  	%r103, %r102, 1;
	setp.eq.s32 	%p6, %r103, 0;
	mul.rn.f32 	%f44, %f331, %f331;
	mov.f32 	%f332, 0fB94D4153;
	@%p6 bra 	$L__BB4_139;

	mov.f32 	%f186, 0fBAB607ED;
	mov.f32 	%f187, 0f37CBAC00;
	fma.rn.f32 	%f332, %f187, %f44, %f186;

$L__BB4_139:
	selp.f32 	%f188, %f331, 0f3F800000, %p6;
	selp.f32 	%f189, 0f3C0885E4, 0f3D2AAABB, %p6;
	fma.rn.f32 	%f190, %f332, %f44, %f189;
	selp.f32 	%f191, 0fBE2AAAA8, 0fBEFFFFFF, %p6;
	fma.rn.f32 	%f192, %f190, %f44, %f191;
	mov.f32 	%f193, 0f00000000;
	fma.rn.f32 	%f194, %f44, %f188, %f193;
	fma.rn.f32 	%f333, %f192, %f194, %f188;
	and.b32  	%r410, %r102, 2;
	setp.eq.s32 	%p139, %r410, 0;
	@%p139 bra 	$L__BB4_141;

	mov.f32 	%f196, 0fBF800000;
	fma.rn.f32 	%f333, %f333, %f196, %f193;

$L__BB4_141:
	ld.param.u64 	%rd206, [wgs84_to_bd09_cuda_float_param_4];
	ld.param.u64 	%rd205, [wgs84_to_bd09_cuda_float_param_3];
	cvta.to.global.u64 	%rd152, %rd205;
	shl.b64 	%rd153, %rd10, 2;
	add.s64 	%rd36, %rd152, %rd153;
	cvta.to.global.u64 	%rd154, %rd206;
	add.s64 	%rd37, %rd154, %rd153;
	cvt.f64.f32 	%fd422, %f330;
	mul.rn.f64 	%fd423, %fd422, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd424, %fd423, %fd422;
	add.rn.f64 	%fd425, %fd424, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f197, %fd425;
	sqrt.rn.f32 	%f198, %f197;
	mov.f32 	%f199, 0f4AC2A60A;
	div.rn.f32 	%f200, %f199, %f198;
	mul.rn.f32 	%f201, %f200, %f333;
	cvt.f64.f32 	%fd426, %f201;
	mul.rn.f64 	%fd427, %fd426, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f202, %fd138;
	cvt.f64.f32 	%fd428, %f202;
	mul.rn.f64 	%fd429, %fd428, 0d4066800000000000;
	div.rn.f64 	%fd430, %fd429, %fd427;
	cvt.rn.f32.f64 	%f203, %fd430;
	add.rn.f32 	%f204, %f1, %f203;
	st.global.f32 	[%rd36], %f204;
	mul.rn.f32 	%f205, %f198, %f197;
	cvt.f64.f32 	%fd431, %f205;
	mov.f64 	%fd432, 0d41582B102DE355C1;
	div.rn.f64 	%fd433, %fd432, %fd431;
	mul.rn.f64 	%fd434, %fd433, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f206, %fd130;
	cvt.f64.f32 	%fd435, %f206;
	mul.rn.f64 	%fd436, %fd435, 0d4066800000000000;
	div.rn.f64 	%fd437, %fd436, %fd434;
	cvt.rn.f32.f64 	%f207, %fd437;
	add.rn.f32 	%f50, %f3, %f207;
	st.global.f32 	[%rd37], %f50;
	ld.global.f32 	%f51, [%rd36];
	cvt.f64.f32 	%fd139, %f51;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r104}, %fd139;
	}
	abs.f64 	%fd140, %fd139;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd140;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd504, [retval0+0];
	} // callseq 34
	setp.lt.s32 	%p140, %r104, 0;
	and.pred  	%p7, %p140, %p76;
	not.pred 	%p142, %p7;
	@%p142 bra 	$L__BB4_143;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r411}, %fd504;
	}
	xor.b32  	%r412, %r411, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r413, %temp}, %fd504;
	}
	mov.b64 	%fd504, {%r413, %r412};

$L__BB4_143:
	setp.eq.f32 	%p143, %f51, 0f00000000;
	@%p143 bra 	$L__BB4_147;
	bra.uni 	$L__BB4_144;

$L__BB4_147:
	selp.b32 	%r414, %r104, 0, %p76;
	mov.u32 	%r415, 0;
	or.b32  	%r416, %r414, 2146435072;
	setp.lt.s32 	%p147, %r62, 0;
	selp.b32 	%r417, %r416, %r414, %p147;
	mov.b64 	%fd504, {%r415, %r417};
	bra.uni 	$L__BB4_148;

$L__BB4_144:
	setp.gt.s32 	%p144, %r104, -1;
	@%p144 bra 	$L__BB4_148;

	mov.f64 	%fd438, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd439, %fd438;
	setp.eq.f64 	%p145, %fd439, 0d4000000000000000;
	@%p145 bra 	$L__BB4_148;

	mov.f64 	%fd504, 0dFFF8000000000000;

$L__BB4_148:
	add.rn.f64 	%fd441, %fd139, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r418}, %fd441;
	}
	and.b32  	%r419, %r418, 2146435072;
	setp.ne.s32 	%p148, %r419, 2146435072;
	@%p148 bra 	$L__BB4_155;

	setp.gtu.f64 	%p149, %fd140, 0d7FF0000000000000;
	@%p149 bra 	$L__BB4_154;
	bra.uni 	$L__BB4_150;

$L__BB4_154:
	mov.f64 	%fd443, 0d4000000000000000;
	add.rn.f64 	%fd504, %fd139, %fd443;
	bra.uni 	$L__BB4_155;

$L__BB4_150:
	mov.f64 	%fd442, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r420, %temp}, %fd442;
	}
	and.b32  	%r105, %r62, 2147483647;
	setp.eq.s32 	%p150, %r105, 2146435072;
	setp.eq.s32 	%p151, %r420, 0;
	and.pred  	%p152, %p150, %p151;
	@%p152 bra 	$L__BB4_153;
	bra.uni 	$L__BB4_151;

$L__BB4_153:
	setp.gt.f64 	%p159, %fd140, 0d3FF0000000000000;
	selp.b32 	%r427, 2146435072, 0, %p159;
	mov.u32 	%r428, 0;
	xor.b32  	%r429, %r427, 2146435072;
	setp.lt.s32 	%p160, %r62, 0;
	selp.b32 	%r430, %r429, %r427, %p160;
	setp.eq.f32 	%p161, %f51, 0fBF800000;
	selp.b32 	%r431, 1072693248, %r430, %p161;
	mov.b64 	%fd504, {%r428, %r431};
	bra.uni 	$L__BB4_155;

$L__BB4_151:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r421, %temp}, %fd139;
	}
	and.b32  	%r422, %r104, 2147483647;
	setp.ne.s32 	%p153, %r422, 2146435072;
	setp.ne.s32 	%p154, %r421, 0;
	or.pred  	%p155, %p153, %p154;
	@%p155 bra 	$L__BB4_155;

	setp.gt.s32 	%p156, %r62, -1;
	selp.b32 	%r423, 2146435072, 0, %p156;
	mov.u32 	%r424, 0;
	setp.ne.s32 	%p157, %r105, 1071644672;
	and.pred  	%p158, %p157, %p7;
	or.b32  	%r425, %r423, -2147483648;
	selp.b32 	%r426, %r425, %r423, %p158;
	mov.b64 	%fd504, {%r424, %r426};

$L__BB4_155:
	cvt.f64.f32 	%fd150, %f50;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd150;
	}
	abs.f64 	%fd151, %fd150;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd151;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd507, [retval0+0];
	} // callseq 35
	setp.lt.s32 	%p162, %r106, 0;
	and.pred  	%p8, %p162, %p76;
	not.pred 	%p164, %p8;
	@%p164 bra 	$L__BB4_157;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r432}, %fd507;
	}
	xor.b32  	%r433, %r432, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r434, %temp}, %fd507;
	}
	mov.b64 	%fd507, {%r434, %r433};

$L__BB4_157:
	setp.eq.f32 	%p165, %f50, 0f00000000;
	@%p165 bra 	$L__BB4_161;
	bra.uni 	$L__BB4_158;

$L__BB4_161:
	selp.b32 	%r435, %r106, 0, %p76;
	mov.u32 	%r436, 0;
	or.b32  	%r437, %r435, 2146435072;
	setp.lt.s32 	%p169, %r62, 0;
	selp.b32 	%r438, %r437, %r435, %p169;
	mov.b64 	%fd507, {%r436, %r438};
	bra.uni 	$L__BB4_162;

$L__BB4_158:
	setp.gt.s32 	%p166, %r106, -1;
	@%p166 bra 	$L__BB4_162;

	mov.f64 	%fd444, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd445, %fd444;
	setp.eq.f64 	%p167, %fd445, 0d4000000000000000;
	@%p167 bra 	$L__BB4_162;

	mov.f64 	%fd507, 0dFFF8000000000000;

$L__BB4_162:
	add.rn.f64 	%fd447, %fd150, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r439}, %fd447;
	}
	and.b32  	%r440, %r439, 2146435072;
	setp.ne.s32 	%p170, %r440, 2146435072;
	@%p170 bra 	$L__BB4_169;

	setp.gtu.f64 	%p171, %fd151, 0d7FF0000000000000;
	@%p171 bra 	$L__BB4_168;
	bra.uni 	$L__BB4_164;

$L__BB4_168:
	mov.f64 	%fd449, 0d4000000000000000;
	add.rn.f64 	%fd507, %fd150, %fd449;
	bra.uni 	$L__BB4_169;

$L__BB4_164:
	mov.f64 	%fd448, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd448;
	}
	and.b32  	%r107, %r62, 2147483647;
	setp.eq.s32 	%p172, %r107, 2146435072;
	setp.eq.s32 	%p173, %r441, 0;
	and.pred  	%p174, %p172, %p173;
	@%p174 bra 	$L__BB4_167;
	bra.uni 	$L__BB4_165;

$L__BB4_167:
	setp.gt.f64 	%p181, %fd151, 0d3FF0000000000000;
	selp.b32 	%r448, 2146435072, 0, %p181;
	mov.u32 	%r449, 0;
	xor.b32  	%r450, %r448, 2146435072;
	setp.lt.s32 	%p182, %r62, 0;
	selp.b32 	%r451, %r450, %r448, %p182;
	setp.eq.f32 	%p183, %f50, 0fBF800000;
	selp.b32 	%r452, 1072693248, %r451, %p183;
	mov.b64 	%fd507, {%r449, %r452};
	bra.uni 	$L__BB4_169;

$L__BB4_165:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r442, %temp}, %fd150;
	}
	and.b32  	%r443, %r106, 2147483647;
	setp.ne.s32 	%p175, %r443, 2146435072;
	setp.ne.s32 	%p176, %r442, 0;
	or.pred  	%p177, %p175, %p176;
	@%p177 bra 	$L__BB4_169;

	setp.gt.s32 	%p178, %r62, -1;
	selp.b32 	%r444, 2146435072, 0, %p178;
	mov.u32 	%r445, 0;
	setp.ne.s32 	%p179, %r107, 1071644672;
	and.pred  	%p180, %p179, %p8;
	or.b32  	%r446, %r444, -2147483648;
	selp.b32 	%r447, %r446, %r444, %p180;
	mov.b64 	%fd507, {%r445, %r447};

$L__BB4_169:
	setp.eq.f32 	%p184, %f50, 0f3F800000;
	selp.f64 	%fd450, 0d3FF0000000000000, %fd507, %p184;
	setp.eq.f32 	%p185, %f51, 0f3F800000;
	selp.f64 	%fd451, 0d3FF0000000000000, %fd504, %p185;
	add.rn.f64 	%fd161, %fd451, %fd450;
	mul.rn.f32 	%f52, %f50, 0f42517084;
	mul.rn.f32 	%f208, %f52, 0f3F22F983;
	cvt.rni.s32.f32 	%r616, %f208;
	cvt.rn.f32.s32 	%f209, %r616;
	mov.f32 	%f210, 0fBFC90FDA;
	fma.rn.f32 	%f211, %f209, %f210, %f52;
	mov.f32 	%f212, 0fB3A22168;
	fma.rn.f32 	%f213, %f209, %f212, %f211;
	mov.f32 	%f214, 0fA7C234C5;
	fma.rn.f32 	%f334, %f209, %f214, %f213;
	abs.f32 	%f54, %f52;
	setp.ltu.f32 	%p186, %f54, 0f47CE4780;
	@%p186 bra 	$L__BB4_177;

	setp.eq.f32 	%p187, %f54, 0f7F800000;
	@%p187 bra 	$L__BB4_176;
	bra.uni 	$L__BB4_171;

$L__BB4_176:
	mov.f32 	%f217, 0f00000000;
	mul.rn.f32 	%f334, %f52, %f217;
	mov.u32 	%r616, 0;
	bra.uni 	$L__BB4_177;

$L__BB4_171:
	mov.b32 	%r109, %f52;
	bfe.u32 	%r454, %r109, 23, 8;
	add.s32 	%r110, %r454, -128;
	shl.b32 	%r455, %r109, 8;
	or.b32  	%r111, %r455, -2147483648;
	shr.u32 	%r112, %r110, 5;
	mov.u64 	%rd232, 0;
	mov.u32 	%r613, 0;
	mov.u64 	%rd231, __cudart_i2opi_f;
	mov.u64 	%rd230, %rd1;

$L__BB4_172:
	.pragma "nounroll";
	ld.global.nc.u32 	%r456, [%rd231];
	mad.wide.u32 	%rd157, %r456, %r111, %rd232;
	shr.u64 	%rd232, %rd157, 32;
	st.local.u32 	[%rd230], %rd157;
	add.s64 	%rd231, %rd231, 4;
	add.s64 	%rd230, %rd230, 4;
	add.s32 	%r613, %r613, 1;
	setp.ne.s32 	%p188, %r613, 6;
	@%p188 bra 	$L__BB4_172;

	add.s64 	%rd214, %rd1, 24;
	st.local.u32 	[%rd214], %rd232;
	mov.u32 	%r457, 4;
	sub.s32 	%r115, %r457, %r112;
	mov.u32 	%r458, 6;
	sub.s32 	%r459, %r458, %r112;
	mul.wide.s32 	%rd158, %r459, 4;
	add.s64 	%rd159, %rd1, %rd158;
	ld.local.u32 	%r614, [%rd159];
	ld.local.u32 	%r615, [%rd159+-4];
	and.b32  	%r118, %r110, 31;
	setp.eq.s32 	%p189, %r118, 0;
	@%p189 bra 	$L__BB4_175;

	mov.u32 	%r460, 32;
	sub.s32 	%r461, %r460, %r118;
	shr.u32 	%r462, %r615, %r461;
	shl.b32 	%r463, %r614, %r118;
	add.s32 	%r614, %r462, %r463;
	mul.wide.s32 	%rd160, %r115, 4;
	add.s64 	%rd161, %rd1, %rd160;
	ld.local.u32 	%r464, [%rd161];
	shr.u32 	%r465, %r464, %r461;
	shl.b32 	%r466, %r615, %r118;
	add.s32 	%r615, %r465, %r466;

$L__BB4_175:
	and.b32  	%r467, %r109, -2147483648;
	shr.u32 	%r468, %r615, 30;
	shl.b32 	%r469, %r614, 2;
	or.b32  	%r470, %r468, %r469;
	shr.u32 	%r471, %r470, 31;
	shr.u32 	%r472, %r614, 30;
	add.s32 	%r473, %r471, %r472;
	neg.s32 	%r474, %r473;
	setp.eq.s32 	%p190, %r467, 0;
	selp.b32 	%r616, %r473, %r474, %p190;
	setp.ne.s32 	%p191, %r471, 0;
	xor.b32  	%r475, %r467, -2147483648;
	selp.b32 	%r476, %r475, %r467, %p191;
	selp.b32 	%r477, -1, 0, %p191;
	xor.b32  	%r478, %r470, %r477;
	shl.b32 	%r479, %r615, 2;
	xor.b32  	%r480, %r479, %r477;
	cvt.u64.u32 	%rd162, %r478;
	cvt.u64.u32 	%rd163, %r480;
	bfi.b64 	%rd164, %rd162, %rd163, 32, 32;
	cvt.rn.f64.s64 	%fd452, %rd164;
	mul.rn.f64 	%fd453, %fd452, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f215, %fd453;
	setp.eq.s32 	%p192, %r476, 0;
	neg.f32 	%f216, %f215;
	selp.f32 	%f334, %f215, %f216, %p192;

$L__BB4_177:
	and.b32  	%r125, %r616, 1;
	setp.eq.s32 	%p193, %r125, 0;
	selp.f32 	%f58, %f334, 0f3F800000, %p193;
	mul.rn.f32 	%f59, %f334, %f334;
	mov.f32 	%f335, 0fB94D4153;
	@%p193 bra 	$L__BB4_179;

	mov.f32 	%f219, 0fBAB607ED;
	mov.f32 	%f220, 0f37CBAC00;
	fma.rn.f32 	%f335, %f220, %f59, %f219;

$L__BB4_179:
	selp.f32 	%f221, 0f3C0885E4, 0f3D2AAABB, %p193;
	fma.rn.f32 	%f222, %f335, %f59, %f221;
	selp.f32 	%f223, 0fBE2AAAA8, 0fBEFFFFFF, %p193;
	fma.rn.f32 	%f224, %f222, %f59, %f223;
	mov.f32 	%f225, 0f00000000;
	fma.rn.f32 	%f226, %f59, %f58, %f225;
	fma.rn.f32 	%f336, %f224, %f226, %f58;
	and.b32  	%r482, %r616, 2;
	setp.eq.s32 	%p195, %r482, 0;
	@%p195 bra 	$L__BB4_181;

	mov.f32 	%f228, 0fBF800000;
	fma.rn.f32 	%f336, %f336, %f228, %f225;

$L__BB4_181:
	cvt.f64.f32 	%fd454, %f336;
	mul.rn.f64 	%fd455, %fd454, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd456, %fd161;
	add.rn.f64 	%fd457, %fd456, %fd455;
	cvt.rn.f32.f64 	%f65, %fd457;
	abs.f32 	%f66, %f51;
	setp.eq.f32 	%p196, %f66, 0f00000000;
	abs.f32 	%f67, %f50;
	setp.eq.f32 	%p197, %f67, 0f00000000;
	and.pred  	%p198, %p196, %p197;
	@%p198 bra 	$L__BB4_185;
	bra.uni 	$L__BB4_182;

$L__BB4_185:
	mov.b32 	%r493, %f51;
	shr.s32 	%r494, %r493, 31;
	and.b32  	%r495, %r494, 1078530011;
	mov.b32 	%r496, %f50;
	and.b32  	%r497, %r496, -2147483648;
	or.b32  	%r498, %r495, %r497;
	mov.b32 	%f337, %r498;
	bra.uni 	$L__BB4_186;

$L__BB4_182:
	setp.eq.f32 	%p199, %f66, 0f7F800000;
	setp.eq.f32 	%p200, %f67, 0f7F800000;
	and.pred  	%p201, %p199, %p200;
	@%p201 bra 	$L__BB4_184;
	bra.uni 	$L__BB4_183;

$L__BB4_184:
	mov.b32 	%r488, %f51;
	setp.lt.s32 	%p205, %r488, 0;
	selp.b32 	%r489, 1075235812, 1061752795, %p205;
	mov.b32 	%r490, %f50;
	and.b32  	%r491, %r490, -2147483648;
	or.b32  	%r492, %r489, %r491;
	mov.b32 	%f337, %r492;
	bra.uni 	$L__BB4_186;

$L__BB4_183:
	max.f32 	%f229, %f67, %f66;
	min.f32 	%f230, %f67, %f66;
	div.rn.f32 	%f231, %f230, %f229;
	mul.rn.f32 	%f232, %f231, %f231;
	mov.f32 	%f233, 0fC0B59883;
	mov.f32 	%f234, 0fBF52C7EA;
	fma.rn.f32 	%f235, %f232, %f234, %f233;
	mov.f32 	%f236, 0fC0D21907;
	fma.rn.f32 	%f237, %f235, %f232, %f236;
	mul.rn.f32 	%f238, %f232, %f237;
	mul.rn.f32 	%f239, %f231, %f238;
	add.rn.f32 	%f240, %f232, 0f41355DC0;
	mov.f32 	%f241, 0f41E6BD60;
	fma.rn.f32 	%f242, %f240, %f232, %f241;
	mov.f32 	%f243, 0f419D92C8;
	fma.rn.f32 	%f244, %f242, %f232, %f243;
	rcp.rn.f32 	%f245, %f244;
	fma.rn.f32 	%f246, %f239, %f245, %f231;
	mov.f32 	%f247, 0f3FC90FDB;
	sub.rn.f32 	%f248, %f247, %f246;
	setp.gt.f32 	%p202, %f67, %f66;
	selp.f32 	%f249, %f248, %f246, %p202;
	mov.b32 	%r483, %f51;
	setp.lt.s32 	%p203, %r483, 0;
	mov.f32 	%f250, 0f40490FDB;
	sub.rn.f32 	%f251, %f250, %f249;
	selp.f32 	%f252, %f251, %f249, %p203;
	mov.b32 	%r484, %f252;
	mov.b32 	%r485, %f50;
	and.b32  	%r486, %r485, -2147483648;
	or.b32  	%r487, %r486, %r484;
	mov.b32 	%f253, %r487;
	add.rn.f32 	%f254, %f66, %f67;
	setp.le.f32 	%p204, %f254, 0f7F800000;
	selp.f32 	%f337, %f253, %f254, %p204;

$L__BB4_186:
	mul.rn.f32 	%f72, %f51, 0f42517084;
	mul.rn.f32 	%f255, %f72, 0f3F22F983;
	cvt.rni.s32.f32 	%r620, %f255;
	cvt.rn.f32.s32 	%f256, %r620;
	mov.f32 	%f257, 0fBFC90FDA;
	fma.rn.f32 	%f258, %f256, %f257, %f72;
	mov.f32 	%f259, 0fB3A22168;
	fma.rn.f32 	%f260, %f256, %f259, %f258;
	mov.f32 	%f261, 0fA7C234C5;
	fma.rn.f32 	%f338, %f256, %f261, %f260;
	abs.f32 	%f74, %f72;
	setp.ltu.f32 	%p206, %f74, 0f47CE4780;
	@%p206 bra 	$L__BB4_194;

	setp.eq.f32 	%p207, %f74, 0f7F800000;
	@%p207 bra 	$L__BB4_193;
	bra.uni 	$L__BB4_188;

$L__BB4_193:
	mov.f32 	%f264, 0f00000000;
	mul.rn.f32 	%f338, %f72, %f264;
	mov.u32 	%r620, 0;
	bra.uni 	$L__BB4_194;

$L__BB4_188:
	mov.b32 	%r127, %f72;
	bfe.u32 	%r500, %r127, 23, 8;
	add.s32 	%r128, %r500, -128;
	shl.b32 	%r501, %r127, 8;
	or.b32  	%r129, %r501, -2147483648;
	shr.u32 	%r130, %r128, 5;
	mov.u64 	%rd235, 0;
	mov.u32 	%r617, 0;
	mov.u64 	%rd234, __cudart_i2opi_f;
	mov.u64 	%rd233, %rd1;

$L__BB4_189:
	.pragma "nounroll";
	ld.global.nc.u32 	%r502, [%rd234];
	mad.wide.u32 	%rd167, %r502, %r129, %rd235;
	shr.u64 	%rd235, %rd167, 32;
	st.local.u32 	[%rd233], %rd167;
	add.s64 	%rd234, %rd234, 4;
	add.s64 	%rd233, %rd233, 4;
	add.s32 	%r617, %r617, 1;
	setp.ne.s32 	%p208, %r617, 6;
	@%p208 bra 	$L__BB4_189;

	add.s64 	%rd215, %rd1, 24;
	st.local.u32 	[%rd215], %rd235;
	mov.u32 	%r503, 4;
	sub.s32 	%r133, %r503, %r130;
	mov.u32 	%r504, 6;
	sub.s32 	%r505, %r504, %r130;
	mul.wide.s32 	%rd168, %r505, 4;
	add.s64 	%rd169, %rd1, %rd168;
	ld.local.u32 	%r618, [%rd169];
	ld.local.u32 	%r619, [%rd169+-4];
	and.b32  	%r136, %r128, 31;
	setp.eq.s32 	%p209, %r136, 0;
	@%p209 bra 	$L__BB4_192;

	mov.u32 	%r506, 32;
	sub.s32 	%r507, %r506, %r136;
	shr.u32 	%r508, %r619, %r507;
	shl.b32 	%r509, %r618, %r136;
	add.s32 	%r618, %r508, %r509;
	mul.wide.s32 	%rd170, %r133, 4;
	add.s64 	%rd171, %rd1, %rd170;
	ld.local.u32 	%r510, [%rd171];
	shr.u32 	%r511, %r510, %r507;
	shl.b32 	%r512, %r619, %r136;
	add.s32 	%r619, %r511, %r512;

$L__BB4_192:
	and.b32  	%r513, %r127, -2147483648;
	shr.u32 	%r514, %r619, 30;
	shl.b32 	%r515, %r618, 2;
	or.b32  	%r516, %r514, %r515;
	shr.u32 	%r517, %r516, 31;
	shr.u32 	%r518, %r618, 30;
	add.s32 	%r519, %r517, %r518;
	neg.s32 	%r520, %r519;
	setp.eq.s32 	%p210, %r513, 0;
	selp.b32 	%r620, %r519, %r520, %p210;
	setp.ne.s32 	%p211, %r517, 0;
	xor.b32  	%r521, %r513, -2147483648;
	selp.b32 	%r522, %r521, %r513, %p211;
	selp.b32 	%r523, -1, 0, %p211;
	xor.b32  	%r524, %r516, %r523;
	shl.b32 	%r525, %r619, 2;
	xor.b32  	%r526, %r525, %r523;
	cvt.u64.u32 	%rd172, %r524;
	cvt.u64.u32 	%rd173, %r526;
	bfi.b64 	%rd174, %rd172, %rd173, 32, 32;
	cvt.rn.f64.s64 	%fd458, %rd174;
	mul.rn.f64 	%fd459, %fd458, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f262, %fd459;
	setp.eq.s32 	%p212, %r522, 0;
	neg.f32 	%f263, %f262;
	selp.f32 	%f338, %f262, %f263, %p212;

$L__BB4_194:
	add.s32 	%r143, %r620, 1;
	and.b32  	%r144, %r143, 1;
	setp.eq.s32 	%p213, %r144, 0;
	selp.f32 	%f78, %f338, 0f3F800000, %p213;
	mul.rn.f32 	%f79, %f338, %f338;
	mov.f32 	%f339, 0fB94D4153;
	@%p213 bra 	$L__BB4_196;

	mov.f32 	%f266, 0fBAB607ED;
	mov.f32 	%f267, 0f37CBAC00;
	fma.rn.f32 	%f339, %f267, %f79, %f266;

$L__BB4_196:
	selp.f32 	%f268, 0f3C0885E4, 0f3D2AAABB, %p213;
	fma.rn.f32 	%f269, %f339, %f79, %f268;
	selp.f32 	%f270, 0fBE2AAAA8, 0fBEFFFFFF, %p213;
	fma.rn.f32 	%f271, %f269, %f79, %f270;
	mov.f32 	%f272, 0f00000000;
	fma.rn.f32 	%f273, %f79, %f78, %f272;
	fma.rn.f32 	%f340, %f271, %f273, %f78;
	and.b32  	%r528, %r143, 2;
	setp.eq.s32 	%p215, %r528, 0;
	@%p215 bra 	$L__BB4_198;

	mov.f32 	%f275, 0fBF800000;
	fma.rn.f32 	%f340, %f340, %f275, %f272;

$L__BB4_198:
	cvt.f64.f32 	%fd460, %f340;
	mul.rn.f64 	%fd461, %fd460, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd462, %f337;
	add.rn.f64 	%fd463, %fd461, %fd462;
	cvt.rn.f32.f64 	%f85, %fd463;
	mul.rn.f32 	%f276, %f85, 0f3F22F983;
	cvt.rni.s32.f32 	%r628, %f276;
	cvt.rn.f32.s32 	%f277, %r628;
	mov.f32 	%f278, 0fBFC90FDA;
	fma.rn.f32 	%f279, %f277, %f278, %f85;
	mov.f32 	%f280, 0fB3A22168;
	fma.rn.f32 	%f281, %f277, %f280, %f279;
	mov.f32 	%f282, 0fA7C234C5;
	fma.rn.f32 	%f344, %f277, %f282, %f281;
	abs.f32 	%f87, %f85;
	setp.ltu.f32 	%p216, %f87, 0f47CE4780;
	mov.u32 	%r624, %r628;
	mov.f32 	%f341, %f344;
	@%p216 bra 	$L__BB4_206;

	setp.eq.f32 	%p217, %f87, 0f7F800000;
	@%p217 bra 	$L__BB4_205;
	bra.uni 	$L__BB4_200;

$L__BB4_205:
	mov.f32 	%f285, 0f00000000;
	mul.rn.f32 	%f341, %f85, %f285;
	mov.u32 	%r624, 0;
	bra.uni 	$L__BB4_206;

$L__BB4_200:
	mov.b32 	%r146, %f85;
	bfe.u32 	%r530, %r146, 23, 8;
	add.s32 	%r147, %r530, -128;
	shl.b32 	%r531, %r146, 8;
	or.b32  	%r148, %r531, -2147483648;
	shr.u32 	%r149, %r147, 5;
	mov.u64 	%rd238, 0;
	mov.u32 	%r621, 0;
	mov.u64 	%rd237, __cudart_i2opi_f;
	mov.u64 	%rd236, %rd1;

$L__BB4_201:
	.pragma "nounroll";
	ld.global.nc.u32 	%r532, [%rd237];
	mad.wide.u32 	%rd177, %r532, %r148, %rd238;
	shr.u64 	%rd238, %rd177, 32;
	st.local.u32 	[%rd236], %rd177;
	add.s64 	%rd237, %rd237, 4;
	add.s64 	%rd236, %rd236, 4;
	add.s32 	%r621, %r621, 1;
	setp.ne.s32 	%p218, %r621, 6;
	@%p218 bra 	$L__BB4_201;

	add.s64 	%rd216, %rd1, 24;
	st.local.u32 	[%rd216], %rd238;
	mov.u32 	%r533, 4;
	sub.s32 	%r152, %r533, %r149;
	mov.u32 	%r534, 6;
	sub.s32 	%r535, %r534, %r149;
	mul.wide.s32 	%rd178, %r535, 4;
	add.s64 	%rd179, %rd1, %rd178;
	ld.local.u32 	%r622, [%rd179];
	ld.local.u32 	%r623, [%rd179+-4];
	and.b32  	%r155, %r147, 31;
	setp.eq.s32 	%p219, %r155, 0;
	@%p219 bra 	$L__BB4_204;

	mov.u32 	%r536, 32;
	sub.s32 	%r537, %r536, %r155;
	shr.u32 	%r538, %r623, %r537;
	shl.b32 	%r539, %r622, %r155;
	add.s32 	%r622, %r538, %r539;
	mul.wide.s32 	%rd180, %r152, 4;
	add.s64 	%rd181, %rd1, %rd180;
	ld.local.u32 	%r540, [%rd181];
	shr.u32 	%r541, %r540, %r537;
	shl.b32 	%r542, %r623, %r155;
	add.s32 	%r623, %r541, %r542;

$L__BB4_204:
	and.b32  	%r543, %r146, -2147483648;
	shr.u32 	%r544, %r623, 30;
	shl.b32 	%r545, %r622, 2;
	or.b32  	%r546, %r544, %r545;
	shr.u32 	%r547, %r546, 31;
	shr.u32 	%r548, %r622, 30;
	add.s32 	%r549, %r547, %r548;
	neg.s32 	%r550, %r549;
	setp.eq.s32 	%p220, %r543, 0;
	selp.b32 	%r624, %r549, %r550, %p220;
	setp.ne.s32 	%p221, %r547, 0;
	xor.b32  	%r551, %r543, -2147483648;
	selp.b32 	%r552, %r551, %r543, %p221;
	selp.b32 	%r553, -1, 0, %p221;
	xor.b32  	%r554, %r546, %r553;
	shl.b32 	%r555, %r623, 2;
	xor.b32  	%r556, %r555, %r553;
	cvt.u64.u32 	%rd182, %r554;
	cvt.u64.u32 	%rd183, %r556;
	bfi.b64 	%rd184, %rd182, %rd183, 32, 32;
	cvt.rn.f64.s64 	%fd464, %rd184;
	mul.rn.f64 	%fd465, %fd464, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f283, %fd465;
	setp.eq.s32 	%p222, %r552, 0;
	neg.f32 	%f284, %f283;
	selp.f32 	%f341, %f283, %f284, %p222;

$L__BB4_206:
	add.s32 	%r162, %r624, 1;
	and.b32  	%r163, %r162, 1;
	setp.eq.s32 	%p223, %r163, 0;
	selp.f32 	%f91, %f341, 0f3F800000, %p223;
	mul.rn.f32 	%f92, %f341, %f341;
	mov.f32 	%f342, 0fB94D4153;
	@%p223 bra 	$L__BB4_208;

	mov.f32 	%f287, 0fBAB607ED;
	mov.f32 	%f288, 0f37CBAC00;
	fma.rn.f32 	%f342, %f288, %f92, %f287;

$L__BB4_208:
	selp.f32 	%f289, 0f3C0885E4, 0f3D2AAABB, %p223;
	fma.rn.f32 	%f290, %f342, %f92, %f289;
	selp.f32 	%f291, 0fBE2AAAA8, 0fBEFFFFFF, %p223;
	fma.rn.f32 	%f292, %f290, %f92, %f291;
	mov.f32 	%f293, 0f00000000;
	fma.rn.f32 	%f294, %f92, %f91, %f293;
	fma.rn.f32 	%f343, %f292, %f294, %f91;
	and.b32  	%r558, %r162, 2;
	setp.eq.s32 	%p225, %r558, 0;
	@%p225 bra 	$L__BB4_210;

	mov.f32 	%f296, 0fBF800000;
	fma.rn.f32 	%f343, %f343, %f296, %f293;

$L__BB4_210:
	mul.rn.f32 	%f297, %f343, %f65;
	cvt.f64.f32 	%fd466, %f297;
	add.rn.f64 	%fd467, %fd466, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f298, %fd467;
	st.global.f32 	[%rd36], %f298;
	@%p216 bra 	$L__BB4_218;

	setp.eq.f32 	%p227, %f87, 0f7F800000;
	@%p227 bra 	$L__BB4_217;
	bra.uni 	$L__BB4_212;

$L__BB4_217:
	mov.f32 	%f301, 0f00000000;
	mul.rn.f32 	%f344, %f85, %f301;
	mov.u32 	%r628, 0;
	bra.uni 	$L__BB4_218;

$L__BB4_212:
	mov.b32 	%r164, %f85;
	bfe.u32 	%r560, %r164, 23, 8;
	add.s32 	%r165, %r560, -128;
	shl.b32 	%r561, %r164, 8;
	or.b32  	%r166, %r561, -2147483648;
	shr.u32 	%r167, %r165, 5;
	mov.u64 	%rd241, 0;
	mov.u32 	%r625, 0;
	mov.u64 	%rd240, __cudart_i2opi_f;
	mov.u64 	%rd239, %rd1;

$L__BB4_213:
	.pragma "nounroll";
	ld.global.nc.u32 	%r562, [%rd240];
	mad.wide.u32 	%rd187, %r562, %r166, %rd241;
	shr.u64 	%rd241, %rd187, 32;
	st.local.u32 	[%rd239], %rd187;
	add.s64 	%rd240, %rd240, 4;
	add.s64 	%rd239, %rd239, 4;
	add.s32 	%r625, %r625, 1;
	setp.ne.s32 	%p228, %r625, 6;
	@%p228 bra 	$L__BB4_213;

	add.s64 	%rd217, %rd1, 24;
	st.local.u32 	[%rd217], %rd241;
	mov.u32 	%r563, 4;
	sub.s32 	%r170, %r563, %r167;
	mov.u32 	%r564, 6;
	sub.s32 	%r565, %r564, %r167;
	mul.wide.s32 	%rd188, %r565, 4;
	add.s64 	%rd189, %rd1, %rd188;
	ld.local.u32 	%r626, [%rd189];
	ld.local.u32 	%r627, [%rd189+-4];
	and.b32  	%r173, %r165, 31;
	setp.eq.s32 	%p229, %r173, 0;
	@%p229 bra 	$L__BB4_216;

	mov.u32 	%r566, 32;
	sub.s32 	%r567, %r566, %r173;
	shr.u32 	%r568, %r627, %r567;
	shl.b32 	%r569, %r626, %r173;
	add.s32 	%r626, %r568, %r569;
	mul.wide.s32 	%rd190, %r170, 4;
	add.s64 	%rd191, %rd1, %rd190;
	ld.local.u32 	%r570, [%rd191];
	shr.u32 	%r571, %r570, %r567;
	shl.b32 	%r572, %r627, %r173;
	add.s32 	%r627, %r571, %r572;

$L__BB4_216:
	and.b32  	%r573, %r164, -2147483648;
	shr.u32 	%r574, %r627, 30;
	shl.b32 	%r575, %r626, 2;
	or.b32  	%r576, %r574, %r575;
	shr.u32 	%r577, %r576, 31;
	shr.u32 	%r578, %r626, 30;
	add.s32 	%r579, %r577, %r578;
	neg.s32 	%r580, %r579;
	setp.eq.s32 	%p230, %r573, 0;
	selp.b32 	%r628, %r579, %r580, %p230;
	setp.ne.s32 	%p231, %r577, 0;
	xor.b32  	%r581, %r573, -2147483648;
	selp.b32 	%r582, %r581, %r573, %p231;
	selp.b32 	%r583, -1, 0, %p231;
	xor.b32  	%r584, %r576, %r583;
	shl.b32 	%r585, %r627, 2;
	xor.b32  	%r586, %r585, %r583;
	cvt.u64.u32 	%rd192, %r584;
	cvt.u64.u32 	%rd193, %r586;
	bfi.b64 	%rd194, %rd192, %rd193, 32, 32;
	cvt.rn.f64.s64 	%fd468, %rd194;
	mul.rn.f64 	%fd469, %fd468, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f299, %fd469;
	setp.eq.s32 	%p232, %r582, 0;
	neg.f32 	%f300, %f299;
	selp.f32 	%f344, %f299, %f300, %p232;

$L__BB4_218:
	and.b32  	%r180, %r628, 1;
	setp.eq.s32 	%p233, %r180, 0;
	selp.f32 	%f101, %f344, 0f3F800000, %p233;
	mul.rn.f32 	%f102, %f344, %f344;
	mov.f32 	%f345, 0fB94D4153;
	@%p233 bra 	$L__BB4_220;

	mov.f32 	%f303, 0fBAB607ED;
	mov.f32 	%f304, 0f37CBAC00;
	fma.rn.f32 	%f345, %f304, %f102, %f303;

$L__BB4_220:
	selp.f32 	%f305, 0f3C0885E4, 0f3D2AAABB, %p233;
	fma.rn.f32 	%f306, %f345, %f102, %f305;
	selp.f32 	%f307, 0fBE2AAAA8, 0fBEFFFFFF, %p233;
	fma.rn.f32 	%f308, %f306, %f102, %f307;
	mov.f32 	%f309, 0f00000000;
	fma.rn.f32 	%f310, %f102, %f101, %f309;
	fma.rn.f32 	%f346, %f308, %f310, %f101;
	and.b32  	%r588, %r628, 2;
	setp.eq.s32 	%p235, %r588, 0;
	@%p235 bra 	$L__BB4_222;

	mov.f32 	%f312, 0fBF800000;
	fma.rn.f32 	%f346, %f346, %f312, %f309;

$L__BB4_222:
	mul.rn.f32 	%f313, %f346, %f65;
	cvt.f64.f32 	%fd470, %f313;
	add.rn.f64 	%fd471, %fd470, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f314, %fd471;
	st.global.f32 	[%rd37], %f314;

$L__BB4_223:
	ret;

}
	// .globl	bd09_to_wgs84_cuda_float
.visible .entry bd09_to_wgs84_cuda_float(
	.param .u32 bd09_to_wgs84_cuda_float_param_0,
	.param .u64 bd09_to_wgs84_cuda_float_param_1,
	.param .u64 bd09_to_wgs84_cuda_float_param_2,
	.param .u64 bd09_to_wgs84_cuda_float_param_3,
	.param .u64 bd09_to_wgs84_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot5[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<236>;
	.reg .f32 	%f<344>;
	.reg .b32 	%r<629>;
	.reg .f64 	%fd<508>;
	.reg .b64 	%rd<237>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r181, [bd09_to_wgs84_cuda_float_param_0];
	ld.param.u64 	%rd62, [bd09_to_wgs84_cuda_float_param_1];
	ld.param.u64 	%rd63, [bd09_to_wgs84_cuda_float_param_2];
	ld.param.u64 	%rd64, [bd09_to_wgs84_cuda_float_param_3];
	ld.param.u64 	%rd65, [bd09_to_wgs84_cuda_float_param_4];
	add.u64 	%rd66, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r182, %ntid.x;
	mov.u32 	%r183, %ctaid.x;
	mov.u32 	%r184, %tid.x;
	mad.lo.s32 	%r1, %r183, %r182, %r184;
	setp.ge.s32 	%p9, %r1, %r181;
	@%p9 bra 	$L__BB5_223;

	cvta.to.global.u64 	%rd75, %rd62;
	cvt.s64.s32 	%rd10, %r1;
	mul.wide.s32 	%rd76, %r1, 4;
	add.s64 	%rd77, %rd75, %rd76;
	cvta.to.global.u64 	%rd78, %rd63;
	add.s64 	%rd79, %rd78, %rd76;
	ld.global.f32 	%f108, [%rd77];
	cvt.f64.f32 	%fd159, %f108;
	add.rn.f64 	%fd160, %fd159, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f1, %fd160;
	ld.global.f32 	%f109, [%rd79];
	cvt.f64.f32 	%fd161, %f109;
	add.rn.f64 	%fd162, %fd161, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f2, %fd162;
	cvt.f64.f32 	%fd1, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd163, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd163;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p10, %r4, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd474, [retval0+0];
	} // callseq 36
	setp.lt.s32 	%p11, %r2, 0;
	and.pred  	%p1, %p11, %p10;
	not.pred 	%p12, %p1;
	@%p12 bra 	$L__BB5_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r185}, %fd474;
	}
	xor.b32  	%r186, %r185, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r187, %temp}, %fd474;
	}
	mov.b64 	%fd474, {%r187, %r186};

$L__BB5_3:
	setp.eq.f32 	%p13, %f1, 0f00000000;
	@%p13 bra 	$L__BB5_7;
	bra.uni 	$L__BB5_4;

$L__BB5_7:
	selp.b32 	%r188, %r2, 0, %p10;
	mov.u32 	%r189, 0;
	or.b32  	%r190, %r188, 2146435072;
	setp.lt.s32 	%p17, %r3, 0;
	selp.b32 	%r191, %r190, %r188, %p17;
	mov.b64 	%fd474, {%r189, %r191};
	bra.uni 	$L__BB5_8;

$L__BB5_4:
	setp.gt.s32 	%p14, %r2, -1;
	@%p14 bra 	$L__BB5_8;

	mov.f64 	%fd164, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd165, %fd164;
	setp.eq.f64 	%p15, %fd165, 0d4000000000000000;
	@%p15 bra 	$L__BB5_8;

	mov.f64 	%fd474, 0dFFF8000000000000;

$L__BB5_8:
	add.rn.f64 	%fd167, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd167;
	}
	and.b32  	%r193, %r192, 2146435072;
	setp.ne.s32 	%p18, %r193, 2146435072;
	@%p18 bra 	$L__BB5_15;

	setp.gtu.f64 	%p19, %fd2, 0d7FF0000000000000;
	@%p19 bra 	$L__BB5_14;
	bra.uni 	$L__BB5_10;

$L__BB5_14:
	mov.f64 	%fd169, 0d4000000000000000;
	add.rn.f64 	%fd474, %fd1, %fd169;
	bra.uni 	$L__BB5_15;

$L__BB5_10:
	mov.f64 	%fd168, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r194, %temp}, %fd168;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p20, %r5, 2146435072;
	setp.eq.s32 	%p21, %r194, 0;
	and.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_11;

$L__BB5_13:
	setp.gt.f64 	%p29, %fd2, 0d3FF0000000000000;
	selp.b32 	%r201, 2146435072, 0, %p29;
	mov.u32 	%r202, 0;
	xor.b32  	%r203, %r201, 2146435072;
	setp.lt.s32 	%p30, %r3, 0;
	selp.b32 	%r204, %r203, %r201, %p30;
	setp.eq.f32 	%p31, %f1, 0fBF800000;
	selp.b32 	%r205, 1072693248, %r204, %p31;
	mov.b64 	%fd474, {%r202, %r205};
	bra.uni 	$L__BB5_15;

$L__BB5_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r195, %temp}, %fd1;
	}
	and.b32  	%r196, %r2, 2147483647;
	setp.ne.s32 	%p23, %r196, 2146435072;
	setp.ne.s32 	%p24, %r195, 0;
	or.pred  	%p25, %p23, %p24;
	@%p25 bra 	$L__BB5_15;

	setp.gt.s32 	%p26, %r3, -1;
	selp.b32 	%r197, 2146435072, 0, %p26;
	mov.u32 	%r198, 0;
	setp.ne.s32 	%p27, %r5, 1071644672;
	and.pred  	%p28, %p27, %p1;
	or.b32  	%r199, %r197, -2147483648;
	selp.b32 	%r200, %r199, %r197, %p28;
	mov.b64 	%fd474, {%r198, %r200};

$L__BB5_15:
	cvt.f64.f32 	%fd12, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd477, [retval0+0];
	} // callseq 37
	setp.lt.s32 	%p32, %r6, 0;
	and.pred  	%p2, %p32, %p10;
	not.pred 	%p34, %p2;
	@%p34 bra 	$L__BB5_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd477;
	}
	xor.b32  	%r207, %r206, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd477;
	}
	mov.b64 	%fd477, {%r208, %r207};

$L__BB5_17:
	setp.eq.f32 	%p35, %f2, 0f00000000;
	@%p35 bra 	$L__BB5_21;
	bra.uni 	$L__BB5_18;

$L__BB5_21:
	selp.b32 	%r209, %r6, 0, %p10;
	mov.u32 	%r210, 0;
	or.b32  	%r211, %r209, 2146435072;
	setp.lt.s32 	%p39, %r3, 0;
	selp.b32 	%r212, %r211, %r209, %p39;
	mov.b64 	%fd477, {%r210, %r212};
	bra.uni 	$L__BB5_22;

$L__BB5_18:
	setp.gt.s32 	%p36, %r6, -1;
	@%p36 bra 	$L__BB5_22;

	mov.f64 	%fd170, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd171, %fd170;
	setp.eq.f64 	%p37, %fd171, 0d4000000000000000;
	@%p37 bra 	$L__BB5_22;

	mov.f64 	%fd477, 0dFFF8000000000000;

$L__BB5_22:
	add.rn.f64 	%fd173, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r213}, %fd173;
	}
	and.b32  	%r214, %r213, 2146435072;
	setp.ne.s32 	%p40, %r214, 2146435072;
	@%p40 bra 	$L__BB5_29;

	setp.gtu.f64 	%p41, %fd13, 0d7FF0000000000000;
	@%p41 bra 	$L__BB5_28;
	bra.uni 	$L__BB5_24;

$L__BB5_28:
	mov.f64 	%fd175, 0d4000000000000000;
	add.rn.f64 	%fd477, %fd12, %fd175;
	bra.uni 	$L__BB5_29;

$L__BB5_24:
	mov.f64 	%fd174, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd174;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p42, %r7, 2146435072;
	setp.eq.s32 	%p43, %r215, 0;
	and.pred  	%p44, %p42, %p43;
	@%p44 bra 	$L__BB5_27;
	bra.uni 	$L__BB5_25;

$L__BB5_27:
	setp.gt.f64 	%p51, %fd13, 0d3FF0000000000000;
	selp.b32 	%r222, 2146435072, 0, %p51;
	mov.u32 	%r223, 0;
	xor.b32  	%r224, %r222, 2146435072;
	setp.lt.s32 	%p52, %r3, 0;
	selp.b32 	%r225, %r224, %r222, %p52;
	setp.eq.f32 	%p53, %f2, 0fBF800000;
	selp.b32 	%r226, 1072693248, %r225, %p53;
	mov.b64 	%fd477, {%r223, %r226};
	bra.uni 	$L__BB5_29;

$L__BB5_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd12;
	}
	and.b32  	%r217, %r6, 2147483647;
	setp.ne.s32 	%p45, %r217, 2146435072;
	setp.ne.s32 	%p46, %r216, 0;
	or.pred  	%p47, %p45, %p46;
	@%p47 bra 	$L__BB5_29;

	setp.gt.s32 	%p48, %r3, -1;
	selp.b32 	%r218, 2146435072, 0, %p48;
	mov.u32 	%r219, 0;
	setp.ne.s32 	%p49, %r7, 1071644672;
	and.pred  	%p50, %p49, %p2;
	or.b32  	%r220, %r218, -2147483648;
	selp.b32 	%r221, %r220, %r218, %p50;
	mov.b64 	%fd477, {%r219, %r221};

$L__BB5_29:
	mul.rn.f32 	%f3, %f2, 0f42517084;
	mul.rn.f32 	%f110, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r592, %f110;
	cvt.rn.f32.s32 	%f111, %r592;
	mov.f32 	%f112, 0fBFC90FDA;
	fma.rn.f32 	%f113, %f111, %f112, %f3;
	mov.f32 	%f114, 0fB3A22168;
	fma.rn.f32 	%f115, %f111, %f114, %f113;
	mov.f32 	%f116, 0fA7C234C5;
	fma.rn.f32 	%f319, %f111, %f116, %f115;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p54, %f5, 0f47CE4780;
	add.s64 	%rd11, %rd1, 24;
	@%p54 bra 	$L__BB5_37;

	setp.eq.f32 	%p55, %f5, 0f7F800000;
	@%p55 bra 	$L__BB5_36;
	bra.uni 	$L__BB5_31;

$L__BB5_36:
	mov.f32 	%f119, 0f00000000;
	mul.rn.f32 	%f319, %f3, %f119;
	mov.u32 	%r592, 0;
	bra.uni 	$L__BB5_37;

$L__BB5_31:
	mov.b32 	%r9, %f3;
	bfe.u32 	%r228, %r9, 23, 8;
	add.s32 	%r10, %r228, -128;
	shl.b32 	%r229, %r9, 8;
	or.b32  	%r11, %r229, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd215, 0;
	mov.u32 	%r589, 0;
	mov.u64 	%rd214, __cudart_i2opi_f;
	mov.u64 	%rd213, %rd1;

$L__BB5_32:
	.pragma "nounroll";
	ld.global.nc.u32 	%r230, [%rd214];
	mad.wide.u32 	%rd82, %r230, %r11, %rd215;
	shr.u64 	%rd215, %rd82, 32;
	st.local.u32 	[%rd213], %rd82;
	add.s64 	%rd214, %rd214, 4;
	add.s64 	%rd213, %rd213, 4;
	add.s32 	%r589, %r589, 1;
	setp.ne.s32 	%p56, %r589, 6;
	@%p56 bra 	$L__BB5_32;

	st.local.u32 	[%rd11], %rd215;
	mov.u32 	%r231, 4;
	sub.s32 	%r15, %r231, %r12;
	mov.u32 	%r232, 6;
	sub.s32 	%r233, %r232, %r12;
	mul.wide.s32 	%rd83, %r233, 4;
	add.s64 	%rd84, %rd1, %rd83;
	ld.local.u32 	%r590, [%rd84];
	ld.local.u32 	%r591, [%rd84+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p57, %r18, 0;
	@%p57 bra 	$L__BB5_35;

	mov.u32 	%r234, 32;
	sub.s32 	%r235, %r234, %r18;
	shr.u32 	%r236, %r591, %r235;
	shl.b32 	%r237, %r590, %r18;
	add.s32 	%r590, %r236, %r237;
	mul.wide.s32 	%rd85, %r15, 4;
	add.s64 	%rd86, %rd1, %rd85;
	ld.local.u32 	%r238, [%rd86];
	shr.u32 	%r239, %r238, %r235;
	shl.b32 	%r240, %r591, %r18;
	add.s32 	%r591, %r239, %r240;

$L__BB5_35:
	and.b32  	%r241, %r9, -2147483648;
	shr.u32 	%r242, %r591, 30;
	shl.b32 	%r243, %r590, 2;
	or.b32  	%r244, %r242, %r243;
	shr.u32 	%r245, %r244, 31;
	shr.u32 	%r246, %r590, 30;
	add.s32 	%r247, %r245, %r246;
	neg.s32 	%r248, %r247;
	setp.eq.s32 	%p58, %r241, 0;
	selp.b32 	%r592, %r247, %r248, %p58;
	setp.ne.s32 	%p59, %r245, 0;
	xor.b32  	%r249, %r241, -2147483648;
	selp.b32 	%r250, %r249, %r241, %p59;
	selp.b32 	%r251, -1, 0, %p59;
	xor.b32  	%r252, %r244, %r251;
	shl.b32 	%r253, %r591, 2;
	xor.b32  	%r254, %r253, %r251;
	cvt.u64.u32 	%rd87, %r252;
	cvt.u64.u32 	%rd88, %r254;
	bfi.b64 	%rd89, %rd87, %rd88, 32, 32;
	cvt.rn.f64.s64 	%fd176, %rd89;
	mul.rn.f64 	%fd177, %fd176, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f117, %fd177;
	setp.eq.s32 	%p60, %r250, 0;
	neg.f32 	%f118, %f117;
	selp.f32 	%f319, %f117, %f118, %p60;

$L__BB5_37:
	and.b32  	%r25, %r592, 1;
	setp.eq.s32 	%p3, %r25, 0;
	mul.rn.f32 	%f9, %f319, %f319;
	setp.eq.f32 	%p61, %f1, 0f3F800000;
	selp.f64 	%fd178, 0d3FF0000000000000, %fd474, %p61;
	setp.eq.f32 	%p62, %f2, 0f3F800000;
	selp.f64 	%fd179, 0d3FF0000000000000, %fd477, %p62;
	add.rn.f64 	%fd23, %fd178, %fd179;
	mov.f32 	%f320, 0fB94D4153;
	@%p3 bra 	$L__BB5_39;

	mov.f32 	%f121, 0fBAB607ED;
	mov.f32 	%f122, 0f37CBAC00;
	fma.rn.f32 	%f320, %f122, %f9, %f121;

$L__BB5_39:
	selp.f32 	%f123, %f319, 0f3F800000, %p3;
	selp.f32 	%f124, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f125, %f320, %f9, %f124;
	selp.f32 	%f126, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f127, %f125, %f9, %f126;
	mov.f32 	%f128, 0f00000000;
	fma.rn.f32 	%f129, %f9, %f123, %f128;
	fma.rn.f32 	%f321, %f127, %f129, %f123;
	and.b32  	%r256, %r592, 2;
	setp.eq.s32 	%p64, %r256, 0;
	@%p64 bra 	$L__BB5_41;

	mov.f32 	%f131, 0fBF800000;
	fma.rn.f32 	%f321, %f321, %f131, %f128;

$L__BB5_41:
	cvt.f64.f32 	%fd180, %f321;
	mul.rn.f64 	%fd181, %fd180, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd182, %fd23;
	add.rn.f64 	%fd183, %fd182, %fd181;
	cvt.rn.f32.f64 	%f15, %fd183;
	abs.f32 	%f16, %f1;
	setp.eq.f32 	%p65, %f16, 0f00000000;
	abs.f32 	%f17, %f2;
	setp.eq.f32 	%p66, %f17, 0f00000000;
	and.pred  	%p67, %p65, %p66;
	@%p67 bra 	$L__BB5_45;
	bra.uni 	$L__BB5_42;

$L__BB5_45:
	mov.b32 	%r267, %f1;
	shr.s32 	%r268, %r267, 31;
	and.b32  	%r269, %r268, 1078530011;
	mov.b32 	%r270, %f2;
	and.b32  	%r271, %r270, -2147483648;
	or.b32  	%r272, %r269, %r271;
	mov.b32 	%f322, %r272;
	bra.uni 	$L__BB5_46;

$L__BB5_42:
	setp.eq.f32 	%p68, %f16, 0f7F800000;
	setp.eq.f32 	%p69, %f17, 0f7F800000;
	and.pred  	%p70, %p68, %p69;
	@%p70 bra 	$L__BB5_44;
	bra.uni 	$L__BB5_43;

$L__BB5_44:
	mov.b32 	%r262, %f1;
	setp.lt.s32 	%p74, %r262, 0;
	selp.b32 	%r263, 1075235812, 1061752795, %p74;
	mov.b32 	%r264, %f2;
	and.b32  	%r265, %r264, -2147483648;
	or.b32  	%r266, %r263, %r265;
	mov.b32 	%f322, %r266;
	bra.uni 	$L__BB5_46;

$L__BB5_43:
	max.f32 	%f132, %f17, %f16;
	min.f32 	%f133, %f17, %f16;
	div.rn.f32 	%f134, %f133, %f132;
	mul.rn.f32 	%f135, %f134, %f134;
	mov.f32 	%f136, 0fC0B59883;
	mov.f32 	%f137, 0fBF52C7EA;
	fma.rn.f32 	%f138, %f135, %f137, %f136;
	mov.f32 	%f139, 0fC0D21907;
	fma.rn.f32 	%f140, %f138, %f135, %f139;
	mul.rn.f32 	%f141, %f135, %f140;
	mul.rn.f32 	%f142, %f134, %f141;
	add.rn.f32 	%f143, %f135, 0f41355DC0;
	mov.f32 	%f144, 0f41E6BD60;
	fma.rn.f32 	%f145, %f143, %f135, %f144;
	mov.f32 	%f146, 0f419D92C8;
	fma.rn.f32 	%f147, %f145, %f135, %f146;
	rcp.rn.f32 	%f148, %f147;
	fma.rn.f32 	%f149, %f142, %f148, %f134;
	mov.f32 	%f150, 0f3FC90FDB;
	sub.rn.f32 	%f151, %f150, %f149;
	setp.gt.f32 	%p71, %f17, %f16;
	selp.f32 	%f152, %f151, %f149, %p71;
	mov.b32 	%r257, %f1;
	setp.lt.s32 	%p72, %r257, 0;
	mov.f32 	%f153, 0f40490FDB;
	sub.rn.f32 	%f154, %f153, %f152;
	selp.f32 	%f155, %f154, %f152, %p72;
	mov.b32 	%r258, %f155;
	mov.b32 	%r259, %f2;
	and.b32  	%r260, %r259, -2147483648;
	or.b32  	%r261, %r260, %r258;
	mov.b32 	%f156, %r261;
	add.rn.f32 	%f157, %f16, %f17;
	setp.le.f32 	%p73, %f157, 0f7F800000;
	selp.f32 	%f322, %f156, %f157, %p73;

$L__BB5_46:
	mul.rn.f32 	%f22, %f1, 0f42517084;
	mul.rn.f32 	%f158, %f22, 0f3F22F983;
	cvt.rni.s32.f32 	%r596, %f158;
	cvt.rn.f32.s32 	%f159, %r596;
	mov.f32 	%f160, 0fBFC90FDA;
	fma.rn.f32 	%f161, %f159, %f160, %f22;
	mov.f32 	%f162, 0fB3A22168;
	fma.rn.f32 	%f163, %f159, %f162, %f161;
	mov.f32 	%f164, 0fA7C234C5;
	fma.rn.f32 	%f323, %f159, %f164, %f163;
	abs.f32 	%f24, %f22;
	setp.ltu.f32 	%p75, %f24, 0f47CE4780;
	@%p75 bra 	$L__BB5_54;

	setp.eq.f32 	%p76, %f24, 0f7F800000;
	@%p76 bra 	$L__BB5_53;
	bra.uni 	$L__BB5_48;

$L__BB5_53:
	mov.f32 	%f167, 0f00000000;
	mul.rn.f32 	%f323, %f22, %f167;
	mov.u32 	%r596, 0;
	bra.uni 	$L__BB5_54;

$L__BB5_48:
	mov.b32 	%r27, %f22;
	bfe.u32 	%r274, %r27, 23, 8;
	add.s32 	%r28, %r274, -128;
	shl.b32 	%r275, %r27, 8;
	or.b32  	%r29, %r275, -2147483648;
	shr.u32 	%r30, %r28, 5;
	mov.u64 	%rd218, 0;
	mov.u32 	%r593, 0;
	mov.u64 	%rd217, __cudart_i2opi_f;
	mov.u64 	%rd216, %rd1;

$L__BB5_49:
	.pragma "nounroll";
	ld.global.nc.u32 	%r276, [%rd217];
	mad.wide.u32 	%rd92, %r276, %r29, %rd218;
	shr.u64 	%rd218, %rd92, 32;
	st.local.u32 	[%rd216], %rd92;
	add.s64 	%rd217, %rd217, 4;
	add.s64 	%rd216, %rd216, 4;
	add.s32 	%r593, %r593, 1;
	setp.ne.s32 	%p77, %r593, 6;
	@%p77 bra 	$L__BB5_49;

	st.local.u32 	[%rd11], %rd218;
	mov.u32 	%r277, 4;
	sub.s32 	%r33, %r277, %r30;
	mov.u32 	%r278, 6;
	sub.s32 	%r279, %r278, %r30;
	mul.wide.s32 	%rd93, %r279, 4;
	add.s64 	%rd94, %rd1, %rd93;
	ld.local.u32 	%r594, [%rd94];
	ld.local.u32 	%r595, [%rd94+-4];
	and.b32  	%r36, %r28, 31;
	setp.eq.s32 	%p78, %r36, 0;
	@%p78 bra 	$L__BB5_52;

	mov.u32 	%r280, 32;
	sub.s32 	%r281, %r280, %r36;
	shr.u32 	%r282, %r595, %r281;
	shl.b32 	%r283, %r594, %r36;
	add.s32 	%r594, %r282, %r283;
	mul.wide.s32 	%rd95, %r33, 4;
	add.s64 	%rd96, %rd1, %rd95;
	ld.local.u32 	%r284, [%rd96];
	shr.u32 	%r285, %r284, %r281;
	shl.b32 	%r286, %r595, %r36;
	add.s32 	%r595, %r285, %r286;

$L__BB5_52:
	and.b32  	%r287, %r27, -2147483648;
	shr.u32 	%r288, %r595, 30;
	shl.b32 	%r289, %r594, 2;
	or.b32  	%r290, %r288, %r289;
	shr.u32 	%r291, %r290, 31;
	shr.u32 	%r292, %r594, 30;
	add.s32 	%r293, %r291, %r292;
	neg.s32 	%r294, %r293;
	setp.eq.s32 	%p79, %r287, 0;
	selp.b32 	%r596, %r293, %r294, %p79;
	setp.ne.s32 	%p80, %r291, 0;
	xor.b32  	%r295, %r287, -2147483648;
	selp.b32 	%r296, %r295, %r287, %p80;
	selp.b32 	%r297, -1, 0, %p80;
	xor.b32  	%r298, %r290, %r297;
	shl.b32 	%r299, %r595, 2;
	xor.b32  	%r300, %r299, %r297;
	cvt.u64.u32 	%rd97, %r298;
	cvt.u64.u32 	%rd98, %r300;
	bfi.b64 	%rd99, %rd97, %rd98, 32, 32;
	cvt.rn.f64.s64 	%fd184, %rd99;
	mul.rn.f64 	%fd185, %fd184, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f165, %fd185;
	setp.eq.s32 	%p81, %r296, 0;
	neg.f32 	%f166, %f165;
	selp.f32 	%f323, %f165, %f166, %p81;

$L__BB5_54:
	add.s32 	%r43, %r596, 1;
	and.b32  	%r44, %r43, 1;
	setp.eq.s32 	%p4, %r44, 0;
	mul.rn.f32 	%f28, %f323, %f323;
	mov.f32 	%f324, 0fB94D4153;
	@%p4 bra 	$L__BB5_56;

	mov.f32 	%f169, 0fBAB607ED;
	mov.f32 	%f170, 0f37CBAC00;
	fma.rn.f32 	%f324, %f170, %f28, %f169;

$L__BB5_56:
	selp.f32 	%f171, %f323, 0f3F800000, %p4;
	selp.f32 	%f172, 0f3C0885E4, 0f3D2AAABB, %p4;
	fma.rn.f32 	%f173, %f324, %f28, %f172;
	selp.f32 	%f174, 0fBE2AAAA8, 0fBEFFFFFF, %p4;
	fma.rn.f32 	%f175, %f173, %f28, %f174;
	mov.f32 	%f176, 0f00000000;
	fma.rn.f32 	%f177, %f28, %f171, %f176;
	fma.rn.f32 	%f325, %f175, %f177, %f171;
	and.b32  	%r302, %r43, 2;
	setp.eq.s32 	%p83, %r302, 0;
	@%p83 bra 	$L__BB5_58;

	mov.f32 	%f179, 0fBF800000;
	fma.rn.f32 	%f325, %f325, %f179, %f176;

$L__BB5_58:
	cvt.f64.f32 	%fd186, %f325;
	mul.rn.f64 	%fd187, %fd186, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd188, %f322;
	add.rn.f64 	%fd189, %fd188, %fd187;
	cvt.rn.f32.f64 	%f34, %fd189;
	mul.rn.f32 	%f180, %f34, 0f3F22F983;
	cvt.rni.s32.f32 	%r604, %f180;
	cvt.rn.f32.s32 	%f181, %r604;
	mov.f32 	%f182, 0fBFC90FDA;
	fma.rn.f32 	%f183, %f181, %f182, %f34;
	mov.f32 	%f184, 0fB3A22168;
	fma.rn.f32 	%f185, %f181, %f184, %f183;
	mov.f32 	%f186, 0fA7C234C5;
	fma.rn.f32 	%f329, %f181, %f186, %f185;
	abs.f32 	%f36, %f34;
	setp.ltu.f32 	%p84, %f36, 0f47CE4780;
	mov.u32 	%r600, %r604;
	mov.f32 	%f326, %f329;
	@%p84 bra 	$L__BB5_66;

	setp.eq.f32 	%p85, %f36, 0f7F800000;
	@%p85 bra 	$L__BB5_65;
	bra.uni 	$L__BB5_60;

$L__BB5_65:
	mov.f32 	%f189, 0f00000000;
	mul.rn.f32 	%f326, %f34, %f189;
	mov.u32 	%r600, 0;
	bra.uni 	$L__BB5_66;

$L__BB5_60:
	mov.b32 	%r46, %f34;
	bfe.u32 	%r304, %r46, 23, 8;
	add.s32 	%r47, %r304, -128;
	shl.b32 	%r305, %r46, 8;
	or.b32  	%r48, %r305, -2147483648;
	shr.u32 	%r49, %r47, 5;
	mov.u64 	%rd221, 0;
	mov.u32 	%r597, 0;
	mov.u64 	%rd220, __cudart_i2opi_f;
	mov.u64 	%rd219, %rd1;

$L__BB5_61:
	.pragma "nounroll";
	ld.global.nc.u32 	%r306, [%rd220];
	mad.wide.u32 	%rd102, %r306, %r48, %rd221;
	shr.u64 	%rd221, %rd102, 32;
	st.local.u32 	[%rd219], %rd102;
	add.s64 	%rd220, %rd220, 4;
	add.s64 	%rd219, %rd219, 4;
	add.s32 	%r597, %r597, 1;
	setp.ne.s32 	%p86, %r597, 6;
	@%p86 bra 	$L__BB5_61;

	st.local.u32 	[%rd11], %rd221;
	mov.u32 	%r307, 4;
	sub.s32 	%r52, %r307, %r49;
	mov.u32 	%r308, 6;
	sub.s32 	%r309, %r308, %r49;
	mul.wide.s32 	%rd103, %r309, 4;
	add.s64 	%rd104, %rd1, %rd103;
	ld.local.u32 	%r598, [%rd104];
	ld.local.u32 	%r599, [%rd104+-4];
	and.b32  	%r55, %r47, 31;
	setp.eq.s32 	%p87, %r55, 0;
	@%p87 bra 	$L__BB5_64;

	mov.u32 	%r310, 32;
	sub.s32 	%r311, %r310, %r55;
	shr.u32 	%r312, %r599, %r311;
	shl.b32 	%r313, %r598, %r55;
	add.s32 	%r598, %r312, %r313;
	mul.wide.s32 	%rd105, %r52, 4;
	add.s64 	%rd106, %rd1, %rd105;
	ld.local.u32 	%r314, [%rd106];
	shr.u32 	%r315, %r314, %r311;
	shl.b32 	%r316, %r599, %r55;
	add.s32 	%r599, %r315, %r316;

$L__BB5_64:
	and.b32  	%r317, %r46, -2147483648;
	shr.u32 	%r318, %r599, 30;
	shl.b32 	%r319, %r598, 2;
	or.b32  	%r320, %r318, %r319;
	shr.u32 	%r321, %r320, 31;
	shr.u32 	%r322, %r598, 30;
	add.s32 	%r323, %r321, %r322;
	neg.s32 	%r324, %r323;
	setp.eq.s32 	%p88, %r317, 0;
	selp.b32 	%r600, %r323, %r324, %p88;
	setp.ne.s32 	%p89, %r321, 0;
	xor.b32  	%r325, %r317, -2147483648;
	selp.b32 	%r326, %r325, %r317, %p89;
	selp.b32 	%r327, -1, 0, %p89;
	xor.b32  	%r328, %r320, %r327;
	shl.b32 	%r329, %r599, 2;
	xor.b32  	%r330, %r329, %r327;
	cvt.u64.u32 	%rd107, %r328;
	cvt.u64.u32 	%rd108, %r330;
	bfi.b64 	%rd109, %rd107, %rd108, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd109;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f187, %fd191;
	setp.eq.s32 	%p90, %r326, 0;
	neg.f32 	%f188, %f187;
	selp.f32 	%f326, %f187, %f188, %p90;

$L__BB5_66:
	add.s32 	%r62, %r600, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p5, %r63, 0;
	mul.rn.f32 	%f40, %f326, %f326;
	mov.f32 	%f327, 0fB94D4153;
	@%p5 bra 	$L__BB5_68;

	mov.f32 	%f191, 0fBAB607ED;
	mov.f32 	%f192, 0f37CBAC00;
	fma.rn.f32 	%f327, %f192, %f40, %f191;

$L__BB5_68:
	selp.f32 	%f193, %f326, 0f3F800000, %p5;
	selp.f32 	%f194, 0f3C0885E4, 0f3D2AAABB, %p5;
	fma.rn.f32 	%f195, %f327, %f40, %f194;
	selp.f32 	%f196, 0fBE2AAAA8, 0fBEFFFFFF, %p5;
	fma.rn.f32 	%f197, %f195, %f40, %f196;
	mov.f32 	%f198, 0f00000000;
	fma.rn.f32 	%f199, %f40, %f193, %f198;
	fma.rn.f32 	%f328, %f197, %f199, %f193;
	and.b32  	%r332, %r62, 2;
	setp.eq.s32 	%p92, %r332, 0;
	@%p92 bra 	$L__BB5_70;

	mov.f32 	%f201, 0fBF800000;
	fma.rn.f32 	%f328, %f328, %f201, %f198;

$L__BB5_70:
	cvta.to.global.u64 	%rd110, %rd64;
	shl.b64 	%rd111, %rd10, 2;
	add.s64 	%rd30, %rd110, %rd111;
	mul.rn.f32 	%f202, %f328, %f15;
	st.global.f32 	[%rd30], %f202;
	@%p84 bra 	$L__BB5_78;

	setp.eq.f32 	%p94, %f36, 0f7F800000;
	@%p94 bra 	$L__BB5_77;
	bra.uni 	$L__BB5_72;

$L__BB5_77:
	mov.f32 	%f205, 0f00000000;
	mul.rn.f32 	%f329, %f34, %f205;
	mov.u32 	%r604, 0;
	bra.uni 	$L__BB5_78;

$L__BB5_72:
	mov.b32 	%r64, %f34;
	bfe.u32 	%r334, %r64, 23, 8;
	add.s32 	%r65, %r334, -128;
	shl.b32 	%r335, %r64, 8;
	or.b32  	%r66, %r335, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd224, 0;
	mov.u32 	%r601, 0;
	mov.u64 	%rd223, __cudart_i2opi_f;
	mov.u64 	%rd222, %rd1;

$L__BB5_73:
	.pragma "nounroll";
	ld.global.nc.u32 	%r336, [%rd223];
	mad.wide.u32 	%rd114, %r336, %r66, %rd224;
	shr.u64 	%rd224, %rd114, 32;
	st.local.u32 	[%rd222], %rd114;
	add.s64 	%rd223, %rd223, 4;
	add.s64 	%rd222, %rd222, 4;
	add.s32 	%r601, %r601, 1;
	setp.ne.s32 	%p95, %r601, 6;
	@%p95 bra 	$L__BB5_73;

	st.local.u32 	[%rd11], %rd224;
	mov.u32 	%r337, 4;
	sub.s32 	%r70, %r337, %r67;
	mov.u32 	%r338, 6;
	sub.s32 	%r339, %r338, %r67;
	mul.wide.s32 	%rd115, %r339, 4;
	add.s64 	%rd116, %rd1, %rd115;
	ld.local.u32 	%r602, [%rd116];
	ld.local.u32 	%r603, [%rd116+-4];
	and.b32  	%r73, %r65, 31;
	setp.eq.s32 	%p96, %r73, 0;
	@%p96 bra 	$L__BB5_76;

	mov.u32 	%r340, 32;
	sub.s32 	%r341, %r340, %r73;
	shr.u32 	%r342, %r603, %r341;
	shl.b32 	%r343, %r602, %r73;
	add.s32 	%r602, %r342, %r343;
	mul.wide.s32 	%rd117, %r70, 4;
	add.s64 	%rd118, %rd1, %rd117;
	ld.local.u32 	%r344, [%rd118];
	shr.u32 	%r345, %r344, %r341;
	shl.b32 	%r346, %r603, %r73;
	add.s32 	%r603, %r345, %r346;

$L__BB5_76:
	and.b32  	%r347, %r64, -2147483648;
	shr.u32 	%r348, %r603, 30;
	shl.b32 	%r349, %r602, 2;
	or.b32  	%r350, %r348, %r349;
	shr.u32 	%r351, %r350, 31;
	shr.u32 	%r352, %r602, 30;
	add.s32 	%r353, %r351, %r352;
	neg.s32 	%r354, %r353;
	setp.eq.s32 	%p97, %r347, 0;
	selp.b32 	%r604, %r353, %r354, %p97;
	setp.ne.s32 	%p98, %r351, 0;
	xor.b32  	%r355, %r347, -2147483648;
	selp.b32 	%r356, %r355, %r347, %p98;
	selp.b32 	%r357, -1, 0, %p98;
	xor.b32  	%r358, %r350, %r357;
	shl.b32 	%r359, %r603, 2;
	xor.b32  	%r360, %r359, %r357;
	cvt.u64.u32 	%rd119, %r358;
	cvt.u64.u32 	%rd120, %r360;
	bfi.b64 	%rd121, %rd119, %rd120, 32, 32;
	cvt.rn.f64.s64 	%fd192, %rd121;
	mul.rn.f64 	%fd193, %fd192, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f203, %fd193;
	setp.eq.s32 	%p99, %r356, 0;
	neg.f32 	%f204, %f203;
	selp.f32 	%f329, %f203, %f204, %p99;

$L__BB5_78:
	cvta.to.global.u64 	%rd122, %rd65;
	add.s64 	%rd37, %rd122, %rd111;
	and.b32  	%r80, %r604, 1;
	setp.eq.s32 	%p100, %r80, 0;
	selp.f32 	%f49, %f329, 0f3F800000, %p100;
	mul.rn.f32 	%f50, %f329, %f329;
	mov.f32 	%f330, 0fB94D4153;
	@%p100 bra 	$L__BB5_80;

	mov.f32 	%f207, 0fBAB607ED;
	mov.f32 	%f208, 0f37CBAC00;
	fma.rn.f32 	%f330, %f208, %f50, %f207;

$L__BB5_80:
	selp.f32 	%f209, 0f3C0885E4, 0f3D2AAABB, %p100;
	fma.rn.f32 	%f210, %f330, %f50, %f209;
	selp.f32 	%f211, 0fBE2AAAA8, 0fBEFFFFFF, %p100;
	fma.rn.f32 	%f212, %f210, %f50, %f211;
	mov.f32 	%f213, 0f00000000;
	fma.rn.f32 	%f214, %f50, %f49, %f213;
	fma.rn.f32 	%f331, %f212, %f214, %f49;
	and.b32  	%r362, %r604, 2;
	setp.eq.s32 	%p102, %r362, 0;
	@%p102 bra 	$L__BB5_82;

	mov.f32 	%f216, 0fBF800000;
	fma.rn.f32 	%f331, %f331, %f216, %f213;

$L__BB5_82:
	mul.rn.f32 	%f56, %f331, %f15;
	st.global.f32 	[%rd37], %f56;
	ld.global.f32 	%f57, [%rd30];
	add.rn.f32 	%f58, %f57, 0fC2D20000;
	add.rn.f32 	%f59, %f56, 0fC20C0000;
	cvt.f64.f32 	%fd24, %f58;
	mul.rn.f64 	%fd194, %fd24, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f60, %fd194;
	cvt.f64.f32 	%fd25, %f59;
	mul.rn.f64 	%fd195, %fd25, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f61, %fd195;
	cvt.f64.f32 	%fd26, %f60;
	mul.rn.f64 	%fd27, %fd26, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r363, %temp}, %fd27;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r364}, %fd27;
	}
	and.b32  	%r365, %r364, 2147483647;
	setp.eq.s32 	%p103, %r365, 2146435072;
	setp.eq.s32 	%p104, %r363, 0;
	and.pred  	%p105, %p104, %p103;
	@%p105 bra 	$L__BB5_85;
	bra.uni 	$L__BB5_83;

$L__BB5_85:
	mov.f64 	%fd205, 0d0000000000000000;
	mul.rn.f64 	%fd478, %fd27, %fd205;
	mov.u32 	%r605, 0;
	bra.uni 	$L__BB5_86;

$L__BB5_83:
	mul.rn.f64 	%fd196, %fd27, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r605, %fd196;
	st.local.u32 	[%rd1], %r605;
	cvt.rn.f64.s32 	%fd197, %r605;
	neg.f64 	%fd198, %fd197;
	mov.f64 	%fd199, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd200, %fd198, %fd199, %fd27;
	mov.f64 	%fd201, 0d3C91A62633145C00;
	fma.rn.f64 	%fd202, %fd198, %fd201, %fd200;
	mov.f64 	%fd203, 0d397B839A252049C0;
	fma.rn.f64 	%fd478, %fd198, %fd203, %fd202;
	abs.f64 	%fd204, %fd27;
	setp.ltu.f64 	%p106, %fd204, 0d41E0000000000000;
	@%p106 bra 	$L__BB5_86;

	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd66;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd478, [retval0+0];
	} // callseq 38
	ld.local.u32 	%r605, [%rd1];

$L__BB5_86:
	and.b32  	%r367, %r605, 1;
	shl.b32 	%r368, %r605, 3;
	and.b32  	%r369, %r368, 8;
	setp.eq.s32 	%p107, %r367, 0;
	selp.f64 	%fd206, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p107;
	mul.wide.s32 	%rd125, %r369, 8;
	mov.u64 	%rd126, __cudart_sin_cos_coeffs;
	add.s64 	%rd127, %rd126, %rd125;
	ld.global.nc.f64 	%fd207, [%rd127+8];
	mul.rn.f64 	%fd32, %fd478, %fd478;
	fma.rn.f64 	%fd208, %fd206, %fd32, %fd207;
	ld.global.nc.f64 	%fd209, [%rd127+16];
	fma.rn.f64 	%fd210, %fd208, %fd32, %fd209;
	ld.global.nc.f64 	%fd211, [%rd127+24];
	fma.rn.f64 	%fd212, %fd210, %fd32, %fd211;
	ld.global.nc.f64 	%fd213, [%rd127+32];
	fma.rn.f64 	%fd214, %fd212, %fd32, %fd213;
	ld.global.nc.f64 	%fd215, [%rd127+40];
	fma.rn.f64 	%fd216, %fd214, %fd32, %fd215;
	ld.global.nc.f64 	%fd217, [%rd127+48];
	fma.rn.f64 	%fd33, %fd216, %fd32, %fd217;
	fma.rn.f64 	%fd480, %fd33, %fd478, %fd478;
	@%p107 bra 	$L__BB5_88;

	mov.f64 	%fd218, 0d3FF0000000000000;
	fma.rn.f64 	%fd480, %fd33, %fd32, %fd218;

$L__BB5_88:
	and.b32  	%r370, %r605, 2;
	setp.eq.s32 	%p108, %r370, 0;
	@%p108 bra 	$L__BB5_90;

	mov.f64 	%fd219, 0d0000000000000000;
	mov.f64 	%fd220, 0dBFF0000000000000;
	fma.rn.f64 	%fd480, %fd480, %fd220, %fd219;

$L__BB5_90:
	add.rn.f64 	%fd39, %fd26, %fd26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd39;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r372}, %fd39;
	}
	and.b32  	%r373, %r372, 2147483647;
	setp.eq.s32 	%p109, %r373, 2146435072;
	setp.eq.s32 	%p110, %r371, 0;
	and.pred  	%p111, %p110, %p109;
	@%p111 bra 	$L__BB5_93;
	bra.uni 	$L__BB5_91;

$L__BB5_93:
	mov.f64 	%fd230, 0d0000000000000000;
	mul.rn.f64 	%fd481, %fd39, %fd230;
	mov.u32 	%r606, 0;
	bra.uni 	$L__BB5_94;

$L__BB5_91:
	mul.rn.f64 	%fd221, %fd39, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r606, %fd221;
	st.local.u32 	[%rd1], %r606;
	cvt.rn.f64.s32 	%fd222, %r606;
	neg.f64 	%fd223, %fd222;
	mov.f64 	%fd224, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd225, %fd223, %fd224, %fd39;
	mov.f64 	%fd226, 0d3C91A62633145C00;
	fma.rn.f64 	%fd227, %fd223, %fd226, %fd225;
	mov.f64 	%fd228, 0d397B839A252049C0;
	fma.rn.f64 	%fd481, %fd223, %fd228, %fd227;
	abs.f64 	%fd229, %fd39;
	setp.ltu.f64 	%p112, %fd229, 0d41E0000000000000;
	@%p112 bra 	$L__BB5_94;

	add.u64 	%rd212, %SP, 0;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd39;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd212;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd481, [retval0+0];
	} // callseq 39
	ld.local.u32 	%r606, [%rd1];

$L__BB5_94:
	and.b32  	%r375, %r606, 1;
	shl.b32 	%r376, %r606, 3;
	and.b32  	%r377, %r376, 8;
	setp.eq.s32 	%p113, %r375, 0;
	selp.f64 	%fd231, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd129, %r377, 8;
	add.s64 	%rd131, %rd126, %rd129;
	ld.global.nc.f64 	%fd232, [%rd131+8];
	mul.rn.f64 	%fd44, %fd481, %fd481;
	fma.rn.f64 	%fd233, %fd231, %fd44, %fd232;
	ld.global.nc.f64 	%fd234, [%rd131+16];
	fma.rn.f64 	%fd235, %fd233, %fd44, %fd234;
	ld.global.nc.f64 	%fd236, [%rd131+24];
	fma.rn.f64 	%fd237, %fd235, %fd44, %fd236;
	ld.global.nc.f64 	%fd238, [%rd131+32];
	fma.rn.f64 	%fd239, %fd237, %fd44, %fd238;
	ld.global.nc.f64 	%fd240, [%rd131+40];
	fma.rn.f64 	%fd241, %fd239, %fd44, %fd240;
	ld.global.nc.f64 	%fd242, [%rd131+48];
	fma.rn.f64 	%fd45, %fd241, %fd44, %fd242;
	fma.rn.f64 	%fd483, %fd45, %fd481, %fd481;
	@%p113 bra 	$L__BB5_96;

	mov.f64 	%fd243, 0d3FF0000000000000;
	fma.rn.f64 	%fd483, %fd45, %fd44, %fd243;

$L__BB5_96:
	and.b32  	%r378, %r606, 2;
	setp.eq.s32 	%p114, %r378, 0;
	@%p114 bra 	$L__BB5_98;

	mov.f64 	%fd244, 0d0000000000000000;
	mov.f64 	%fd245, 0dBFF0000000000000;
	fma.rn.f64 	%fd483, %fd483, %fd245, %fd244;

$L__BB5_98:
	mul.rn.f64 	%fd246, %fd483, 0d4034000000000000;
	mul.rn.f64 	%fd247, %fd480, 0d4034000000000000;
	add.rn.f64 	%fd51, %fd247, %fd246;
	mul.rn.f32 	%f217, %f61, 0f3F22F983;
	cvt.rni.s32.f32 	%r610, %f217;
	cvt.rn.f32.s32 	%f218, %r610;
	mov.f32 	%f219, 0fBFC90FDA;
	fma.rn.f32 	%f220, %f218, %f219, %f61;
	mov.f32 	%f221, 0fB3A22168;
	fma.rn.f32 	%f222, %f218, %f221, %f220;
	mov.f32 	%f223, 0fA7C234C5;
	fma.rn.f32 	%f332, %f218, %f223, %f222;
	abs.f32 	%f63, %f61;
	setp.ltu.f32 	%p115, %f63, 0f47CE4780;
	@%p115 bra 	$L__BB5_106;

	setp.eq.f32 	%p116, %f63, 0f7F800000;
	@%p116 bra 	$L__BB5_105;
	bra.uni 	$L__BB5_100;

$L__BB5_105:
	mov.f32 	%f226, 0f00000000;
	mul.rn.f32 	%f332, %f61, %f226;
	mov.u32 	%r610, 0;
	bra.uni 	$L__BB5_106;

$L__BB5_100:
	mov.b32 	%r88, %f61;
	bfe.u32 	%r380, %r88, 23, 8;
	add.s32 	%r89, %r380, -128;
	shl.b32 	%r381, %r88, 8;
	or.b32  	%r90, %r381, -2147483648;
	shr.u32 	%r91, %r89, 5;
	mov.u64 	%rd227, 0;
	mov.u32 	%r607, 0;
	mov.u64 	%rd226, __cudart_i2opi_f;
	mov.u64 	%rd225, %rd1;

$L__BB5_101:
	.pragma "nounroll";
	ld.global.nc.u32 	%r382, [%rd226];
	mad.wide.u32 	%rd134, %r382, %r90, %rd227;
	shr.u64 	%rd227, %rd134, 32;
	st.local.u32 	[%rd225], %rd134;
	add.s64 	%rd226, %rd226, 4;
	add.s64 	%rd225, %rd225, 4;
	add.s32 	%r607, %r607, 1;
	setp.ne.s32 	%p117, %r607, 6;
	@%p117 bra 	$L__BB5_101;

	add.s64 	%rd196, %rd1, 24;
	st.local.u32 	[%rd196], %rd227;
	mov.u32 	%r383, 4;
	sub.s32 	%r94, %r383, %r91;
	mov.u32 	%r384, 6;
	sub.s32 	%r385, %r384, %r91;
	mul.wide.s32 	%rd135, %r385, 4;
	add.s64 	%rd136, %rd1, %rd135;
	ld.local.u32 	%r608, [%rd136];
	ld.local.u32 	%r609, [%rd136+-4];
	and.b32  	%r97, %r89, 31;
	setp.eq.s32 	%p118, %r97, 0;
	@%p118 bra 	$L__BB5_104;

	mov.u32 	%r386, 32;
	sub.s32 	%r387, %r386, %r97;
	shr.u32 	%r388, %r609, %r387;
	shl.b32 	%r389, %r608, %r97;
	add.s32 	%r608, %r388, %r389;
	mul.wide.s32 	%rd137, %r94, 4;
	add.s64 	%rd138, %rd1, %rd137;
	ld.local.u32 	%r390, [%rd138];
	shr.u32 	%r391, %r390, %r387;
	shl.b32 	%r392, %r609, %r97;
	add.s32 	%r609, %r391, %r392;

$L__BB5_104:
	and.b32  	%r393, %r88, -2147483648;
	shr.u32 	%r394, %r609, 30;
	shl.b32 	%r395, %r608, 2;
	or.b32  	%r396, %r394, %r395;
	shr.u32 	%r397, %r396, 31;
	shr.u32 	%r398, %r608, 30;
	add.s32 	%r399, %r397, %r398;
	neg.s32 	%r400, %r399;
	setp.eq.s32 	%p119, %r393, 0;
	selp.b32 	%r610, %r399, %r400, %p119;
	setp.ne.s32 	%p120, %r397, 0;
	xor.b32  	%r401, %r393, -2147483648;
	selp.b32 	%r402, %r401, %r393, %p120;
	selp.b32 	%r403, -1, 0, %p120;
	xor.b32  	%r404, %r396, %r403;
	shl.b32 	%r405, %r609, 2;
	xor.b32  	%r406, %r405, %r403;
	cvt.u64.u32 	%rd139, %r404;
	cvt.u64.u32 	%rd140, %r406;
	bfi.b64 	%rd141, %rd139, %rd140, 32, 32;
	cvt.rn.f64.s64 	%fd248, %rd141;
	mul.rn.f64 	%fd249, %fd248, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f224, %fd249;
	setp.eq.s32 	%p121, %r402, 0;
	neg.f32 	%f225, %f224;
	selp.f32 	%f332, %f224, %f225, %p121;

$L__BB5_106:
	and.b32  	%r104, %r610, 1;
	setp.eq.s32 	%p122, %r104, 0;
	selp.f32 	%f67, %f332, 0f3F800000, %p122;
	mul.rn.f32 	%f68, %f332, %f332;
	mov.f32 	%f333, 0fB94D4153;
	@%p122 bra 	$L__BB5_108;

	mov.f32 	%f228, 0fBAB607ED;
	mov.f32 	%f229, 0f37CBAC00;
	fma.rn.f32 	%f333, %f229, %f68, %f228;

$L__BB5_108:
	selp.f32 	%f230, 0f3C0885E4, 0f3D2AAABB, %p122;
	fma.rn.f32 	%f231, %f333, %f68, %f230;
	selp.f32 	%f232, 0fBE2AAAA8, 0fBEFFFFFF, %p122;
	fma.rn.f32 	%f233, %f231, %f68, %f232;
	mov.f32 	%f234, 0f00000000;
	fma.rn.f32 	%f235, %f68, %f67, %f234;
	fma.rn.f32 	%f334, %f233, %f235, %f67;
	and.b32  	%r408, %r610, 2;
	setp.eq.s32 	%p124, %r408, 0;
	@%p124 bra 	$L__BB5_110;

	mov.f32 	%f237, 0fBF800000;
	fma.rn.f32 	%f334, %f334, %f237, %f234;

$L__BB5_110:
	cvt.f64.f32 	%fd52, %f61;
	div.rn.f64 	%fd53, %fd52, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd53;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r410}, %fd53;
	}
	and.b32  	%r411, %r410, 2147483647;
	setp.eq.s32 	%p125, %r411, 2146435072;
	setp.eq.s32 	%p126, %r409, 0;
	and.pred  	%p127, %p126, %p125;
	@%p127 bra 	$L__BB5_113;
	bra.uni 	$L__BB5_111;

$L__BB5_113:
	mov.f64 	%fd259, 0d0000000000000000;
	mul.rn.f64 	%fd484, %fd53, %fd259;
	mov.u32 	%r611, 0;
	bra.uni 	$L__BB5_114;

$L__BB5_111:
	mul.rn.f64 	%fd250, %fd53, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r611, %fd250;
	st.local.u32 	[%rd1], %r611;
	cvt.rn.f64.s32 	%fd251, %r611;
	neg.f64 	%fd252, %fd251;
	mov.f64 	%fd253, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd254, %fd252, %fd253, %fd53;
	mov.f64 	%fd255, 0d3C91A62633145C00;
	fma.rn.f64 	%fd256, %fd252, %fd255, %fd254;
	mov.f64 	%fd257, 0d397B839A252049C0;
	fma.rn.f64 	%fd484, %fd252, %fd257, %fd256;
	abs.f64 	%fd258, %fd53;
	setp.ltu.f64 	%p128, %fd258, 0d41E0000000000000;
	@%p128 bra 	$L__BB5_114;

	add.u64 	%rd197, %SP, 0;
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd53;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd197;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd484, [retval0+0];
	} // callseq 40
	ld.local.u32 	%r611, [%rd1];

$L__BB5_114:
	mov.u64 	%rd198, __cudart_sin_cos_coeffs;
	and.b32  	%r413, %r611, 1;
	shl.b32 	%r414, %r611, 3;
	and.b32  	%r415, %r414, 8;
	setp.eq.s32 	%p129, %r413, 0;
	selp.f64 	%fd260, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p129;
	mul.wide.s32 	%rd143, %r415, 8;
	add.s64 	%rd145, %rd198, %rd143;
	ld.global.nc.f64 	%fd261, [%rd145+8];
	mul.rn.f64 	%fd58, %fd484, %fd484;
	fma.rn.f64 	%fd262, %fd260, %fd58, %fd261;
	ld.global.nc.f64 	%fd263, [%rd145+16];
	fma.rn.f64 	%fd264, %fd262, %fd58, %fd263;
	ld.global.nc.f64 	%fd265, [%rd145+24];
	fma.rn.f64 	%fd266, %fd264, %fd58, %fd265;
	ld.global.nc.f64 	%fd267, [%rd145+32];
	fma.rn.f64 	%fd268, %fd266, %fd58, %fd267;
	ld.global.nc.f64 	%fd269, [%rd145+40];
	fma.rn.f64 	%fd270, %fd268, %fd58, %fd269;
	ld.global.nc.f64 	%fd271, [%rd145+48];
	fma.rn.f64 	%fd59, %fd270, %fd58, %fd271;
	fma.rn.f64 	%fd486, %fd59, %fd484, %fd484;
	@%p129 bra 	$L__BB5_116;

	mov.f64 	%fd272, 0d3FF0000000000000;
	fma.rn.f64 	%fd486, %fd59, %fd58, %fd272;

$L__BB5_116:
	and.b32  	%r416, %r611, 2;
	setp.eq.s32 	%p130, %r416, 0;
	@%p130 bra 	$L__BB5_118;

	mov.f64 	%fd273, 0d0000000000000000;
	mov.f64 	%fd274, 0dBFF0000000000000;
	fma.rn.f64 	%fd486, %fd486, %fd274, %fd273;

$L__BB5_118:
	mul.rn.f64 	%fd275, %fd486, 0d4044000000000000;
	cvt.f64.f32 	%fd276, %f334;
	mul.rn.f64 	%fd277, %fd276, 0d4034000000000000;
	add.rn.f64 	%fd65, %fd277, %fd275;
	div.rn.f64 	%fd66, %fd52, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r417, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r418}, %fd66;
	}
	and.b32  	%r419, %r418, 2147483647;
	setp.eq.s32 	%p131, %r419, 2146435072;
	setp.eq.s32 	%p132, %r417, 0;
	and.pred  	%p133, %p132, %p131;
	@%p133 bra 	$L__BB5_121;
	bra.uni 	$L__BB5_119;

$L__BB5_121:
	mov.f64 	%fd287, 0d0000000000000000;
	mul.rn.f64 	%fd487, %fd66, %fd287;
	mov.u32 	%r612, 0;
	bra.uni 	$L__BB5_122;

$L__BB5_119:
	mul.rn.f64 	%fd278, %fd66, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r612, %fd278;
	st.local.u32 	[%rd1], %r612;
	cvt.rn.f64.s32 	%fd279, %r612;
	neg.f64 	%fd280, %fd279;
	mov.f64 	%fd281, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd282, %fd280, %fd281, %fd66;
	mov.f64 	%fd283, 0d3C91A62633145C00;
	fma.rn.f64 	%fd284, %fd280, %fd283, %fd282;
	mov.f64 	%fd285, 0d397B839A252049C0;
	fma.rn.f64 	%fd487, %fd280, %fd285, %fd284;
	abs.f64 	%fd286, %fd66;
	setp.ltu.f64 	%p134, %fd286, 0d41E0000000000000;
	@%p134 bra 	$L__BB5_122;

	add.u64 	%rd199, %SP, 0;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd66;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd199;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd487, [retval0+0];
	} // callseq 41
	ld.local.u32 	%r612, [%rd1];

$L__BB5_122:
	mov.u64 	%rd200, __cudart_sin_cos_coeffs;
	and.b32  	%r421, %r612, 1;
	shl.b32 	%r422, %r612, 3;
	and.b32  	%r423, %r422, 8;
	setp.eq.s32 	%p135, %r421, 0;
	selp.f64 	%fd288, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p135;
	mul.wide.s32 	%rd147, %r423, 8;
	add.s64 	%rd149, %rd200, %rd147;
	ld.global.nc.f64 	%fd289, [%rd149+8];
	mul.rn.f64 	%fd71, %fd487, %fd487;
	fma.rn.f64 	%fd290, %fd288, %fd71, %fd289;
	ld.global.nc.f64 	%fd291, [%rd149+16];
	fma.rn.f64 	%fd292, %fd290, %fd71, %fd291;
	ld.global.nc.f64 	%fd293, [%rd149+24];
	fma.rn.f64 	%fd294, %fd292, %fd71, %fd293;
	ld.global.nc.f64 	%fd295, [%rd149+32];
	fma.rn.f64 	%fd296, %fd294, %fd71, %fd295;
	ld.global.nc.f64 	%fd297, [%rd149+40];
	fma.rn.f64 	%fd298, %fd296, %fd71, %fd297;
	ld.global.nc.f64 	%fd299, [%rd149+48];
	fma.rn.f64 	%fd72, %fd298, %fd71, %fd299;
	fma.rn.f64 	%fd489, %fd72, %fd487, %fd487;
	@%p135 bra 	$L__BB5_124;

	mov.f64 	%fd300, 0d3FF0000000000000;
	fma.rn.f64 	%fd489, %fd72, %fd71, %fd300;

$L__BB5_124:
	and.b32  	%r424, %r612, 2;
	setp.eq.s32 	%p136, %r424, 0;
	@%p136 bra 	$L__BB5_126;

	mov.f64 	%fd301, 0d0000000000000000;
	mov.f64 	%fd302, 0dBFF0000000000000;
	fma.rn.f64 	%fd489, %fd489, %fd302, %fd301;

$L__BB5_126:
	mul.rn.f64 	%fd303, %fd489, 0d4064000000000000;
	add.rn.f64 	%fd78, %fd65, %fd303;
	div.rn.f64 	%fd79, %fd52, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r425, %temp}, %fd79;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r426}, %fd79;
	}
	and.b32  	%r427, %r426, 2147483647;
	setp.eq.s32 	%p137, %r427, 2146435072;
	setp.eq.s32 	%p138, %r425, 0;
	and.pred  	%p139, %p138, %p137;
	@%p139 bra 	$L__BB5_129;
	bra.uni 	$L__BB5_127;

$L__BB5_129:
	mov.f64 	%fd313, 0d0000000000000000;
	mul.rn.f64 	%fd490, %fd79, %fd313;
	mov.u32 	%r613, 0;
	bra.uni 	$L__BB5_130;

$L__BB5_127:
	mul.rn.f64 	%fd304, %fd79, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r613, %fd304;
	st.local.u32 	[%rd1], %r613;
	cvt.rn.f64.s32 	%fd305, %r613;
	neg.f64 	%fd306, %fd305;
	mov.f64 	%fd307, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd308, %fd306, %fd307, %fd79;
	mov.f64 	%fd309, 0d3C91A62633145C00;
	fma.rn.f64 	%fd310, %fd306, %fd309, %fd308;
	mov.f64 	%fd311, 0d397B839A252049C0;
	fma.rn.f64 	%fd490, %fd306, %fd311, %fd310;
	abs.f64 	%fd312, %fd79;
	setp.ltu.f64 	%p140, %fd312, 0d41E0000000000000;
	@%p140 bra 	$L__BB5_130;

	add.u64 	%rd201, %SP, 0;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd490, [retval0+0];
	} // callseq 42
	ld.local.u32 	%r613, [%rd1];

$L__BB5_130:
	mov.u64 	%rd202, __cudart_sin_cos_coeffs;
	and.b32  	%r429, %r613, 1;
	shl.b32 	%r430, %r613, 3;
	and.b32  	%r431, %r430, 8;
	setp.eq.s32 	%p141, %r429, 0;
	selp.f64 	%fd314, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p141;
	mul.wide.s32 	%rd151, %r431, 8;
	add.s64 	%rd153, %rd202, %rd151;
	ld.global.nc.f64 	%fd315, [%rd153+8];
	mul.rn.f64 	%fd84, %fd490, %fd490;
	fma.rn.f64 	%fd316, %fd314, %fd84, %fd315;
	ld.global.nc.f64 	%fd317, [%rd153+16];
	fma.rn.f64 	%fd318, %fd316, %fd84, %fd317;
	ld.global.nc.f64 	%fd319, [%rd153+24];
	fma.rn.f64 	%fd320, %fd318, %fd84, %fd319;
	ld.global.nc.f64 	%fd321, [%rd153+32];
	fma.rn.f64 	%fd322, %fd320, %fd84, %fd321;
	ld.global.nc.f64 	%fd323, [%rd153+40];
	fma.rn.f64 	%fd324, %fd322, %fd84, %fd323;
	ld.global.nc.f64 	%fd325, [%rd153+48];
	fma.rn.f64 	%fd85, %fd324, %fd84, %fd325;
	fma.rn.f64 	%fd492, %fd85, %fd490, %fd490;
	@%p141 bra 	$L__BB5_132;

	mov.f64 	%fd326, 0d3FF0000000000000;
	fma.rn.f64 	%fd492, %fd85, %fd84, %fd326;

$L__BB5_132:
	and.b32  	%r432, %r613, 2;
	setp.eq.s32 	%p142, %r432, 0;
	@%p142 bra 	$L__BB5_134;

	mov.f64 	%fd327, 0d0000000000000000;
	mov.f64 	%fd328, 0dBFF0000000000000;
	fma.rn.f64 	%fd492, %fd492, %fd328, %fd327;

$L__BB5_134:
	mul.rn.f64 	%fd329, %fd492, 0d4074000000000000;
	add.rn.f64 	%fd91, %fd78, %fd329;
	mul.rn.f32 	%f238, %f60, 0f3F22F983;
	cvt.rni.s32.f32 	%r617, %f238;
	cvt.rn.f32.s32 	%f239, %r617;
	mov.f32 	%f240, 0fBFC90FDA;
	fma.rn.f32 	%f241, %f239, %f240, %f60;
	mov.f32 	%f242, 0fB3A22168;
	fma.rn.f32 	%f243, %f239, %f242, %f241;
	mov.f32 	%f244, 0fA7C234C5;
	fma.rn.f32 	%f335, %f239, %f244, %f243;
	abs.f32 	%f75, %f60;
	setp.ltu.f32 	%p143, %f75, 0f47CE4780;
	@%p143 bra 	$L__BB5_142;

	setp.eq.f32 	%p144, %f75, 0f7F800000;
	@%p144 bra 	$L__BB5_141;
	bra.uni 	$L__BB5_136;

$L__BB5_141:
	mov.f32 	%f247, 0f00000000;
	mul.rn.f32 	%f335, %f60, %f247;
	mov.u32 	%r617, 0;
	bra.uni 	$L__BB5_142;

$L__BB5_136:
	mov.b32 	%r115, %f60;
	bfe.u32 	%r434, %r115, 23, 8;
	add.s32 	%r116, %r434, -128;
	shl.b32 	%r435, %r115, 8;
	or.b32  	%r117, %r435, -2147483648;
	shr.u32 	%r118, %r116, 5;
	mov.u64 	%rd230, 0;
	mov.u32 	%r614, 0;
	mov.u64 	%rd229, __cudart_i2opi_f;
	mov.u64 	%rd228, %rd1;

$L__BB5_137:
	.pragma "nounroll";
	ld.global.nc.u32 	%r436, [%rd229];
	mad.wide.u32 	%rd156, %r436, %r117, %rd230;
	shr.u64 	%rd230, %rd156, 32;
	st.local.u32 	[%rd228], %rd156;
	add.s64 	%rd229, %rd229, 4;
	add.s64 	%rd228, %rd228, 4;
	add.s32 	%r614, %r614, 1;
	setp.ne.s32 	%p145, %r614, 6;
	@%p145 bra 	$L__BB5_137;

	add.s64 	%rd203, %rd1, 24;
	st.local.u32 	[%rd203], %rd230;
	mov.u32 	%r437, 4;
	sub.s32 	%r121, %r437, %r118;
	mov.u32 	%r438, 6;
	sub.s32 	%r439, %r438, %r118;
	mul.wide.s32 	%rd157, %r439, 4;
	add.s64 	%rd158, %rd1, %rd157;
	ld.local.u32 	%r615, [%rd158];
	ld.local.u32 	%r616, [%rd158+-4];
	and.b32  	%r124, %r116, 31;
	setp.eq.s32 	%p146, %r124, 0;
	@%p146 bra 	$L__BB5_140;

	mov.u32 	%r440, 32;
	sub.s32 	%r441, %r440, %r124;
	shr.u32 	%r442, %r616, %r441;
	shl.b32 	%r443, %r615, %r124;
	add.s32 	%r615, %r442, %r443;
	mul.wide.s32 	%rd159, %r121, 4;
	add.s64 	%rd160, %rd1, %rd159;
	ld.local.u32 	%r444, [%rd160];
	shr.u32 	%r445, %r444, %r441;
	shl.b32 	%r446, %r616, %r124;
	add.s32 	%r616, %r445, %r446;

$L__BB5_140:
	and.b32  	%r447, %r115, -2147483648;
	shr.u32 	%r448, %r616, 30;
	shl.b32 	%r449, %r615, 2;
	or.b32  	%r450, %r448, %r449;
	shr.u32 	%r451, %r450, 31;
	shr.u32 	%r452, %r615, 30;
	add.s32 	%r453, %r451, %r452;
	neg.s32 	%r454, %r453;
	setp.eq.s32 	%p147, %r447, 0;
	selp.b32 	%r617, %r453, %r454, %p147;
	setp.ne.s32 	%p148, %r451, 0;
	xor.b32  	%r455, %r447, -2147483648;
	selp.b32 	%r456, %r455, %r447, %p148;
	selp.b32 	%r457, -1, 0, %p148;
	xor.b32  	%r458, %r450, %r457;
	shl.b32 	%r459, %r616, 2;
	xor.b32  	%r460, %r459, %r457;
	cvt.u64.u32 	%rd161, %r458;
	cvt.u64.u32 	%rd162, %r460;
	bfi.b64 	%rd163, %rd161, %rd162, 32, 32;
	cvt.rn.f64.s64 	%fd330, %rd163;
	mul.rn.f64 	%fd331, %fd330, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f245, %fd331;
	setp.eq.s32 	%p149, %r456, 0;
	neg.f32 	%f246, %f245;
	selp.f32 	%f335, %f245, %f246, %p149;

$L__BB5_142:
	cvt.rn.f32.f64 	%f249, %fd51;
	cvt.f64.f32 	%fd92, %f249;
	and.b32  	%r131, %r617, 1;
	setp.eq.s32 	%p150, %r131, 0;
	selp.f32 	%f79, %f335, 0f3F800000, %p150;
	mul.rn.f32 	%f80, %f335, %f335;
	mov.f32 	%f336, 0fB94D4153;
	@%p150 bra 	$L__BB5_144;

	mov.f32 	%f250, 0fBAB607ED;
	mov.f32 	%f251, 0f37CBAC00;
	fma.rn.f32 	%f336, %f251, %f80, %f250;

$L__BB5_144:
	selp.f32 	%f252, 0f3C0885E4, 0f3D2AAABB, %p150;
	fma.rn.f32 	%f253, %f336, %f80, %f252;
	selp.f32 	%f254, 0fBE2AAAA8, 0fBEFFFFFF, %p150;
	fma.rn.f32 	%f255, %f253, %f80, %f254;
	mov.f32 	%f256, 0f00000000;
	fma.rn.f32 	%f257, %f80, %f79, %f256;
	fma.rn.f32 	%f337, %f255, %f257, %f79;
	and.b32  	%r462, %r617, 2;
	setp.eq.s32 	%p152, %r462, 0;
	@%p152 bra 	$L__BB5_146;

	mov.f32 	%f259, 0fBF800000;
	fma.rn.f32 	%f337, %f337, %f259, %f256;

$L__BB5_146:
	div.rn.f64 	%fd93, %fd26, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r463, %temp}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r464}, %fd93;
	}
	and.b32  	%r465, %r464, 2147483647;
	setp.eq.s32 	%p153, %r465, 2146435072;
	setp.eq.s32 	%p154, %r463, 0;
	and.pred  	%p155, %p154, %p153;
	@%p155 bra 	$L__BB5_149;
	bra.uni 	$L__BB5_147;

$L__BB5_149:
	mov.f64 	%fd341, 0d0000000000000000;
	mul.rn.f64 	%fd493, %fd93, %fd341;
	mov.u32 	%r618, 0;
	bra.uni 	$L__BB5_150;

$L__BB5_147:
	mul.rn.f64 	%fd332, %fd93, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r618, %fd332;
	st.local.u32 	[%rd1], %r618;
	cvt.rn.f64.s32 	%fd333, %r618;
	neg.f64 	%fd334, %fd333;
	mov.f64 	%fd335, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd336, %fd334, %fd335, %fd93;
	mov.f64 	%fd337, 0d3C91A62633145C00;
	fma.rn.f64 	%fd338, %fd334, %fd337, %fd336;
	mov.f64 	%fd339, 0d397B839A252049C0;
	fma.rn.f64 	%fd493, %fd334, %fd339, %fd338;
	abs.f64 	%fd340, %fd93;
	setp.ltu.f64 	%p156, %fd340, 0d41E0000000000000;
	@%p156 bra 	$L__BB5_150;

	add.u64 	%rd204, %SP, 0;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd93;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd204;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd493, [retval0+0];
	} // callseq 43
	ld.local.u32 	%r618, [%rd1];

$L__BB5_150:
	mov.u64 	%rd205, __cudart_sin_cos_coeffs;
	and.b32  	%r467, %r618, 1;
	shl.b32 	%r468, %r618, 3;
	and.b32  	%r469, %r468, 8;
	setp.eq.s32 	%p157, %r467, 0;
	selp.f64 	%fd342, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p157;
	mul.wide.s32 	%rd165, %r469, 8;
	add.s64 	%rd167, %rd205, %rd165;
	ld.global.nc.f64 	%fd343, [%rd167+8];
	mul.rn.f64 	%fd98, %fd493, %fd493;
	fma.rn.f64 	%fd344, %fd342, %fd98, %fd343;
	ld.global.nc.f64 	%fd345, [%rd167+16];
	fma.rn.f64 	%fd346, %fd344, %fd98, %fd345;
	ld.global.nc.f64 	%fd347, [%rd167+24];
	fma.rn.f64 	%fd348, %fd346, %fd98, %fd347;
	ld.global.nc.f64 	%fd349, [%rd167+32];
	fma.rn.f64 	%fd350, %fd348, %fd98, %fd349;
	ld.global.nc.f64 	%fd351, [%rd167+40];
	fma.rn.f64 	%fd352, %fd350, %fd98, %fd351;
	ld.global.nc.f64 	%fd353, [%rd167+48];
	fma.rn.f64 	%fd99, %fd352, %fd98, %fd353;
	fma.rn.f64 	%fd495, %fd99, %fd493, %fd493;
	@%p157 bra 	$L__BB5_152;

	mov.f64 	%fd354, 0d3FF0000000000000;
	fma.rn.f64 	%fd495, %fd99, %fd98, %fd354;

$L__BB5_152:
	and.b32  	%r470, %r618, 2;
	setp.eq.s32 	%p158, %r470, 0;
	@%p158 bra 	$L__BB5_154;

	mov.f64 	%fd355, 0d0000000000000000;
	mov.f64 	%fd356, 0dBFF0000000000000;
	fma.rn.f64 	%fd495, %fd495, %fd356, %fd355;

$L__BB5_154:
	mul.rn.f64 	%fd357, %fd495, 0d4044000000000000;
	cvt.f64.f32 	%fd358, %f337;
	mul.rn.f64 	%fd359, %fd358, 0d4034000000000000;
	add.rn.f64 	%fd105, %fd359, %fd357;
	div.rn.f64 	%fd106, %fd26, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r471, %temp}, %fd106;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r472}, %fd106;
	}
	and.b32  	%r473, %r472, 2147483647;
	setp.eq.s32 	%p159, %r473, 2146435072;
	setp.eq.s32 	%p160, %r471, 0;
	and.pred  	%p161, %p160, %p159;
	@%p161 bra 	$L__BB5_157;
	bra.uni 	$L__BB5_155;

$L__BB5_157:
	mov.f64 	%fd369, 0d0000000000000000;
	mul.rn.f64 	%fd496, %fd106, %fd369;
	mov.u32 	%r619, 0;
	bra.uni 	$L__BB5_158;

$L__BB5_155:
	mul.rn.f64 	%fd360, %fd106, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r619, %fd360;
	st.local.u32 	[%rd1], %r619;
	cvt.rn.f64.s32 	%fd361, %r619;
	neg.f64 	%fd362, %fd361;
	mov.f64 	%fd363, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd364, %fd362, %fd363, %fd106;
	mov.f64 	%fd365, 0d3C91A62633145C00;
	fma.rn.f64 	%fd366, %fd362, %fd365, %fd364;
	mov.f64 	%fd367, 0d397B839A252049C0;
	fma.rn.f64 	%fd496, %fd362, %fd367, %fd366;
	abs.f64 	%fd368, %fd106;
	setp.ltu.f64 	%p162, %fd368, 0d41E0000000000000;
	@%p162 bra 	$L__BB5_158;

	add.u64 	%rd206, %SP, 0;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd206;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd496, [retval0+0];
	} // callseq 44
	ld.local.u32 	%r619, [%rd1];

$L__BB5_158:
	mov.u64 	%rd207, __cudart_sin_cos_coeffs;
	and.b32  	%r475, %r619, 1;
	shl.b32 	%r476, %r619, 3;
	and.b32  	%r477, %r476, 8;
	setp.eq.s32 	%p163, %r475, 0;
	selp.f64 	%fd370, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p163;
	mul.wide.s32 	%rd169, %r477, 8;
	add.s64 	%rd171, %rd207, %rd169;
	ld.global.nc.f64 	%fd371, [%rd171+8];
	mul.rn.f64 	%fd111, %fd496, %fd496;
	fma.rn.f64 	%fd372, %fd370, %fd111, %fd371;
	ld.global.nc.f64 	%fd373, [%rd171+16];
	fma.rn.f64 	%fd374, %fd372, %fd111, %fd373;
	ld.global.nc.f64 	%fd375, [%rd171+24];
	fma.rn.f64 	%fd376, %fd374, %fd111, %fd375;
	ld.global.nc.f64 	%fd377, [%rd171+32];
	fma.rn.f64 	%fd378, %fd376, %fd111, %fd377;
	ld.global.nc.f64 	%fd379, [%rd171+40];
	fma.rn.f64 	%fd380, %fd378, %fd111, %fd379;
	ld.global.nc.f64 	%fd381, [%rd171+48];
	fma.rn.f64 	%fd112, %fd380, %fd111, %fd381;
	fma.rn.f64 	%fd498, %fd112, %fd496, %fd496;
	@%p163 bra 	$L__BB5_160;

	mov.f64 	%fd382, 0d3FF0000000000000;
	fma.rn.f64 	%fd498, %fd112, %fd111, %fd382;

$L__BB5_160:
	and.b32  	%r478, %r619, 2;
	setp.eq.s32 	%p164, %r478, 0;
	@%p164 bra 	$L__BB5_162;

	mov.f64 	%fd383, 0d0000000000000000;
	mov.f64 	%fd384, 0dBFF0000000000000;
	fma.rn.f64 	%fd498, %fd498, %fd384, %fd383;

$L__BB5_162:
	mul.rn.f64 	%fd385, %fd498, 0d4062C00000000000;
	add.rn.f64 	%fd118, %fd105, %fd385;
	div.rn.f64 	%fd119, %fd26, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r479, %temp}, %fd119;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r480}, %fd119;
	}
	and.b32  	%r481, %r480, 2147483647;
	setp.eq.s32 	%p165, %r481, 2146435072;
	setp.eq.s32 	%p166, %r479, 0;
	and.pred  	%p167, %p166, %p165;
	@%p167 bra 	$L__BB5_165;
	bra.uni 	$L__BB5_163;

$L__BB5_165:
	mov.f64 	%fd395, 0d0000000000000000;
	mul.rn.f64 	%fd499, %fd119, %fd395;
	mov.u32 	%r620, 0;
	bra.uni 	$L__BB5_166;

$L__BB5_163:
	mul.rn.f64 	%fd386, %fd119, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r620, %fd386;
	st.local.u32 	[%rd1], %r620;
	cvt.rn.f64.s32 	%fd387, %r620;
	neg.f64 	%fd388, %fd387;
	mov.f64 	%fd389, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd390, %fd388, %fd389, %fd119;
	mov.f64 	%fd391, 0d3C91A62633145C00;
	fma.rn.f64 	%fd392, %fd388, %fd391, %fd390;
	mov.f64 	%fd393, 0d397B839A252049C0;
	fma.rn.f64 	%fd499, %fd388, %fd393, %fd392;
	abs.f64 	%fd394, %fd119;
	setp.ltu.f64 	%p168, %fd394, 0d41E0000000000000;
	@%p168 bra 	$L__BB5_166;

	add.u64 	%rd208, %SP, 0;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd208;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd499, [retval0+0];
	} // callseq 45
	ld.local.u32 	%r620, [%rd1];

$L__BB5_166:
	mov.u64 	%rd209, __cudart_sin_cos_coeffs;
	and.b32  	%r483, %r620, 1;
	shl.b32 	%r484, %r620, 3;
	and.b32  	%r485, %r484, 8;
	setp.eq.s32 	%p169, %r483, 0;
	selp.f64 	%fd396, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p169;
	mul.wide.s32 	%rd173, %r485, 8;
	add.s64 	%rd175, %rd209, %rd173;
	ld.global.nc.f64 	%fd397, [%rd175+8];
	mul.rn.f64 	%fd124, %fd499, %fd499;
	fma.rn.f64 	%fd398, %fd396, %fd124, %fd397;
	ld.global.nc.f64 	%fd399, [%rd175+16];
	fma.rn.f64 	%fd400, %fd398, %fd124, %fd399;
	ld.global.nc.f64 	%fd401, [%rd175+24];
	fma.rn.f64 	%fd402, %fd400, %fd124, %fd401;
	ld.global.nc.f64 	%fd403, [%rd175+32];
	fma.rn.f64 	%fd404, %fd402, %fd124, %fd403;
	ld.global.nc.f64 	%fd405, [%rd175+40];
	fma.rn.f64 	%fd406, %fd404, %fd124, %fd405;
	ld.global.nc.f64 	%fd407, [%rd175+48];
	fma.rn.f64 	%fd125, %fd406, %fd124, %fd407;
	fma.rn.f64 	%fd501, %fd125, %fd499, %fd499;
	@%p169 bra 	$L__BB5_168;

	mov.f64 	%fd408, 0d3FF0000000000000;
	fma.rn.f64 	%fd501, %fd125, %fd124, %fd408;

$L__BB5_168:
	and.b32  	%r486, %r620, 2;
	setp.eq.s32 	%p170, %r486, 0;
	@%p170 bra 	$L__BB5_170;

	mov.f64 	%fd409, 0d0000000000000000;
	mov.f64 	%fd410, 0dBFF0000000000000;
	fma.rn.f64 	%fd501, %fd501, %fd410, %fd409;

$L__BB5_170:
	mul.rn.f64 	%fd411, %fd501, 0d4072C00000000000;
	add.rn.f64 	%fd412, %fd118, %fd411;
	add.rn.f64 	%fd131, %fd412, %fd92;
	add.rn.f64 	%fd132, %fd91, %fd92;
	add.rn.f64 	%fd413, %fd24, %fd24;
	add.rn.f64 	%fd414, %fd413, 0dC059000000000000;
	mul.rn.f64 	%fd415, %fd25, 0d4008000000000000;
	add.rn.f64 	%fd133, %fd415, %fd414;
	abs.f64 	%fd134, %fd25;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd504, [retval0+0];
	} // callseq 46
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd25;
	}
	setp.lt.s32 	%p171, %r141, 0;
	and.pred  	%p6, %p171, %p10;
	not.pred 	%p173, %p6;
	@%p173 bra 	$L__BB5_172;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r487}, %fd504;
	}
	xor.b32  	%r488, %r487, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r489, %temp}, %fd504;
	}
	mov.b64 	%fd504, {%r489, %r488};

$L__BB5_172:
	setp.eq.f32 	%p174, %f59, 0f00000000;
	@%p174 bra 	$L__BB5_176;
	bra.uni 	$L__BB5_173;

$L__BB5_176:
	selp.b32 	%r490, %r141, 0, %p10;
	mov.u32 	%r491, 0;
	or.b32  	%r492, %r490, 2146435072;
	setp.lt.s32 	%p178, %r3, 0;
	selp.b32 	%r493, %r492, %r490, %p178;
	mov.b64 	%fd504, {%r491, %r493};
	bra.uni 	$L__BB5_177;

$L__BB5_173:
	setp.gt.s32 	%p175, %r141, -1;
	@%p175 bra 	$L__BB5_177;

	mov.f64 	%fd416, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd417, %fd416;
	setp.eq.f64 	%p176, %fd417, 0d4000000000000000;
	@%p176 bra 	$L__BB5_177;

	mov.f64 	%fd504, 0dFFF8000000000000;

$L__BB5_177:
	add.rn.f64 	%fd419, %fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r494}, %fd419;
	}
	and.b32  	%r495, %r494, 2146435072;
	setp.ne.s32 	%p179, %r495, 2146435072;
	@%p179 bra 	$L__BB5_184;

	setp.gtu.f64 	%p180, %fd134, 0d7FF0000000000000;
	@%p180 bra 	$L__BB5_183;
	bra.uni 	$L__BB5_179;

$L__BB5_183:
	mov.f64 	%fd421, 0d4000000000000000;
	add.rn.f64 	%fd504, %fd25, %fd421;
	bra.uni 	$L__BB5_184;

$L__BB5_179:
	mov.f64 	%fd420, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r496, %temp}, %fd420;
	}
	and.b32  	%r142, %r3, 2147483647;
	setp.eq.s32 	%p181, %r142, 2146435072;
	setp.eq.s32 	%p182, %r496, 0;
	and.pred  	%p183, %p181, %p182;
	@%p183 bra 	$L__BB5_182;
	bra.uni 	$L__BB5_180;

$L__BB5_182:
	setp.gt.f64 	%p190, %fd134, 0d3FF0000000000000;
	selp.b32 	%r503, 2146435072, 0, %p190;
	mov.u32 	%r504, 0;
	xor.b32  	%r505, %r503, 2146435072;
	setp.lt.s32 	%p191, %r3, 0;
	selp.b32 	%r506, %r505, %r503, %p191;
	setp.eq.f32 	%p192, %f59, 0fBF800000;
	selp.b32 	%r507, 1072693248, %r506, %p192;
	mov.b64 	%fd504, {%r504, %r507};
	bra.uni 	$L__BB5_184;

$L__BB5_180:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r497, %temp}, %fd25;
	}
	and.b32  	%r498, %r141, 2147483647;
	setp.ne.s32 	%p184, %r498, 2146435072;
	setp.ne.s32 	%p185, %r497, 0;
	or.pred  	%p186, %p184, %p185;
	@%p186 bra 	$L__BB5_184;

	setp.gt.s32 	%p187, %r3, -1;
	selp.b32 	%r499, 2146435072, 0, %p187;
	mov.u32 	%r500, 0;
	setp.ne.s32 	%p188, %r142, 1071644672;
	and.pred  	%p189, %p188, %p6;
	or.b32  	%r501, %r499, -2147483648;
	selp.b32 	%r502, %r501, %r499, %p189;
	mov.b64 	%fd504, {%r500, %r502};

$L__BB5_184:
	add.rn.f32 	%f315, %f57, 0fC2D20000;
	mul.rn.f64 	%fd422, %fd504, 0d3FC999999999999A;
	setp.eq.f32 	%p193, %f59, 0f3F800000;
	selp.f64 	%fd423, 0d3FC999999999999A, %fd422, %p193;
	add.rn.f64 	%fd424, %fd133, %fd423;
	mul.rn.f32 	%f260, %f59, %f315;
	cvt.f64.f32 	%fd425, %f260;
	mul.rn.f64 	%fd144, %fd425, 0d3FB999999999999A;
	add.rn.f64 	%fd426, %fd144, %fd424;
	abs.f32 	%f261, %f315;
	sqrt.rn.f32 	%f262, %f261;
	cvt.f64.f32 	%fd145, %f262;
	mul.rn.f64 	%fd427, %fd145, 0d3FC999999999999A;
	add.rn.f64 	%fd428, %fd427, %fd426;
	cvt.rn.f32.f64 	%f263, %fd132;
	cvt.f64.f32 	%fd429, %f263;
	mul.rn.f64 	%fd430, %fd429, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f264, %fd430;
	cvt.f64.f32 	%fd431, %f264;
	add.rn.f64 	%fd146, %fd428, %fd431;
	add.rn.f64 	%fd432, %fd25, %fd25;
	add.rn.f64 	%fd433, %fd24, 0d4072C00000000000;
	add.rn.f64 	%fd147, %fd432, %fd433;
	abs.f64 	%fd148, %fd24;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd507, [retval0+0];
	} // callseq 47
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r143}, %fd24;
	}
	setp.lt.s32 	%p194, %r143, 0;
	and.pred  	%p7, %p194, %p10;
	not.pred 	%p196, %p7;
	@%p196 bra 	$L__BB5_186;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r508}, %fd507;
	}
	xor.b32  	%r509, %r508, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r510, %temp}, %fd507;
	}
	mov.b64 	%fd507, {%r510, %r509};

$L__BB5_186:
	add.rn.f32 	%f316, %f57, 0fC2D20000;
	setp.eq.f32 	%p197, %f316, 0f00000000;
	@%p197 bra 	$L__BB5_190;
	bra.uni 	$L__BB5_187;

$L__BB5_190:
	selp.b32 	%r511, %r143, 0, %p10;
	mov.u32 	%r512, 0;
	or.b32  	%r513, %r511, 2146435072;
	setp.lt.s32 	%p201, %r3, 0;
	selp.b32 	%r514, %r513, %r511, %p201;
	mov.b64 	%fd507, {%r512, %r514};
	bra.uni 	$L__BB5_191;

$L__BB5_187:
	setp.gt.s32 	%p198, %r143, -1;
	@%p198 bra 	$L__BB5_191;

	mov.f64 	%fd434, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd435, %fd434;
	setp.eq.f64 	%p199, %fd435, 0d4000000000000000;
	@%p199 bra 	$L__BB5_191;

	mov.f64 	%fd507, 0dFFF8000000000000;

$L__BB5_191:
	add.rn.f64 	%fd437, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r515}, %fd437;
	}
	and.b32  	%r516, %r515, 2146435072;
	setp.ne.s32 	%p202, %r516, 2146435072;
	@%p202 bra 	$L__BB5_198;

	setp.gtu.f64 	%p203, %fd148, 0d7FF0000000000000;
	@%p203 bra 	$L__BB5_197;
	bra.uni 	$L__BB5_193;

$L__BB5_197:
	mov.f64 	%fd439, 0d4000000000000000;
	add.rn.f64 	%fd507, %fd24, %fd439;
	bra.uni 	$L__BB5_198;

$L__BB5_193:
	mov.f64 	%fd438, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r517, %temp}, %fd438;
	}
	and.b32  	%r144, %r3, 2147483647;
	setp.eq.s32 	%p204, %r144, 2146435072;
	setp.eq.s32 	%p205, %r517, 0;
	and.pred  	%p206, %p204, %p205;
	@%p206 bra 	$L__BB5_196;
	bra.uni 	$L__BB5_194;

$L__BB5_196:
	add.rn.f32 	%f318, %f57, 0fC2D20000;
	setp.gt.f64 	%p213, %fd148, 0d3FF0000000000000;
	selp.b32 	%r524, 2146435072, 0, %p213;
	mov.u32 	%r525, 0;
	xor.b32  	%r526, %r524, 2146435072;
	setp.lt.s32 	%p214, %r3, 0;
	selp.b32 	%r527, %r526, %r524, %p214;
	setp.eq.f32 	%p215, %f318, 0fBF800000;
	selp.b32 	%r528, 1072693248, %r527, %p215;
	mov.b64 	%fd507, {%r525, %r528};
	bra.uni 	$L__BB5_198;

$L__BB5_194:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r518, %temp}, %fd24;
	}
	and.b32  	%r519, %r143, 2147483647;
	setp.ne.s32 	%p207, %r519, 2146435072;
	setp.ne.s32 	%p208, %r518, 0;
	or.pred  	%p209, %p207, %p208;
	@%p209 bra 	$L__BB5_198;

	setp.gt.s32 	%p210, %r3, -1;
	selp.b32 	%r520, 2146435072, 0, %p210;
	mov.u32 	%r521, 0;
	setp.ne.s32 	%p211, %r144, 1071644672;
	and.pred  	%p212, %p211, %p7;
	or.b32  	%r522, %r520, -2147483648;
	selp.b32 	%r523, %r522, %r520, %p212;
	mov.b64 	%fd507, {%r521, %r523};

$L__BB5_198:
	add.rn.f32 	%f317, %f57, 0fC2D20000;
	mul.rn.f64 	%fd440, %fd507, 0d3FB999999999999A;
	setp.eq.f32 	%p216, %f317, 0f3F800000;
	selp.f64 	%fd441, 0d3FB999999999999A, %fd440, %p216;
	add.rn.f64 	%fd442, %fd147, %fd441;
	add.rn.f64 	%fd443, %fd144, %fd442;
	mul.rn.f64 	%fd444, %fd145, 0d3FB999999999999A;
	add.rn.f64 	%fd445, %fd444, %fd443;
	cvt.rn.f32.f64 	%f265, %fd131;
	cvt.f64.f32 	%fd446, %f265;
	mul.rn.f64 	%fd447, %fd446, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f266, %fd447;
	cvt.f64.f32 	%fd448, %f266;
	add.rn.f64 	%fd158, %fd445, %fd448;
	cvt.f64.f32 	%fd449, %f56;
	div.rn.f64 	%fd450, %fd449, 0d4066800000000000;
	mul.rn.f64 	%fd451, %fd450, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f86, %fd451;
	mul.rn.f32 	%f267, %f86, 0f3F22F983;
	cvt.rni.s32.f32 	%r628, %f267;
	cvt.rn.f32.s32 	%f268, %r628;
	mov.f32 	%f269, 0fBFC90FDA;
	fma.rn.f32 	%f270, %f268, %f269, %f86;
	mov.f32 	%f271, 0fB3A22168;
	fma.rn.f32 	%f272, %f268, %f271, %f270;
	mov.f32 	%f273, 0fA7C234C5;
	fma.rn.f32 	%f341, %f268, %f273, %f272;
	abs.f32 	%f88, %f86;
	setp.ltu.f32 	%p217, %f88, 0f47CE4780;
	mov.u32 	%r624, %r628;
	mov.f32 	%f338, %f341;
	@%p217 bra 	$L__BB5_206;

	setp.eq.f32 	%p218, %f88, 0f7F800000;
	@%p218 bra 	$L__BB5_205;
	bra.uni 	$L__BB5_200;

$L__BB5_205:
	mov.f32 	%f276, 0f00000000;
	mul.rn.f32 	%f338, %f86, %f276;
	mov.u32 	%r624, 0;
	bra.uni 	$L__BB5_206;

$L__BB5_200:
	mov.b32 	%r146, %f86;
	bfe.u32 	%r530, %r146, 23, 8;
	add.s32 	%r147, %r530, -128;
	shl.b32 	%r531, %r146, 8;
	or.b32  	%r148, %r531, -2147483648;
	shr.u32 	%r149, %r147, 5;
	mov.u64 	%rd233, 0;
	mov.u32 	%r621, 0;
	mov.u64 	%rd232, __cudart_i2opi_f;
	mov.u64 	%rd231, %rd1;

$L__BB5_201:
	.pragma "nounroll";
	ld.global.nc.u32 	%r532, [%rd232];
	mad.wide.u32 	%rd178, %r532, %r148, %rd233;
	shr.u64 	%rd233, %rd178, 32;
	st.local.u32 	[%rd231], %rd178;
	add.s64 	%rd232, %rd232, 4;
	add.s64 	%rd231, %rd231, 4;
	add.s32 	%r621, %r621, 1;
	setp.ne.s32 	%p219, %r621, 6;
	@%p219 bra 	$L__BB5_201;

	add.s64 	%rd210, %rd1, 24;
	st.local.u32 	[%rd210], %rd233;
	mov.u32 	%r533, 4;
	sub.s32 	%r152, %r533, %r149;
	mov.u32 	%r534, 6;
	sub.s32 	%r535, %r534, %r149;
	mul.wide.s32 	%rd179, %r535, 4;
	add.s64 	%rd180, %rd1, %rd179;
	ld.local.u32 	%r622, [%rd180];
	ld.local.u32 	%r623, [%rd180+-4];
	and.b32  	%r155, %r147, 31;
	setp.eq.s32 	%p220, %r155, 0;
	@%p220 bra 	$L__BB5_204;

	mov.u32 	%r536, 32;
	sub.s32 	%r537, %r536, %r155;
	shr.u32 	%r538, %r623, %r537;
	shl.b32 	%r539, %r622, %r155;
	add.s32 	%r622, %r538, %r539;
	mul.wide.s32 	%rd181, %r152, 4;
	add.s64 	%rd182, %rd1, %rd181;
	ld.local.u32 	%r540, [%rd182];
	shr.u32 	%r541, %r540, %r537;
	shl.b32 	%r542, %r623, %r155;
	add.s32 	%r623, %r541, %r542;

$L__BB5_204:
	and.b32  	%r543, %r146, -2147483648;
	shr.u32 	%r544, %r623, 30;
	shl.b32 	%r545, %r622, 2;
	or.b32  	%r546, %r544, %r545;
	shr.u32 	%r547, %r546, 31;
	shr.u32 	%r548, %r622, 30;
	add.s32 	%r549, %r547, %r548;
	neg.s32 	%r550, %r549;
	setp.eq.s32 	%p221, %r543, 0;
	selp.b32 	%r624, %r549, %r550, %p221;
	setp.ne.s32 	%p222, %r547, 0;
	xor.b32  	%r551, %r543, -2147483648;
	selp.b32 	%r552, %r551, %r543, %p222;
	selp.b32 	%r553, -1, 0, %p222;
	xor.b32  	%r554, %r546, %r553;
	shl.b32 	%r555, %r623, 2;
	xor.b32  	%r556, %r555, %r553;
	cvt.u64.u32 	%rd183, %r554;
	cvt.u64.u32 	%rd184, %r556;
	bfi.b64 	%rd185, %rd183, %rd184, 32, 32;
	cvt.rn.f64.s64 	%fd452, %rd185;
	mul.rn.f64 	%fd453, %fd452, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f274, %fd453;
	setp.eq.s32 	%p223, %r552, 0;
	neg.f32 	%f275, %f274;
	selp.f32 	%f338, %f274, %f275, %p223;

$L__BB5_206:
	and.b32  	%r162, %r624, 1;
	setp.eq.s32 	%p224, %r162, 0;
	selp.f32 	%f92, %f338, 0f3F800000, %p224;
	mul.rn.f32 	%f93, %f338, %f338;
	mov.f32 	%f339, 0fB94D4153;
	@%p224 bra 	$L__BB5_208;

	mov.f32 	%f278, 0fBAB607ED;
	mov.f32 	%f279, 0f37CBAC00;
	fma.rn.f32 	%f339, %f279, %f93, %f278;

$L__BB5_208:
	selp.f32 	%f280, 0f3C0885E4, 0f3D2AAABB, %p224;
	fma.rn.f32 	%f281, %f339, %f93, %f280;
	selp.f32 	%f282, 0fBE2AAAA8, 0fBEFFFFFF, %p224;
	fma.rn.f32 	%f283, %f281, %f93, %f282;
	mov.f32 	%f284, 0f00000000;
	fma.rn.f32 	%f285, %f93, %f92, %f284;
	fma.rn.f32 	%f340, %f283, %f285, %f92;
	and.b32  	%r558, %r624, 2;
	setp.eq.s32 	%p226, %r558, 0;
	@%p226 bra 	$L__BB5_210;

	mov.f32 	%f287, 0fBF800000;
	fma.rn.f32 	%f340, %f340, %f287, %f284;

$L__BB5_210:
	@%p217 bra 	$L__BB5_218;

	setp.eq.f32 	%p228, %f88, 0f7F800000;
	@%p228 bra 	$L__BB5_217;
	bra.uni 	$L__BB5_212;

$L__BB5_217:
	mov.f32 	%f290, 0f00000000;
	mul.rn.f32 	%f341, %f86, %f290;
	mov.u32 	%r628, 0;
	bra.uni 	$L__BB5_218;

$L__BB5_212:
	mov.b32 	%r163, %f86;
	bfe.u32 	%r560, %r163, 23, 8;
	add.s32 	%r164, %r560, -128;
	shl.b32 	%r561, %r163, 8;
	or.b32  	%r165, %r561, -2147483648;
	shr.u32 	%r166, %r164, 5;
	mov.u64 	%rd236, 0;
	mov.u32 	%r625, 0;
	mov.u64 	%rd235, __cudart_i2opi_f;
	mov.u64 	%rd234, %rd1;

$L__BB5_213:
	.pragma "nounroll";
	ld.global.nc.u32 	%r562, [%rd235];
	mad.wide.u32 	%rd188, %r562, %r165, %rd236;
	shr.u64 	%rd236, %rd188, 32;
	st.local.u32 	[%rd234], %rd188;
	add.s64 	%rd235, %rd235, 4;
	add.s64 	%rd234, %rd234, 4;
	add.s32 	%r625, %r625, 1;
	setp.ne.s32 	%p229, %r625, 6;
	@%p229 bra 	$L__BB5_213;

	add.s64 	%rd211, %rd1, 24;
	st.local.u32 	[%rd211], %rd236;
	mov.u32 	%r563, 4;
	sub.s32 	%r169, %r563, %r166;
	mov.u32 	%r564, 6;
	sub.s32 	%r565, %r564, %r166;
	mul.wide.s32 	%rd189, %r565, 4;
	add.s64 	%rd190, %rd1, %rd189;
	ld.local.u32 	%r626, [%rd190];
	ld.local.u32 	%r627, [%rd190+-4];
	and.b32  	%r172, %r164, 31;
	setp.eq.s32 	%p230, %r172, 0;
	@%p230 bra 	$L__BB5_216;

	mov.u32 	%r566, 32;
	sub.s32 	%r567, %r566, %r172;
	shr.u32 	%r568, %r627, %r567;
	shl.b32 	%r569, %r626, %r172;
	add.s32 	%r626, %r568, %r569;
	mul.wide.s32 	%rd191, %r169, 4;
	add.s64 	%rd192, %rd1, %rd191;
	ld.local.u32 	%r570, [%rd192];
	shr.u32 	%r571, %r570, %r567;
	shl.b32 	%r572, %r627, %r172;
	add.s32 	%r627, %r571, %r572;

$L__BB5_216:
	and.b32  	%r573, %r163, -2147483648;
	shr.u32 	%r574, %r627, 30;
	shl.b32 	%r575, %r626, 2;
	or.b32  	%r576, %r574, %r575;
	shr.u32 	%r577, %r576, 31;
	shr.u32 	%r578, %r626, 30;
	add.s32 	%r579, %r577, %r578;
	neg.s32 	%r580, %r579;
	setp.eq.s32 	%p231, %r573, 0;
	selp.b32 	%r628, %r579, %r580, %p231;
	setp.ne.s32 	%p232, %r577, 0;
	xor.b32  	%r581, %r573, -2147483648;
	selp.b32 	%r582, %r581, %r573, %p232;
	selp.b32 	%r583, -1, 0, %p232;
	xor.b32  	%r584, %r576, %r583;
	shl.b32 	%r585, %r627, 2;
	xor.b32  	%r586, %r585, %r583;
	cvt.u64.u32 	%rd193, %r584;
	cvt.u64.u32 	%rd194, %r586;
	bfi.b64 	%rd195, %rd193, %rd194, 32, 32;
	cvt.rn.f64.s64 	%fd454, %rd195;
	mul.rn.f64 	%fd455, %fd454, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f288, %fd455;
	setp.eq.s32 	%p233, %r582, 0;
	neg.f32 	%f289, %f288;
	selp.f32 	%f341, %f288, %f289, %p233;

$L__BB5_218:
	add.s32 	%r179, %r628, 1;
	and.b32  	%r180, %r179, 1;
	setp.eq.s32 	%p8, %r180, 0;
	mul.rn.f32 	%f102, %f341, %f341;
	mov.f32 	%f342, 0fB94D4153;
	@%p8 bra 	$L__BB5_220;

	mov.f32 	%f292, 0fBAB607ED;
	mov.f32 	%f293, 0f37CBAC00;
	fma.rn.f32 	%f342, %f293, %f102, %f292;

$L__BB5_220:
	selp.f32 	%f294, %f341, 0f3F800000, %p8;
	selp.f32 	%f295, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f296, %f342, %f102, %f295;
	selp.f32 	%f297, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f298, %f296, %f102, %f297;
	mov.f32 	%f299, 0f00000000;
	fma.rn.f32 	%f300, %f102, %f294, %f299;
	fma.rn.f32 	%f343, %f298, %f300, %f294;
	and.b32  	%r588, %r179, 2;
	setp.eq.s32 	%p235, %r588, 0;
	@%p235 bra 	$L__BB5_222;

	mov.f32 	%f302, 0fBF800000;
	fma.rn.f32 	%f343, %f343, %f302, %f299;

$L__BB5_222:
	cvt.f64.f32 	%fd456, %f340;
	mul.rn.f64 	%fd457, %fd456, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd458, %fd457, %fd456;
	add.rn.f64 	%fd459, %fd458, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f303, %fd459;
	sqrt.rn.f32 	%f304, %f303;
	mov.f32 	%f305, 0fCAC2A60A;
	div.rn.f32 	%f306, %f305, %f304;
	mul.rn.f32 	%f307, %f306, %f343;
	cvt.f64.f32 	%fd460, %f307;
	mul.rn.f64 	%fd461, %fd460, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f308, %fd158;
	cvt.f64.f32 	%fd462, %f308;
	mul.rn.f64 	%fd463, %fd462, 0d4066800000000000;
	div.rn.f64 	%fd464, %fd463, %fd461;
	cvt.rn.f32.f64 	%f309, %fd464;
	add.rn.f32 	%f310, %f57, %f309;
	st.global.f32 	[%rd30], %f310;
	mul.rn.f32 	%f311, %f304, %f303;
	cvt.f64.f32 	%fd465, %f311;
	mov.f64 	%fd466, 0dC1582B102DE355C1;
	div.rn.f64 	%fd467, %fd466, %fd465;
	mul.rn.f64 	%fd468, %fd467, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f312, %fd146;
	cvt.f64.f32 	%fd469, %f312;
	mul.rn.f64 	%fd470, %fd469, 0d4066800000000000;
	div.rn.f64 	%fd471, %fd470, %fd468;
	cvt.rn.f32.f64 	%f313, %fd471;
	add.rn.f32 	%f314, %f56, %f313;
	st.global.f32 	[%rd37], %f314;

$L__BB5_223:
	ret;

}
	// .globl	gcj02_to_wgs84_exact_cuda_float
.visible .entry gcj02_to_wgs84_exact_cuda_float(
	.param .u32 gcj02_to_wgs84_exact_cuda_float_param_0,
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_1,
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_2,
	.param .f32 gcj02_to_wgs84_exact_cuda_float_param_3,
	.param .u8 gcj02_to_wgs84_exact_cuda_float_param_4,
	.param .u32 gcj02_to_wgs84_exact_cuda_float_param_5,
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_6,
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_7
)
{
	.local .align 4 .b8 	__local_depot6[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<367>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<469>;
	.reg .b32 	%r<892>;
	.reg .f64 	%fd<1032>;
	.reg .b64 	%rd<331>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r244, [gcj02_to_wgs84_exact_cuda_float_param_0];
	ld.param.u64 	%rd73, [gcj02_to_wgs84_exact_cuda_float_param_1];
	ld.param.u64 	%rd74, [gcj02_to_wgs84_exact_cuda_float_param_2];
	ld.param.f32 	%f148, [gcj02_to_wgs84_exact_cuda_float_param_3];
	add.u64 	%rd77, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r245, %ntid.x;
	mov.u32 	%r246, %ctaid.x;
	mov.u32 	%r247, %tid.x;
	mad.lo.s32 	%r1, %r246, %r245, %r247;
	setp.ge.s32 	%p9, %r1, %r244;
	@%p9 bra 	$L__BB6_362;

	cvta.to.global.u64 	%rd97, %rd73;
	mul.wide.s32 	%rd98, %r1, 4;
	add.s64 	%rd99, %rd97, %rd98;
	cvta.to.global.u64 	%rd100, %rd74;
	add.s64 	%rd101, %rd100, %rd98;
	ld.global.f32 	%f1, [%rd99];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd101];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd317, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd317;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd318, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd318;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r248, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r249}, %fd4;
	}
	and.b32  	%r250, %r249, 2147483647;
	setp.eq.s32 	%p10, %r250, 2146435072;
	setp.eq.s32 	%p11, %r248, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB6_4;
	bra.uni 	$L__BB6_2;

$L__BB6_4:
	mov.f64 	%fd328, 0d0000000000000000;
	mul.rn.f64 	%fd960, %fd4, %fd328;
	mov.u32 	%r838, 0;
	bra.uni 	$L__BB6_5;

$L__BB6_2:
	mul.rn.f64 	%fd319, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r838, %fd319;
	st.local.u32 	[%rd8], %r838;
	cvt.rn.f64.s32 	%fd320, %r838;
	neg.f64 	%fd321, %fd320;
	mov.f64 	%fd322, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd323, %fd321, %fd322, %fd4;
	mov.f64 	%fd324, 0d3C91A62633145C00;
	fma.rn.f64 	%fd325, %fd321, %fd324, %fd323;
	mov.f64 	%fd326, 0d397B839A252049C0;
	fma.rn.f64 	%fd960, %fd321, %fd326, %fd325;
	abs.f64 	%fd327, %fd4;
	setp.ltu.f64 	%p13, %fd327, 0d41E0000000000000;
	@%p13 bra 	$L__BB6_5;

	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd960, [retval0+0];
	} // callseq 48
	ld.local.u32 	%r838, [%rd8];

$L__BB6_5:
	and.b32  	%r252, %r838, 1;
	shl.b32 	%r253, %r838, 3;
	and.b32  	%r254, %r253, 8;
	setp.eq.s32 	%p14, %r252, 0;
	selp.f64 	%fd329, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd105, %r254, 8;
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	add.s64 	%rd107, %rd106, %rd105;
	ld.global.nc.f64 	%fd330, [%rd107+8];
	mul.rn.f64 	%fd9, %fd960, %fd960;
	fma.rn.f64 	%fd331, %fd329, %fd9, %fd330;
	ld.global.nc.f64 	%fd332, [%rd107+16];
	fma.rn.f64 	%fd333, %fd331, %fd9, %fd332;
	ld.global.nc.f64 	%fd334, [%rd107+24];
	fma.rn.f64 	%fd335, %fd333, %fd9, %fd334;
	ld.global.nc.f64 	%fd336, [%rd107+32];
	fma.rn.f64 	%fd337, %fd335, %fd9, %fd336;
	ld.global.nc.f64 	%fd338, [%rd107+40];
	fma.rn.f64 	%fd339, %fd337, %fd9, %fd338;
	ld.global.nc.f64 	%fd340, [%rd107+48];
	fma.rn.f64 	%fd10, %fd339, %fd9, %fd340;
	fma.rn.f64 	%fd962, %fd10, %fd960, %fd960;
	@%p14 bra 	$L__BB6_7;

	mov.f64 	%fd341, 0d3FF0000000000000;
	fma.rn.f64 	%fd962, %fd10, %fd9, %fd341;

$L__BB6_7:
	and.b32  	%r255, %r838, 2;
	setp.eq.s32 	%p15, %r255, 0;
	@%p15 bra 	$L__BB6_9;

	mov.f64 	%fd342, 0d0000000000000000;
	mov.f64 	%fd343, 0dBFF0000000000000;
	fma.rn.f64 	%fd962, %fd962, %fd343, %fd342;

$L__BB6_9:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r256, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r257}, %fd16;
	}
	and.b32  	%r258, %r257, 2147483647;
	setp.eq.s32 	%p16, %r258, 2146435072;
	setp.eq.s32 	%p17, %r256, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB6_12;
	bra.uni 	$L__BB6_10;

$L__BB6_12:
	mov.f64 	%fd353, 0d0000000000000000;
	mul.rn.f64 	%fd963, %fd16, %fd353;
	mov.u32 	%r839, 0;
	bra.uni 	$L__BB6_13;

$L__BB6_10:
	mul.rn.f64 	%fd344, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r839, %fd344;
	st.local.u32 	[%rd8], %r839;
	cvt.rn.f64.s32 	%fd345, %r839;
	neg.f64 	%fd346, %fd345;
	mov.f64 	%fd347, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd348, %fd346, %fd347, %fd16;
	mov.f64 	%fd349, 0d3C91A62633145C00;
	fma.rn.f64 	%fd350, %fd346, %fd349, %fd348;
	mov.f64 	%fd351, 0d397B839A252049C0;
	fma.rn.f64 	%fd963, %fd346, %fd351, %fd350;
	abs.f64 	%fd352, %fd16;
	setp.ltu.f64 	%p19, %fd352, 0d41E0000000000000;
	@%p19 bra 	$L__BB6_13;

	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd963, [retval0+0];
	} // callseq 49
	ld.local.u32 	%r839, [%rd8];

$L__BB6_13:
	and.b32  	%r260, %r839, 1;
	shl.b32 	%r261, %r839, 3;
	and.b32  	%r262, %r261, 8;
	setp.eq.s32 	%p20, %r260, 0;
	selp.f64 	%fd354, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd109, %r262, 8;
	add.s64 	%rd111, %rd106, %rd109;
	ld.global.nc.f64 	%fd355, [%rd111+8];
	mul.rn.f64 	%fd21, %fd963, %fd963;
	fma.rn.f64 	%fd356, %fd354, %fd21, %fd355;
	ld.global.nc.f64 	%fd357, [%rd111+16];
	fma.rn.f64 	%fd358, %fd356, %fd21, %fd357;
	ld.global.nc.f64 	%fd359, [%rd111+24];
	fma.rn.f64 	%fd360, %fd358, %fd21, %fd359;
	ld.global.nc.f64 	%fd361, [%rd111+32];
	fma.rn.f64 	%fd362, %fd360, %fd21, %fd361;
	ld.global.nc.f64 	%fd363, [%rd111+40];
	fma.rn.f64 	%fd364, %fd362, %fd21, %fd363;
	ld.global.nc.f64 	%fd365, [%rd111+48];
	fma.rn.f64 	%fd22, %fd364, %fd21, %fd365;
	fma.rn.f64 	%fd965, %fd22, %fd963, %fd963;
	@%p20 bra 	$L__BB6_15;

	mov.f64 	%fd366, 0d3FF0000000000000;
	fma.rn.f64 	%fd965, %fd22, %fd21, %fd366;

$L__BB6_15:
	and.b32  	%r263, %r839, 2;
	setp.eq.s32 	%p21, %r263, 0;
	@%p21 bra 	$L__BB6_17;

	mov.f64 	%fd367, 0d0000000000000000;
	mov.f64 	%fd368, 0dBFF0000000000000;
	fma.rn.f64 	%fd965, %fd965, %fd368, %fd367;

$L__BB6_17:
	mul.rn.f64 	%fd369, %fd965, 0d4034000000000000;
	mul.rn.f64 	%fd370, %fd962, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd370, %fd369;
	mul.rn.f32 	%f149, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r843, %f149;
	cvt.rn.f32.s32 	%f150, %r843;
	mov.f32 	%f151, 0fBFC90FDA;
	fma.rn.f32 	%f152, %f150, %f151, %f6;
	mov.f32 	%f153, 0fB3A22168;
	fma.rn.f32 	%f154, %f150, %f153, %f152;
	mov.f32 	%f155, 0fA7C234C5;
	fma.rn.f32 	%f434, %f150, %f155, %f154;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p22, %f8, 0f47CE4780;
	add.s64 	%rd23, %rd1, 24;
	@%p22 bra 	$L__BB6_25;

	setp.eq.f32 	%p23, %f8, 0f7F800000;
	@%p23 bra 	$L__BB6_24;
	bra.uni 	$L__BB6_19;

$L__BB6_24:
	mov.f32 	%f158, 0f00000000;
	mul.rn.f32 	%f434, %f6, %f158;
	mov.u32 	%r843, 0;
	bra.uni 	$L__BB6_25;

$L__BB6_19:
	mov.b32 	%r9, %f6;
	bfe.u32 	%r265, %r9, 23, 8;
	add.s32 	%r10, %r265, -128;
	shl.b32 	%r266, %r9, 8;
	or.b32  	%r11, %r266, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd309, 0;
	mov.u32 	%r840, 0;
	mov.u64 	%rd308, __cudart_i2opi_f;
	mov.u64 	%rd307, %rd1;

$L__BB6_20:
	.pragma "nounroll";
	ld.global.nc.u32 	%r267, [%rd308];
	mad.wide.u32 	%rd114, %r267, %r11, %rd309;
	shr.u64 	%rd309, %rd114, 32;
	st.local.u32 	[%rd307], %rd114;
	add.s64 	%rd308, %rd308, 4;
	add.s64 	%rd307, %rd307, 4;
	add.s32 	%r840, %r840, 1;
	setp.ne.s32 	%p24, %r840, 6;
	@%p24 bra 	$L__BB6_20;

	st.local.u32 	[%rd23], %rd309;
	mov.u32 	%r268, 4;
	sub.s32 	%r15, %r268, %r12;
	mov.u32 	%r269, 6;
	sub.s32 	%r270, %r269, %r12;
	mul.wide.s32 	%rd115, %r270, 4;
	add.s64 	%rd116, %rd1, %rd115;
	ld.local.u32 	%r841, [%rd116];
	ld.local.u32 	%r842, [%rd116+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p25, %r18, 0;
	@%p25 bra 	$L__BB6_23;

	mov.u32 	%r271, 32;
	sub.s32 	%r272, %r271, %r18;
	shr.u32 	%r273, %r842, %r272;
	shl.b32 	%r274, %r841, %r18;
	add.s32 	%r841, %r273, %r274;
	mul.wide.s32 	%rd117, %r15, 4;
	add.s64 	%rd118, %rd1, %rd117;
	ld.local.u32 	%r275, [%rd118];
	shr.u32 	%r276, %r275, %r272;
	shl.b32 	%r277, %r842, %r18;
	add.s32 	%r842, %r276, %r277;

$L__BB6_23:
	and.b32  	%r278, %r9, -2147483648;
	shr.u32 	%r279, %r842, 30;
	shl.b32 	%r280, %r841, 2;
	or.b32  	%r281, %r279, %r280;
	shr.u32 	%r282, %r281, 31;
	shr.u32 	%r283, %r841, 30;
	add.s32 	%r284, %r282, %r283;
	neg.s32 	%r285, %r284;
	setp.eq.s32 	%p26, %r278, 0;
	selp.b32 	%r843, %r284, %r285, %p26;
	setp.ne.s32 	%p27, %r282, 0;
	xor.b32  	%r286, %r278, -2147483648;
	selp.b32 	%r287, %r286, %r278, %p27;
	selp.b32 	%r288, -1, 0, %p27;
	xor.b32  	%r289, %r281, %r288;
	shl.b32 	%r290, %r842, 2;
	xor.b32  	%r291, %r290, %r288;
	cvt.u64.u32 	%rd119, %r289;
	cvt.u64.u32 	%rd120, %r291;
	bfi.b64 	%rd121, %rd119, %rd120, 32, 32;
	cvt.rn.f64.s64 	%fd371, %rd121;
	mul.rn.f64 	%fd372, %fd371, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f156, %fd372;
	setp.eq.s32 	%p28, %r287, 0;
	neg.f32 	%f157, %f156;
	selp.f32 	%f434, %f156, %f157, %p28;

$L__BB6_25:
	and.b32  	%r25, %r843, 1;
	setp.eq.s32 	%p29, %r25, 0;
	selp.f32 	%f12, %f434, 0f3F800000, %p29;
	mul.rn.f32 	%f13, %f434, %f434;
	mov.f32 	%f435, 0fB94D4153;
	@%p29 bra 	$L__BB6_27;

	mov.f32 	%f160, 0fBAB607ED;
	mov.f32 	%f161, 0f37CBAC00;
	fma.rn.f32 	%f435, %f161, %f13, %f160;

$L__BB6_27:
	selp.f32 	%f162, 0f3C0885E4, 0f3D2AAABB, %p29;
	fma.rn.f32 	%f163, %f435, %f13, %f162;
	selp.f32 	%f164, 0fBE2AAAA8, 0fBEFFFFFF, %p29;
	fma.rn.f32 	%f165, %f163, %f13, %f164;
	mov.f32 	%f166, 0f00000000;
	fma.rn.f32 	%f167, %f13, %f12, %f166;
	fma.rn.f32 	%f436, %f165, %f167, %f12;
	and.b32  	%r293, %r843, 2;
	setp.eq.s32 	%p31, %r293, 0;
	@%p31 bra 	$L__BB6_29;

	mov.f32 	%f169, 0fBF800000;
	fma.rn.f32 	%f436, %f436, %f169, %f166;

$L__BB6_29:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r294, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r295}, %fd30;
	}
	and.b32  	%r296, %r295, 2147483647;
	setp.eq.s32 	%p32, %r296, 2146435072;
	setp.eq.s32 	%p33, %r294, 0;
	and.pred  	%p34, %p33, %p32;
	@%p34 bra 	$L__BB6_32;
	bra.uni 	$L__BB6_30;

$L__BB6_32:
	mov.f64 	%fd382, 0d0000000000000000;
	mul.rn.f64 	%fd966, %fd30, %fd382;
	mov.u32 	%r844, 0;
	bra.uni 	$L__BB6_33;

$L__BB6_30:
	mul.rn.f64 	%fd373, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r844, %fd373;
	st.local.u32 	[%rd8], %r844;
	cvt.rn.f64.s32 	%fd374, %r844;
	neg.f64 	%fd375, %fd374;
	mov.f64 	%fd376, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd377, %fd375, %fd376, %fd30;
	mov.f64 	%fd378, 0d3C91A62633145C00;
	fma.rn.f64 	%fd379, %fd375, %fd378, %fd377;
	mov.f64 	%fd380, 0d397B839A252049C0;
	fma.rn.f64 	%fd966, %fd375, %fd380, %fd379;
	abs.f64 	%fd381, %fd30;
	setp.ltu.f64 	%p35, %fd381, 0d41E0000000000000;
	@%p35 bra 	$L__BB6_33;

	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd966, [retval0+0];
	} // callseq 50
	ld.local.u32 	%r844, [%rd8];

$L__BB6_33:
	and.b32  	%r298, %r844, 1;
	shl.b32 	%r299, %r844, 3;
	and.b32  	%r300, %r299, 8;
	setp.eq.s32 	%p36, %r298, 0;
	selp.f64 	%fd383, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p36;
	mul.wide.s32 	%rd123, %r300, 8;
	add.s64 	%rd125, %rd106, %rd123;
	ld.global.nc.f64 	%fd384, [%rd125+8];
	mul.rn.f64 	%fd35, %fd966, %fd966;
	fma.rn.f64 	%fd385, %fd383, %fd35, %fd384;
	ld.global.nc.f64 	%fd386, [%rd125+16];
	fma.rn.f64 	%fd387, %fd385, %fd35, %fd386;
	ld.global.nc.f64 	%fd388, [%rd125+24];
	fma.rn.f64 	%fd389, %fd387, %fd35, %fd388;
	ld.global.nc.f64 	%fd390, [%rd125+32];
	fma.rn.f64 	%fd391, %fd389, %fd35, %fd390;
	ld.global.nc.f64 	%fd392, [%rd125+40];
	fma.rn.f64 	%fd393, %fd391, %fd35, %fd392;
	ld.global.nc.f64 	%fd394, [%rd125+48];
	fma.rn.f64 	%fd36, %fd393, %fd35, %fd394;
	fma.rn.f64 	%fd968, %fd36, %fd966, %fd966;
	@%p36 bra 	$L__BB6_35;

	mov.f64 	%fd395, 0d3FF0000000000000;
	fma.rn.f64 	%fd968, %fd36, %fd35, %fd395;

$L__BB6_35:
	and.b32  	%r301, %r844, 2;
	setp.eq.s32 	%p37, %r301, 0;
	@%p37 bra 	$L__BB6_37;

	mov.f64 	%fd396, 0d0000000000000000;
	mov.f64 	%fd397, 0dBFF0000000000000;
	fma.rn.f64 	%fd968, %fd968, %fd397, %fd396;

$L__BB6_37:
	mul.rn.f64 	%fd398, %fd968, 0d4044000000000000;
	cvt.f64.f32 	%fd399, %f436;
	mul.rn.f64 	%fd400, %fd399, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd400, %fd398;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r302, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd43;
	}
	and.b32  	%r304, %r303, 2147483647;
	setp.eq.s32 	%p38, %r304, 2146435072;
	setp.eq.s32 	%p39, %r302, 0;
	and.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB6_40;
	bra.uni 	$L__BB6_38;

$L__BB6_40:
	mov.f64 	%fd410, 0d0000000000000000;
	mul.rn.f64 	%fd969, %fd43, %fd410;
	mov.u32 	%r845, 0;
	bra.uni 	$L__BB6_41;

$L__BB6_38:
	mul.rn.f64 	%fd401, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r845, %fd401;
	st.local.u32 	[%rd8], %r845;
	cvt.rn.f64.s32 	%fd402, %r845;
	neg.f64 	%fd403, %fd402;
	mov.f64 	%fd404, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd405, %fd403, %fd404, %fd43;
	mov.f64 	%fd406, 0d3C91A62633145C00;
	fma.rn.f64 	%fd407, %fd403, %fd406, %fd405;
	mov.f64 	%fd408, 0d397B839A252049C0;
	fma.rn.f64 	%fd969, %fd403, %fd408, %fd407;
	abs.f64 	%fd409, %fd43;
	setp.ltu.f64 	%p41, %fd409, 0d41E0000000000000;
	@%p41 bra 	$L__BB6_41;

	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd969, [retval0+0];
	} // callseq 51
	ld.local.u32 	%r845, [%rd8];

$L__BB6_41:
	and.b32  	%r306, %r845, 1;
	shl.b32 	%r307, %r845, 3;
	and.b32  	%r308, %r307, 8;
	setp.eq.s32 	%p42, %r306, 0;
	selp.f64 	%fd411, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	mul.wide.s32 	%rd127, %r308, 8;
	add.s64 	%rd129, %rd106, %rd127;
	ld.global.nc.f64 	%fd412, [%rd129+8];
	mul.rn.f64 	%fd48, %fd969, %fd969;
	fma.rn.f64 	%fd413, %fd411, %fd48, %fd412;
	ld.global.nc.f64 	%fd414, [%rd129+16];
	fma.rn.f64 	%fd415, %fd413, %fd48, %fd414;
	ld.global.nc.f64 	%fd416, [%rd129+24];
	fma.rn.f64 	%fd417, %fd415, %fd48, %fd416;
	ld.global.nc.f64 	%fd418, [%rd129+32];
	fma.rn.f64 	%fd419, %fd417, %fd48, %fd418;
	ld.global.nc.f64 	%fd420, [%rd129+40];
	fma.rn.f64 	%fd421, %fd419, %fd48, %fd420;
	ld.global.nc.f64 	%fd422, [%rd129+48];
	fma.rn.f64 	%fd49, %fd421, %fd48, %fd422;
	fma.rn.f64 	%fd971, %fd49, %fd969, %fd969;
	@%p42 bra 	$L__BB6_43;

	mov.f64 	%fd423, 0d3FF0000000000000;
	fma.rn.f64 	%fd971, %fd49, %fd48, %fd423;

$L__BB6_43:
	and.b32  	%r309, %r845, 2;
	setp.eq.s32 	%p43, %r309, 0;
	@%p43 bra 	$L__BB6_45;

	mov.f64 	%fd424, 0d0000000000000000;
	mov.f64 	%fd425, 0dBFF0000000000000;
	fma.rn.f64 	%fd971, %fd971, %fd425, %fd424;

$L__BB6_45:
	mul.rn.f64 	%fd426, %fd971, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd426;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r310, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r311}, %fd56;
	}
	and.b32  	%r312, %r311, 2147483647;
	setp.eq.s32 	%p44, %r312, 2146435072;
	setp.eq.s32 	%p45, %r310, 0;
	and.pred  	%p46, %p45, %p44;
	@%p46 bra 	$L__BB6_48;
	bra.uni 	$L__BB6_46;

$L__BB6_48:
	mov.f64 	%fd436, 0d0000000000000000;
	mul.rn.f64 	%fd972, %fd56, %fd436;
	mov.u32 	%r846, 0;
	bra.uni 	$L__BB6_49;

$L__BB6_46:
	mul.rn.f64 	%fd427, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r846, %fd427;
	st.local.u32 	[%rd8], %r846;
	cvt.rn.f64.s32 	%fd428, %r846;
	neg.f64 	%fd429, %fd428;
	mov.f64 	%fd430, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd431, %fd429, %fd430, %fd56;
	mov.f64 	%fd432, 0d3C91A62633145C00;
	fma.rn.f64 	%fd433, %fd429, %fd432, %fd431;
	mov.f64 	%fd434, 0d397B839A252049C0;
	fma.rn.f64 	%fd972, %fd429, %fd434, %fd433;
	abs.f64 	%fd435, %fd56;
	setp.ltu.f64 	%p47, %fd435, 0d41E0000000000000;
	@%p47 bra 	$L__BB6_49;

	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd972, [retval0+0];
	} // callseq 52
	ld.local.u32 	%r846, [%rd8];

$L__BB6_49:
	and.b32  	%r314, %r846, 1;
	shl.b32 	%r315, %r846, 3;
	and.b32  	%r316, %r315, 8;
	setp.eq.s32 	%p48, %r314, 0;
	selp.f64 	%fd437, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p48;
	mul.wide.s32 	%rd131, %r316, 8;
	add.s64 	%rd133, %rd106, %rd131;
	ld.global.nc.f64 	%fd438, [%rd133+8];
	mul.rn.f64 	%fd61, %fd972, %fd972;
	fma.rn.f64 	%fd439, %fd437, %fd61, %fd438;
	ld.global.nc.f64 	%fd440, [%rd133+16];
	fma.rn.f64 	%fd441, %fd439, %fd61, %fd440;
	ld.global.nc.f64 	%fd442, [%rd133+24];
	fma.rn.f64 	%fd443, %fd441, %fd61, %fd442;
	ld.global.nc.f64 	%fd444, [%rd133+32];
	fma.rn.f64 	%fd445, %fd443, %fd61, %fd444;
	ld.global.nc.f64 	%fd446, [%rd133+40];
	fma.rn.f64 	%fd447, %fd445, %fd61, %fd446;
	ld.global.nc.f64 	%fd448, [%rd133+48];
	fma.rn.f64 	%fd62, %fd447, %fd61, %fd448;
	fma.rn.f64 	%fd974, %fd62, %fd972, %fd972;
	@%p48 bra 	$L__BB6_51;

	mov.f64 	%fd449, 0d3FF0000000000000;
	fma.rn.f64 	%fd974, %fd62, %fd61, %fd449;

$L__BB6_51:
	and.b32  	%r317, %r846, 2;
	setp.eq.s32 	%p49, %r317, 0;
	@%p49 bra 	$L__BB6_53;

	mov.f64 	%fd450, 0d0000000000000000;
	mov.f64 	%fd451, 0dBFF0000000000000;
	fma.rn.f64 	%fd974, %fd974, %fd451, %fd450;

$L__BB6_53:
	mul.rn.f64 	%fd452, %fd974, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd452;
	mul.rn.f32 	%f170, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r850, %f170;
	cvt.rn.f32.s32 	%f171, %r850;
	mov.f32 	%f172, 0fBFC90FDA;
	fma.rn.f32 	%f173, %f171, %f172, %f5;
	mov.f32 	%f174, 0fB3A22168;
	fma.rn.f32 	%f175, %f171, %f174, %f173;
	mov.f32 	%f176, 0fA7C234C5;
	fma.rn.f32 	%f437, %f171, %f176, %f175;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p50, %f20, 0f47CE4780;
	@%p50 bra 	$L__BB6_61;

	setp.eq.f32 	%p51, %f20, 0f7F800000;
	@%p51 bra 	$L__BB6_60;
	bra.uni 	$L__BB6_55;

$L__BB6_60:
	mov.f32 	%f179, 0f00000000;
	mul.rn.f32 	%f437, %f5, %f179;
	mov.u32 	%r850, 0;
	bra.uni 	$L__BB6_61;

$L__BB6_55:
	mov.b32 	%r36, %f5;
	bfe.u32 	%r319, %r36, 23, 8;
	add.s32 	%r37, %r319, -128;
	shl.b32 	%r320, %r36, 8;
	or.b32  	%r38, %r320, -2147483648;
	shr.u32 	%r39, %r37, 5;
	mov.u64 	%rd312, 0;
	mov.u32 	%r847, 0;
	mov.u64 	%rd311, __cudart_i2opi_f;
	mov.u64 	%rd310, %rd1;

$L__BB6_56:
	.pragma "nounroll";
	ld.global.nc.u32 	%r321, [%rd311];
	mad.wide.u32 	%rd136, %r321, %r38, %rd312;
	shr.u64 	%rd312, %rd136, 32;
	st.local.u32 	[%rd310], %rd136;
	add.s64 	%rd311, %rd311, 4;
	add.s64 	%rd310, %rd310, 4;
	add.s32 	%r847, %r847, 1;
	setp.ne.s32 	%p52, %r847, 6;
	@%p52 bra 	$L__BB6_56;

	st.local.u32 	[%rd23], %rd312;
	mov.u32 	%r322, 4;
	sub.s32 	%r42, %r322, %r39;
	mov.u32 	%r323, 6;
	sub.s32 	%r324, %r323, %r39;
	mul.wide.s32 	%rd137, %r324, 4;
	add.s64 	%rd138, %rd1, %rd137;
	ld.local.u32 	%r848, [%rd138];
	ld.local.u32 	%r849, [%rd138+-4];
	and.b32  	%r45, %r37, 31;
	setp.eq.s32 	%p53, %r45, 0;
	@%p53 bra 	$L__BB6_59;

	mov.u32 	%r325, 32;
	sub.s32 	%r326, %r325, %r45;
	shr.u32 	%r327, %r849, %r326;
	shl.b32 	%r328, %r848, %r45;
	add.s32 	%r848, %r327, %r328;
	mul.wide.s32 	%rd139, %r42, 4;
	add.s64 	%rd140, %rd1, %rd139;
	ld.local.u32 	%r329, [%rd140];
	shr.u32 	%r330, %r329, %r326;
	shl.b32 	%r331, %r849, %r45;
	add.s32 	%r849, %r330, %r331;

$L__BB6_59:
	and.b32  	%r332, %r36, -2147483648;
	shr.u32 	%r333, %r849, 30;
	shl.b32 	%r334, %r848, 2;
	or.b32  	%r335, %r333, %r334;
	shr.u32 	%r336, %r335, 31;
	shr.u32 	%r337, %r848, 30;
	add.s32 	%r338, %r336, %r337;
	neg.s32 	%r339, %r338;
	setp.eq.s32 	%p54, %r332, 0;
	selp.b32 	%r850, %r338, %r339, %p54;
	setp.ne.s32 	%p55, %r336, 0;
	xor.b32  	%r340, %r332, -2147483648;
	selp.b32 	%r341, %r340, %r332, %p55;
	selp.b32 	%r342, -1, 0, %p55;
	xor.b32  	%r343, %r335, %r342;
	shl.b32 	%r344, %r849, 2;
	xor.b32  	%r345, %r344, %r342;
	cvt.u64.u32 	%rd141, %r343;
	cvt.u64.u32 	%rd142, %r345;
	bfi.b64 	%rd143, %rd141, %rd142, 32, 32;
	cvt.rn.f64.s64 	%fd453, %rd143;
	mul.rn.f64 	%fd454, %fd453, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f177, %fd454;
	setp.eq.s32 	%p56, %r341, 0;
	neg.f32 	%f178, %f177;
	selp.f32 	%f437, %f177, %f178, %p56;

$L__BB6_61:
	cvt.rn.f32.f64 	%f181, %fd28;
	cvt.f64.f32 	%fd69, %f181;
	and.b32  	%r52, %r850, 1;
	setp.eq.s32 	%p57, %r52, 0;
	selp.f32 	%f24, %f437, 0f3F800000, %p57;
	mul.rn.f32 	%f25, %f437, %f437;
	mov.f32 	%f438, 0fB94D4153;
	@%p57 bra 	$L__BB6_63;

	mov.f32 	%f182, 0fBAB607ED;
	mov.f32 	%f183, 0f37CBAC00;
	fma.rn.f32 	%f438, %f183, %f25, %f182;

$L__BB6_63:
	selp.f32 	%f184, 0f3C0885E4, 0f3D2AAABB, %p57;
	fma.rn.f32 	%f185, %f438, %f25, %f184;
	selp.f32 	%f186, 0fBE2AAAA8, 0fBEFFFFFF, %p57;
	fma.rn.f32 	%f187, %f185, %f25, %f186;
	mov.f32 	%f188, 0f00000000;
	fma.rn.f32 	%f189, %f25, %f24, %f188;
	fma.rn.f32 	%f439, %f187, %f189, %f24;
	and.b32  	%r347, %r850, 2;
	setp.eq.s32 	%p59, %r347, 0;
	@%p59 bra 	$L__BB6_65;

	mov.f32 	%f191, 0fBF800000;
	fma.rn.f32 	%f439, %f439, %f191, %f188;

$L__BB6_65:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r348, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r349}, %fd70;
	}
	and.b32  	%r350, %r349, 2147483647;
	setp.eq.s32 	%p60, %r350, 2146435072;
	setp.eq.s32 	%p61, %r348, 0;
	and.pred  	%p62, %p61, %p60;
	@%p62 bra 	$L__BB6_68;
	bra.uni 	$L__BB6_66;

$L__BB6_68:
	mov.f64 	%fd464, 0d0000000000000000;
	mul.rn.f64 	%fd975, %fd70, %fd464;
	mov.u32 	%r851, 0;
	bra.uni 	$L__BB6_69;

$L__BB6_66:
	mul.rn.f64 	%fd455, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r851, %fd455;
	st.local.u32 	[%rd8], %r851;
	cvt.rn.f64.s32 	%fd456, %r851;
	neg.f64 	%fd457, %fd456;
	mov.f64 	%fd458, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd459, %fd457, %fd458, %fd70;
	mov.f64 	%fd460, 0d3C91A62633145C00;
	fma.rn.f64 	%fd461, %fd457, %fd460, %fd459;
	mov.f64 	%fd462, 0d397B839A252049C0;
	fma.rn.f64 	%fd975, %fd457, %fd462, %fd461;
	abs.f64 	%fd463, %fd70;
	setp.ltu.f64 	%p63, %fd463, 0d41E0000000000000;
	@%p63 bra 	$L__BB6_69;

	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd975, [retval0+0];
	} // callseq 53
	ld.local.u32 	%r851, [%rd8];

$L__BB6_69:
	and.b32  	%r352, %r851, 1;
	shl.b32 	%r353, %r851, 3;
	and.b32  	%r354, %r353, 8;
	setp.eq.s32 	%p64, %r352, 0;
	selp.f64 	%fd465, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p64;
	mul.wide.s32 	%rd145, %r354, 8;
	add.s64 	%rd147, %rd106, %rd145;
	ld.global.nc.f64 	%fd466, [%rd147+8];
	mul.rn.f64 	%fd75, %fd975, %fd975;
	fma.rn.f64 	%fd467, %fd465, %fd75, %fd466;
	ld.global.nc.f64 	%fd468, [%rd147+16];
	fma.rn.f64 	%fd469, %fd467, %fd75, %fd468;
	ld.global.nc.f64 	%fd470, [%rd147+24];
	fma.rn.f64 	%fd471, %fd469, %fd75, %fd470;
	ld.global.nc.f64 	%fd472, [%rd147+32];
	fma.rn.f64 	%fd473, %fd471, %fd75, %fd472;
	ld.global.nc.f64 	%fd474, [%rd147+40];
	fma.rn.f64 	%fd475, %fd473, %fd75, %fd474;
	ld.global.nc.f64 	%fd476, [%rd147+48];
	fma.rn.f64 	%fd76, %fd475, %fd75, %fd476;
	fma.rn.f64 	%fd977, %fd76, %fd975, %fd975;
	@%p64 bra 	$L__BB6_71;

	mov.f64 	%fd477, 0d3FF0000000000000;
	fma.rn.f64 	%fd977, %fd76, %fd75, %fd477;

$L__BB6_71:
	and.b32  	%r355, %r851, 2;
	setp.eq.s32 	%p65, %r355, 0;
	@%p65 bra 	$L__BB6_73;

	mov.f64 	%fd478, 0d0000000000000000;
	mov.f64 	%fd479, 0dBFF0000000000000;
	fma.rn.f64 	%fd977, %fd977, %fd479, %fd478;

$L__BB6_73:
	mul.rn.f64 	%fd480, %fd977, 0d4044000000000000;
	cvt.f64.f32 	%fd481, %f439;
	mul.rn.f64 	%fd482, %fd481, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd482, %fd480;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r356, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd83;
	}
	and.b32  	%r358, %r357, 2147483647;
	setp.eq.s32 	%p66, %r358, 2146435072;
	setp.eq.s32 	%p67, %r356, 0;
	and.pred  	%p68, %p67, %p66;
	@%p68 bra 	$L__BB6_76;
	bra.uni 	$L__BB6_74;

$L__BB6_76:
	mov.f64 	%fd492, 0d0000000000000000;
	mul.rn.f64 	%fd978, %fd83, %fd492;
	mov.u32 	%r852, 0;
	bra.uni 	$L__BB6_77;

$L__BB6_74:
	mul.rn.f64 	%fd483, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r852, %fd483;
	st.local.u32 	[%rd8], %r852;
	cvt.rn.f64.s32 	%fd484, %r852;
	neg.f64 	%fd485, %fd484;
	mov.f64 	%fd486, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd487, %fd485, %fd486, %fd83;
	mov.f64 	%fd488, 0d3C91A62633145C00;
	fma.rn.f64 	%fd489, %fd485, %fd488, %fd487;
	mov.f64 	%fd490, 0d397B839A252049C0;
	fma.rn.f64 	%fd978, %fd485, %fd490, %fd489;
	abs.f64 	%fd491, %fd83;
	setp.ltu.f64 	%p69, %fd491, 0d41E0000000000000;
	@%p69 bra 	$L__BB6_77;

	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd978, [retval0+0];
	} // callseq 54
	ld.local.u32 	%r852, [%rd8];

$L__BB6_77:
	and.b32  	%r360, %r852, 1;
	shl.b32 	%r361, %r852, 3;
	and.b32  	%r362, %r361, 8;
	setp.eq.s32 	%p70, %r360, 0;
	selp.f64 	%fd493, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p70;
	mul.wide.s32 	%rd149, %r362, 8;
	add.s64 	%rd151, %rd106, %rd149;
	ld.global.nc.f64 	%fd494, [%rd151+8];
	mul.rn.f64 	%fd88, %fd978, %fd978;
	fma.rn.f64 	%fd495, %fd493, %fd88, %fd494;
	ld.global.nc.f64 	%fd496, [%rd151+16];
	fma.rn.f64 	%fd497, %fd495, %fd88, %fd496;
	ld.global.nc.f64 	%fd498, [%rd151+24];
	fma.rn.f64 	%fd499, %fd497, %fd88, %fd498;
	ld.global.nc.f64 	%fd500, [%rd151+32];
	fma.rn.f64 	%fd501, %fd499, %fd88, %fd500;
	ld.global.nc.f64 	%fd502, [%rd151+40];
	fma.rn.f64 	%fd503, %fd501, %fd88, %fd502;
	ld.global.nc.f64 	%fd504, [%rd151+48];
	fma.rn.f64 	%fd89, %fd503, %fd88, %fd504;
	fma.rn.f64 	%fd980, %fd89, %fd978, %fd978;
	@%p70 bra 	$L__BB6_79;

	mov.f64 	%fd505, 0d3FF0000000000000;
	fma.rn.f64 	%fd980, %fd89, %fd88, %fd505;

$L__BB6_79:
	and.b32  	%r363, %r852, 2;
	setp.eq.s32 	%p71, %r363, 0;
	@%p71 bra 	$L__BB6_81;

	mov.f64 	%fd506, 0d0000000000000000;
	mov.f64 	%fd507, 0dBFF0000000000000;
	fma.rn.f64 	%fd980, %fd980, %fd507, %fd506;

$L__BB6_81:
	mul.rn.f64 	%fd508, %fd980, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd508;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r364, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r365}, %fd96;
	}
	and.b32  	%r366, %r365, 2147483647;
	setp.eq.s32 	%p72, %r366, 2146435072;
	setp.eq.s32 	%p73, %r364, 0;
	and.pred  	%p74, %p73, %p72;
	@%p74 bra 	$L__BB6_84;
	bra.uni 	$L__BB6_82;

$L__BB6_84:
	mov.f64 	%fd518, 0d0000000000000000;
	mul.rn.f64 	%fd981, %fd96, %fd518;
	mov.u32 	%r853, 0;
	bra.uni 	$L__BB6_85;

$L__BB6_82:
	mul.rn.f64 	%fd509, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r853, %fd509;
	st.local.u32 	[%rd8], %r853;
	cvt.rn.f64.s32 	%fd510, %r853;
	neg.f64 	%fd511, %fd510;
	mov.f64 	%fd512, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd513, %fd511, %fd512, %fd96;
	mov.f64 	%fd514, 0d3C91A62633145C00;
	fma.rn.f64 	%fd515, %fd511, %fd514, %fd513;
	mov.f64 	%fd516, 0d397B839A252049C0;
	fma.rn.f64 	%fd981, %fd511, %fd516, %fd515;
	abs.f64 	%fd517, %fd96;
	setp.ltu.f64 	%p75, %fd517, 0d41E0000000000000;
	@%p75 bra 	$L__BB6_85;

	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd981, [retval0+0];
	} // callseq 55
	ld.local.u32 	%r853, [%rd8];

$L__BB6_85:
	and.b32  	%r368, %r853, 1;
	shl.b32 	%r369, %r853, 3;
	and.b32  	%r370, %r369, 8;
	setp.eq.s32 	%p76, %r368, 0;
	selp.f64 	%fd519, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd153, %r370, 8;
	add.s64 	%rd155, %rd106, %rd153;
	ld.global.nc.f64 	%fd520, [%rd155+8];
	mul.rn.f64 	%fd101, %fd981, %fd981;
	fma.rn.f64 	%fd521, %fd519, %fd101, %fd520;
	ld.global.nc.f64 	%fd522, [%rd155+16];
	fma.rn.f64 	%fd523, %fd521, %fd101, %fd522;
	ld.global.nc.f64 	%fd524, [%rd155+24];
	fma.rn.f64 	%fd525, %fd523, %fd101, %fd524;
	ld.global.nc.f64 	%fd526, [%rd155+32];
	fma.rn.f64 	%fd527, %fd525, %fd101, %fd526;
	ld.global.nc.f64 	%fd528, [%rd155+40];
	fma.rn.f64 	%fd529, %fd527, %fd101, %fd528;
	ld.global.nc.f64 	%fd530, [%rd155+48];
	fma.rn.f64 	%fd102, %fd529, %fd101, %fd530;
	fma.rn.f64 	%fd983, %fd102, %fd981, %fd981;
	@%p76 bra 	$L__BB6_87;

	mov.f64 	%fd531, 0d3FF0000000000000;
	fma.rn.f64 	%fd983, %fd102, %fd101, %fd531;

$L__BB6_87:
	and.b32  	%r371, %r853, 2;
	setp.eq.s32 	%p77, %r371, 0;
	@%p77 bra 	$L__BB6_89;

	mov.f64 	%fd532, 0d0000000000000000;
	mov.f64 	%fd533, 0dBFF0000000000000;
	fma.rn.f64 	%fd983, %fd983, %fd533, %fd532;

$L__BB6_89:
	mul.rn.f64 	%fd534, %fd983, 0d4072C00000000000;
	add.rn.f64 	%fd535, %fd95, %fd534;
	add.rn.f64 	%fd108, %fd535, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd536, %fd1, %fd1;
	mov.f64 	%fd537, 0d4000000000000000;
	add.rn.f64 	%fd538, %fd536, 0dC059000000000000;
	mul.rn.f64 	%fd539, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd538, %fd539;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd537;
	}
	and.b32  	%r63, %r62, 2146435072;
	setp.eq.s32 	%p78, %r63, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd986, [retval0+0];
	} // callseq 56
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r64}, %fd2;
	}
	setp.lt.s32 	%p79, %r64, 0;
	and.pred  	%p1, %p79, %p78;
	not.pred 	%p80, %p1;
	@%p80 bra 	$L__BB6_91;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r372}, %fd986;
	}
	xor.b32  	%r373, %r372, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r374, %temp}, %fd986;
	}
	mov.b64 	%fd986, {%r374, %r373};

$L__BB6_91:
	add.rn.f32 	%f420, %f3, 0fC20C0000;
	setp.eq.f32 	%p81, %f420, 0f00000000;
	@%p81 bra 	$L__BB6_95;
	bra.uni 	$L__BB6_92;

$L__BB6_95:
	selp.b32 	%r375, %r64, 0, %p78;
	mov.u32 	%r376, 0;
	or.b32  	%r377, %r375, 2146435072;
	setp.lt.s32 	%p85, %r62, 0;
	selp.b32 	%r378, %r377, %r375, %p85;
	mov.b64 	%fd986, {%r376, %r378};
	bra.uni 	$L__BB6_96;

$L__BB6_92:
	setp.gt.s32 	%p82, %r64, -1;
	@%p82 bra 	$L__BB6_96;

	mov.f64 	%fd540, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd541, %fd540;
	setp.eq.f64 	%p83, %fd541, 0d4000000000000000;
	@%p83 bra 	$L__BB6_96;

	mov.f64 	%fd986, 0dFFF8000000000000;

$L__BB6_96:
	add.rn.f64 	%fd543, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r379}, %fd543;
	}
	and.b32  	%r380, %r379, 2146435072;
	setp.ne.s32 	%p86, %r380, 2146435072;
	@%p86 bra 	$L__BB6_103;

	setp.gtu.f64 	%p87, %fd111, 0d7FF0000000000000;
	@%p87 bra 	$L__BB6_102;
	bra.uni 	$L__BB6_98;

$L__BB6_102:
	mov.f64 	%fd545, 0d4000000000000000;
	add.rn.f64 	%fd986, %fd2, %fd545;
	bra.uni 	$L__BB6_103;

$L__BB6_98:
	mov.f64 	%fd544, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r381, %temp}, %fd544;
	}
	and.b32  	%r65, %r62, 2147483647;
	setp.eq.s32 	%p88, %r65, 2146435072;
	setp.eq.s32 	%p89, %r381, 0;
	and.pred  	%p90, %p88, %p89;
	@%p90 bra 	$L__BB6_101;
	bra.uni 	$L__BB6_99;

$L__BB6_101:
	add.rn.f32 	%f426, %f3, 0fC20C0000;
	setp.gt.f64 	%p97, %fd111, 0d3FF0000000000000;
	selp.b32 	%r388, 2146435072, 0, %p97;
	mov.u32 	%r389, 0;
	xor.b32  	%r390, %r388, 2146435072;
	setp.lt.s32 	%p98, %r62, 0;
	selp.b32 	%r391, %r390, %r388, %p98;
	setp.eq.f32 	%p99, %f426, 0fBF800000;
	selp.b32 	%r392, 1072693248, %r391, %p99;
	mov.b64 	%fd986, {%r389, %r392};
	bra.uni 	$L__BB6_103;

$L__BB6_99:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r382, %temp}, %fd2;
	}
	and.b32  	%r383, %r64, 2147483647;
	setp.ne.s32 	%p91, %r383, 2146435072;
	setp.ne.s32 	%p92, %r382, 0;
	or.pred  	%p93, %p91, %p92;
	@%p93 bra 	$L__BB6_103;

	setp.gt.s32 	%p94, %r62, -1;
	selp.b32 	%r384, 2146435072, 0, %p94;
	mov.u32 	%r385, 0;
	setp.ne.s32 	%p95, %r65, 1071644672;
	and.pred  	%p96, %p95, %p1;
	or.b32  	%r386, %r384, -2147483648;
	selp.b32 	%r387, %r386, %r384, %p96;
	mov.b64 	%fd986, {%r385, %r387};

$L__BB6_103:
	add.rn.f32 	%f422, %f1, 0fC2D20000;
	add.rn.f32 	%f421, %f3, 0fC20C0000;
	mul.rn.f64 	%fd546, %fd986, 0d3FC999999999999A;
	setp.eq.f32 	%p100, %f421, 0f3F800000;
	selp.f64 	%fd547, 0d3FC999999999999A, %fd546, %p100;
	add.rn.f64 	%fd548, %fd110, %fd547;
	mul.rn.f32 	%f192, %f422, %f421;
	cvt.f64.f32 	%fd549, %f192;
	mul.rn.f64 	%fd121, %fd549, 0d3FB999999999999A;
	add.rn.f64 	%fd550, %fd121, %fd548;
	abs.f32 	%f193, %f422;
	sqrt.rn.f32 	%f194, %f193;
	cvt.f64.f32 	%fd122, %f194;
	mul.rn.f64 	%fd551, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd552, %fd551, %fd550;
	cvt.rn.f32.f64 	%f195, %fd109;
	cvt.f64.f32 	%fd553, %f195;
	mul.rn.f64 	%fd554, %fd553, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f196, %fd554;
	cvt.f64.f32 	%fd555, %f196;
	add.rn.f64 	%fd123, %fd552, %fd555;
	add.rn.f64 	%fd556, %fd2, %fd2;
	add.rn.f64 	%fd557, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd557, %fd556;
	abs.f64 	%fd125, %fd1;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd989, [retval0+0];
	} // callseq 57
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd1;
	}
	setp.lt.s32 	%p101, %r66, 0;
	and.pred  	%p2, %p101, %p78;
	not.pred 	%p103, %p2;
	@%p103 bra 	$L__BB6_105;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r393}, %fd989;
	}
	xor.b32  	%r394, %r393, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r395, %temp}, %fd989;
	}
	mov.b64 	%fd989, {%r395, %r394};

$L__BB6_105:
	add.rn.f32 	%f423, %f1, 0fC2D20000;
	setp.eq.f32 	%p104, %f423, 0f00000000;
	@%p104 bra 	$L__BB6_109;
	bra.uni 	$L__BB6_106;

$L__BB6_109:
	selp.b32 	%r396, %r66, 0, %p78;
	mov.u32 	%r397, 0;
	or.b32  	%r398, %r396, 2146435072;
	setp.lt.s32 	%p108, %r62, 0;
	selp.b32 	%r399, %r398, %r396, %p108;
	mov.b64 	%fd989, {%r397, %r399};
	bra.uni 	$L__BB6_110;

$L__BB6_106:
	setp.gt.s32 	%p105, %r66, -1;
	@%p105 bra 	$L__BB6_110;

	mov.f64 	%fd558, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd559, %fd558;
	setp.eq.f64 	%p106, %fd559, 0d4000000000000000;
	@%p106 bra 	$L__BB6_110;

	mov.f64 	%fd989, 0dFFF8000000000000;

$L__BB6_110:
	add.rn.f64 	%fd561, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r400}, %fd561;
	}
	and.b32  	%r401, %r400, 2146435072;
	setp.ne.s32 	%p109, %r401, 2146435072;
	@%p109 bra 	$L__BB6_117;

	setp.gtu.f64 	%p110, %fd125, 0d7FF0000000000000;
	@%p110 bra 	$L__BB6_116;
	bra.uni 	$L__BB6_112;

$L__BB6_116:
	mov.f64 	%fd563, 0d4000000000000000;
	add.rn.f64 	%fd989, %fd1, %fd563;
	bra.uni 	$L__BB6_117;

$L__BB6_112:
	mov.f64 	%fd562, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd562;
	}
	and.b32  	%r67, %r62, 2147483647;
	setp.eq.s32 	%p111, %r67, 2146435072;
	setp.eq.s32 	%p112, %r402, 0;
	and.pred  	%p113, %p111, %p112;
	@%p113 bra 	$L__BB6_115;
	bra.uni 	$L__BB6_113;

$L__BB6_115:
	add.rn.f32 	%f425, %f1, 0fC2D20000;
	setp.gt.f64 	%p120, %fd125, 0d3FF0000000000000;
	selp.b32 	%r409, 2146435072, 0, %p120;
	mov.u32 	%r410, 0;
	xor.b32  	%r411, %r409, 2146435072;
	setp.lt.s32 	%p121, %r62, 0;
	selp.b32 	%r412, %r411, %r409, %p121;
	setp.eq.f32 	%p122, %f425, 0fBF800000;
	selp.b32 	%r413, 1072693248, %r412, %p122;
	mov.b64 	%fd989, {%r410, %r413};
	bra.uni 	$L__BB6_117;

$L__BB6_113:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r403, %temp}, %fd1;
	}
	and.b32  	%r404, %r66, 2147483647;
	setp.ne.s32 	%p114, %r404, 2146435072;
	setp.ne.s32 	%p115, %r403, 0;
	or.pred  	%p116, %p114, %p115;
	@%p116 bra 	$L__BB6_117;

	setp.gt.s32 	%p117, %r62, -1;
	selp.b32 	%r405, 2146435072, 0, %p117;
	mov.u32 	%r406, 0;
	setp.ne.s32 	%p118, %r67, 1071644672;
	and.pred  	%p119, %p118, %p2;
	or.b32  	%r407, %r405, -2147483648;
	selp.b32 	%r408, %r407, %r405, %p119;
	mov.b64 	%fd989, {%r406, %r408};

$L__BB6_117:
	add.rn.f32 	%f424, %f1, 0fC2D20000;
	mul.rn.f64 	%fd564, %fd989, 0d3FB999999999999A;
	setp.eq.f32 	%p123, %f424, 0f3F800000;
	selp.f64 	%fd565, 0d3FB999999999999A, %fd564, %p123;
	add.rn.f64 	%fd566, %fd124, %fd565;
	add.rn.f64 	%fd567, %fd121, %fd566;
	mul.rn.f64 	%fd568, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd569, %fd568, %fd567;
	cvt.rn.f32.f64 	%f197, %fd108;
	cvt.f64.f32 	%fd570, %f197;
	mul.rn.f64 	%fd571, %fd570, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f198, %fd571;
	cvt.f64.f32 	%fd572, %f198;
	add.rn.f64 	%fd135, %fd569, %fd572;
	cvt.f64.f32 	%fd573, %f3;
	div.rn.f64 	%fd574, %fd573, 0d4066800000000000;
	mul.rn.f64 	%fd575, %fd574, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd575;
	mul.rn.f32 	%f199, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r861, %f199;
	cvt.rn.f32.s32 	%f200, %r861;
	mov.f32 	%f201, 0fBFC90FDA;
	fma.rn.f32 	%f202, %f200, %f201, %f31;
	mov.f32 	%f203, 0fB3A22168;
	fma.rn.f32 	%f204, %f200, %f203, %f202;
	mov.f32 	%f205, 0fA7C234C5;
	fma.rn.f32 	%f443, %f200, %f205, %f204;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p124, %f33, 0f47CE4780;
	mov.u32 	%r857, %r861;
	mov.f32 	%f440, %f443;
	@%p124 bra 	$L__BB6_125;

	setp.eq.f32 	%p125, %f33, 0f7F800000;
	@%p125 bra 	$L__BB6_124;
	bra.uni 	$L__BB6_119;

$L__BB6_124:
	mov.f32 	%f208, 0f00000000;
	mul.rn.f32 	%f440, %f31, %f208;
	mov.u32 	%r857, 0;
	bra.uni 	$L__BB6_125;

$L__BB6_119:
	mov.b32 	%r69, %f31;
	bfe.u32 	%r415, %r69, 23, 8;
	add.s32 	%r70, %r415, -128;
	shl.b32 	%r416, %r69, 8;
	or.b32  	%r71, %r416, -2147483648;
	shr.u32 	%r72, %r70, 5;
	mov.u64 	%rd315, 0;
	mov.u32 	%r854, 0;
	mov.u64 	%rd314, __cudart_i2opi_f;
	mov.u64 	%rd313, %rd1;

$L__BB6_120:
	.pragma "nounroll";
	ld.global.nc.u32 	%r417, [%rd314];
	mad.wide.u32 	%rd158, %r417, %r71, %rd315;
	shr.u64 	%rd315, %rd158, 32;
	st.local.u32 	[%rd313], %rd158;
	add.s64 	%rd314, %rd314, 4;
	add.s64 	%rd313, %rd313, 4;
	add.s32 	%r854, %r854, 1;
	setp.ne.s32 	%p126, %r854, 6;
	@%p126 bra 	$L__BB6_120;

	st.local.u32 	[%rd23], %rd315;
	mov.u32 	%r418, 4;
	sub.s32 	%r75, %r418, %r72;
	mov.u32 	%r419, 6;
	sub.s32 	%r420, %r419, %r72;
	mul.wide.s32 	%rd159, %r420, 4;
	add.s64 	%rd160, %rd1, %rd159;
	ld.local.u32 	%r855, [%rd160];
	ld.local.u32 	%r856, [%rd160+-4];
	and.b32  	%r78, %r70, 31;
	setp.eq.s32 	%p127, %r78, 0;
	@%p127 bra 	$L__BB6_123;

	mov.u32 	%r421, 32;
	sub.s32 	%r422, %r421, %r78;
	shr.u32 	%r423, %r856, %r422;
	shl.b32 	%r424, %r855, %r78;
	add.s32 	%r855, %r423, %r424;
	mul.wide.s32 	%rd161, %r75, 4;
	add.s64 	%rd162, %rd1, %rd161;
	ld.local.u32 	%r425, [%rd162];
	shr.u32 	%r426, %r425, %r422;
	shl.b32 	%r427, %r856, %r78;
	add.s32 	%r856, %r426, %r427;

$L__BB6_123:
	and.b32  	%r428, %r69, -2147483648;
	shr.u32 	%r429, %r856, 30;
	shl.b32 	%r430, %r855, 2;
	or.b32  	%r431, %r429, %r430;
	shr.u32 	%r432, %r431, 31;
	shr.u32 	%r433, %r855, 30;
	add.s32 	%r434, %r432, %r433;
	neg.s32 	%r435, %r434;
	setp.eq.s32 	%p128, %r428, 0;
	selp.b32 	%r857, %r434, %r435, %p128;
	setp.ne.s32 	%p129, %r432, 0;
	xor.b32  	%r436, %r428, -2147483648;
	selp.b32 	%r437, %r436, %r428, %p129;
	selp.b32 	%r438, -1, 0, %p129;
	xor.b32  	%r439, %r431, %r438;
	shl.b32 	%r440, %r856, 2;
	xor.b32  	%r441, %r440, %r438;
	cvt.u64.u32 	%rd163, %r439;
	cvt.u64.u32 	%rd164, %r441;
	bfi.b64 	%rd165, %rd163, %rd164, 32, 32;
	cvt.rn.f64.s64 	%fd576, %rd165;
	mul.rn.f64 	%fd577, %fd576, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f206, %fd577;
	setp.eq.s32 	%p130, %r437, 0;
	neg.f32 	%f207, %f206;
	selp.f32 	%f440, %f206, %f207, %p130;

$L__BB6_125:
	and.b32  	%r85, %r857, 1;
	setp.eq.s32 	%p131, %r85, 0;
	selp.f32 	%f37, %f440, 0f3F800000, %p131;
	mul.rn.f32 	%f38, %f440, %f440;
	mov.f32 	%f441, 0fB94D4153;
	@%p131 bra 	$L__BB6_127;

	mov.f32 	%f210, 0fBAB607ED;
	mov.f32 	%f211, 0f37CBAC00;
	fma.rn.f32 	%f441, %f211, %f38, %f210;

$L__BB6_127:
	selp.f32 	%f212, 0f3C0885E4, 0f3D2AAABB, %p131;
	fma.rn.f32 	%f213, %f441, %f38, %f212;
	selp.f32 	%f214, 0fBE2AAAA8, 0fBEFFFFFF, %p131;
	fma.rn.f32 	%f215, %f213, %f38, %f214;
	mov.f32 	%f216, 0f00000000;
	fma.rn.f32 	%f217, %f38, %f37, %f216;
	fma.rn.f32 	%f442, %f215, %f217, %f37;
	and.b32  	%r443, %r857, 2;
	setp.eq.s32 	%p133, %r443, 0;
	@%p133 bra 	$L__BB6_129;

	mov.f32 	%f219, 0fBF800000;
	fma.rn.f32 	%f442, %f442, %f219, %f216;

$L__BB6_129:
	@%p124 bra 	$L__BB6_137;

	setp.eq.f32 	%p135, %f33, 0f7F800000;
	@%p135 bra 	$L__BB6_136;
	bra.uni 	$L__BB6_131;

$L__BB6_136:
	mov.f32 	%f222, 0f00000000;
	mul.rn.f32 	%f443, %f31, %f222;
	mov.u32 	%r861, 0;
	bra.uni 	$L__BB6_137;

$L__BB6_131:
	mov.b32 	%r86, %f31;
	bfe.u32 	%r445, %r86, 23, 8;
	add.s32 	%r87, %r445, -128;
	shl.b32 	%r446, %r86, 8;
	or.b32  	%r88, %r446, -2147483648;
	shr.u32 	%r89, %r87, 5;
	mov.u64 	%rd316, 0;
	mov.u32 	%r858, 0;
	mov.u64 	%rd169, __cudart_i2opi_f;
	mov.u64 	%rd317, %rd316;

$L__BB6_132:
	.pragma "nounroll";
	shl.b64 	%rd168, %rd316, 2;
	add.s64 	%rd170, %rd169, %rd168;
	ld.global.nc.u32 	%r447, [%rd170];
	mad.wide.u32 	%rd171, %r447, %r88, %rd317;
	shr.u64 	%rd317, %rd171, 32;
	add.s64 	%rd172, %rd1, %rd168;
	st.local.u32 	[%rd172], %rd171;
	add.s32 	%r858, %r858, 1;
	cvt.s64.s32 	%rd316, %r858;
	setp.ne.s32 	%p136, %r858, 6;
	@%p136 bra 	$L__BB6_132;

	st.local.u32 	[%rd23], %rd317;
	mov.u32 	%r448, 4;
	sub.s32 	%r92, %r448, %r89;
	mov.u32 	%r449, 6;
	sub.s32 	%r450, %r449, %r89;
	mul.wide.s32 	%rd173, %r450, 4;
	add.s64 	%rd174, %rd1, %rd173;
	ld.local.u32 	%r859, [%rd174];
	ld.local.u32 	%r860, [%rd174+-4];
	and.b32  	%r95, %r87, 31;
	setp.eq.s32 	%p137, %r95, 0;
	@%p137 bra 	$L__BB6_135;

	mov.u32 	%r451, 32;
	sub.s32 	%r452, %r451, %r95;
	shr.u32 	%r453, %r860, %r452;
	shl.b32 	%r454, %r859, %r95;
	add.s32 	%r859, %r453, %r454;
	mul.wide.s32 	%rd175, %r92, 4;
	add.s64 	%rd176, %rd1, %rd175;
	ld.local.u32 	%r455, [%rd176];
	shr.u32 	%r456, %r455, %r452;
	shl.b32 	%r457, %r860, %r95;
	add.s32 	%r860, %r456, %r457;

$L__BB6_135:
	and.b32  	%r458, %r86, -2147483648;
	shr.u32 	%r459, %r860, 30;
	shl.b32 	%r460, %r859, 2;
	or.b32  	%r461, %r459, %r460;
	shr.u32 	%r462, %r461, 31;
	shr.u32 	%r463, %r859, 30;
	add.s32 	%r464, %r462, %r463;
	neg.s32 	%r465, %r464;
	setp.eq.s32 	%p138, %r458, 0;
	selp.b32 	%r861, %r464, %r465, %p138;
	setp.ne.s32 	%p139, %r462, 0;
	xor.b32  	%r466, %r458, -2147483648;
	selp.b32 	%r467, %r466, %r458, %p139;
	selp.b32 	%r468, -1, 0, %p139;
	xor.b32  	%r469, %r461, %r468;
	shl.b32 	%r470, %r860, 2;
	xor.b32  	%r471, %r470, %r468;
	cvt.u64.u32 	%rd177, %r469;
	cvt.u64.u32 	%rd178, %r471;
	bfi.b64 	%rd179, %rd177, %rd178, 32, 32;
	cvt.rn.f64.s64 	%fd578, %rd179;
	mul.rn.f64 	%fd579, %fd578, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f220, %fd579;
	setp.eq.s32 	%p140, %r467, 0;
	neg.f32 	%f221, %f220;
	selp.f32 	%f443, %f220, %f221, %p140;

$L__BB6_137:
	add.s32 	%r102, %r861, 1;
	and.b32  	%r103, %r102, 1;
	setp.eq.s32 	%p3, %r103, 0;
	mul.rn.f32 	%f47, %f443, %f443;
	mov.f32 	%f444, 0fB94D4153;
	@%p3 bra 	$L__BB6_139;

	mov.f32 	%f224, 0fBAB607ED;
	mov.f32 	%f225, 0f37CBAC00;
	fma.rn.f32 	%f444, %f225, %f47, %f224;

$L__BB6_139:
	selp.f32 	%f226, %f443, 0f3F800000, %p3;
	selp.f32 	%f227, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f228, %f444, %f47, %f227;
	selp.f32 	%f229, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f230, %f228, %f47, %f229;
	mov.f32 	%f231, 0f00000000;
	fma.rn.f32 	%f232, %f47, %f226, %f231;
	fma.rn.f32 	%f445, %f230, %f232, %f226;
	and.b32  	%r473, %r102, 2;
	setp.eq.s32 	%p142, %r473, 0;
	@%p142 bra 	$L__BB6_141;

	mov.f32 	%f234, 0fBF800000;
	fma.rn.f32 	%f445, %f445, %f234, %f231;

$L__BB6_141:
	ld.param.u32 	%r837, [gcj02_to_wgs84_exact_cuda_float_param_5];
	cvt.f64.f32 	%fd580, %f442;
	mul.rn.f64 	%fd581, %fd580, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd582, %fd581, %fd580;
	add.rn.f64 	%fd583, %fd582, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f235, %fd583;
	sqrt.rn.f32 	%f236, %f235;
	mov.f32 	%f237, 0fCAC2A60A;
	div.rn.f32 	%f238, %f237, %f236;
	mul.rn.f32 	%f239, %f238, %f445;
	cvt.f64.f32 	%fd584, %f239;
	mul.rn.f64 	%fd585, %fd584, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f240, %fd135;
	cvt.f64.f32 	%fd586, %f240;
	mul.rn.f64 	%fd587, %fd586, 0d4066800000000000;
	div.rn.f64 	%fd588, %fd587, %fd585;
	cvt.rn.f32.f64 	%f241, %fd588;
	add.rn.f32 	%f467, %f1, %f241;
	mul.rn.f32 	%f242, %f236, %f235;
	cvt.f64.f32 	%fd589, %f242;
	mov.f64 	%fd590, 0dC1582B102DE355C1;
	div.rn.f64 	%fd591, %fd590, %fd589;
	mul.rn.f64 	%fd592, %fd591, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f243, %fd123;
	cvt.f64.f32 	%fd593, %f243;
	mul.rn.f64 	%fd594, %fd593, 0d4066800000000000;
	div.rn.f64 	%fd595, %fd594, %fd592;
	cvt.rn.f32.f64 	%f244, %fd595;
	add.rn.f32 	%f468, %f3, %f244;
	setp.lt.s32 	%p143, %r837, 1;
	@%p143 bra 	$L__BB6_361;

	and.b32  	%r104, %r62, 2147483647;
	setp.gt.s32 	%p144, %r62, -1;
	selp.b32 	%r105, 2146435072, 0, %p144;
	mov.u32 	%r862, 0;
	or.b32  	%r106, %r105, -2147483648;
	mov.u64 	%rd188, __cudart_i2opi_f;
	mov.f32 	%f446, %f468;
	mov.f32 	%f447, %f467;

$L__BB6_143:
	mov.f32 	%f467, %f447;
	mov.f32 	%f468, %f446;
	add.rn.f32 	%f57, %f468, 0fC20C0000;
	add.rn.f32 	%f58, %f467, 0fC2D20000;
	cvt.f64.f32 	%fd136, %f58;
	mul.rn.f64 	%fd596, %fd136, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f59, %fd596;
	cvt.f64.f32 	%fd137, %f57;
	mul.rn.f64 	%fd597, %fd137, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f60, %fd597;
	cvt.f64.f32 	%fd138, %f59;
	mul.rn.f64 	%fd139, %fd138, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r475, %temp}, %fd139;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r476}, %fd139;
	}
	and.b32  	%r477, %r476, 2147483647;
	setp.eq.s32 	%p145, %r477, 2146435072;
	setp.eq.s32 	%p146, %r475, 0;
	and.pred  	%p147, %p146, %p145;
	@%p147 bra 	$L__BB6_146;
	bra.uni 	$L__BB6_144;

$L__BB6_146:
	mov.f64 	%fd607, 0d0000000000000000;
	mul.rn.f64 	%fd990, %fd139, %fd607;
	mov.u32 	%r863, 0;
	bra.uni 	$L__BB6_147;

$L__BB6_144:
	mul.rn.f64 	%fd598, %fd139, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r863, %fd598;
	st.local.u32 	[%rd8], %r863;
	cvt.rn.f64.s32 	%fd599, %r863;
	neg.f64 	%fd600, %fd599;
	mov.f64 	%fd601, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd602, %fd600, %fd601, %fd139;
	mov.f64 	%fd603, 0d3C91A62633145C00;
	fma.rn.f64 	%fd604, %fd600, %fd603, %fd602;
	mov.f64 	%fd605, 0d397B839A252049C0;
	fma.rn.f64 	%fd990, %fd600, %fd605, %fd604;
	abs.f64 	%fd606, %fd139;
	setp.ltu.f64 	%p148, %fd606, 0d41E0000000000000;
	@%p148 bra 	$L__BB6_147;

	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd139;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd990, [retval0+0];
	} // callseq 58
	ld.local.u32 	%r863, [%rd8];

$L__BB6_147:
	and.b32  	%r479, %r863, 1;
	shl.b32 	%r480, %r863, 3;
	and.b32  	%r481, %r480, 8;
	setp.eq.s32 	%p149, %r479, 0;
	selp.f64 	%fd608, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p149;
	mul.wide.s32 	%rd181, %r481, 8;
	add.s64 	%rd183, %rd106, %rd181;
	ld.global.nc.f64 	%fd609, [%rd183+8];
	mul.rn.f64 	%fd144, %fd990, %fd990;
	fma.rn.f64 	%fd610, %fd608, %fd144, %fd609;
	ld.global.nc.f64 	%fd611, [%rd183+16];
	fma.rn.f64 	%fd612, %fd610, %fd144, %fd611;
	ld.global.nc.f64 	%fd613, [%rd183+24];
	fma.rn.f64 	%fd614, %fd612, %fd144, %fd613;
	ld.global.nc.f64 	%fd615, [%rd183+32];
	fma.rn.f64 	%fd616, %fd614, %fd144, %fd615;
	ld.global.nc.f64 	%fd617, [%rd183+40];
	fma.rn.f64 	%fd618, %fd616, %fd144, %fd617;
	ld.global.nc.f64 	%fd619, [%rd183+48];
	fma.rn.f64 	%fd145, %fd618, %fd144, %fd619;
	fma.rn.f64 	%fd992, %fd145, %fd990, %fd990;
	@%p149 bra 	$L__BB6_149;

	mov.f64 	%fd620, 0d3FF0000000000000;
	fma.rn.f64 	%fd992, %fd145, %fd144, %fd620;

$L__BB6_149:
	and.b32  	%r482, %r863, 2;
	setp.eq.s32 	%p150, %r482, 0;
	@%p150 bra 	$L__BB6_151;

	mov.f64 	%fd621, 0d0000000000000000;
	mov.f64 	%fd622, 0dBFF0000000000000;
	fma.rn.f64 	%fd992, %fd992, %fd622, %fd621;

$L__BB6_151:
	add.rn.f64 	%fd151, %fd138, %fd138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r483, %temp}, %fd151;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r484}, %fd151;
	}
	and.b32  	%r485, %r484, 2147483647;
	setp.eq.s32 	%p151, %r485, 2146435072;
	setp.eq.s32 	%p152, %r483, 0;
	and.pred  	%p153, %p152, %p151;
	@%p153 bra 	$L__BB6_154;
	bra.uni 	$L__BB6_152;

$L__BB6_154:
	mov.f64 	%fd632, 0d0000000000000000;
	mul.rn.f64 	%fd993, %fd151, %fd632;
	mov.u32 	%r864, 0;
	bra.uni 	$L__BB6_155;

$L__BB6_152:
	mul.rn.f64 	%fd623, %fd151, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r864, %fd623;
	st.local.u32 	[%rd8], %r864;
	cvt.rn.f64.s32 	%fd624, %r864;
	neg.f64 	%fd625, %fd624;
	mov.f64 	%fd626, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd627, %fd625, %fd626, %fd151;
	mov.f64 	%fd628, 0d3C91A62633145C00;
	fma.rn.f64 	%fd629, %fd625, %fd628, %fd627;
	mov.f64 	%fd630, 0d397B839A252049C0;
	fma.rn.f64 	%fd993, %fd625, %fd630, %fd629;
	abs.f64 	%fd631, %fd151;
	setp.ltu.f64 	%p154, %fd631, 0d41E0000000000000;
	@%p154 bra 	$L__BB6_155;

	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd151;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd993, [retval0+0];
	} // callseq 59
	ld.local.u32 	%r864, [%rd8];

$L__BB6_155:
	and.b32  	%r487, %r864, 1;
	shl.b32 	%r488, %r864, 3;
	and.b32  	%r489, %r488, 8;
	setp.eq.s32 	%p155, %r487, 0;
	selp.f64 	%fd633, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p155;
	mul.wide.s32 	%rd185, %r489, 8;
	add.s64 	%rd187, %rd106, %rd185;
	ld.global.nc.f64 	%fd634, [%rd187+8];
	mul.rn.f64 	%fd156, %fd993, %fd993;
	fma.rn.f64 	%fd635, %fd633, %fd156, %fd634;
	ld.global.nc.f64 	%fd636, [%rd187+16];
	fma.rn.f64 	%fd637, %fd635, %fd156, %fd636;
	ld.global.nc.f64 	%fd638, [%rd187+24];
	fma.rn.f64 	%fd639, %fd637, %fd156, %fd638;
	ld.global.nc.f64 	%fd640, [%rd187+32];
	fma.rn.f64 	%fd641, %fd639, %fd156, %fd640;
	ld.global.nc.f64 	%fd642, [%rd187+40];
	fma.rn.f64 	%fd643, %fd641, %fd156, %fd642;
	ld.global.nc.f64 	%fd644, [%rd187+48];
	fma.rn.f64 	%fd157, %fd643, %fd156, %fd644;
	fma.rn.f64 	%fd995, %fd157, %fd993, %fd993;
	@%p155 bra 	$L__BB6_157;

	mov.f64 	%fd645, 0d3FF0000000000000;
	fma.rn.f64 	%fd995, %fd157, %fd156, %fd645;

$L__BB6_157:
	and.b32  	%r490, %r864, 2;
	setp.eq.s32 	%p156, %r490, 0;
	@%p156 bra 	$L__BB6_159;

	mov.f64 	%fd646, 0d0000000000000000;
	mov.f64 	%fd647, 0dBFF0000000000000;
	fma.rn.f64 	%fd995, %fd995, %fd647, %fd646;

$L__BB6_159:
	mul.rn.f64 	%fd648, %fd995, 0d4034000000000000;
	mul.rn.f64 	%fd649, %fd992, 0d4034000000000000;
	add.rn.f64 	%fd163, %fd649, %fd648;
	mul.rn.f32 	%f245, %f60, 0f3F22F983;
	cvt.rni.s32.f32 	%r868, %f245;
	cvt.rn.f32.s32 	%f246, %r868;
	mov.f32 	%f247, 0fBFC90FDA;
	fma.rn.f32 	%f248, %f246, %f247, %f60;
	mov.f32 	%f249, 0fB3A22168;
	fma.rn.f32 	%f250, %f246, %f249, %f248;
	mov.f32 	%f251, 0fA7C234C5;
	fma.rn.f32 	%f448, %f246, %f251, %f250;
	abs.f32 	%f62, %f60;
	setp.ltu.f32 	%p157, %f62, 0f47CE4780;
	@%p157 bra 	$L__BB6_167;

	setp.eq.f32 	%p158, %f62, 0f7F800000;
	@%p158 bra 	$L__BB6_166;
	bra.uni 	$L__BB6_161;

$L__BB6_166:
	mov.f32 	%f254, 0f00000000;
	mul.rn.f32 	%f448, %f60, %f254;
	mov.u32 	%r868, 0;
	bra.uni 	$L__BB6_167;

$L__BB6_161:
	mov.b32 	%r115, %f60;
	bfe.u32 	%r492, %r115, 23, 8;
	add.s32 	%r116, %r492, -128;
	shl.b32 	%r493, %r115, 8;
	or.b32  	%r117, %r493, -2147483648;
	shr.u32 	%r118, %r116, 5;
	mov.u64 	%rd320, 0;
	mov.u32 	%r865, 0;
	mov.u64 	%rd318, %rd1;
	mov.u64 	%rd319, %rd188;

$L__BB6_162:
	.pragma "nounroll";
	ld.global.nc.u32 	%r494, [%rd319];
	mad.wide.u32 	%rd190, %r494, %r117, %rd320;
	shr.u64 	%rd320, %rd190, 32;
	st.local.u32 	[%rd318], %rd190;
	add.s64 	%rd319, %rd319, 4;
	add.s64 	%rd318, %rd318, 4;
	add.s32 	%r865, %r865, 1;
	setp.ne.s32 	%p159, %r865, 6;
	@%p159 bra 	$L__BB6_162;

	st.local.u32 	[%rd23], %rd320;
	mov.u32 	%r495, 4;
	sub.s32 	%r121, %r495, %r118;
	mov.u32 	%r496, 6;
	sub.s32 	%r497, %r496, %r118;
	mul.wide.s32 	%rd191, %r497, 4;
	add.s64 	%rd192, %rd1, %rd191;
	ld.local.u32 	%r866, [%rd192];
	ld.local.u32 	%r867, [%rd192+-4];
	and.b32  	%r124, %r116, 31;
	setp.eq.s32 	%p160, %r124, 0;
	@%p160 bra 	$L__BB6_165;

	mov.u32 	%r498, 32;
	sub.s32 	%r499, %r498, %r124;
	shr.u32 	%r500, %r867, %r499;
	shl.b32 	%r501, %r866, %r124;
	add.s32 	%r866, %r500, %r501;
	mul.wide.s32 	%rd193, %r121, 4;
	add.s64 	%rd194, %rd1, %rd193;
	ld.local.u32 	%r502, [%rd194];
	shr.u32 	%r503, %r502, %r499;
	shl.b32 	%r504, %r867, %r124;
	add.s32 	%r867, %r503, %r504;

$L__BB6_165:
	and.b32  	%r505, %r115, -2147483648;
	shr.u32 	%r506, %r867, 30;
	shl.b32 	%r507, %r866, 2;
	or.b32  	%r508, %r506, %r507;
	shr.u32 	%r509, %r508, 31;
	shr.u32 	%r510, %r866, 30;
	add.s32 	%r511, %r509, %r510;
	neg.s32 	%r512, %r511;
	setp.eq.s32 	%p161, %r505, 0;
	selp.b32 	%r868, %r511, %r512, %p161;
	setp.ne.s32 	%p162, %r509, 0;
	xor.b32  	%r513, %r505, -2147483648;
	selp.b32 	%r514, %r513, %r505, %p162;
	selp.b32 	%r515, -1, 0, %p162;
	xor.b32  	%r516, %r508, %r515;
	shl.b32 	%r517, %r867, 2;
	xor.b32  	%r518, %r517, %r515;
	cvt.u64.u32 	%rd195, %r516;
	cvt.u64.u32 	%rd196, %r518;
	bfi.b64 	%rd197, %rd195, %rd196, 32, 32;
	cvt.rn.f64.s64 	%fd650, %rd197;
	mul.rn.f64 	%fd651, %fd650, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f252, %fd651;
	setp.eq.s32 	%p163, %r514, 0;
	neg.f32 	%f253, %f252;
	selp.f32 	%f448, %f252, %f253, %p163;

$L__BB6_167:
	and.b32  	%r131, %r868, 1;
	setp.eq.s32 	%p164, %r131, 0;
	selp.f32 	%f66, %f448, 0f3F800000, %p164;
	mul.rn.f32 	%f67, %f448, %f448;
	mov.f32 	%f449, 0fB94D4153;
	@%p164 bra 	$L__BB6_169;

	mov.f32 	%f256, 0fBAB607ED;
	mov.f32 	%f257, 0f37CBAC00;
	fma.rn.f32 	%f449, %f257, %f67, %f256;

$L__BB6_169:
	selp.f32 	%f258, 0f3C0885E4, 0f3D2AAABB, %p164;
	fma.rn.f32 	%f259, %f449, %f67, %f258;
	selp.f32 	%f260, 0fBE2AAAA8, 0fBEFFFFFF, %p164;
	fma.rn.f32 	%f261, %f259, %f67, %f260;
	mov.f32 	%f262, 0f00000000;
	fma.rn.f32 	%f263, %f67, %f66, %f262;
	fma.rn.f32 	%f450, %f261, %f263, %f66;
	and.b32  	%r520, %r868, 2;
	setp.eq.s32 	%p166, %r520, 0;
	@%p166 bra 	$L__BB6_171;

	mov.f32 	%f265, 0fBF800000;
	fma.rn.f32 	%f450, %f450, %f265, %f262;

$L__BB6_171:
	cvt.f64.f32 	%fd164, %f60;
	div.rn.f64 	%fd165, %fd164, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r521, %temp}, %fd165;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r522}, %fd165;
	}
	and.b32  	%r523, %r522, 2147483647;
	setp.eq.s32 	%p167, %r523, 2146435072;
	setp.eq.s32 	%p168, %r521, 0;
	and.pred  	%p169, %p168, %p167;
	@%p169 bra 	$L__BB6_174;
	bra.uni 	$L__BB6_172;

$L__BB6_174:
	mov.f64 	%fd661, 0d0000000000000000;
	mul.rn.f64 	%fd996, %fd165, %fd661;
	mov.u32 	%r869, 0;
	bra.uni 	$L__BB6_175;

$L__BB6_172:
	mul.rn.f64 	%fd652, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r869, %fd652;
	st.local.u32 	[%rd1], %r869;
	cvt.rn.f64.s32 	%fd653, %r869;
	neg.f64 	%fd654, %fd653;
	mov.f64 	%fd655, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd656, %fd654, %fd655, %fd165;
	mov.f64 	%fd657, 0d3C91A62633145C00;
	fma.rn.f64 	%fd658, %fd654, %fd657, %fd656;
	mov.f64 	%fd659, 0d397B839A252049C0;
	fma.rn.f64 	%fd996, %fd654, %fd659, %fd658;
	abs.f64 	%fd660, %fd165;
	setp.ltu.f64 	%p170, %fd660, 0d41E0000000000000;
	@%p170 bra 	$L__BB6_175;

	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd996, [retval0+0];
	} // callseq 60
	ld.local.u32 	%r869, [%rd1];

$L__BB6_175:
	and.b32  	%r525, %r869, 1;
	shl.b32 	%r526, %r869, 3;
	and.b32  	%r527, %r526, 8;
	setp.eq.s32 	%p171, %r525, 0;
	selp.f64 	%fd662, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p171;
	mul.wide.s32 	%rd199, %r527, 8;
	add.s64 	%rd201, %rd106, %rd199;
	ld.global.nc.f64 	%fd663, [%rd201+8];
	mul.rn.f64 	%fd170, %fd996, %fd996;
	fma.rn.f64 	%fd664, %fd662, %fd170, %fd663;
	ld.global.nc.f64 	%fd665, [%rd201+16];
	fma.rn.f64 	%fd666, %fd664, %fd170, %fd665;
	ld.global.nc.f64 	%fd667, [%rd201+24];
	fma.rn.f64 	%fd668, %fd666, %fd170, %fd667;
	ld.global.nc.f64 	%fd669, [%rd201+32];
	fma.rn.f64 	%fd670, %fd668, %fd170, %fd669;
	ld.global.nc.f64 	%fd671, [%rd201+40];
	fma.rn.f64 	%fd672, %fd670, %fd170, %fd671;
	ld.global.nc.f64 	%fd673, [%rd201+48];
	fma.rn.f64 	%fd171, %fd672, %fd170, %fd673;
	fma.rn.f64 	%fd998, %fd171, %fd996, %fd996;
	@%p171 bra 	$L__BB6_177;

	mov.f64 	%fd674, 0d3FF0000000000000;
	fma.rn.f64 	%fd998, %fd171, %fd170, %fd674;

$L__BB6_177:
	and.b32  	%r528, %r869, 2;
	setp.eq.s32 	%p172, %r528, 0;
	@%p172 bra 	$L__BB6_179;

	mov.f64 	%fd675, 0d0000000000000000;
	mov.f64 	%fd676, 0dBFF0000000000000;
	fma.rn.f64 	%fd998, %fd998, %fd676, %fd675;

$L__BB6_179:
	mul.rn.f64 	%fd677, %fd998, 0d4044000000000000;
	cvt.f64.f32 	%fd678, %f450;
	mul.rn.f64 	%fd679, %fd678, 0d4034000000000000;
	add.rn.f64 	%fd177, %fd679, %fd677;
	div.rn.f64 	%fd178, %fd164, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r529, %temp}, %fd178;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r530}, %fd178;
	}
	and.b32  	%r531, %r530, 2147483647;
	setp.eq.s32 	%p173, %r531, 2146435072;
	setp.eq.s32 	%p174, %r529, 0;
	and.pred  	%p175, %p174, %p173;
	@%p175 bra 	$L__BB6_182;
	bra.uni 	$L__BB6_180;

$L__BB6_182:
	mov.f64 	%fd689, 0d0000000000000000;
	mul.rn.f64 	%fd999, %fd178, %fd689;
	mov.u32 	%r870, 0;
	bra.uni 	$L__BB6_183;

$L__BB6_180:
	mul.rn.f64 	%fd680, %fd178, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r870, %fd680;
	st.local.u32 	[%rd1], %r870;
	cvt.rn.f64.s32 	%fd681, %r870;
	neg.f64 	%fd682, %fd681;
	mov.f64 	%fd683, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd684, %fd682, %fd683, %fd178;
	mov.f64 	%fd685, 0d3C91A62633145C00;
	fma.rn.f64 	%fd686, %fd682, %fd685, %fd684;
	mov.f64 	%fd687, 0d397B839A252049C0;
	fma.rn.f64 	%fd999, %fd682, %fd687, %fd686;
	abs.f64 	%fd688, %fd178;
	setp.ltu.f64 	%p176, %fd688, 0d41E0000000000000;
	@%p176 bra 	$L__BB6_183;

	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd999, [retval0+0];
	} // callseq 61
	ld.local.u32 	%r870, [%rd1];

$L__BB6_183:
	and.b32  	%r533, %r870, 1;
	shl.b32 	%r534, %r870, 3;
	and.b32  	%r535, %r534, 8;
	setp.eq.s32 	%p177, %r533, 0;
	selp.f64 	%fd690, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p177;
	mul.wide.s32 	%rd203, %r535, 8;
	add.s64 	%rd205, %rd106, %rd203;
	ld.global.nc.f64 	%fd691, [%rd205+8];
	mul.rn.f64 	%fd183, %fd999, %fd999;
	fma.rn.f64 	%fd692, %fd690, %fd183, %fd691;
	ld.global.nc.f64 	%fd693, [%rd205+16];
	fma.rn.f64 	%fd694, %fd692, %fd183, %fd693;
	ld.global.nc.f64 	%fd695, [%rd205+24];
	fma.rn.f64 	%fd696, %fd694, %fd183, %fd695;
	ld.global.nc.f64 	%fd697, [%rd205+32];
	fma.rn.f64 	%fd698, %fd696, %fd183, %fd697;
	ld.global.nc.f64 	%fd699, [%rd205+40];
	fma.rn.f64 	%fd700, %fd698, %fd183, %fd699;
	ld.global.nc.f64 	%fd701, [%rd205+48];
	fma.rn.f64 	%fd184, %fd700, %fd183, %fd701;
	fma.rn.f64 	%fd1001, %fd184, %fd999, %fd999;
	@%p177 bra 	$L__BB6_185;

	mov.f64 	%fd702, 0d3FF0000000000000;
	fma.rn.f64 	%fd1001, %fd184, %fd183, %fd702;

$L__BB6_185:
	and.b32  	%r536, %r870, 2;
	setp.eq.s32 	%p178, %r536, 0;
	@%p178 bra 	$L__BB6_187;

	mov.f64 	%fd703, 0d0000000000000000;
	mov.f64 	%fd704, 0dBFF0000000000000;
	fma.rn.f64 	%fd1001, %fd1001, %fd704, %fd703;

$L__BB6_187:
	mul.rn.f64 	%fd705, %fd1001, 0d4064000000000000;
	add.rn.f64 	%fd190, %fd177, %fd705;
	div.rn.f64 	%fd191, %fd164, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r537, %temp}, %fd191;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r538}, %fd191;
	}
	and.b32  	%r539, %r538, 2147483647;
	setp.eq.s32 	%p179, %r539, 2146435072;
	setp.eq.s32 	%p180, %r537, 0;
	and.pred  	%p181, %p180, %p179;
	@%p181 bra 	$L__BB6_190;
	bra.uni 	$L__BB6_188;

$L__BB6_190:
	mov.f64 	%fd715, 0d0000000000000000;
	mul.rn.f64 	%fd1002, %fd191, %fd715;
	mov.u32 	%r871, 0;
	bra.uni 	$L__BB6_191;

$L__BB6_188:
	mul.rn.f64 	%fd706, %fd191, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r871, %fd706;
	st.local.u32 	[%rd1], %r871;
	cvt.rn.f64.s32 	%fd707, %r871;
	neg.f64 	%fd708, %fd707;
	mov.f64 	%fd709, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd710, %fd708, %fd709, %fd191;
	mov.f64 	%fd711, 0d3C91A62633145C00;
	fma.rn.f64 	%fd712, %fd708, %fd711, %fd710;
	mov.f64 	%fd713, 0d397B839A252049C0;
	fma.rn.f64 	%fd1002, %fd708, %fd713, %fd712;
	abs.f64 	%fd714, %fd191;
	setp.ltu.f64 	%p182, %fd714, 0d41E0000000000000;
	@%p182 bra 	$L__BB6_191;

	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1002, [retval0+0];
	} // callseq 62
	ld.local.u32 	%r871, [%rd1];

$L__BB6_191:
	and.b32  	%r541, %r871, 1;
	shl.b32 	%r542, %r871, 3;
	and.b32  	%r543, %r542, 8;
	setp.eq.s32 	%p183, %r541, 0;
	selp.f64 	%fd716, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p183;
	mul.wide.s32 	%rd207, %r543, 8;
	add.s64 	%rd209, %rd106, %rd207;
	ld.global.nc.f64 	%fd717, [%rd209+8];
	mul.rn.f64 	%fd196, %fd1002, %fd1002;
	fma.rn.f64 	%fd718, %fd716, %fd196, %fd717;
	ld.global.nc.f64 	%fd719, [%rd209+16];
	fma.rn.f64 	%fd720, %fd718, %fd196, %fd719;
	ld.global.nc.f64 	%fd721, [%rd209+24];
	fma.rn.f64 	%fd722, %fd720, %fd196, %fd721;
	ld.global.nc.f64 	%fd723, [%rd209+32];
	fma.rn.f64 	%fd724, %fd722, %fd196, %fd723;
	ld.global.nc.f64 	%fd725, [%rd209+40];
	fma.rn.f64 	%fd726, %fd724, %fd196, %fd725;
	ld.global.nc.f64 	%fd727, [%rd209+48];
	fma.rn.f64 	%fd197, %fd726, %fd196, %fd727;
	fma.rn.f64 	%fd1004, %fd197, %fd1002, %fd1002;
	@%p183 bra 	$L__BB6_193;

	mov.f64 	%fd728, 0d3FF0000000000000;
	fma.rn.f64 	%fd1004, %fd197, %fd196, %fd728;

$L__BB6_193:
	and.b32  	%r544, %r871, 2;
	setp.eq.s32 	%p184, %r544, 0;
	@%p184 bra 	$L__BB6_195;

	mov.f64 	%fd729, 0d0000000000000000;
	mov.f64 	%fd730, 0dBFF0000000000000;
	fma.rn.f64 	%fd1004, %fd1004, %fd730, %fd729;

$L__BB6_195:
	mul.rn.f64 	%fd731, %fd1004, 0d4074000000000000;
	add.rn.f64 	%fd203, %fd190, %fd731;
	mul.rn.f32 	%f266, %f59, 0f3F22F983;
	cvt.rni.s32.f32 	%r874, %f266;
	cvt.rn.f32.s32 	%f267, %r874;
	mov.f32 	%f268, 0fBFC90FDA;
	fma.rn.f32 	%f269, %f267, %f268, %f59;
	mov.f32 	%f270, 0fB3A22168;
	fma.rn.f32 	%f271, %f267, %f270, %f269;
	mov.f32 	%f272, 0fA7C234C5;
	fma.rn.f32 	%f451, %f267, %f272, %f271;
	abs.f32 	%f74, %f59;
	setp.ltu.f32 	%p185, %f74, 0f47CE4780;
	@%p185 bra 	$L__BB6_203;

	setp.eq.f32 	%p186, %f74, 0f7F800000;
	@%p186 bra 	$L__BB6_202;
	bra.uni 	$L__BB6_197;

$L__BB6_202:
	mov.f32 	%f275, 0f00000000;
	mul.rn.f32 	%f451, %f59, %f275;
	mov.u32 	%r874, 0;
	bra.uni 	$L__BB6_203;

$L__BB6_197:
	mov.b32 	%r142, %f59;
	bfe.u32 	%r545, %r142, 23, 8;
	add.s32 	%r143, %r545, -128;
	shl.b32 	%r546, %r142, 8;
	or.b32  	%r144, %r546, -2147483648;
	shr.u32 	%r145, %r143, 5;
	mov.u64 	%rd321, 0;
	mov.u64 	%rd322, %rd321;

$L__BB6_198:
	.pragma "nounroll";
	shl.b64 	%rd212, %rd321, 2;
	mov.u64 	%rd213, __cudart_i2opi_f;
	add.s64 	%rd214, %rd213, %rd212;
	ld.global.nc.u32 	%r547, [%rd214];
	mad.wide.u32 	%rd215, %r547, %r144, %rd322;
	shr.u64 	%rd322, %rd215, 32;
	add.s64 	%rd216, %rd1, %rd212;
	st.local.u32 	[%rd216], %rd215;
	cvt.u32.u64 	%r548, %rd321;
	add.s32 	%r549, %r548, 1;
	cvt.s64.s32 	%rd321, %r549;
	setp.ne.s32 	%p187, %r549, 6;
	@%p187 bra 	$L__BB6_198;

	st.local.u32 	[%rd23], %rd322;
	mov.u32 	%r550, 4;
	sub.s32 	%r146, %r550, %r145;
	mov.u32 	%r551, 6;
	sub.s32 	%r552, %r551, %r145;
	mul.wide.s32 	%rd217, %r552, 4;
	add.s64 	%rd218, %rd1, %rd217;
	ld.local.u32 	%r872, [%rd218];
	ld.local.u32 	%r873, [%rd218+-4];
	and.b32  	%r149, %r143, 31;
	setp.eq.s32 	%p188, %r149, 0;
	@%p188 bra 	$L__BB6_201;

	mov.u32 	%r553, 32;
	sub.s32 	%r554, %r553, %r149;
	shr.u32 	%r555, %r873, %r554;
	shl.b32 	%r556, %r872, %r149;
	add.s32 	%r872, %r555, %r556;
	mul.wide.s32 	%rd219, %r146, 4;
	add.s64 	%rd220, %rd1, %rd219;
	ld.local.u32 	%r557, [%rd220];
	shr.u32 	%r558, %r557, %r554;
	shl.b32 	%r559, %r873, %r149;
	add.s32 	%r873, %r558, %r559;

$L__BB6_201:
	and.b32  	%r560, %r142, -2147483648;
	shr.u32 	%r561, %r873, 30;
	shl.b32 	%r562, %r872, 2;
	or.b32  	%r563, %r561, %r562;
	shr.u32 	%r564, %r563, 31;
	shr.u32 	%r565, %r872, 30;
	add.s32 	%r566, %r564, %r565;
	neg.s32 	%r567, %r566;
	setp.eq.s32 	%p189, %r560, 0;
	selp.b32 	%r874, %r566, %r567, %p189;
	setp.ne.s32 	%p190, %r564, 0;
	xor.b32  	%r568, %r560, -2147483648;
	selp.b32 	%r569, %r568, %r560, %p190;
	selp.b32 	%r570, -1, 0, %p190;
	xor.b32  	%r571, %r563, %r570;
	shl.b32 	%r572, %r873, 2;
	xor.b32  	%r573, %r572, %r570;
	cvt.u64.u32 	%rd221, %r571;
	cvt.u64.u32 	%rd222, %r573;
	bfi.b64 	%rd223, %rd221, %rd222, 32, 32;
	cvt.rn.f64.s64 	%fd732, %rd223;
	mul.rn.f64 	%fd733, %fd732, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f273, %fd733;
	setp.eq.s32 	%p191, %r569, 0;
	neg.f32 	%f274, %f273;
	selp.f32 	%f451, %f273, %f274, %p191;

$L__BB6_203:
	cvt.rn.f32.f64 	%f277, %fd163;
	cvt.f64.f32 	%fd204, %f277;
	and.b32  	%r156, %r874, 1;
	setp.eq.s32 	%p192, %r156, 0;
	selp.f32 	%f78, %f451, 0f3F800000, %p192;
	mul.rn.f32 	%f79, %f451, %f451;
	mov.f32 	%f452, 0fB94D4153;
	@%p192 bra 	$L__BB6_205;

	mov.f32 	%f278, 0fBAB607ED;
	mov.f32 	%f279, 0f37CBAC00;
	fma.rn.f32 	%f452, %f279, %f79, %f278;

$L__BB6_205:
	selp.f32 	%f280, 0f3C0885E4, 0f3D2AAABB, %p192;
	fma.rn.f32 	%f281, %f452, %f79, %f280;
	selp.f32 	%f282, 0fBE2AAAA8, 0fBEFFFFFF, %p192;
	fma.rn.f32 	%f283, %f281, %f79, %f282;
	mov.f32 	%f284, 0f00000000;
	fma.rn.f32 	%f285, %f79, %f78, %f284;
	fma.rn.f32 	%f453, %f283, %f285, %f78;
	and.b32  	%r575, %r874, 2;
	setp.eq.s32 	%p194, %r575, 0;
	@%p194 bra 	$L__BB6_207;

	mov.f32 	%f287, 0fBF800000;
	fma.rn.f32 	%f453, %f453, %f287, %f284;

$L__BB6_207:
	div.rn.f64 	%fd205, %fd138, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r576, %temp}, %fd205;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r577}, %fd205;
	}
	and.b32  	%r578, %r577, 2147483647;
	setp.eq.s32 	%p195, %r578, 2146435072;
	setp.eq.s32 	%p196, %r576, 0;
	and.pred  	%p197, %p196, %p195;
	@%p197 bra 	$L__BB6_210;
	bra.uni 	$L__BB6_208;

$L__BB6_210:
	mov.f64 	%fd743, 0d0000000000000000;
	mul.rn.f64 	%fd1005, %fd205, %fd743;
	mov.u32 	%r875, 0;
	bra.uni 	$L__BB6_211;

$L__BB6_208:
	mul.rn.f64 	%fd734, %fd205, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r875, %fd734;
	st.local.u32 	[%rd1], %r875;
	cvt.rn.f64.s32 	%fd735, %r875;
	neg.f64 	%fd736, %fd735;
	mov.f64 	%fd737, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd738, %fd736, %fd737, %fd205;
	mov.f64 	%fd739, 0d3C91A62633145C00;
	fma.rn.f64 	%fd740, %fd736, %fd739, %fd738;
	mov.f64 	%fd741, 0d397B839A252049C0;
	fma.rn.f64 	%fd1005, %fd736, %fd741, %fd740;
	abs.f64 	%fd742, %fd205;
	setp.ltu.f64 	%p198, %fd742, 0d41E0000000000000;
	@%p198 bra 	$L__BB6_211;

	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd205;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1005, [retval0+0];
	} // callseq 63
	ld.local.u32 	%r875, [%rd1];

$L__BB6_211:
	and.b32  	%r580, %r875, 1;
	shl.b32 	%r581, %r875, 3;
	and.b32  	%r582, %r581, 8;
	setp.eq.s32 	%p199, %r580, 0;
	selp.f64 	%fd744, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p199;
	mul.wide.s32 	%rd225, %r582, 8;
	add.s64 	%rd227, %rd106, %rd225;
	ld.global.nc.f64 	%fd745, [%rd227+8];
	mul.rn.f64 	%fd210, %fd1005, %fd1005;
	fma.rn.f64 	%fd746, %fd744, %fd210, %fd745;
	ld.global.nc.f64 	%fd747, [%rd227+16];
	fma.rn.f64 	%fd748, %fd746, %fd210, %fd747;
	ld.global.nc.f64 	%fd749, [%rd227+24];
	fma.rn.f64 	%fd750, %fd748, %fd210, %fd749;
	ld.global.nc.f64 	%fd751, [%rd227+32];
	fma.rn.f64 	%fd752, %fd750, %fd210, %fd751;
	ld.global.nc.f64 	%fd753, [%rd227+40];
	fma.rn.f64 	%fd754, %fd752, %fd210, %fd753;
	ld.global.nc.f64 	%fd755, [%rd227+48];
	fma.rn.f64 	%fd211, %fd754, %fd210, %fd755;
	fma.rn.f64 	%fd1007, %fd211, %fd1005, %fd1005;
	@%p199 bra 	$L__BB6_213;

	mov.f64 	%fd756, 0d3FF0000000000000;
	fma.rn.f64 	%fd1007, %fd211, %fd210, %fd756;

$L__BB6_213:
	and.b32  	%r583, %r875, 2;
	setp.eq.s32 	%p200, %r583, 0;
	@%p200 bra 	$L__BB6_215;

	mov.f64 	%fd757, 0d0000000000000000;
	mov.f64 	%fd758, 0dBFF0000000000000;
	fma.rn.f64 	%fd1007, %fd1007, %fd758, %fd757;

$L__BB6_215:
	mul.rn.f64 	%fd759, %fd1007, 0d4044000000000000;
	cvt.f64.f32 	%fd760, %f453;
	mul.rn.f64 	%fd761, %fd760, 0d4034000000000000;
	add.rn.f64 	%fd217, %fd761, %fd759;
	div.rn.f64 	%fd218, %fd138, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r584, %temp}, %fd218;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r585}, %fd218;
	}
	and.b32  	%r586, %r585, 2147483647;
	setp.eq.s32 	%p201, %r586, 2146435072;
	setp.eq.s32 	%p202, %r584, 0;
	and.pred  	%p203, %p202, %p201;
	@%p203 bra 	$L__BB6_218;
	bra.uni 	$L__BB6_216;

$L__BB6_218:
	mov.f64 	%fd771, 0d0000000000000000;
	mul.rn.f64 	%fd1008, %fd218, %fd771;
	mov.u32 	%r876, 0;
	bra.uni 	$L__BB6_219;

$L__BB6_216:
	mul.rn.f64 	%fd762, %fd218, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r876, %fd762;
	st.local.u32 	[%rd1], %r876;
	cvt.rn.f64.s32 	%fd763, %r876;
	neg.f64 	%fd764, %fd763;
	mov.f64 	%fd765, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd766, %fd764, %fd765, %fd218;
	mov.f64 	%fd767, 0d3C91A62633145C00;
	fma.rn.f64 	%fd768, %fd764, %fd767, %fd766;
	mov.f64 	%fd769, 0d397B839A252049C0;
	fma.rn.f64 	%fd1008, %fd764, %fd769, %fd768;
	abs.f64 	%fd770, %fd218;
	setp.ltu.f64 	%p204, %fd770, 0d41E0000000000000;
	@%p204 bra 	$L__BB6_219;

	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd218;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1008, [retval0+0];
	} // callseq 64
	ld.local.u32 	%r876, [%rd1];

$L__BB6_219:
	and.b32  	%r588, %r876, 1;
	shl.b32 	%r589, %r876, 3;
	and.b32  	%r590, %r589, 8;
	setp.eq.s32 	%p205, %r588, 0;
	selp.f64 	%fd772, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p205;
	mul.wide.s32 	%rd229, %r590, 8;
	add.s64 	%rd231, %rd106, %rd229;
	ld.global.nc.f64 	%fd773, [%rd231+8];
	mul.rn.f64 	%fd223, %fd1008, %fd1008;
	fma.rn.f64 	%fd774, %fd772, %fd223, %fd773;
	ld.global.nc.f64 	%fd775, [%rd231+16];
	fma.rn.f64 	%fd776, %fd774, %fd223, %fd775;
	ld.global.nc.f64 	%fd777, [%rd231+24];
	fma.rn.f64 	%fd778, %fd776, %fd223, %fd777;
	ld.global.nc.f64 	%fd779, [%rd231+32];
	fma.rn.f64 	%fd780, %fd778, %fd223, %fd779;
	ld.global.nc.f64 	%fd781, [%rd231+40];
	fma.rn.f64 	%fd782, %fd780, %fd223, %fd781;
	ld.global.nc.f64 	%fd783, [%rd231+48];
	fma.rn.f64 	%fd224, %fd782, %fd223, %fd783;
	fma.rn.f64 	%fd1010, %fd224, %fd1008, %fd1008;
	@%p205 bra 	$L__BB6_221;

	mov.f64 	%fd784, 0d3FF0000000000000;
	fma.rn.f64 	%fd1010, %fd224, %fd223, %fd784;

$L__BB6_221:
	and.b32  	%r591, %r876, 2;
	setp.eq.s32 	%p206, %r591, 0;
	@%p206 bra 	$L__BB6_223;

	mov.f64 	%fd785, 0d0000000000000000;
	mov.f64 	%fd786, 0dBFF0000000000000;
	fma.rn.f64 	%fd1010, %fd1010, %fd786, %fd785;

$L__BB6_223:
	mul.rn.f64 	%fd787, %fd1010, 0d4062C00000000000;
	add.rn.f64 	%fd230, %fd217, %fd787;
	div.rn.f64 	%fd231, %fd138, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r592, %temp}, %fd231;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r593}, %fd231;
	}
	and.b32  	%r594, %r593, 2147483647;
	setp.eq.s32 	%p207, %r594, 2146435072;
	setp.eq.s32 	%p208, %r592, 0;
	and.pred  	%p209, %p208, %p207;
	@%p209 bra 	$L__BB6_226;
	bra.uni 	$L__BB6_224;

$L__BB6_226:
	mov.f64 	%fd797, 0d0000000000000000;
	mul.rn.f64 	%fd1011, %fd231, %fd797;
	mov.u32 	%r877, 0;
	bra.uni 	$L__BB6_227;

$L__BB6_224:
	mul.rn.f64 	%fd788, %fd231, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r877, %fd788;
	st.local.u32 	[%rd1], %r877;
	cvt.rn.f64.s32 	%fd789, %r877;
	neg.f64 	%fd790, %fd789;
	mov.f64 	%fd791, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd792, %fd790, %fd791, %fd231;
	mov.f64 	%fd793, 0d3C91A62633145C00;
	fma.rn.f64 	%fd794, %fd790, %fd793, %fd792;
	mov.f64 	%fd795, 0d397B839A252049C0;
	fma.rn.f64 	%fd1011, %fd790, %fd795, %fd794;
	abs.f64 	%fd796, %fd231;
	setp.ltu.f64 	%p210, %fd796, 0d41E0000000000000;
	@%p210 bra 	$L__BB6_227;

	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd231;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1011, [retval0+0];
	} // callseq 65
	ld.local.u32 	%r877, [%rd1];

$L__BB6_227:
	and.b32  	%r596, %r877, 1;
	shl.b32 	%r597, %r877, 3;
	and.b32  	%r598, %r597, 8;
	setp.eq.s32 	%p211, %r596, 0;
	selp.f64 	%fd798, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p211;
	mul.wide.s32 	%rd233, %r598, 8;
	add.s64 	%rd235, %rd106, %rd233;
	ld.global.nc.f64 	%fd799, [%rd235+8];
	mul.rn.f64 	%fd236, %fd1011, %fd1011;
	fma.rn.f64 	%fd800, %fd798, %fd236, %fd799;
	ld.global.nc.f64 	%fd801, [%rd235+16];
	fma.rn.f64 	%fd802, %fd800, %fd236, %fd801;
	ld.global.nc.f64 	%fd803, [%rd235+24];
	fma.rn.f64 	%fd804, %fd802, %fd236, %fd803;
	ld.global.nc.f64 	%fd805, [%rd235+32];
	fma.rn.f64 	%fd806, %fd804, %fd236, %fd805;
	ld.global.nc.f64 	%fd807, [%rd235+40];
	fma.rn.f64 	%fd808, %fd806, %fd236, %fd807;
	ld.global.nc.f64 	%fd809, [%rd235+48];
	fma.rn.f64 	%fd237, %fd808, %fd236, %fd809;
	fma.rn.f64 	%fd1013, %fd237, %fd1011, %fd1011;
	@%p211 bra 	$L__BB6_229;

	mov.f64 	%fd810, 0d3FF0000000000000;
	fma.rn.f64 	%fd1013, %fd237, %fd236, %fd810;

$L__BB6_229:
	and.b32  	%r599, %r877, 2;
	setp.eq.s32 	%p212, %r599, 0;
	@%p212 bra 	$L__BB6_231;

	mov.f64 	%fd811, 0d0000000000000000;
	mov.f64 	%fd812, 0dBFF0000000000000;
	fma.rn.f64 	%fd1013, %fd1013, %fd812, %fd811;

$L__BB6_231:
	mul.rn.f64 	%fd813, %fd1013, 0d4072C00000000000;
	add.rn.f64 	%fd814, %fd230, %fd813;
	add.rn.f64 	%fd243, %fd814, %fd204;
	add.rn.f64 	%fd244, %fd203, %fd204;
	add.rn.f64 	%fd815, %fd136, %fd136;
	add.rn.f64 	%fd816, %fd815, 0dC059000000000000;
	mul.rn.f64 	%fd817, %fd137, 0d4008000000000000;
	add.rn.f64 	%fd245, %fd816, %fd817;
	abs.f64 	%fd246, %fd137;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1016, [retval0+0];
	} // callseq 66
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd137;
	}
	setp.lt.s32 	%p213, %r166, 0;
	and.pred  	%p4, %p213, %p78;
	not.pred 	%p215, %p4;
	@%p215 bra 	$L__BB6_233;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r600}, %fd1016;
	}
	xor.b32  	%r601, %r600, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r602, %temp}, %fd1016;
	}
	mov.b64 	%fd1016, {%r602, %r601};

$L__BB6_233:
	add.rn.f32 	%f427, %f468, 0fC20C0000;
	setp.eq.f32 	%p216, %f427, 0f00000000;
	@%p216 bra 	$L__BB6_237;
	bra.uni 	$L__BB6_234;

$L__BB6_237:
	setp.lt.s32 	%p219, %r62, 0;
	mov.u32 	%r603, 0;
	selp.b32 	%r604, %r166, 0, %p78;
	or.b32  	%r605, %r604, 2146435072;
	selp.b32 	%r606, %r605, %r604, %p219;
	mov.b64 	%fd1016, {%r603, %r606};
	bra.uni 	$L__BB6_238;

$L__BB6_234:
	setp.gt.s32 	%p217, %r166, -1;
	@%p217 bra 	$L__BB6_238;

	mov.f64 	%fd818, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd819, %fd818;
	setp.eq.f64 	%p218, %fd819, 0d4000000000000000;
	@%p218 bra 	$L__BB6_238;

	mov.f64 	%fd1016, 0dFFF8000000000000;

$L__BB6_238:
	add.rn.f64 	%fd821, %fd137, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r607}, %fd821;
	}
	and.b32  	%r608, %r607, 2146435072;
	setp.ne.s32 	%p221, %r608, 2146435072;
	@%p221 bra 	$L__BB6_245;

	setp.gtu.f64 	%p222, %fd246, 0d7FF0000000000000;
	@%p222 bra 	$L__BB6_244;
	bra.uni 	$L__BB6_240;

$L__BB6_244:
	mov.f64 	%fd823, 0d4000000000000000;
	add.rn.f64 	%fd1016, %fd137, %fd823;
	bra.uni 	$L__BB6_245;

$L__BB6_240:
	setp.eq.s32 	%p223, %r104, 2146435072;
	mov.f64 	%fd822, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r609, %temp}, %fd822;
	}
	setp.eq.s32 	%p224, %r609, 0;
	and.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB6_243;
	bra.uni 	$L__BB6_241;

$L__BB6_243:
	add.rn.f32 	%f433, %f468, 0fC20C0000;
	setp.lt.s32 	%p231, %r62, 0;
	mov.u32 	%r614, 0;
	setp.gt.f64 	%p232, %fd246, 0d3FF0000000000000;
	selp.b32 	%r615, 2146435072, 0, %p232;
	xor.b32  	%r616, %r615, 2146435072;
	selp.b32 	%r617, %r616, %r615, %p231;
	setp.eq.f32 	%p233, %f433, 0fBF800000;
	selp.b32 	%r618, 1072693248, %r617, %p233;
	mov.b64 	%fd1016, {%r614, %r618};
	bra.uni 	$L__BB6_245;

$L__BB6_241:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r610, %temp}, %fd137;
	}
	and.b32  	%r611, %r166, 2147483647;
	setp.ne.s32 	%p226, %r611, 2146435072;
	setp.ne.s32 	%p227, %r610, 0;
	or.pred  	%p228, %p226, %p227;
	@%p228 bra 	$L__BB6_245;

	setp.ne.s32 	%p229, %r104, 1071644672;
	and.pred  	%p230, %p229, %p4;
	selp.b32 	%r612, %r106, %r105, %p230;
	mov.u32 	%r613, 0;
	mov.b64 	%fd1016, {%r613, %r612};

$L__BB6_245:
	add.rn.f32 	%f429, %f467, 0fC2D20000;
	add.rn.f32 	%f428, %f468, 0fC20C0000;
	mul.rn.f64 	%fd824, %fd1016, 0d3FC999999999999A;
	setp.eq.f32 	%p234, %f428, 0f3F800000;
	selp.f64 	%fd825, 0d3FC999999999999A, %fd824, %p234;
	add.rn.f64 	%fd826, %fd245, %fd825;
	mul.rn.f32 	%f288, %f429, %f428;
	cvt.f64.f32 	%fd827, %f288;
	mul.rn.f64 	%fd256, %fd827, 0d3FB999999999999A;
	add.rn.f64 	%fd828, %fd256, %fd826;
	abs.f32 	%f289, %f429;
	sqrt.rn.f32 	%f290, %f289;
	cvt.f64.f32 	%fd257, %f290;
	mul.rn.f64 	%fd829, %fd257, 0d3FC999999999999A;
	add.rn.f64 	%fd830, %fd829, %fd828;
	cvt.rn.f32.f64 	%f291, %fd244;
	cvt.f64.f32 	%fd831, %f291;
	mul.rn.f64 	%fd832, %fd831, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f292, %fd832;
	cvt.f64.f32 	%fd833, %f292;
	add.rn.f64 	%fd258, %fd830, %fd833;
	add.rn.f64 	%fd834, %fd137, %fd137;
	add.rn.f64 	%fd835, %fd136, 0d4072C00000000000;
	add.rn.f64 	%fd259, %fd835, %fd834;
	abs.f64 	%fd260, %fd136;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd260;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1019, [retval0+0];
	} // callseq 67
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r167}, %fd136;
	}
	setp.lt.s32 	%p235, %r167, 0;
	and.pred  	%p5, %p235, %p78;
	not.pred 	%p237, %p5;
	@%p237 bra 	$L__BB6_247;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r619}, %fd1019;
	}
	xor.b32  	%r620, %r619, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r621, %temp}, %fd1019;
	}
	mov.b64 	%fd1019, {%r621, %r620};

$L__BB6_247:
	add.rn.f32 	%f430, %f467, 0fC2D20000;
	setp.eq.f32 	%p238, %f430, 0f00000000;
	@%p238 bra 	$L__BB6_251;
	bra.uni 	$L__BB6_248;

$L__BB6_251:
	setp.lt.s32 	%p241, %r62, 0;
	mov.u32 	%r622, 0;
	selp.b32 	%r623, %r167, 0, %p78;
	or.b32  	%r624, %r623, 2146435072;
	selp.b32 	%r625, %r624, %r623, %p241;
	mov.b64 	%fd1019, {%r622, %r625};
	bra.uni 	$L__BB6_252;

$L__BB6_248:
	setp.gt.s32 	%p239, %r167, -1;
	@%p239 bra 	$L__BB6_252;

	mov.f64 	%fd836, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd837, %fd836;
	setp.eq.f64 	%p240, %fd837, 0d4000000000000000;
	@%p240 bra 	$L__BB6_252;

	mov.f64 	%fd1019, 0dFFF8000000000000;

$L__BB6_252:
	add.rn.f64 	%fd839, %fd136, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r626}, %fd839;
	}
	and.b32  	%r627, %r626, 2146435072;
	setp.ne.s32 	%p243, %r627, 2146435072;
	@%p243 bra 	$L__BB6_259;

	setp.gtu.f64 	%p244, %fd260, 0d7FF0000000000000;
	@%p244 bra 	$L__BB6_258;
	bra.uni 	$L__BB6_254;

$L__BB6_258:
	mov.f64 	%fd841, 0d4000000000000000;
	add.rn.f64 	%fd1019, %fd136, %fd841;
	bra.uni 	$L__BB6_259;

$L__BB6_254:
	setp.eq.s32 	%p245, %r104, 2146435072;
	mov.f64 	%fd840, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r628, %temp}, %fd840;
	}
	setp.eq.s32 	%p246, %r628, 0;
	and.pred  	%p247, %p245, %p246;
	@%p247 bra 	$L__BB6_257;
	bra.uni 	$L__BB6_255;

$L__BB6_257:
	add.rn.f32 	%f432, %f467, 0fC2D20000;
	setp.lt.s32 	%p253, %r62, 0;
	mov.u32 	%r633, 0;
	setp.gt.f64 	%p254, %fd260, 0d3FF0000000000000;
	selp.b32 	%r634, 2146435072, 0, %p254;
	xor.b32  	%r635, %r634, 2146435072;
	selp.b32 	%r636, %r635, %r634, %p253;
	setp.eq.f32 	%p255, %f432, 0fBF800000;
	selp.b32 	%r637, 1072693248, %r636, %p255;
	mov.b64 	%fd1019, {%r633, %r637};
	bra.uni 	$L__BB6_259;

$L__BB6_255:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r629, %temp}, %fd136;
	}
	and.b32  	%r630, %r167, 2147483647;
	setp.ne.s32 	%p248, %r630, 2146435072;
	setp.ne.s32 	%p249, %r629, 0;
	or.pred  	%p250, %p248, %p249;
	@%p250 bra 	$L__BB6_259;

	setp.ne.s32 	%p251, %r104, 1071644672;
	and.pred  	%p252, %p251, %p5;
	selp.b32 	%r631, %r106, %r105, %p252;
	mov.u32 	%r632, 0;
	mov.b64 	%fd1019, {%r632, %r631};

$L__BB6_259:
	add.rn.f32 	%f431, %f467, 0fC2D20000;
	mul.rn.f64 	%fd842, %fd1019, 0d3FB999999999999A;
	setp.eq.f32 	%p256, %f431, 0f3F800000;
	selp.f64 	%fd843, 0d3FB999999999999A, %fd842, %p256;
	add.rn.f64 	%fd844, %fd259, %fd843;
	add.rn.f64 	%fd845, %fd256, %fd844;
	mul.rn.f64 	%fd846, %fd257, 0d3FB999999999999A;
	add.rn.f64 	%fd847, %fd846, %fd845;
	cvt.rn.f32.f64 	%f293, %fd243;
	cvt.f64.f32 	%fd848, %f293;
	mul.rn.f64 	%fd849, %fd848, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f294, %fd849;
	cvt.f64.f32 	%fd850, %f294;
	add.rn.f64 	%fd270, %fd847, %fd850;
	cvt.f64.f32 	%fd271, %f468;
	div.rn.f64 	%fd851, %fd271, 0d4066800000000000;
	mul.rn.f64 	%fd852, %fd851, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f85, %fd852;
	mul.rn.f32 	%f295, %f85, 0f3F22F983;
	cvt.rni.s32.f32 	%r883, %f295;
	cvt.rn.f32.s32 	%f296, %r883;
	mov.f32 	%f297, 0fBFC90FDA;
	fma.rn.f32 	%f298, %f296, %f297, %f85;
	mov.f32 	%f299, 0fB3A22168;
	fma.rn.f32 	%f300, %f296, %f299, %f298;
	mov.f32 	%f301, 0fA7C234C5;
	fma.rn.f32 	%f457, %f296, %f301, %f300;
	abs.f32 	%f87, %f85;
	setp.ltu.f32 	%p257, %f87, 0f47CE4780;
	mov.u32 	%r880, %r883;
	mov.f32 	%f454, %f457;
	@%p257 bra 	$L__BB6_267;

	setp.eq.f32 	%p258, %f87, 0f7F800000;
	@%p258 bra 	$L__BB6_266;
	bra.uni 	$L__BB6_261;

$L__BB6_266:
	mov.f32 	%f304, 0f00000000;
	mul.rn.f32 	%f454, %f85, %f304;
	mov.u32 	%r880, 0;
	bra.uni 	$L__BB6_267;

$L__BB6_261:
	mov.b32 	%r169, %f85;
	bfe.u32 	%r638, %r169, 23, 8;
	add.s32 	%r170, %r638, -128;
	shl.b32 	%r639, %r169, 8;
	or.b32  	%r171, %r639, -2147483648;
	shr.u32 	%r172, %r170, 5;
	mov.u64 	%rd323, 0;
	mov.u64 	%rd324, %rd323;

$L__BB6_262:
	.pragma "nounroll";
	shl.b64 	%rd238, %rd323, 2;
	mov.u64 	%rd239, __cudart_i2opi_f;
	add.s64 	%rd240, %rd239, %rd238;
	ld.global.nc.u32 	%r640, [%rd240];
	mad.wide.u32 	%rd241, %r640, %r171, %rd324;
	shr.u64 	%rd324, %rd241, 32;
	add.s64 	%rd242, %rd1, %rd238;
	st.local.u32 	[%rd242], %rd241;
	cvt.u32.u64 	%r641, %rd323;
	add.s32 	%r642, %r641, 1;
	cvt.s64.s32 	%rd323, %r642;
	setp.ne.s32 	%p259, %r642, 6;
	@%p259 bra 	$L__BB6_262;

	st.local.u32 	[%rd23], %rd324;
	mov.u32 	%r643, 4;
	sub.s32 	%r173, %r643, %r172;
	mov.u32 	%r644, 6;
	sub.s32 	%r645, %r644, %r172;
	mul.wide.s32 	%rd243, %r645, 4;
	add.s64 	%rd244, %rd1, %rd243;
	ld.local.u32 	%r878, [%rd244];
	ld.local.u32 	%r879, [%rd244+-4];
	and.b32  	%r176, %r170, 31;
	setp.eq.s32 	%p260, %r176, 0;
	@%p260 bra 	$L__BB6_265;

	mov.u32 	%r646, 32;
	sub.s32 	%r647, %r646, %r176;
	shr.u32 	%r648, %r879, %r647;
	shl.b32 	%r649, %r878, %r176;
	add.s32 	%r878, %r648, %r649;
	mul.wide.s32 	%rd245, %r173, 4;
	add.s64 	%rd246, %rd1, %rd245;
	ld.local.u32 	%r650, [%rd246];
	shr.u32 	%r651, %r650, %r647;
	shl.b32 	%r652, %r879, %r176;
	add.s32 	%r879, %r651, %r652;

$L__BB6_265:
	and.b32  	%r653, %r169, -2147483648;
	shr.u32 	%r654, %r879, 30;
	shl.b32 	%r655, %r878, 2;
	or.b32  	%r656, %r654, %r655;
	shr.u32 	%r657, %r656, 31;
	shr.u32 	%r658, %r878, 30;
	add.s32 	%r659, %r657, %r658;
	neg.s32 	%r660, %r659;
	setp.eq.s32 	%p261, %r653, 0;
	selp.b32 	%r880, %r659, %r660, %p261;
	setp.ne.s32 	%p262, %r657, 0;
	xor.b32  	%r661, %r653, -2147483648;
	selp.b32 	%r662, %r661, %r653, %p262;
	selp.b32 	%r663, -1, 0, %p262;
	xor.b32  	%r664, %r656, %r663;
	shl.b32 	%r665, %r879, 2;
	xor.b32  	%r666, %r665, %r663;
	cvt.u64.u32 	%rd247, %r664;
	cvt.u64.u32 	%rd248, %r666;
	bfi.b64 	%rd249, %rd247, %rd248, 32, 32;
	cvt.rn.f64.s64 	%fd853, %rd249;
	mul.rn.f64 	%fd854, %fd853, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f302, %fd854;
	setp.eq.s32 	%p263, %r662, 0;
	neg.f32 	%f303, %f302;
	selp.f32 	%f454, %f302, %f303, %p263;

$L__BB6_267:
	and.b32  	%r183, %r880, 1;
	setp.eq.s32 	%p264, %r183, 0;
	selp.f32 	%f91, %f454, 0f3F800000, %p264;
	mul.rn.f32 	%f92, %f454, %f454;
	mov.f32 	%f455, 0fB94D4153;
	@%p264 bra 	$L__BB6_269;

	mov.f32 	%f306, 0fBAB607ED;
	mov.f32 	%f307, 0f37CBAC00;
	fma.rn.f32 	%f455, %f307, %f92, %f306;

$L__BB6_269:
	selp.f32 	%f308, 0f3C0885E4, 0f3D2AAABB, %p264;
	fma.rn.f32 	%f309, %f455, %f92, %f308;
	selp.f32 	%f310, 0fBE2AAAA8, 0fBEFFFFFF, %p264;
	fma.rn.f32 	%f311, %f309, %f92, %f310;
	mov.f32 	%f312, 0f00000000;
	fma.rn.f32 	%f313, %f92, %f91, %f312;
	fma.rn.f32 	%f456, %f311, %f313, %f91;
	and.b32  	%r668, %r880, 2;
	setp.eq.s32 	%p266, %r668, 0;
	@%p266 bra 	$L__BB6_271;

	mov.f32 	%f315, 0fBF800000;
	fma.rn.f32 	%f456, %f456, %f315, %f312;

$L__BB6_271:
	@%p257 bra 	$L__BB6_279;

	setp.eq.f32 	%p268, %f87, 0f7F800000;
	@%p268 bra 	$L__BB6_278;
	bra.uni 	$L__BB6_273;

$L__BB6_278:
	mov.f32 	%f318, 0f00000000;
	mul.rn.f32 	%f457, %f85, %f318;
	mov.u32 	%r883, 0;
	bra.uni 	$L__BB6_279;

$L__BB6_273:
	mov.b32 	%r184, %f85;
	bfe.u32 	%r669, %r184, 23, 8;
	add.s32 	%r185, %r669, -128;
	shl.b32 	%r670, %r184, 8;
	or.b32  	%r186, %r670, -2147483648;
	shr.u32 	%r187, %r185, 5;
	mov.u64 	%rd325, 0;
	mov.u64 	%rd326, %rd325;

$L__BB6_274:
	.pragma "nounroll";
	shl.b64 	%rd252, %rd325, 2;
	mov.u64 	%rd253, __cudart_i2opi_f;
	add.s64 	%rd254, %rd253, %rd252;
	ld.global.nc.u32 	%r671, [%rd254];
	mad.wide.u32 	%rd255, %r671, %r186, %rd326;
	shr.u64 	%rd326, %rd255, 32;
	add.s64 	%rd256, %rd1, %rd252;
	st.local.u32 	[%rd256], %rd255;
	cvt.u32.u64 	%r672, %rd325;
	add.s32 	%r673, %r672, 1;
	cvt.s64.s32 	%rd325, %r673;
	setp.ne.s32 	%p269, %r673, 6;
	@%p269 bra 	$L__BB6_274;

	st.local.u32 	[%rd23], %rd326;
	mov.u32 	%r674, 4;
	sub.s32 	%r188, %r674, %r187;
	mov.u32 	%r675, 6;
	sub.s32 	%r676, %r675, %r187;
	mul.wide.s32 	%rd257, %r676, 4;
	add.s64 	%rd258, %rd1, %rd257;
	ld.local.u32 	%r881, [%rd258];
	ld.local.u32 	%r882, [%rd258+-4];
	and.b32  	%r191, %r185, 31;
	setp.eq.s32 	%p270, %r191, 0;
	@%p270 bra 	$L__BB6_277;

	mov.u32 	%r677, 32;
	sub.s32 	%r678, %r677, %r191;
	shr.u32 	%r679, %r882, %r678;
	shl.b32 	%r680, %r881, %r191;
	add.s32 	%r881, %r679, %r680;
	mul.wide.s32 	%rd259, %r188, 4;
	add.s64 	%rd260, %rd1, %rd259;
	ld.local.u32 	%r681, [%rd260];
	shr.u32 	%r682, %r681, %r678;
	shl.b32 	%r683, %r882, %r191;
	add.s32 	%r882, %r682, %r683;

$L__BB6_277:
	and.b32  	%r684, %r184, -2147483648;
	shr.u32 	%r685, %r882, 30;
	shl.b32 	%r686, %r881, 2;
	or.b32  	%r687, %r685, %r686;
	shr.u32 	%r688, %r687, 31;
	shr.u32 	%r689, %r881, 30;
	add.s32 	%r690, %r688, %r689;
	neg.s32 	%r691, %r690;
	setp.eq.s32 	%p271, %r684, 0;
	selp.b32 	%r883, %r690, %r691, %p271;
	setp.ne.s32 	%p272, %r688, 0;
	xor.b32  	%r692, %r684, -2147483648;
	selp.b32 	%r693, %r692, %r684, %p272;
	selp.b32 	%r694, -1, 0, %p272;
	xor.b32  	%r695, %r687, %r694;
	shl.b32 	%r696, %r882, 2;
	xor.b32  	%r697, %r696, %r694;
	cvt.u64.u32 	%rd261, %r695;
	cvt.u64.u32 	%rd262, %r697;
	bfi.b64 	%rd263, %rd261, %rd262, 32, 32;
	cvt.rn.f64.s64 	%fd855, %rd263;
	mul.rn.f64 	%fd856, %fd855, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f316, %fd856;
	setp.eq.s32 	%p273, %r693, 0;
	neg.f32 	%f317, %f316;
	selp.f32 	%f457, %f316, %f317, %p273;

$L__BB6_279:
	add.s32 	%r198, %r883, 1;
	and.b32  	%r199, %r198, 1;
	setp.eq.s32 	%p6, %r199, 0;
	mul.rn.f32 	%f101, %f457, %f457;
	mov.f32 	%f458, 0fB94D4153;
	@%p6 bra 	$L__BB6_281;

	mov.f32 	%f320, 0fBAB607ED;
	mov.f32 	%f321, 0f37CBAC00;
	fma.rn.f32 	%f458, %f321, %f101, %f320;

$L__BB6_281:
	selp.f32 	%f322, %f457, 0f3F800000, %p6;
	selp.f32 	%f323, 0f3C0885E4, 0f3D2AAABB, %p6;
	fma.rn.f32 	%f324, %f458, %f101, %f323;
	selp.f32 	%f325, 0fBE2AAAA8, 0fBEFFFFFF, %p6;
	fma.rn.f32 	%f326, %f324, %f101, %f325;
	mov.f32 	%f327, 0f00000000;
	fma.rn.f32 	%f328, %f101, %f322, %f327;
	fma.rn.f32 	%f459, %f326, %f328, %f322;
	and.b32  	%r699, %r198, 2;
	setp.eq.s32 	%p275, %r699, 0;
	@%p275 bra 	$L__BB6_283;

	mov.f32 	%f330, 0fBF800000;
	fma.rn.f32 	%f459, %f459, %f330, %f327;

$L__BB6_283:
	ld.param.s8 	%rs2, [gcj02_to_wgs84_exact_cuda_float_param_4];
	cvt.f64.f32 	%fd857, %f456;
	mul.rn.f64 	%fd858, %fd857, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd859, %fd858, %fd857;
	add.rn.f64 	%fd860, %fd859, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f331, %fd860;
	sqrt.rn.f32 	%f332, %f331;
	mov.f32 	%f333, 0f4AC2A60A;
	div.rn.f32 	%f334, %f333, %f332;
	mul.rn.f32 	%f335, %f334, %f459;
	cvt.f64.f32 	%fd861, %f335;
	mul.rn.f64 	%fd862, %fd861, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f336, %fd270;
	cvt.f64.f32 	%fd863, %f336;
	mul.rn.f64 	%fd864, %fd863, 0d4066800000000000;
	div.rn.f64 	%fd865, %fd864, %fd862;
	cvt.rn.f32.f64 	%f337, %fd865;
	add.rn.f32 	%f338, %f467, %f337;
	sub.rn.f32 	%f107, %f1, %f338;
	mul.rn.f32 	%f339, %f332, %f331;
	cvt.f64.f32 	%fd866, %f339;
	mov.f64 	%fd867, 0d41582B102DE355C1;
	div.rn.f64 	%fd868, %fd867, %fd866;
	mul.rn.f64 	%fd869, %fd868, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f340, %fd258;
	cvt.f64.f32 	%fd870, %f340;
	mul.rn.f64 	%fd871, %fd870, 0d4066800000000000;
	div.rn.f64 	%fd872, %fd871, %fd869;
	cvt.rn.f32.f64 	%f341, %fd872;
	add.rn.f32 	%f342, %f468, %f341;
	sub.rn.f32 	%f108, %f3, %f342;
	add.rn.f32 	%f447, %f467, %f107;
	add.rn.f32 	%f446, %f468, %f108;
	setp.eq.s16 	%p276, %rs2, 0;
	@%p276 bra 	$L__BB6_358;

	mul.rn.f64 	%fd873, %fd271, 0d400921FB54442D18;
	div.rn.f64 	%fd874, %fd873, 0d4066800000000000;
	cvt.rn.f32.f64 	%f111, %fd874;
	cvt.f64.f32 	%fd875, %f446;
	mul.rn.f64 	%fd876, %fd875, 0d400921FB54442D18;
	div.rn.f64 	%fd877, %fd876, 0d4066800000000000;
	cvt.rn.f32.f64 	%f112, %fd877;
	sub.rn.f32 	%f343, %f112, %f111;
	cvt.f64.f32 	%fd878, %f343;
	mul.rn.f64 	%fd272, %fd878, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r700, %temp}, %fd272;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r701}, %fd272;
	}
	and.b32  	%r702, %r701, 2147483647;
	setp.eq.s32 	%p277, %r702, 2146435072;
	setp.eq.s32 	%p278, %r700, 0;
	and.pred  	%p279, %p278, %p277;
	@%p279 bra 	$L__BB6_287;
	bra.uni 	$L__BB6_285;

$L__BB6_287:
	mov.f64 	%fd888, 0d0000000000000000;
	mul.rn.f64 	%fd1020, %fd272, %fd888;
	mov.u32 	%r884, 0;
	bra.uni 	$L__BB6_288;

$L__BB6_358:
	abs.f32 	%f418, %f107;
	setp.geu.f32 	%p364, %f418, %f148;
	@%p364 bra 	$L__BB6_360;

	abs.f32 	%f419, %f108;
	setp.lt.f32 	%p365, %f419, %f148;
	@%p365 bra 	$L__BB6_361;
	bra.uni 	$L__BB6_360;

$L__BB6_285:
	mul.rn.f64 	%fd879, %fd272, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r884, %fd879;
	st.local.u32 	[%rd8], %r884;
	cvt.rn.f64.s32 	%fd880, %r884;
	neg.f64 	%fd881, %fd880;
	mov.f64 	%fd882, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd883, %fd881, %fd882, %fd272;
	mov.f64 	%fd884, 0d3C91A62633145C00;
	fma.rn.f64 	%fd885, %fd881, %fd884, %fd883;
	mov.f64 	%fd886, 0d397B839A252049C0;
	fma.rn.f64 	%fd1020, %fd881, %fd886, %fd885;
	abs.f64 	%fd887, %fd272;
	setp.ltu.f64 	%p280, %fd887, 0d41E0000000000000;
	@%p280 bra 	$L__BB6_288;

	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1020, [retval0+0];
	} // callseq 68
	ld.local.u32 	%r884, [%rd8];

$L__BB6_288:
	and.b32  	%r704, %r884, 1;
	shl.b32 	%r705, %r884, 3;
	and.b32  	%r706, %r705, 8;
	setp.eq.s32 	%p281, %r704, 0;
	selp.f64 	%fd889, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p281;
	mul.wide.s32 	%rd265, %r706, 8;
	add.s64 	%rd267, %rd106, %rd265;
	ld.global.nc.f64 	%fd890, [%rd267+8];
	mul.rn.f64 	%fd277, %fd1020, %fd1020;
	fma.rn.f64 	%fd891, %fd889, %fd277, %fd890;
	ld.global.nc.f64 	%fd892, [%rd267+16];
	fma.rn.f64 	%fd893, %fd891, %fd277, %fd892;
	ld.global.nc.f64 	%fd894, [%rd267+24];
	fma.rn.f64 	%fd895, %fd893, %fd277, %fd894;
	ld.global.nc.f64 	%fd896, [%rd267+32];
	fma.rn.f64 	%fd897, %fd895, %fd277, %fd896;
	ld.global.nc.f64 	%fd898, [%rd267+40];
	fma.rn.f64 	%fd899, %fd897, %fd277, %fd898;
	ld.global.nc.f64 	%fd900, [%rd267+48];
	fma.rn.f64 	%fd278, %fd899, %fd277, %fd900;
	fma.rn.f64 	%fd1022, %fd278, %fd1020, %fd1020;
	@%p281 bra 	$L__BB6_290;

	mov.f64 	%fd901, 0d3FF0000000000000;
	fma.rn.f64 	%fd1022, %fd278, %fd277, %fd901;

$L__BB6_290:
	and.b32  	%r707, %r884, 2;
	setp.eq.s32 	%p282, %r707, 0;
	@%p282 bra 	$L__BB6_292;

	mov.f64 	%fd902, 0d0000000000000000;
	mov.f64 	%fd903, 0dBFF0000000000000;
	fma.rn.f64 	%fd1022, %fd1022, %fd903, %fd902;

$L__BB6_292:
	abs.f64 	%fd284, %fd1022;
	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd284;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1025, [retval0+0];
	} // callseq 69
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r203}, %fd1022;
	}
	setp.lt.s32 	%p283, %r203, 0;
	and.pred  	%p7, %p283, %p78;
	not.pred 	%p285, %p7;
	@%p285 bra 	$L__BB6_294;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r708}, %fd1025;
	}
	xor.b32  	%r709, %r708, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r710, %temp}, %fd1025;
	}
	mov.b64 	%fd1025, {%r710, %r709};

$L__BB6_294:
	setp.eq.f64 	%p286, %fd1022, 0d0000000000000000;
	@%p286 bra 	$L__BB6_298;
	bra.uni 	$L__BB6_295;

$L__BB6_298:
	setp.lt.s32 	%p289, %r62, 0;
	mov.u32 	%r711, 0;
	selp.b32 	%r712, %r203, 0, %p78;
	or.b32  	%r713, %r712, 2146435072;
	selp.b32 	%r714, %r713, %r712, %p289;
	mov.b64 	%fd1025, {%r711, %r714};
	bra.uni 	$L__BB6_299;

$L__BB6_295:
	setp.gt.s32 	%p287, %r203, -1;
	@%p287 bra 	$L__BB6_299;

	mov.f64 	%fd904, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd905, %fd904;
	setp.eq.f64 	%p288, %fd905, 0d4000000000000000;
	@%p288 bra 	$L__BB6_299;

	mov.f64 	%fd1025, 0dFFF8000000000000;

$L__BB6_299:
	add.rn.f64 	%fd907, %fd1022, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r715}, %fd907;
	}
	and.b32  	%r716, %r715, 2146435072;
	setp.ne.s32 	%p291, %r716, 2146435072;
	@%p291 bra 	$L__BB6_306;

	setp.gtu.f64 	%p292, %fd284, 0d7FF0000000000000;
	@%p292 bra 	$L__BB6_305;
	bra.uni 	$L__BB6_301;

$L__BB6_305:
	mov.f64 	%fd909, 0d4000000000000000;
	add.rn.f64 	%fd1025, %fd1022, %fd909;
	bra.uni 	$L__BB6_306;

$L__BB6_301:
	setp.eq.s32 	%p293, %r104, 2146435072;
	mov.f64 	%fd908, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r717, %temp}, %fd908;
	}
	setp.eq.s32 	%p294, %r717, 0;
	and.pred  	%p295, %p293, %p294;
	@%p295 bra 	$L__BB6_304;
	bra.uni 	$L__BB6_302;

$L__BB6_304:
	setp.lt.s32 	%p301, %r62, 0;
	mov.u32 	%r722, 0;
	setp.gt.f64 	%p302, %fd284, 0d3FF0000000000000;
	selp.b32 	%r723, 2146435072, 0, %p302;
	xor.b32  	%r724, %r723, 2146435072;
	selp.b32 	%r725, %r724, %r723, %p301;
	setp.eq.f64 	%p303, %fd1022, 0dBFF0000000000000;
	selp.b32 	%r726, 1072693248, %r725, %p303;
	mov.b64 	%fd1025, {%r722, %r726};
	bra.uni 	$L__BB6_306;

$L__BB6_302:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r718, %temp}, %fd1022;
	}
	and.b32  	%r719, %r203, 2147483647;
	setp.ne.s32 	%p296, %r719, 2146435072;
	setp.ne.s32 	%p297, %r718, 0;
	or.pred  	%p298, %p296, %p297;
	@%p298 bra 	$L__BB6_306;

	setp.ne.s32 	%p299, %r104, 1071644672;
	and.pred  	%p300, %p299, %p7;
	selp.b32 	%r720, %r106, %r105, %p300;
	mov.u32 	%r721, 0;
	mov.b64 	%fd1025, {%r721, %r720};

$L__BB6_306:
	setp.eq.f64 	%p304, %fd1022, 0d3FF0000000000000;
	selp.f64 	%fd294, 0d3FF0000000000000, %fd1025, %p304;
	mul.rn.f32 	%f344, %f111, 0f3F22F983;
	cvt.rni.s32.f32 	%r887, %f344;
	cvt.rn.f32.s32 	%f345, %r887;
	mov.f32 	%f346, 0fBFC90FDA;
	fma.rn.f32 	%f347, %f345, %f346, %f111;
	mov.f32 	%f348, 0fB3A22168;
	fma.rn.f32 	%f349, %f345, %f348, %f347;
	mov.f32 	%f350, 0fA7C234C5;
	fma.rn.f32 	%f460, %f345, %f350, %f349;
	abs.f32 	%f114, %f111;
	setp.ltu.f32 	%p305, %f114, 0f47CE4780;
	add.s64 	%rd64, %rd8, 24;
	@%p305 bra 	$L__BB6_314;

	setp.eq.f32 	%p306, %f114, 0f7F800000;
	@%p306 bra 	$L__BB6_313;
	bra.uni 	$L__BB6_308;

$L__BB6_313:
	mov.f32 	%f353, 0f00000000;
	mul.rn.f32 	%f460, %f111, %f353;
	mov.u32 	%r887, 0;
	bra.uni 	$L__BB6_314;

$L__BB6_308:
	mov.b32 	%r205, %f111;
	bfe.u32 	%r727, %r205, 23, 8;
	add.s32 	%r206, %r727, -128;
	shl.b32 	%r728, %r205, 8;
	or.b32  	%r207, %r728, -2147483648;
	shr.u32 	%r208, %r206, 5;
	mov.u64 	%rd327, 0;
	mov.u64 	%rd328, %rd327;

$L__BB6_309:
	.pragma "nounroll";
	shl.b64 	%rd270, %rd327, 2;
	mov.u64 	%rd271, __cudart_i2opi_f;
	add.s64 	%rd272, %rd271, %rd270;
	ld.global.nc.u32 	%r729, [%rd272];
	mad.wide.u32 	%rd273, %r729, %r207, %rd328;
	shr.u64 	%rd328, %rd273, 32;
	add.s64 	%rd274, %rd8, %rd270;
	st.local.u32 	[%rd274], %rd273;
	cvt.u32.u64 	%r730, %rd327;
	add.s32 	%r731, %r730, 1;
	cvt.s64.s32 	%rd327, %r731;
	setp.ne.s32 	%p307, %r731, 6;
	@%p307 bra 	$L__BB6_309;

	st.local.u32 	[%rd64], %rd328;
	mov.u32 	%r732, 4;
	sub.s32 	%r209, %r732, %r208;
	mov.u32 	%r733, 6;
	sub.s32 	%r734, %r733, %r208;
	mul.wide.s32 	%rd275, %r734, 4;
	add.s64 	%rd276, %rd8, %rd275;
	ld.local.u32 	%r885, [%rd276];
	ld.local.u32 	%r886, [%rd276+-4];
	and.b32  	%r212, %r206, 31;
	setp.eq.s32 	%p308, %r212, 0;
	@%p308 bra 	$L__BB6_312;

	mov.u32 	%r735, 32;
	sub.s32 	%r736, %r735, %r212;
	shr.u32 	%r737, %r886, %r736;
	shl.b32 	%r738, %r885, %r212;
	add.s32 	%r885, %r737, %r738;
	mul.wide.s32 	%rd277, %r209, 4;
	add.s64 	%rd278, %rd8, %rd277;
	ld.local.u32 	%r739, [%rd278];
	shr.u32 	%r740, %r739, %r736;
	shl.b32 	%r741, %r886, %r212;
	add.s32 	%r886, %r740, %r741;

$L__BB6_312:
	and.b32  	%r742, %r205, -2147483648;
	shr.u32 	%r743, %r886, 30;
	shl.b32 	%r744, %r885, 2;
	or.b32  	%r745, %r743, %r744;
	shr.u32 	%r746, %r745, 31;
	shr.u32 	%r747, %r885, 30;
	add.s32 	%r748, %r746, %r747;
	neg.s32 	%r749, %r748;
	setp.eq.s32 	%p309, %r742, 0;
	selp.b32 	%r887, %r748, %r749, %p309;
	setp.ne.s32 	%p310, %r746, 0;
	xor.b32  	%r750, %r742, -2147483648;
	selp.b32 	%r751, %r750, %r742, %p310;
	selp.b32 	%r752, -1, 0, %p310;
	xor.b32  	%r753, %r745, %r752;
	shl.b32 	%r754, %r886, 2;
	xor.b32  	%r755, %r754, %r752;
	cvt.u64.u32 	%rd279, %r753;
	cvt.u64.u32 	%rd280, %r755;
	bfi.b64 	%rd281, %rd279, %rd280, 32, 32;
	cvt.rn.f64.s64 	%fd910, %rd281;
	mul.rn.f64 	%fd911, %fd910, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f351, %fd911;
	setp.eq.s32 	%p311, %r751, 0;
	neg.f32 	%f352, %f351;
	selp.f32 	%f460, %f351, %f352, %p311;

$L__BB6_314:
	add.s32 	%r219, %r887, 1;
	and.b32  	%r220, %r219, 1;
	setp.eq.s32 	%p312, %r220, 0;
	selp.f32 	%f118, %f460, 0f3F800000, %p312;
	mul.rn.f32 	%f119, %f460, %f460;
	mov.f32 	%f461, 0fB94D4153;
	@%p312 bra 	$L__BB6_316;

	mov.f32 	%f355, 0fBAB607ED;
	mov.f32 	%f356, 0f37CBAC00;
	fma.rn.f32 	%f461, %f356, %f119, %f355;

$L__BB6_316:
	selp.f32 	%f357, 0f3C0885E4, 0f3D2AAABB, %p312;
	fma.rn.f32 	%f358, %f461, %f119, %f357;
	selp.f32 	%f359, 0fBE2AAAA8, 0fBEFFFFFF, %p312;
	fma.rn.f32 	%f360, %f358, %f119, %f359;
	mov.f32 	%f361, 0f00000000;
	fma.rn.f32 	%f362, %f119, %f118, %f361;
	fma.rn.f32 	%f462, %f360, %f362, %f118;
	and.b32  	%r757, %r219, 2;
	setp.eq.s32 	%p314, %r757, 0;
	@%p314 bra 	$L__BB6_318;

	mov.f32 	%f364, 0fBF800000;
	fma.rn.f32 	%f462, %f462, %f364, %f361;

$L__BB6_318:
	mul.rn.f32 	%f365, %f112, 0f3F22F983;
	cvt.rni.s32.f32 	%r890, %f365;
	cvt.rn.f32.s32 	%f366, %r890;
	mov.f32 	%f367, 0fBFC90FDA;
	fma.rn.f32 	%f368, %f366, %f367, %f112;
	mov.f32 	%f369, 0fB3A22168;
	fma.rn.f32 	%f370, %f366, %f369, %f368;
	mov.f32 	%f371, 0fA7C234C5;
	fma.rn.f32 	%f463, %f366, %f371, %f370;
	abs.f32 	%f126, %f112;
	setp.ltu.f32 	%p315, %f126, 0f47CE4780;
	@%p315 bra 	$L__BB6_326;

	setp.eq.f32 	%p316, %f126, 0f7F800000;
	@%p316 bra 	$L__BB6_325;
	bra.uni 	$L__BB6_320;

$L__BB6_325:
	mov.f32 	%f374, 0f00000000;
	mul.rn.f32 	%f463, %f112, %f374;
	mov.u32 	%r890, 0;
	bra.uni 	$L__BB6_326;

$L__BB6_320:
	mov.b32 	%r222, %f112;
	bfe.u32 	%r758, %r222, 23, 8;
	add.s32 	%r223, %r758, -128;
	shl.b32 	%r759, %r222, 8;
	or.b32  	%r224, %r759, -2147483648;
	shr.u32 	%r225, %r223, 5;
	mov.u64 	%rd329, 0;
	mov.u64 	%rd330, %rd329;

$L__BB6_321:
	.pragma "nounroll";
	shl.b64 	%rd284, %rd329, 2;
	mov.u64 	%rd285, __cudart_i2opi_f;
	add.s64 	%rd286, %rd285, %rd284;
	ld.global.nc.u32 	%r760, [%rd286];
	mad.wide.u32 	%rd287, %r760, %r224, %rd330;
	shr.u64 	%rd330, %rd287, 32;
	add.s64 	%rd288, %rd8, %rd284;
	st.local.u32 	[%rd288], %rd287;
	cvt.u32.u64 	%r761, %rd329;
	add.s32 	%r762, %r761, 1;
	cvt.s64.s32 	%rd329, %r762;
	setp.ne.s32 	%p317, %r762, 6;
	@%p317 bra 	$L__BB6_321;

	st.local.u32 	[%rd64], %rd330;
	mov.u32 	%r763, 4;
	sub.s32 	%r226, %r763, %r225;
	mov.u32 	%r764, 6;
	sub.s32 	%r765, %r764, %r225;
	mul.wide.s32 	%rd289, %r765, 4;
	add.s64 	%rd290, %rd8, %rd289;
	ld.local.u32 	%r888, [%rd290];
	ld.local.u32 	%r889, [%rd290+-4];
	and.b32  	%r229, %r223, 31;
	setp.eq.s32 	%p318, %r229, 0;
	@%p318 bra 	$L__BB6_324;

	mov.u32 	%r766, 32;
	sub.s32 	%r767, %r766, %r229;
	shr.u32 	%r768, %r889, %r767;
	shl.b32 	%r769, %r888, %r229;
	add.s32 	%r888, %r768, %r769;
	mul.wide.s32 	%rd291, %r226, 4;
	add.s64 	%rd292, %rd8, %rd291;
	ld.local.u32 	%r770, [%rd292];
	shr.u32 	%r771, %r770, %r767;
	shl.b32 	%r772, %r889, %r229;
	add.s32 	%r889, %r771, %r772;

$L__BB6_324:
	and.b32  	%r773, %r222, -2147483648;
	shr.u32 	%r774, %r889, 30;
	shl.b32 	%r775, %r888, 2;
	or.b32  	%r776, %r774, %r775;
	shr.u32 	%r777, %r776, 31;
	shr.u32 	%r778, %r888, 30;
	add.s32 	%r779, %r777, %r778;
	neg.s32 	%r780, %r779;
	setp.eq.s32 	%p319, %r773, 0;
	selp.b32 	%r890, %r779, %r780, %p319;
	setp.ne.s32 	%p320, %r777, 0;
	xor.b32  	%r781, %r773, -2147483648;
	selp.b32 	%r782, %r781, %r773, %p320;
	selp.b32 	%r783, -1, 0, %p320;
	xor.b32  	%r784, %r776, %r783;
	shl.b32 	%r785, %r889, 2;
	xor.b32  	%r786, %r785, %r783;
	cvt.u64.u32 	%rd293, %r784;
	cvt.u64.u32 	%rd294, %r786;
	bfi.b64 	%rd295, %rd293, %rd294, 32, 32;
	cvt.rn.f64.s64 	%fd912, %rd295;
	mul.rn.f64 	%fd913, %fd912, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f372, %fd913;
	setp.eq.s32 	%p321, %r782, 0;
	neg.f32 	%f373, %f372;
	selp.f32 	%f463, %f372, %f373, %p321;

$L__BB6_326:
	add.s32 	%r236, %r890, 1;
	and.b32  	%r237, %r236, 1;
	setp.eq.s32 	%p322, %r237, 0;
	selp.f32 	%f130, %f463, 0f3F800000, %p322;
	mul.rn.f32 	%f131, %f463, %f463;
	mov.f32 	%f464, 0fB94D4153;
	@%p322 bra 	$L__BB6_328;

	mov.f32 	%f376, 0fBAB607ED;
	mov.f32 	%f377, 0f37CBAC00;
	fma.rn.f32 	%f464, %f377, %f131, %f376;

$L__BB6_328:
	selp.f32 	%f378, 0f3C0885E4, 0f3D2AAABB, %p322;
	fma.rn.f32 	%f379, %f464, %f131, %f378;
	selp.f32 	%f380, 0fBE2AAAA8, 0fBEFFFFFF, %p322;
	fma.rn.f32 	%f381, %f379, %f131, %f380;
	mov.f32 	%f382, 0f00000000;
	fma.rn.f32 	%f383, %f131, %f130, %f382;
	fma.rn.f32 	%f465, %f381, %f383, %f130;
	and.b32  	%r788, %r236, 2;
	setp.eq.s32 	%p324, %r788, 0;
	@%p324 bra 	$L__BB6_330;

	mov.f32 	%f385, 0fBF800000;
	fma.rn.f32 	%f465, %f465, %f385, %f382;

$L__BB6_330:
	mul.rn.f32 	%f137, %f462, %f465;
	cvt.f64.f32 	%fd914, %f467;
	mul.rn.f64 	%fd915, %fd914, 0d400921FB54442D18;
	div.rn.f64 	%fd916, %fd915, 0d4066800000000000;
	cvt.rn.f32.f64 	%f386, %fd916;
	cvt.f64.f32 	%fd917, %f447;
	mul.rn.f64 	%fd918, %fd917, 0d400921FB54442D18;
	div.rn.f64 	%fd919, %fd918, 0d4066800000000000;
	cvt.rn.f32.f64 	%f387, %fd919;
	sub.rn.f32 	%f388, %f387, %f386;
	cvt.f64.f32 	%fd920, %f388;
	mul.rn.f64 	%fd295, %fd920, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r789, %temp}, %fd295;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r790}, %fd295;
	}
	and.b32  	%r791, %r790, 2147483647;
	setp.eq.s32 	%p325, %r791, 2146435072;
	setp.eq.s32 	%p326, %r789, 0;
	and.pred  	%p327, %p326, %p325;
	@%p327 bra 	$L__BB6_333;
	bra.uni 	$L__BB6_331;

$L__BB6_333:
	mov.f64 	%fd930, 0d0000000000000000;
	mul.rn.f64 	%fd1026, %fd295, %fd930;
	mov.u32 	%r891, 0;
	bra.uni 	$L__BB6_334;

$L__BB6_331:
	mul.rn.f64 	%fd921, %fd295, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r891, %fd921;
	st.local.u32 	[%rd8], %r891;
	cvt.rn.f64.s32 	%fd922, %r891;
	neg.f64 	%fd923, %fd922;
	mov.f64 	%fd924, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd925, %fd923, %fd924, %fd295;
	mov.f64 	%fd926, 0d3C91A62633145C00;
	fma.rn.f64 	%fd927, %fd923, %fd926, %fd925;
	mov.f64 	%fd928, 0d397B839A252049C0;
	fma.rn.f64 	%fd1026, %fd923, %fd928, %fd927;
	abs.f64 	%fd929, %fd295;
	setp.ltu.f64 	%p328, %fd929, 0d41E0000000000000;
	@%p328 bra 	$L__BB6_334;

	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd295;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd77;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1026, [retval0+0];
	} // callseq 70
	ld.local.u32 	%r891, [%rd8];

$L__BB6_334:
	and.b32  	%r793, %r891, 1;
	shl.b32 	%r794, %r891, 3;
	and.b32  	%r795, %r794, 8;
	setp.eq.s32 	%p329, %r793, 0;
	selp.f64 	%fd931, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p329;
	mul.wide.s32 	%rd297, %r795, 8;
	add.s64 	%rd299, %rd106, %rd297;
	ld.global.nc.f64 	%fd932, [%rd299+8];
	mul.rn.f64 	%fd300, %fd1026, %fd1026;
	fma.rn.f64 	%fd933, %fd931, %fd300, %fd932;
	ld.global.nc.f64 	%fd934, [%rd299+16];
	fma.rn.f64 	%fd935, %fd933, %fd300, %fd934;
	ld.global.nc.f64 	%fd936, [%rd299+24];
	fma.rn.f64 	%fd937, %fd935, %fd300, %fd936;
	ld.global.nc.f64 	%fd938, [%rd299+32];
	fma.rn.f64 	%fd939, %fd937, %fd300, %fd938;
	ld.global.nc.f64 	%fd940, [%rd299+40];
	fma.rn.f64 	%fd941, %fd939, %fd300, %fd940;
	ld.global.nc.f64 	%fd942, [%rd299+48];
	fma.rn.f64 	%fd301, %fd941, %fd300, %fd942;
	fma.rn.f64 	%fd1028, %fd301, %fd1026, %fd1026;
	@%p329 bra 	$L__BB6_336;

	mov.f64 	%fd943, 0d3FF0000000000000;
	fma.rn.f64 	%fd1028, %fd301, %fd300, %fd943;

$L__BB6_336:
	and.b32  	%r796, %r891, 2;
	setp.eq.s32 	%p330, %r796, 0;
	@%p330 bra 	$L__BB6_338;

	mov.f64 	%fd944, 0d0000000000000000;
	mov.f64 	%fd945, 0dBFF0000000000000;
	fma.rn.f64 	%fd1028, %fd1028, %fd945, %fd944;

$L__BB6_338:
	abs.f64 	%fd307, %fd1028;
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd307;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1031, [retval0+0];
	} // callseq 71
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r241}, %fd1028;
	}
	setp.lt.s32 	%p331, %r241, 0;
	and.pred  	%p8, %p331, %p78;
	not.pred 	%p333, %p8;
	@%p333 bra 	$L__BB6_340;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r797}, %fd1031;
	}
	xor.b32  	%r798, %r797, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r799, %temp}, %fd1031;
	}
	mov.b64 	%fd1031, {%r799, %r798};

$L__BB6_340:
	setp.eq.f64 	%p334, %fd1028, 0d0000000000000000;
	@%p334 bra 	$L__BB6_344;
	bra.uni 	$L__BB6_341;

$L__BB6_344:
	setp.lt.s32 	%p337, %r62, 0;
	mov.u32 	%r800, 0;
	selp.b32 	%r801, %r241, 0, %p78;
	or.b32  	%r802, %r801, 2146435072;
	selp.b32 	%r803, %r802, %r801, %p337;
	mov.b64 	%fd1031, {%r800, %r803};
	bra.uni 	$L__BB6_345;

$L__BB6_341:
	setp.gt.s32 	%p335, %r241, -1;
	@%p335 bra 	$L__BB6_345;

	mov.f64 	%fd946, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd947, %fd946;
	setp.eq.f64 	%p336, %fd947, 0d4000000000000000;
	@%p336 bra 	$L__BB6_345;

	mov.f64 	%fd1031, 0dFFF8000000000000;

$L__BB6_345:
	add.rn.f64 	%fd949, %fd1028, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r804}, %fd949;
	}
	and.b32  	%r805, %r804, 2146435072;
	setp.ne.s32 	%p339, %r805, 2146435072;
	@%p339 bra 	$L__BB6_352;

	setp.gtu.f64 	%p340, %fd307, 0d7FF0000000000000;
	@%p340 bra 	$L__BB6_351;
	bra.uni 	$L__BB6_347;

$L__BB6_351:
	mov.f64 	%fd951, 0d4000000000000000;
	add.rn.f64 	%fd1031, %fd1028, %fd951;
	bra.uni 	$L__BB6_352;

$L__BB6_347:
	setp.eq.s32 	%p341, %r104, 2146435072;
	mov.f64 	%fd950, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r806, %temp}, %fd950;
	}
	setp.eq.s32 	%p342, %r806, 0;
	and.pred  	%p343, %p341, %p342;
	@%p343 bra 	$L__BB6_350;
	bra.uni 	$L__BB6_348;

$L__BB6_350:
	setp.lt.s32 	%p349, %r62, 0;
	mov.u32 	%r811, 0;
	setp.gt.f64 	%p350, %fd307, 0d3FF0000000000000;
	selp.b32 	%r812, 2146435072, 0, %p350;
	xor.b32  	%r813, %r812, 2146435072;
	selp.b32 	%r814, %r813, %r812, %p349;
	setp.eq.f64 	%p351, %fd1028, 0dBFF0000000000000;
	selp.b32 	%r815, 1072693248, %r814, %p351;
	mov.b64 	%fd1031, {%r811, %r815};
	bra.uni 	$L__BB6_352;

$L__BB6_348:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r807, %temp}, %fd1028;
	}
	and.b32  	%r808, %r241, 2147483647;
	setp.ne.s32 	%p344, %r808, 2146435072;
	setp.ne.s32 	%p345, %r807, 0;
	or.pred  	%p346, %p344, %p345;
	@%p346 bra 	$L__BB6_352;

	setp.ne.s32 	%p347, %r104, 1071644672;
	and.pred  	%p348, %p347, %p8;
	selp.b32 	%r809, %r106, %r105, %p348;
	mov.u32 	%r810, 0;
	mov.b64 	%fd1031, {%r810, %r809};

$L__BB6_352:
	setp.eq.f64 	%p352, %fd1028, 0d3FF0000000000000;
	mov.f64 	%fd952, 0d3FF0000000000000;
	selp.f64 	%fd953, 0d3FF0000000000000, %fd1031, %p352;
	cvt.f64.f32 	%fd954, %f137;
	mul.rn.f64 	%fd955, %fd953, %fd954;
	add.rn.f64 	%fd956, %fd294, %fd955;
	cvt.rn.f32.f64 	%f389, %fd956;
	sqrt.rn.f32 	%f138, %f389;
	cvt.f64.f32 	%fd957, %f389;
	sub.rn.f64 	%fd958, %fd952, %fd957;
	sqrt.rn.f64 	%fd959, %fd958;
	cvt.rn.f32.f64 	%f139, %fd959;
	abs.f32 	%f140, %f139;
	abs.f32 	%f141, %f138;
	setp.eq.f32 	%p353, %f140, 0f00000000;
	setp.eq.f32 	%p354, %f141, 0f00000000;
	and.pred  	%p355, %p353, %p354;
	@%p355 bra 	$L__BB6_356;
	bra.uni 	$L__BB6_353;

$L__BB6_356:
	mov.b32 	%r826, %f139;
	shr.s32 	%r827, %r826, 31;
	and.b32  	%r828, %r827, 1078530011;
	mov.b32 	%r829, %f138;
	and.b32  	%r830, %r829, -2147483648;
	or.b32  	%r831, %r828, %r830;
	mov.b32 	%f466, %r831;
	bra.uni 	$L__BB6_357;

$L__BB6_353:
	setp.eq.f32 	%p356, %f140, 0f7F800000;
	setp.eq.f32 	%p357, %f141, 0f7F800000;
	and.pred  	%p358, %p356, %p357;
	@%p358 bra 	$L__BB6_355;
	bra.uni 	$L__BB6_354;

$L__BB6_355:
	mov.b32 	%r821, %f139;
	setp.lt.s32 	%p362, %r821, 0;
	selp.b32 	%r822, 1075235812, 1061752795, %p362;
	mov.b32 	%r823, %f138;
	and.b32  	%r824, %r823, -2147483648;
	or.b32  	%r825, %r822, %r824;
	mov.b32 	%f466, %r825;
	bra.uni 	$L__BB6_357;

$L__BB6_354:
	max.f32 	%f390, %f141, %f140;
	min.f32 	%f391, %f141, %f140;
	div.rn.f32 	%f392, %f391, %f390;
	mul.rn.f32 	%f393, %f392, %f392;
	mov.f32 	%f394, 0fC0B59883;
	mov.f32 	%f395, 0fBF52C7EA;
	fma.rn.f32 	%f396, %f393, %f395, %f394;
	mov.f32 	%f397, 0fC0D21907;
	fma.rn.f32 	%f398, %f396, %f393, %f397;
	mul.rn.f32 	%f399, %f393, %f398;
	mul.rn.f32 	%f400, %f392, %f399;
	add.rn.f32 	%f401, %f393, 0f41355DC0;
	mov.f32 	%f402, 0f41E6BD60;
	fma.rn.f32 	%f403, %f401, %f393, %f402;
	mov.f32 	%f404, 0f419D92C8;
	fma.rn.f32 	%f405, %f403, %f393, %f404;
	rcp.rn.f32 	%f406, %f405;
	fma.rn.f32 	%f407, %f400, %f406, %f392;
	mov.f32 	%f408, 0f3FC90FDB;
	sub.rn.f32 	%f409, %f408, %f407;
	setp.gt.f32 	%p359, %f141, %f140;
	selp.f32 	%f410, %f409, %f407, %p359;
	mov.b32 	%r816, %f139;
	setp.lt.s32 	%p360, %r816, 0;
	mov.f32 	%f411, 0f40490FDB;
	sub.rn.f32 	%f412, %f411, %f410;
	selp.f32 	%f413, %f412, %f410, %p360;
	mov.b32 	%r817, %f413;
	mov.b32 	%r818, %f138;
	and.b32  	%r819, %r818, -2147483648;
	or.b32  	%r820, %r819, %r817;
	mov.b32 	%f414, %r820;
	add.rn.f32 	%f415, %f140, %f141;
	setp.le.f32 	%p361, %f415, 0f7F800000;
	selp.f32 	%f466, %f414, %f415, %p361;

$L__BB6_357:
	add.rn.f32 	%f416, %f466, %f466;
	mul.rn.f32 	%f417, %f416, 0f4AC2A532;
	setp.lt.f32 	%p363, %f417, %f148;
	@%p363 bra 	$L__BB6_361;

$L__BB6_360:
	ld.param.u32 	%r836, [gcj02_to_wgs84_exact_cuda_float_param_5];
	add.s32 	%r862, %r862, 1;
	setp.lt.s32 	%p366, %r862, %r836;
	mov.f32 	%f467, %f447;
	mov.f32 	%f468, %f446;
	@%p366 bra 	$L__BB6_143;

$L__BB6_361:
	mov.u32 	%r835, %tid.x;
	mov.u32 	%r834, %ntid.x;
	mov.u32 	%r833, %ctaid.x;
	mad.lo.s32 	%r832, %r833, %r834, %r835;
	mul.wide.s32 	%rd306, %r832, 4;
	ld.param.u64 	%rd305, [gcj02_to_wgs84_exact_cuda_float_param_7];
	cvta.to.global.u64 	%rd304, %rd305;
	add.s64 	%rd303, %rd304, %rd306;
	ld.param.u64 	%rd302, [gcj02_to_wgs84_exact_cuda_float_param_6];
	cvta.to.global.u64 	%rd301, %rd302;
	add.s64 	%rd300, %rd301, %rd306;
	st.global.f32 	[%rd300], %f467;
	st.global.f32 	[%rd303], %f468;

$L__BB6_362:
	ret;

}
	// .globl	bd09_to_wgs84_exact_cuda_float
.visible .entry bd09_to_wgs84_exact_cuda_float(
	.param .u32 bd09_to_wgs84_exact_cuda_float_param_0,
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_1,
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_2,
	.param .f32 bd09_to_wgs84_exact_cuda_float_param_3,
	.param .u8 bd09_to_wgs84_exact_cuda_float_param_4,
	.param .u32 bd09_to_wgs84_exact_cuda_float_param_5,
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_6,
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_7
)
{
	.local .align 4 .b8 	__local_depot7[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<561>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<821>;
	.reg .b32 	%r<1420>;
	.reg .f64 	%fd<1158>;
	.reg .b64 	%rd<487>;


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r388, [bd09_to_wgs84_exact_cuda_float_param_0];
	ld.param.u64 	%rd113, [bd09_to_wgs84_exact_cuda_float_param_1];
	ld.param.u64 	%rd114, [bd09_to_wgs84_exact_cuda_float_param_2];
	ld.param.f32 	%f266, [bd09_to_wgs84_exact_cuda_float_param_3];
	add.u64 	%rd117, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r389, %ntid.x;
	mov.u32 	%r390, %ctaid.x;
	mov.u32 	%r391, %tid.x;
	mad.lo.s32 	%r1, %r390, %r389, %r391;
	setp.ge.s32 	%p13, %r1, %r388;
	@%p13 bra 	$L__BB7_524;

	cvta.to.global.u64 	%rd137, %rd113;
	mul.wide.s32 	%rd138, %r1, 4;
	add.s64 	%rd139, %rd137, %rd138;
	cvta.to.global.u64 	%rd140, %rd114;
	add.s64 	%rd141, %rd140, %rd138;
	ld.global.f32 	%f1, [%rd139];
	cvt.f64.f32 	%fd364, %f1;
	add.rn.f64 	%fd365, %fd364, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f2, %fd365;
	ld.global.f32 	%f3, [%rd141];
	cvt.f64.f32 	%fd366, %f3;
	add.rn.f64 	%fd367, %fd366, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f4, %fd367;
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd368, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd368;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p14, %r4, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1076, [retval0+0];
	} // callseq 72
	setp.lt.s32 	%p15, %r2, 0;
	and.pred  	%p1, %p15, %p14;
	not.pred 	%p16, %p1;
	@%p16 bra 	$L__BB7_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r392}, %fd1076;
	}
	xor.b32  	%r393, %r392, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r394, %temp}, %fd1076;
	}
	mov.b64 	%fd1076, {%r394, %r393};

$L__BB7_3:
	setp.eq.f32 	%p17, %f2, 0f00000000;
	@%p17 bra 	$L__BB7_7;
	bra.uni 	$L__BB7_4;

$L__BB7_7:
	selp.b32 	%r395, %r2, 0, %p14;
	mov.u32 	%r396, 0;
	or.b32  	%r397, %r395, 2146435072;
	setp.lt.s32 	%p21, %r3, 0;
	selp.b32 	%r398, %r397, %r395, %p21;
	mov.b64 	%fd1076, {%r396, %r398};
	bra.uni 	$L__BB7_8;

$L__BB7_4:
	setp.gt.s32 	%p18, %r2, -1;
	@%p18 bra 	$L__BB7_8;

	mov.f64 	%fd369, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd370, %fd369;
	setp.eq.f64 	%p19, %fd370, 0d4000000000000000;
	@%p19 bra 	$L__BB7_8;

	mov.f64 	%fd1076, 0dFFF8000000000000;

$L__BB7_8:
	add.rn.f64 	%fd372, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r399}, %fd372;
	}
	and.b32  	%r400, %r399, 2146435072;
	setp.ne.s32 	%p22, %r400, 2146435072;
	@%p22 bra 	$L__BB7_15;

	setp.gtu.f64 	%p23, %fd2, 0d7FF0000000000000;
	@%p23 bra 	$L__BB7_14;
	bra.uni 	$L__BB7_10;

$L__BB7_14:
	mov.f64 	%fd374, 0d4000000000000000;
	add.rn.f64 	%fd1076, %fd1, %fd374;
	bra.uni 	$L__BB7_15;

$L__BB7_10:
	mov.f64 	%fd373, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r401, %temp}, %fd373;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p24, %r5, 2146435072;
	setp.eq.s32 	%p25, %r401, 0;
	and.pred  	%p26, %p24, %p25;
	@%p26 bra 	$L__BB7_13;
	bra.uni 	$L__BB7_11;

$L__BB7_13:
	setp.gt.f64 	%p33, %fd2, 0d3FF0000000000000;
	selp.b32 	%r408, 2146435072, 0, %p33;
	mov.u32 	%r409, 0;
	xor.b32  	%r410, %r408, 2146435072;
	setp.lt.s32 	%p34, %r3, 0;
	selp.b32 	%r411, %r410, %r408, %p34;
	setp.eq.f32 	%p35, %f2, 0fBF800000;
	selp.b32 	%r412, 1072693248, %r411, %p35;
	mov.b64 	%fd1076, {%r409, %r412};
	bra.uni 	$L__BB7_15;

$L__BB7_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd1;
	}
	and.b32  	%r403, %r2, 2147483647;
	setp.ne.s32 	%p27, %r403, 2146435072;
	setp.ne.s32 	%p28, %r402, 0;
	or.pred  	%p29, %p27, %p28;
	@%p29 bra 	$L__BB7_15;

	setp.gt.s32 	%p30, %r3, -1;
	selp.b32 	%r404, 2146435072, 0, %p30;
	mov.u32 	%r405, 0;
	setp.ne.s32 	%p31, %r5, 1071644672;
	and.pred  	%p32, %p31, %p1;
	or.b32  	%r406, %r404, -2147483648;
	selp.b32 	%r407, %r406, %r404, %p32;
	mov.b64 	%fd1076, {%r405, %r407};

$L__BB7_15:
	cvt.f64.f32 	%fd12, %f4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1079, [retval0+0];
	} // callseq 73
	setp.lt.s32 	%p36, %r6, 0;
	and.pred  	%p2, %p36, %p14;
	not.pred 	%p38, %p2;
	@%p38 bra 	$L__BB7_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r413}, %fd1079;
	}
	xor.b32  	%r414, %r413, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r415, %temp}, %fd1079;
	}
	mov.b64 	%fd1079, {%r415, %r414};

$L__BB7_17:
	setp.eq.f32 	%p39, %f4, 0f00000000;
	@%p39 bra 	$L__BB7_21;
	bra.uni 	$L__BB7_18;

$L__BB7_21:
	selp.b32 	%r416, %r6, 0, %p14;
	mov.u32 	%r417, 0;
	or.b32  	%r418, %r416, 2146435072;
	setp.lt.s32 	%p43, %r3, 0;
	selp.b32 	%r419, %r418, %r416, %p43;
	mov.b64 	%fd1079, {%r417, %r419};
	bra.uni 	$L__BB7_22;

$L__BB7_18:
	setp.gt.s32 	%p40, %r6, -1;
	@%p40 bra 	$L__BB7_22;

	mov.f64 	%fd375, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd376, %fd375;
	setp.eq.f64 	%p41, %fd376, 0d4000000000000000;
	@%p41 bra 	$L__BB7_22;

	mov.f64 	%fd1079, 0dFFF8000000000000;

$L__BB7_22:
	add.rn.f64 	%fd378, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r420}, %fd378;
	}
	and.b32  	%r421, %r420, 2146435072;
	setp.ne.s32 	%p44, %r421, 2146435072;
	@%p44 bra 	$L__BB7_29;

	setp.gtu.f64 	%p45, %fd13, 0d7FF0000000000000;
	@%p45 bra 	$L__BB7_28;
	bra.uni 	$L__BB7_24;

$L__BB7_28:
	mov.f64 	%fd380, 0d4000000000000000;
	add.rn.f64 	%fd1079, %fd12, %fd380;
	bra.uni 	$L__BB7_29;

$L__BB7_24:
	mov.f64 	%fd379, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r422, %temp}, %fd379;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p46, %r7, 2146435072;
	setp.eq.s32 	%p47, %r422, 0;
	and.pred  	%p48, %p46, %p47;
	@%p48 bra 	$L__BB7_27;
	bra.uni 	$L__BB7_25;

$L__BB7_27:
	setp.gt.f64 	%p55, %fd13, 0d3FF0000000000000;
	selp.b32 	%r429, 2146435072, 0, %p55;
	mov.u32 	%r430, 0;
	xor.b32  	%r431, %r429, 2146435072;
	setp.lt.s32 	%p56, %r3, 0;
	selp.b32 	%r432, %r431, %r429, %p56;
	setp.eq.f32 	%p57, %f4, 0fBF800000;
	selp.b32 	%r433, 1072693248, %r432, %p57;
	mov.b64 	%fd1079, {%r430, %r433};
	bra.uni 	$L__BB7_29;

$L__BB7_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r423, %temp}, %fd12;
	}
	and.b32  	%r424, %r6, 2147483647;
	setp.ne.s32 	%p49, %r424, 2146435072;
	setp.ne.s32 	%p50, %r423, 0;
	or.pred  	%p51, %p49, %p50;
	@%p51 bra 	$L__BB7_29;

	setp.gt.s32 	%p52, %r3, -1;
	selp.b32 	%r425, 2146435072, 0, %p52;
	mov.u32 	%r426, 0;
	setp.ne.s32 	%p53, %r7, 1071644672;
	and.pred  	%p54, %p53, %p2;
	or.b32  	%r427, %r425, -2147483648;
	selp.b32 	%r428, %r427, %r425, %p54;
	mov.b64 	%fd1079, {%r426, %r428};

$L__BB7_29:
	setp.eq.f32 	%p58, %f4, 0f3F800000;
	selp.f64 	%fd381, 0d3FF0000000000000, %fd1079, %p58;
	setp.eq.f32 	%p59, %f2, 0f3F800000;
	selp.f64 	%fd382, 0d3FF0000000000000, %fd1076, %p59;
	add.rn.f64 	%fd23, %fd382, %fd381;
	mul.rn.f32 	%f5, %f4, 0f42517084;
	mul.rn.f32 	%f267, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r1341, %f267;
	cvt.rn.f32.s32 	%f268, %r1341;
	mov.f32 	%f269, 0fBFC90FDA;
	fma.rn.f32 	%f270, %f268, %f269, %f5;
	mov.f32 	%f271, 0fB3A22168;
	fma.rn.f32 	%f272, %f268, %f271, %f270;
	mov.f32 	%f273, 0fA7C234C5;
	fma.rn.f32 	%f760, %f268, %f273, %f272;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p60, %f7, 0f47CE4780;
	add.s64 	%rd23, %rd1, 24;
	@%p60 bra 	$L__BB7_37;

	setp.eq.f32 	%p61, %f7, 0f7F800000;
	@%p61 bra 	$L__BB7_36;
	bra.uni 	$L__BB7_31;

$L__BB7_36:
	mov.f32 	%f276, 0f00000000;
	mul.rn.f32 	%f760, %f5, %f276;
	mov.u32 	%r1341, 0;
	bra.uni 	$L__BB7_37;

$L__BB7_31:
	mov.b32 	%r9, %f5;
	bfe.u32 	%r435, %r9, 23, 8;
	add.s32 	%r10, %r435, -128;
	shl.b32 	%r436, %r9, 8;
	or.b32  	%r11, %r436, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd445, 0;
	mov.u32 	%r1338, 0;
	mov.u64 	%rd444, __cudart_i2opi_f;
	mov.u64 	%rd443, %rd1;

$L__BB7_32:
	.pragma "nounroll";
	ld.global.nc.u32 	%r437, [%rd444];
	mad.wide.u32 	%rd146, %r437, %r11, %rd445;
	shr.u64 	%rd445, %rd146, 32;
	st.local.u32 	[%rd443], %rd146;
	add.s64 	%rd444, %rd444, 4;
	add.s64 	%rd443, %rd443, 4;
	add.s32 	%r1338, %r1338, 1;
	setp.ne.s32 	%p62, %r1338, 6;
	@%p62 bra 	$L__BB7_32;

	st.local.u32 	[%rd23], %rd445;
	mov.u32 	%r438, 4;
	sub.s32 	%r15, %r438, %r12;
	mov.u32 	%r439, 6;
	sub.s32 	%r440, %r439, %r12;
	mul.wide.s32 	%rd147, %r440, 4;
	add.s64 	%rd148, %rd1, %rd147;
	ld.local.u32 	%r1339, [%rd148];
	ld.local.u32 	%r1340, [%rd148+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p63, %r18, 0;
	@%p63 bra 	$L__BB7_35;

	mov.u32 	%r441, 32;
	sub.s32 	%r442, %r441, %r18;
	shr.u32 	%r443, %r1340, %r442;
	shl.b32 	%r444, %r1339, %r18;
	add.s32 	%r1339, %r443, %r444;
	mul.wide.s32 	%rd149, %r15, 4;
	add.s64 	%rd150, %rd1, %rd149;
	ld.local.u32 	%r445, [%rd150];
	shr.u32 	%r446, %r445, %r442;
	shl.b32 	%r447, %r1340, %r18;
	add.s32 	%r1340, %r446, %r447;

$L__BB7_35:
	and.b32  	%r448, %r9, -2147483648;
	shr.u32 	%r449, %r1340, 30;
	shl.b32 	%r450, %r1339, 2;
	or.b32  	%r451, %r449, %r450;
	shr.u32 	%r452, %r451, 31;
	shr.u32 	%r453, %r1339, 30;
	add.s32 	%r454, %r452, %r453;
	neg.s32 	%r455, %r454;
	setp.eq.s32 	%p64, %r448, 0;
	selp.b32 	%r1341, %r454, %r455, %p64;
	setp.ne.s32 	%p65, %r452, 0;
	xor.b32  	%r456, %r448, -2147483648;
	selp.b32 	%r457, %r456, %r448, %p65;
	selp.b32 	%r458, -1, 0, %p65;
	xor.b32  	%r459, %r451, %r458;
	shl.b32 	%r460, %r1340, 2;
	xor.b32  	%r461, %r460, %r458;
	cvt.u64.u32 	%rd151, %r459;
	cvt.u64.u32 	%rd152, %r461;
	bfi.b64 	%rd153, %rd151, %rd152, 32, 32;
	cvt.rn.f64.s64 	%fd383, %rd153;
	mul.rn.f64 	%fd384, %fd383, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f274, %fd384;
	setp.eq.s32 	%p66, %r457, 0;
	neg.f32 	%f275, %f274;
	selp.f32 	%f760, %f274, %f275, %p66;

$L__BB7_37:
	and.b32  	%r25, %r1341, 1;
	setp.eq.s32 	%p67, %r25, 0;
	selp.f32 	%f11, %f760, 0f3F800000, %p67;
	mul.rn.f32 	%f12, %f760, %f760;
	mov.f32 	%f761, 0fB94D4153;
	@%p67 bra 	$L__BB7_39;

	mov.f32 	%f278, 0fBAB607ED;
	mov.f32 	%f279, 0f37CBAC00;
	fma.rn.f32 	%f761, %f279, %f12, %f278;

$L__BB7_39:
	selp.f32 	%f280, 0f3C0885E4, 0f3D2AAABB, %p67;
	fma.rn.f32 	%f281, %f761, %f12, %f280;
	selp.f32 	%f282, 0fBE2AAAA8, 0fBEFFFFFF, %p67;
	fma.rn.f32 	%f283, %f281, %f12, %f282;
	mov.f32 	%f284, 0f00000000;
	fma.rn.f32 	%f285, %f12, %f11, %f284;
	fma.rn.f32 	%f762, %f283, %f285, %f11;
	and.b32  	%r463, %r1341, 2;
	setp.eq.s32 	%p69, %r463, 0;
	@%p69 bra 	$L__BB7_41;

	mov.f32 	%f287, 0fBF800000;
	fma.rn.f32 	%f762, %f762, %f287, %f284;

$L__BB7_41:
	cvt.f64.f32 	%fd385, %f762;
	mul.rn.f64 	%fd386, %fd385, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd387, %fd23;
	add.rn.f64 	%fd388, %fd387, %fd386;
	cvt.rn.f32.f64 	%f18, %fd388;
	abs.f32 	%f19, %f2;
	setp.eq.f32 	%p70, %f19, 0f00000000;
	abs.f32 	%f20, %f4;
	setp.eq.f32 	%p71, %f20, 0f00000000;
	and.pred  	%p72, %p70, %p71;
	@%p72 bra 	$L__BB7_45;
	bra.uni 	$L__BB7_42;

$L__BB7_45:
	mov.b32 	%r474, %f2;
	shr.s32 	%r475, %r474, 31;
	and.b32  	%r476, %r475, 1078530011;
	mov.b32 	%r477, %f4;
	and.b32  	%r478, %r477, -2147483648;
	or.b32  	%r479, %r476, %r478;
	mov.b32 	%f763, %r479;
	bra.uni 	$L__BB7_46;

$L__BB7_42:
	setp.eq.f32 	%p73, %f19, 0f7F800000;
	setp.eq.f32 	%p74, %f20, 0f7F800000;
	and.pred  	%p75, %p73, %p74;
	@%p75 bra 	$L__BB7_44;
	bra.uni 	$L__BB7_43;

$L__BB7_44:
	mov.b32 	%r469, %f2;
	setp.lt.s32 	%p79, %r469, 0;
	selp.b32 	%r470, 1075235812, 1061752795, %p79;
	mov.b32 	%r471, %f4;
	and.b32  	%r472, %r471, -2147483648;
	or.b32  	%r473, %r470, %r472;
	mov.b32 	%f763, %r473;
	bra.uni 	$L__BB7_46;

$L__BB7_43:
	max.f32 	%f288, %f20, %f19;
	min.f32 	%f289, %f20, %f19;
	div.rn.f32 	%f290, %f289, %f288;
	mul.rn.f32 	%f291, %f290, %f290;
	mov.f32 	%f292, 0fC0B59883;
	mov.f32 	%f293, 0fBF52C7EA;
	fma.rn.f32 	%f294, %f291, %f293, %f292;
	mov.f32 	%f295, 0fC0D21907;
	fma.rn.f32 	%f296, %f294, %f291, %f295;
	mul.rn.f32 	%f297, %f291, %f296;
	mul.rn.f32 	%f298, %f290, %f297;
	add.rn.f32 	%f299, %f291, 0f41355DC0;
	mov.f32 	%f300, 0f41E6BD60;
	fma.rn.f32 	%f301, %f299, %f291, %f300;
	mov.f32 	%f302, 0f419D92C8;
	fma.rn.f32 	%f303, %f301, %f291, %f302;
	rcp.rn.f32 	%f304, %f303;
	fma.rn.f32 	%f305, %f298, %f304, %f290;
	mov.f32 	%f306, 0f3FC90FDB;
	sub.rn.f32 	%f307, %f306, %f305;
	setp.gt.f32 	%p76, %f20, %f19;
	selp.f32 	%f308, %f307, %f305, %p76;
	mov.b32 	%r464, %f2;
	setp.lt.s32 	%p77, %r464, 0;
	mov.f32 	%f309, 0f40490FDB;
	sub.rn.f32 	%f310, %f309, %f308;
	selp.f32 	%f311, %f310, %f308, %p77;
	mov.b32 	%r465, %f311;
	mov.b32 	%r466, %f4;
	and.b32  	%r467, %r466, -2147483648;
	or.b32  	%r468, %r467, %r465;
	mov.b32 	%f312, %r468;
	add.rn.f32 	%f313, %f19, %f20;
	setp.le.f32 	%p78, %f313, 0f7F800000;
	selp.f32 	%f763, %f312, %f313, %p78;

$L__BB7_46:
	mul.rn.f32 	%f25, %f2, 0f42517084;
	mul.rn.f32 	%f314, %f25, 0f3F22F983;
	cvt.rni.s32.f32 	%r1345, %f314;
	cvt.rn.f32.s32 	%f315, %r1345;
	mov.f32 	%f316, 0fBFC90FDA;
	fma.rn.f32 	%f317, %f315, %f316, %f25;
	mov.f32 	%f318, 0fB3A22168;
	fma.rn.f32 	%f319, %f315, %f318, %f317;
	mov.f32 	%f320, 0fA7C234C5;
	fma.rn.f32 	%f764, %f315, %f320, %f319;
	abs.f32 	%f27, %f25;
	setp.ltu.f32 	%p80, %f27, 0f47CE4780;
	@%p80 bra 	$L__BB7_54;

	setp.eq.f32 	%p81, %f27, 0f7F800000;
	@%p81 bra 	$L__BB7_53;
	bra.uni 	$L__BB7_48;

$L__BB7_53:
	mov.f32 	%f323, 0f00000000;
	mul.rn.f32 	%f764, %f25, %f323;
	mov.u32 	%r1345, 0;
	bra.uni 	$L__BB7_54;

$L__BB7_48:
	mov.b32 	%r27, %f25;
	bfe.u32 	%r481, %r27, 23, 8;
	add.s32 	%r28, %r481, -128;
	shl.b32 	%r482, %r27, 8;
	or.b32  	%r29, %r482, -2147483648;
	shr.u32 	%r30, %r28, 5;
	mov.u64 	%rd448, 0;
	mov.u32 	%r1342, 0;
	mov.u64 	%rd447, __cudart_i2opi_f;
	mov.u64 	%rd446, %rd1;

$L__BB7_49:
	.pragma "nounroll";
	ld.global.nc.u32 	%r483, [%rd447];
	mad.wide.u32 	%rd156, %r483, %r29, %rd448;
	shr.u64 	%rd448, %rd156, 32;
	st.local.u32 	[%rd446], %rd156;
	add.s64 	%rd447, %rd447, 4;
	add.s64 	%rd446, %rd446, 4;
	add.s32 	%r1342, %r1342, 1;
	setp.ne.s32 	%p82, %r1342, 6;
	@%p82 bra 	$L__BB7_49;

	st.local.u32 	[%rd23], %rd448;
	mov.u32 	%r484, 4;
	sub.s32 	%r33, %r484, %r30;
	mov.u32 	%r485, 6;
	sub.s32 	%r486, %r485, %r30;
	mul.wide.s32 	%rd157, %r486, 4;
	add.s64 	%rd158, %rd1, %rd157;
	ld.local.u32 	%r1343, [%rd158];
	ld.local.u32 	%r1344, [%rd158+-4];
	and.b32  	%r36, %r28, 31;
	setp.eq.s32 	%p83, %r36, 0;
	@%p83 bra 	$L__BB7_52;

	mov.u32 	%r487, 32;
	sub.s32 	%r488, %r487, %r36;
	shr.u32 	%r489, %r1344, %r488;
	shl.b32 	%r490, %r1343, %r36;
	add.s32 	%r1343, %r489, %r490;
	mul.wide.s32 	%rd159, %r33, 4;
	add.s64 	%rd160, %rd1, %rd159;
	ld.local.u32 	%r491, [%rd160];
	shr.u32 	%r492, %r491, %r488;
	shl.b32 	%r493, %r1344, %r36;
	add.s32 	%r1344, %r492, %r493;

$L__BB7_52:
	and.b32  	%r494, %r27, -2147483648;
	shr.u32 	%r495, %r1344, 30;
	shl.b32 	%r496, %r1343, 2;
	or.b32  	%r497, %r495, %r496;
	shr.u32 	%r498, %r497, 31;
	shr.u32 	%r499, %r1343, 30;
	add.s32 	%r500, %r498, %r499;
	neg.s32 	%r501, %r500;
	setp.eq.s32 	%p84, %r494, 0;
	selp.b32 	%r1345, %r500, %r501, %p84;
	setp.ne.s32 	%p85, %r498, 0;
	xor.b32  	%r502, %r494, -2147483648;
	selp.b32 	%r503, %r502, %r494, %p85;
	selp.b32 	%r504, -1, 0, %p85;
	xor.b32  	%r505, %r497, %r504;
	shl.b32 	%r506, %r1344, 2;
	xor.b32  	%r507, %r506, %r504;
	cvt.u64.u32 	%rd161, %r505;
	cvt.u64.u32 	%rd162, %r507;
	bfi.b64 	%rd163, %rd161, %rd162, 32, 32;
	cvt.rn.f64.s64 	%fd389, %rd163;
	mul.rn.f64 	%fd390, %fd389, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f321, %fd390;
	setp.eq.s32 	%p86, %r503, 0;
	neg.f32 	%f322, %f321;
	selp.f32 	%f764, %f321, %f322, %p86;

$L__BB7_54:
	add.s32 	%r43, %r1345, 1;
	and.b32  	%r44, %r43, 1;
	setp.eq.s32 	%p87, %r44, 0;
	selp.f32 	%f31, %f764, 0f3F800000, %p87;
	mul.rn.f32 	%f32, %f764, %f764;
	mov.f32 	%f765, 0fB94D4153;
	@%p87 bra 	$L__BB7_56;

	mov.f32 	%f325, 0fBAB607ED;
	mov.f32 	%f326, 0f37CBAC00;
	fma.rn.f32 	%f765, %f326, %f32, %f325;

$L__BB7_56:
	selp.f32 	%f327, 0f3C0885E4, 0f3D2AAABB, %p87;
	fma.rn.f32 	%f328, %f765, %f32, %f327;
	selp.f32 	%f329, 0fBE2AAAA8, 0fBEFFFFFF, %p87;
	fma.rn.f32 	%f330, %f328, %f32, %f329;
	mov.f32 	%f331, 0f00000000;
	fma.rn.f32 	%f332, %f32, %f31, %f331;
	fma.rn.f32 	%f766, %f330, %f332, %f31;
	and.b32  	%r509, %r43, 2;
	setp.eq.s32 	%p89, %r509, 0;
	@%p89 bra 	$L__BB7_58;

	mov.f32 	%f334, 0fBF800000;
	fma.rn.f32 	%f766, %f766, %f334, %f331;

$L__BB7_58:
	cvt.f64.f32 	%fd391, %f766;
	mul.rn.f64 	%fd392, %fd391, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd393, %f763;
	add.rn.f64 	%fd394, %fd393, %fd392;
	cvt.rn.f32.f64 	%f38, %fd394;
	mul.rn.f32 	%f335, %f38, 0f3F22F983;
	cvt.rni.s32.f32 	%r1353, %f335;
	cvt.rn.f32.s32 	%f336, %r1353;
	mov.f32 	%f337, 0fBFC90FDA;
	fma.rn.f32 	%f338, %f336, %f337, %f38;
	mov.f32 	%f339, 0fB3A22168;
	fma.rn.f32 	%f340, %f336, %f339, %f338;
	mov.f32 	%f341, 0fA7C234C5;
	fma.rn.f32 	%f770, %f336, %f341, %f340;
	abs.f32 	%f40, %f38;
	setp.ltu.f32 	%p90, %f40, 0f47CE4780;
	mov.u32 	%r1349, %r1353;
	mov.f32 	%f767, %f770;
	@%p90 bra 	$L__BB7_66;

	setp.eq.f32 	%p91, %f40, 0f7F800000;
	@%p91 bra 	$L__BB7_65;
	bra.uni 	$L__BB7_60;

$L__BB7_65:
	mov.f32 	%f344, 0f00000000;
	mul.rn.f32 	%f767, %f38, %f344;
	mov.u32 	%r1349, 0;
	bra.uni 	$L__BB7_66;

$L__BB7_60:
	mov.b32 	%r46, %f38;
	bfe.u32 	%r511, %r46, 23, 8;
	add.s32 	%r47, %r511, -128;
	shl.b32 	%r512, %r46, 8;
	or.b32  	%r48, %r512, -2147483648;
	shr.u32 	%r49, %r47, 5;
	mov.u64 	%rd451, 0;
	mov.u32 	%r1346, 0;
	mov.u64 	%rd450, __cudart_i2opi_f;
	mov.u64 	%rd449, %rd1;

$L__BB7_61:
	.pragma "nounroll";
	ld.global.nc.u32 	%r513, [%rd450];
	mad.wide.u32 	%rd166, %r513, %r48, %rd451;
	shr.u64 	%rd451, %rd166, 32;
	st.local.u32 	[%rd449], %rd166;
	add.s64 	%rd450, %rd450, 4;
	add.s64 	%rd449, %rd449, 4;
	add.s32 	%r1346, %r1346, 1;
	setp.ne.s32 	%p92, %r1346, 6;
	@%p92 bra 	$L__BB7_61;

	st.local.u32 	[%rd23], %rd451;
	mov.u32 	%r514, 4;
	sub.s32 	%r52, %r514, %r49;
	mov.u32 	%r515, 6;
	sub.s32 	%r516, %r515, %r49;
	mul.wide.s32 	%rd167, %r516, 4;
	add.s64 	%rd168, %rd1, %rd167;
	ld.local.u32 	%r1347, [%rd168];
	ld.local.u32 	%r1348, [%rd168+-4];
	and.b32  	%r55, %r47, 31;
	setp.eq.s32 	%p93, %r55, 0;
	@%p93 bra 	$L__BB7_64;

	mov.u32 	%r517, 32;
	sub.s32 	%r518, %r517, %r55;
	shr.u32 	%r519, %r1348, %r518;
	shl.b32 	%r520, %r1347, %r55;
	add.s32 	%r1347, %r519, %r520;
	mul.wide.s32 	%rd169, %r52, 4;
	add.s64 	%rd170, %rd1, %rd169;
	ld.local.u32 	%r521, [%rd170];
	shr.u32 	%r522, %r521, %r518;
	shl.b32 	%r523, %r1348, %r55;
	add.s32 	%r1348, %r522, %r523;

$L__BB7_64:
	and.b32  	%r524, %r46, -2147483648;
	shr.u32 	%r525, %r1348, 30;
	shl.b32 	%r526, %r1347, 2;
	or.b32  	%r527, %r525, %r526;
	shr.u32 	%r528, %r527, 31;
	shr.u32 	%r529, %r1347, 30;
	add.s32 	%r530, %r528, %r529;
	neg.s32 	%r531, %r530;
	setp.eq.s32 	%p94, %r524, 0;
	selp.b32 	%r1349, %r530, %r531, %p94;
	setp.ne.s32 	%p95, %r528, 0;
	xor.b32  	%r532, %r524, -2147483648;
	selp.b32 	%r533, %r532, %r524, %p95;
	selp.b32 	%r534, -1, 0, %p95;
	xor.b32  	%r535, %r527, %r534;
	shl.b32 	%r536, %r1348, 2;
	xor.b32  	%r537, %r536, %r534;
	cvt.u64.u32 	%rd171, %r535;
	cvt.u64.u32 	%rd172, %r537;
	bfi.b64 	%rd173, %rd171, %rd172, 32, 32;
	cvt.rn.f64.s64 	%fd395, %rd173;
	mul.rn.f64 	%fd396, %fd395, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f342, %fd396;
	setp.eq.s32 	%p96, %r533, 0;
	neg.f32 	%f343, %f342;
	selp.f32 	%f767, %f342, %f343, %p96;

$L__BB7_66:
	add.s32 	%r62, %r1349, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p97, %r63, 0;
	selp.f32 	%f44, %f767, 0f3F800000, %p97;
	mul.rn.f32 	%f45, %f767, %f767;
	mov.f32 	%f768, 0fB94D4153;
	@%p97 bra 	$L__BB7_68;

	mov.f32 	%f346, 0fBAB607ED;
	mov.f32 	%f347, 0f37CBAC00;
	fma.rn.f32 	%f768, %f347, %f45, %f346;

$L__BB7_68:
	selp.f32 	%f348, 0f3C0885E4, 0f3D2AAABB, %p97;
	fma.rn.f32 	%f349, %f768, %f45, %f348;
	selp.f32 	%f350, 0fBE2AAAA8, 0fBEFFFFFF, %p97;
	fma.rn.f32 	%f351, %f349, %f45, %f350;
	mov.f32 	%f352, 0f00000000;
	fma.rn.f32 	%f353, %f45, %f44, %f352;
	fma.rn.f32 	%f769, %f351, %f353, %f44;
	and.b32  	%r539, %r62, 2;
	setp.eq.s32 	%p99, %r539, 0;
	@%p99 bra 	$L__BB7_70;

	mov.f32 	%f355, 0fBF800000;
	fma.rn.f32 	%f769, %f769, %f355, %f352;

$L__BB7_70:
	mul.rn.f32 	%f51, %f769, %f18;
	@%p90 bra 	$L__BB7_78;

	setp.eq.f32 	%p101, %f40, 0f7F800000;
	@%p101 bra 	$L__BB7_77;
	bra.uni 	$L__BB7_72;

$L__BB7_77:
	mov.f32 	%f358, 0f00000000;
	mul.rn.f32 	%f770, %f38, %f358;
	mov.u32 	%r1353, 0;
	bra.uni 	$L__BB7_78;

$L__BB7_72:
	mov.b32 	%r64, %f38;
	bfe.u32 	%r541, %r64, 23, 8;
	add.s32 	%r65, %r541, -128;
	shl.b32 	%r542, %r64, 8;
	or.b32  	%r66, %r542, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd454, 0;
	mov.u32 	%r1350, 0;
	mov.u64 	%rd453, __cudart_i2opi_f;
	mov.u64 	%rd452, %rd1;

$L__BB7_73:
	.pragma "nounroll";
	ld.global.nc.u32 	%r543, [%rd453];
	mad.wide.u32 	%rd176, %r543, %r66, %rd454;
	shr.u64 	%rd454, %rd176, 32;
	st.local.u32 	[%rd452], %rd176;
	add.s64 	%rd453, %rd453, 4;
	add.s64 	%rd452, %rd452, 4;
	add.s32 	%r1350, %r1350, 1;
	setp.ne.s32 	%p102, %r1350, 6;
	@%p102 bra 	$L__BB7_73;

	st.local.u32 	[%rd23], %rd454;
	mov.u32 	%r544, 4;
	sub.s32 	%r70, %r544, %r67;
	mov.u32 	%r545, 6;
	sub.s32 	%r546, %r545, %r67;
	mul.wide.s32 	%rd177, %r546, 4;
	add.s64 	%rd178, %rd1, %rd177;
	ld.local.u32 	%r1351, [%rd178];
	ld.local.u32 	%r1352, [%rd178+-4];
	and.b32  	%r73, %r65, 31;
	setp.eq.s32 	%p103, %r73, 0;
	@%p103 bra 	$L__BB7_76;

	mov.u32 	%r547, 32;
	sub.s32 	%r548, %r547, %r73;
	shr.u32 	%r549, %r1352, %r548;
	shl.b32 	%r550, %r1351, %r73;
	add.s32 	%r1351, %r549, %r550;
	mul.wide.s32 	%rd179, %r70, 4;
	add.s64 	%rd180, %rd1, %rd179;
	ld.local.u32 	%r551, [%rd180];
	shr.u32 	%r552, %r551, %r548;
	shl.b32 	%r553, %r1352, %r73;
	add.s32 	%r1352, %r552, %r553;

$L__BB7_76:
	and.b32  	%r554, %r64, -2147483648;
	shr.u32 	%r555, %r1352, 30;
	shl.b32 	%r556, %r1351, 2;
	or.b32  	%r557, %r555, %r556;
	shr.u32 	%r558, %r557, 31;
	shr.u32 	%r559, %r1351, 30;
	add.s32 	%r560, %r558, %r559;
	neg.s32 	%r561, %r560;
	setp.eq.s32 	%p104, %r554, 0;
	selp.b32 	%r1353, %r560, %r561, %p104;
	setp.ne.s32 	%p105, %r558, 0;
	xor.b32  	%r562, %r554, -2147483648;
	selp.b32 	%r563, %r562, %r554, %p105;
	selp.b32 	%r564, -1, 0, %p105;
	xor.b32  	%r565, %r557, %r564;
	shl.b32 	%r566, %r1352, 2;
	xor.b32  	%r567, %r566, %r564;
	cvt.u64.u32 	%rd181, %r565;
	cvt.u64.u32 	%rd182, %r567;
	bfi.b64 	%rd183, %rd181, %rd182, 32, 32;
	cvt.rn.f64.s64 	%fd397, %rd183;
	mul.rn.f64 	%fd398, %fd397, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f356, %fd398;
	setp.eq.s32 	%p106, %r563, 0;
	neg.f32 	%f357, %f356;
	selp.f32 	%f770, %f356, %f357, %p106;

$L__BB7_78:
	and.b32  	%r80, %r1353, 1;
	setp.eq.s32 	%p107, %r80, 0;
	selp.f32 	%f55, %f770, 0f3F800000, %p107;
	mul.rn.f32 	%f56, %f770, %f770;
	mov.f32 	%f771, 0fB94D4153;
	@%p107 bra 	$L__BB7_80;

	mov.f32 	%f360, 0fBAB607ED;
	mov.f32 	%f361, 0f37CBAC00;
	fma.rn.f32 	%f771, %f361, %f56, %f360;

$L__BB7_80:
	selp.f32 	%f362, 0f3C0885E4, 0f3D2AAABB, %p107;
	fma.rn.f32 	%f363, %f771, %f56, %f362;
	selp.f32 	%f364, 0fBE2AAAA8, 0fBEFFFFFF, %p107;
	fma.rn.f32 	%f365, %f363, %f56, %f364;
	mov.f32 	%f366, 0f00000000;
	fma.rn.f32 	%f367, %f56, %f55, %f366;
	fma.rn.f32 	%f772, %f365, %f367, %f55;
	and.b32  	%r569, %r1353, 2;
	setp.eq.s32 	%p109, %r569, 0;
	@%p109 bra 	$L__BB7_82;

	mov.f32 	%f369, 0fBF800000;
	fma.rn.f32 	%f772, %f772, %f369, %f366;

$L__BB7_82:
	mul.rn.f32 	%f62, %f772, %f18;
	add.rn.f32 	%f63, %f62, 0fC20C0000;
	add.rn.f32 	%f64, %f51, 0fC2D20000;
	cvt.f64.f32 	%fd24, %f64;
	mul.rn.f64 	%fd399, %fd24, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f65, %fd399;
	cvt.f64.f32 	%fd25, %f63;
	mul.rn.f64 	%fd400, %fd25, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f66, %fd400;
	cvt.f64.f32 	%fd26, %f65;
	mul.rn.f64 	%fd27, %fd26, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r570, %temp}, %fd27;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r571}, %fd27;
	}
	and.b32  	%r572, %r571, 2147483647;
	setp.eq.s32 	%p110, %r572, 2146435072;
	setp.eq.s32 	%p111, %r570, 0;
	and.pred  	%p112, %p111, %p110;
	@%p112 bra 	$L__BB7_85;
	bra.uni 	$L__BB7_83;

$L__BB7_85:
	mov.f64 	%fd410, 0d0000000000000000;
	mul.rn.f64 	%fd1080, %fd27, %fd410;
	mov.u32 	%r1354, 0;
	bra.uni 	$L__BB7_86;

$L__BB7_83:
	mul.rn.f64 	%fd401, %fd27, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1354, %fd401;
	st.local.u32 	[%rd8], %r1354;
	cvt.rn.f64.s32 	%fd402, %r1354;
	neg.f64 	%fd403, %fd402;
	mov.f64 	%fd404, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd405, %fd403, %fd404, %fd27;
	mov.f64 	%fd406, 0d3C91A62633145C00;
	fma.rn.f64 	%fd407, %fd403, %fd406, %fd405;
	mov.f64 	%fd408, 0d397B839A252049C0;
	fma.rn.f64 	%fd1080, %fd403, %fd408, %fd407;
	abs.f64 	%fd409, %fd27;
	setp.ltu.f64 	%p113, %fd409, 0d41E0000000000000;
	@%p113 bra 	$L__BB7_86;

	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1080, [retval0+0];
	} // callseq 74
	ld.local.u32 	%r1354, [%rd8];

$L__BB7_86:
	and.b32  	%r574, %r1354, 1;
	shl.b32 	%r575, %r1354, 3;
	and.b32  	%r576, %r575, 8;
	setp.eq.s32 	%p114, %r574, 0;
	selp.f64 	%fd411, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p114;
	mul.wide.s32 	%rd185, %r576, 8;
	mov.u64 	%rd186, __cudart_sin_cos_coeffs;
	add.s64 	%rd187, %rd186, %rd185;
	ld.global.nc.f64 	%fd412, [%rd187+8];
	mul.rn.f64 	%fd32, %fd1080, %fd1080;
	fma.rn.f64 	%fd413, %fd411, %fd32, %fd412;
	ld.global.nc.f64 	%fd414, [%rd187+16];
	fma.rn.f64 	%fd415, %fd413, %fd32, %fd414;
	ld.global.nc.f64 	%fd416, [%rd187+24];
	fma.rn.f64 	%fd417, %fd415, %fd32, %fd416;
	ld.global.nc.f64 	%fd418, [%rd187+32];
	fma.rn.f64 	%fd419, %fd417, %fd32, %fd418;
	ld.global.nc.f64 	%fd420, [%rd187+40];
	fma.rn.f64 	%fd421, %fd419, %fd32, %fd420;
	ld.global.nc.f64 	%fd422, [%rd187+48];
	fma.rn.f64 	%fd33, %fd421, %fd32, %fd422;
	fma.rn.f64 	%fd1082, %fd33, %fd1080, %fd1080;
	@%p114 bra 	$L__BB7_88;

	mov.f64 	%fd423, 0d3FF0000000000000;
	fma.rn.f64 	%fd1082, %fd33, %fd32, %fd423;

$L__BB7_88:
	and.b32  	%r577, %r1354, 2;
	setp.eq.s32 	%p115, %r577, 0;
	@%p115 bra 	$L__BB7_90;

	mov.f64 	%fd424, 0d0000000000000000;
	mov.f64 	%fd425, 0dBFF0000000000000;
	fma.rn.f64 	%fd1082, %fd1082, %fd425, %fd424;

$L__BB7_90:
	add.rn.f64 	%fd39, %fd26, %fd26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r578, %temp}, %fd39;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r579}, %fd39;
	}
	and.b32  	%r580, %r579, 2147483647;
	setp.eq.s32 	%p116, %r580, 2146435072;
	setp.eq.s32 	%p117, %r578, 0;
	and.pred  	%p118, %p117, %p116;
	@%p118 bra 	$L__BB7_93;
	bra.uni 	$L__BB7_91;

$L__BB7_93:
	mov.f64 	%fd435, 0d0000000000000000;
	mul.rn.f64 	%fd1083, %fd39, %fd435;
	mov.u32 	%r1355, 0;
	bra.uni 	$L__BB7_94;

$L__BB7_91:
	mul.rn.f64 	%fd426, %fd39, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1355, %fd426;
	st.local.u32 	[%rd8], %r1355;
	cvt.rn.f64.s32 	%fd427, %r1355;
	neg.f64 	%fd428, %fd427;
	mov.f64 	%fd429, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd430, %fd428, %fd429, %fd39;
	mov.f64 	%fd431, 0d3C91A62633145C00;
	fma.rn.f64 	%fd432, %fd428, %fd431, %fd430;
	mov.f64 	%fd433, 0d397B839A252049C0;
	fma.rn.f64 	%fd1083, %fd428, %fd433, %fd432;
	abs.f64 	%fd434, %fd39;
	setp.ltu.f64 	%p119, %fd434, 0d41E0000000000000;
	@%p119 bra 	$L__BB7_94;

	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd39;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1083, [retval0+0];
	} // callseq 75
	ld.local.u32 	%r1355, [%rd8];

$L__BB7_94:
	and.b32  	%r582, %r1355, 1;
	shl.b32 	%r583, %r1355, 3;
	and.b32  	%r584, %r583, 8;
	setp.eq.s32 	%p120, %r582, 0;
	selp.f64 	%fd436, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p120;
	mul.wide.s32 	%rd189, %r584, 8;
	add.s64 	%rd191, %rd186, %rd189;
	ld.global.nc.f64 	%fd437, [%rd191+8];
	mul.rn.f64 	%fd44, %fd1083, %fd1083;
	fma.rn.f64 	%fd438, %fd436, %fd44, %fd437;
	ld.global.nc.f64 	%fd439, [%rd191+16];
	fma.rn.f64 	%fd440, %fd438, %fd44, %fd439;
	ld.global.nc.f64 	%fd441, [%rd191+24];
	fma.rn.f64 	%fd442, %fd440, %fd44, %fd441;
	ld.global.nc.f64 	%fd443, [%rd191+32];
	fma.rn.f64 	%fd444, %fd442, %fd44, %fd443;
	ld.global.nc.f64 	%fd445, [%rd191+40];
	fma.rn.f64 	%fd446, %fd444, %fd44, %fd445;
	ld.global.nc.f64 	%fd447, [%rd191+48];
	fma.rn.f64 	%fd45, %fd446, %fd44, %fd447;
	fma.rn.f64 	%fd1085, %fd45, %fd1083, %fd1083;
	@%p120 bra 	$L__BB7_96;

	mov.f64 	%fd448, 0d3FF0000000000000;
	fma.rn.f64 	%fd1085, %fd45, %fd44, %fd448;

$L__BB7_96:
	and.b32  	%r585, %r1355, 2;
	setp.eq.s32 	%p121, %r585, 0;
	@%p121 bra 	$L__BB7_98;

	mov.f64 	%fd449, 0d0000000000000000;
	mov.f64 	%fd450, 0dBFF0000000000000;
	fma.rn.f64 	%fd1085, %fd1085, %fd450, %fd449;

$L__BB7_98:
	mul.rn.f64 	%fd451, %fd1085, 0d4034000000000000;
	mul.rn.f64 	%fd452, %fd1082, 0d4034000000000000;
	add.rn.f64 	%fd51, %fd452, %fd451;
	mul.rn.f32 	%f370, %f66, 0f3F22F983;
	cvt.rni.s32.f32 	%r1359, %f370;
	cvt.rn.f32.s32 	%f371, %r1359;
	mov.f32 	%f372, 0fBFC90FDA;
	fma.rn.f32 	%f373, %f371, %f372, %f66;
	mov.f32 	%f374, 0fB3A22168;
	fma.rn.f32 	%f375, %f371, %f374, %f373;
	mov.f32 	%f376, 0fA7C234C5;
	fma.rn.f32 	%f773, %f371, %f376, %f375;
	abs.f32 	%f68, %f66;
	setp.ltu.f32 	%p122, %f68, 0f47CE4780;
	@%p122 bra 	$L__BB7_106;

	setp.eq.f32 	%p123, %f68, 0f7F800000;
	@%p123 bra 	$L__BB7_105;
	bra.uni 	$L__BB7_100;

$L__BB7_105:
	mov.f32 	%f379, 0f00000000;
	mul.rn.f32 	%f773, %f66, %f379;
	mov.u32 	%r1359, 0;
	bra.uni 	$L__BB7_106;

$L__BB7_100:
	mov.b32 	%r88, %f66;
	bfe.u32 	%r587, %r88, 23, 8;
	add.s32 	%r89, %r587, -128;
	shl.b32 	%r588, %r88, 8;
	or.b32  	%r90, %r588, -2147483648;
	shr.u32 	%r91, %r89, 5;
	mov.u64 	%rd457, 0;
	mov.u32 	%r1356, 0;
	mov.u64 	%rd456, __cudart_i2opi_f;
	mov.u64 	%rd455, %rd1;

$L__BB7_101:
	.pragma "nounroll";
	ld.global.nc.u32 	%r589, [%rd456];
	mad.wide.u32 	%rd194, %r589, %r90, %rd457;
	shr.u64 	%rd457, %rd194, 32;
	st.local.u32 	[%rd455], %rd194;
	add.s64 	%rd456, %rd456, 4;
	add.s64 	%rd455, %rd455, 4;
	add.s32 	%r1356, %r1356, 1;
	setp.ne.s32 	%p124, %r1356, 6;
	@%p124 bra 	$L__BB7_101;

	st.local.u32 	[%rd23], %rd457;
	mov.u32 	%r590, 4;
	sub.s32 	%r94, %r590, %r91;
	mov.u32 	%r591, 6;
	sub.s32 	%r592, %r591, %r91;
	mul.wide.s32 	%rd195, %r592, 4;
	add.s64 	%rd196, %rd1, %rd195;
	ld.local.u32 	%r1357, [%rd196];
	ld.local.u32 	%r1358, [%rd196+-4];
	and.b32  	%r97, %r89, 31;
	setp.eq.s32 	%p125, %r97, 0;
	@%p125 bra 	$L__BB7_104;

	mov.u32 	%r593, 32;
	sub.s32 	%r594, %r593, %r97;
	shr.u32 	%r595, %r1358, %r594;
	shl.b32 	%r596, %r1357, %r97;
	add.s32 	%r1357, %r595, %r596;
	mul.wide.s32 	%rd197, %r94, 4;
	add.s64 	%rd198, %rd1, %rd197;
	ld.local.u32 	%r597, [%rd198];
	shr.u32 	%r598, %r597, %r594;
	shl.b32 	%r599, %r1358, %r97;
	add.s32 	%r1358, %r598, %r599;

$L__BB7_104:
	and.b32  	%r600, %r88, -2147483648;
	shr.u32 	%r601, %r1358, 30;
	shl.b32 	%r602, %r1357, 2;
	or.b32  	%r603, %r601, %r602;
	shr.u32 	%r604, %r603, 31;
	shr.u32 	%r605, %r1357, 30;
	add.s32 	%r606, %r604, %r605;
	neg.s32 	%r607, %r606;
	setp.eq.s32 	%p126, %r600, 0;
	selp.b32 	%r1359, %r606, %r607, %p126;
	setp.ne.s32 	%p127, %r604, 0;
	xor.b32  	%r608, %r600, -2147483648;
	selp.b32 	%r609, %r608, %r600, %p127;
	selp.b32 	%r610, -1, 0, %p127;
	xor.b32  	%r611, %r603, %r610;
	shl.b32 	%r612, %r1358, 2;
	xor.b32  	%r613, %r612, %r610;
	cvt.u64.u32 	%rd199, %r611;
	cvt.u64.u32 	%rd200, %r613;
	bfi.b64 	%rd201, %rd199, %rd200, 32, 32;
	cvt.rn.f64.s64 	%fd453, %rd201;
	mul.rn.f64 	%fd454, %fd453, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f377, %fd454;
	setp.eq.s32 	%p128, %r609, 0;
	neg.f32 	%f378, %f377;
	selp.f32 	%f773, %f377, %f378, %p128;

$L__BB7_106:
	and.b32  	%r104, %r1359, 1;
	setp.eq.s32 	%p129, %r104, 0;
	selp.f32 	%f72, %f773, 0f3F800000, %p129;
	mul.rn.f32 	%f73, %f773, %f773;
	mov.f32 	%f774, 0fB94D4153;
	@%p129 bra 	$L__BB7_108;

	mov.f32 	%f381, 0fBAB607ED;
	mov.f32 	%f382, 0f37CBAC00;
	fma.rn.f32 	%f774, %f382, %f73, %f381;

$L__BB7_108:
	selp.f32 	%f383, 0f3C0885E4, 0f3D2AAABB, %p129;
	fma.rn.f32 	%f384, %f774, %f73, %f383;
	selp.f32 	%f385, 0fBE2AAAA8, 0fBEFFFFFF, %p129;
	fma.rn.f32 	%f386, %f384, %f73, %f385;
	mov.f32 	%f387, 0f00000000;
	fma.rn.f32 	%f388, %f73, %f72, %f387;
	fma.rn.f32 	%f775, %f386, %f388, %f72;
	and.b32  	%r615, %r1359, 2;
	setp.eq.s32 	%p131, %r615, 0;
	@%p131 bra 	$L__BB7_110;

	mov.f32 	%f390, 0fBF800000;
	fma.rn.f32 	%f775, %f775, %f390, %f387;

$L__BB7_110:
	cvt.f64.f32 	%fd52, %f66;
	div.rn.f64 	%fd53, %fd52, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r616, %temp}, %fd53;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r617}, %fd53;
	}
	and.b32  	%r618, %r617, 2147483647;
	setp.eq.s32 	%p132, %r618, 2146435072;
	setp.eq.s32 	%p133, %r616, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB7_113;
	bra.uni 	$L__BB7_111;

$L__BB7_113:
	mov.f64 	%fd464, 0d0000000000000000;
	mul.rn.f64 	%fd1086, %fd53, %fd464;
	mov.u32 	%r1360, 0;
	bra.uni 	$L__BB7_114;

$L__BB7_111:
	mul.rn.f64 	%fd455, %fd53, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1360, %fd455;
	st.local.u32 	[%rd8], %r1360;
	cvt.rn.f64.s32 	%fd456, %r1360;
	neg.f64 	%fd457, %fd456;
	mov.f64 	%fd458, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd459, %fd457, %fd458, %fd53;
	mov.f64 	%fd460, 0d3C91A62633145C00;
	fma.rn.f64 	%fd461, %fd457, %fd460, %fd459;
	mov.f64 	%fd462, 0d397B839A252049C0;
	fma.rn.f64 	%fd1086, %fd457, %fd462, %fd461;
	abs.f64 	%fd463, %fd53;
	setp.ltu.f64 	%p135, %fd463, 0d41E0000000000000;
	@%p135 bra 	$L__BB7_114;

	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd53;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1086, [retval0+0];
	} // callseq 76
	ld.local.u32 	%r1360, [%rd8];

$L__BB7_114:
	and.b32  	%r620, %r1360, 1;
	shl.b32 	%r621, %r1360, 3;
	and.b32  	%r622, %r621, 8;
	setp.eq.s32 	%p136, %r620, 0;
	selp.f64 	%fd465, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd203, %r622, 8;
	add.s64 	%rd205, %rd186, %rd203;
	ld.global.nc.f64 	%fd466, [%rd205+8];
	mul.rn.f64 	%fd58, %fd1086, %fd1086;
	fma.rn.f64 	%fd467, %fd465, %fd58, %fd466;
	ld.global.nc.f64 	%fd468, [%rd205+16];
	fma.rn.f64 	%fd469, %fd467, %fd58, %fd468;
	ld.global.nc.f64 	%fd470, [%rd205+24];
	fma.rn.f64 	%fd471, %fd469, %fd58, %fd470;
	ld.global.nc.f64 	%fd472, [%rd205+32];
	fma.rn.f64 	%fd473, %fd471, %fd58, %fd472;
	ld.global.nc.f64 	%fd474, [%rd205+40];
	fma.rn.f64 	%fd475, %fd473, %fd58, %fd474;
	ld.global.nc.f64 	%fd476, [%rd205+48];
	fma.rn.f64 	%fd59, %fd475, %fd58, %fd476;
	fma.rn.f64 	%fd1088, %fd59, %fd1086, %fd1086;
	@%p136 bra 	$L__BB7_116;

	mov.f64 	%fd477, 0d3FF0000000000000;
	fma.rn.f64 	%fd1088, %fd59, %fd58, %fd477;

$L__BB7_116:
	and.b32  	%r623, %r1360, 2;
	setp.eq.s32 	%p137, %r623, 0;
	@%p137 bra 	$L__BB7_118;

	mov.f64 	%fd478, 0d0000000000000000;
	mov.f64 	%fd479, 0dBFF0000000000000;
	fma.rn.f64 	%fd1088, %fd1088, %fd479, %fd478;

$L__BB7_118:
	mul.rn.f64 	%fd480, %fd1088, 0d4044000000000000;
	cvt.f64.f32 	%fd481, %f775;
	mul.rn.f64 	%fd482, %fd481, 0d4034000000000000;
	add.rn.f64 	%fd65, %fd482, %fd480;
	div.rn.f64 	%fd66, %fd52, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r624, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r625}, %fd66;
	}
	and.b32  	%r626, %r625, 2147483647;
	setp.eq.s32 	%p138, %r626, 2146435072;
	setp.eq.s32 	%p139, %r624, 0;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB7_121;
	bra.uni 	$L__BB7_119;

$L__BB7_121:
	mov.f64 	%fd492, 0d0000000000000000;
	mul.rn.f64 	%fd1089, %fd66, %fd492;
	mov.u32 	%r1361, 0;
	bra.uni 	$L__BB7_122;

$L__BB7_119:
	mul.rn.f64 	%fd483, %fd66, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1361, %fd483;
	st.local.u32 	[%rd8], %r1361;
	cvt.rn.f64.s32 	%fd484, %r1361;
	neg.f64 	%fd485, %fd484;
	mov.f64 	%fd486, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd487, %fd485, %fd486, %fd66;
	mov.f64 	%fd488, 0d3C91A62633145C00;
	fma.rn.f64 	%fd489, %fd485, %fd488, %fd487;
	mov.f64 	%fd490, 0d397B839A252049C0;
	fma.rn.f64 	%fd1089, %fd485, %fd490, %fd489;
	abs.f64 	%fd491, %fd66;
	setp.ltu.f64 	%p141, %fd491, 0d41E0000000000000;
	@%p141 bra 	$L__BB7_122;

	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd66;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1089, [retval0+0];
	} // callseq 77
	ld.local.u32 	%r1361, [%rd8];

$L__BB7_122:
	and.b32  	%r628, %r1361, 1;
	shl.b32 	%r629, %r1361, 3;
	and.b32  	%r630, %r629, 8;
	setp.eq.s32 	%p142, %r628, 0;
	selp.f64 	%fd493, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd207, %r630, 8;
	add.s64 	%rd209, %rd186, %rd207;
	ld.global.nc.f64 	%fd494, [%rd209+8];
	mul.rn.f64 	%fd71, %fd1089, %fd1089;
	fma.rn.f64 	%fd495, %fd493, %fd71, %fd494;
	ld.global.nc.f64 	%fd496, [%rd209+16];
	fma.rn.f64 	%fd497, %fd495, %fd71, %fd496;
	ld.global.nc.f64 	%fd498, [%rd209+24];
	fma.rn.f64 	%fd499, %fd497, %fd71, %fd498;
	ld.global.nc.f64 	%fd500, [%rd209+32];
	fma.rn.f64 	%fd501, %fd499, %fd71, %fd500;
	ld.global.nc.f64 	%fd502, [%rd209+40];
	fma.rn.f64 	%fd503, %fd501, %fd71, %fd502;
	ld.global.nc.f64 	%fd504, [%rd209+48];
	fma.rn.f64 	%fd72, %fd503, %fd71, %fd504;
	fma.rn.f64 	%fd1091, %fd72, %fd1089, %fd1089;
	@%p142 bra 	$L__BB7_124;

	mov.f64 	%fd505, 0d3FF0000000000000;
	fma.rn.f64 	%fd1091, %fd72, %fd71, %fd505;

$L__BB7_124:
	and.b32  	%r631, %r1361, 2;
	setp.eq.s32 	%p143, %r631, 0;
	@%p143 bra 	$L__BB7_126;

	mov.f64 	%fd506, 0d0000000000000000;
	mov.f64 	%fd507, 0dBFF0000000000000;
	fma.rn.f64 	%fd1091, %fd1091, %fd507, %fd506;

$L__BB7_126:
	mul.rn.f64 	%fd508, %fd1091, 0d4064000000000000;
	add.rn.f64 	%fd78, %fd65, %fd508;
	div.rn.f64 	%fd79, %fd52, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r632, %temp}, %fd79;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r633}, %fd79;
	}
	and.b32  	%r634, %r633, 2147483647;
	setp.eq.s32 	%p144, %r634, 2146435072;
	setp.eq.s32 	%p145, %r632, 0;
	and.pred  	%p146, %p145, %p144;
	@%p146 bra 	$L__BB7_129;
	bra.uni 	$L__BB7_127;

$L__BB7_129:
	mov.f64 	%fd518, 0d0000000000000000;
	mul.rn.f64 	%fd1092, %fd79, %fd518;
	mov.u32 	%r1362, 0;
	bra.uni 	$L__BB7_130;

$L__BB7_127:
	mul.rn.f64 	%fd509, %fd79, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1362, %fd509;
	st.local.u32 	[%rd8], %r1362;
	cvt.rn.f64.s32 	%fd510, %r1362;
	neg.f64 	%fd511, %fd510;
	mov.f64 	%fd512, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd513, %fd511, %fd512, %fd79;
	mov.f64 	%fd514, 0d3C91A62633145C00;
	fma.rn.f64 	%fd515, %fd511, %fd514, %fd513;
	mov.f64 	%fd516, 0d397B839A252049C0;
	fma.rn.f64 	%fd1092, %fd511, %fd516, %fd515;
	abs.f64 	%fd517, %fd79;
	setp.ltu.f64 	%p147, %fd517, 0d41E0000000000000;
	@%p147 bra 	$L__BB7_130;

	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1092, [retval0+0];
	} // callseq 78
	ld.local.u32 	%r1362, [%rd8];

$L__BB7_130:
	and.b32  	%r636, %r1362, 1;
	shl.b32 	%r637, %r1362, 3;
	and.b32  	%r638, %r637, 8;
	setp.eq.s32 	%p148, %r636, 0;
	selp.f64 	%fd519, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p148;
	mul.wide.s32 	%rd211, %r638, 8;
	add.s64 	%rd213, %rd186, %rd211;
	ld.global.nc.f64 	%fd520, [%rd213+8];
	mul.rn.f64 	%fd84, %fd1092, %fd1092;
	fma.rn.f64 	%fd521, %fd519, %fd84, %fd520;
	ld.global.nc.f64 	%fd522, [%rd213+16];
	fma.rn.f64 	%fd523, %fd521, %fd84, %fd522;
	ld.global.nc.f64 	%fd524, [%rd213+24];
	fma.rn.f64 	%fd525, %fd523, %fd84, %fd524;
	ld.global.nc.f64 	%fd526, [%rd213+32];
	fma.rn.f64 	%fd527, %fd525, %fd84, %fd526;
	ld.global.nc.f64 	%fd528, [%rd213+40];
	fma.rn.f64 	%fd529, %fd527, %fd84, %fd528;
	ld.global.nc.f64 	%fd530, [%rd213+48];
	fma.rn.f64 	%fd85, %fd529, %fd84, %fd530;
	fma.rn.f64 	%fd1094, %fd85, %fd1092, %fd1092;
	@%p148 bra 	$L__BB7_132;

	mov.f64 	%fd531, 0d3FF0000000000000;
	fma.rn.f64 	%fd1094, %fd85, %fd84, %fd531;

$L__BB7_132:
	and.b32  	%r639, %r1362, 2;
	setp.eq.s32 	%p149, %r639, 0;
	@%p149 bra 	$L__BB7_134;

	mov.f64 	%fd532, 0d0000000000000000;
	mov.f64 	%fd533, 0dBFF0000000000000;
	fma.rn.f64 	%fd1094, %fd1094, %fd533, %fd532;

$L__BB7_134:
	mul.rn.f64 	%fd534, %fd1094, 0d4074000000000000;
	add.rn.f64 	%fd91, %fd78, %fd534;
	mul.rn.f32 	%f391, %f65, 0f3F22F983;
	cvt.rni.s32.f32 	%r1366, %f391;
	cvt.rn.f32.s32 	%f392, %r1366;
	mov.f32 	%f393, 0fBFC90FDA;
	fma.rn.f32 	%f394, %f392, %f393, %f65;
	mov.f32 	%f395, 0fB3A22168;
	fma.rn.f32 	%f396, %f392, %f395, %f394;
	mov.f32 	%f397, 0fA7C234C5;
	fma.rn.f32 	%f776, %f392, %f397, %f396;
	abs.f32 	%f80, %f65;
	setp.ltu.f32 	%p150, %f80, 0f47CE4780;
	@%p150 bra 	$L__BB7_142;

	setp.eq.f32 	%p151, %f80, 0f7F800000;
	@%p151 bra 	$L__BB7_141;
	bra.uni 	$L__BB7_136;

$L__BB7_141:
	mov.f32 	%f400, 0f00000000;
	mul.rn.f32 	%f776, %f65, %f400;
	mov.u32 	%r1366, 0;
	bra.uni 	$L__BB7_142;

$L__BB7_136:
	mov.b32 	%r115, %f65;
	bfe.u32 	%r641, %r115, 23, 8;
	add.s32 	%r116, %r641, -128;
	shl.b32 	%r642, %r115, 8;
	or.b32  	%r117, %r642, -2147483648;
	shr.u32 	%r118, %r116, 5;
	mov.u64 	%rd460, 0;
	mov.u32 	%r1363, 0;
	mov.u64 	%rd459, __cudart_i2opi_f;
	mov.u64 	%rd458, %rd1;

$L__BB7_137:
	.pragma "nounroll";
	ld.global.nc.u32 	%r643, [%rd459];
	mad.wide.u32 	%rd216, %r643, %r117, %rd460;
	shr.u64 	%rd460, %rd216, 32;
	st.local.u32 	[%rd458], %rd216;
	add.s64 	%rd459, %rd459, 4;
	add.s64 	%rd458, %rd458, 4;
	add.s32 	%r1363, %r1363, 1;
	setp.ne.s32 	%p152, %r1363, 6;
	@%p152 bra 	$L__BB7_137;

	st.local.u32 	[%rd23], %rd460;
	mov.u32 	%r644, 4;
	sub.s32 	%r121, %r644, %r118;
	mov.u32 	%r645, 6;
	sub.s32 	%r646, %r645, %r118;
	mul.wide.s32 	%rd217, %r646, 4;
	add.s64 	%rd218, %rd1, %rd217;
	ld.local.u32 	%r1364, [%rd218];
	ld.local.u32 	%r1365, [%rd218+-4];
	and.b32  	%r124, %r116, 31;
	setp.eq.s32 	%p153, %r124, 0;
	@%p153 bra 	$L__BB7_140;

	mov.u32 	%r647, 32;
	sub.s32 	%r648, %r647, %r124;
	shr.u32 	%r649, %r1365, %r648;
	shl.b32 	%r650, %r1364, %r124;
	add.s32 	%r1364, %r649, %r650;
	mul.wide.s32 	%rd219, %r121, 4;
	add.s64 	%rd220, %rd1, %rd219;
	ld.local.u32 	%r651, [%rd220];
	shr.u32 	%r652, %r651, %r648;
	shl.b32 	%r653, %r1365, %r124;
	add.s32 	%r1365, %r652, %r653;

$L__BB7_140:
	and.b32  	%r654, %r115, -2147483648;
	shr.u32 	%r655, %r1365, 30;
	shl.b32 	%r656, %r1364, 2;
	or.b32  	%r657, %r655, %r656;
	shr.u32 	%r658, %r657, 31;
	shr.u32 	%r659, %r1364, 30;
	add.s32 	%r660, %r658, %r659;
	neg.s32 	%r661, %r660;
	setp.eq.s32 	%p154, %r654, 0;
	selp.b32 	%r1366, %r660, %r661, %p154;
	setp.ne.s32 	%p155, %r658, 0;
	xor.b32  	%r662, %r654, -2147483648;
	selp.b32 	%r663, %r662, %r654, %p155;
	selp.b32 	%r664, -1, 0, %p155;
	xor.b32  	%r665, %r657, %r664;
	shl.b32 	%r666, %r1365, 2;
	xor.b32  	%r667, %r666, %r664;
	cvt.u64.u32 	%rd221, %r665;
	cvt.u64.u32 	%rd222, %r667;
	bfi.b64 	%rd223, %rd221, %rd222, 32, 32;
	cvt.rn.f64.s64 	%fd535, %rd223;
	mul.rn.f64 	%fd536, %fd535, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f398, %fd536;
	setp.eq.s32 	%p156, %r663, 0;
	neg.f32 	%f399, %f398;
	selp.f32 	%f776, %f398, %f399, %p156;

$L__BB7_142:
	cvt.rn.f32.f64 	%f402, %fd51;
	cvt.f64.f32 	%fd92, %f402;
	and.b32  	%r131, %r1366, 1;
	setp.eq.s32 	%p157, %r131, 0;
	selp.f32 	%f84, %f776, 0f3F800000, %p157;
	mul.rn.f32 	%f85, %f776, %f776;
	mov.f32 	%f777, 0fB94D4153;
	@%p157 bra 	$L__BB7_144;

	mov.f32 	%f403, 0fBAB607ED;
	mov.f32 	%f404, 0f37CBAC00;
	fma.rn.f32 	%f777, %f404, %f85, %f403;

$L__BB7_144:
	selp.f32 	%f405, 0f3C0885E4, 0f3D2AAABB, %p157;
	fma.rn.f32 	%f406, %f777, %f85, %f405;
	selp.f32 	%f407, 0fBE2AAAA8, 0fBEFFFFFF, %p157;
	fma.rn.f32 	%f408, %f406, %f85, %f407;
	mov.f32 	%f409, 0f00000000;
	fma.rn.f32 	%f410, %f85, %f84, %f409;
	fma.rn.f32 	%f778, %f408, %f410, %f84;
	and.b32  	%r669, %r1366, 2;
	setp.eq.s32 	%p159, %r669, 0;
	@%p159 bra 	$L__BB7_146;

	mov.f32 	%f412, 0fBF800000;
	fma.rn.f32 	%f778, %f778, %f412, %f409;

$L__BB7_146:
	div.rn.f64 	%fd93, %fd26, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r670, %temp}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r671}, %fd93;
	}
	and.b32  	%r672, %r671, 2147483647;
	setp.eq.s32 	%p160, %r672, 2146435072;
	setp.eq.s32 	%p161, %r670, 0;
	and.pred  	%p162, %p161, %p160;
	@%p162 bra 	$L__BB7_149;
	bra.uni 	$L__BB7_147;

$L__BB7_149:
	mov.f64 	%fd546, 0d0000000000000000;
	mul.rn.f64 	%fd1095, %fd93, %fd546;
	mov.u32 	%r1367, 0;
	bra.uni 	$L__BB7_150;

$L__BB7_147:
	mul.rn.f64 	%fd537, %fd93, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1367, %fd537;
	st.local.u32 	[%rd8], %r1367;
	cvt.rn.f64.s32 	%fd538, %r1367;
	neg.f64 	%fd539, %fd538;
	mov.f64 	%fd540, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd541, %fd539, %fd540, %fd93;
	mov.f64 	%fd542, 0d3C91A62633145C00;
	fma.rn.f64 	%fd543, %fd539, %fd542, %fd541;
	mov.f64 	%fd544, 0d397B839A252049C0;
	fma.rn.f64 	%fd1095, %fd539, %fd544, %fd543;
	abs.f64 	%fd545, %fd93;
	setp.ltu.f64 	%p163, %fd545, 0d41E0000000000000;
	@%p163 bra 	$L__BB7_150;

	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd93;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1095, [retval0+0];
	} // callseq 79
	ld.local.u32 	%r1367, [%rd8];

$L__BB7_150:
	and.b32  	%r674, %r1367, 1;
	shl.b32 	%r675, %r1367, 3;
	and.b32  	%r676, %r675, 8;
	setp.eq.s32 	%p164, %r674, 0;
	selp.f64 	%fd547, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p164;
	mul.wide.s32 	%rd225, %r676, 8;
	add.s64 	%rd227, %rd186, %rd225;
	ld.global.nc.f64 	%fd548, [%rd227+8];
	mul.rn.f64 	%fd98, %fd1095, %fd1095;
	fma.rn.f64 	%fd549, %fd547, %fd98, %fd548;
	ld.global.nc.f64 	%fd550, [%rd227+16];
	fma.rn.f64 	%fd551, %fd549, %fd98, %fd550;
	ld.global.nc.f64 	%fd552, [%rd227+24];
	fma.rn.f64 	%fd553, %fd551, %fd98, %fd552;
	ld.global.nc.f64 	%fd554, [%rd227+32];
	fma.rn.f64 	%fd555, %fd553, %fd98, %fd554;
	ld.global.nc.f64 	%fd556, [%rd227+40];
	fma.rn.f64 	%fd557, %fd555, %fd98, %fd556;
	ld.global.nc.f64 	%fd558, [%rd227+48];
	fma.rn.f64 	%fd99, %fd557, %fd98, %fd558;
	fma.rn.f64 	%fd1097, %fd99, %fd1095, %fd1095;
	@%p164 bra 	$L__BB7_152;

	mov.f64 	%fd559, 0d3FF0000000000000;
	fma.rn.f64 	%fd1097, %fd99, %fd98, %fd559;

$L__BB7_152:
	and.b32  	%r677, %r1367, 2;
	setp.eq.s32 	%p165, %r677, 0;
	@%p165 bra 	$L__BB7_154;

	mov.f64 	%fd560, 0d0000000000000000;
	mov.f64 	%fd561, 0dBFF0000000000000;
	fma.rn.f64 	%fd1097, %fd1097, %fd561, %fd560;

$L__BB7_154:
	mul.rn.f64 	%fd562, %fd1097, 0d4044000000000000;
	cvt.f64.f32 	%fd563, %f778;
	mul.rn.f64 	%fd564, %fd563, 0d4034000000000000;
	add.rn.f64 	%fd105, %fd564, %fd562;
	div.rn.f64 	%fd106, %fd26, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r678, %temp}, %fd106;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r679}, %fd106;
	}
	and.b32  	%r680, %r679, 2147483647;
	setp.eq.s32 	%p166, %r680, 2146435072;
	setp.eq.s32 	%p167, %r678, 0;
	and.pred  	%p168, %p167, %p166;
	@%p168 bra 	$L__BB7_157;
	bra.uni 	$L__BB7_155;

$L__BB7_157:
	mov.f64 	%fd574, 0d0000000000000000;
	mul.rn.f64 	%fd1098, %fd106, %fd574;
	mov.u32 	%r1368, 0;
	bra.uni 	$L__BB7_158;

$L__BB7_155:
	mul.rn.f64 	%fd565, %fd106, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1368, %fd565;
	st.local.u32 	[%rd8], %r1368;
	cvt.rn.f64.s32 	%fd566, %r1368;
	neg.f64 	%fd567, %fd566;
	mov.f64 	%fd568, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd569, %fd567, %fd568, %fd106;
	mov.f64 	%fd570, 0d3C91A62633145C00;
	fma.rn.f64 	%fd571, %fd567, %fd570, %fd569;
	mov.f64 	%fd572, 0d397B839A252049C0;
	fma.rn.f64 	%fd1098, %fd567, %fd572, %fd571;
	abs.f64 	%fd573, %fd106;
	setp.ltu.f64 	%p169, %fd573, 0d41E0000000000000;
	@%p169 bra 	$L__BB7_158;

	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1098, [retval0+0];
	} // callseq 80
	ld.local.u32 	%r1368, [%rd8];

$L__BB7_158:
	and.b32  	%r682, %r1368, 1;
	shl.b32 	%r683, %r1368, 3;
	and.b32  	%r684, %r683, 8;
	setp.eq.s32 	%p170, %r682, 0;
	selp.f64 	%fd575, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p170;
	mul.wide.s32 	%rd229, %r684, 8;
	add.s64 	%rd231, %rd186, %rd229;
	ld.global.nc.f64 	%fd576, [%rd231+8];
	mul.rn.f64 	%fd111, %fd1098, %fd1098;
	fma.rn.f64 	%fd577, %fd575, %fd111, %fd576;
	ld.global.nc.f64 	%fd578, [%rd231+16];
	fma.rn.f64 	%fd579, %fd577, %fd111, %fd578;
	ld.global.nc.f64 	%fd580, [%rd231+24];
	fma.rn.f64 	%fd581, %fd579, %fd111, %fd580;
	ld.global.nc.f64 	%fd582, [%rd231+32];
	fma.rn.f64 	%fd583, %fd581, %fd111, %fd582;
	ld.global.nc.f64 	%fd584, [%rd231+40];
	fma.rn.f64 	%fd585, %fd583, %fd111, %fd584;
	ld.global.nc.f64 	%fd586, [%rd231+48];
	fma.rn.f64 	%fd112, %fd585, %fd111, %fd586;
	fma.rn.f64 	%fd1100, %fd112, %fd1098, %fd1098;
	@%p170 bra 	$L__BB7_160;

	mov.f64 	%fd587, 0d3FF0000000000000;
	fma.rn.f64 	%fd1100, %fd112, %fd111, %fd587;

$L__BB7_160:
	and.b32  	%r685, %r1368, 2;
	setp.eq.s32 	%p171, %r685, 0;
	@%p171 bra 	$L__BB7_162;

	mov.f64 	%fd588, 0d0000000000000000;
	mov.f64 	%fd589, 0dBFF0000000000000;
	fma.rn.f64 	%fd1100, %fd1100, %fd589, %fd588;

$L__BB7_162:
	mul.rn.f64 	%fd590, %fd1100, 0d4062C00000000000;
	add.rn.f64 	%fd118, %fd105, %fd590;
	div.rn.f64 	%fd119, %fd26, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r686, %temp}, %fd119;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r687}, %fd119;
	}
	and.b32  	%r688, %r687, 2147483647;
	setp.eq.s32 	%p172, %r688, 2146435072;
	setp.eq.s32 	%p173, %r686, 0;
	and.pred  	%p174, %p173, %p172;
	@%p174 bra 	$L__BB7_165;
	bra.uni 	$L__BB7_163;

$L__BB7_165:
	mov.f64 	%fd600, 0d0000000000000000;
	mul.rn.f64 	%fd1101, %fd119, %fd600;
	mov.u32 	%r1369, 0;
	bra.uni 	$L__BB7_166;

$L__BB7_163:
	mul.rn.f64 	%fd591, %fd119, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1369, %fd591;
	st.local.u32 	[%rd8], %r1369;
	cvt.rn.f64.s32 	%fd592, %r1369;
	neg.f64 	%fd593, %fd592;
	mov.f64 	%fd594, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd595, %fd593, %fd594, %fd119;
	mov.f64 	%fd596, 0d3C91A62633145C00;
	fma.rn.f64 	%fd597, %fd593, %fd596, %fd595;
	mov.f64 	%fd598, 0d397B839A252049C0;
	fma.rn.f64 	%fd1101, %fd593, %fd598, %fd597;
	abs.f64 	%fd599, %fd119;
	setp.ltu.f64 	%p175, %fd599, 0d41E0000000000000;
	@%p175 bra 	$L__BB7_166;

	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1101, [retval0+0];
	} // callseq 81
	ld.local.u32 	%r1369, [%rd8];

$L__BB7_166:
	and.b32  	%r690, %r1369, 1;
	shl.b32 	%r691, %r1369, 3;
	and.b32  	%r692, %r691, 8;
	setp.eq.s32 	%p176, %r690, 0;
	selp.f64 	%fd601, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p176;
	mul.wide.s32 	%rd233, %r692, 8;
	add.s64 	%rd235, %rd186, %rd233;
	ld.global.nc.f64 	%fd602, [%rd235+8];
	mul.rn.f64 	%fd124, %fd1101, %fd1101;
	fma.rn.f64 	%fd603, %fd601, %fd124, %fd602;
	ld.global.nc.f64 	%fd604, [%rd235+16];
	fma.rn.f64 	%fd605, %fd603, %fd124, %fd604;
	ld.global.nc.f64 	%fd606, [%rd235+24];
	fma.rn.f64 	%fd607, %fd605, %fd124, %fd606;
	ld.global.nc.f64 	%fd608, [%rd235+32];
	fma.rn.f64 	%fd609, %fd607, %fd124, %fd608;
	ld.global.nc.f64 	%fd610, [%rd235+40];
	fma.rn.f64 	%fd611, %fd609, %fd124, %fd610;
	ld.global.nc.f64 	%fd612, [%rd235+48];
	fma.rn.f64 	%fd125, %fd611, %fd124, %fd612;
	fma.rn.f64 	%fd1103, %fd125, %fd1101, %fd1101;
	@%p176 bra 	$L__BB7_168;

	mov.f64 	%fd613, 0d3FF0000000000000;
	fma.rn.f64 	%fd1103, %fd125, %fd124, %fd613;

$L__BB7_168:
	and.b32  	%r693, %r1369, 2;
	setp.eq.s32 	%p177, %r693, 0;
	@%p177 bra 	$L__BB7_170;

	mov.f64 	%fd614, 0d0000000000000000;
	mov.f64 	%fd615, 0dBFF0000000000000;
	fma.rn.f64 	%fd1103, %fd1103, %fd615, %fd614;

$L__BB7_170:
	mul.rn.f64 	%fd616, %fd1103, 0d4072C00000000000;
	add.rn.f64 	%fd617, %fd118, %fd616;
	add.rn.f64 	%fd131, %fd617, %fd92;
	add.rn.f64 	%fd132, %fd91, %fd92;
	add.rn.f64 	%fd618, %fd24, %fd24;
	add.rn.f64 	%fd619, %fd618, 0dC059000000000000;
	mul.rn.f64 	%fd620, %fd25, 0d4008000000000000;
	add.rn.f64 	%fd133, %fd619, %fd620;
	abs.f64 	%fd134, %fd25;
	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1106, [retval0+0];
	} // callseq 82
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd25;
	}
	setp.lt.s32 	%p178, %r141, 0;
	and.pred  	%p3, %p178, %p14;
	not.pred 	%p180, %p3;
	@%p180 bra 	$L__BB7_172;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r694}, %fd1106;
	}
	xor.b32  	%r695, %r694, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r696, %temp}, %fd1106;
	}
	mov.b64 	%fd1106, {%r696, %r695};

$L__BB7_172:
	add.rn.f32 	%f746, %f62, 0fC20C0000;
	setp.eq.f32 	%p181, %f746, 0f00000000;
	@%p181 bra 	$L__BB7_176;
	bra.uni 	$L__BB7_173;

$L__BB7_176:
	selp.b32 	%r697, %r141, 0, %p14;
	mov.u32 	%r698, 0;
	or.b32  	%r699, %r697, 2146435072;
	setp.lt.s32 	%p185, %r3, 0;
	selp.b32 	%r700, %r699, %r697, %p185;
	mov.b64 	%fd1106, {%r698, %r700};
	bra.uni 	$L__BB7_177;

$L__BB7_173:
	setp.gt.s32 	%p182, %r141, -1;
	@%p182 bra 	$L__BB7_177;

	mov.f64 	%fd621, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd622, %fd621;
	setp.eq.f64 	%p183, %fd622, 0d4000000000000000;
	@%p183 bra 	$L__BB7_177;

	mov.f64 	%fd1106, 0dFFF8000000000000;

$L__BB7_177:
	add.rn.f64 	%fd624, %fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r701}, %fd624;
	}
	and.b32  	%r702, %r701, 2146435072;
	setp.ne.s32 	%p186, %r702, 2146435072;
	@%p186 bra 	$L__BB7_184;

	setp.gtu.f64 	%p187, %fd134, 0d7FF0000000000000;
	@%p187 bra 	$L__BB7_183;
	bra.uni 	$L__BB7_179;

$L__BB7_183:
	mov.f64 	%fd626, 0d4000000000000000;
	add.rn.f64 	%fd1106, %fd25, %fd626;
	bra.uni 	$L__BB7_184;

$L__BB7_179:
	mov.f64 	%fd625, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r703, %temp}, %fd625;
	}
	and.b32  	%r142, %r3, 2147483647;
	setp.eq.s32 	%p188, %r142, 2146435072;
	setp.eq.s32 	%p189, %r703, 0;
	and.pred  	%p190, %p188, %p189;
	@%p190 bra 	$L__BB7_182;
	bra.uni 	$L__BB7_180;

$L__BB7_182:
	add.rn.f32 	%f752, %f62, 0fC20C0000;
	setp.gt.f64 	%p197, %fd134, 0d3FF0000000000000;
	selp.b32 	%r710, 2146435072, 0, %p197;
	mov.u32 	%r711, 0;
	xor.b32  	%r712, %r710, 2146435072;
	setp.lt.s32 	%p198, %r3, 0;
	selp.b32 	%r713, %r712, %r710, %p198;
	setp.eq.f32 	%p199, %f752, 0fBF800000;
	selp.b32 	%r714, 1072693248, %r713, %p199;
	mov.b64 	%fd1106, {%r711, %r714};
	bra.uni 	$L__BB7_184;

$L__BB7_180:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r704, %temp}, %fd25;
	}
	and.b32  	%r705, %r141, 2147483647;
	setp.ne.s32 	%p191, %r705, 2146435072;
	setp.ne.s32 	%p192, %r704, 0;
	or.pred  	%p193, %p191, %p192;
	@%p193 bra 	$L__BB7_184;

	setp.gt.s32 	%p194, %r3, -1;
	selp.b32 	%r706, 2146435072, 0, %p194;
	mov.u32 	%r707, 0;
	setp.ne.s32 	%p195, %r142, 1071644672;
	and.pred  	%p196, %p195, %p3;
	or.b32  	%r708, %r706, -2147483648;
	selp.b32 	%r709, %r708, %r706, %p196;
	mov.b64 	%fd1106, {%r707, %r709};

$L__BB7_184:
	add.rn.f32 	%f748, %f62, 0fC20C0000;
	add.rn.f32 	%f747, %f51, 0fC2D20000;
	mul.rn.f64 	%fd627, %fd1106, 0d3FC999999999999A;
	setp.eq.f32 	%p200, %f748, 0f3F800000;
	selp.f64 	%fd628, 0d3FC999999999999A, %fd627, %p200;
	add.rn.f64 	%fd629, %fd133, %fd628;
	mul.rn.f32 	%f413, %f747, %f748;
	cvt.f64.f32 	%fd630, %f413;
	mul.rn.f64 	%fd144, %fd630, 0d3FB999999999999A;
	add.rn.f64 	%fd631, %fd144, %fd629;
	abs.f32 	%f414, %f747;
	sqrt.rn.f32 	%f415, %f414;
	cvt.f64.f32 	%fd145, %f415;
	mul.rn.f64 	%fd632, %fd145, 0d3FC999999999999A;
	add.rn.f64 	%fd633, %fd632, %fd631;
	cvt.rn.f32.f64 	%f416, %fd132;
	cvt.f64.f32 	%fd634, %f416;
	mul.rn.f64 	%fd635, %fd634, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f417, %fd635;
	cvt.f64.f32 	%fd636, %f417;
	add.rn.f64 	%fd146, %fd633, %fd636;
	add.rn.f64 	%fd637, %fd25, %fd25;
	add.rn.f64 	%fd638, %fd24, 0d4072C00000000000;
	add.rn.f64 	%fd147, %fd638, %fd637;
	abs.f64 	%fd148, %fd24;
	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1109, [retval0+0];
	} // callseq 83
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r143}, %fd24;
	}
	setp.lt.s32 	%p201, %r143, 0;
	and.pred  	%p4, %p201, %p14;
	not.pred 	%p203, %p4;
	@%p203 bra 	$L__BB7_186;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r715}, %fd1109;
	}
	xor.b32  	%r716, %r715, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r717, %temp}, %fd1109;
	}
	mov.b64 	%fd1109, {%r717, %r716};

$L__BB7_186:
	add.rn.f32 	%f749, %f51, 0fC2D20000;
	setp.eq.f32 	%p204, %f749, 0f00000000;
	@%p204 bra 	$L__BB7_190;
	bra.uni 	$L__BB7_187;

$L__BB7_190:
	selp.b32 	%r718, %r143, 0, %p14;
	mov.u32 	%r719, 0;
	or.b32  	%r720, %r718, 2146435072;
	setp.lt.s32 	%p208, %r3, 0;
	selp.b32 	%r721, %r720, %r718, %p208;
	mov.b64 	%fd1109, {%r719, %r721};
	bra.uni 	$L__BB7_191;

$L__BB7_187:
	setp.gt.s32 	%p205, %r143, -1;
	@%p205 bra 	$L__BB7_191;

	mov.f64 	%fd639, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd640, %fd639;
	setp.eq.f64 	%p206, %fd640, 0d4000000000000000;
	@%p206 bra 	$L__BB7_191;

	mov.f64 	%fd1109, 0dFFF8000000000000;

$L__BB7_191:
	add.rn.f64 	%fd642, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r722}, %fd642;
	}
	and.b32  	%r723, %r722, 2146435072;
	setp.ne.s32 	%p209, %r723, 2146435072;
	@%p209 bra 	$L__BB7_198;

	setp.gtu.f64 	%p210, %fd148, 0d7FF0000000000000;
	@%p210 bra 	$L__BB7_197;
	bra.uni 	$L__BB7_193;

$L__BB7_197:
	mov.f64 	%fd644, 0d4000000000000000;
	add.rn.f64 	%fd1109, %fd24, %fd644;
	bra.uni 	$L__BB7_198;

$L__BB7_193:
	mov.f64 	%fd643, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r724, %temp}, %fd643;
	}
	and.b32  	%r144, %r3, 2147483647;
	setp.eq.s32 	%p211, %r144, 2146435072;
	setp.eq.s32 	%p212, %r724, 0;
	and.pred  	%p213, %p211, %p212;
	@%p213 bra 	$L__BB7_196;
	bra.uni 	$L__BB7_194;

$L__BB7_196:
	add.rn.f32 	%f751, %f51, 0fC2D20000;
	setp.gt.f64 	%p220, %fd148, 0d3FF0000000000000;
	selp.b32 	%r731, 2146435072, 0, %p220;
	mov.u32 	%r732, 0;
	xor.b32  	%r733, %r731, 2146435072;
	setp.lt.s32 	%p221, %r3, 0;
	selp.b32 	%r734, %r733, %r731, %p221;
	setp.eq.f32 	%p222, %f751, 0fBF800000;
	selp.b32 	%r735, 1072693248, %r734, %p222;
	mov.b64 	%fd1109, {%r732, %r735};
	bra.uni 	$L__BB7_198;

$L__BB7_194:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r725, %temp}, %fd24;
	}
	and.b32  	%r726, %r143, 2147483647;
	setp.ne.s32 	%p214, %r726, 2146435072;
	setp.ne.s32 	%p215, %r725, 0;
	or.pred  	%p216, %p214, %p215;
	@%p216 bra 	$L__BB7_198;

	setp.gt.s32 	%p217, %r3, -1;
	selp.b32 	%r727, 2146435072, 0, %p217;
	mov.u32 	%r728, 0;
	setp.ne.s32 	%p218, %r144, 1071644672;
	and.pred  	%p219, %p218, %p4;
	or.b32  	%r729, %r727, -2147483648;
	selp.b32 	%r730, %r729, %r727, %p219;
	mov.b64 	%fd1109, {%r728, %r730};

$L__BB7_198:
	add.rn.f32 	%f750, %f51, 0fC2D20000;
	mul.rn.f64 	%fd645, %fd1109, 0d3FB999999999999A;
	setp.eq.f32 	%p223, %f750, 0f3F800000;
	selp.f64 	%fd646, 0d3FB999999999999A, %fd645, %p223;
	add.rn.f64 	%fd647, %fd147, %fd646;
	add.rn.f64 	%fd648, %fd144, %fd647;
	mul.rn.f64 	%fd649, %fd145, 0d3FB999999999999A;
	add.rn.f64 	%fd650, %fd649, %fd648;
	cvt.rn.f32.f64 	%f418, %fd131;
	cvt.f64.f32 	%fd651, %f418;
	mul.rn.f64 	%fd652, %fd651, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f419, %fd652;
	cvt.f64.f32 	%fd653, %f419;
	add.rn.f64 	%fd158, %fd650, %fd653;
	cvt.f64.f32 	%fd654, %f62;
	div.rn.f64 	%fd655, %fd654, 0d4066800000000000;
	mul.rn.f64 	%fd656, %fd655, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f91, %fd656;
	mul.rn.f32 	%f420, %f91, 0f3F22F983;
	cvt.rni.s32.f32 	%r1377, %f420;
	cvt.rn.f32.s32 	%f421, %r1377;
	mov.f32 	%f422, 0fBFC90FDA;
	fma.rn.f32 	%f423, %f421, %f422, %f91;
	mov.f32 	%f424, 0fB3A22168;
	fma.rn.f32 	%f425, %f421, %f424, %f423;
	mov.f32 	%f426, 0fA7C234C5;
	fma.rn.f32 	%f782, %f421, %f426, %f425;
	abs.f32 	%f93, %f91;
	setp.ltu.f32 	%p224, %f93, 0f47CE4780;
	mov.u32 	%r1373, %r1377;
	mov.f32 	%f779, %f782;
	@%p224 bra 	$L__BB7_206;

	setp.eq.f32 	%p225, %f93, 0f7F800000;
	@%p225 bra 	$L__BB7_205;
	bra.uni 	$L__BB7_200;

$L__BB7_205:
	mov.f32 	%f429, 0f00000000;
	mul.rn.f32 	%f779, %f91, %f429;
	mov.u32 	%r1373, 0;
	bra.uni 	$L__BB7_206;

$L__BB7_200:
	mov.b32 	%r146, %f91;
	bfe.u32 	%r737, %r146, 23, 8;
	add.s32 	%r147, %r737, -128;
	shl.b32 	%r738, %r146, 8;
	or.b32  	%r148, %r738, -2147483648;
	shr.u32 	%r149, %r147, 5;
	mov.u64 	%rd463, 0;
	mov.u32 	%r1370, 0;
	mov.u64 	%rd462, __cudart_i2opi_f;
	mov.u64 	%rd461, %rd1;

$L__BB7_201:
	.pragma "nounroll";
	ld.global.nc.u32 	%r739, [%rd462];
	mad.wide.u32 	%rd238, %r739, %r148, %rd463;
	shr.u64 	%rd463, %rd238, 32;
	st.local.u32 	[%rd461], %rd238;
	add.s64 	%rd462, %rd462, 4;
	add.s64 	%rd461, %rd461, 4;
	add.s32 	%r1370, %r1370, 1;
	setp.ne.s32 	%p226, %r1370, 6;
	@%p226 bra 	$L__BB7_201;

	st.local.u32 	[%rd23], %rd463;
	mov.u32 	%r740, 4;
	sub.s32 	%r152, %r740, %r149;
	mov.u32 	%r741, 6;
	sub.s32 	%r742, %r741, %r149;
	mul.wide.s32 	%rd239, %r742, 4;
	add.s64 	%rd240, %rd1, %rd239;
	ld.local.u32 	%r1371, [%rd240];
	ld.local.u32 	%r1372, [%rd240+-4];
	and.b32  	%r155, %r147, 31;
	setp.eq.s32 	%p227, %r155, 0;
	@%p227 bra 	$L__BB7_204;

	mov.u32 	%r743, 32;
	sub.s32 	%r744, %r743, %r155;
	shr.u32 	%r745, %r1372, %r744;
	shl.b32 	%r746, %r1371, %r155;
	add.s32 	%r1371, %r745, %r746;
	mul.wide.s32 	%rd241, %r152, 4;
	add.s64 	%rd242, %rd1, %rd241;
	ld.local.u32 	%r747, [%rd242];
	shr.u32 	%r748, %r747, %r744;
	shl.b32 	%r749, %r1372, %r155;
	add.s32 	%r1372, %r748, %r749;

$L__BB7_204:
	and.b32  	%r750, %r146, -2147483648;
	shr.u32 	%r751, %r1372, 30;
	shl.b32 	%r752, %r1371, 2;
	or.b32  	%r753, %r751, %r752;
	shr.u32 	%r754, %r753, 31;
	shr.u32 	%r755, %r1371, 30;
	add.s32 	%r756, %r754, %r755;
	neg.s32 	%r757, %r756;
	setp.eq.s32 	%p228, %r750, 0;
	selp.b32 	%r1373, %r756, %r757, %p228;
	setp.ne.s32 	%p229, %r754, 0;
	xor.b32  	%r758, %r750, -2147483648;
	selp.b32 	%r759, %r758, %r750, %p229;
	selp.b32 	%r760, -1, 0, %p229;
	xor.b32  	%r761, %r753, %r760;
	shl.b32 	%r762, %r1372, 2;
	xor.b32  	%r763, %r762, %r760;
	cvt.u64.u32 	%rd243, %r761;
	cvt.u64.u32 	%rd244, %r763;
	bfi.b64 	%rd245, %rd243, %rd244, 32, 32;
	cvt.rn.f64.s64 	%fd657, %rd245;
	mul.rn.f64 	%fd658, %fd657, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f427, %fd658;
	setp.eq.s32 	%p230, %r759, 0;
	neg.f32 	%f428, %f427;
	selp.f32 	%f779, %f427, %f428, %p230;

$L__BB7_206:
	and.b32  	%r162, %r1373, 1;
	setp.eq.s32 	%p231, %r162, 0;
	selp.f32 	%f97, %f779, 0f3F800000, %p231;
	mul.rn.f32 	%f98, %f779, %f779;
	mov.f32 	%f780, 0fB94D4153;
	@%p231 bra 	$L__BB7_208;

	mov.f32 	%f431, 0fBAB607ED;
	mov.f32 	%f432, 0f37CBAC00;
	fma.rn.f32 	%f780, %f432, %f98, %f431;

$L__BB7_208:
	selp.f32 	%f433, 0f3C0885E4, 0f3D2AAABB, %p231;
	fma.rn.f32 	%f434, %f780, %f98, %f433;
	selp.f32 	%f435, 0fBE2AAAA8, 0fBEFFFFFF, %p231;
	fma.rn.f32 	%f436, %f434, %f98, %f435;
	mov.f32 	%f437, 0f00000000;
	fma.rn.f32 	%f438, %f98, %f97, %f437;
	fma.rn.f32 	%f781, %f436, %f438, %f97;
	and.b32  	%r765, %r1373, 2;
	setp.eq.s32 	%p233, %r765, 0;
	@%p233 bra 	$L__BB7_210;

	mov.f32 	%f440, 0fBF800000;
	fma.rn.f32 	%f781, %f781, %f440, %f437;

$L__BB7_210:
	@%p224 bra 	$L__BB7_218;

	setp.eq.f32 	%p235, %f93, 0f7F800000;
	@%p235 bra 	$L__BB7_217;
	bra.uni 	$L__BB7_212;

$L__BB7_217:
	mov.f32 	%f443, 0f00000000;
	mul.rn.f32 	%f782, %f91, %f443;
	mov.u32 	%r1377, 0;
	bra.uni 	$L__BB7_218;

$L__BB7_212:
	mov.b32 	%r163, %f91;
	bfe.u32 	%r767, %r163, 23, 8;
	add.s32 	%r164, %r767, -128;
	shl.b32 	%r768, %r163, 8;
	or.b32  	%r165, %r768, -2147483648;
	shr.u32 	%r166, %r164, 5;
	mov.u64 	%rd464, 0;
	mov.u32 	%r1374, 0;
	mov.u64 	%rd249, __cudart_i2opi_f;
	mov.u64 	%rd465, %rd464;

$L__BB7_213:
	.pragma "nounroll";
	shl.b64 	%rd248, %rd464, 2;
	add.s64 	%rd250, %rd249, %rd248;
	ld.global.nc.u32 	%r769, [%rd250];
	mad.wide.u32 	%rd251, %r769, %r165, %rd465;
	shr.u64 	%rd465, %rd251, 32;
	add.s64 	%rd252, %rd1, %rd248;
	st.local.u32 	[%rd252], %rd251;
	add.s32 	%r1374, %r1374, 1;
	cvt.s64.s32 	%rd464, %r1374;
	setp.ne.s32 	%p236, %r1374, 6;
	@%p236 bra 	$L__BB7_213;

	st.local.u32 	[%rd23], %rd465;
	mov.u32 	%r770, 4;
	sub.s32 	%r169, %r770, %r166;
	mov.u32 	%r771, 6;
	sub.s32 	%r772, %r771, %r166;
	mul.wide.s32 	%rd253, %r772, 4;
	add.s64 	%rd254, %rd1, %rd253;
	ld.local.u32 	%r1375, [%rd254];
	ld.local.u32 	%r1376, [%rd254+-4];
	and.b32  	%r172, %r164, 31;
	setp.eq.s32 	%p237, %r172, 0;
	@%p237 bra 	$L__BB7_216;

	mov.u32 	%r773, 32;
	sub.s32 	%r774, %r773, %r172;
	shr.u32 	%r775, %r1376, %r774;
	shl.b32 	%r776, %r1375, %r172;
	add.s32 	%r1375, %r775, %r776;
	mul.wide.s32 	%rd255, %r169, 4;
	add.s64 	%rd256, %rd1, %rd255;
	ld.local.u32 	%r777, [%rd256];
	shr.u32 	%r778, %r777, %r774;
	shl.b32 	%r779, %r1376, %r172;
	add.s32 	%r1376, %r778, %r779;

$L__BB7_216:
	and.b32  	%r780, %r163, -2147483648;
	shr.u32 	%r781, %r1376, 30;
	shl.b32 	%r782, %r1375, 2;
	or.b32  	%r783, %r781, %r782;
	shr.u32 	%r784, %r783, 31;
	shr.u32 	%r785, %r1375, 30;
	add.s32 	%r786, %r784, %r785;
	neg.s32 	%r787, %r786;
	setp.eq.s32 	%p238, %r780, 0;
	selp.b32 	%r1377, %r786, %r787, %p238;
	setp.ne.s32 	%p239, %r784, 0;
	xor.b32  	%r788, %r780, -2147483648;
	selp.b32 	%r789, %r788, %r780, %p239;
	selp.b32 	%r790, -1, 0, %p239;
	xor.b32  	%r791, %r783, %r790;
	shl.b32 	%r792, %r1376, 2;
	xor.b32  	%r793, %r792, %r790;
	cvt.u64.u32 	%rd257, %r791;
	cvt.u64.u32 	%rd258, %r793;
	bfi.b64 	%rd259, %rd257, %rd258, 32, 32;
	cvt.rn.f64.s64 	%fd659, %rd259;
	mul.rn.f64 	%fd660, %fd659, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f441, %fd660;
	setp.eq.s32 	%p240, %r789, 0;
	neg.f32 	%f442, %f441;
	selp.f32 	%f782, %f441, %f442, %p240;

$L__BB7_218:
	add.s32 	%r179, %r1377, 1;
	and.b32  	%r180, %r179, 1;
	setp.eq.s32 	%p5, %r180, 0;
	mul.rn.f32 	%f107, %f782, %f782;
	mov.f32 	%f783, 0fB94D4153;
	@%p5 bra 	$L__BB7_220;

	mov.f32 	%f445, 0fBAB607ED;
	mov.f32 	%f446, 0f37CBAC00;
	fma.rn.f32 	%f783, %f446, %f107, %f445;

$L__BB7_220:
	selp.f32 	%f447, %f782, 0f3F800000, %p5;
	selp.f32 	%f448, 0f3C0885E4, 0f3D2AAABB, %p5;
	fma.rn.f32 	%f449, %f783, %f107, %f448;
	selp.f32 	%f450, 0fBE2AAAA8, 0fBEFFFFFF, %p5;
	fma.rn.f32 	%f451, %f449, %f107, %f450;
	mov.f32 	%f452, 0f00000000;
	fma.rn.f32 	%f453, %f107, %f447, %f452;
	fma.rn.f32 	%f784, %f451, %f453, %f447;
	and.b32  	%r795, %r179, 2;
	setp.eq.s32 	%p242, %r795, 0;
	@%p242 bra 	$L__BB7_222;

	mov.f32 	%f455, 0fBF800000;
	fma.rn.f32 	%f784, %f784, %f455, %f452;

$L__BB7_222:
	ld.param.u32 	%r1337, [bd09_to_wgs84_exact_cuda_float_param_5];
	cvt.f64.f32 	%fd661, %f781;
	mul.rn.f64 	%fd662, %fd661, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd663, %fd662, %fd661;
	add.rn.f64 	%fd664, %fd663, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f456, %fd664;
	sqrt.rn.f32 	%f457, %f456;
	mov.f32 	%f458, 0fCAC2A60A;
	div.rn.f32 	%f459, %f458, %f457;
	mul.rn.f32 	%f460, %f459, %f784;
	cvt.f64.f32 	%fd665, %f460;
	mul.rn.f64 	%fd666, %fd665, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f461, %fd158;
	cvt.f64.f32 	%fd667, %f461;
	mul.rn.f64 	%fd668, %fd667, 0d4066800000000000;
	div.rn.f64 	%fd669, %fd668, %fd666;
	cvt.rn.f32.f64 	%f462, %fd669;
	add.rn.f32 	%f819, %f51, %f462;
	mul.rn.f32 	%f463, %f457, %f456;
	cvt.f64.f32 	%fd670, %f463;
	mov.f64 	%fd671, 0dC1582B102DE355C1;
	div.rn.f64 	%fd672, %fd671, %fd670;
	mul.rn.f64 	%fd673, %fd672, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f464, %fd146;
	cvt.f64.f32 	%fd674, %f464;
	mul.rn.f64 	%fd675, %fd674, 0d4066800000000000;
	div.rn.f64 	%fd676, %fd675, %fd673;
	cvt.rn.f32.f64 	%f465, %fd676;
	add.rn.f32 	%f820, %f62, %f465;
	setp.lt.s32 	%p243, %r1337, 1;
	@%p243 bra 	$L__BB7_523;

	and.b32  	%r181, %r3, 2147483647;
	setp.gt.s32 	%p244, %r3, -1;
	selp.b32 	%r182, 2146435072, 0, %p244;
	mov.u32 	%r1378, 0;
	or.b32  	%r183, %r182, -2147483648;
	mov.u64 	%rd268, __cudart_i2opi_f;
	mov.f32 	%f785, %f820;
	mov.f32 	%f786, %f819;

$L__BB7_224:
	mov.f32 	%f819, %f786;
	mov.f32 	%f820, %f785;
	add.rn.f32 	%f117, %f820, 0fC20C0000;
	add.rn.f32 	%f118, %f819, 0fC2D20000;
	cvt.f64.f32 	%fd159, %f118;
	mul.rn.f64 	%fd677, %fd159, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f119, %fd677;
	cvt.f64.f32 	%fd160, %f117;
	mul.rn.f64 	%fd678, %fd160, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f120, %fd678;
	cvt.f64.f32 	%fd161, %f119;
	mul.rn.f64 	%fd162, %fd161, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r797, %temp}, %fd162;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r798}, %fd162;
	}
	and.b32  	%r799, %r798, 2147483647;
	setp.eq.s32 	%p245, %r799, 2146435072;
	setp.eq.s32 	%p246, %r797, 0;
	and.pred  	%p247, %p246, %p245;
	@%p247 bra 	$L__BB7_227;
	bra.uni 	$L__BB7_225;

$L__BB7_227:
	mov.f64 	%fd688, 0d0000000000000000;
	mul.rn.f64 	%fd1110, %fd162, %fd688;
	mov.u32 	%r1379, 0;
	bra.uni 	$L__BB7_228;

$L__BB7_225:
	mul.rn.f64 	%fd679, %fd162, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1379, %fd679;
	st.local.u32 	[%rd8], %r1379;
	cvt.rn.f64.s32 	%fd680, %r1379;
	neg.f64 	%fd681, %fd680;
	mov.f64 	%fd682, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd683, %fd681, %fd682, %fd162;
	mov.f64 	%fd684, 0d3C91A62633145C00;
	fma.rn.f64 	%fd685, %fd681, %fd684, %fd683;
	mov.f64 	%fd686, 0d397B839A252049C0;
	fma.rn.f64 	%fd1110, %fd681, %fd686, %fd685;
	abs.f64 	%fd687, %fd162;
	setp.ltu.f64 	%p248, %fd687, 0d41E0000000000000;
	@%p248 bra 	$L__BB7_228;

	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd162;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1110, [retval0+0];
	} // callseq 84
	ld.local.u32 	%r1379, [%rd8];

$L__BB7_228:
	and.b32  	%r801, %r1379, 1;
	shl.b32 	%r802, %r1379, 3;
	and.b32  	%r803, %r802, 8;
	setp.eq.s32 	%p249, %r801, 0;
	selp.f64 	%fd689, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p249;
	mul.wide.s32 	%rd261, %r803, 8;
	add.s64 	%rd263, %rd186, %rd261;
	ld.global.nc.f64 	%fd690, [%rd263+8];
	mul.rn.f64 	%fd167, %fd1110, %fd1110;
	fma.rn.f64 	%fd691, %fd689, %fd167, %fd690;
	ld.global.nc.f64 	%fd692, [%rd263+16];
	fma.rn.f64 	%fd693, %fd691, %fd167, %fd692;
	ld.global.nc.f64 	%fd694, [%rd263+24];
	fma.rn.f64 	%fd695, %fd693, %fd167, %fd694;
	ld.global.nc.f64 	%fd696, [%rd263+32];
	fma.rn.f64 	%fd697, %fd695, %fd167, %fd696;
	ld.global.nc.f64 	%fd698, [%rd263+40];
	fma.rn.f64 	%fd699, %fd697, %fd167, %fd698;
	ld.global.nc.f64 	%fd700, [%rd263+48];
	fma.rn.f64 	%fd168, %fd699, %fd167, %fd700;
	fma.rn.f64 	%fd1112, %fd168, %fd1110, %fd1110;
	@%p249 bra 	$L__BB7_230;

	mov.f64 	%fd701, 0d3FF0000000000000;
	fma.rn.f64 	%fd1112, %fd168, %fd167, %fd701;

$L__BB7_230:
	and.b32  	%r804, %r1379, 2;
	setp.eq.s32 	%p250, %r804, 0;
	@%p250 bra 	$L__BB7_232;

	mov.f64 	%fd702, 0d0000000000000000;
	mov.f64 	%fd703, 0dBFF0000000000000;
	fma.rn.f64 	%fd1112, %fd1112, %fd703, %fd702;

$L__BB7_232:
	add.rn.f64 	%fd174, %fd161, %fd161;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r805, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r806}, %fd174;
	}
	and.b32  	%r807, %r806, 2147483647;
	setp.eq.s32 	%p251, %r807, 2146435072;
	setp.eq.s32 	%p252, %r805, 0;
	and.pred  	%p253, %p252, %p251;
	@%p253 bra 	$L__BB7_235;
	bra.uni 	$L__BB7_233;

$L__BB7_235:
	mov.f64 	%fd713, 0d0000000000000000;
	mul.rn.f64 	%fd1113, %fd174, %fd713;
	mov.u32 	%r1380, 0;
	bra.uni 	$L__BB7_236;

$L__BB7_233:
	mul.rn.f64 	%fd704, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1380, %fd704;
	st.local.u32 	[%rd8], %r1380;
	cvt.rn.f64.s32 	%fd705, %r1380;
	neg.f64 	%fd706, %fd705;
	mov.f64 	%fd707, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd708, %fd706, %fd707, %fd174;
	mov.f64 	%fd709, 0d3C91A62633145C00;
	fma.rn.f64 	%fd710, %fd706, %fd709, %fd708;
	mov.f64 	%fd711, 0d397B839A252049C0;
	fma.rn.f64 	%fd1113, %fd706, %fd711, %fd710;
	abs.f64 	%fd712, %fd174;
	setp.ltu.f64 	%p254, %fd712, 0d41E0000000000000;
	@%p254 bra 	$L__BB7_236;

	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1113, [retval0+0];
	} // callseq 85
	ld.local.u32 	%r1380, [%rd8];

$L__BB7_236:
	and.b32  	%r809, %r1380, 1;
	shl.b32 	%r810, %r1380, 3;
	and.b32  	%r811, %r810, 8;
	setp.eq.s32 	%p255, %r809, 0;
	selp.f64 	%fd714, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p255;
	mul.wide.s32 	%rd265, %r811, 8;
	add.s64 	%rd267, %rd186, %rd265;
	ld.global.nc.f64 	%fd715, [%rd267+8];
	mul.rn.f64 	%fd179, %fd1113, %fd1113;
	fma.rn.f64 	%fd716, %fd714, %fd179, %fd715;
	ld.global.nc.f64 	%fd717, [%rd267+16];
	fma.rn.f64 	%fd718, %fd716, %fd179, %fd717;
	ld.global.nc.f64 	%fd719, [%rd267+24];
	fma.rn.f64 	%fd720, %fd718, %fd179, %fd719;
	ld.global.nc.f64 	%fd721, [%rd267+32];
	fma.rn.f64 	%fd722, %fd720, %fd179, %fd721;
	ld.global.nc.f64 	%fd723, [%rd267+40];
	fma.rn.f64 	%fd724, %fd722, %fd179, %fd723;
	ld.global.nc.f64 	%fd725, [%rd267+48];
	fma.rn.f64 	%fd180, %fd724, %fd179, %fd725;
	fma.rn.f64 	%fd1115, %fd180, %fd1113, %fd1113;
	@%p255 bra 	$L__BB7_238;

	mov.f64 	%fd726, 0d3FF0000000000000;
	fma.rn.f64 	%fd1115, %fd180, %fd179, %fd726;

$L__BB7_238:
	and.b32  	%r812, %r1380, 2;
	setp.eq.s32 	%p256, %r812, 0;
	@%p256 bra 	$L__BB7_240;

	mov.f64 	%fd727, 0d0000000000000000;
	mov.f64 	%fd728, 0dBFF0000000000000;
	fma.rn.f64 	%fd1115, %fd1115, %fd728, %fd727;

$L__BB7_240:
	mul.rn.f64 	%fd729, %fd1115, 0d4034000000000000;
	mul.rn.f64 	%fd730, %fd1112, 0d4034000000000000;
	add.rn.f64 	%fd186, %fd730, %fd729;
	mul.rn.f32 	%f466, %f120, 0f3F22F983;
	cvt.rni.s32.f32 	%r1384, %f466;
	cvt.rn.f32.s32 	%f467, %r1384;
	mov.f32 	%f468, 0fBFC90FDA;
	fma.rn.f32 	%f469, %f467, %f468, %f120;
	mov.f32 	%f470, 0fB3A22168;
	fma.rn.f32 	%f471, %f467, %f470, %f469;
	mov.f32 	%f472, 0fA7C234C5;
	fma.rn.f32 	%f787, %f467, %f472, %f471;
	abs.f32 	%f122, %f120;
	setp.ltu.f32 	%p257, %f122, 0f47CE4780;
	@%p257 bra 	$L__BB7_248;

	setp.eq.f32 	%p258, %f122, 0f7F800000;
	@%p258 bra 	$L__BB7_247;
	bra.uni 	$L__BB7_242;

$L__BB7_247:
	mov.f32 	%f475, 0f00000000;
	mul.rn.f32 	%f787, %f120, %f475;
	mov.u32 	%r1384, 0;
	bra.uni 	$L__BB7_248;

$L__BB7_242:
	mov.b32 	%r192, %f120;
	bfe.u32 	%r814, %r192, 23, 8;
	add.s32 	%r193, %r814, -128;
	shl.b32 	%r815, %r192, 8;
	or.b32  	%r194, %r815, -2147483648;
	shr.u32 	%r195, %r193, 5;
	mov.u64 	%rd468, 0;
	mov.u32 	%r1381, 0;
	mov.u64 	%rd466, %rd1;
	mov.u64 	%rd467, %rd268;

$L__BB7_243:
	.pragma "nounroll";
	ld.global.nc.u32 	%r816, [%rd467];
	mad.wide.u32 	%rd270, %r816, %r194, %rd468;
	shr.u64 	%rd468, %rd270, 32;
	st.local.u32 	[%rd466], %rd270;
	add.s64 	%rd467, %rd467, 4;
	add.s64 	%rd466, %rd466, 4;
	add.s32 	%r1381, %r1381, 1;
	setp.ne.s32 	%p259, %r1381, 6;
	@%p259 bra 	$L__BB7_243;

	st.local.u32 	[%rd23], %rd468;
	mov.u32 	%r817, 4;
	sub.s32 	%r198, %r817, %r195;
	mov.u32 	%r818, 6;
	sub.s32 	%r819, %r818, %r195;
	mul.wide.s32 	%rd271, %r819, 4;
	add.s64 	%rd272, %rd1, %rd271;
	ld.local.u32 	%r1382, [%rd272];
	ld.local.u32 	%r1383, [%rd272+-4];
	and.b32  	%r201, %r193, 31;
	setp.eq.s32 	%p260, %r201, 0;
	@%p260 bra 	$L__BB7_246;

	mov.u32 	%r820, 32;
	sub.s32 	%r821, %r820, %r201;
	shr.u32 	%r822, %r1383, %r821;
	shl.b32 	%r823, %r1382, %r201;
	add.s32 	%r1382, %r822, %r823;
	mul.wide.s32 	%rd273, %r198, 4;
	add.s64 	%rd274, %rd1, %rd273;
	ld.local.u32 	%r824, [%rd274];
	shr.u32 	%r825, %r824, %r821;
	shl.b32 	%r826, %r1383, %r201;
	add.s32 	%r1383, %r825, %r826;

$L__BB7_246:
	and.b32  	%r827, %r192, -2147483648;
	shr.u32 	%r828, %r1383, 30;
	shl.b32 	%r829, %r1382, 2;
	or.b32  	%r830, %r828, %r829;
	shr.u32 	%r831, %r830, 31;
	shr.u32 	%r832, %r1382, 30;
	add.s32 	%r833, %r831, %r832;
	neg.s32 	%r834, %r833;
	setp.eq.s32 	%p261, %r827, 0;
	selp.b32 	%r1384, %r833, %r834, %p261;
	setp.ne.s32 	%p262, %r831, 0;
	xor.b32  	%r835, %r827, -2147483648;
	selp.b32 	%r836, %r835, %r827, %p262;
	selp.b32 	%r837, -1, 0, %p262;
	xor.b32  	%r838, %r830, %r837;
	shl.b32 	%r839, %r1383, 2;
	xor.b32  	%r840, %r839, %r837;
	cvt.u64.u32 	%rd275, %r838;
	cvt.u64.u32 	%rd276, %r840;
	bfi.b64 	%rd277, %rd275, %rd276, 32, 32;
	cvt.rn.f64.s64 	%fd731, %rd277;
	mul.rn.f64 	%fd732, %fd731, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f473, %fd732;
	setp.eq.s32 	%p263, %r836, 0;
	neg.f32 	%f474, %f473;
	selp.f32 	%f787, %f473, %f474, %p263;

$L__BB7_248:
	and.b32  	%r208, %r1384, 1;
	setp.eq.s32 	%p264, %r208, 0;
	selp.f32 	%f126, %f787, 0f3F800000, %p264;
	mul.rn.f32 	%f127, %f787, %f787;
	mov.f32 	%f788, 0fB94D4153;
	@%p264 bra 	$L__BB7_250;

	mov.f32 	%f477, 0fBAB607ED;
	mov.f32 	%f478, 0f37CBAC00;
	fma.rn.f32 	%f788, %f478, %f127, %f477;

$L__BB7_250:
	selp.f32 	%f479, 0f3C0885E4, 0f3D2AAABB, %p264;
	fma.rn.f32 	%f480, %f788, %f127, %f479;
	selp.f32 	%f481, 0fBE2AAAA8, 0fBEFFFFFF, %p264;
	fma.rn.f32 	%f482, %f480, %f127, %f481;
	mov.f32 	%f483, 0f00000000;
	fma.rn.f32 	%f484, %f127, %f126, %f483;
	fma.rn.f32 	%f789, %f482, %f484, %f126;
	and.b32  	%r842, %r1384, 2;
	setp.eq.s32 	%p266, %r842, 0;
	@%p266 bra 	$L__BB7_252;

	mov.f32 	%f486, 0fBF800000;
	fma.rn.f32 	%f789, %f789, %f486, %f483;

$L__BB7_252:
	cvt.f64.f32 	%fd187, %f120;
	div.rn.f64 	%fd188, %fd187, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r843, %temp}, %fd188;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r844}, %fd188;
	}
	and.b32  	%r845, %r844, 2147483647;
	setp.eq.s32 	%p267, %r845, 2146435072;
	setp.eq.s32 	%p268, %r843, 0;
	and.pred  	%p269, %p268, %p267;
	@%p269 bra 	$L__BB7_255;
	bra.uni 	$L__BB7_253;

$L__BB7_255:
	mov.f64 	%fd742, 0d0000000000000000;
	mul.rn.f64 	%fd1116, %fd188, %fd742;
	mov.u32 	%r1385, 0;
	bra.uni 	$L__BB7_256;

$L__BB7_253:
	mul.rn.f64 	%fd733, %fd188, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1385, %fd733;
	st.local.u32 	[%rd1], %r1385;
	cvt.rn.f64.s32 	%fd734, %r1385;
	neg.f64 	%fd735, %fd734;
	mov.f64 	%fd736, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd737, %fd735, %fd736, %fd188;
	mov.f64 	%fd738, 0d3C91A62633145C00;
	fma.rn.f64 	%fd739, %fd735, %fd738, %fd737;
	mov.f64 	%fd740, 0d397B839A252049C0;
	fma.rn.f64 	%fd1116, %fd735, %fd740, %fd739;
	abs.f64 	%fd741, %fd188;
	setp.ltu.f64 	%p270, %fd741, 0d41E0000000000000;
	@%p270 bra 	$L__BB7_256;

	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd188;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1116, [retval0+0];
	} // callseq 86
	ld.local.u32 	%r1385, [%rd1];

$L__BB7_256:
	and.b32  	%r847, %r1385, 1;
	shl.b32 	%r848, %r1385, 3;
	and.b32  	%r849, %r848, 8;
	setp.eq.s32 	%p271, %r847, 0;
	selp.f64 	%fd743, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p271;
	mul.wide.s32 	%rd279, %r849, 8;
	add.s64 	%rd281, %rd186, %rd279;
	ld.global.nc.f64 	%fd744, [%rd281+8];
	mul.rn.f64 	%fd193, %fd1116, %fd1116;
	fma.rn.f64 	%fd745, %fd743, %fd193, %fd744;
	ld.global.nc.f64 	%fd746, [%rd281+16];
	fma.rn.f64 	%fd747, %fd745, %fd193, %fd746;
	ld.global.nc.f64 	%fd748, [%rd281+24];
	fma.rn.f64 	%fd749, %fd747, %fd193, %fd748;
	ld.global.nc.f64 	%fd750, [%rd281+32];
	fma.rn.f64 	%fd751, %fd749, %fd193, %fd750;
	ld.global.nc.f64 	%fd752, [%rd281+40];
	fma.rn.f64 	%fd753, %fd751, %fd193, %fd752;
	ld.global.nc.f64 	%fd754, [%rd281+48];
	fma.rn.f64 	%fd194, %fd753, %fd193, %fd754;
	fma.rn.f64 	%fd1118, %fd194, %fd1116, %fd1116;
	@%p271 bra 	$L__BB7_258;

	mov.f64 	%fd755, 0d3FF0000000000000;
	fma.rn.f64 	%fd1118, %fd194, %fd193, %fd755;

$L__BB7_258:
	and.b32  	%r850, %r1385, 2;
	setp.eq.s32 	%p272, %r850, 0;
	@%p272 bra 	$L__BB7_260;

	mov.f64 	%fd756, 0d0000000000000000;
	mov.f64 	%fd757, 0dBFF0000000000000;
	fma.rn.f64 	%fd1118, %fd1118, %fd757, %fd756;

$L__BB7_260:
	mul.rn.f64 	%fd758, %fd1118, 0d4044000000000000;
	cvt.f64.f32 	%fd759, %f789;
	mul.rn.f64 	%fd760, %fd759, 0d4034000000000000;
	add.rn.f64 	%fd200, %fd760, %fd758;
	div.rn.f64 	%fd201, %fd187, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r851, %temp}, %fd201;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r852}, %fd201;
	}
	and.b32  	%r853, %r852, 2147483647;
	setp.eq.s32 	%p273, %r853, 2146435072;
	setp.eq.s32 	%p274, %r851, 0;
	and.pred  	%p275, %p274, %p273;
	@%p275 bra 	$L__BB7_263;
	bra.uni 	$L__BB7_261;

$L__BB7_263:
	mov.f64 	%fd770, 0d0000000000000000;
	mul.rn.f64 	%fd1119, %fd201, %fd770;
	mov.u32 	%r1386, 0;
	bra.uni 	$L__BB7_264;

$L__BB7_261:
	mul.rn.f64 	%fd761, %fd201, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1386, %fd761;
	st.local.u32 	[%rd1], %r1386;
	cvt.rn.f64.s32 	%fd762, %r1386;
	neg.f64 	%fd763, %fd762;
	mov.f64 	%fd764, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd765, %fd763, %fd764, %fd201;
	mov.f64 	%fd766, 0d3C91A62633145C00;
	fma.rn.f64 	%fd767, %fd763, %fd766, %fd765;
	mov.f64 	%fd768, 0d397B839A252049C0;
	fma.rn.f64 	%fd1119, %fd763, %fd768, %fd767;
	abs.f64 	%fd769, %fd201;
	setp.ltu.f64 	%p276, %fd769, 0d41E0000000000000;
	@%p276 bra 	$L__BB7_264;

	{ // callseq 87, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd201;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1119, [retval0+0];
	} // callseq 87
	ld.local.u32 	%r1386, [%rd1];

$L__BB7_264:
	and.b32  	%r855, %r1386, 1;
	shl.b32 	%r856, %r1386, 3;
	and.b32  	%r857, %r856, 8;
	setp.eq.s32 	%p277, %r855, 0;
	selp.f64 	%fd771, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p277;
	mul.wide.s32 	%rd283, %r857, 8;
	add.s64 	%rd285, %rd186, %rd283;
	ld.global.nc.f64 	%fd772, [%rd285+8];
	mul.rn.f64 	%fd206, %fd1119, %fd1119;
	fma.rn.f64 	%fd773, %fd771, %fd206, %fd772;
	ld.global.nc.f64 	%fd774, [%rd285+16];
	fma.rn.f64 	%fd775, %fd773, %fd206, %fd774;
	ld.global.nc.f64 	%fd776, [%rd285+24];
	fma.rn.f64 	%fd777, %fd775, %fd206, %fd776;
	ld.global.nc.f64 	%fd778, [%rd285+32];
	fma.rn.f64 	%fd779, %fd777, %fd206, %fd778;
	ld.global.nc.f64 	%fd780, [%rd285+40];
	fma.rn.f64 	%fd781, %fd779, %fd206, %fd780;
	ld.global.nc.f64 	%fd782, [%rd285+48];
	fma.rn.f64 	%fd207, %fd781, %fd206, %fd782;
	fma.rn.f64 	%fd1121, %fd207, %fd1119, %fd1119;
	@%p277 bra 	$L__BB7_266;

	mov.f64 	%fd783, 0d3FF0000000000000;
	fma.rn.f64 	%fd1121, %fd207, %fd206, %fd783;

$L__BB7_266:
	and.b32  	%r858, %r1386, 2;
	setp.eq.s32 	%p278, %r858, 0;
	@%p278 bra 	$L__BB7_268;

	mov.f64 	%fd784, 0d0000000000000000;
	mov.f64 	%fd785, 0dBFF0000000000000;
	fma.rn.f64 	%fd1121, %fd1121, %fd785, %fd784;

$L__BB7_268:
	mul.rn.f64 	%fd786, %fd1121, 0d4064000000000000;
	add.rn.f64 	%fd213, %fd200, %fd786;
	div.rn.f64 	%fd214, %fd187, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r859, %temp}, %fd214;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r860}, %fd214;
	}
	and.b32  	%r861, %r860, 2147483647;
	setp.eq.s32 	%p279, %r861, 2146435072;
	setp.eq.s32 	%p280, %r859, 0;
	and.pred  	%p281, %p280, %p279;
	@%p281 bra 	$L__BB7_271;
	bra.uni 	$L__BB7_269;

$L__BB7_271:
	mov.f64 	%fd796, 0d0000000000000000;
	mul.rn.f64 	%fd1122, %fd214, %fd796;
	mov.u32 	%r1387, 0;
	bra.uni 	$L__BB7_272;

$L__BB7_269:
	mul.rn.f64 	%fd787, %fd214, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1387, %fd787;
	st.local.u32 	[%rd1], %r1387;
	cvt.rn.f64.s32 	%fd788, %r1387;
	neg.f64 	%fd789, %fd788;
	mov.f64 	%fd790, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd791, %fd789, %fd790, %fd214;
	mov.f64 	%fd792, 0d3C91A62633145C00;
	fma.rn.f64 	%fd793, %fd789, %fd792, %fd791;
	mov.f64 	%fd794, 0d397B839A252049C0;
	fma.rn.f64 	%fd1122, %fd789, %fd794, %fd793;
	abs.f64 	%fd795, %fd214;
	setp.ltu.f64 	%p282, %fd795, 0d41E0000000000000;
	@%p282 bra 	$L__BB7_272;

	{ // callseq 88, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd214;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1122, [retval0+0];
	} // callseq 88
	ld.local.u32 	%r1387, [%rd1];

$L__BB7_272:
	and.b32  	%r863, %r1387, 1;
	shl.b32 	%r864, %r1387, 3;
	and.b32  	%r865, %r864, 8;
	setp.eq.s32 	%p283, %r863, 0;
	selp.f64 	%fd797, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p283;
	mul.wide.s32 	%rd287, %r865, 8;
	add.s64 	%rd289, %rd186, %rd287;
	ld.global.nc.f64 	%fd798, [%rd289+8];
	mul.rn.f64 	%fd219, %fd1122, %fd1122;
	fma.rn.f64 	%fd799, %fd797, %fd219, %fd798;
	ld.global.nc.f64 	%fd800, [%rd289+16];
	fma.rn.f64 	%fd801, %fd799, %fd219, %fd800;
	ld.global.nc.f64 	%fd802, [%rd289+24];
	fma.rn.f64 	%fd803, %fd801, %fd219, %fd802;
	ld.global.nc.f64 	%fd804, [%rd289+32];
	fma.rn.f64 	%fd805, %fd803, %fd219, %fd804;
	ld.global.nc.f64 	%fd806, [%rd289+40];
	fma.rn.f64 	%fd807, %fd805, %fd219, %fd806;
	ld.global.nc.f64 	%fd808, [%rd289+48];
	fma.rn.f64 	%fd220, %fd807, %fd219, %fd808;
	fma.rn.f64 	%fd1124, %fd220, %fd1122, %fd1122;
	@%p283 bra 	$L__BB7_274;

	mov.f64 	%fd809, 0d3FF0000000000000;
	fma.rn.f64 	%fd1124, %fd220, %fd219, %fd809;

$L__BB7_274:
	and.b32  	%r866, %r1387, 2;
	setp.eq.s32 	%p284, %r866, 0;
	@%p284 bra 	$L__BB7_276;

	mov.f64 	%fd810, 0d0000000000000000;
	mov.f64 	%fd811, 0dBFF0000000000000;
	fma.rn.f64 	%fd1124, %fd1124, %fd811, %fd810;

$L__BB7_276:
	mul.rn.f64 	%fd812, %fd1124, 0d4074000000000000;
	add.rn.f64 	%fd226, %fd213, %fd812;
	mul.rn.f32 	%f487, %f119, 0f3F22F983;
	cvt.rni.s32.f32 	%r1390, %f487;
	cvt.rn.f32.s32 	%f488, %r1390;
	mov.f32 	%f489, 0fBFC90FDA;
	fma.rn.f32 	%f490, %f488, %f489, %f119;
	mov.f32 	%f491, 0fB3A22168;
	fma.rn.f32 	%f492, %f488, %f491, %f490;
	mov.f32 	%f493, 0fA7C234C5;
	fma.rn.f32 	%f790, %f488, %f493, %f492;
	abs.f32 	%f134, %f119;
	setp.ltu.f32 	%p285, %f134, 0f47CE4780;
	@%p285 bra 	$L__BB7_284;

	setp.eq.f32 	%p286, %f134, 0f7F800000;
	@%p286 bra 	$L__BB7_283;
	bra.uni 	$L__BB7_278;

$L__BB7_283:
	mov.f32 	%f496, 0f00000000;
	mul.rn.f32 	%f790, %f119, %f496;
	mov.u32 	%r1390, 0;
	bra.uni 	$L__BB7_284;

$L__BB7_278:
	mov.b32 	%r219, %f119;
	bfe.u32 	%r867, %r219, 23, 8;
	add.s32 	%r220, %r867, -128;
	shl.b32 	%r868, %r219, 8;
	or.b32  	%r221, %r868, -2147483648;
	shr.u32 	%r222, %r220, 5;
	mov.u64 	%rd469, 0;
	mov.u64 	%rd470, %rd469;

$L__BB7_279:
	.pragma "nounroll";
	shl.b64 	%rd292, %rd469, 2;
	mov.u64 	%rd293, __cudart_i2opi_f;
	add.s64 	%rd294, %rd293, %rd292;
	ld.global.nc.u32 	%r869, [%rd294];
	mad.wide.u32 	%rd295, %r869, %r221, %rd470;
	shr.u64 	%rd470, %rd295, 32;
	add.s64 	%rd296, %rd1, %rd292;
	st.local.u32 	[%rd296], %rd295;
	cvt.u32.u64 	%r870, %rd469;
	add.s32 	%r871, %r870, 1;
	cvt.s64.s32 	%rd469, %r871;
	setp.ne.s32 	%p287, %r871, 6;
	@%p287 bra 	$L__BB7_279;

	st.local.u32 	[%rd23], %rd470;
	mov.u32 	%r872, 4;
	sub.s32 	%r223, %r872, %r222;
	mov.u32 	%r873, 6;
	sub.s32 	%r874, %r873, %r222;
	mul.wide.s32 	%rd297, %r874, 4;
	add.s64 	%rd298, %rd1, %rd297;
	ld.local.u32 	%r1388, [%rd298];
	ld.local.u32 	%r1389, [%rd298+-4];
	and.b32  	%r226, %r220, 31;
	setp.eq.s32 	%p288, %r226, 0;
	@%p288 bra 	$L__BB7_282;

	mov.u32 	%r875, 32;
	sub.s32 	%r876, %r875, %r226;
	shr.u32 	%r877, %r1389, %r876;
	shl.b32 	%r878, %r1388, %r226;
	add.s32 	%r1388, %r877, %r878;
	mul.wide.s32 	%rd299, %r223, 4;
	add.s64 	%rd300, %rd1, %rd299;
	ld.local.u32 	%r879, [%rd300];
	shr.u32 	%r880, %r879, %r876;
	shl.b32 	%r881, %r1389, %r226;
	add.s32 	%r1389, %r880, %r881;

$L__BB7_282:
	and.b32  	%r882, %r219, -2147483648;
	shr.u32 	%r883, %r1389, 30;
	shl.b32 	%r884, %r1388, 2;
	or.b32  	%r885, %r883, %r884;
	shr.u32 	%r886, %r885, 31;
	shr.u32 	%r887, %r1388, 30;
	add.s32 	%r888, %r886, %r887;
	neg.s32 	%r889, %r888;
	setp.eq.s32 	%p289, %r882, 0;
	selp.b32 	%r1390, %r888, %r889, %p289;
	setp.ne.s32 	%p290, %r886, 0;
	xor.b32  	%r890, %r882, -2147483648;
	selp.b32 	%r891, %r890, %r882, %p290;
	selp.b32 	%r892, -1, 0, %p290;
	xor.b32  	%r893, %r885, %r892;
	shl.b32 	%r894, %r1389, 2;
	xor.b32  	%r895, %r894, %r892;
	cvt.u64.u32 	%rd301, %r893;
	cvt.u64.u32 	%rd302, %r895;
	bfi.b64 	%rd303, %rd301, %rd302, 32, 32;
	cvt.rn.f64.s64 	%fd813, %rd303;
	mul.rn.f64 	%fd814, %fd813, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f494, %fd814;
	setp.eq.s32 	%p291, %r891, 0;
	neg.f32 	%f495, %f494;
	selp.f32 	%f790, %f494, %f495, %p291;

$L__BB7_284:
	cvt.rn.f32.f64 	%f498, %fd186;
	cvt.f64.f32 	%fd227, %f498;
	and.b32  	%r233, %r1390, 1;
	setp.eq.s32 	%p292, %r233, 0;
	selp.f32 	%f138, %f790, 0f3F800000, %p292;
	mul.rn.f32 	%f139, %f790, %f790;
	mov.f32 	%f791, 0fB94D4153;
	@%p292 bra 	$L__BB7_286;

	mov.f32 	%f499, 0fBAB607ED;
	mov.f32 	%f500, 0f37CBAC00;
	fma.rn.f32 	%f791, %f500, %f139, %f499;

$L__BB7_286:
	selp.f32 	%f501, 0f3C0885E4, 0f3D2AAABB, %p292;
	fma.rn.f32 	%f502, %f791, %f139, %f501;
	selp.f32 	%f503, 0fBE2AAAA8, 0fBEFFFFFF, %p292;
	fma.rn.f32 	%f504, %f502, %f139, %f503;
	mov.f32 	%f505, 0f00000000;
	fma.rn.f32 	%f506, %f139, %f138, %f505;
	fma.rn.f32 	%f792, %f504, %f506, %f138;
	and.b32  	%r897, %r1390, 2;
	setp.eq.s32 	%p294, %r897, 0;
	@%p294 bra 	$L__BB7_288;

	mov.f32 	%f508, 0fBF800000;
	fma.rn.f32 	%f792, %f792, %f508, %f505;

$L__BB7_288:
	div.rn.f64 	%fd228, %fd161, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r898, %temp}, %fd228;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r899}, %fd228;
	}
	and.b32  	%r900, %r899, 2147483647;
	setp.eq.s32 	%p295, %r900, 2146435072;
	setp.eq.s32 	%p296, %r898, 0;
	and.pred  	%p297, %p296, %p295;
	@%p297 bra 	$L__BB7_291;
	bra.uni 	$L__BB7_289;

$L__BB7_291:
	mov.f64 	%fd824, 0d0000000000000000;
	mul.rn.f64 	%fd1125, %fd228, %fd824;
	mov.u32 	%r1391, 0;
	bra.uni 	$L__BB7_292;

$L__BB7_289:
	mul.rn.f64 	%fd815, %fd228, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1391, %fd815;
	st.local.u32 	[%rd1], %r1391;
	cvt.rn.f64.s32 	%fd816, %r1391;
	neg.f64 	%fd817, %fd816;
	mov.f64 	%fd818, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd819, %fd817, %fd818, %fd228;
	mov.f64 	%fd820, 0d3C91A62633145C00;
	fma.rn.f64 	%fd821, %fd817, %fd820, %fd819;
	mov.f64 	%fd822, 0d397B839A252049C0;
	fma.rn.f64 	%fd1125, %fd817, %fd822, %fd821;
	abs.f64 	%fd823, %fd228;
	setp.ltu.f64 	%p298, %fd823, 0d41E0000000000000;
	@%p298 bra 	$L__BB7_292;

	{ // callseq 89, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd228;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1125, [retval0+0];
	} // callseq 89
	ld.local.u32 	%r1391, [%rd1];

$L__BB7_292:
	and.b32  	%r902, %r1391, 1;
	shl.b32 	%r903, %r1391, 3;
	and.b32  	%r904, %r903, 8;
	setp.eq.s32 	%p299, %r902, 0;
	selp.f64 	%fd825, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p299;
	mul.wide.s32 	%rd305, %r904, 8;
	add.s64 	%rd307, %rd186, %rd305;
	ld.global.nc.f64 	%fd826, [%rd307+8];
	mul.rn.f64 	%fd233, %fd1125, %fd1125;
	fma.rn.f64 	%fd827, %fd825, %fd233, %fd826;
	ld.global.nc.f64 	%fd828, [%rd307+16];
	fma.rn.f64 	%fd829, %fd827, %fd233, %fd828;
	ld.global.nc.f64 	%fd830, [%rd307+24];
	fma.rn.f64 	%fd831, %fd829, %fd233, %fd830;
	ld.global.nc.f64 	%fd832, [%rd307+32];
	fma.rn.f64 	%fd833, %fd831, %fd233, %fd832;
	ld.global.nc.f64 	%fd834, [%rd307+40];
	fma.rn.f64 	%fd835, %fd833, %fd233, %fd834;
	ld.global.nc.f64 	%fd836, [%rd307+48];
	fma.rn.f64 	%fd234, %fd835, %fd233, %fd836;
	fma.rn.f64 	%fd1127, %fd234, %fd1125, %fd1125;
	@%p299 bra 	$L__BB7_294;

	mov.f64 	%fd837, 0d3FF0000000000000;
	fma.rn.f64 	%fd1127, %fd234, %fd233, %fd837;

$L__BB7_294:
	and.b32  	%r905, %r1391, 2;
	setp.eq.s32 	%p300, %r905, 0;
	@%p300 bra 	$L__BB7_296;

	mov.f64 	%fd838, 0d0000000000000000;
	mov.f64 	%fd839, 0dBFF0000000000000;
	fma.rn.f64 	%fd1127, %fd1127, %fd839, %fd838;

$L__BB7_296:
	mul.rn.f64 	%fd840, %fd1127, 0d4044000000000000;
	cvt.f64.f32 	%fd841, %f792;
	mul.rn.f64 	%fd842, %fd841, 0d4034000000000000;
	add.rn.f64 	%fd240, %fd842, %fd840;
	div.rn.f64 	%fd241, %fd161, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r906, %temp}, %fd241;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r907}, %fd241;
	}
	and.b32  	%r908, %r907, 2147483647;
	setp.eq.s32 	%p301, %r908, 2146435072;
	setp.eq.s32 	%p302, %r906, 0;
	and.pred  	%p303, %p302, %p301;
	@%p303 bra 	$L__BB7_299;
	bra.uni 	$L__BB7_297;

$L__BB7_299:
	mov.f64 	%fd852, 0d0000000000000000;
	mul.rn.f64 	%fd1128, %fd241, %fd852;
	mov.u32 	%r1392, 0;
	bra.uni 	$L__BB7_300;

$L__BB7_297:
	mul.rn.f64 	%fd843, %fd241, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1392, %fd843;
	st.local.u32 	[%rd1], %r1392;
	cvt.rn.f64.s32 	%fd844, %r1392;
	neg.f64 	%fd845, %fd844;
	mov.f64 	%fd846, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd847, %fd845, %fd846, %fd241;
	mov.f64 	%fd848, 0d3C91A62633145C00;
	fma.rn.f64 	%fd849, %fd845, %fd848, %fd847;
	mov.f64 	%fd850, 0d397B839A252049C0;
	fma.rn.f64 	%fd1128, %fd845, %fd850, %fd849;
	abs.f64 	%fd851, %fd241;
	setp.ltu.f64 	%p304, %fd851, 0d41E0000000000000;
	@%p304 bra 	$L__BB7_300;

	{ // callseq 90, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd241;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1128, [retval0+0];
	} // callseq 90
	ld.local.u32 	%r1392, [%rd1];

$L__BB7_300:
	and.b32  	%r910, %r1392, 1;
	shl.b32 	%r911, %r1392, 3;
	and.b32  	%r912, %r911, 8;
	setp.eq.s32 	%p305, %r910, 0;
	selp.f64 	%fd853, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p305;
	mul.wide.s32 	%rd309, %r912, 8;
	add.s64 	%rd311, %rd186, %rd309;
	ld.global.nc.f64 	%fd854, [%rd311+8];
	mul.rn.f64 	%fd246, %fd1128, %fd1128;
	fma.rn.f64 	%fd855, %fd853, %fd246, %fd854;
	ld.global.nc.f64 	%fd856, [%rd311+16];
	fma.rn.f64 	%fd857, %fd855, %fd246, %fd856;
	ld.global.nc.f64 	%fd858, [%rd311+24];
	fma.rn.f64 	%fd859, %fd857, %fd246, %fd858;
	ld.global.nc.f64 	%fd860, [%rd311+32];
	fma.rn.f64 	%fd861, %fd859, %fd246, %fd860;
	ld.global.nc.f64 	%fd862, [%rd311+40];
	fma.rn.f64 	%fd863, %fd861, %fd246, %fd862;
	ld.global.nc.f64 	%fd864, [%rd311+48];
	fma.rn.f64 	%fd247, %fd863, %fd246, %fd864;
	fma.rn.f64 	%fd1130, %fd247, %fd1128, %fd1128;
	@%p305 bra 	$L__BB7_302;

	mov.f64 	%fd865, 0d3FF0000000000000;
	fma.rn.f64 	%fd1130, %fd247, %fd246, %fd865;

$L__BB7_302:
	and.b32  	%r913, %r1392, 2;
	setp.eq.s32 	%p306, %r913, 0;
	@%p306 bra 	$L__BB7_304;

	mov.f64 	%fd866, 0d0000000000000000;
	mov.f64 	%fd867, 0dBFF0000000000000;
	fma.rn.f64 	%fd1130, %fd1130, %fd867, %fd866;

$L__BB7_304:
	mul.rn.f64 	%fd868, %fd1130, 0d4062C00000000000;
	add.rn.f64 	%fd253, %fd240, %fd868;
	div.rn.f64 	%fd254, %fd161, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r914, %temp}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r915}, %fd254;
	}
	and.b32  	%r916, %r915, 2147483647;
	setp.eq.s32 	%p307, %r916, 2146435072;
	setp.eq.s32 	%p308, %r914, 0;
	and.pred  	%p309, %p308, %p307;
	@%p309 bra 	$L__BB7_307;
	bra.uni 	$L__BB7_305;

$L__BB7_307:
	mov.f64 	%fd878, 0d0000000000000000;
	mul.rn.f64 	%fd1131, %fd254, %fd878;
	mov.u32 	%r1393, 0;
	bra.uni 	$L__BB7_308;

$L__BB7_305:
	mul.rn.f64 	%fd869, %fd254, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1393, %fd869;
	st.local.u32 	[%rd1], %r1393;
	cvt.rn.f64.s32 	%fd870, %r1393;
	neg.f64 	%fd871, %fd870;
	mov.f64 	%fd872, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd873, %fd871, %fd872, %fd254;
	mov.f64 	%fd874, 0d3C91A62633145C00;
	fma.rn.f64 	%fd875, %fd871, %fd874, %fd873;
	mov.f64 	%fd876, 0d397B839A252049C0;
	fma.rn.f64 	%fd1131, %fd871, %fd876, %fd875;
	abs.f64 	%fd877, %fd254;
	setp.ltu.f64 	%p310, %fd877, 0d41E0000000000000;
	@%p310 bra 	$L__BB7_308;

	{ // callseq 91, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd254;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1131, [retval0+0];
	} // callseq 91
	ld.local.u32 	%r1393, [%rd1];

$L__BB7_308:
	and.b32  	%r918, %r1393, 1;
	shl.b32 	%r919, %r1393, 3;
	and.b32  	%r920, %r919, 8;
	setp.eq.s32 	%p311, %r918, 0;
	selp.f64 	%fd879, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p311;
	mul.wide.s32 	%rd313, %r920, 8;
	add.s64 	%rd315, %rd186, %rd313;
	ld.global.nc.f64 	%fd880, [%rd315+8];
	mul.rn.f64 	%fd259, %fd1131, %fd1131;
	fma.rn.f64 	%fd881, %fd879, %fd259, %fd880;
	ld.global.nc.f64 	%fd882, [%rd315+16];
	fma.rn.f64 	%fd883, %fd881, %fd259, %fd882;
	ld.global.nc.f64 	%fd884, [%rd315+24];
	fma.rn.f64 	%fd885, %fd883, %fd259, %fd884;
	ld.global.nc.f64 	%fd886, [%rd315+32];
	fma.rn.f64 	%fd887, %fd885, %fd259, %fd886;
	ld.global.nc.f64 	%fd888, [%rd315+40];
	fma.rn.f64 	%fd889, %fd887, %fd259, %fd888;
	ld.global.nc.f64 	%fd890, [%rd315+48];
	fma.rn.f64 	%fd260, %fd889, %fd259, %fd890;
	fma.rn.f64 	%fd1133, %fd260, %fd1131, %fd1131;
	@%p311 bra 	$L__BB7_310;

	mov.f64 	%fd891, 0d3FF0000000000000;
	fma.rn.f64 	%fd1133, %fd260, %fd259, %fd891;

$L__BB7_310:
	and.b32  	%r921, %r1393, 2;
	setp.eq.s32 	%p312, %r921, 0;
	@%p312 bra 	$L__BB7_312;

	mov.f64 	%fd892, 0d0000000000000000;
	mov.f64 	%fd893, 0dBFF0000000000000;
	fma.rn.f64 	%fd1133, %fd1133, %fd893, %fd892;

$L__BB7_312:
	mul.rn.f64 	%fd894, %fd1133, 0d4072C00000000000;
	add.rn.f64 	%fd895, %fd253, %fd894;
	add.rn.f64 	%fd266, %fd895, %fd227;
	add.rn.f64 	%fd267, %fd226, %fd227;
	add.rn.f64 	%fd896, %fd159, %fd159;
	add.rn.f64 	%fd897, %fd896, 0dC059000000000000;
	mul.rn.f64 	%fd898, %fd160, 0d4008000000000000;
	add.rn.f64 	%fd268, %fd897, %fd898;
	abs.f64 	%fd269, %fd160;
	{ // callseq 92, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd269;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1136, [retval0+0];
	} // callseq 92
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r243}, %fd160;
	}
	setp.lt.s32 	%p313, %r243, 0;
	and.pred  	%p6, %p313, %p14;
	not.pred 	%p315, %p6;
	@%p315 bra 	$L__BB7_314;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r922}, %fd1136;
	}
	xor.b32  	%r923, %r922, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r924, %temp}, %fd1136;
	}
	mov.b64 	%fd1136, {%r924, %r923};

$L__BB7_314:
	add.rn.f32 	%f753, %f820, 0fC20C0000;
	setp.eq.f32 	%p316, %f753, 0f00000000;
	@%p316 bra 	$L__BB7_318;
	bra.uni 	$L__BB7_315;

$L__BB7_318:
	setp.lt.s32 	%p319, %r3, 0;
	mov.u32 	%r925, 0;
	selp.b32 	%r926, %r243, 0, %p14;
	or.b32  	%r927, %r926, 2146435072;
	selp.b32 	%r928, %r927, %r926, %p319;
	mov.b64 	%fd1136, {%r925, %r928};
	bra.uni 	$L__BB7_319;

$L__BB7_315:
	setp.gt.s32 	%p317, %r243, -1;
	@%p317 bra 	$L__BB7_319;

	mov.f64 	%fd899, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd900, %fd899;
	setp.eq.f64 	%p318, %fd900, 0d4000000000000000;
	@%p318 bra 	$L__BB7_319;

	mov.f64 	%fd1136, 0dFFF8000000000000;

$L__BB7_319:
	add.rn.f64 	%fd902, %fd160, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r929}, %fd902;
	}
	and.b32  	%r930, %r929, 2146435072;
	setp.ne.s32 	%p321, %r930, 2146435072;
	@%p321 bra 	$L__BB7_326;

	setp.gtu.f64 	%p322, %fd269, 0d7FF0000000000000;
	@%p322 bra 	$L__BB7_325;
	bra.uni 	$L__BB7_321;

$L__BB7_325:
	mov.f64 	%fd904, 0d4000000000000000;
	add.rn.f64 	%fd1136, %fd160, %fd904;
	bra.uni 	$L__BB7_326;

$L__BB7_321:
	setp.eq.s32 	%p323, %r181, 2146435072;
	mov.f64 	%fd903, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r931, %temp}, %fd903;
	}
	setp.eq.s32 	%p324, %r931, 0;
	and.pred  	%p325, %p323, %p324;
	@%p325 bra 	$L__BB7_324;
	bra.uni 	$L__BB7_322;

$L__BB7_324:
	add.rn.f32 	%f759, %f820, 0fC20C0000;
	setp.lt.s32 	%p331, %r3, 0;
	mov.u32 	%r936, 0;
	setp.gt.f64 	%p332, %fd269, 0d3FF0000000000000;
	selp.b32 	%r937, 2146435072, 0, %p332;
	xor.b32  	%r938, %r937, 2146435072;
	selp.b32 	%r939, %r938, %r937, %p331;
	setp.eq.f32 	%p333, %f759, 0fBF800000;
	selp.b32 	%r940, 1072693248, %r939, %p333;
	mov.b64 	%fd1136, {%r936, %r940};
	bra.uni 	$L__BB7_326;

$L__BB7_322:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r932, %temp}, %fd160;
	}
	and.b32  	%r933, %r243, 2147483647;
	setp.ne.s32 	%p326, %r933, 2146435072;
	setp.ne.s32 	%p327, %r932, 0;
	or.pred  	%p328, %p326, %p327;
	@%p328 bra 	$L__BB7_326;

	setp.ne.s32 	%p329, %r181, 1071644672;
	and.pred  	%p330, %p329, %p6;
	selp.b32 	%r934, %r183, %r182, %p330;
	mov.u32 	%r935, 0;
	mov.b64 	%fd1136, {%r935, %r934};

$L__BB7_326:
	add.rn.f32 	%f755, %f819, 0fC2D20000;
	add.rn.f32 	%f754, %f820, 0fC20C0000;
	mul.rn.f64 	%fd905, %fd1136, 0d3FC999999999999A;
	setp.eq.f32 	%p334, %f754, 0f3F800000;
	selp.f64 	%fd906, 0d3FC999999999999A, %fd905, %p334;
	add.rn.f64 	%fd907, %fd268, %fd906;
	mul.rn.f32 	%f509, %f755, %f754;
	cvt.f64.f32 	%fd908, %f509;
	mul.rn.f64 	%fd279, %fd908, 0d3FB999999999999A;
	add.rn.f64 	%fd909, %fd279, %fd907;
	abs.f32 	%f510, %f755;
	sqrt.rn.f32 	%f511, %f510;
	cvt.f64.f32 	%fd280, %f511;
	mul.rn.f64 	%fd910, %fd280, 0d3FC999999999999A;
	add.rn.f64 	%fd911, %fd910, %fd909;
	cvt.rn.f32.f64 	%f512, %fd267;
	cvt.f64.f32 	%fd912, %f512;
	mul.rn.f64 	%fd913, %fd912, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f513, %fd913;
	cvt.f64.f32 	%fd914, %f513;
	add.rn.f64 	%fd281, %fd911, %fd914;
	add.rn.f64 	%fd915, %fd160, %fd160;
	add.rn.f64 	%fd916, %fd159, 0d4072C00000000000;
	add.rn.f64 	%fd282, %fd916, %fd915;
	abs.f64 	%fd283, %fd159;
	{ // callseq 93, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd283;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1139, [retval0+0];
	} // callseq 93
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r244}, %fd159;
	}
	setp.lt.s32 	%p335, %r244, 0;
	and.pred  	%p7, %p335, %p14;
	not.pred 	%p337, %p7;
	@%p337 bra 	$L__BB7_328;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r941}, %fd1139;
	}
	xor.b32  	%r942, %r941, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r943, %temp}, %fd1139;
	}
	mov.b64 	%fd1139, {%r943, %r942};

$L__BB7_328:
	add.rn.f32 	%f756, %f819, 0fC2D20000;
	setp.eq.f32 	%p338, %f756, 0f00000000;
	@%p338 bra 	$L__BB7_332;
	bra.uni 	$L__BB7_329;

$L__BB7_332:
	setp.lt.s32 	%p341, %r3, 0;
	mov.u32 	%r944, 0;
	selp.b32 	%r945, %r244, 0, %p14;
	or.b32  	%r946, %r945, 2146435072;
	selp.b32 	%r947, %r946, %r945, %p341;
	mov.b64 	%fd1139, {%r944, %r947};
	bra.uni 	$L__BB7_333;

$L__BB7_329:
	setp.gt.s32 	%p339, %r244, -1;
	@%p339 bra 	$L__BB7_333;

	mov.f64 	%fd917, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd918, %fd917;
	setp.eq.f64 	%p340, %fd918, 0d4000000000000000;
	@%p340 bra 	$L__BB7_333;

	mov.f64 	%fd1139, 0dFFF8000000000000;

$L__BB7_333:
	add.rn.f64 	%fd920, %fd159, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r948}, %fd920;
	}
	and.b32  	%r949, %r948, 2146435072;
	setp.ne.s32 	%p343, %r949, 2146435072;
	@%p343 bra 	$L__BB7_340;

	setp.gtu.f64 	%p344, %fd283, 0d7FF0000000000000;
	@%p344 bra 	$L__BB7_339;
	bra.uni 	$L__BB7_335;

$L__BB7_339:
	mov.f64 	%fd922, 0d4000000000000000;
	add.rn.f64 	%fd1139, %fd159, %fd922;
	bra.uni 	$L__BB7_340;

$L__BB7_335:
	setp.eq.s32 	%p345, %r181, 2146435072;
	mov.f64 	%fd921, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r950, %temp}, %fd921;
	}
	setp.eq.s32 	%p346, %r950, 0;
	and.pred  	%p347, %p345, %p346;
	@%p347 bra 	$L__BB7_338;
	bra.uni 	$L__BB7_336;

$L__BB7_338:
	add.rn.f32 	%f758, %f819, 0fC2D20000;
	setp.lt.s32 	%p353, %r3, 0;
	mov.u32 	%r955, 0;
	setp.gt.f64 	%p354, %fd283, 0d3FF0000000000000;
	selp.b32 	%r956, 2146435072, 0, %p354;
	xor.b32  	%r957, %r956, 2146435072;
	selp.b32 	%r958, %r957, %r956, %p353;
	setp.eq.f32 	%p355, %f758, 0fBF800000;
	selp.b32 	%r959, 1072693248, %r958, %p355;
	mov.b64 	%fd1139, {%r955, %r959};
	bra.uni 	$L__BB7_340;

$L__BB7_336:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r951, %temp}, %fd159;
	}
	and.b32  	%r952, %r244, 2147483647;
	setp.ne.s32 	%p348, %r952, 2146435072;
	setp.ne.s32 	%p349, %r951, 0;
	or.pred  	%p350, %p348, %p349;
	@%p350 bra 	$L__BB7_340;

	setp.ne.s32 	%p351, %r181, 1071644672;
	and.pred  	%p352, %p351, %p7;
	selp.b32 	%r953, %r183, %r182, %p352;
	mov.u32 	%r954, 0;
	mov.b64 	%fd1139, {%r954, %r953};

$L__BB7_340:
	add.rn.f32 	%f757, %f819, 0fC2D20000;
	mul.rn.f64 	%fd923, %fd1139, 0d3FB999999999999A;
	setp.eq.f32 	%p356, %f757, 0f3F800000;
	selp.f64 	%fd924, 0d3FB999999999999A, %fd923, %p356;
	add.rn.f64 	%fd925, %fd282, %fd924;
	add.rn.f64 	%fd926, %fd279, %fd925;
	mul.rn.f64 	%fd927, %fd280, 0d3FB999999999999A;
	add.rn.f64 	%fd928, %fd927, %fd926;
	cvt.rn.f32.f64 	%f514, %fd266;
	cvt.f64.f32 	%fd929, %f514;
	mul.rn.f64 	%fd930, %fd929, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f515, %fd930;
	cvt.f64.f32 	%fd931, %f515;
	add.rn.f64 	%fd293, %fd928, %fd931;
	cvt.f64.f32 	%fd294, %f820;
	div.rn.f64 	%fd932, %fd294, 0d4066800000000000;
	mul.rn.f64 	%fd933, %fd932, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f145, %fd933;
	mul.rn.f32 	%f516, %f145, 0f3F22F983;
	cvt.rni.s32.f32 	%r1399, %f516;
	cvt.rn.f32.s32 	%f517, %r1399;
	mov.f32 	%f518, 0fBFC90FDA;
	fma.rn.f32 	%f519, %f517, %f518, %f145;
	mov.f32 	%f520, 0fB3A22168;
	fma.rn.f32 	%f521, %f517, %f520, %f519;
	mov.f32 	%f522, 0fA7C234C5;
	fma.rn.f32 	%f796, %f517, %f522, %f521;
	abs.f32 	%f147, %f145;
	setp.ltu.f32 	%p357, %f147, 0f47CE4780;
	mov.u32 	%r1396, %r1399;
	mov.f32 	%f793, %f796;
	@%p357 bra 	$L__BB7_348;

	setp.eq.f32 	%p358, %f147, 0f7F800000;
	@%p358 bra 	$L__BB7_347;
	bra.uni 	$L__BB7_342;

$L__BB7_347:
	mov.f32 	%f525, 0f00000000;
	mul.rn.f32 	%f793, %f145, %f525;
	mov.u32 	%r1396, 0;
	bra.uni 	$L__BB7_348;

$L__BB7_342:
	mov.b32 	%r246, %f145;
	bfe.u32 	%r960, %r246, 23, 8;
	add.s32 	%r247, %r960, -128;
	shl.b32 	%r961, %r246, 8;
	or.b32  	%r248, %r961, -2147483648;
	shr.u32 	%r249, %r247, 5;
	mov.u64 	%rd471, 0;
	mov.u64 	%rd472, %rd471;

$L__BB7_343:
	.pragma "nounroll";
	shl.b64 	%rd318, %rd471, 2;
	mov.u64 	%rd319, __cudart_i2opi_f;
	add.s64 	%rd320, %rd319, %rd318;
	ld.global.nc.u32 	%r962, [%rd320];
	mad.wide.u32 	%rd321, %r962, %r248, %rd472;
	shr.u64 	%rd472, %rd321, 32;
	add.s64 	%rd322, %rd1, %rd318;
	st.local.u32 	[%rd322], %rd321;
	cvt.u32.u64 	%r963, %rd471;
	add.s32 	%r964, %r963, 1;
	cvt.s64.s32 	%rd471, %r964;
	setp.ne.s32 	%p359, %r964, 6;
	@%p359 bra 	$L__BB7_343;

	st.local.u32 	[%rd23], %rd472;
	mov.u32 	%r965, 4;
	sub.s32 	%r250, %r965, %r249;
	mov.u32 	%r966, 6;
	sub.s32 	%r967, %r966, %r249;
	mul.wide.s32 	%rd323, %r967, 4;
	add.s64 	%rd324, %rd1, %rd323;
	ld.local.u32 	%r1394, [%rd324];
	ld.local.u32 	%r1395, [%rd324+-4];
	and.b32  	%r253, %r247, 31;
	setp.eq.s32 	%p360, %r253, 0;
	@%p360 bra 	$L__BB7_346;

	mov.u32 	%r968, 32;
	sub.s32 	%r969, %r968, %r253;
	shr.u32 	%r970, %r1395, %r969;
	shl.b32 	%r971, %r1394, %r253;
	add.s32 	%r1394, %r970, %r971;
	mul.wide.s32 	%rd325, %r250, 4;
	add.s64 	%rd326, %rd1, %rd325;
	ld.local.u32 	%r972, [%rd326];
	shr.u32 	%r973, %r972, %r969;
	shl.b32 	%r974, %r1395, %r253;
	add.s32 	%r1395, %r973, %r974;

$L__BB7_346:
	and.b32  	%r975, %r246, -2147483648;
	shr.u32 	%r976, %r1395, 30;
	shl.b32 	%r977, %r1394, 2;
	or.b32  	%r978, %r976, %r977;
	shr.u32 	%r979, %r978, 31;
	shr.u32 	%r980, %r1394, 30;
	add.s32 	%r981, %r979, %r980;
	neg.s32 	%r982, %r981;
	setp.eq.s32 	%p361, %r975, 0;
	selp.b32 	%r1396, %r981, %r982, %p361;
	setp.ne.s32 	%p362, %r979, 0;
	xor.b32  	%r983, %r975, -2147483648;
	selp.b32 	%r984, %r983, %r975, %p362;
	selp.b32 	%r985, -1, 0, %p362;
	xor.b32  	%r986, %r978, %r985;
	shl.b32 	%r987, %r1395, 2;
	xor.b32  	%r988, %r987, %r985;
	cvt.u64.u32 	%rd327, %r986;
	cvt.u64.u32 	%rd328, %r988;
	bfi.b64 	%rd329, %rd327, %rd328, 32, 32;
	cvt.rn.f64.s64 	%fd934, %rd329;
	mul.rn.f64 	%fd935, %fd934, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f523, %fd935;
	setp.eq.s32 	%p363, %r984, 0;
	neg.f32 	%f524, %f523;
	selp.f32 	%f793, %f523, %f524, %p363;

$L__BB7_348:
	and.b32  	%r260, %r1396, 1;
	setp.eq.s32 	%p364, %r260, 0;
	selp.f32 	%f151, %f793, 0f3F800000, %p364;
	mul.rn.f32 	%f152, %f793, %f793;
	mov.f32 	%f794, 0fB94D4153;
	@%p364 bra 	$L__BB7_350;

	mov.f32 	%f527, 0fBAB607ED;
	mov.f32 	%f528, 0f37CBAC00;
	fma.rn.f32 	%f794, %f528, %f152, %f527;

$L__BB7_350:
	selp.f32 	%f529, 0f3C0885E4, 0f3D2AAABB, %p364;
	fma.rn.f32 	%f530, %f794, %f152, %f529;
	selp.f32 	%f531, 0fBE2AAAA8, 0fBEFFFFFF, %p364;
	fma.rn.f32 	%f532, %f530, %f152, %f531;
	mov.f32 	%f533, 0f00000000;
	fma.rn.f32 	%f534, %f152, %f151, %f533;
	fma.rn.f32 	%f795, %f532, %f534, %f151;
	and.b32  	%r990, %r1396, 2;
	setp.eq.s32 	%p366, %r990, 0;
	@%p366 bra 	$L__BB7_352;

	mov.f32 	%f536, 0fBF800000;
	fma.rn.f32 	%f795, %f795, %f536, %f533;

$L__BB7_352:
	@%p357 bra 	$L__BB7_360;

	setp.eq.f32 	%p368, %f147, 0f7F800000;
	@%p368 bra 	$L__BB7_359;
	bra.uni 	$L__BB7_354;

$L__BB7_359:
	mov.f32 	%f539, 0f00000000;
	mul.rn.f32 	%f796, %f145, %f539;
	mov.u32 	%r1399, 0;
	bra.uni 	$L__BB7_360;

$L__BB7_354:
	mov.b32 	%r261, %f145;
	bfe.u32 	%r991, %r261, 23, 8;
	add.s32 	%r262, %r991, -128;
	shl.b32 	%r992, %r261, 8;
	or.b32  	%r263, %r992, -2147483648;
	shr.u32 	%r264, %r262, 5;
	mov.u64 	%rd473, 0;
	mov.u64 	%rd474, %rd473;

$L__BB7_355:
	.pragma "nounroll";
	shl.b64 	%rd332, %rd473, 2;
	mov.u64 	%rd333, __cudart_i2opi_f;
	add.s64 	%rd334, %rd333, %rd332;
	ld.global.nc.u32 	%r993, [%rd334];
	mad.wide.u32 	%rd335, %r993, %r263, %rd474;
	shr.u64 	%rd474, %rd335, 32;
	add.s64 	%rd336, %rd1, %rd332;
	st.local.u32 	[%rd336], %rd335;
	cvt.u32.u64 	%r994, %rd473;
	add.s32 	%r995, %r994, 1;
	cvt.s64.s32 	%rd473, %r995;
	setp.ne.s32 	%p369, %r995, 6;
	@%p369 bra 	$L__BB7_355;

	st.local.u32 	[%rd23], %rd474;
	mov.u32 	%r996, 4;
	sub.s32 	%r265, %r996, %r264;
	mov.u32 	%r997, 6;
	sub.s32 	%r998, %r997, %r264;
	mul.wide.s32 	%rd337, %r998, 4;
	add.s64 	%rd338, %rd1, %rd337;
	ld.local.u32 	%r1397, [%rd338];
	ld.local.u32 	%r1398, [%rd338+-4];
	and.b32  	%r268, %r262, 31;
	setp.eq.s32 	%p370, %r268, 0;
	@%p370 bra 	$L__BB7_358;

	mov.u32 	%r999, 32;
	sub.s32 	%r1000, %r999, %r268;
	shr.u32 	%r1001, %r1398, %r1000;
	shl.b32 	%r1002, %r1397, %r268;
	add.s32 	%r1397, %r1001, %r1002;
	mul.wide.s32 	%rd339, %r265, 4;
	add.s64 	%rd340, %rd1, %rd339;
	ld.local.u32 	%r1003, [%rd340];
	shr.u32 	%r1004, %r1003, %r1000;
	shl.b32 	%r1005, %r1398, %r268;
	add.s32 	%r1398, %r1004, %r1005;

$L__BB7_358:
	and.b32  	%r1006, %r261, -2147483648;
	shr.u32 	%r1007, %r1398, 30;
	shl.b32 	%r1008, %r1397, 2;
	or.b32  	%r1009, %r1007, %r1008;
	shr.u32 	%r1010, %r1009, 31;
	shr.u32 	%r1011, %r1397, 30;
	add.s32 	%r1012, %r1010, %r1011;
	neg.s32 	%r1013, %r1012;
	setp.eq.s32 	%p371, %r1006, 0;
	selp.b32 	%r1399, %r1012, %r1013, %p371;
	setp.ne.s32 	%p372, %r1010, 0;
	xor.b32  	%r1014, %r1006, -2147483648;
	selp.b32 	%r1015, %r1014, %r1006, %p372;
	selp.b32 	%r1016, -1, 0, %p372;
	xor.b32  	%r1017, %r1009, %r1016;
	shl.b32 	%r1018, %r1398, 2;
	xor.b32  	%r1019, %r1018, %r1016;
	cvt.u64.u32 	%rd341, %r1017;
	cvt.u64.u32 	%rd342, %r1019;
	bfi.b64 	%rd343, %rd341, %rd342, 32, 32;
	cvt.rn.f64.s64 	%fd936, %rd343;
	mul.rn.f64 	%fd937, %fd936, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f537, %fd937;
	setp.eq.s32 	%p373, %r1015, 0;
	neg.f32 	%f538, %f537;
	selp.f32 	%f796, %f537, %f538, %p373;

$L__BB7_360:
	add.s32 	%r275, %r1399, 1;
	and.b32  	%r276, %r275, 1;
	setp.eq.s32 	%p8, %r276, 0;
	mul.rn.f32 	%f161, %f796, %f796;
	mov.f32 	%f797, 0fB94D4153;
	@%p8 bra 	$L__BB7_362;

	mov.f32 	%f541, 0fBAB607ED;
	mov.f32 	%f542, 0f37CBAC00;
	fma.rn.f32 	%f797, %f542, %f161, %f541;

$L__BB7_362:
	selp.f32 	%f543, %f796, 0f3F800000, %p8;
	selp.f32 	%f544, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f545, %f797, %f161, %f544;
	selp.f32 	%f546, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f547, %f545, %f161, %f546;
	mov.f32 	%f548, 0f00000000;
	fma.rn.f32 	%f549, %f161, %f543, %f548;
	fma.rn.f32 	%f798, %f547, %f549, %f543;
	and.b32  	%r1021, %r275, 2;
	setp.eq.s32 	%p375, %r1021, 0;
	@%p375 bra 	$L__BB7_364;

	mov.f32 	%f551, 0fBF800000;
	fma.rn.f32 	%f798, %f798, %f551, %f548;

$L__BB7_364:
	cvt.f64.f32 	%fd938, %f795;
	mul.rn.f64 	%fd939, %fd938, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd940, %fd939, %fd938;
	add.rn.f64 	%fd941, %fd940, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f552, %fd941;
	sqrt.rn.f32 	%f553, %f552;
	mov.f32 	%f554, 0f4AC2A60A;
	div.rn.f32 	%f555, %f554, %f553;
	mul.rn.f32 	%f556, %f555, %f798;
	cvt.f64.f32 	%fd942, %f556;
	mul.rn.f64 	%fd943, %fd942, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f557, %fd293;
	cvt.f64.f32 	%fd944, %f557;
	mul.rn.f64 	%fd945, %fd944, 0d4066800000000000;
	div.rn.f64 	%fd946, %fd945, %fd943;
	cvt.rn.f32.f64 	%f558, %fd946;
	add.rn.f32 	%f167, %f819, %f558;
	mul.rn.f32 	%f559, %f553, %f552;
	cvt.f64.f32 	%fd947, %f559;
	mov.f64 	%fd948, 0d41582B102DE355C1;
	div.rn.f64 	%fd949, %fd948, %fd947;
	mul.rn.f64 	%fd950, %fd949, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f560, %fd281;
	cvt.f64.f32 	%fd951, %f560;
	mul.rn.f64 	%fd952, %fd951, 0d4066800000000000;
	div.rn.f64 	%fd953, %fd952, %fd950;
	cvt.rn.f32.f64 	%f561, %fd953;
	add.rn.f32 	%f168, %f820, %f561;
	cvt.f64.f32 	%fd295, %f167;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r277}, %fd295;
	}
	abs.f64 	%fd296, %fd295;
	{ // callseq 94, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd296;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1142, [retval0+0];
	} // callseq 94
	setp.lt.s32 	%p376, %r277, 0;
	and.pred  	%p9, %p376, %p14;
	not.pred 	%p378, %p9;
	@%p378 bra 	$L__BB7_366;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1022}, %fd1142;
	}
	xor.b32  	%r1023, %r1022, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1024, %temp}, %fd1142;
	}
	mov.b64 	%fd1142, {%r1024, %r1023};

$L__BB7_366:
	setp.eq.f32 	%p379, %f167, 0f00000000;
	@%p379 bra 	$L__BB7_370;
	bra.uni 	$L__BB7_367;

$L__BB7_370:
	setp.lt.s32 	%p382, %r3, 0;
	mov.u32 	%r1025, 0;
	selp.b32 	%r1026, %r277, 0, %p14;
	or.b32  	%r1027, %r1026, 2146435072;
	selp.b32 	%r1028, %r1027, %r1026, %p382;
	mov.b64 	%fd1142, {%r1025, %r1028};
	bra.uni 	$L__BB7_371;

$L__BB7_367:
	setp.gt.s32 	%p380, %r277, -1;
	@%p380 bra 	$L__BB7_371;

	mov.f64 	%fd954, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd955, %fd954;
	setp.eq.f64 	%p381, %fd955, 0d4000000000000000;
	@%p381 bra 	$L__BB7_371;

	mov.f64 	%fd1142, 0dFFF8000000000000;

$L__BB7_371:
	add.rn.f64 	%fd957, %fd295, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1029}, %fd957;
	}
	and.b32  	%r1030, %r1029, 2146435072;
	setp.ne.s32 	%p384, %r1030, 2146435072;
	@%p384 bra 	$L__BB7_378;

	setp.gtu.f64 	%p385, %fd296, 0d7FF0000000000000;
	@%p385 bra 	$L__BB7_377;
	bra.uni 	$L__BB7_373;

$L__BB7_377:
	mov.f64 	%fd959, 0d4000000000000000;
	add.rn.f64 	%fd1142, %fd295, %fd959;
	bra.uni 	$L__BB7_378;

$L__BB7_373:
	setp.eq.s32 	%p386, %r181, 2146435072;
	mov.f64 	%fd958, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1031, %temp}, %fd958;
	}
	setp.eq.s32 	%p387, %r1031, 0;
	and.pred  	%p388, %p386, %p387;
	@%p388 bra 	$L__BB7_376;
	bra.uni 	$L__BB7_374;

$L__BB7_376:
	setp.lt.s32 	%p394, %r3, 0;
	mov.u32 	%r1036, 0;
	setp.gt.f64 	%p395, %fd296, 0d3FF0000000000000;
	selp.b32 	%r1037, 2146435072, 0, %p395;
	xor.b32  	%r1038, %r1037, 2146435072;
	selp.b32 	%r1039, %r1038, %r1037, %p394;
	setp.eq.f32 	%p396, %f167, 0fBF800000;
	selp.b32 	%r1040, 1072693248, %r1039, %p396;
	mov.b64 	%fd1142, {%r1036, %r1040};
	bra.uni 	$L__BB7_378;

$L__BB7_374:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1032, %temp}, %fd295;
	}
	and.b32  	%r1033, %r277, 2147483647;
	setp.ne.s32 	%p389, %r1033, 2146435072;
	setp.ne.s32 	%p390, %r1032, 0;
	or.pred  	%p391, %p389, %p390;
	@%p391 bra 	$L__BB7_378;

	setp.ne.s32 	%p392, %r181, 1071644672;
	and.pred  	%p393, %p392, %p9;
	selp.b32 	%r1034, %r183, %r182, %p393;
	mov.u32 	%r1035, 0;
	mov.b64 	%fd1142, {%r1035, %r1034};

$L__BB7_378:
	cvt.f64.f32 	%fd306, %f168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r278}, %fd306;
	}
	abs.f64 	%fd307, %fd306;
	{ // callseq 95, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd307;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1145, [retval0+0];
	} // callseq 95
	setp.lt.s32 	%p397, %r278, 0;
	and.pred  	%p10, %p397, %p14;
	not.pred 	%p399, %p10;
	@%p399 bra 	$L__BB7_380;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1041}, %fd1145;
	}
	xor.b32  	%r1042, %r1041, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1043, %temp}, %fd1145;
	}
	mov.b64 	%fd1145, {%r1043, %r1042};

$L__BB7_380:
	setp.eq.f32 	%p400, %f168, 0f00000000;
	@%p400 bra 	$L__BB7_384;
	bra.uni 	$L__BB7_381;

$L__BB7_384:
	setp.lt.s32 	%p403, %r3, 0;
	mov.u32 	%r1044, 0;
	selp.b32 	%r1045, %r278, 0, %p14;
	or.b32  	%r1046, %r1045, 2146435072;
	selp.b32 	%r1047, %r1046, %r1045, %p403;
	mov.b64 	%fd1145, {%r1044, %r1047};
	bra.uni 	$L__BB7_385;

$L__BB7_381:
	setp.gt.s32 	%p401, %r278, -1;
	@%p401 bra 	$L__BB7_385;

	mov.f64 	%fd960, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd961, %fd960;
	setp.eq.f64 	%p402, %fd961, 0d4000000000000000;
	@%p402 bra 	$L__BB7_385;

	mov.f64 	%fd1145, 0dFFF8000000000000;

$L__BB7_385:
	add.rn.f64 	%fd963, %fd306, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1048}, %fd963;
	}
	and.b32  	%r1049, %r1048, 2146435072;
	setp.ne.s32 	%p405, %r1049, 2146435072;
	@%p405 bra 	$L__BB7_392;

	setp.gtu.f64 	%p406, %fd307, 0d7FF0000000000000;
	@%p406 bra 	$L__BB7_391;
	bra.uni 	$L__BB7_387;

$L__BB7_391:
	mov.f64 	%fd965, 0d4000000000000000;
	add.rn.f64 	%fd1145, %fd306, %fd965;
	bra.uni 	$L__BB7_392;

$L__BB7_387:
	setp.eq.s32 	%p407, %r181, 2146435072;
	mov.f64 	%fd964, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1050, %temp}, %fd964;
	}
	setp.eq.s32 	%p408, %r1050, 0;
	and.pred  	%p409, %p407, %p408;
	@%p409 bra 	$L__BB7_390;
	bra.uni 	$L__BB7_388;

$L__BB7_390:
	setp.lt.s32 	%p415, %r3, 0;
	mov.u32 	%r1055, 0;
	setp.gt.f64 	%p416, %fd307, 0d3FF0000000000000;
	selp.b32 	%r1056, 2146435072, 0, %p416;
	xor.b32  	%r1057, %r1056, 2146435072;
	selp.b32 	%r1058, %r1057, %r1056, %p415;
	setp.eq.f32 	%p417, %f168, 0fBF800000;
	selp.b32 	%r1059, 1072693248, %r1058, %p417;
	mov.b64 	%fd1145, {%r1055, %r1059};
	bra.uni 	$L__BB7_392;

$L__BB7_388:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1051, %temp}, %fd306;
	}
	and.b32  	%r1052, %r278, 2147483647;
	setp.ne.s32 	%p410, %r1052, 2146435072;
	setp.ne.s32 	%p411, %r1051, 0;
	or.pred  	%p412, %p410, %p411;
	@%p412 bra 	$L__BB7_392;

	setp.ne.s32 	%p413, %r181, 1071644672;
	and.pred  	%p414, %p413, %p10;
	selp.b32 	%r1053, %r183, %r182, %p414;
	mov.u32 	%r1054, 0;
	mov.b64 	%fd1145, {%r1054, %r1053};

$L__BB7_392:
	setp.eq.f32 	%p418, %f168, 0f3F800000;
	selp.f64 	%fd966, 0d3FF0000000000000, %fd1145, %p418;
	setp.eq.f32 	%p419, %f167, 0f3F800000;
	selp.f64 	%fd967, 0d3FF0000000000000, %fd1142, %p419;
	add.rn.f64 	%fd317, %fd967, %fd966;
	mul.rn.f32 	%f169, %f168, 0f42517084;
	mul.rn.f32 	%f562, %f169, 0f3F22F983;
	cvt.rni.s32.f32 	%r1402, %f562;
	cvt.rn.f32.s32 	%f563, %r1402;
	mov.f32 	%f564, 0fBFC90FDA;
	fma.rn.f32 	%f565, %f563, %f564, %f169;
	mov.f32 	%f566, 0fB3A22168;
	fma.rn.f32 	%f567, %f563, %f566, %f565;
	mov.f32 	%f568, 0fA7C234C5;
	fma.rn.f32 	%f799, %f563, %f568, %f567;
	abs.f32 	%f171, %f169;
	setp.ltu.f32 	%p420, %f171, 0f47CE4780;
	@%p420 bra 	$L__BB7_400;

	setp.eq.f32 	%p421, %f171, 0f7F800000;
	@%p421 bra 	$L__BB7_399;
	bra.uni 	$L__BB7_394;

$L__BB7_399:
	mov.f32 	%f571, 0f00000000;
	mul.rn.f32 	%f799, %f169, %f571;
	mov.u32 	%r1402, 0;
	bra.uni 	$L__BB7_400;

$L__BB7_394:
	mov.b32 	%r280, %f169;
	bfe.u32 	%r1060, %r280, 23, 8;
	add.s32 	%r281, %r1060, -128;
	shl.b32 	%r1061, %r280, 8;
	or.b32  	%r282, %r1061, -2147483648;
	shr.u32 	%r283, %r281, 5;
	mov.u64 	%rd475, 0;
	mov.u64 	%rd476, %rd475;

$L__BB7_395:
	.pragma "nounroll";
	shl.b64 	%rd346, %rd475, 2;
	mov.u64 	%rd347, __cudart_i2opi_f;
	add.s64 	%rd348, %rd347, %rd346;
	ld.global.nc.u32 	%r1062, [%rd348];
	mad.wide.u32 	%rd349, %r1062, %r282, %rd476;
	shr.u64 	%rd476, %rd349, 32;
	add.s64 	%rd350, %rd1, %rd346;
	st.local.u32 	[%rd350], %rd349;
	cvt.u32.u64 	%r1063, %rd475;
	add.s32 	%r1064, %r1063, 1;
	cvt.s64.s32 	%rd475, %r1064;
	setp.ne.s32 	%p422, %r1064, 6;
	@%p422 bra 	$L__BB7_395;

	st.local.u32 	[%rd23], %rd476;
	mov.u32 	%r1065, 4;
	sub.s32 	%r284, %r1065, %r283;
	mov.u32 	%r1066, 6;
	sub.s32 	%r1067, %r1066, %r283;
	mul.wide.s32 	%rd351, %r1067, 4;
	add.s64 	%rd352, %rd1, %rd351;
	ld.local.u32 	%r1400, [%rd352];
	ld.local.u32 	%r1401, [%rd352+-4];
	and.b32  	%r287, %r281, 31;
	setp.eq.s32 	%p423, %r287, 0;
	@%p423 bra 	$L__BB7_398;

	mov.u32 	%r1068, 32;
	sub.s32 	%r1069, %r1068, %r287;
	shr.u32 	%r1070, %r1401, %r1069;
	shl.b32 	%r1071, %r1400, %r287;
	add.s32 	%r1400, %r1070, %r1071;
	mul.wide.s32 	%rd353, %r284, 4;
	add.s64 	%rd354, %rd1, %rd353;
	ld.local.u32 	%r1072, [%rd354];
	shr.u32 	%r1073, %r1072, %r1069;
	shl.b32 	%r1074, %r1401, %r287;
	add.s32 	%r1401, %r1073, %r1074;

$L__BB7_398:
	and.b32  	%r1075, %r280, -2147483648;
	shr.u32 	%r1076, %r1401, 30;
	shl.b32 	%r1077, %r1400, 2;
	or.b32  	%r1078, %r1076, %r1077;
	shr.u32 	%r1079, %r1078, 31;
	shr.u32 	%r1080, %r1400, 30;
	add.s32 	%r1081, %r1079, %r1080;
	neg.s32 	%r1082, %r1081;
	setp.eq.s32 	%p424, %r1075, 0;
	selp.b32 	%r1402, %r1081, %r1082, %p424;
	setp.ne.s32 	%p425, %r1079, 0;
	xor.b32  	%r1083, %r1075, -2147483648;
	selp.b32 	%r1084, %r1083, %r1075, %p425;
	selp.b32 	%r1085, -1, 0, %p425;
	xor.b32  	%r1086, %r1078, %r1085;
	shl.b32 	%r1087, %r1401, 2;
	xor.b32  	%r1088, %r1087, %r1085;
	cvt.u64.u32 	%rd355, %r1086;
	cvt.u64.u32 	%rd356, %r1088;
	bfi.b64 	%rd357, %rd355, %rd356, 32, 32;
	cvt.rn.f64.s64 	%fd968, %rd357;
	mul.rn.f64 	%fd969, %fd968, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f569, %fd969;
	setp.eq.s32 	%p426, %r1084, 0;
	neg.f32 	%f570, %f569;
	selp.f32 	%f799, %f569, %f570, %p426;

$L__BB7_400:
	and.b32  	%r294, %r1402, 1;
	setp.eq.s32 	%p427, %r294, 0;
	selp.f32 	%f175, %f799, 0f3F800000, %p427;
	mul.rn.f32 	%f176, %f799, %f799;
	mov.f32 	%f800, 0fB94D4153;
	@%p427 bra 	$L__BB7_402;

	mov.f32 	%f573, 0fBAB607ED;
	mov.f32 	%f574, 0f37CBAC00;
	fma.rn.f32 	%f800, %f574, %f176, %f573;

$L__BB7_402:
	selp.f32 	%f575, 0f3C0885E4, 0f3D2AAABB, %p427;
	fma.rn.f32 	%f576, %f800, %f176, %f575;
	selp.f32 	%f577, 0fBE2AAAA8, 0fBEFFFFFF, %p427;
	fma.rn.f32 	%f578, %f576, %f176, %f577;
	mov.f32 	%f579, 0f00000000;
	fma.rn.f32 	%f580, %f176, %f175, %f579;
	fma.rn.f32 	%f801, %f578, %f580, %f175;
	and.b32  	%r1090, %r1402, 2;
	setp.eq.s32 	%p429, %r1090, 0;
	@%p429 bra 	$L__BB7_404;

	mov.f32 	%f582, 0fBF800000;
	fma.rn.f32 	%f801, %f801, %f582, %f579;

$L__BB7_404:
	cvt.f64.f32 	%fd970, %f801;
	mul.rn.f64 	%fd971, %fd970, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd972, %fd317;
	add.rn.f64 	%fd318, %fd972, %fd971;
	abs.f32 	%f182, %f167;
	setp.eq.f32 	%p430, %f182, 0f00000000;
	abs.f32 	%f183, %f168;
	setp.eq.f32 	%p431, %f183, 0f00000000;
	and.pred  	%p432, %p430, %p431;
	@%p432 bra 	$L__BB7_408;
	bra.uni 	$L__BB7_405;

$L__BB7_408:
	mov.b32 	%r1101, %f167;
	shr.s32 	%r1102, %r1101, 31;
	and.b32  	%r1103, %r1102, 1078530011;
	mov.b32 	%r1104, %f168;
	and.b32  	%r1105, %r1104, -2147483648;
	or.b32  	%r1106, %r1103, %r1105;
	mov.b32 	%f802, %r1106;
	bra.uni 	$L__BB7_409;

$L__BB7_405:
	setp.eq.f32 	%p433, %f182, 0f7F800000;
	setp.eq.f32 	%p434, %f183, 0f7F800000;
	and.pred  	%p435, %p433, %p434;
	@%p435 bra 	$L__BB7_407;
	bra.uni 	$L__BB7_406;

$L__BB7_407:
	mov.b32 	%r1096, %f167;
	setp.lt.s32 	%p439, %r1096, 0;
	selp.b32 	%r1097, 1075235812, 1061752795, %p439;
	mov.b32 	%r1098, %f168;
	and.b32  	%r1099, %r1098, -2147483648;
	or.b32  	%r1100, %r1097, %r1099;
	mov.b32 	%f802, %r1100;
	bra.uni 	$L__BB7_409;

$L__BB7_406:
	max.f32 	%f583, %f183, %f182;
	min.f32 	%f584, %f183, %f182;
	div.rn.f32 	%f585, %f584, %f583;
	mul.rn.f32 	%f586, %f585, %f585;
	mov.f32 	%f587, 0fC0B59883;
	mov.f32 	%f588, 0fBF52C7EA;
	fma.rn.f32 	%f589, %f586, %f588, %f587;
	mov.f32 	%f590, 0fC0D21907;
	fma.rn.f32 	%f591, %f589, %f586, %f590;
	mul.rn.f32 	%f592, %f586, %f591;
	mul.rn.f32 	%f593, %f585, %f592;
	add.rn.f32 	%f594, %f586, 0f41355DC0;
	mov.f32 	%f595, 0f41E6BD60;
	fma.rn.f32 	%f596, %f594, %f586, %f595;
	mov.f32 	%f597, 0f419D92C8;
	fma.rn.f32 	%f598, %f596, %f586, %f597;
	rcp.rn.f32 	%f599, %f598;
	fma.rn.f32 	%f600, %f593, %f599, %f585;
	mov.f32 	%f601, 0f3FC90FDB;
	sub.rn.f32 	%f602, %f601, %f600;
	setp.gt.f32 	%p436, %f183, %f182;
	selp.f32 	%f603, %f602, %f600, %p436;
	mov.b32 	%r1091, %f167;
	setp.lt.s32 	%p437, %r1091, 0;
	mov.f32 	%f604, 0f40490FDB;
	sub.rn.f32 	%f605, %f604, %f603;
	selp.f32 	%f606, %f605, %f603, %p437;
	mov.b32 	%r1092, %f606;
	mov.b32 	%r1093, %f168;
	and.b32  	%r1094, %r1093, -2147483648;
	or.b32  	%r1095, %r1094, %r1092;
	mov.b32 	%f607, %r1095;
	add.rn.f32 	%f608, %f182, %f183;
	setp.le.f32 	%p438, %f608, 0f7F800000;
	selp.f32 	%f802, %f607, %f608, %p438;

$L__BB7_409:
	mul.rn.f32 	%f188, %f167, 0f42517084;
	mul.rn.f32 	%f609, %f188, 0f3F22F983;
	cvt.rni.s32.f32 	%r1405, %f609;
	cvt.rn.f32.s32 	%f610, %r1405;
	mov.f32 	%f611, 0fBFC90FDA;
	fma.rn.f32 	%f612, %f610, %f611, %f188;
	mov.f32 	%f613, 0fB3A22168;
	fma.rn.f32 	%f614, %f610, %f613, %f612;
	mov.f32 	%f615, 0fA7C234C5;
	fma.rn.f32 	%f803, %f610, %f615, %f614;
	abs.f32 	%f190, %f188;
	setp.ltu.f32 	%p440, %f190, 0f47CE4780;
	@%p440 bra 	$L__BB7_417;

	setp.eq.f32 	%p441, %f190, 0f7F800000;
	@%p441 bra 	$L__BB7_416;
	bra.uni 	$L__BB7_411;

$L__BB7_416:
	mov.f32 	%f618, 0f00000000;
	mul.rn.f32 	%f803, %f188, %f618;
	mov.u32 	%r1405, 0;
	bra.uni 	$L__BB7_417;

$L__BB7_411:
	mov.b32 	%r296, %f188;
	bfe.u32 	%r1107, %r296, 23, 8;
	add.s32 	%r297, %r1107, -128;
	shl.b32 	%r1108, %r296, 8;
	or.b32  	%r298, %r1108, -2147483648;
	shr.u32 	%r299, %r297, 5;
	mov.u64 	%rd477, 0;
	mov.u64 	%rd478, %rd477;

$L__BB7_412:
	.pragma "nounroll";
	shl.b64 	%rd360, %rd477, 2;
	mov.u64 	%rd361, __cudart_i2opi_f;
	add.s64 	%rd362, %rd361, %rd360;
	ld.global.nc.u32 	%r1109, [%rd362];
	mad.wide.u32 	%rd363, %r1109, %r298, %rd478;
	shr.u64 	%rd478, %rd363, 32;
	add.s64 	%rd364, %rd1, %rd360;
	st.local.u32 	[%rd364], %rd363;
	cvt.u32.u64 	%r1110, %rd477;
	add.s32 	%r1111, %r1110, 1;
	cvt.s64.s32 	%rd477, %r1111;
	setp.ne.s32 	%p442, %r1111, 6;
	@%p442 bra 	$L__BB7_412;

	st.local.u32 	[%rd23], %rd478;
	mov.u32 	%r1112, 4;
	sub.s32 	%r300, %r1112, %r299;
	mov.u32 	%r1113, 6;
	sub.s32 	%r1114, %r1113, %r299;
	mul.wide.s32 	%rd365, %r1114, 4;
	add.s64 	%rd366, %rd1, %rd365;
	ld.local.u32 	%r1403, [%rd366];
	ld.local.u32 	%r1404, [%rd366+-4];
	and.b32  	%r303, %r297, 31;
	setp.eq.s32 	%p443, %r303, 0;
	@%p443 bra 	$L__BB7_415;

	mov.u32 	%r1115, 32;
	sub.s32 	%r1116, %r1115, %r303;
	shr.u32 	%r1117, %r1404, %r1116;
	shl.b32 	%r1118, %r1403, %r303;
	add.s32 	%r1403, %r1117, %r1118;
	mul.wide.s32 	%rd367, %r300, 4;
	add.s64 	%rd368, %rd1, %rd367;
	ld.local.u32 	%r1119, [%rd368];
	shr.u32 	%r1120, %r1119, %r1116;
	shl.b32 	%r1121, %r1404, %r303;
	add.s32 	%r1404, %r1120, %r1121;

$L__BB7_415:
	and.b32  	%r1122, %r296, -2147483648;
	shr.u32 	%r1123, %r1404, 30;
	shl.b32 	%r1124, %r1403, 2;
	or.b32  	%r1125, %r1123, %r1124;
	shr.u32 	%r1126, %r1125, 31;
	shr.u32 	%r1127, %r1403, 30;
	add.s32 	%r1128, %r1126, %r1127;
	neg.s32 	%r1129, %r1128;
	setp.eq.s32 	%p444, %r1122, 0;
	selp.b32 	%r1405, %r1128, %r1129, %p444;
	setp.ne.s32 	%p445, %r1126, 0;
	xor.b32  	%r1130, %r1122, -2147483648;
	selp.b32 	%r1131, %r1130, %r1122, %p445;
	selp.b32 	%r1132, -1, 0, %p445;
	xor.b32  	%r1133, %r1125, %r1132;
	shl.b32 	%r1134, %r1404, 2;
	xor.b32  	%r1135, %r1134, %r1132;
	cvt.u64.u32 	%rd369, %r1133;
	cvt.u64.u32 	%rd370, %r1135;
	bfi.b64 	%rd371, %rd369, %rd370, 32, 32;
	cvt.rn.f64.s64 	%fd973, %rd371;
	mul.rn.f64 	%fd974, %fd973, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f616, %fd974;
	setp.eq.s32 	%p446, %r1131, 0;
	neg.f32 	%f617, %f616;
	selp.f32 	%f803, %f616, %f617, %p446;

$L__BB7_417:
	cvt.rn.f32.f64 	%f194, %fd318;
	add.s32 	%r310, %r1405, 1;
	and.b32  	%r311, %r310, 1;
	setp.eq.s32 	%p447, %r311, 0;
	selp.f32 	%f195, %f803, 0f3F800000, %p447;
	mul.rn.f32 	%f196, %f803, %f803;
	mov.f32 	%f804, 0fB94D4153;
	@%p447 bra 	$L__BB7_419;

	mov.f32 	%f620, 0fBAB607ED;
	mov.f32 	%f621, 0f37CBAC00;
	fma.rn.f32 	%f804, %f621, %f196, %f620;

$L__BB7_419:
	selp.f32 	%f622, 0f3C0885E4, 0f3D2AAABB, %p447;
	fma.rn.f32 	%f623, %f804, %f196, %f622;
	selp.f32 	%f624, 0fBE2AAAA8, 0fBEFFFFFF, %p447;
	fma.rn.f32 	%f625, %f623, %f196, %f624;
	mov.f32 	%f626, 0f00000000;
	fma.rn.f32 	%f627, %f196, %f195, %f626;
	fma.rn.f32 	%f805, %f625, %f627, %f195;
	and.b32  	%r1137, %r310, 2;
	setp.eq.s32 	%p449, %r1137, 0;
	@%p449 bra 	$L__BB7_421;

	mov.f32 	%f629, 0fBF800000;
	fma.rn.f32 	%f805, %f805, %f629, %f626;

$L__BB7_421:
	cvt.f64.f32 	%fd975, %f805;
	mul.rn.f64 	%fd976, %fd975, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd977, %f802;
	add.rn.f64 	%fd978, %fd976, %fd977;
	cvt.rn.f32.f64 	%f202, %fd978;
	mul.rn.f32 	%f630, %f202, 0f3F22F983;
	cvt.rni.s32.f32 	%r1411, %f630;
	cvt.rn.f32.s32 	%f631, %r1411;
	mov.f32 	%f632, 0fBFC90FDA;
	fma.rn.f32 	%f633, %f631, %f632, %f202;
	mov.f32 	%f634, 0fB3A22168;
	fma.rn.f32 	%f635, %f631, %f634, %f633;
	mov.f32 	%f636, 0fA7C234C5;
	fma.rn.f32 	%f809, %f631, %f636, %f635;
	abs.f32 	%f204, %f202;
	setp.ltu.f32 	%p450, %f204, 0f47CE4780;
	mov.u32 	%r1408, %r1411;
	mov.f32 	%f806, %f809;
	@%p450 bra 	$L__BB7_429;

	setp.eq.f32 	%p451, %f204, 0f7F800000;
	@%p451 bra 	$L__BB7_428;
	bra.uni 	$L__BB7_423;

$L__BB7_428:
	mov.f32 	%f639, 0f00000000;
	mul.rn.f32 	%f806, %f202, %f639;
	mov.u32 	%r1408, 0;
	bra.uni 	$L__BB7_429;

$L__BB7_423:
	mov.b32 	%r313, %f202;
	bfe.u32 	%r1138, %r313, 23, 8;
	add.s32 	%r314, %r1138, -128;
	shl.b32 	%r1139, %r313, 8;
	or.b32  	%r315, %r1139, -2147483648;
	shr.u32 	%r316, %r314, 5;
	mov.u64 	%rd479, 0;
	mov.u64 	%rd480, %rd479;

$L__BB7_424:
	.pragma "nounroll";
	shl.b64 	%rd374, %rd479, 2;
	mov.u64 	%rd375, __cudart_i2opi_f;
	add.s64 	%rd376, %rd375, %rd374;
	ld.global.nc.u32 	%r1140, [%rd376];
	mad.wide.u32 	%rd377, %r1140, %r315, %rd480;
	shr.u64 	%rd480, %rd377, 32;
	add.s64 	%rd378, %rd1, %rd374;
	st.local.u32 	[%rd378], %rd377;
	cvt.u32.u64 	%r1141, %rd479;
	add.s32 	%r1142, %r1141, 1;
	cvt.s64.s32 	%rd479, %r1142;
	setp.ne.s32 	%p452, %r1142, 6;
	@%p452 bra 	$L__BB7_424;

	st.local.u32 	[%rd23], %rd480;
	mov.u32 	%r1143, 4;
	sub.s32 	%r317, %r1143, %r316;
	mov.u32 	%r1144, 6;
	sub.s32 	%r1145, %r1144, %r316;
	mul.wide.s32 	%rd379, %r1145, 4;
	add.s64 	%rd380, %rd1, %rd379;
	ld.local.u32 	%r1406, [%rd380];
	ld.local.u32 	%r1407, [%rd380+-4];
	and.b32  	%r320, %r314, 31;
	setp.eq.s32 	%p453, %r320, 0;
	@%p453 bra 	$L__BB7_427;

	mov.u32 	%r1146, 32;
	sub.s32 	%r1147, %r1146, %r320;
	shr.u32 	%r1148, %r1407, %r1147;
	shl.b32 	%r1149, %r1406, %r320;
	add.s32 	%r1406, %r1148, %r1149;
	mul.wide.s32 	%rd381, %r317, 4;
	add.s64 	%rd382, %rd1, %rd381;
	ld.local.u32 	%r1150, [%rd382];
	shr.u32 	%r1151, %r1150, %r1147;
	shl.b32 	%r1152, %r1407, %r320;
	add.s32 	%r1407, %r1151, %r1152;

$L__BB7_427:
	and.b32  	%r1153, %r313, -2147483648;
	shr.u32 	%r1154, %r1407, 30;
	shl.b32 	%r1155, %r1406, 2;
	or.b32  	%r1156, %r1154, %r1155;
	shr.u32 	%r1157, %r1156, 31;
	shr.u32 	%r1158, %r1406, 30;
	add.s32 	%r1159, %r1157, %r1158;
	neg.s32 	%r1160, %r1159;
	setp.eq.s32 	%p454, %r1153, 0;
	selp.b32 	%r1408, %r1159, %r1160, %p454;
	setp.ne.s32 	%p455, %r1157, 0;
	xor.b32  	%r1161, %r1153, -2147483648;
	selp.b32 	%r1162, %r1161, %r1153, %p455;
	selp.b32 	%r1163, -1, 0, %p455;
	xor.b32  	%r1164, %r1156, %r1163;
	shl.b32 	%r1165, %r1407, 2;
	xor.b32  	%r1166, %r1165, %r1163;
	cvt.u64.u32 	%rd383, %r1164;
	cvt.u64.u32 	%rd384, %r1166;
	bfi.b64 	%rd385, %rd383, %rd384, 32, 32;
	cvt.rn.f64.s64 	%fd979, %rd385;
	mul.rn.f64 	%fd980, %fd979, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f637, %fd980;
	setp.eq.s32 	%p456, %r1162, 0;
	neg.f32 	%f638, %f637;
	selp.f32 	%f806, %f637, %f638, %p456;

$L__BB7_429:
	add.s32 	%r327, %r1408, 1;
	and.b32  	%r328, %r327, 1;
	setp.eq.s32 	%p457, %r328, 0;
	selp.f32 	%f208, %f806, 0f3F800000, %p457;
	mul.rn.f32 	%f209, %f806, %f806;
	mov.f32 	%f807, 0fB94D4153;
	@%p457 bra 	$L__BB7_431;

	mov.f32 	%f641, 0fBAB607ED;
	mov.f32 	%f642, 0f37CBAC00;
	fma.rn.f32 	%f807, %f642, %f209, %f641;

$L__BB7_431:
	selp.f32 	%f643, 0f3C0885E4, 0f3D2AAABB, %p457;
	fma.rn.f32 	%f644, %f807, %f209, %f643;
	selp.f32 	%f645, 0fBE2AAAA8, 0fBEFFFFFF, %p457;
	fma.rn.f32 	%f646, %f644, %f209, %f645;
	mov.f32 	%f647, 0f00000000;
	fma.rn.f32 	%f648, %f209, %f208, %f647;
	fma.rn.f32 	%f808, %f646, %f648, %f208;
	and.b32  	%r1168, %r327, 2;
	setp.eq.s32 	%p459, %r1168, 0;
	@%p459 bra 	$L__BB7_433;

	mov.f32 	%f650, 0fBF800000;
	fma.rn.f32 	%f808, %f808, %f650, %f647;

$L__BB7_433:
	@%p450 bra 	$L__BB7_441;

	setp.eq.f32 	%p461, %f204, 0f7F800000;
	@%p461 bra 	$L__BB7_440;
	bra.uni 	$L__BB7_435;

$L__BB7_440:
	mov.f32 	%f653, 0f00000000;
	mul.rn.f32 	%f809, %f202, %f653;
	mov.u32 	%r1411, 0;
	bra.uni 	$L__BB7_441;

$L__BB7_435:
	mov.b32 	%r329, %f202;
	bfe.u32 	%r1169, %r329, 23, 8;
	add.s32 	%r330, %r1169, -128;
	shl.b32 	%r1170, %r329, 8;
	or.b32  	%r331, %r1170, -2147483648;
	shr.u32 	%r332, %r330, 5;
	mov.u64 	%rd481, 0;
	mov.u64 	%rd482, %rd481;

$L__BB7_436:
	.pragma "nounroll";
	shl.b64 	%rd388, %rd481, 2;
	mov.u64 	%rd389, __cudart_i2opi_f;
	add.s64 	%rd390, %rd389, %rd388;
	ld.global.nc.u32 	%r1171, [%rd390];
	mad.wide.u32 	%rd391, %r1171, %r331, %rd482;
	shr.u64 	%rd482, %rd391, 32;
	add.s64 	%rd392, %rd1, %rd388;
	st.local.u32 	[%rd392], %rd391;
	cvt.u32.u64 	%r1172, %rd481;
	add.s32 	%r1173, %r1172, 1;
	cvt.s64.s32 	%rd481, %r1173;
	setp.ne.s32 	%p462, %r1173, 6;
	@%p462 bra 	$L__BB7_436;

	st.local.u32 	[%rd23], %rd482;
	mov.u32 	%r1174, 4;
	sub.s32 	%r333, %r1174, %r332;
	mov.u32 	%r1175, 6;
	sub.s32 	%r1176, %r1175, %r332;
	mul.wide.s32 	%rd393, %r1176, 4;
	add.s64 	%rd394, %rd1, %rd393;
	ld.local.u32 	%r1409, [%rd394];
	ld.local.u32 	%r1410, [%rd394+-4];
	and.b32  	%r336, %r330, 31;
	setp.eq.s32 	%p463, %r336, 0;
	@%p463 bra 	$L__BB7_439;

	mov.u32 	%r1177, 32;
	sub.s32 	%r1178, %r1177, %r336;
	shr.u32 	%r1179, %r1410, %r1178;
	shl.b32 	%r1180, %r1409, %r336;
	add.s32 	%r1409, %r1179, %r1180;
	mul.wide.s32 	%rd395, %r333, 4;
	add.s64 	%rd396, %rd1, %rd395;
	ld.local.u32 	%r1181, [%rd396];
	shr.u32 	%r1182, %r1181, %r1178;
	shl.b32 	%r1183, %r1410, %r336;
	add.s32 	%r1410, %r1182, %r1183;

$L__BB7_439:
	and.b32  	%r1184, %r329, -2147483648;
	shr.u32 	%r1185, %r1410, 30;
	shl.b32 	%r1186, %r1409, 2;
	or.b32  	%r1187, %r1185, %r1186;
	shr.u32 	%r1188, %r1187, 31;
	shr.u32 	%r1189, %r1409, 30;
	add.s32 	%r1190, %r1188, %r1189;
	neg.s32 	%r1191, %r1190;
	setp.eq.s32 	%p464, %r1184, 0;
	selp.b32 	%r1411, %r1190, %r1191, %p464;
	setp.ne.s32 	%p465, %r1188, 0;
	xor.b32  	%r1192, %r1184, -2147483648;
	selp.b32 	%r1193, %r1192, %r1184, %p465;
	selp.b32 	%r1194, -1, 0, %p465;
	xor.b32  	%r1195, %r1187, %r1194;
	shl.b32 	%r1196, %r1410, 2;
	xor.b32  	%r1197, %r1196, %r1194;
	cvt.u64.u32 	%rd397, %r1195;
	cvt.u64.u32 	%rd398, %r1197;
	bfi.b64 	%rd399, %rd397, %rd398, 32, 32;
	cvt.rn.f64.s64 	%fd981, %rd399;
	mul.rn.f64 	%fd982, %fd981, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f651, %fd982;
	setp.eq.s32 	%p466, %r1193, 0;
	neg.f32 	%f652, %f651;
	selp.f32 	%f809, %f651, %f652, %p466;

$L__BB7_441:
	and.b32  	%r343, %r1411, 1;
	setp.eq.s32 	%p467, %r343, 0;
	selp.f32 	%f218, %f809, 0f3F800000, %p467;
	mul.rn.f32 	%f219, %f809, %f809;
	mov.f32 	%f810, 0fB94D4153;
	@%p467 bra 	$L__BB7_443;

	mov.f32 	%f655, 0fBAB607ED;
	mov.f32 	%f656, 0f37CBAC00;
	fma.rn.f32 	%f810, %f656, %f219, %f655;

$L__BB7_443:
	selp.f32 	%f657, 0f3C0885E4, 0f3D2AAABB, %p467;
	fma.rn.f32 	%f658, %f810, %f219, %f657;
	selp.f32 	%f659, 0fBE2AAAA8, 0fBEFFFFFF, %p467;
	fma.rn.f32 	%f660, %f658, %f219, %f659;
	mov.f32 	%f661, 0f00000000;
	fma.rn.f32 	%f662, %f219, %f218, %f661;
	fma.rn.f32 	%f811, %f660, %f662, %f218;
	and.b32  	%r1199, %r1411, 2;
	setp.eq.s32 	%p469, %r1199, 0;
	@%p469 bra 	$L__BB7_445;

	mov.f32 	%f664, 0fBF800000;
	fma.rn.f32 	%f811, %f811, %f664, %f661;

$L__BB7_445:
	ld.param.s8 	%rs2, [bd09_to_wgs84_exact_cuda_float_param_4];
	mul.rn.f32 	%f665, %f811, %f194;
	cvt.f64.f32 	%fd983, %f665;
	add.rn.f64 	%fd984, %fd983, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f666, %fd984;
	sub.rn.f32 	%f225, %f3, %f666;
	mul.rn.f32 	%f667, %f808, %f194;
	cvt.f64.f32 	%fd985, %f667;
	add.rn.f64 	%fd986, %fd985, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f668, %fd986;
	sub.rn.f32 	%f226, %f1, %f668;
	add.rn.f32 	%f786, %f819, %f226;
	add.rn.f32 	%f785, %f820, %f225;
	setp.eq.s16 	%p470, %rs2, 0;
	@%p470 bra 	$L__BB7_520;

	mul.rn.f64 	%fd987, %fd294, 0d400921FB54442D18;
	div.rn.f64 	%fd988, %fd987, 0d4066800000000000;
	cvt.rn.f32.f64 	%f229, %fd988;
	cvt.f64.f32 	%fd989, %f785;
	mul.rn.f64 	%fd990, %fd989, 0d400921FB54442D18;
	div.rn.f64 	%fd991, %fd990, 0d4066800000000000;
	cvt.rn.f32.f64 	%f230, %fd991;
	sub.rn.f32 	%f669, %f230, %f229;
	cvt.f64.f32 	%fd992, %f669;
	mul.rn.f64 	%fd319, %fd992, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1200, %temp}, %fd319;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1201}, %fd319;
	}
	and.b32  	%r1202, %r1201, 2147483647;
	setp.eq.s32 	%p471, %r1202, 2146435072;
	setp.eq.s32 	%p472, %r1200, 0;
	and.pred  	%p473, %p472, %p471;
	@%p473 bra 	$L__BB7_449;
	bra.uni 	$L__BB7_447;

$L__BB7_449:
	mov.f64 	%fd1002, 0d0000000000000000;
	mul.rn.f64 	%fd1146, %fd319, %fd1002;
	mov.u32 	%r1412, 0;
	bra.uni 	$L__BB7_450;

$L__BB7_520:
	abs.f32 	%f744, %f226;
	setp.geu.f32 	%p558, %f744, %f266;
	@%p558 bra 	$L__BB7_522;

	abs.f32 	%f745, %f225;
	setp.lt.f32 	%p559, %f745, %f266;
	@%p559 bra 	$L__BB7_523;
	bra.uni 	$L__BB7_522;

$L__BB7_447:
	mul.rn.f64 	%fd993, %fd319, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1412, %fd993;
	st.local.u32 	[%rd8], %r1412;
	cvt.rn.f64.s32 	%fd994, %r1412;
	neg.f64 	%fd995, %fd994;
	mov.f64 	%fd996, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd997, %fd995, %fd996, %fd319;
	mov.f64 	%fd998, 0d3C91A62633145C00;
	fma.rn.f64 	%fd999, %fd995, %fd998, %fd997;
	mov.f64 	%fd1000, 0d397B839A252049C0;
	fma.rn.f64 	%fd1146, %fd995, %fd1000, %fd999;
	abs.f64 	%fd1001, %fd319;
	setp.ltu.f64 	%p474, %fd1001, 0d41E0000000000000;
	@%p474 bra 	$L__BB7_450;

	{ // callseq 96, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd319;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1146, [retval0+0];
	} // callseq 96
	ld.local.u32 	%r1412, [%rd8];

$L__BB7_450:
	and.b32  	%r1204, %r1412, 1;
	shl.b32 	%r1205, %r1412, 3;
	and.b32  	%r1206, %r1205, 8;
	setp.eq.s32 	%p475, %r1204, 0;
	selp.f64 	%fd1003, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p475;
	mul.wide.s32 	%rd401, %r1206, 8;
	add.s64 	%rd403, %rd186, %rd401;
	ld.global.nc.f64 	%fd1004, [%rd403+8];
	mul.rn.f64 	%fd324, %fd1146, %fd1146;
	fma.rn.f64 	%fd1005, %fd1003, %fd324, %fd1004;
	ld.global.nc.f64 	%fd1006, [%rd403+16];
	fma.rn.f64 	%fd1007, %fd1005, %fd324, %fd1006;
	ld.global.nc.f64 	%fd1008, [%rd403+24];
	fma.rn.f64 	%fd1009, %fd1007, %fd324, %fd1008;
	ld.global.nc.f64 	%fd1010, [%rd403+32];
	fma.rn.f64 	%fd1011, %fd1009, %fd324, %fd1010;
	ld.global.nc.f64 	%fd1012, [%rd403+40];
	fma.rn.f64 	%fd1013, %fd1011, %fd324, %fd1012;
	ld.global.nc.f64 	%fd1014, [%rd403+48];
	fma.rn.f64 	%fd325, %fd1013, %fd324, %fd1014;
	fma.rn.f64 	%fd1148, %fd325, %fd1146, %fd1146;
	@%p475 bra 	$L__BB7_452;

	mov.f64 	%fd1015, 0d3FF0000000000000;
	fma.rn.f64 	%fd1148, %fd325, %fd324, %fd1015;

$L__BB7_452:
	and.b32  	%r1207, %r1412, 2;
	setp.eq.s32 	%p476, %r1207, 0;
	@%p476 bra 	$L__BB7_454;

	mov.f64 	%fd1016, 0d0000000000000000;
	mov.f64 	%fd1017, 0dBFF0000000000000;
	fma.rn.f64 	%fd1148, %fd1148, %fd1017, %fd1016;

$L__BB7_454:
	abs.f64 	%fd331, %fd1148;
	{ // callseq 97, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd331;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1151, [retval0+0];
	} // callseq 97
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r347}, %fd1148;
	}
	setp.lt.s32 	%p477, %r347, 0;
	and.pred  	%p11, %p477, %p14;
	not.pred 	%p479, %p11;
	@%p479 bra 	$L__BB7_456;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1208}, %fd1151;
	}
	xor.b32  	%r1209, %r1208, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1210, %temp}, %fd1151;
	}
	mov.b64 	%fd1151, {%r1210, %r1209};

$L__BB7_456:
	setp.eq.f64 	%p480, %fd1148, 0d0000000000000000;
	@%p480 bra 	$L__BB7_460;
	bra.uni 	$L__BB7_457;

$L__BB7_460:
	setp.lt.s32 	%p483, %r3, 0;
	mov.u32 	%r1211, 0;
	selp.b32 	%r1212, %r347, 0, %p14;
	or.b32  	%r1213, %r1212, 2146435072;
	selp.b32 	%r1214, %r1213, %r1212, %p483;
	mov.b64 	%fd1151, {%r1211, %r1214};
	bra.uni 	$L__BB7_461;

$L__BB7_457:
	setp.gt.s32 	%p481, %r347, -1;
	@%p481 bra 	$L__BB7_461;

	mov.f64 	%fd1018, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1019, %fd1018;
	setp.eq.f64 	%p482, %fd1019, 0d4000000000000000;
	@%p482 bra 	$L__BB7_461;

	mov.f64 	%fd1151, 0dFFF8000000000000;

$L__BB7_461:
	add.rn.f64 	%fd1021, %fd1148, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1215}, %fd1021;
	}
	and.b32  	%r1216, %r1215, 2146435072;
	setp.ne.s32 	%p485, %r1216, 2146435072;
	@%p485 bra 	$L__BB7_468;

	setp.gtu.f64 	%p486, %fd331, 0d7FF0000000000000;
	@%p486 bra 	$L__BB7_467;
	bra.uni 	$L__BB7_463;

$L__BB7_467:
	mov.f64 	%fd1023, 0d4000000000000000;
	add.rn.f64 	%fd1151, %fd1148, %fd1023;
	bra.uni 	$L__BB7_468;

$L__BB7_463:
	setp.eq.s32 	%p487, %r181, 2146435072;
	mov.f64 	%fd1022, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1217, %temp}, %fd1022;
	}
	setp.eq.s32 	%p488, %r1217, 0;
	and.pred  	%p489, %p487, %p488;
	@%p489 bra 	$L__BB7_466;
	bra.uni 	$L__BB7_464;

$L__BB7_466:
	setp.lt.s32 	%p495, %r3, 0;
	mov.u32 	%r1222, 0;
	setp.gt.f64 	%p496, %fd331, 0d3FF0000000000000;
	selp.b32 	%r1223, 2146435072, 0, %p496;
	xor.b32  	%r1224, %r1223, 2146435072;
	selp.b32 	%r1225, %r1224, %r1223, %p495;
	setp.eq.f64 	%p497, %fd1148, 0dBFF0000000000000;
	selp.b32 	%r1226, 1072693248, %r1225, %p497;
	mov.b64 	%fd1151, {%r1222, %r1226};
	bra.uni 	$L__BB7_468;

$L__BB7_464:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1218, %temp}, %fd1148;
	}
	and.b32  	%r1219, %r347, 2147483647;
	setp.ne.s32 	%p490, %r1219, 2146435072;
	setp.ne.s32 	%p491, %r1218, 0;
	or.pred  	%p492, %p490, %p491;
	@%p492 bra 	$L__BB7_468;

	setp.ne.s32 	%p493, %r181, 1071644672;
	and.pred  	%p494, %p493, %p11;
	selp.b32 	%r1220, %r183, %r182, %p494;
	mov.u32 	%r1221, 0;
	mov.b64 	%fd1151, {%r1221, %r1220};

$L__BB7_468:
	setp.eq.f64 	%p498, %fd1148, 0d3FF0000000000000;
	selp.f64 	%fd341, 0d3FF0000000000000, %fd1151, %p498;
	mul.rn.f32 	%f670, %f229, 0f3F22F983;
	cvt.rni.s32.f32 	%r1415, %f670;
	cvt.rn.f32.s32 	%f671, %r1415;
	mov.f32 	%f672, 0fBFC90FDA;
	fma.rn.f32 	%f673, %f671, %f672, %f229;
	mov.f32 	%f674, 0fB3A22168;
	fma.rn.f32 	%f675, %f671, %f674, %f673;
	mov.f32 	%f676, 0fA7C234C5;
	fma.rn.f32 	%f812, %f671, %f676, %f675;
	abs.f32 	%f232, %f229;
	setp.ltu.f32 	%p499, %f232, 0f47CE4780;
	add.s64 	%rd104, %rd8, 24;
	@%p499 bra 	$L__BB7_476;

	setp.eq.f32 	%p500, %f232, 0f7F800000;
	@%p500 bra 	$L__BB7_475;
	bra.uni 	$L__BB7_470;

$L__BB7_475:
	mov.f32 	%f679, 0f00000000;
	mul.rn.f32 	%f812, %f229, %f679;
	mov.u32 	%r1415, 0;
	bra.uni 	$L__BB7_476;

$L__BB7_470:
	mov.b32 	%r349, %f229;
	bfe.u32 	%r1227, %r349, 23, 8;
	add.s32 	%r350, %r1227, -128;
	shl.b32 	%r1228, %r349, 8;
	or.b32  	%r351, %r1228, -2147483648;
	shr.u32 	%r352, %r350, 5;
	mov.u64 	%rd483, 0;
	mov.u64 	%rd484, %rd483;

$L__BB7_471:
	.pragma "nounroll";
	shl.b64 	%rd406, %rd483, 2;
	mov.u64 	%rd407, __cudart_i2opi_f;
	add.s64 	%rd408, %rd407, %rd406;
	ld.global.nc.u32 	%r1229, [%rd408];
	mad.wide.u32 	%rd409, %r1229, %r351, %rd484;
	shr.u64 	%rd484, %rd409, 32;
	add.s64 	%rd410, %rd8, %rd406;
	st.local.u32 	[%rd410], %rd409;
	cvt.u32.u64 	%r1230, %rd483;
	add.s32 	%r1231, %r1230, 1;
	cvt.s64.s32 	%rd483, %r1231;
	setp.ne.s32 	%p501, %r1231, 6;
	@%p501 bra 	$L__BB7_471;

	st.local.u32 	[%rd104], %rd484;
	mov.u32 	%r1232, 4;
	sub.s32 	%r353, %r1232, %r352;
	mov.u32 	%r1233, 6;
	sub.s32 	%r1234, %r1233, %r352;
	mul.wide.s32 	%rd411, %r1234, 4;
	add.s64 	%rd412, %rd8, %rd411;
	ld.local.u32 	%r1413, [%rd412];
	ld.local.u32 	%r1414, [%rd412+-4];
	and.b32  	%r356, %r350, 31;
	setp.eq.s32 	%p502, %r356, 0;
	@%p502 bra 	$L__BB7_474;

	mov.u32 	%r1235, 32;
	sub.s32 	%r1236, %r1235, %r356;
	shr.u32 	%r1237, %r1414, %r1236;
	shl.b32 	%r1238, %r1413, %r356;
	add.s32 	%r1413, %r1237, %r1238;
	mul.wide.s32 	%rd413, %r353, 4;
	add.s64 	%rd414, %rd8, %rd413;
	ld.local.u32 	%r1239, [%rd414];
	shr.u32 	%r1240, %r1239, %r1236;
	shl.b32 	%r1241, %r1414, %r356;
	add.s32 	%r1414, %r1240, %r1241;

$L__BB7_474:
	and.b32  	%r1242, %r349, -2147483648;
	shr.u32 	%r1243, %r1414, 30;
	shl.b32 	%r1244, %r1413, 2;
	or.b32  	%r1245, %r1243, %r1244;
	shr.u32 	%r1246, %r1245, 31;
	shr.u32 	%r1247, %r1413, 30;
	add.s32 	%r1248, %r1246, %r1247;
	neg.s32 	%r1249, %r1248;
	setp.eq.s32 	%p503, %r1242, 0;
	selp.b32 	%r1415, %r1248, %r1249, %p503;
	setp.ne.s32 	%p504, %r1246, 0;
	xor.b32  	%r1250, %r1242, -2147483648;
	selp.b32 	%r1251, %r1250, %r1242, %p504;
	selp.b32 	%r1252, -1, 0, %p504;
	xor.b32  	%r1253, %r1245, %r1252;
	shl.b32 	%r1254, %r1414, 2;
	xor.b32  	%r1255, %r1254, %r1252;
	cvt.u64.u32 	%rd415, %r1253;
	cvt.u64.u32 	%rd416, %r1255;
	bfi.b64 	%rd417, %rd415, %rd416, 32, 32;
	cvt.rn.f64.s64 	%fd1024, %rd417;
	mul.rn.f64 	%fd1025, %fd1024, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f677, %fd1025;
	setp.eq.s32 	%p505, %r1251, 0;
	neg.f32 	%f678, %f677;
	selp.f32 	%f812, %f677, %f678, %p505;

$L__BB7_476:
	add.s32 	%r363, %r1415, 1;
	and.b32  	%r364, %r363, 1;
	setp.eq.s32 	%p506, %r364, 0;
	selp.f32 	%f236, %f812, 0f3F800000, %p506;
	mul.rn.f32 	%f237, %f812, %f812;
	mov.f32 	%f813, 0fB94D4153;
	@%p506 bra 	$L__BB7_478;

	mov.f32 	%f681, 0fBAB607ED;
	mov.f32 	%f682, 0f37CBAC00;
	fma.rn.f32 	%f813, %f682, %f237, %f681;

$L__BB7_478:
	selp.f32 	%f683, 0f3C0885E4, 0f3D2AAABB, %p506;
	fma.rn.f32 	%f684, %f813, %f237, %f683;
	selp.f32 	%f685, 0fBE2AAAA8, 0fBEFFFFFF, %p506;
	fma.rn.f32 	%f686, %f684, %f237, %f685;
	mov.f32 	%f687, 0f00000000;
	fma.rn.f32 	%f688, %f237, %f236, %f687;
	fma.rn.f32 	%f814, %f686, %f688, %f236;
	and.b32  	%r1257, %r363, 2;
	setp.eq.s32 	%p508, %r1257, 0;
	@%p508 bra 	$L__BB7_480;

	mov.f32 	%f690, 0fBF800000;
	fma.rn.f32 	%f814, %f814, %f690, %f687;

$L__BB7_480:
	mul.rn.f32 	%f691, %f230, 0f3F22F983;
	cvt.rni.s32.f32 	%r1418, %f691;
	cvt.rn.f32.s32 	%f692, %r1418;
	mov.f32 	%f693, 0fBFC90FDA;
	fma.rn.f32 	%f694, %f692, %f693, %f230;
	mov.f32 	%f695, 0fB3A22168;
	fma.rn.f32 	%f696, %f692, %f695, %f694;
	mov.f32 	%f697, 0fA7C234C5;
	fma.rn.f32 	%f815, %f692, %f697, %f696;
	abs.f32 	%f244, %f230;
	setp.ltu.f32 	%p509, %f244, 0f47CE4780;
	@%p509 bra 	$L__BB7_488;

	setp.eq.f32 	%p510, %f244, 0f7F800000;
	@%p510 bra 	$L__BB7_487;
	bra.uni 	$L__BB7_482;

$L__BB7_487:
	mov.f32 	%f700, 0f00000000;
	mul.rn.f32 	%f815, %f230, %f700;
	mov.u32 	%r1418, 0;
	bra.uni 	$L__BB7_488;

$L__BB7_482:
	mov.b32 	%r366, %f230;
	bfe.u32 	%r1258, %r366, 23, 8;
	add.s32 	%r367, %r1258, -128;
	shl.b32 	%r1259, %r366, 8;
	or.b32  	%r368, %r1259, -2147483648;
	shr.u32 	%r369, %r367, 5;
	mov.u64 	%rd485, 0;
	mov.u64 	%rd486, %rd485;

$L__BB7_483:
	.pragma "nounroll";
	shl.b64 	%rd420, %rd485, 2;
	mov.u64 	%rd421, __cudart_i2opi_f;
	add.s64 	%rd422, %rd421, %rd420;
	ld.global.nc.u32 	%r1260, [%rd422];
	mad.wide.u32 	%rd423, %r1260, %r368, %rd486;
	shr.u64 	%rd486, %rd423, 32;
	add.s64 	%rd424, %rd8, %rd420;
	st.local.u32 	[%rd424], %rd423;
	cvt.u32.u64 	%r1261, %rd485;
	add.s32 	%r1262, %r1261, 1;
	cvt.s64.s32 	%rd485, %r1262;
	setp.ne.s32 	%p511, %r1262, 6;
	@%p511 bra 	$L__BB7_483;

	st.local.u32 	[%rd104], %rd486;
	mov.u32 	%r1263, 4;
	sub.s32 	%r370, %r1263, %r369;
	mov.u32 	%r1264, 6;
	sub.s32 	%r1265, %r1264, %r369;
	mul.wide.s32 	%rd425, %r1265, 4;
	add.s64 	%rd426, %rd8, %rd425;
	ld.local.u32 	%r1416, [%rd426];
	ld.local.u32 	%r1417, [%rd426+-4];
	and.b32  	%r373, %r367, 31;
	setp.eq.s32 	%p512, %r373, 0;
	@%p512 bra 	$L__BB7_486;

	mov.u32 	%r1266, 32;
	sub.s32 	%r1267, %r1266, %r373;
	shr.u32 	%r1268, %r1417, %r1267;
	shl.b32 	%r1269, %r1416, %r373;
	add.s32 	%r1416, %r1268, %r1269;
	mul.wide.s32 	%rd427, %r370, 4;
	add.s64 	%rd428, %rd8, %rd427;
	ld.local.u32 	%r1270, [%rd428];
	shr.u32 	%r1271, %r1270, %r1267;
	shl.b32 	%r1272, %r1417, %r373;
	add.s32 	%r1417, %r1271, %r1272;

$L__BB7_486:
	and.b32  	%r1273, %r366, -2147483648;
	shr.u32 	%r1274, %r1417, 30;
	shl.b32 	%r1275, %r1416, 2;
	or.b32  	%r1276, %r1274, %r1275;
	shr.u32 	%r1277, %r1276, 31;
	shr.u32 	%r1278, %r1416, 30;
	add.s32 	%r1279, %r1277, %r1278;
	neg.s32 	%r1280, %r1279;
	setp.eq.s32 	%p513, %r1273, 0;
	selp.b32 	%r1418, %r1279, %r1280, %p513;
	setp.ne.s32 	%p514, %r1277, 0;
	xor.b32  	%r1281, %r1273, -2147483648;
	selp.b32 	%r1282, %r1281, %r1273, %p514;
	selp.b32 	%r1283, -1, 0, %p514;
	xor.b32  	%r1284, %r1276, %r1283;
	shl.b32 	%r1285, %r1417, 2;
	xor.b32  	%r1286, %r1285, %r1283;
	cvt.u64.u32 	%rd429, %r1284;
	cvt.u64.u32 	%rd430, %r1286;
	bfi.b64 	%rd431, %rd429, %rd430, 32, 32;
	cvt.rn.f64.s64 	%fd1026, %rd431;
	mul.rn.f64 	%fd1027, %fd1026, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f698, %fd1027;
	setp.eq.s32 	%p515, %r1282, 0;
	neg.f32 	%f699, %f698;
	selp.f32 	%f815, %f698, %f699, %p515;

$L__BB7_488:
	add.s32 	%r380, %r1418, 1;
	and.b32  	%r381, %r380, 1;
	setp.eq.s32 	%p516, %r381, 0;
	selp.f32 	%f248, %f815, 0f3F800000, %p516;
	mul.rn.f32 	%f249, %f815, %f815;
	mov.f32 	%f816, 0fB94D4153;
	@%p516 bra 	$L__BB7_490;

	mov.f32 	%f702, 0fBAB607ED;
	mov.f32 	%f703, 0f37CBAC00;
	fma.rn.f32 	%f816, %f703, %f249, %f702;

$L__BB7_490:
	selp.f32 	%f704, 0f3C0885E4, 0f3D2AAABB, %p516;
	fma.rn.f32 	%f705, %f816, %f249, %f704;
	selp.f32 	%f706, 0fBE2AAAA8, 0fBEFFFFFF, %p516;
	fma.rn.f32 	%f707, %f705, %f249, %f706;
	mov.f32 	%f708, 0f00000000;
	fma.rn.f32 	%f709, %f249, %f248, %f708;
	fma.rn.f32 	%f817, %f707, %f709, %f248;
	and.b32  	%r1288, %r380, 2;
	setp.eq.s32 	%p518, %r1288, 0;
	@%p518 bra 	$L__BB7_492;

	mov.f32 	%f711, 0fBF800000;
	fma.rn.f32 	%f817, %f817, %f711, %f708;

$L__BB7_492:
	mul.rn.f32 	%f255, %f814, %f817;
	cvt.f64.f32 	%fd1028, %f819;
	mul.rn.f64 	%fd1029, %fd1028, 0d400921FB54442D18;
	div.rn.f64 	%fd1030, %fd1029, 0d4066800000000000;
	cvt.rn.f32.f64 	%f712, %fd1030;
	cvt.f64.f32 	%fd1031, %f786;
	mul.rn.f64 	%fd1032, %fd1031, 0d400921FB54442D18;
	div.rn.f64 	%fd1033, %fd1032, 0d4066800000000000;
	cvt.rn.f32.f64 	%f713, %fd1033;
	sub.rn.f32 	%f714, %f713, %f712;
	cvt.f64.f32 	%fd1034, %f714;
	mul.rn.f64 	%fd342, %fd1034, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1289, %temp}, %fd342;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1290}, %fd342;
	}
	and.b32  	%r1291, %r1290, 2147483647;
	setp.eq.s32 	%p519, %r1291, 2146435072;
	setp.eq.s32 	%p520, %r1289, 0;
	and.pred  	%p521, %p520, %p519;
	@%p521 bra 	$L__BB7_495;
	bra.uni 	$L__BB7_493;

$L__BB7_495:
	mov.f64 	%fd1044, 0d0000000000000000;
	mul.rn.f64 	%fd1152, %fd342, %fd1044;
	mov.u32 	%r1419, 0;
	bra.uni 	$L__BB7_496;

$L__BB7_493:
	mul.rn.f64 	%fd1035, %fd342, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1419, %fd1035;
	st.local.u32 	[%rd8], %r1419;
	cvt.rn.f64.s32 	%fd1036, %r1419;
	neg.f64 	%fd1037, %fd1036;
	mov.f64 	%fd1038, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1039, %fd1037, %fd1038, %fd342;
	mov.f64 	%fd1040, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1041, %fd1037, %fd1040, %fd1039;
	mov.f64 	%fd1042, 0d397B839A252049C0;
	fma.rn.f64 	%fd1152, %fd1037, %fd1042, %fd1041;
	abs.f64 	%fd1043, %fd342;
	setp.ltu.f64 	%p522, %fd1043, 0d41E0000000000000;
	@%p522 bra 	$L__BB7_496;

	{ // callseq 98, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd342;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1152, [retval0+0];
	} // callseq 98
	ld.local.u32 	%r1419, [%rd8];

$L__BB7_496:
	and.b32  	%r1293, %r1419, 1;
	shl.b32 	%r1294, %r1419, 3;
	and.b32  	%r1295, %r1294, 8;
	setp.eq.s32 	%p523, %r1293, 0;
	selp.f64 	%fd1045, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p523;
	mul.wide.s32 	%rd433, %r1295, 8;
	add.s64 	%rd435, %rd186, %rd433;
	ld.global.nc.f64 	%fd1046, [%rd435+8];
	mul.rn.f64 	%fd347, %fd1152, %fd1152;
	fma.rn.f64 	%fd1047, %fd1045, %fd347, %fd1046;
	ld.global.nc.f64 	%fd1048, [%rd435+16];
	fma.rn.f64 	%fd1049, %fd1047, %fd347, %fd1048;
	ld.global.nc.f64 	%fd1050, [%rd435+24];
	fma.rn.f64 	%fd1051, %fd1049, %fd347, %fd1050;
	ld.global.nc.f64 	%fd1052, [%rd435+32];
	fma.rn.f64 	%fd1053, %fd1051, %fd347, %fd1052;
	ld.global.nc.f64 	%fd1054, [%rd435+40];
	fma.rn.f64 	%fd1055, %fd1053, %fd347, %fd1054;
	ld.global.nc.f64 	%fd1056, [%rd435+48];
	fma.rn.f64 	%fd348, %fd1055, %fd347, %fd1056;
	fma.rn.f64 	%fd1154, %fd348, %fd1152, %fd1152;
	@%p523 bra 	$L__BB7_498;

	mov.f64 	%fd1057, 0d3FF0000000000000;
	fma.rn.f64 	%fd1154, %fd348, %fd347, %fd1057;

$L__BB7_498:
	and.b32  	%r1296, %r1419, 2;
	setp.eq.s32 	%p524, %r1296, 0;
	@%p524 bra 	$L__BB7_500;

	mov.f64 	%fd1058, 0d0000000000000000;
	mov.f64 	%fd1059, 0dBFF0000000000000;
	fma.rn.f64 	%fd1154, %fd1154, %fd1059, %fd1058;

$L__BB7_500:
	abs.f64 	%fd354, %fd1154;
	{ // callseq 99, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd354;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1157, [retval0+0];
	} // callseq 99
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r385}, %fd1154;
	}
	setp.lt.s32 	%p525, %r385, 0;
	and.pred  	%p12, %p525, %p14;
	not.pred 	%p527, %p12;
	@%p527 bra 	$L__BB7_502;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1297}, %fd1157;
	}
	xor.b32  	%r1298, %r1297, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1299, %temp}, %fd1157;
	}
	mov.b64 	%fd1157, {%r1299, %r1298};

$L__BB7_502:
	setp.eq.f64 	%p528, %fd1154, 0d0000000000000000;
	@%p528 bra 	$L__BB7_506;
	bra.uni 	$L__BB7_503;

$L__BB7_506:
	setp.lt.s32 	%p531, %r3, 0;
	mov.u32 	%r1300, 0;
	selp.b32 	%r1301, %r385, 0, %p14;
	or.b32  	%r1302, %r1301, 2146435072;
	selp.b32 	%r1303, %r1302, %r1301, %p531;
	mov.b64 	%fd1157, {%r1300, %r1303};
	bra.uni 	$L__BB7_507;

$L__BB7_503:
	setp.gt.s32 	%p529, %r385, -1;
	@%p529 bra 	$L__BB7_507;

	mov.f64 	%fd1060, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1061, %fd1060;
	setp.eq.f64 	%p530, %fd1061, 0d4000000000000000;
	@%p530 bra 	$L__BB7_507;

	mov.f64 	%fd1157, 0dFFF8000000000000;

$L__BB7_507:
	add.rn.f64 	%fd1063, %fd1154, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1304}, %fd1063;
	}
	and.b32  	%r1305, %r1304, 2146435072;
	setp.ne.s32 	%p533, %r1305, 2146435072;
	@%p533 bra 	$L__BB7_514;

	setp.gtu.f64 	%p534, %fd354, 0d7FF0000000000000;
	@%p534 bra 	$L__BB7_513;
	bra.uni 	$L__BB7_509;

$L__BB7_513:
	mov.f64 	%fd1065, 0d4000000000000000;
	add.rn.f64 	%fd1157, %fd1154, %fd1065;
	bra.uni 	$L__BB7_514;

$L__BB7_509:
	setp.eq.s32 	%p535, %r181, 2146435072;
	mov.f64 	%fd1064, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1306, %temp}, %fd1064;
	}
	setp.eq.s32 	%p536, %r1306, 0;
	and.pred  	%p537, %p535, %p536;
	@%p537 bra 	$L__BB7_512;
	bra.uni 	$L__BB7_510;

$L__BB7_512:
	setp.lt.s32 	%p543, %r3, 0;
	mov.u32 	%r1311, 0;
	setp.gt.f64 	%p544, %fd354, 0d3FF0000000000000;
	selp.b32 	%r1312, 2146435072, 0, %p544;
	xor.b32  	%r1313, %r1312, 2146435072;
	selp.b32 	%r1314, %r1313, %r1312, %p543;
	setp.eq.f64 	%p545, %fd1154, 0dBFF0000000000000;
	selp.b32 	%r1315, 1072693248, %r1314, %p545;
	mov.b64 	%fd1157, {%r1311, %r1315};
	bra.uni 	$L__BB7_514;

$L__BB7_510:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1307, %temp}, %fd1154;
	}
	and.b32  	%r1308, %r385, 2147483647;
	setp.ne.s32 	%p538, %r1308, 2146435072;
	setp.ne.s32 	%p539, %r1307, 0;
	or.pred  	%p540, %p538, %p539;
	@%p540 bra 	$L__BB7_514;

	setp.ne.s32 	%p541, %r181, 1071644672;
	and.pred  	%p542, %p541, %p12;
	selp.b32 	%r1309, %r183, %r182, %p542;
	mov.u32 	%r1310, 0;
	mov.b64 	%fd1157, {%r1310, %r1309};

$L__BB7_514:
	setp.eq.f64 	%p546, %fd1154, 0d3FF0000000000000;
	mov.f64 	%fd1066, 0d3FF0000000000000;
	selp.f64 	%fd1067, 0d3FF0000000000000, %fd1157, %p546;
	cvt.f64.f32 	%fd1068, %f255;
	mul.rn.f64 	%fd1069, %fd1067, %fd1068;
	add.rn.f64 	%fd1070, %fd341, %fd1069;
	cvt.rn.f32.f64 	%f715, %fd1070;
	sqrt.rn.f32 	%f256, %f715;
	cvt.f64.f32 	%fd1071, %f715;
	sub.rn.f64 	%fd1072, %fd1066, %fd1071;
	sqrt.rn.f64 	%fd1073, %fd1072;
	cvt.rn.f32.f64 	%f257, %fd1073;
	abs.f32 	%f258, %f257;
	abs.f32 	%f259, %f256;
	setp.eq.f32 	%p547, %f258, 0f00000000;
	setp.eq.f32 	%p548, %f259, 0f00000000;
	and.pred  	%p549, %p547, %p548;
	@%p549 bra 	$L__BB7_518;
	bra.uni 	$L__BB7_515;

$L__BB7_518:
	mov.b32 	%r1326, %f257;
	shr.s32 	%r1327, %r1326, 31;
	and.b32  	%r1328, %r1327, 1078530011;
	mov.b32 	%r1329, %f256;
	and.b32  	%r1330, %r1329, -2147483648;
	or.b32  	%r1331, %r1328, %r1330;
	mov.b32 	%f818, %r1331;
	bra.uni 	$L__BB7_519;

$L__BB7_515:
	setp.eq.f32 	%p550, %f258, 0f7F800000;
	setp.eq.f32 	%p551, %f259, 0f7F800000;
	and.pred  	%p552, %p550, %p551;
	@%p552 bra 	$L__BB7_517;
	bra.uni 	$L__BB7_516;

$L__BB7_517:
	mov.b32 	%r1321, %f257;
	setp.lt.s32 	%p556, %r1321, 0;
	selp.b32 	%r1322, 1075235812, 1061752795, %p556;
	mov.b32 	%r1323, %f256;
	and.b32  	%r1324, %r1323, -2147483648;
	or.b32  	%r1325, %r1322, %r1324;
	mov.b32 	%f818, %r1325;
	bra.uni 	$L__BB7_519;

$L__BB7_516:
	max.f32 	%f716, %f259, %f258;
	min.f32 	%f717, %f259, %f258;
	div.rn.f32 	%f718, %f717, %f716;
	mul.rn.f32 	%f719, %f718, %f718;
	mov.f32 	%f720, 0fC0B59883;
	mov.f32 	%f721, 0fBF52C7EA;
	fma.rn.f32 	%f722, %f719, %f721, %f720;
	mov.f32 	%f723, 0fC0D21907;
	fma.rn.f32 	%f724, %f722, %f719, %f723;
	mul.rn.f32 	%f725, %f719, %f724;
	mul.rn.f32 	%f726, %f718, %f725;
	add.rn.f32 	%f727, %f719, 0f41355DC0;
	mov.f32 	%f728, 0f41E6BD60;
	fma.rn.f32 	%f729, %f727, %f719, %f728;
	mov.f32 	%f730, 0f419D92C8;
	fma.rn.f32 	%f731, %f729, %f719, %f730;
	rcp.rn.f32 	%f732, %f731;
	fma.rn.f32 	%f733, %f726, %f732, %f718;
	mov.f32 	%f734, 0f3FC90FDB;
	sub.rn.f32 	%f735, %f734, %f733;
	setp.gt.f32 	%p553, %f259, %f258;
	selp.f32 	%f736, %f735, %f733, %p553;
	mov.b32 	%r1316, %f257;
	setp.lt.s32 	%p554, %r1316, 0;
	mov.f32 	%f737, 0f40490FDB;
	sub.rn.f32 	%f738, %f737, %f736;
	selp.f32 	%f739, %f738, %f736, %p554;
	mov.b32 	%r1317, %f739;
	mov.b32 	%r1318, %f256;
	and.b32  	%r1319, %r1318, -2147483648;
	or.b32  	%r1320, %r1319, %r1317;
	mov.b32 	%f740, %r1320;
	add.rn.f32 	%f741, %f258, %f259;
	setp.le.f32 	%p555, %f741, 0f7F800000;
	selp.f32 	%f818, %f740, %f741, %p555;

$L__BB7_519:
	add.rn.f32 	%f742, %f818, %f818;
	mul.rn.f32 	%f743, %f742, 0f4AC2A532;
	setp.lt.f32 	%p557, %f743, %f266;
	@%p557 bra 	$L__BB7_523;

$L__BB7_522:
	ld.param.u32 	%r1336, [bd09_to_wgs84_exact_cuda_float_param_5];
	add.s32 	%r1378, %r1378, 1;
	setp.lt.s32 	%p560, %r1378, %r1336;
	mov.f32 	%f819, %f786;
	mov.f32 	%f820, %f785;
	@%p560 bra 	$L__BB7_224;

$L__BB7_523:
	mov.u32 	%r1335, %tid.x;
	mov.u32 	%r1334, %ntid.x;
	mov.u32 	%r1333, %ctaid.x;
	mad.lo.s32 	%r1332, %r1333, %r1334, %r1335;
	mul.wide.s32 	%rd442, %r1332, 4;
	ld.param.u64 	%rd441, [bd09_to_wgs84_exact_cuda_float_param_7];
	cvta.to.global.u64 	%rd440, %rd441;
	add.s64 	%rd439, %rd440, %rd442;
	ld.param.u64 	%rd438, [bd09_to_wgs84_exact_cuda_float_param_6];
	cvta.to.global.u64 	%rd437, %rd438;
	add.s64 	%rd436, %rd437, %rd442;
	st.global.f32 	[%rd436], %f819;
	st.global.f32 	[%rd439], %f820;

$L__BB7_524:
	ret;

}
	// .globl	bd09_to_gcj02_exact_cuda_float
.visible .entry bd09_to_gcj02_exact_cuda_float(
	.param .u32 bd09_to_gcj02_exact_cuda_float_param_0,
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_1,
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_2,
	.param .f32 bd09_to_gcj02_exact_cuda_float_param_3,
	.param .u8 bd09_to_gcj02_exact_cuda_float_param_4,
	.param .u32 bd09_to_gcj02_exact_cuda_float_param_5,
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_6,
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_7
)
{
	.local .align 4 .b8 	__local_depot8[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<291>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<487>;
	.reg .b32 	%r<737>;
	.reg .f64 	%fd<271>;
	.reg .b64 	%rd<237>;


	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r198, [bd09_to_gcj02_exact_cuda_float_param_0];
	ld.param.u64 	%rd57, [bd09_to_gcj02_exact_cuda_float_param_1];
	ld.param.u64 	%rd58, [bd09_to_gcj02_exact_cuda_float_param_2];
	ld.param.f32 	%f162, [bd09_to_gcj02_exact_cuda_float_param_3];
	ld.param.u32 	%r197, [bd09_to_gcj02_exact_cuda_float_param_5];
	add.u64 	%rd61, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd2, %SPL, 0;
	add.u64 	%rd3, %SPL, 0;
	mov.u32 	%r199, %ntid.x;
	mov.u32 	%r200, %ctaid.x;
	mov.u32 	%r201, %tid.x;
	mad.lo.s32 	%r1, %r200, %r199, %r201;
	setp.ge.s32 	%p7, %r1, %r198;
	@%p7 bra 	$L__BB8_244;

	cvta.to.global.u64 	%rd65, %rd57;
	mul.wide.s32 	%rd66, %r1, 4;
	add.s64 	%rd67, %rd65, %rd66;
	cvta.to.global.u64 	%rd68, %rd58;
	add.s64 	%rd69, %rd68, %rd66;
	ld.global.f32 	%f1, [%rd67];
	cvt.f64.f32 	%fd93, %f1;
	add.rn.f64 	%fd94, %fd93, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f2, %fd94;
	ld.global.f32 	%f3, [%rd69];
	cvt.f64.f32 	%fd95, %f3;
	add.rn.f64 	%fd96, %fd95, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f4, %fd96;
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd97, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd97;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p8, %r4, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 100, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd249, [retval0+0];
	} // callseq 100
	setp.lt.s32 	%p9, %r2, 0;
	and.pred  	%p1, %p9, %p8;
	not.pred 	%p10, %p1;
	@%p10 bra 	$L__BB8_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd249;
	}
	xor.b32  	%r203, %r202, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r204, %temp}, %fd249;
	}
	mov.b64 	%fd249, {%r204, %r203};

$L__BB8_3:
	setp.eq.f32 	%p11, %f2, 0f00000000;
	@%p11 bra 	$L__BB8_7;
	bra.uni 	$L__BB8_4;

$L__BB8_7:
	selp.b32 	%r205, %r2, 0, %p8;
	mov.u32 	%r206, 0;
	or.b32  	%r207, %r205, 2146435072;
	setp.lt.s32 	%p15, %r3, 0;
	selp.b32 	%r208, %r207, %r205, %p15;
	mov.b64 	%fd249, {%r206, %r208};
	bra.uni 	$L__BB8_8;

$L__BB8_4:
	setp.gt.s32 	%p12, %r2, -1;
	@%p12 bra 	$L__BB8_8;

	mov.f64 	%fd98, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd99, %fd98;
	setp.eq.f64 	%p13, %fd99, 0d4000000000000000;
	@%p13 bra 	$L__BB8_8;

	mov.f64 	%fd249, 0dFFF8000000000000;

$L__BB8_8:
	add.rn.f64 	%fd101, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd101;
	}
	and.b32  	%r210, %r209, 2146435072;
	setp.ne.s32 	%p16, %r210, 2146435072;
	@%p16 bra 	$L__BB8_15;

	setp.gtu.f64 	%p17, %fd2, 0d7FF0000000000000;
	@%p17 bra 	$L__BB8_14;
	bra.uni 	$L__BB8_10;

$L__BB8_14:
	mov.f64 	%fd103, 0d4000000000000000;
	add.rn.f64 	%fd249, %fd1, %fd103;
	bra.uni 	$L__BB8_15;

$L__BB8_10:
	mov.f64 	%fd102, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r211, %temp}, %fd102;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p18, %r5, 2146435072;
	setp.eq.s32 	%p19, %r211, 0;
	and.pred  	%p20, %p18, %p19;
	@%p20 bra 	$L__BB8_13;
	bra.uni 	$L__BB8_11;

$L__BB8_13:
	setp.gt.f64 	%p27, %fd2, 0d3FF0000000000000;
	selp.b32 	%r218, 2146435072, 0, %p27;
	mov.u32 	%r219, 0;
	xor.b32  	%r220, %r218, 2146435072;
	setp.lt.s32 	%p28, %r3, 0;
	selp.b32 	%r221, %r220, %r218, %p28;
	setp.eq.f32 	%p29, %f2, 0fBF800000;
	selp.b32 	%r222, 1072693248, %r221, %p29;
	mov.b64 	%fd249, {%r219, %r222};
	bra.uni 	$L__BB8_15;

$L__BB8_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r212, %temp}, %fd1;
	}
	and.b32  	%r213, %r2, 2147483647;
	setp.ne.s32 	%p21, %r213, 2146435072;
	setp.ne.s32 	%p22, %r212, 0;
	or.pred  	%p23, %p21, %p22;
	@%p23 bra 	$L__BB8_15;

	setp.gt.s32 	%p24, %r3, -1;
	selp.b32 	%r214, 2146435072, 0, %p24;
	mov.u32 	%r215, 0;
	setp.ne.s32 	%p25, %r5, 1071644672;
	and.pred  	%p26, %p25, %p1;
	or.b32  	%r216, %r214, -2147483648;
	selp.b32 	%r217, %r216, %r214, %p26;
	mov.b64 	%fd249, {%r215, %r217};

$L__BB8_15:
	cvt.f64.f32 	%fd12, %f4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 101, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd252, [retval0+0];
	} // callseq 101
	setp.lt.s32 	%p30, %r6, 0;
	and.pred  	%p2, %p30, %p8;
	not.pred 	%p32, %p2;
	@%p32 bra 	$L__BB8_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r223}, %fd252;
	}
	xor.b32  	%r224, %r223, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r225, %temp}, %fd252;
	}
	mov.b64 	%fd252, {%r225, %r224};

$L__BB8_17:
	setp.eq.f32 	%p33, %f4, 0f00000000;
	@%p33 bra 	$L__BB8_21;
	bra.uni 	$L__BB8_18;

$L__BB8_21:
	selp.b32 	%r226, %r6, 0, %p8;
	mov.u32 	%r227, 0;
	or.b32  	%r228, %r226, 2146435072;
	setp.lt.s32 	%p37, %r3, 0;
	selp.b32 	%r229, %r228, %r226, %p37;
	mov.b64 	%fd252, {%r227, %r229};
	bra.uni 	$L__BB8_22;

$L__BB8_18:
	setp.gt.s32 	%p34, %r6, -1;
	@%p34 bra 	$L__BB8_22;

	mov.f64 	%fd104, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd105, %fd104;
	setp.eq.f64 	%p35, %fd105, 0d4000000000000000;
	@%p35 bra 	$L__BB8_22;

	mov.f64 	%fd252, 0dFFF8000000000000;

$L__BB8_22:
	add.rn.f64 	%fd107, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r230}, %fd107;
	}
	and.b32  	%r231, %r230, 2146435072;
	setp.ne.s32 	%p38, %r231, 2146435072;
	@%p38 bra 	$L__BB8_29;

	setp.gtu.f64 	%p39, %fd13, 0d7FF0000000000000;
	@%p39 bra 	$L__BB8_28;
	bra.uni 	$L__BB8_24;

$L__BB8_28:
	mov.f64 	%fd109, 0d4000000000000000;
	add.rn.f64 	%fd252, %fd12, %fd109;
	bra.uni 	$L__BB8_29;

$L__BB8_24:
	mov.f64 	%fd108, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r232, %temp}, %fd108;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p40, %r7, 2146435072;
	setp.eq.s32 	%p41, %r232, 0;
	and.pred  	%p42, %p40, %p41;
	@%p42 bra 	$L__BB8_27;
	bra.uni 	$L__BB8_25;

$L__BB8_27:
	setp.gt.f64 	%p49, %fd13, 0d3FF0000000000000;
	selp.b32 	%r239, 2146435072, 0, %p49;
	mov.u32 	%r240, 0;
	xor.b32  	%r241, %r239, 2146435072;
	setp.lt.s32 	%p50, %r3, 0;
	selp.b32 	%r242, %r241, %r239, %p50;
	setp.eq.f32 	%p51, %f4, 0fBF800000;
	selp.b32 	%r243, 1072693248, %r242, %p51;
	mov.b64 	%fd252, {%r240, %r243};
	bra.uni 	$L__BB8_29;

$L__BB8_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd12;
	}
	and.b32  	%r234, %r6, 2147483647;
	setp.ne.s32 	%p43, %r234, 2146435072;
	setp.ne.s32 	%p44, %r233, 0;
	or.pred  	%p45, %p43, %p44;
	@%p45 bra 	$L__BB8_29;

	setp.gt.s32 	%p46, %r3, -1;
	selp.b32 	%r235, 2146435072, 0, %p46;
	mov.u32 	%r236, 0;
	setp.ne.s32 	%p47, %r7, 1071644672;
	and.pred  	%p48, %p47, %p2;
	or.b32  	%r237, %r235, -2147483648;
	selp.b32 	%r238, %r237, %r235, %p48;
	mov.b64 	%fd252, {%r236, %r238};

$L__BB8_29:
	setp.eq.f32 	%p52, %f4, 0f3F800000;
	selp.f64 	%fd110, 0d3FF0000000000000, %fd252, %p52;
	setp.eq.f32 	%p53, %f2, 0f3F800000;
	selp.f64 	%fd111, 0d3FF0000000000000, %fd249, %p53;
	add.rn.f64 	%fd23, %fd111, %fd110;
	mul.rn.f32 	%f5, %f4, 0f42517084;
	mul.rn.f32 	%f163, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r702, %f163;
	cvt.rn.f32.s32 	%f164, %r702;
	mov.f32 	%f165, 0fBFC90FDA;
	fma.rn.f32 	%f166, %f164, %f165, %f5;
	mov.f32 	%f167, 0fB3A22168;
	fma.rn.f32 	%f168, %f164, %f167, %f166;
	mov.f32 	%f169, 0fA7C234C5;
	fma.rn.f32 	%f450, %f164, %f169, %f168;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p54, %f7, 0f47CE4780;
	add.s64 	%rd7, %rd2, 24;
	@%p54 bra 	$L__BB8_37;

	setp.eq.f32 	%p55, %f7, 0f7F800000;
	@%p55 bra 	$L__BB8_36;
	bra.uni 	$L__BB8_31;

$L__BB8_36:
	mov.f32 	%f172, 0f00000000;
	mul.rn.f32 	%f450, %f5, %f172;
	mov.u32 	%r702, 0;
	bra.uni 	$L__BB8_37;

$L__BB8_31:
	mov.b32 	%r9, %f5;
	bfe.u32 	%r245, %r9, 23, 8;
	add.s32 	%r10, %r245, -128;
	shl.b32 	%r246, %r9, 8;
	or.b32  	%r11, %r246, -2147483648;
	shr.u32 	%r12, %r10, 5;
	mov.u64 	%rd215, 0;
	mov.u32 	%r699, 0;
	mov.u64 	%rd214, __cudart_i2opi_f;
	mov.u64 	%rd213, %rd2;

$L__BB8_32:
	.pragma "nounroll";
	ld.global.nc.u32 	%r247, [%rd214];
	mad.wide.u32 	%rd74, %r247, %r11, %rd215;
	shr.u64 	%rd215, %rd74, 32;
	st.local.u32 	[%rd213], %rd74;
	add.s64 	%rd214, %rd214, 4;
	add.s64 	%rd213, %rd213, 4;
	add.s32 	%r699, %r699, 1;
	setp.ne.s32 	%p56, %r699, 6;
	@%p56 bra 	$L__BB8_32;

	st.local.u32 	[%rd7], %rd215;
	mov.u32 	%r248, 4;
	sub.s32 	%r15, %r248, %r12;
	mov.u32 	%r249, 6;
	sub.s32 	%r250, %r249, %r12;
	mul.wide.s32 	%rd75, %r250, 4;
	add.s64 	%rd76, %rd2, %rd75;
	ld.local.u32 	%r700, [%rd76];
	ld.local.u32 	%r701, [%rd76+-4];
	and.b32  	%r18, %r10, 31;
	setp.eq.s32 	%p57, %r18, 0;
	@%p57 bra 	$L__BB8_35;

	mov.u32 	%r251, 32;
	sub.s32 	%r252, %r251, %r18;
	shr.u32 	%r253, %r701, %r252;
	shl.b32 	%r254, %r700, %r18;
	add.s32 	%r700, %r253, %r254;
	mul.wide.s32 	%rd77, %r15, 4;
	add.s64 	%rd78, %rd2, %rd77;
	ld.local.u32 	%r255, [%rd78];
	shr.u32 	%r256, %r255, %r252;
	shl.b32 	%r257, %r701, %r18;
	add.s32 	%r701, %r256, %r257;

$L__BB8_35:
	and.b32  	%r258, %r9, -2147483648;
	shr.u32 	%r259, %r701, 30;
	shl.b32 	%r260, %r700, 2;
	or.b32  	%r261, %r259, %r260;
	shr.u32 	%r262, %r261, 31;
	shr.u32 	%r263, %r700, 30;
	add.s32 	%r264, %r262, %r263;
	neg.s32 	%r265, %r264;
	setp.eq.s32 	%p58, %r258, 0;
	selp.b32 	%r702, %r264, %r265, %p58;
	setp.ne.s32 	%p59, %r262, 0;
	xor.b32  	%r266, %r258, -2147483648;
	selp.b32 	%r267, %r266, %r258, %p59;
	selp.b32 	%r268, -1, 0, %p59;
	xor.b32  	%r269, %r261, %r268;
	shl.b32 	%r270, %r701, 2;
	xor.b32  	%r271, %r270, %r268;
	cvt.u64.u32 	%rd79, %r269;
	cvt.u64.u32 	%rd80, %r271;
	bfi.b64 	%rd81, %rd79, %rd80, 32, 32;
	cvt.rn.f64.s64 	%fd112, %rd81;
	mul.rn.f64 	%fd113, %fd112, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f170, %fd113;
	setp.eq.s32 	%p60, %r267, 0;
	neg.f32 	%f171, %f170;
	selp.f32 	%f450, %f170, %f171, %p60;

$L__BB8_37:
	and.b32  	%r25, %r702, 1;
	setp.eq.s32 	%p61, %r25, 0;
	selp.f32 	%f11, %f450, 0f3F800000, %p61;
	mul.rn.f32 	%f12, %f450, %f450;
	mov.f32 	%f451, 0fB94D4153;
	@%p61 bra 	$L__BB8_39;

	mov.f32 	%f174, 0fBAB607ED;
	mov.f32 	%f175, 0f37CBAC00;
	fma.rn.f32 	%f451, %f175, %f12, %f174;

$L__BB8_39:
	selp.f32 	%f176, 0f3C0885E4, 0f3D2AAABB, %p61;
	fma.rn.f32 	%f177, %f451, %f12, %f176;
	selp.f32 	%f178, 0fBE2AAAA8, 0fBEFFFFFF, %p61;
	fma.rn.f32 	%f179, %f177, %f12, %f178;
	mov.f32 	%f180, 0f00000000;
	fma.rn.f32 	%f181, %f12, %f11, %f180;
	fma.rn.f32 	%f452, %f179, %f181, %f11;
	and.b32  	%r273, %r702, 2;
	setp.eq.s32 	%p63, %r273, 0;
	@%p63 bra 	$L__BB8_41;

	mov.f32 	%f183, 0fBF800000;
	fma.rn.f32 	%f452, %f452, %f183, %f180;

$L__BB8_41:
	cvt.f64.f32 	%fd114, %f452;
	mul.rn.f64 	%fd115, %fd114, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd116, %fd23;
	add.rn.f64 	%fd117, %fd116, %fd115;
	cvt.rn.f32.f64 	%f18, %fd117;
	abs.f32 	%f19, %f2;
	setp.eq.f32 	%p64, %f19, 0f00000000;
	abs.f32 	%f20, %f4;
	setp.eq.f32 	%p65, %f20, 0f00000000;
	and.pred  	%p66, %p64, %p65;
	@%p66 bra 	$L__BB8_45;
	bra.uni 	$L__BB8_42;

$L__BB8_45:
	mov.b32 	%r284, %f2;
	shr.s32 	%r285, %r284, 31;
	and.b32  	%r286, %r285, 1078530011;
	mov.b32 	%r287, %f4;
	and.b32  	%r288, %r287, -2147483648;
	or.b32  	%r289, %r286, %r288;
	mov.b32 	%f453, %r289;
	bra.uni 	$L__BB8_46;

$L__BB8_42:
	setp.eq.f32 	%p67, %f19, 0f7F800000;
	setp.eq.f32 	%p68, %f20, 0f7F800000;
	and.pred  	%p69, %p67, %p68;
	@%p69 bra 	$L__BB8_44;
	bra.uni 	$L__BB8_43;

$L__BB8_44:
	mov.b32 	%r279, %f2;
	setp.lt.s32 	%p73, %r279, 0;
	selp.b32 	%r280, 1075235812, 1061752795, %p73;
	mov.b32 	%r281, %f4;
	and.b32  	%r282, %r281, -2147483648;
	or.b32  	%r283, %r280, %r282;
	mov.b32 	%f453, %r283;
	bra.uni 	$L__BB8_46;

$L__BB8_43:
	max.f32 	%f184, %f20, %f19;
	min.f32 	%f185, %f20, %f19;
	div.rn.f32 	%f186, %f185, %f184;
	mul.rn.f32 	%f187, %f186, %f186;
	mov.f32 	%f188, 0fC0B59883;
	mov.f32 	%f189, 0fBF52C7EA;
	fma.rn.f32 	%f190, %f187, %f189, %f188;
	mov.f32 	%f191, 0fC0D21907;
	fma.rn.f32 	%f192, %f190, %f187, %f191;
	mul.rn.f32 	%f193, %f187, %f192;
	mul.rn.f32 	%f194, %f186, %f193;
	add.rn.f32 	%f195, %f187, 0f41355DC0;
	mov.f32 	%f196, 0f41E6BD60;
	fma.rn.f32 	%f197, %f195, %f187, %f196;
	mov.f32 	%f198, 0f419D92C8;
	fma.rn.f32 	%f199, %f197, %f187, %f198;
	rcp.rn.f32 	%f200, %f199;
	fma.rn.f32 	%f201, %f194, %f200, %f186;
	mov.f32 	%f202, 0f3FC90FDB;
	sub.rn.f32 	%f203, %f202, %f201;
	setp.gt.f32 	%p70, %f20, %f19;
	selp.f32 	%f204, %f203, %f201, %p70;
	mov.b32 	%r274, %f2;
	setp.lt.s32 	%p71, %r274, 0;
	mov.f32 	%f205, 0f40490FDB;
	sub.rn.f32 	%f206, %f205, %f204;
	selp.f32 	%f207, %f206, %f204, %p71;
	mov.b32 	%r275, %f207;
	mov.b32 	%r276, %f4;
	and.b32  	%r277, %r276, -2147483648;
	or.b32  	%r278, %r277, %r275;
	mov.b32 	%f208, %r278;
	add.rn.f32 	%f209, %f19, %f20;
	setp.le.f32 	%p72, %f209, 0f7F800000;
	selp.f32 	%f453, %f208, %f209, %p72;

$L__BB8_46:
	mul.rn.f32 	%f25, %f2, 0f42517084;
	mul.rn.f32 	%f210, %f25, 0f3F22F983;
	cvt.rni.s32.f32 	%r706, %f210;
	cvt.rn.f32.s32 	%f211, %r706;
	mov.f32 	%f212, 0fBFC90FDA;
	fma.rn.f32 	%f213, %f211, %f212, %f25;
	mov.f32 	%f214, 0fB3A22168;
	fma.rn.f32 	%f215, %f211, %f214, %f213;
	mov.f32 	%f216, 0fA7C234C5;
	fma.rn.f32 	%f454, %f211, %f216, %f215;
	abs.f32 	%f27, %f25;
	setp.ltu.f32 	%p74, %f27, 0f47CE4780;
	@%p74 bra 	$L__BB8_54;

	setp.eq.f32 	%p75, %f27, 0f7F800000;
	@%p75 bra 	$L__BB8_53;
	bra.uni 	$L__BB8_48;

$L__BB8_53:
	mov.f32 	%f219, 0f00000000;
	mul.rn.f32 	%f454, %f25, %f219;
	mov.u32 	%r706, 0;
	bra.uni 	$L__BB8_54;

$L__BB8_48:
	mov.b32 	%r27, %f25;
	bfe.u32 	%r291, %r27, 23, 8;
	add.s32 	%r28, %r291, -128;
	shl.b32 	%r292, %r27, 8;
	or.b32  	%r29, %r292, -2147483648;
	shr.u32 	%r30, %r28, 5;
	mov.u64 	%rd218, 0;
	mov.u32 	%r703, 0;
	mov.u64 	%rd217, __cudart_i2opi_f;
	mov.u64 	%rd216, %rd2;

$L__BB8_49:
	.pragma "nounroll";
	ld.global.nc.u32 	%r293, [%rd217];
	mad.wide.u32 	%rd84, %r293, %r29, %rd218;
	shr.u64 	%rd218, %rd84, 32;
	st.local.u32 	[%rd216], %rd84;
	add.s64 	%rd217, %rd217, 4;
	add.s64 	%rd216, %rd216, 4;
	add.s32 	%r703, %r703, 1;
	setp.ne.s32 	%p76, %r703, 6;
	@%p76 bra 	$L__BB8_49;

	st.local.u32 	[%rd7], %rd218;
	mov.u32 	%r294, 4;
	sub.s32 	%r33, %r294, %r30;
	mov.u32 	%r295, 6;
	sub.s32 	%r296, %r295, %r30;
	mul.wide.s32 	%rd85, %r296, 4;
	add.s64 	%rd86, %rd2, %rd85;
	ld.local.u32 	%r704, [%rd86];
	ld.local.u32 	%r705, [%rd86+-4];
	and.b32  	%r36, %r28, 31;
	setp.eq.s32 	%p77, %r36, 0;
	@%p77 bra 	$L__BB8_52;

	mov.u32 	%r297, 32;
	sub.s32 	%r298, %r297, %r36;
	shr.u32 	%r299, %r705, %r298;
	shl.b32 	%r300, %r704, %r36;
	add.s32 	%r704, %r299, %r300;
	mul.wide.s32 	%rd87, %r33, 4;
	add.s64 	%rd88, %rd2, %rd87;
	ld.local.u32 	%r301, [%rd88];
	shr.u32 	%r302, %r301, %r298;
	shl.b32 	%r303, %r705, %r36;
	add.s32 	%r705, %r302, %r303;

$L__BB8_52:
	and.b32  	%r304, %r27, -2147483648;
	shr.u32 	%r305, %r705, 30;
	shl.b32 	%r306, %r704, 2;
	or.b32  	%r307, %r305, %r306;
	shr.u32 	%r308, %r307, 31;
	shr.u32 	%r309, %r704, 30;
	add.s32 	%r310, %r308, %r309;
	neg.s32 	%r311, %r310;
	setp.eq.s32 	%p78, %r304, 0;
	selp.b32 	%r706, %r310, %r311, %p78;
	setp.ne.s32 	%p79, %r308, 0;
	xor.b32  	%r312, %r304, -2147483648;
	selp.b32 	%r313, %r312, %r304, %p79;
	selp.b32 	%r314, -1, 0, %p79;
	xor.b32  	%r315, %r307, %r314;
	shl.b32 	%r316, %r705, 2;
	xor.b32  	%r317, %r316, %r314;
	cvt.u64.u32 	%rd89, %r315;
	cvt.u64.u32 	%rd90, %r317;
	bfi.b64 	%rd91, %rd89, %rd90, 32, 32;
	cvt.rn.f64.s64 	%fd118, %rd91;
	mul.rn.f64 	%fd119, %fd118, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f217, %fd119;
	setp.eq.s32 	%p80, %r313, 0;
	neg.f32 	%f218, %f217;
	selp.f32 	%f454, %f217, %f218, %p80;

$L__BB8_54:
	add.s32 	%r43, %r706, 1;
	and.b32  	%r44, %r43, 1;
	setp.eq.s32 	%p81, %r44, 0;
	selp.f32 	%f31, %f454, 0f3F800000, %p81;
	mul.rn.f32 	%f32, %f454, %f454;
	mov.f32 	%f455, 0fB94D4153;
	@%p81 bra 	$L__BB8_56;

	mov.f32 	%f221, 0fBAB607ED;
	mov.f32 	%f222, 0f37CBAC00;
	fma.rn.f32 	%f455, %f222, %f32, %f221;

$L__BB8_56:
	selp.f32 	%f223, 0f3C0885E4, 0f3D2AAABB, %p81;
	fma.rn.f32 	%f224, %f455, %f32, %f223;
	selp.f32 	%f225, 0fBE2AAAA8, 0fBEFFFFFF, %p81;
	fma.rn.f32 	%f226, %f224, %f32, %f225;
	mov.f32 	%f227, 0f00000000;
	fma.rn.f32 	%f228, %f32, %f31, %f227;
	fma.rn.f32 	%f456, %f226, %f228, %f31;
	and.b32  	%r319, %r43, 2;
	setp.eq.s32 	%p83, %r319, 0;
	@%p83 bra 	$L__BB8_58;

	mov.f32 	%f230, 0fBF800000;
	fma.rn.f32 	%f456, %f456, %f230, %f227;

$L__BB8_58:
	cvt.f64.f32 	%fd120, %f456;
	mul.rn.f64 	%fd121, %fd120, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd122, %f453;
	add.rn.f64 	%fd123, %fd122, %fd121;
	cvt.rn.f32.f64 	%f38, %fd123;
	mul.rn.f32 	%f231, %f38, 0f3F22F983;
	cvt.rni.s32.f32 	%r714, %f231;
	cvt.rn.f32.s32 	%f232, %r714;
	mov.f32 	%f233, 0fBFC90FDA;
	fma.rn.f32 	%f234, %f232, %f233, %f38;
	mov.f32 	%f235, 0fB3A22168;
	fma.rn.f32 	%f236, %f232, %f235, %f234;
	mov.f32 	%f237, 0fA7C234C5;
	fma.rn.f32 	%f460, %f232, %f237, %f236;
	abs.f32 	%f40, %f38;
	setp.ltu.f32 	%p84, %f40, 0f47CE4780;
	mov.u32 	%r710, %r714;
	mov.f32 	%f457, %f460;
	@%p84 bra 	$L__BB8_66;

	setp.eq.f32 	%p85, %f40, 0f7F800000;
	@%p85 bra 	$L__BB8_65;
	bra.uni 	$L__BB8_60;

$L__BB8_65:
	mov.f32 	%f240, 0f00000000;
	mul.rn.f32 	%f457, %f38, %f240;
	mov.u32 	%r710, 0;
	bra.uni 	$L__BB8_66;

$L__BB8_60:
	mov.b32 	%r46, %f38;
	bfe.u32 	%r321, %r46, 23, 8;
	add.s32 	%r47, %r321, -128;
	shl.b32 	%r322, %r46, 8;
	or.b32  	%r48, %r322, -2147483648;
	shr.u32 	%r49, %r47, 5;
	mov.u64 	%rd221, 0;
	mov.u32 	%r707, 0;
	mov.u64 	%rd220, __cudart_i2opi_f;
	mov.u64 	%rd219, %rd2;

$L__BB8_61:
	.pragma "nounroll";
	ld.global.nc.u32 	%r323, [%rd220];
	mad.wide.u32 	%rd94, %r323, %r48, %rd221;
	shr.u64 	%rd221, %rd94, 32;
	st.local.u32 	[%rd219], %rd94;
	add.s64 	%rd220, %rd220, 4;
	add.s64 	%rd219, %rd219, 4;
	add.s32 	%r707, %r707, 1;
	setp.ne.s32 	%p86, %r707, 6;
	@%p86 bra 	$L__BB8_61;

	st.local.u32 	[%rd7], %rd221;
	mov.u32 	%r324, 4;
	sub.s32 	%r52, %r324, %r49;
	mov.u32 	%r325, 6;
	sub.s32 	%r326, %r325, %r49;
	mul.wide.s32 	%rd95, %r326, 4;
	add.s64 	%rd96, %rd2, %rd95;
	ld.local.u32 	%r708, [%rd96];
	ld.local.u32 	%r709, [%rd96+-4];
	and.b32  	%r55, %r47, 31;
	setp.eq.s32 	%p87, %r55, 0;
	@%p87 bra 	$L__BB8_64;

	mov.u32 	%r327, 32;
	sub.s32 	%r328, %r327, %r55;
	shr.u32 	%r329, %r709, %r328;
	shl.b32 	%r330, %r708, %r55;
	add.s32 	%r708, %r329, %r330;
	mul.wide.s32 	%rd97, %r52, 4;
	add.s64 	%rd98, %rd2, %rd97;
	ld.local.u32 	%r331, [%rd98];
	shr.u32 	%r332, %r331, %r328;
	shl.b32 	%r333, %r709, %r55;
	add.s32 	%r709, %r332, %r333;

$L__BB8_64:
	and.b32  	%r334, %r46, -2147483648;
	shr.u32 	%r335, %r709, 30;
	shl.b32 	%r336, %r708, 2;
	or.b32  	%r337, %r335, %r336;
	shr.u32 	%r338, %r337, 31;
	shr.u32 	%r339, %r708, 30;
	add.s32 	%r340, %r338, %r339;
	neg.s32 	%r341, %r340;
	setp.eq.s32 	%p88, %r334, 0;
	selp.b32 	%r710, %r340, %r341, %p88;
	setp.ne.s32 	%p89, %r338, 0;
	xor.b32  	%r342, %r334, -2147483648;
	selp.b32 	%r343, %r342, %r334, %p89;
	selp.b32 	%r344, -1, 0, %p89;
	xor.b32  	%r345, %r337, %r344;
	shl.b32 	%r346, %r709, 2;
	xor.b32  	%r347, %r346, %r344;
	cvt.u64.u32 	%rd99, %r345;
	cvt.u64.u32 	%rd100, %r347;
	bfi.b64 	%rd101, %rd99, %rd100, 32, 32;
	cvt.rn.f64.s64 	%fd124, %rd101;
	mul.rn.f64 	%fd125, %fd124, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f238, %fd125;
	setp.eq.s32 	%p90, %r343, 0;
	neg.f32 	%f239, %f238;
	selp.f32 	%f457, %f238, %f239, %p90;

$L__BB8_66:
	add.s32 	%r62, %r710, 1;
	and.b32  	%r63, %r62, 1;
	setp.eq.s32 	%p91, %r63, 0;
	selp.f32 	%f44, %f457, 0f3F800000, %p91;
	mul.rn.f32 	%f45, %f457, %f457;
	mov.f32 	%f458, 0fB94D4153;
	@%p91 bra 	$L__BB8_68;

	mov.f32 	%f242, 0fBAB607ED;
	mov.f32 	%f243, 0f37CBAC00;
	fma.rn.f32 	%f458, %f243, %f45, %f242;

$L__BB8_68:
	selp.f32 	%f244, 0f3C0885E4, 0f3D2AAABB, %p91;
	fma.rn.f32 	%f245, %f458, %f45, %f244;
	selp.f32 	%f246, 0fBE2AAAA8, 0fBEFFFFFF, %p91;
	fma.rn.f32 	%f247, %f245, %f45, %f246;
	mov.f32 	%f248, 0f00000000;
	fma.rn.f32 	%f249, %f45, %f44, %f248;
	fma.rn.f32 	%f459, %f247, %f249, %f44;
	and.b32  	%r349, %r62, 2;
	setp.eq.s32 	%p93, %r349, 0;
	@%p93 bra 	$L__BB8_70;

	mov.f32 	%f251, 0fBF800000;
	fma.rn.f32 	%f459, %f459, %f251, %f248;

$L__BB8_70:
	mul.rn.f32 	%f485, %f459, %f18;
	@%p84 bra 	$L__BB8_78;

	setp.eq.f32 	%p95, %f40, 0f7F800000;
	@%p95 bra 	$L__BB8_77;
	bra.uni 	$L__BB8_72;

$L__BB8_77:
	mov.f32 	%f254, 0f00000000;
	mul.rn.f32 	%f460, %f38, %f254;
	mov.u32 	%r714, 0;
	bra.uni 	$L__BB8_78;

$L__BB8_72:
	mov.b32 	%r64, %f38;
	bfe.u32 	%r351, %r64, 23, 8;
	add.s32 	%r65, %r351, -128;
	shl.b32 	%r352, %r64, 8;
	or.b32  	%r66, %r352, -2147483648;
	shr.u32 	%r67, %r65, 5;
	mov.u64 	%rd222, 0;
	mov.u32 	%r711, 0;
	mov.u64 	%rd105, __cudart_i2opi_f;
	mov.u64 	%rd223, %rd222;

$L__BB8_73:
	.pragma "nounroll";
	shl.b64 	%rd104, %rd222, 2;
	add.s64 	%rd106, %rd105, %rd104;
	ld.global.nc.u32 	%r353, [%rd106];
	mad.wide.u32 	%rd107, %r353, %r66, %rd223;
	shr.u64 	%rd223, %rd107, 32;
	add.s64 	%rd108, %rd2, %rd104;
	st.local.u32 	[%rd108], %rd107;
	add.s32 	%r711, %r711, 1;
	cvt.s64.s32 	%rd222, %r711;
	setp.ne.s32 	%p96, %r711, 6;
	@%p96 bra 	$L__BB8_73;

	st.local.u32 	[%rd7], %rd223;
	mov.u32 	%r354, 4;
	sub.s32 	%r70, %r354, %r67;
	mov.u32 	%r355, 6;
	sub.s32 	%r356, %r355, %r67;
	mul.wide.s32 	%rd109, %r356, 4;
	add.s64 	%rd110, %rd2, %rd109;
	ld.local.u32 	%r712, [%rd110];
	ld.local.u32 	%r713, [%rd110+-4];
	and.b32  	%r73, %r65, 31;
	setp.eq.s32 	%p97, %r73, 0;
	@%p97 bra 	$L__BB8_76;

	mov.u32 	%r357, 32;
	sub.s32 	%r358, %r357, %r73;
	shr.u32 	%r359, %r713, %r358;
	shl.b32 	%r360, %r712, %r73;
	add.s32 	%r712, %r359, %r360;
	mul.wide.s32 	%rd111, %r70, 4;
	add.s64 	%rd112, %rd2, %rd111;
	ld.local.u32 	%r361, [%rd112];
	shr.u32 	%r362, %r361, %r358;
	shl.b32 	%r363, %r713, %r73;
	add.s32 	%r713, %r362, %r363;

$L__BB8_76:
	and.b32  	%r364, %r64, -2147483648;
	shr.u32 	%r365, %r713, 30;
	shl.b32 	%r366, %r712, 2;
	or.b32  	%r367, %r365, %r366;
	shr.u32 	%r368, %r367, 31;
	shr.u32 	%r369, %r712, 30;
	add.s32 	%r370, %r368, %r369;
	neg.s32 	%r371, %r370;
	setp.eq.s32 	%p98, %r364, 0;
	selp.b32 	%r714, %r370, %r371, %p98;
	setp.ne.s32 	%p99, %r368, 0;
	xor.b32  	%r372, %r364, -2147483648;
	selp.b32 	%r373, %r372, %r364, %p99;
	selp.b32 	%r374, -1, 0, %p99;
	xor.b32  	%r375, %r367, %r374;
	shl.b32 	%r376, %r713, 2;
	xor.b32  	%r377, %r376, %r374;
	cvt.u64.u32 	%rd113, %r375;
	cvt.u64.u32 	%rd114, %r377;
	bfi.b64 	%rd115, %rd113, %rd114, 32, 32;
	cvt.rn.f64.s64 	%fd126, %rd115;
	mul.rn.f64 	%fd127, %fd126, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f252, %fd127;
	setp.eq.s32 	%p100, %r373, 0;
	neg.f32 	%f253, %f252;
	selp.f32 	%f460, %f252, %f253, %p100;

$L__BB8_78:
	and.b32  	%r80, %r714, 1;
	setp.eq.s32 	%p101, %r80, 0;
	selp.f32 	%f55, %f460, 0f3F800000, %p101;
	mul.rn.f32 	%f56, %f460, %f460;
	mov.f32 	%f461, 0fB94D4153;
	@%p101 bra 	$L__BB8_80;

	mov.f32 	%f256, 0fBAB607ED;
	mov.f32 	%f257, 0f37CBAC00;
	fma.rn.f32 	%f461, %f257, %f56, %f256;

$L__BB8_80:
	selp.f32 	%f258, 0f3C0885E4, 0f3D2AAABB, %p101;
	fma.rn.f32 	%f259, %f461, %f56, %f258;
	selp.f32 	%f260, 0fBE2AAAA8, 0fBEFFFFFF, %p101;
	fma.rn.f32 	%f261, %f259, %f56, %f260;
	mov.f32 	%f262, 0f00000000;
	fma.rn.f32 	%f263, %f56, %f55, %f262;
	fma.rn.f32 	%f462, %f261, %f263, %f55;
	and.b32  	%r379, %r714, 2;
	setp.eq.s32 	%p103, %r379, 0;
	@%p103 bra 	$L__BB8_82;

	mov.f32 	%f265, 0fBF800000;
	fma.rn.f32 	%f462, %f462, %f265, %f262;

$L__BB8_82:
	mul.rn.f32 	%f486, %f462, %f18;
	setp.lt.s32 	%p104, %r197, 1;
	@%p104 bra 	$L__BB8_243;

	and.b32  	%r81, %r3, 2147483647;
	setp.gt.s32 	%p105, %r3, -1;
	selp.b32 	%r82, 2146435072, 0, %p105;
	mov.u32 	%r715, 0;
	or.b32  	%r83, %r82, -2147483648;
	add.s64 	%rd30, %rd1, 24;
	mov.u64 	%rd116, __cudart_i2opi_f;
	mov.f32 	%f463, %f486;
	mov.f32 	%f464, %f485;

$L__BB8_84:
	mov.f32 	%f485, %f464;
	mov.f32 	%f486, %f463;
	cvt.f64.f32 	%fd24, %f485;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd24;
	}
	abs.f64 	%fd25, %fd24;
	{ // callseq 102, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd255, [retval0+0];
	} // callseq 102
	setp.lt.s32 	%p106, %r85, 0;
	and.pred  	%p3, %p106, %p8;
	not.pred 	%p108, %p3;
	@%p108 bra 	$L__BB8_86;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r381}, %fd255;
	}
	xor.b32  	%r382, %r381, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r383, %temp}, %fd255;
	}
	mov.b64 	%fd255, {%r383, %r382};

$L__BB8_86:
	setp.eq.f32 	%p109, %f485, 0f00000000;
	@%p109 bra 	$L__BB8_90;
	bra.uni 	$L__BB8_87;

$L__BB8_90:
	setp.lt.s32 	%p112, %r3, 0;
	mov.u32 	%r384, 0;
	selp.b32 	%r385, %r85, 0, %p8;
	or.b32  	%r386, %r385, 2146435072;
	selp.b32 	%r387, %r386, %r385, %p112;
	mov.b64 	%fd255, {%r384, %r387};
	bra.uni 	$L__BB8_91;

$L__BB8_87:
	setp.gt.s32 	%p110, %r85, -1;
	@%p110 bra 	$L__BB8_91;

	mov.f64 	%fd128, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd129, %fd128;
	setp.eq.f64 	%p111, %fd129, 0d4000000000000000;
	@%p111 bra 	$L__BB8_91;

	mov.f64 	%fd255, 0dFFF8000000000000;

$L__BB8_91:
	add.rn.f64 	%fd131, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r388}, %fd131;
	}
	and.b32  	%r389, %r388, 2146435072;
	setp.ne.s32 	%p114, %r389, 2146435072;
	@%p114 bra 	$L__BB8_98;

	setp.gtu.f64 	%p115, %fd25, 0d7FF0000000000000;
	@%p115 bra 	$L__BB8_97;
	bra.uni 	$L__BB8_93;

$L__BB8_97:
	mov.f64 	%fd133, 0d4000000000000000;
	add.rn.f64 	%fd255, %fd24, %fd133;
	bra.uni 	$L__BB8_98;

$L__BB8_93:
	setp.eq.s32 	%p116, %r81, 2146435072;
	mov.f64 	%fd132, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r390, %temp}, %fd132;
	}
	setp.eq.s32 	%p117, %r390, 0;
	and.pred  	%p118, %p116, %p117;
	@%p118 bra 	$L__BB8_96;
	bra.uni 	$L__BB8_94;

$L__BB8_96:
	setp.lt.s32 	%p124, %r3, 0;
	mov.u32 	%r395, 0;
	setp.gt.f64 	%p125, %fd25, 0d3FF0000000000000;
	selp.b32 	%r396, 2146435072, 0, %p125;
	xor.b32  	%r397, %r396, 2146435072;
	selp.b32 	%r398, %r397, %r396, %p124;
	setp.eq.f32 	%p126, %f485, 0fBF800000;
	selp.b32 	%r399, 1072693248, %r398, %p126;
	mov.b64 	%fd255, {%r395, %r399};
	bra.uni 	$L__BB8_98;

$L__BB8_94:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r391, %temp}, %fd24;
	}
	and.b32  	%r392, %r85, 2147483647;
	setp.ne.s32 	%p119, %r392, 2146435072;
	setp.ne.s32 	%p120, %r391, 0;
	or.pred  	%p121, %p119, %p120;
	@%p121 bra 	$L__BB8_98;

	setp.ne.s32 	%p122, %r81, 1071644672;
	and.pred  	%p123, %p122, %p3;
	selp.b32 	%r393, %r83, %r82, %p123;
	mov.u32 	%r394, 0;
	mov.b64 	%fd255, {%r394, %r393};

$L__BB8_98:
	cvt.f64.f32 	%fd35, %f486;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd35;
	}
	abs.f64 	%fd36, %fd35;
	{ // callseq 103, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd258, [retval0+0];
	} // callseq 103
	setp.lt.s32 	%p127, %r86, 0;
	and.pred  	%p4, %p127, %p8;
	not.pred 	%p129, %p4;
	@%p129 bra 	$L__BB8_100;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r400}, %fd258;
	}
	xor.b32  	%r401, %r400, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd258;
	}
	mov.b64 	%fd258, {%r402, %r401};

$L__BB8_100:
	setp.eq.f32 	%p130, %f486, 0f00000000;
	@%p130 bra 	$L__BB8_104;
	bra.uni 	$L__BB8_101;

$L__BB8_104:
	setp.lt.s32 	%p133, %r3, 0;
	mov.u32 	%r403, 0;
	selp.b32 	%r404, %r86, 0, %p8;
	or.b32  	%r405, %r404, 2146435072;
	selp.b32 	%r406, %r405, %r404, %p133;
	mov.b64 	%fd258, {%r403, %r406};
	bra.uni 	$L__BB8_105;

$L__BB8_101:
	setp.gt.s32 	%p131, %r86, -1;
	@%p131 bra 	$L__BB8_105;

	mov.f64 	%fd134, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd135, %fd134;
	setp.eq.f64 	%p132, %fd135, 0d4000000000000000;
	@%p132 bra 	$L__BB8_105;

	mov.f64 	%fd258, 0dFFF8000000000000;

$L__BB8_105:
	add.rn.f64 	%fd137, %fd35, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r407}, %fd137;
	}
	and.b32  	%r408, %r407, 2146435072;
	setp.ne.s32 	%p135, %r408, 2146435072;
	@%p135 bra 	$L__BB8_112;

	setp.gtu.f64 	%p136, %fd36, 0d7FF0000000000000;
	@%p136 bra 	$L__BB8_111;
	bra.uni 	$L__BB8_107;

$L__BB8_111:
	mov.f64 	%fd139, 0d4000000000000000;
	add.rn.f64 	%fd258, %fd35, %fd139;
	bra.uni 	$L__BB8_112;

$L__BB8_107:
	setp.eq.s32 	%p137, %r81, 2146435072;
	mov.f64 	%fd138, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd138;
	}
	setp.eq.s32 	%p138, %r409, 0;
	and.pred  	%p139, %p137, %p138;
	@%p139 bra 	$L__BB8_110;
	bra.uni 	$L__BB8_108;

$L__BB8_110:
	setp.lt.s32 	%p145, %r3, 0;
	mov.u32 	%r414, 0;
	setp.gt.f64 	%p146, %fd36, 0d3FF0000000000000;
	selp.b32 	%r415, 2146435072, 0, %p146;
	xor.b32  	%r416, %r415, 2146435072;
	selp.b32 	%r417, %r416, %r415, %p145;
	setp.eq.f32 	%p147, %f486, 0fBF800000;
	selp.b32 	%r418, 1072693248, %r417, %p147;
	mov.b64 	%fd258, {%r414, %r418};
	bra.uni 	$L__BB8_112;

$L__BB8_108:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r410, %temp}, %fd35;
	}
	and.b32  	%r411, %r86, 2147483647;
	setp.ne.s32 	%p140, %r411, 2146435072;
	setp.ne.s32 	%p141, %r410, 0;
	or.pred  	%p142, %p140, %p141;
	@%p142 bra 	$L__BB8_112;

	setp.ne.s32 	%p143, %r81, 1071644672;
	and.pred  	%p144, %p143, %p4;
	selp.b32 	%r412, %r83, %r82, %p144;
	mov.u32 	%r413, 0;
	mov.b64 	%fd258, {%r413, %r412};

$L__BB8_112:
	setp.eq.f32 	%p148, %f486, 0f3F800000;
	selp.f64 	%fd140, 0d3FF0000000000000, %fd258, %p148;
	setp.eq.f32 	%p149, %f485, 0f3F800000;
	selp.f64 	%fd141, 0d3FF0000000000000, %fd255, %p149;
	add.rn.f64 	%fd46, %fd141, %fd140;
	mul.rn.f32 	%f65, %f486, 0f42517084;
	mul.rn.f32 	%f266, %f65, 0f3F22F983;
	cvt.rni.s32.f32 	%r719, %f266;
	cvt.rn.f32.s32 	%f267, %r719;
	mov.f32 	%f268, 0fBFC90FDA;
	fma.rn.f32 	%f269, %f267, %f268, %f65;
	mov.f32 	%f270, 0fB3A22168;
	fma.rn.f32 	%f271, %f267, %f270, %f269;
	mov.f32 	%f272, 0fA7C234C5;
	fma.rn.f32 	%f465, %f267, %f272, %f271;
	abs.f32 	%f67, %f65;
	setp.ltu.f32 	%p150, %f67, 0f47CE4780;
	@%p150 bra 	$L__BB8_120;

	setp.eq.f32 	%p151, %f67, 0f7F800000;
	@%p151 bra 	$L__BB8_119;
	bra.uni 	$L__BB8_114;

$L__BB8_119:
	mov.f32 	%f275, 0f00000000;
	mul.rn.f32 	%f465, %f65, %f275;
	mov.u32 	%r719, 0;
	bra.uni 	$L__BB8_120;

$L__BB8_114:
	mov.b32 	%r88, %f65;
	bfe.u32 	%r420, %r88, 23, 8;
	add.s32 	%r89, %r420, -128;
	shl.b32 	%r421, %r88, 8;
	or.b32  	%r90, %r421, -2147483648;
	shr.u32 	%r91, %r89, 5;
	mov.u64 	%rd226, 0;
	mov.u32 	%r716, 0;
	mov.u64 	%rd224, %rd1;
	mov.u64 	%rd225, %rd116;

$L__BB8_115:
	.pragma "nounroll";
	ld.global.nc.u32 	%r422, [%rd225];
	mad.wide.u32 	%rd118, %r422, %r90, %rd226;
	shr.u64 	%rd226, %rd118, 32;
	st.local.u32 	[%rd224], %rd118;
	add.s64 	%rd225, %rd225, 4;
	add.s64 	%rd224, %rd224, 4;
	add.s32 	%r716, %r716, 1;
	setp.ne.s32 	%p152, %r716, 6;
	@%p152 bra 	$L__BB8_115;

	st.local.u32 	[%rd30], %rd226;
	mov.u32 	%r423, 4;
	sub.s32 	%r94, %r423, %r91;
	mov.u32 	%r424, 6;
	sub.s32 	%r425, %r424, %r91;
	mul.wide.s32 	%rd119, %r425, 4;
	add.s64 	%rd120, %rd1, %rd119;
	ld.local.u32 	%r717, [%rd120];
	ld.local.u32 	%r718, [%rd120+-4];
	and.b32  	%r97, %r89, 31;
	setp.eq.s32 	%p153, %r97, 0;
	@%p153 bra 	$L__BB8_118;

	mov.u32 	%r426, 32;
	sub.s32 	%r427, %r426, %r97;
	shr.u32 	%r428, %r718, %r427;
	shl.b32 	%r429, %r717, %r97;
	add.s32 	%r717, %r428, %r429;
	mul.wide.s32 	%rd121, %r94, 4;
	add.s64 	%rd122, %rd1, %rd121;
	ld.local.u32 	%r430, [%rd122];
	shr.u32 	%r431, %r430, %r427;
	shl.b32 	%r432, %r718, %r97;
	add.s32 	%r718, %r431, %r432;

$L__BB8_118:
	and.b32  	%r433, %r88, -2147483648;
	shr.u32 	%r434, %r718, 30;
	shl.b32 	%r435, %r717, 2;
	or.b32  	%r436, %r434, %r435;
	shr.u32 	%r437, %r436, 31;
	shr.u32 	%r438, %r717, 30;
	add.s32 	%r439, %r437, %r438;
	neg.s32 	%r440, %r439;
	setp.eq.s32 	%p154, %r433, 0;
	selp.b32 	%r719, %r439, %r440, %p154;
	setp.ne.s32 	%p155, %r437, 0;
	xor.b32  	%r441, %r433, -2147483648;
	selp.b32 	%r442, %r441, %r433, %p155;
	selp.b32 	%r443, -1, 0, %p155;
	xor.b32  	%r444, %r436, %r443;
	shl.b32 	%r445, %r718, 2;
	xor.b32  	%r446, %r445, %r443;
	cvt.u64.u32 	%rd123, %r444;
	cvt.u64.u32 	%rd124, %r446;
	bfi.b64 	%rd125, %rd123, %rd124, 32, 32;
	cvt.rn.f64.s64 	%fd142, %rd125;
	mul.rn.f64 	%fd143, %fd142, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f273, %fd143;
	setp.eq.s32 	%p156, %r442, 0;
	neg.f32 	%f274, %f273;
	selp.f32 	%f465, %f273, %f274, %p156;

$L__BB8_120:
	and.b32  	%r104, %r719, 1;
	setp.eq.s32 	%p157, %r104, 0;
	selp.f32 	%f71, %f465, 0f3F800000, %p157;
	mul.rn.f32 	%f72, %f465, %f465;
	mov.f32 	%f466, 0fB94D4153;
	@%p157 bra 	$L__BB8_122;

	mov.f32 	%f277, 0fBAB607ED;
	mov.f32 	%f278, 0f37CBAC00;
	fma.rn.f32 	%f466, %f278, %f72, %f277;

$L__BB8_122:
	selp.f32 	%f279, 0f3C0885E4, 0f3D2AAABB, %p157;
	fma.rn.f32 	%f280, %f466, %f72, %f279;
	selp.f32 	%f281, 0fBE2AAAA8, 0fBEFFFFFF, %p157;
	fma.rn.f32 	%f282, %f280, %f72, %f281;
	mov.f32 	%f283, 0f00000000;
	fma.rn.f32 	%f284, %f72, %f71, %f283;
	fma.rn.f32 	%f467, %f282, %f284, %f71;
	and.b32  	%r448, %r719, 2;
	setp.eq.s32 	%p159, %r448, 0;
	@%p159 bra 	$L__BB8_124;

	mov.f32 	%f286, 0fBF800000;
	fma.rn.f32 	%f467, %f467, %f286, %f283;

$L__BB8_124:
	cvt.f64.f32 	%fd144, %f467;
	mul.rn.f64 	%fd145, %fd144, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd146, %fd46;
	add.rn.f64 	%fd47, %fd146, %fd145;
	abs.f32 	%f78, %f485;
	setp.eq.f32 	%p160, %f78, 0f00000000;
	abs.f32 	%f79, %f486;
	setp.eq.f32 	%p161, %f79, 0f00000000;
	and.pred  	%p162, %p160, %p161;
	@%p162 bra 	$L__BB8_128;
	bra.uni 	$L__BB8_125;

$L__BB8_128:
	mov.b32 	%r459, %f485;
	shr.s32 	%r460, %r459, 31;
	and.b32  	%r461, %r460, 1078530011;
	mov.b32 	%r462, %f486;
	and.b32  	%r463, %r462, -2147483648;
	or.b32  	%r464, %r461, %r463;
	mov.b32 	%f468, %r464;
	bra.uni 	$L__BB8_129;

$L__BB8_125:
	setp.eq.f32 	%p163, %f78, 0f7F800000;
	setp.eq.f32 	%p164, %f79, 0f7F800000;
	and.pred  	%p165, %p163, %p164;
	@%p165 bra 	$L__BB8_127;
	bra.uni 	$L__BB8_126;

$L__BB8_127:
	mov.b32 	%r454, %f485;
	setp.lt.s32 	%p169, %r454, 0;
	selp.b32 	%r455, 1075235812, 1061752795, %p169;
	mov.b32 	%r456, %f486;
	and.b32  	%r457, %r456, -2147483648;
	or.b32  	%r458, %r455, %r457;
	mov.b32 	%f468, %r458;
	bra.uni 	$L__BB8_129;

$L__BB8_126:
	max.f32 	%f287, %f79, %f78;
	min.f32 	%f288, %f79, %f78;
	div.rn.f32 	%f289, %f288, %f287;
	mul.rn.f32 	%f290, %f289, %f289;
	mov.f32 	%f291, 0fC0B59883;
	mov.f32 	%f292, 0fBF52C7EA;
	fma.rn.f32 	%f293, %f290, %f292, %f291;
	mov.f32 	%f294, 0fC0D21907;
	fma.rn.f32 	%f295, %f293, %f290, %f294;
	mul.rn.f32 	%f296, %f290, %f295;
	mul.rn.f32 	%f297, %f289, %f296;
	add.rn.f32 	%f298, %f290, 0f41355DC0;
	mov.f32 	%f299, 0f41E6BD60;
	fma.rn.f32 	%f300, %f298, %f290, %f299;
	mov.f32 	%f301, 0f419D92C8;
	fma.rn.f32 	%f302, %f300, %f290, %f301;
	rcp.rn.f32 	%f303, %f302;
	fma.rn.f32 	%f304, %f297, %f303, %f289;
	mov.f32 	%f305, 0f3FC90FDB;
	sub.rn.f32 	%f306, %f305, %f304;
	setp.gt.f32 	%p166, %f79, %f78;
	selp.f32 	%f307, %f306, %f304, %p166;
	mov.b32 	%r449, %f485;
	setp.lt.s32 	%p167, %r449, 0;
	mov.f32 	%f308, 0f40490FDB;
	sub.rn.f32 	%f309, %f308, %f307;
	selp.f32 	%f310, %f309, %f307, %p167;
	mov.b32 	%r450, %f310;
	mov.b32 	%r451, %f486;
	and.b32  	%r452, %r451, -2147483648;
	or.b32  	%r453, %r452, %r450;
	mov.b32 	%f311, %r453;
	add.rn.f32 	%f312, %f78, %f79;
	setp.le.f32 	%p168, %f312, 0f7F800000;
	selp.f32 	%f468, %f311, %f312, %p168;

$L__BB8_129:
	mul.rn.f32 	%f84, %f485, 0f42517084;
	mul.rn.f32 	%f313, %f84, 0f3F22F983;
	cvt.rni.s32.f32 	%r722, %f313;
	cvt.rn.f32.s32 	%f314, %r722;
	mov.f32 	%f315, 0fBFC90FDA;
	fma.rn.f32 	%f316, %f314, %f315, %f84;
	mov.f32 	%f317, 0fB3A22168;
	fma.rn.f32 	%f318, %f314, %f317, %f316;
	mov.f32 	%f319, 0fA7C234C5;
	fma.rn.f32 	%f469, %f314, %f319, %f318;
	abs.f32 	%f86, %f84;
	setp.ltu.f32 	%p170, %f86, 0f47CE4780;
	@%p170 bra 	$L__BB8_137;

	setp.eq.f32 	%p171, %f86, 0f7F800000;
	@%p171 bra 	$L__BB8_136;
	bra.uni 	$L__BB8_131;

$L__BB8_136:
	mov.f32 	%f322, 0f00000000;
	mul.rn.f32 	%f469, %f84, %f322;
	mov.u32 	%r722, 0;
	bra.uni 	$L__BB8_137;

$L__BB8_131:
	mov.b32 	%r106, %f84;
	bfe.u32 	%r465, %r106, 23, 8;
	add.s32 	%r107, %r465, -128;
	shl.b32 	%r466, %r106, 8;
	or.b32  	%r108, %r466, -2147483648;
	shr.u32 	%r109, %r107, 5;
	mov.u64 	%rd227, 0;
	mov.u64 	%rd228, %rd227;

$L__BB8_132:
	.pragma "nounroll";
	shl.b64 	%rd128, %rd227, 2;
	mov.u64 	%rd129, __cudart_i2opi_f;
	add.s64 	%rd130, %rd129, %rd128;
	ld.global.nc.u32 	%r467, [%rd130];
	mad.wide.u32 	%rd131, %r467, %r108, %rd228;
	shr.u64 	%rd228, %rd131, 32;
	add.s64 	%rd132, %rd1, %rd128;
	st.local.u32 	[%rd132], %rd131;
	cvt.u32.u64 	%r468, %rd227;
	add.s32 	%r469, %r468, 1;
	cvt.s64.s32 	%rd227, %r469;
	setp.ne.s32 	%p172, %r469, 6;
	@%p172 bra 	$L__BB8_132;

	st.local.u32 	[%rd30], %rd228;
	mov.u32 	%r470, 4;
	sub.s32 	%r110, %r470, %r109;
	mov.u32 	%r471, 6;
	sub.s32 	%r472, %r471, %r109;
	mul.wide.s32 	%rd133, %r472, 4;
	add.s64 	%rd134, %rd1, %rd133;
	ld.local.u32 	%r720, [%rd134];
	ld.local.u32 	%r721, [%rd134+-4];
	and.b32  	%r113, %r107, 31;
	setp.eq.s32 	%p173, %r113, 0;
	@%p173 bra 	$L__BB8_135;

	mov.u32 	%r473, 32;
	sub.s32 	%r474, %r473, %r113;
	shr.u32 	%r475, %r721, %r474;
	shl.b32 	%r476, %r720, %r113;
	add.s32 	%r720, %r475, %r476;
	mul.wide.s32 	%rd135, %r110, 4;
	add.s64 	%rd136, %rd1, %rd135;
	ld.local.u32 	%r477, [%rd136];
	shr.u32 	%r478, %r477, %r474;
	shl.b32 	%r479, %r721, %r113;
	add.s32 	%r721, %r478, %r479;

$L__BB8_135:
	and.b32  	%r480, %r106, -2147483648;
	shr.u32 	%r481, %r721, 30;
	shl.b32 	%r482, %r720, 2;
	or.b32  	%r483, %r481, %r482;
	shr.u32 	%r484, %r483, 31;
	shr.u32 	%r485, %r720, 30;
	add.s32 	%r486, %r484, %r485;
	neg.s32 	%r487, %r486;
	setp.eq.s32 	%p174, %r480, 0;
	selp.b32 	%r722, %r486, %r487, %p174;
	setp.ne.s32 	%p175, %r484, 0;
	xor.b32  	%r488, %r480, -2147483648;
	selp.b32 	%r489, %r488, %r480, %p175;
	selp.b32 	%r490, -1, 0, %p175;
	xor.b32  	%r491, %r483, %r490;
	shl.b32 	%r492, %r721, 2;
	xor.b32  	%r493, %r492, %r490;
	cvt.u64.u32 	%rd137, %r491;
	cvt.u64.u32 	%rd138, %r493;
	bfi.b64 	%rd139, %rd137, %rd138, 32, 32;
	cvt.rn.f64.s64 	%fd147, %rd139;
	mul.rn.f64 	%fd148, %fd147, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f320, %fd148;
	setp.eq.s32 	%p176, %r489, 0;
	neg.f32 	%f321, %f320;
	selp.f32 	%f469, %f320, %f321, %p176;

$L__BB8_137:
	cvt.rn.f32.f64 	%f90, %fd47;
	add.s32 	%r120, %r722, 1;
	and.b32  	%r121, %r120, 1;
	setp.eq.s32 	%p177, %r121, 0;
	selp.f32 	%f91, %f469, 0f3F800000, %p177;
	mul.rn.f32 	%f92, %f469, %f469;
	mov.f32 	%f470, 0fB94D4153;
	@%p177 bra 	$L__BB8_139;

	mov.f32 	%f324, 0fBAB607ED;
	mov.f32 	%f325, 0f37CBAC00;
	fma.rn.f32 	%f470, %f325, %f92, %f324;

$L__BB8_139:
	selp.f32 	%f326, 0f3C0885E4, 0f3D2AAABB, %p177;
	fma.rn.f32 	%f327, %f470, %f92, %f326;
	selp.f32 	%f328, 0fBE2AAAA8, 0fBEFFFFFF, %p177;
	fma.rn.f32 	%f329, %f327, %f92, %f328;
	mov.f32 	%f330, 0f00000000;
	fma.rn.f32 	%f331, %f92, %f91, %f330;
	fma.rn.f32 	%f471, %f329, %f331, %f91;
	and.b32  	%r495, %r120, 2;
	setp.eq.s32 	%p179, %r495, 0;
	@%p179 bra 	$L__BB8_141;

	mov.f32 	%f333, 0fBF800000;
	fma.rn.f32 	%f471, %f471, %f333, %f330;

$L__BB8_141:
	cvt.f64.f32 	%fd149, %f471;
	mul.rn.f64 	%fd150, %fd149, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd151, %f468;
	add.rn.f64 	%fd152, %fd150, %fd151;
	cvt.rn.f32.f64 	%f98, %fd152;
	mul.rn.f32 	%f334, %f98, 0f3F22F983;
	cvt.rni.s32.f32 	%r728, %f334;
	cvt.rn.f32.s32 	%f335, %r728;
	mov.f32 	%f336, 0fBFC90FDA;
	fma.rn.f32 	%f337, %f335, %f336, %f98;
	mov.f32 	%f338, 0fB3A22168;
	fma.rn.f32 	%f339, %f335, %f338, %f337;
	mov.f32 	%f340, 0fA7C234C5;
	fma.rn.f32 	%f475, %f335, %f340, %f339;
	abs.f32 	%f100, %f98;
	setp.ltu.f32 	%p180, %f100, 0f47CE4780;
	mov.u32 	%r725, %r728;
	mov.f32 	%f472, %f475;
	@%p180 bra 	$L__BB8_149;

	setp.eq.f32 	%p181, %f100, 0f7F800000;
	@%p181 bra 	$L__BB8_148;
	bra.uni 	$L__BB8_143;

$L__BB8_148:
	mov.f32 	%f343, 0f00000000;
	mul.rn.f32 	%f472, %f98, %f343;
	mov.u32 	%r725, 0;
	bra.uni 	$L__BB8_149;

$L__BB8_143:
	mov.b32 	%r123, %f98;
	bfe.u32 	%r496, %r123, 23, 8;
	add.s32 	%r124, %r496, -128;
	shl.b32 	%r497, %r123, 8;
	or.b32  	%r125, %r497, -2147483648;
	shr.u32 	%r126, %r124, 5;
	mov.u64 	%rd229, 0;
	mov.u64 	%rd230, %rd229;

$L__BB8_144:
	.pragma "nounroll";
	shl.b64 	%rd142, %rd229, 2;
	mov.u64 	%rd143, __cudart_i2opi_f;
	add.s64 	%rd144, %rd143, %rd142;
	ld.global.nc.u32 	%r498, [%rd144];
	mad.wide.u32 	%rd145, %r498, %r125, %rd230;
	shr.u64 	%rd230, %rd145, 32;
	add.s64 	%rd146, %rd1, %rd142;
	st.local.u32 	[%rd146], %rd145;
	cvt.u32.u64 	%r499, %rd229;
	add.s32 	%r500, %r499, 1;
	cvt.s64.s32 	%rd229, %r500;
	setp.ne.s32 	%p182, %r500, 6;
	@%p182 bra 	$L__BB8_144;

	st.local.u32 	[%rd30], %rd230;
	mov.u32 	%r501, 4;
	sub.s32 	%r127, %r501, %r126;
	mov.u32 	%r502, 6;
	sub.s32 	%r503, %r502, %r126;
	mul.wide.s32 	%rd147, %r503, 4;
	add.s64 	%rd148, %rd1, %rd147;
	ld.local.u32 	%r723, [%rd148];
	ld.local.u32 	%r724, [%rd148+-4];
	and.b32  	%r130, %r124, 31;
	setp.eq.s32 	%p183, %r130, 0;
	@%p183 bra 	$L__BB8_147;

	mov.u32 	%r504, 32;
	sub.s32 	%r505, %r504, %r130;
	shr.u32 	%r506, %r724, %r505;
	shl.b32 	%r507, %r723, %r130;
	add.s32 	%r723, %r506, %r507;
	mul.wide.s32 	%rd149, %r127, 4;
	add.s64 	%rd150, %rd1, %rd149;
	ld.local.u32 	%r508, [%rd150];
	shr.u32 	%r509, %r508, %r505;
	shl.b32 	%r510, %r724, %r130;
	add.s32 	%r724, %r509, %r510;

$L__BB8_147:
	and.b32  	%r511, %r123, -2147483648;
	shr.u32 	%r512, %r724, 30;
	shl.b32 	%r513, %r723, 2;
	or.b32  	%r514, %r512, %r513;
	shr.u32 	%r515, %r514, 31;
	shr.u32 	%r516, %r723, 30;
	add.s32 	%r517, %r515, %r516;
	neg.s32 	%r518, %r517;
	setp.eq.s32 	%p184, %r511, 0;
	selp.b32 	%r725, %r517, %r518, %p184;
	setp.ne.s32 	%p185, %r515, 0;
	xor.b32  	%r519, %r511, -2147483648;
	selp.b32 	%r520, %r519, %r511, %p185;
	selp.b32 	%r521, -1, 0, %p185;
	xor.b32  	%r522, %r514, %r521;
	shl.b32 	%r523, %r724, 2;
	xor.b32  	%r524, %r523, %r521;
	cvt.u64.u32 	%rd151, %r522;
	cvt.u64.u32 	%rd152, %r524;
	bfi.b64 	%rd153, %rd151, %rd152, 32, 32;
	cvt.rn.f64.s64 	%fd153, %rd153;
	mul.rn.f64 	%fd154, %fd153, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f341, %fd154;
	setp.eq.s32 	%p186, %r520, 0;
	neg.f32 	%f342, %f341;
	selp.f32 	%f472, %f341, %f342, %p186;

$L__BB8_149:
	add.s32 	%r137, %r725, 1;
	and.b32  	%r138, %r137, 1;
	setp.eq.s32 	%p187, %r138, 0;
	selp.f32 	%f104, %f472, 0f3F800000, %p187;
	mul.rn.f32 	%f105, %f472, %f472;
	mov.f32 	%f473, 0fB94D4153;
	@%p187 bra 	$L__BB8_151;

	mov.f32 	%f345, 0fBAB607ED;
	mov.f32 	%f346, 0f37CBAC00;
	fma.rn.f32 	%f473, %f346, %f105, %f345;

$L__BB8_151:
	selp.f32 	%f347, 0f3C0885E4, 0f3D2AAABB, %p187;
	fma.rn.f32 	%f348, %f473, %f105, %f347;
	selp.f32 	%f349, 0fBE2AAAA8, 0fBEFFFFFF, %p187;
	fma.rn.f32 	%f350, %f348, %f105, %f349;
	mov.f32 	%f351, 0f00000000;
	fma.rn.f32 	%f352, %f105, %f104, %f351;
	fma.rn.f32 	%f474, %f350, %f352, %f104;
	and.b32  	%r526, %r137, 2;
	setp.eq.s32 	%p189, %r526, 0;
	@%p189 bra 	$L__BB8_153;

	mov.f32 	%f354, 0fBF800000;
	fma.rn.f32 	%f474, %f474, %f354, %f351;

$L__BB8_153:
	@%p180 bra 	$L__BB8_161;

	setp.eq.f32 	%p191, %f100, 0f7F800000;
	@%p191 bra 	$L__BB8_160;
	bra.uni 	$L__BB8_155;

$L__BB8_160:
	mov.f32 	%f357, 0f00000000;
	mul.rn.f32 	%f475, %f98, %f357;
	mov.u32 	%r728, 0;
	bra.uni 	$L__BB8_161;

$L__BB8_155:
	mov.b32 	%r139, %f98;
	bfe.u32 	%r527, %r139, 23, 8;
	add.s32 	%r140, %r527, -128;
	shl.b32 	%r528, %r139, 8;
	or.b32  	%r141, %r528, -2147483648;
	shr.u32 	%r142, %r140, 5;
	mov.u64 	%rd231, 0;
	mov.u64 	%rd232, %rd231;

$L__BB8_156:
	.pragma "nounroll";
	shl.b64 	%rd156, %rd231, 2;
	mov.u64 	%rd157, __cudart_i2opi_f;
	add.s64 	%rd158, %rd157, %rd156;
	ld.global.nc.u32 	%r529, [%rd158];
	mad.wide.u32 	%rd159, %r529, %r141, %rd232;
	shr.u64 	%rd232, %rd159, 32;
	add.s64 	%rd160, %rd1, %rd156;
	st.local.u32 	[%rd160], %rd159;
	cvt.u32.u64 	%r530, %rd231;
	add.s32 	%r531, %r530, 1;
	cvt.s64.s32 	%rd231, %r531;
	setp.ne.s32 	%p192, %r531, 6;
	@%p192 bra 	$L__BB8_156;

	st.local.u32 	[%rd30], %rd232;
	mov.u32 	%r532, 4;
	sub.s32 	%r143, %r532, %r142;
	mov.u32 	%r533, 6;
	sub.s32 	%r534, %r533, %r142;
	mul.wide.s32 	%rd161, %r534, 4;
	add.s64 	%rd162, %rd1, %rd161;
	ld.local.u32 	%r726, [%rd162];
	ld.local.u32 	%r727, [%rd162+-4];
	and.b32  	%r146, %r140, 31;
	setp.eq.s32 	%p193, %r146, 0;
	@%p193 bra 	$L__BB8_159;

	mov.u32 	%r535, 32;
	sub.s32 	%r536, %r535, %r146;
	shr.u32 	%r537, %r727, %r536;
	shl.b32 	%r538, %r726, %r146;
	add.s32 	%r726, %r537, %r538;
	mul.wide.s32 	%rd163, %r143, 4;
	add.s64 	%rd164, %rd1, %rd163;
	ld.local.u32 	%r539, [%rd164];
	shr.u32 	%r540, %r539, %r536;
	shl.b32 	%r541, %r727, %r146;
	add.s32 	%r727, %r540, %r541;

$L__BB8_159:
	and.b32  	%r542, %r139, -2147483648;
	shr.u32 	%r543, %r727, 30;
	shl.b32 	%r544, %r726, 2;
	or.b32  	%r545, %r543, %r544;
	shr.u32 	%r546, %r545, 31;
	shr.u32 	%r547, %r726, 30;
	add.s32 	%r548, %r546, %r547;
	neg.s32 	%r549, %r548;
	setp.eq.s32 	%p194, %r542, 0;
	selp.b32 	%r728, %r548, %r549, %p194;
	setp.ne.s32 	%p195, %r546, 0;
	xor.b32  	%r550, %r542, -2147483648;
	selp.b32 	%r551, %r550, %r542, %p195;
	selp.b32 	%r552, -1, 0, %p195;
	xor.b32  	%r553, %r545, %r552;
	shl.b32 	%r554, %r727, 2;
	xor.b32  	%r555, %r554, %r552;
	cvt.u64.u32 	%rd165, %r553;
	cvt.u64.u32 	%rd166, %r555;
	bfi.b64 	%rd167, %rd165, %rd166, 32, 32;
	cvt.rn.f64.s64 	%fd155, %rd167;
	mul.rn.f64 	%fd156, %fd155, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f355, %fd156;
	setp.eq.s32 	%p196, %r551, 0;
	neg.f32 	%f356, %f355;
	selp.f32 	%f475, %f355, %f356, %p196;

$L__BB8_161:
	and.b32  	%r153, %r728, 1;
	setp.eq.s32 	%p197, %r153, 0;
	selp.f32 	%f114, %f475, 0f3F800000, %p197;
	mul.rn.f32 	%f115, %f475, %f475;
	mov.f32 	%f476, 0fB94D4153;
	@%p197 bra 	$L__BB8_163;

	mov.f32 	%f359, 0fBAB607ED;
	mov.f32 	%f360, 0f37CBAC00;
	fma.rn.f32 	%f476, %f360, %f115, %f359;

$L__BB8_163:
	selp.f32 	%f361, 0f3C0885E4, 0f3D2AAABB, %p197;
	fma.rn.f32 	%f362, %f476, %f115, %f361;
	selp.f32 	%f363, 0fBE2AAAA8, 0fBEFFFFFF, %p197;
	fma.rn.f32 	%f364, %f362, %f115, %f363;
	mov.f32 	%f365, 0f00000000;
	fma.rn.f32 	%f366, %f115, %f114, %f365;
	fma.rn.f32 	%f477, %f364, %f366, %f114;
	and.b32  	%r557, %r728, 2;
	setp.eq.s32 	%p199, %r557, 0;
	@%p199 bra 	$L__BB8_165;

	mov.f32 	%f368, 0fBF800000;
	fma.rn.f32 	%f477, %f477, %f368, %f365;

$L__BB8_165:
	ld.param.s8 	%rs2, [bd09_to_gcj02_exact_cuda_float_param_4];
	mul.rn.f32 	%f369, %f477, %f90;
	cvt.f64.f32 	%fd157, %f369;
	add.rn.f64 	%fd158, %fd157, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f370, %fd158;
	sub.rn.f32 	%f121, %f3, %f370;
	mul.rn.f32 	%f371, %f474, %f90;
	cvt.f64.f32 	%fd159, %f371;
	add.rn.f64 	%fd160, %fd159, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f372, %fd160;
	sub.rn.f32 	%f122, %f1, %f372;
	add.rn.f32 	%f464, %f485, %f122;
	add.rn.f32 	%f463, %f486, %f121;
	setp.eq.s16 	%p200, %rs2, 0;
	@%p200 bra 	$L__BB8_240;

	mul.rn.f64 	%fd161, %fd35, 0d400921FB54442D18;
	div.rn.f64 	%fd162, %fd161, 0d4066800000000000;
	cvt.rn.f32.f64 	%f125, %fd162;
	cvt.f64.f32 	%fd163, %f463;
	mul.rn.f64 	%fd164, %fd163, 0d400921FB54442D18;
	div.rn.f64 	%fd165, %fd164, 0d4066800000000000;
	cvt.rn.f32.f64 	%f126, %fd165;
	sub.rn.f32 	%f373, %f126, %f125;
	cvt.f64.f32 	%fd166, %f373;
	mul.rn.f64 	%fd48, %fd166, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r558, %temp}, %fd48;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r559}, %fd48;
	}
	and.b32  	%r560, %r559, 2147483647;
	setp.eq.s32 	%p201, %r560, 2146435072;
	setp.eq.s32 	%p202, %r558, 0;
	and.pred  	%p203, %p202, %p201;
	@%p203 bra 	$L__BB8_169;
	bra.uni 	$L__BB8_167;

$L__BB8_169:
	mov.f64 	%fd176, 0d0000000000000000;
	mul.rn.f64 	%fd259, %fd48, %fd176;
	mov.u32 	%r729, 0;
	bra.uni 	$L__BB8_170;

$L__BB8_240:
	abs.f32 	%f448, %f122;
	setp.geu.f32 	%p288, %f448, %f162;
	@%p288 bra 	$L__BB8_242;

	abs.f32 	%f449, %f121;
	setp.lt.f32 	%p289, %f449, %f162;
	@%p289 bra 	$L__BB8_243;
	bra.uni 	$L__BB8_242;

$L__BB8_167:
	mul.rn.f64 	%fd167, %fd48, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r729, %fd167;
	st.local.u32 	[%rd3], %r729;
	cvt.rn.f64.s32 	%fd168, %r729;
	neg.f64 	%fd169, %fd168;
	mov.f64 	%fd170, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd171, %fd169, %fd170, %fd48;
	mov.f64 	%fd172, 0d3C91A62633145C00;
	fma.rn.f64 	%fd173, %fd169, %fd172, %fd171;
	mov.f64 	%fd174, 0d397B839A252049C0;
	fma.rn.f64 	%fd259, %fd169, %fd174, %fd173;
	abs.f64 	%fd175, %fd48;
	setp.ltu.f64 	%p204, %fd175, 0d41E0000000000000;
	@%p204 bra 	$L__BB8_170;

	{ // callseq 104, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd48;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 104
	ld.local.u32 	%r729, [%rd3];

$L__BB8_170:
	and.b32  	%r562, %r729, 1;
	shl.b32 	%r563, %r729, 3;
	and.b32  	%r564, %r563, 8;
	setp.eq.s32 	%p205, %r562, 0;
	selp.f64 	%fd177, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p205;
	mul.wide.s32 	%rd169, %r564, 8;
	mov.u64 	%rd170, __cudart_sin_cos_coeffs;
	add.s64 	%rd171, %rd170, %rd169;
	ld.global.nc.f64 	%fd178, [%rd171+8];
	mul.rn.f64 	%fd53, %fd259, %fd259;
	fma.rn.f64 	%fd179, %fd177, %fd53, %fd178;
	ld.global.nc.f64 	%fd180, [%rd171+16];
	fma.rn.f64 	%fd181, %fd179, %fd53, %fd180;
	ld.global.nc.f64 	%fd182, [%rd171+24];
	fma.rn.f64 	%fd183, %fd181, %fd53, %fd182;
	ld.global.nc.f64 	%fd184, [%rd171+32];
	fma.rn.f64 	%fd185, %fd183, %fd53, %fd184;
	ld.global.nc.f64 	%fd186, [%rd171+40];
	fma.rn.f64 	%fd187, %fd185, %fd53, %fd186;
	ld.global.nc.f64 	%fd188, [%rd171+48];
	fma.rn.f64 	%fd54, %fd187, %fd53, %fd188;
	fma.rn.f64 	%fd261, %fd54, %fd259, %fd259;
	@%p205 bra 	$L__BB8_172;

	mov.f64 	%fd189, 0d3FF0000000000000;
	fma.rn.f64 	%fd261, %fd54, %fd53, %fd189;

$L__BB8_172:
	and.b32  	%r565, %r729, 2;
	setp.eq.s32 	%p206, %r565, 0;
	@%p206 bra 	$L__BB8_174;

	mov.f64 	%fd190, 0d0000000000000000;
	mov.f64 	%fd191, 0dBFF0000000000000;
	fma.rn.f64 	%fd261, %fd261, %fd191, %fd190;

$L__BB8_174:
	abs.f64 	%fd60, %fd261;
	{ // callseq 105, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd60;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd264, [retval0+0];
	} // callseq 105
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd261;
	}
	setp.lt.s32 	%p207, %r157, 0;
	and.pred  	%p5, %p207, %p8;
	not.pred 	%p209, %p5;
	@%p209 bra 	$L__BB8_176;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r566}, %fd264;
	}
	xor.b32  	%r567, %r566, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r568, %temp}, %fd264;
	}
	mov.b64 	%fd264, {%r568, %r567};

$L__BB8_176:
	setp.eq.f64 	%p210, %fd261, 0d0000000000000000;
	@%p210 bra 	$L__BB8_180;
	bra.uni 	$L__BB8_177;

$L__BB8_180:
	setp.lt.s32 	%p213, %r3, 0;
	mov.u32 	%r569, 0;
	selp.b32 	%r570, %r157, 0, %p8;
	or.b32  	%r571, %r570, 2146435072;
	selp.b32 	%r572, %r571, %r570, %p213;
	mov.b64 	%fd264, {%r569, %r572};
	bra.uni 	$L__BB8_181;

$L__BB8_177:
	setp.gt.s32 	%p211, %r157, -1;
	@%p211 bra 	$L__BB8_181;

	mov.f64 	%fd192, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd193, %fd192;
	setp.eq.f64 	%p212, %fd193, 0d4000000000000000;
	@%p212 bra 	$L__BB8_181;

	mov.f64 	%fd264, 0dFFF8000000000000;

$L__BB8_181:
	add.rn.f64 	%fd195, %fd261, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r573}, %fd195;
	}
	and.b32  	%r574, %r573, 2146435072;
	setp.ne.s32 	%p215, %r574, 2146435072;
	@%p215 bra 	$L__BB8_188;

	setp.gtu.f64 	%p216, %fd60, 0d7FF0000000000000;
	@%p216 bra 	$L__BB8_187;
	bra.uni 	$L__BB8_183;

$L__BB8_187:
	mov.f64 	%fd197, 0d4000000000000000;
	add.rn.f64 	%fd264, %fd261, %fd197;
	bra.uni 	$L__BB8_188;

$L__BB8_183:
	setp.eq.s32 	%p217, %r81, 2146435072;
	mov.f64 	%fd196, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r575, %temp}, %fd196;
	}
	setp.eq.s32 	%p218, %r575, 0;
	and.pred  	%p219, %p217, %p218;
	@%p219 bra 	$L__BB8_186;
	bra.uni 	$L__BB8_184;

$L__BB8_186:
	setp.lt.s32 	%p225, %r3, 0;
	mov.u32 	%r580, 0;
	setp.gt.f64 	%p226, %fd60, 0d3FF0000000000000;
	selp.b32 	%r581, 2146435072, 0, %p226;
	xor.b32  	%r582, %r581, 2146435072;
	selp.b32 	%r583, %r582, %r581, %p225;
	setp.eq.f64 	%p227, %fd261, 0dBFF0000000000000;
	selp.b32 	%r584, 1072693248, %r583, %p227;
	mov.b64 	%fd264, {%r580, %r584};
	bra.uni 	$L__BB8_188;

$L__BB8_184:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r576, %temp}, %fd261;
	}
	and.b32  	%r577, %r157, 2147483647;
	setp.ne.s32 	%p220, %r577, 2146435072;
	setp.ne.s32 	%p221, %r576, 0;
	or.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB8_188;

	setp.ne.s32 	%p223, %r81, 1071644672;
	and.pred  	%p224, %p223, %p5;
	selp.b32 	%r578, %r83, %r82, %p224;
	mov.u32 	%r579, 0;
	mov.b64 	%fd264, {%r579, %r578};

$L__BB8_188:
	setp.eq.f64 	%p228, %fd261, 0d3FF0000000000000;
	selp.f64 	%fd70, 0d3FF0000000000000, %fd264, %p228;
	mul.rn.f32 	%f374, %f125, 0f3F22F983;
	cvt.rni.s32.f32 	%r732, %f374;
	cvt.rn.f32.s32 	%f375, %r732;
	mov.f32 	%f376, 0fBFC90FDA;
	fma.rn.f32 	%f377, %f375, %f376, %f125;
	mov.f32 	%f378, 0fB3A22168;
	fma.rn.f32 	%f379, %f375, %f378, %f377;
	mov.f32 	%f380, 0fA7C234C5;
	fma.rn.f32 	%f478, %f375, %f380, %f379;
	abs.f32 	%f128, %f125;
	setp.ltu.f32 	%p229, %f128, 0f47CE4780;
	@%p229 bra 	$L__BB8_196;

	setp.eq.f32 	%p230, %f128, 0f7F800000;
	@%p230 bra 	$L__BB8_195;
	bra.uni 	$L__BB8_190;

$L__BB8_195:
	mov.f32 	%f383, 0f00000000;
	mul.rn.f32 	%f478, %f125, %f383;
	mov.u32 	%r732, 0;
	bra.uni 	$L__BB8_196;

$L__BB8_190:
	mov.b32 	%r159, %f125;
	bfe.u32 	%r585, %r159, 23, 8;
	add.s32 	%r160, %r585, -128;
	shl.b32 	%r586, %r159, 8;
	or.b32  	%r161, %r586, -2147483648;
	shr.u32 	%r162, %r160, 5;
	mov.u64 	%rd233, 0;
	mov.u64 	%rd234, %rd233;

$L__BB8_191:
	.pragma "nounroll";
	shl.b64 	%rd174, %rd233, 2;
	mov.u64 	%rd175, __cudart_i2opi_f;
	add.s64 	%rd176, %rd175, %rd174;
	ld.global.nc.u32 	%r587, [%rd176];
	mad.wide.u32 	%rd177, %r587, %r161, %rd234;
	shr.u64 	%rd234, %rd177, 32;
	add.s64 	%rd178, %rd2, %rd174;
	st.local.u32 	[%rd178], %rd177;
	cvt.u32.u64 	%r588, %rd233;
	add.s32 	%r589, %r588, 1;
	cvt.s64.s32 	%rd233, %r589;
	setp.ne.s32 	%p231, %r589, 6;
	@%p231 bra 	$L__BB8_191;

	st.local.u32 	[%rd7], %rd234;
	mov.u32 	%r590, 4;
	sub.s32 	%r163, %r590, %r162;
	mov.u32 	%r591, 6;
	sub.s32 	%r592, %r591, %r162;
	mul.wide.s32 	%rd179, %r592, 4;
	add.s64 	%rd180, %rd2, %rd179;
	ld.local.u32 	%r730, [%rd180];
	ld.local.u32 	%r731, [%rd180+-4];
	and.b32  	%r166, %r160, 31;
	setp.eq.s32 	%p232, %r166, 0;
	@%p232 bra 	$L__BB8_194;

	mov.u32 	%r593, 32;
	sub.s32 	%r594, %r593, %r166;
	shr.u32 	%r595, %r731, %r594;
	shl.b32 	%r596, %r730, %r166;
	add.s32 	%r730, %r595, %r596;
	mul.wide.s32 	%rd181, %r163, 4;
	add.s64 	%rd182, %rd2, %rd181;
	ld.local.u32 	%r597, [%rd182];
	shr.u32 	%r598, %r597, %r594;
	shl.b32 	%r599, %r731, %r166;
	add.s32 	%r731, %r598, %r599;

$L__BB8_194:
	and.b32  	%r600, %r159, -2147483648;
	shr.u32 	%r601, %r731, 30;
	shl.b32 	%r602, %r730, 2;
	or.b32  	%r603, %r601, %r602;
	shr.u32 	%r604, %r603, 31;
	shr.u32 	%r605, %r730, 30;
	add.s32 	%r606, %r604, %r605;
	neg.s32 	%r607, %r606;
	setp.eq.s32 	%p233, %r600, 0;
	selp.b32 	%r732, %r606, %r607, %p233;
	setp.ne.s32 	%p234, %r604, 0;
	xor.b32  	%r608, %r600, -2147483648;
	selp.b32 	%r609, %r608, %r600, %p234;
	selp.b32 	%r610, -1, 0, %p234;
	xor.b32  	%r611, %r603, %r610;
	shl.b32 	%r612, %r731, 2;
	xor.b32  	%r613, %r612, %r610;
	cvt.u64.u32 	%rd183, %r611;
	cvt.u64.u32 	%rd184, %r613;
	bfi.b64 	%rd185, %rd183, %rd184, 32, 32;
	cvt.rn.f64.s64 	%fd198, %rd185;
	mul.rn.f64 	%fd199, %fd198, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f381, %fd199;
	setp.eq.s32 	%p235, %r609, 0;
	neg.f32 	%f382, %f381;
	selp.f32 	%f478, %f381, %f382, %p235;

$L__BB8_196:
	add.s32 	%r173, %r732, 1;
	and.b32  	%r174, %r173, 1;
	setp.eq.s32 	%p236, %r174, 0;
	selp.f32 	%f132, %f478, 0f3F800000, %p236;
	mul.rn.f32 	%f133, %f478, %f478;
	mov.f32 	%f479, 0fB94D4153;
	@%p236 bra 	$L__BB8_198;

	mov.f32 	%f385, 0fBAB607ED;
	mov.f32 	%f386, 0f37CBAC00;
	fma.rn.f32 	%f479, %f386, %f133, %f385;

$L__BB8_198:
	selp.f32 	%f387, 0f3C0885E4, 0f3D2AAABB, %p236;
	fma.rn.f32 	%f388, %f479, %f133, %f387;
	selp.f32 	%f389, 0fBE2AAAA8, 0fBEFFFFFF, %p236;
	fma.rn.f32 	%f390, %f388, %f133, %f389;
	mov.f32 	%f391, 0f00000000;
	fma.rn.f32 	%f392, %f133, %f132, %f391;
	fma.rn.f32 	%f480, %f390, %f392, %f132;
	and.b32  	%r615, %r173, 2;
	setp.eq.s32 	%p238, %r615, 0;
	@%p238 bra 	$L__BB8_200;

	mov.f32 	%f394, 0fBF800000;
	fma.rn.f32 	%f480, %f480, %f394, %f391;

$L__BB8_200:
	mul.rn.f32 	%f395, %f126, 0f3F22F983;
	cvt.rni.s32.f32 	%r735, %f395;
	cvt.rn.f32.s32 	%f396, %r735;
	mov.f32 	%f397, 0fBFC90FDA;
	fma.rn.f32 	%f398, %f396, %f397, %f126;
	mov.f32 	%f399, 0fB3A22168;
	fma.rn.f32 	%f400, %f396, %f399, %f398;
	mov.f32 	%f401, 0fA7C234C5;
	fma.rn.f32 	%f481, %f396, %f401, %f400;
	abs.f32 	%f140, %f126;
	setp.ltu.f32 	%p239, %f140, 0f47CE4780;
	@%p239 bra 	$L__BB8_208;

	setp.eq.f32 	%p240, %f140, 0f7F800000;
	@%p240 bra 	$L__BB8_207;
	bra.uni 	$L__BB8_202;

$L__BB8_207:
	mov.f32 	%f404, 0f00000000;
	mul.rn.f32 	%f481, %f126, %f404;
	mov.u32 	%r735, 0;
	bra.uni 	$L__BB8_208;

$L__BB8_202:
	mov.b32 	%r176, %f126;
	bfe.u32 	%r616, %r176, 23, 8;
	add.s32 	%r177, %r616, -128;
	shl.b32 	%r617, %r176, 8;
	or.b32  	%r178, %r617, -2147483648;
	shr.u32 	%r179, %r177, 5;
	mov.u64 	%rd235, 0;
	mov.u64 	%rd236, %rd235;

$L__BB8_203:
	.pragma "nounroll";
	shl.b64 	%rd188, %rd235, 2;
	mov.u64 	%rd189, __cudart_i2opi_f;
	add.s64 	%rd190, %rd189, %rd188;
	ld.global.nc.u32 	%r618, [%rd190];
	mad.wide.u32 	%rd191, %r618, %r178, %rd236;
	shr.u64 	%rd236, %rd191, 32;
	add.s64 	%rd192, %rd2, %rd188;
	st.local.u32 	[%rd192], %rd191;
	cvt.u32.u64 	%r619, %rd235;
	add.s32 	%r620, %r619, 1;
	cvt.s64.s32 	%rd235, %r620;
	setp.ne.s32 	%p241, %r620, 6;
	@%p241 bra 	$L__BB8_203;

	st.local.u32 	[%rd7], %rd236;
	mov.u32 	%r621, 4;
	sub.s32 	%r180, %r621, %r179;
	mov.u32 	%r622, 6;
	sub.s32 	%r623, %r622, %r179;
	mul.wide.s32 	%rd193, %r623, 4;
	add.s64 	%rd194, %rd2, %rd193;
	ld.local.u32 	%r733, [%rd194];
	ld.local.u32 	%r734, [%rd194+-4];
	and.b32  	%r183, %r177, 31;
	setp.eq.s32 	%p242, %r183, 0;
	@%p242 bra 	$L__BB8_206;

	mov.u32 	%r624, 32;
	sub.s32 	%r625, %r624, %r183;
	shr.u32 	%r626, %r734, %r625;
	shl.b32 	%r627, %r733, %r183;
	add.s32 	%r733, %r626, %r627;
	mul.wide.s32 	%rd195, %r180, 4;
	add.s64 	%rd196, %rd2, %rd195;
	ld.local.u32 	%r628, [%rd196];
	shr.u32 	%r629, %r628, %r625;
	shl.b32 	%r630, %r734, %r183;
	add.s32 	%r734, %r629, %r630;

$L__BB8_206:
	and.b32  	%r631, %r176, -2147483648;
	shr.u32 	%r632, %r734, 30;
	shl.b32 	%r633, %r733, 2;
	or.b32  	%r634, %r632, %r633;
	shr.u32 	%r635, %r634, 31;
	shr.u32 	%r636, %r733, 30;
	add.s32 	%r637, %r635, %r636;
	neg.s32 	%r638, %r637;
	setp.eq.s32 	%p243, %r631, 0;
	selp.b32 	%r735, %r637, %r638, %p243;
	setp.ne.s32 	%p244, %r635, 0;
	xor.b32  	%r639, %r631, -2147483648;
	selp.b32 	%r640, %r639, %r631, %p244;
	selp.b32 	%r641, -1, 0, %p244;
	xor.b32  	%r642, %r634, %r641;
	shl.b32 	%r643, %r734, 2;
	xor.b32  	%r644, %r643, %r641;
	cvt.u64.u32 	%rd197, %r642;
	cvt.u64.u32 	%rd198, %r644;
	bfi.b64 	%rd199, %rd197, %rd198, 32, 32;
	cvt.rn.f64.s64 	%fd200, %rd199;
	mul.rn.f64 	%fd201, %fd200, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f402, %fd201;
	setp.eq.s32 	%p245, %r640, 0;
	neg.f32 	%f403, %f402;
	selp.f32 	%f481, %f402, %f403, %p245;

$L__BB8_208:
	add.s32 	%r190, %r735, 1;
	and.b32  	%r191, %r190, 1;
	setp.eq.s32 	%p246, %r191, 0;
	selp.f32 	%f144, %f481, 0f3F800000, %p246;
	mul.rn.f32 	%f145, %f481, %f481;
	mov.f32 	%f482, 0fB94D4153;
	@%p246 bra 	$L__BB8_210;

	mov.f32 	%f406, 0fBAB607ED;
	mov.f32 	%f407, 0f37CBAC00;
	fma.rn.f32 	%f482, %f407, %f145, %f406;

$L__BB8_210:
	selp.f32 	%f408, 0f3C0885E4, 0f3D2AAABB, %p246;
	fma.rn.f32 	%f409, %f482, %f145, %f408;
	selp.f32 	%f410, 0fBE2AAAA8, 0fBEFFFFFF, %p246;
	fma.rn.f32 	%f411, %f409, %f145, %f410;
	mov.f32 	%f412, 0f00000000;
	fma.rn.f32 	%f413, %f145, %f144, %f412;
	fma.rn.f32 	%f483, %f411, %f413, %f144;
	and.b32  	%r646, %r190, 2;
	setp.eq.s32 	%p248, %r646, 0;
	@%p248 bra 	$L__BB8_212;

	mov.f32 	%f415, 0fBF800000;
	fma.rn.f32 	%f483, %f483, %f415, %f412;

$L__BB8_212:
	mul.rn.f32 	%f151, %f480, %f483;
	mul.rn.f64 	%fd202, %fd24, 0d400921FB54442D18;
	div.rn.f64 	%fd203, %fd202, 0d4066800000000000;
	cvt.rn.f32.f64 	%f416, %fd203;
	cvt.f64.f32 	%fd204, %f464;
	mul.rn.f64 	%fd205, %fd204, 0d400921FB54442D18;
	div.rn.f64 	%fd206, %fd205, 0d4066800000000000;
	cvt.rn.f32.f64 	%f417, %fd206;
	sub.rn.f32 	%f418, %f417, %f416;
	cvt.f64.f32 	%fd207, %f418;
	mul.rn.f64 	%fd71, %fd207, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r647, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r648}, %fd71;
	}
	and.b32  	%r649, %r648, 2147483647;
	setp.eq.s32 	%p249, %r649, 2146435072;
	setp.eq.s32 	%p250, %r647, 0;
	and.pred  	%p251, %p250, %p249;
	@%p251 bra 	$L__BB8_215;
	bra.uni 	$L__BB8_213;

$L__BB8_215:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd265, %fd71, %fd217;
	mov.u32 	%r736, 0;
	bra.uni 	$L__BB8_216;

$L__BB8_213:
	mul.rn.f64 	%fd208, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r736, %fd208;
	st.local.u32 	[%rd3], %r736;
	cvt.rn.f64.s32 	%fd209, %r736;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd71;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd265, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd71;
	setp.ltu.f64 	%p252, %fd216, 0d41E0000000000000;
	@%p252 bra 	$L__BB8_216;

	{ // callseq 106, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd61;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd265, [retval0+0];
	} // callseq 106
	ld.local.u32 	%r736, [%rd3];

$L__BB8_216:
	mov.u64 	%rd204, __cudart_sin_cos_coeffs;
	and.b32  	%r651, %r736, 1;
	shl.b32 	%r652, %r736, 3;
	and.b32  	%r653, %r652, 8;
	setp.eq.s32 	%p253, %r651, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p253;
	mul.wide.s32 	%rd201, %r653, 8;
	add.s64 	%rd203, %rd204, %rd201;
	ld.global.nc.f64 	%fd219, [%rd203+8];
	mul.rn.f64 	%fd76, %fd265, %fd265;
	fma.rn.f64 	%fd220, %fd218, %fd76, %fd219;
	ld.global.nc.f64 	%fd221, [%rd203+16];
	fma.rn.f64 	%fd222, %fd220, %fd76, %fd221;
	ld.global.nc.f64 	%fd223, [%rd203+24];
	fma.rn.f64 	%fd224, %fd222, %fd76, %fd223;
	ld.global.nc.f64 	%fd225, [%rd203+32];
	fma.rn.f64 	%fd226, %fd224, %fd76, %fd225;
	ld.global.nc.f64 	%fd227, [%rd203+40];
	fma.rn.f64 	%fd228, %fd226, %fd76, %fd227;
	ld.global.nc.f64 	%fd229, [%rd203+48];
	fma.rn.f64 	%fd77, %fd228, %fd76, %fd229;
	fma.rn.f64 	%fd267, %fd77, %fd265, %fd265;
	@%p253 bra 	$L__BB8_218;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd267, %fd77, %fd76, %fd230;

$L__BB8_218:
	and.b32  	%r654, %r736, 2;
	setp.eq.s32 	%p254, %r654, 0;
	@%p254 bra 	$L__BB8_220;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd267, %fd267, %fd232, %fd231;

$L__BB8_220:
	abs.f64 	%fd83, %fd267;
	{ // callseq 107, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd270, [retval0+0];
	} // callseq 107
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r195}, %fd267;
	}
	setp.lt.s32 	%p255, %r195, 0;
	and.pred  	%p6, %p255, %p8;
	not.pred 	%p257, %p6;
	@%p257 bra 	$L__BB8_222;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r655}, %fd270;
	}
	xor.b32  	%r656, %r655, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r657, %temp}, %fd270;
	}
	mov.b64 	%fd270, {%r657, %r656};

$L__BB8_222:
	setp.eq.f64 	%p258, %fd267, 0d0000000000000000;
	@%p258 bra 	$L__BB8_226;
	bra.uni 	$L__BB8_223;

$L__BB8_226:
	setp.lt.s32 	%p261, %r3, 0;
	mov.u32 	%r658, 0;
	selp.b32 	%r659, %r195, 0, %p8;
	or.b32  	%r660, %r659, 2146435072;
	selp.b32 	%r661, %r660, %r659, %p261;
	mov.b64 	%fd270, {%r658, %r661};
	bra.uni 	$L__BB8_227;

$L__BB8_223:
	setp.gt.s32 	%p259, %r195, -1;
	@%p259 bra 	$L__BB8_227;

	mov.f64 	%fd233, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd234, %fd233;
	setp.eq.f64 	%p260, %fd234, 0d4000000000000000;
	@%p260 bra 	$L__BB8_227;

	mov.f64 	%fd270, 0dFFF8000000000000;

$L__BB8_227:
	add.rn.f64 	%fd236, %fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r662}, %fd236;
	}
	and.b32  	%r663, %r662, 2146435072;
	setp.ne.s32 	%p263, %r663, 2146435072;
	@%p263 bra 	$L__BB8_234;

	setp.gtu.f64 	%p264, %fd83, 0d7FF0000000000000;
	@%p264 bra 	$L__BB8_233;
	bra.uni 	$L__BB8_229;

$L__BB8_233:
	mov.f64 	%fd238, 0d4000000000000000;
	add.rn.f64 	%fd270, %fd267, %fd238;
	bra.uni 	$L__BB8_234;

$L__BB8_229:
	setp.eq.s32 	%p265, %r81, 2146435072;
	mov.f64 	%fd237, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r664, %temp}, %fd237;
	}
	setp.eq.s32 	%p266, %r664, 0;
	and.pred  	%p267, %p265, %p266;
	@%p267 bra 	$L__BB8_232;
	bra.uni 	$L__BB8_230;

$L__BB8_232:
	setp.lt.s32 	%p273, %r3, 0;
	mov.u32 	%r669, 0;
	setp.gt.f64 	%p274, %fd83, 0d3FF0000000000000;
	selp.b32 	%r670, 2146435072, 0, %p274;
	xor.b32  	%r671, %r670, 2146435072;
	selp.b32 	%r672, %r671, %r670, %p273;
	setp.eq.f64 	%p275, %fd267, 0dBFF0000000000000;
	selp.b32 	%r673, 1072693248, %r672, %p275;
	mov.b64 	%fd270, {%r669, %r673};
	bra.uni 	$L__BB8_234;

$L__BB8_230:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r665, %temp}, %fd267;
	}
	and.b32  	%r666, %r195, 2147483647;
	setp.ne.s32 	%p268, %r666, 2146435072;
	setp.ne.s32 	%p269, %r665, 0;
	or.pred  	%p270, %p268, %p269;
	@%p270 bra 	$L__BB8_234;

	setp.ne.s32 	%p271, %r81, 1071644672;
	and.pred  	%p272, %p271, %p6;
	selp.b32 	%r667, %r83, %r82, %p272;
	mov.u32 	%r668, 0;
	mov.b64 	%fd270, {%r668, %r667};

$L__BB8_234:
	setp.eq.f64 	%p276, %fd267, 0d3FF0000000000000;
	mov.f64 	%fd239, 0d3FF0000000000000;
	selp.f64 	%fd240, 0d3FF0000000000000, %fd270, %p276;
	cvt.f64.f32 	%fd241, %f151;
	mul.rn.f64 	%fd242, %fd240, %fd241;
	add.rn.f64 	%fd243, %fd70, %fd242;
	cvt.rn.f32.f64 	%f419, %fd243;
	sqrt.rn.f32 	%f152, %f419;
	cvt.f64.f32 	%fd244, %f419;
	sub.rn.f64 	%fd245, %fd239, %fd244;
	sqrt.rn.f64 	%fd246, %fd245;
	cvt.rn.f32.f64 	%f153, %fd246;
	abs.f32 	%f154, %f153;
	abs.f32 	%f155, %f152;
	setp.eq.f32 	%p277, %f154, 0f00000000;
	setp.eq.f32 	%p278, %f155, 0f00000000;
	and.pred  	%p279, %p277, %p278;
	@%p279 bra 	$L__BB8_238;
	bra.uni 	$L__BB8_235;

$L__BB8_238:
	mov.b32 	%r684, %f153;
	shr.s32 	%r685, %r684, 31;
	and.b32  	%r686, %r685, 1078530011;
	mov.b32 	%r687, %f152;
	and.b32  	%r688, %r687, -2147483648;
	or.b32  	%r689, %r686, %r688;
	mov.b32 	%f484, %r689;
	bra.uni 	$L__BB8_239;

$L__BB8_235:
	setp.eq.f32 	%p280, %f154, 0f7F800000;
	setp.eq.f32 	%p281, %f155, 0f7F800000;
	and.pred  	%p282, %p280, %p281;
	@%p282 bra 	$L__BB8_237;
	bra.uni 	$L__BB8_236;

$L__BB8_237:
	mov.b32 	%r679, %f153;
	setp.lt.s32 	%p286, %r679, 0;
	selp.b32 	%r680, 1075235812, 1061752795, %p286;
	mov.b32 	%r681, %f152;
	and.b32  	%r682, %r681, -2147483648;
	or.b32  	%r683, %r680, %r682;
	mov.b32 	%f484, %r683;
	bra.uni 	$L__BB8_239;

$L__BB8_236:
	max.f32 	%f420, %f155, %f154;
	min.f32 	%f421, %f155, %f154;
	div.rn.f32 	%f422, %f421, %f420;
	mul.rn.f32 	%f423, %f422, %f422;
	mov.f32 	%f424, 0fC0B59883;
	mov.f32 	%f425, 0fBF52C7EA;
	fma.rn.f32 	%f426, %f423, %f425, %f424;
	mov.f32 	%f427, 0fC0D21907;
	fma.rn.f32 	%f428, %f426, %f423, %f427;
	mul.rn.f32 	%f429, %f423, %f428;
	mul.rn.f32 	%f430, %f422, %f429;
	add.rn.f32 	%f431, %f423, 0f41355DC0;
	mov.f32 	%f432, 0f41E6BD60;
	fma.rn.f32 	%f433, %f431, %f423, %f432;
	mov.f32 	%f434, 0f419D92C8;
	fma.rn.f32 	%f435, %f433, %f423, %f434;
	rcp.rn.f32 	%f436, %f435;
	fma.rn.f32 	%f437, %f430, %f436, %f422;
	mov.f32 	%f438, 0f3FC90FDB;
	sub.rn.f32 	%f439, %f438, %f437;
	setp.gt.f32 	%p283, %f155, %f154;
	selp.f32 	%f440, %f439, %f437, %p283;
	mov.b32 	%r674, %f153;
	setp.lt.s32 	%p284, %r674, 0;
	mov.f32 	%f441, 0f40490FDB;
	sub.rn.f32 	%f442, %f441, %f440;
	selp.f32 	%f443, %f442, %f440, %p284;
	mov.b32 	%r675, %f443;
	mov.b32 	%r676, %f152;
	and.b32  	%r677, %r676, -2147483648;
	or.b32  	%r678, %r677, %r675;
	mov.b32 	%f444, %r678;
	add.rn.f32 	%f445, %f154, %f155;
	setp.le.f32 	%p285, %f445, 0f7F800000;
	selp.f32 	%f484, %f444, %f445, %p285;

$L__BB8_239:
	add.rn.f32 	%f446, %f484, %f484;
	mul.rn.f32 	%f447, %f446, 0f4AC2A532;
	setp.lt.f32 	%p287, %f447, %f162;
	@%p287 bra 	$L__BB8_243;

$L__BB8_242:
	ld.param.u32 	%r690, [bd09_to_gcj02_exact_cuda_float_param_5];
	add.s32 	%r715, %r715, 1;
	setp.lt.s32 	%p290, %r715, %r690;
	mov.f32 	%f485, %f464;
	mov.f32 	%f486, %f463;
	@%p290 bra 	$L__BB8_84;

$L__BB8_243:
	ld.param.u64 	%rd212, [bd09_to_gcj02_exact_cuda_float_param_7];
	mov.u32 	%r698, %tid.x;
	mov.u32 	%r697, %ntid.x;
	mov.u32 	%r696, %ctaid.x;
	mad.lo.s32 	%r695, %r696, %r697, %r698;
	mul.wide.s32 	%rd211, %r695, 4;
	cvta.to.global.u64 	%rd210, %rd212;
	add.s64 	%rd209, %rd210, %rd211;
	ld.param.u64 	%rd208, [bd09_to_gcj02_exact_cuda_float_param_6];
	mov.u32 	%r694, %tid.x;
	mov.u32 	%r693, %ntid.x;
	mov.u32 	%r692, %ctaid.x;
	mad.lo.s32 	%r691, %r692, %r693, %r694;
	mul.wide.s32 	%rd207, %r691, 4;
	cvta.to.global.u64 	%rd206, %rd208;
	add.s64 	%rd205, %rd206, %rd207;
	st.global.f32 	[%rd205], %f485;
	st.global.f32 	[%rd209], %f486;

$L__BB8_244:
	ret;

}
	// .globl	bd09_to_gcj02_cuda_double
.visible .entry bd09_to_gcj02_cuda_double(
	.param .u32 bd09_to_gcj02_cuda_double_param_0,
	.param .u64 bd09_to_gcj02_cuda_double_param_1,
	.param .u64 bd09_to_gcj02_cuda_double_param_2,
	.param .u64 bd09_to_gcj02_cuda_double_param_3,
	.param .u64 bd09_to_gcj02_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot9[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<82>;
	.reg .b32 	%r<121>;
	.reg .f64 	%fd<275>;
	.reg .b64 	%rd<50>;


	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r24, [bd09_to_gcj02_cuda_double_param_0];
	ld.param.u64 	%rd6, [bd09_to_gcj02_cuda_double_param_1];
	ld.param.u64 	%rd7, [bd09_to_gcj02_cuda_double_param_2];
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r26, %r25, %r27;
	setp.ge.s32 	%p4, %r1, %r24;
	@%p4 bra 	$L__BB9_69;

	cvta.to.global.u64 	%rd14, %rd6;
	mul.wide.s32 	%rd15, %r1, 8;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd7;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.f64 	%fd78, [%rd16];
	add.rn.f64 	%fd1, %fd78, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd79, [%rd18];
	add.rn.f64 	%fd2, %fd79, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd80;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p5, %r4, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 108, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd256, [retval0+0];
	} // callseq 108
	setp.lt.s32 	%p6, %r2, 0;
	and.pred  	%p1, %p6, %p5;
	not.pred 	%p7, %p1;
	@%p7 bra 	$L__BB9_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd256;
	}
	xor.b32  	%r29, %r28, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd256;
	}
	mov.b64 	%fd256, {%r30, %r29};

$L__BB9_3:
	setp.eq.f64 	%p8, %fd1, 0d0000000000000000;
	@%p8 bra 	$L__BB9_7;
	bra.uni 	$L__BB9_4;

$L__BB9_7:
	selp.b32 	%r31, %r2, 0, %p5;
	mov.u32 	%r32, 0;
	or.b32  	%r33, %r31, 2146435072;
	setp.lt.s32 	%p12, %r3, 0;
	selp.b32 	%r34, %r33, %r31, %p12;
	mov.b64 	%fd256, {%r32, %r34};
	bra.uni 	$L__BB9_8;

$L__BB9_4:
	setp.gt.s32 	%p9, %r2, -1;
	@%p9 bra 	$L__BB9_8;

	mov.f64 	%fd81, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd82, %fd81;
	setp.eq.f64 	%p10, %fd82, 0d4000000000000000;
	@%p10 bra 	$L__BB9_8;

	mov.f64 	%fd256, 0dFFF8000000000000;

$L__BB9_8:
	add.rn.f64 	%fd84, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd84;
	}
	and.b32  	%r36, %r35, 2146435072;
	setp.ne.s32 	%p13, %r36, 2146435072;
	@%p13 bra 	$L__BB9_15;

	setp.gtu.f64 	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	$L__BB9_14;
	bra.uni 	$L__BB9_10;

$L__BB9_14:
	mov.f64 	%fd86, 0d4000000000000000;
	add.rn.f64 	%fd256, %fd1, %fd86;
	bra.uni 	$L__BB9_15;

$L__BB9_10:
	mov.f64 	%fd85, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd85;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p15, %r5, 2146435072;
	setp.eq.s32 	%p16, %r37, 0;
	and.pred  	%p17, %p15, %p16;
	@%p17 bra 	$L__BB9_13;
	bra.uni 	$L__BB9_11;

$L__BB9_13:
	setp.gt.f64 	%p24, %fd3, 0d3FF0000000000000;
	selp.b32 	%r44, 2146435072, 0, %p24;
	mov.u32 	%r45, 0;
	xor.b32  	%r46, %r44, 2146435072;
	setp.lt.s32 	%p25, %r3, 0;
	selp.b32 	%r47, %r46, %r44, %p25;
	setp.eq.f64 	%p26, %fd1, 0dBFF0000000000000;
	selp.b32 	%r48, 1072693248, %r47, %p26;
	mov.b64 	%fd256, {%r45, %r48};
	bra.uni 	$L__BB9_15;

$L__BB9_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd1;
	}
	and.b32  	%r39, %r2, 2147483647;
	setp.ne.s32 	%p18, %r39, 2146435072;
	setp.ne.s32 	%p19, %r38, 0;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	$L__BB9_15;

	setp.gt.s32 	%p21, %r3, -1;
	selp.b32 	%r40, 2146435072, 0, %p21;
	mov.u32 	%r41, 0;
	setp.ne.s32 	%p22, %r5, 1071644672;
	and.pred  	%p23, %p22, %p1;
	or.b32  	%r42, %r40, -2147483648;
	selp.b32 	%r43, %r42, %r40, %p23;
	mov.b64 	%fd256, {%r41, %r43};

$L__BB9_15:
	abs.f64 	%fd13, %fd2;
	{ // callseq 109, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 109
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	setp.lt.s32 	%p27, %r6, 0;
	and.pred  	%p2, %p27, %p5;
	not.pred 	%p29, %p2;
	@%p29 bra 	$L__BB9_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd259;
	}
	xor.b32  	%r50, %r49, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd259;
	}
	mov.b64 	%fd259, {%r51, %r50};

$L__BB9_17:
	setp.eq.f64 	%p30, %fd2, 0d0000000000000000;
	@%p30 bra 	$L__BB9_21;
	bra.uni 	$L__BB9_18;

$L__BB9_21:
	selp.b32 	%r52, %r6, 0, %p5;
	mov.u32 	%r53, 0;
	or.b32  	%r54, %r52, 2146435072;
	setp.lt.s32 	%p34, %r3, 0;
	selp.b32 	%r55, %r54, %r52, %p34;
	mov.b64 	%fd259, {%r53, %r55};
	bra.uni 	$L__BB9_22;

$L__BB9_18:
	setp.gt.s32 	%p31, %r6, -1;
	@%p31 bra 	$L__BB9_22;

	mov.f64 	%fd87, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd88, %fd87;
	setp.eq.f64 	%p32, %fd88, 0d4000000000000000;
	@%p32 bra 	$L__BB9_22;

	mov.f64 	%fd259, 0dFFF8000000000000;

$L__BB9_22:
	add.rn.f64 	%fd90, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd90;
	}
	and.b32  	%r57, %r56, 2146435072;
	setp.ne.s32 	%p35, %r57, 2146435072;
	@%p35 bra 	$L__BB9_29;

	setp.gtu.f64 	%p36, %fd13, 0d7FF0000000000000;
	@%p36 bra 	$L__BB9_28;
	bra.uni 	$L__BB9_24;

$L__BB9_28:
	mov.f64 	%fd92, 0d4000000000000000;
	add.rn.f64 	%fd259, %fd2, %fd92;
	bra.uni 	$L__BB9_29;

$L__BB9_24:
	mov.f64 	%fd91, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd91;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p37, %r7, 2146435072;
	setp.eq.s32 	%p38, %r58, 0;
	and.pred  	%p39, %p37, %p38;
	@%p39 bra 	$L__BB9_27;
	bra.uni 	$L__BB9_25;

$L__BB9_27:
	setp.gt.f64 	%p46, %fd13, 0d3FF0000000000000;
	selp.b32 	%r65, 2146435072, 0, %p46;
	mov.u32 	%r66, 0;
	xor.b32  	%r67, %r65, 2146435072;
	setp.lt.s32 	%p47, %r3, 0;
	selp.b32 	%r68, %r67, %r65, %p47;
	setp.eq.f64 	%p48, %fd2, 0dBFF0000000000000;
	selp.b32 	%r69, 1072693248, %r68, %p48;
	mov.b64 	%fd259, {%r66, %r69};
	bra.uni 	$L__BB9_29;

$L__BB9_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r59, %temp}, %fd2;
	}
	and.b32  	%r60, %r6, 2147483647;
	setp.ne.s32 	%p40, %r60, 2146435072;
	setp.ne.s32 	%p41, %r59, 0;
	or.pred  	%p42, %p40, %p41;
	@%p42 bra 	$L__BB9_29;

	setp.gt.s32 	%p43, %r3, -1;
	selp.b32 	%r61, 2146435072, 0, %p43;
	mov.u32 	%r62, 0;
	setp.ne.s32 	%p44, %r7, 1071644672;
	and.pred  	%p45, %p44, %p2;
	or.b32  	%r63, %r61, -2147483648;
	selp.b32 	%r64, %r63, %r61, %p45;
	mov.b64 	%fd259, {%r62, %r64};

$L__BB9_29:
	setp.eq.f64 	%p49, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd93, 0d3FF0000000000000, %fd259, %p49;
	setp.eq.f64 	%p50, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd94, 0d3FF0000000000000, %fd256, %p50;
	add.rn.f64 	%fd23, %fd94, %fd93;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd24;
	}
	and.b32  	%r72, %r71, 2147483647;
	setp.eq.s32 	%p51, %r72, 2146435072;
	setp.eq.s32 	%p52, %r70, 0;
	and.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB9_32;
	bra.uni 	$L__BB9_30;

$L__BB9_32:
	mov.f64 	%fd104, 0d0000000000000000;
	mul.rn.f64 	%fd260, %fd24, %fd104;
	mov.u32 	%r115, 0;
	bra.uni 	$L__BB9_33;

$L__BB9_30:
	mul.rn.f64 	%fd95, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r115, %fd95;
	st.local.u32 	[%rd1], %r115;
	cvt.rn.f64.s32 	%fd96, %r115;
	neg.f64 	%fd97, %fd96;
	mov.f64 	%fd98, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd99, %fd97, %fd98, %fd24;
	mov.f64 	%fd100, 0d3C91A62633145C00;
	fma.rn.f64 	%fd101, %fd97, %fd100, %fd99;
	mov.f64 	%fd102, 0d397B839A252049C0;
	fma.rn.f64 	%fd260, %fd97, %fd102, %fd101;
	abs.f64 	%fd103, %fd24;
	setp.ltu.f64 	%p54, %fd103, 0d41E0000000000000;
	@%p54 bra 	$L__BB9_33;

	{ // callseq 110, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd260, [retval0+0];
	} // callseq 110
	ld.local.u32 	%r115, [%rd1];

$L__BB9_33:
	and.b32  	%r74, %r115, 1;
	shl.b32 	%r75, %r115, 3;
	and.b32  	%r76, %r75, 8;
	setp.eq.s32 	%p55, %r74, 0;
	selp.f64 	%fd105, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p55;
	mul.wide.s32 	%rd20, %r76, 8;
	mov.u64 	%rd21, __cudart_sin_cos_coeffs;
	add.s64 	%rd22, %rd21, %rd20;
	ld.global.nc.f64 	%fd106, [%rd22+8];
	mul.rn.f64 	%fd29, %fd260, %fd260;
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd22+16];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd22+24];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd22+32];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd22+40];
	fma.rn.f64 	%fd115, %fd113, %fd29, %fd114;
	ld.global.nc.f64 	%fd116, [%rd22+48];
	fma.rn.f64 	%fd30, %fd115, %fd29, %fd116;
	fma.rn.f64 	%fd262, %fd30, %fd260, %fd260;
	@%p55 bra 	$L__BB9_35;

	mov.f64 	%fd117, 0d3FF0000000000000;
	fma.rn.f64 	%fd262, %fd30, %fd29, %fd117;

$L__BB9_35:
	and.b32  	%r77, %r115, 2;
	setp.eq.s32 	%p56, %r77, 0;
	@%p56 bra 	$L__BB9_37;

	mov.f64 	%fd118, 0d0000000000000000;
	mov.f64 	%fd119, 0dBFF0000000000000;
	fma.rn.f64 	%fd262, %fd262, %fd119, %fd118;

$L__BB9_37:
	mul.rn.f64 	%fd120, %fd262, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd121, %fd23;
	add.rn.f64 	%fd36, %fd121, %fd120;
	setp.eq.f64 	%p57, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p58, %fd3, 0d0000000000000000;
	and.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB9_41;
	bra.uni 	$L__BB9_38;

$L__BB9_41:
	selp.f64 	%fd174, 0d400921FB54442D18, 0d0000000000000000, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd174;
	}
	and.b32  	%r88, %r6, -2147483648;
	or.b32  	%r89, %r87, %r88;
	mov.b64 	%fd263, {%r86, %r89};
	bra.uni 	$L__BB9_42;

$L__BB9_38:
	setp.eq.f64 	%p60, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p61, %fd13, 0d7FF0000000000000;
	and.pred  	%p62, %p60, %p61;
	@%p62 bra 	$L__BB9_40;
	bra.uni 	$L__BB9_39;

$L__BB9_40:
	selp.f64 	%fd173, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r82, %temp}, %fd173;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd173;
	}
	and.b32  	%r84, %r6, -2147483648;
	or.b32  	%r85, %r83, %r84;
	mov.b64 	%fd263, {%r82, %r85};
	bra.uni 	$L__BB9_42;

$L__BB9_39:
	min.f64 	%fd122, %fd13, %fd3;
	max.f64 	%fd123, %fd13, %fd3;
	div.rn.f64 	%fd124, %fd122, %fd123;
	mul.rn.f64 	%fd125, %fd124, %fd124;
	mov.f64 	%fd126, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd127, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd128, %fd127, %fd125, %fd126;
	mov.f64 	%fd129, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd130, %fd128, %fd125, %fd129;
	mov.f64 	%fd131, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd132, %fd130, %fd125, %fd131;
	mov.f64 	%fd133, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd134, %fd132, %fd125, %fd133;
	mov.f64 	%fd135, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd136, %fd134, %fd125, %fd135;
	mov.f64 	%fd137, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd138, %fd136, %fd125, %fd137;
	mov.f64 	%fd139, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd140, %fd138, %fd125, %fd139;
	mov.f64 	%fd141, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd142, %fd140, %fd125, %fd141;
	mov.f64 	%fd143, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd144, %fd142, %fd125, %fd143;
	mov.f64 	%fd145, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd146, %fd144, %fd125, %fd145;
	mov.f64 	%fd147, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd148, %fd146, %fd125, %fd147;
	mov.f64 	%fd149, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd150, %fd148, %fd125, %fd149;
	mov.f64 	%fd151, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd152, %fd150, %fd125, %fd151;
	mov.f64 	%fd153, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd154, %fd152, %fd125, %fd153;
	mov.f64 	%fd155, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd156, %fd154, %fd125, %fd155;
	mov.f64 	%fd157, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd158, %fd156, %fd125, %fd157;
	mov.f64 	%fd159, 0d3FC99999999840D2;
	fma.rn.f64 	%fd160, %fd158, %fd125, %fd159;
	mov.f64 	%fd161, 0dBFD555555555544C;
	fma.rn.f64 	%fd162, %fd160, %fd125, %fd161;
	mul.rn.f64 	%fd163, %fd125, %fd162;
	fma.rn.f64 	%fd164, %fd163, %fd124, %fd124;
	mov.f64 	%fd165, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd166, %fd165, %fd164;
	setp.gt.f64 	%p64, %fd13, %fd3;
	selp.f64 	%fd167, %fd166, %fd164, %p64;
	mov.f64 	%fd168, 0d400921FB54442D18;
	sub.rn.f64 	%fd169, %fd168, %fd167;
	selp.f64 	%fd170, %fd169, %fd167, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd170;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd170;
	}
	and.b32  	%r80, %r6, -2147483648;
	or.b32  	%r81, %r79, %r80;
	mov.b64 	%fd171, {%r78, %r81};
	add.rn.f64 	%fd172, %fd3, %fd13;
	setp.le.f64 	%p65, %fd172, 0d7FF0000000000000;
	selp.f64 	%fd263, %fd171, %fd172, %p65;

$L__BB9_42:
	add.rn.f64 	%fd253, %fd78, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd253, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd41;
	}
	and.b32  	%r92, %r91, 2147483647;
	setp.eq.s32 	%p68, %r92, 2146435072;
	setp.eq.s32 	%p69, %r90, 0;
	and.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB9_46;
	bra.uni 	$L__BB9_43;

$L__BB9_46:
	mov.f64 	%fd184, 0d0000000000000000;
	mul.rn.f64 	%fd265, %fd41, %fd184;
	mov.u32 	%r117, 1;
	bra.uni 	$L__BB9_47;

$L__BB9_43:
	mul.rn.f64 	%fd175, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r116, %fd175;
	st.local.u32 	[%rd1], %r116;
	cvt.rn.f64.s32 	%fd176, %r116;
	neg.f64 	%fd177, %fd176;
	mov.f64 	%fd178, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd179, %fd177, %fd178, %fd41;
	mov.f64 	%fd180, 0d3C91A62633145C00;
	fma.rn.f64 	%fd181, %fd177, %fd180, %fd179;
	mov.f64 	%fd182, 0d397B839A252049C0;
	fma.rn.f64 	%fd265, %fd177, %fd182, %fd181;
	abs.f64 	%fd183, %fd41;
	setp.ltu.f64 	%p71, %fd183, 0d41E0000000000000;
	@%p71 bra 	$L__BB9_45;

	add.u64 	%rd44, %SP, 0;
	{ // callseq 111, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd44;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd265, [retval0+0];
	} // callseq 111
	ld.local.u32 	%r116, [%rd1];

$L__BB9_45:
	add.s32 	%r117, %r116, 1;

$L__BB9_47:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r94, %r117, 1;
	shl.b32 	%r95, %r117, 3;
	and.b32  	%r96, %r95, 8;
	setp.eq.s32 	%p72, %r94, 0;
	selp.f64 	%fd185, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p72;
	mul.wide.s32 	%rd24, %r96, 8;
	add.s64 	%rd26, %rd45, %rd24;
	ld.global.nc.f64 	%fd186, [%rd26+8];
	mul.rn.f64 	%fd47, %fd265, %fd265;
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd26+16];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd26+24];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd26+32];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd26+40];
	fma.rn.f64 	%fd195, %fd193, %fd47, %fd194;
	ld.global.nc.f64 	%fd196, [%rd26+48];
	fma.rn.f64 	%fd48, %fd195, %fd47, %fd196;
	fma.rn.f64 	%fd267, %fd48, %fd265, %fd265;
	@%p72 bra 	$L__BB9_49;

	mov.f64 	%fd197, 0d3FF0000000000000;
	fma.rn.f64 	%fd267, %fd48, %fd47, %fd197;

$L__BB9_49:
	and.b32  	%r97, %r117, 2;
	setp.eq.s32 	%p73, %r97, 0;
	@%p73 bra 	$L__BB9_51;

	mov.f64 	%fd198, 0d0000000000000000;
	mov.f64 	%fd199, 0dBFF0000000000000;
	fma.rn.f64 	%fd267, %fd267, %fd199, %fd198;

$L__BB9_51:
	mul.rn.f64 	%fd200, %fd267, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd263, %fd200;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd54;
	}
	and.b32  	%r100, %r99, 2147483647;
	setp.eq.s32 	%p74, %r100, 2146435072;
	setp.eq.s32 	%p75, %r98, 0;
	and.pred  	%p3, %p75, %p74;
	@%p3 bra 	$L__BB9_55;
	bra.uni 	$L__BB9_52;

$L__BB9_55:
	mov.f64 	%fd210, 0d0000000000000000;
	mul.rn.f64 	%fd269, %fd54, %fd210;
	mov.u32 	%r119, 1;
	bra.uni 	$L__BB9_56;

$L__BB9_52:
	mul.rn.f64 	%fd201, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd201;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd202, %r118;
	neg.f64 	%fd203, %fd202;
	mov.f64 	%fd204, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd205, %fd203, %fd204, %fd54;
	mov.f64 	%fd206, 0d3C91A62633145C00;
	fma.rn.f64 	%fd207, %fd203, %fd206, %fd205;
	mov.f64 	%fd208, 0d397B839A252049C0;
	fma.rn.f64 	%fd269, %fd203, %fd208, %fd207;
	abs.f64 	%fd209, %fd54;
	setp.ltu.f64 	%p76, %fd209, 0d41E0000000000000;
	@%p76 bra 	$L__BB9_54;

	add.u64 	%rd46, %SP, 0;
	{ // callseq 112, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd46;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd269, [retval0+0];
	} // callseq 112
	ld.local.u32 	%r118, [%rd1];

$L__BB9_54:
	add.s32 	%r119, %r118, 1;

$L__BB9_56:
	mov.u64 	%rd47, __cudart_sin_cos_coeffs;
	and.b32  	%r102, %r119, 1;
	shl.b32 	%r103, %r119, 3;
	and.b32  	%r104, %r103, 8;
	setp.eq.s32 	%p77, %r102, 0;
	selp.f64 	%fd211, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p77;
	mul.wide.s32 	%rd28, %r104, 8;
	add.s64 	%rd30, %rd47, %rd28;
	ld.global.nc.f64 	%fd212, [%rd30+8];
	mul.rn.f64 	%fd60, %fd269, %fd269;
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd30+16];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd30+24];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd30+32];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd30+40];
	fma.rn.f64 	%fd221, %fd219, %fd60, %fd220;
	ld.global.nc.f64 	%fd222, [%rd30+48];
	fma.rn.f64 	%fd61, %fd221, %fd60, %fd222;
	fma.rn.f64 	%fd271, %fd61, %fd269, %fd269;
	@%p77 bra 	$L__BB9_58;

	mov.f64 	%fd223, 0d3FF0000000000000;
	fma.rn.f64 	%fd271, %fd61, %fd60, %fd223;

$L__BB9_58:
	and.b32  	%r105, %r119, 2;
	setp.eq.s32 	%p78, %r105, 0;
	@%p78 bra 	$L__BB9_60;

	mov.f64 	%fd224, 0d0000000000000000;
	mov.f64 	%fd225, 0dBFF0000000000000;
	fma.rn.f64 	%fd271, %fd271, %fd225, %fd224;

$L__BB9_60:
	mov.u32 	%r114, %tid.x;
	mov.u32 	%r113, %ntid.x;
	mov.u32 	%r112, %ctaid.x;
	mad.lo.s32 	%r111, %r112, %r113, %r114;
	cvt.s64.s32 	%rd42, %r111;
	ld.param.u64 	%rd41, [bd09_to_gcj02_cuda_double_param_3];
	mul.rn.f64 	%fd226, %fd36, %fd271;
	cvta.to.global.u64 	%rd31, %rd41;
	shl.b64 	%rd32, %rd42, 3;
	add.s64 	%rd33, %rd31, %rd32;
	st.global.f64 	[%rd33], %fd226;
	@%p3 bra 	$L__BB9_63;
	bra.uni 	$L__BB9_61;

$L__BB9_63:
	mov.f64 	%fd236, 0d0000000000000000;
	mul.rn.f64 	%fd272, %fd54, %fd236;
	mov.u32 	%r120, 0;
	bra.uni 	$L__BB9_64;

$L__BB9_61:
	mul.rn.f64 	%fd227, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r120, %fd227;
	st.local.u32 	[%rd1], %r120;
	cvt.rn.f64.s32 	%fd228, %r120;
	neg.f64 	%fd229, %fd228;
	mov.f64 	%fd230, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd231, %fd229, %fd230, %fd54;
	mov.f64 	%fd232, 0d3C91A62633145C00;
	fma.rn.f64 	%fd233, %fd229, %fd232, %fd231;
	mov.f64 	%fd234, 0d397B839A252049C0;
	fma.rn.f64 	%fd272, %fd229, %fd234, %fd233;
	abs.f64 	%fd235, %fd54;
	setp.ltu.f64 	%p79, %fd235, 0d41E0000000000000;
	@%p79 bra 	$L__BB9_64;

	add.u64 	%rd48, %SP, 0;
	{ // callseq 113, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd48;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd272, [retval0+0];
	} // callseq 113
	ld.local.u32 	%r120, [%rd1];

$L__BB9_64:
	mov.u64 	%rd49, __cudart_sin_cos_coeffs;
	and.b32  	%r107, %r120, 1;
	shl.b32 	%r108, %r120, 3;
	and.b32  	%r109, %r108, 8;
	setp.eq.s32 	%p80, %r107, 0;
	selp.f64 	%fd237, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p80;
	mul.wide.s32 	%rd35, %r109, 8;
	add.s64 	%rd37, %rd49, %rd35;
	ld.global.nc.f64 	%fd238, [%rd37+8];
	mul.rn.f64 	%fd71, %fd272, %fd272;
	fma.rn.f64 	%fd239, %fd237, %fd71, %fd238;
	ld.global.nc.f64 	%fd240, [%rd37+16];
	fma.rn.f64 	%fd241, %fd239, %fd71, %fd240;
	ld.global.nc.f64 	%fd242, [%rd37+24];
	fma.rn.f64 	%fd243, %fd241, %fd71, %fd242;
	ld.global.nc.f64 	%fd244, [%rd37+32];
	fma.rn.f64 	%fd245, %fd243, %fd71, %fd244;
	ld.global.nc.f64 	%fd246, [%rd37+40];
	fma.rn.f64 	%fd247, %fd245, %fd71, %fd246;
	ld.global.nc.f64 	%fd248, [%rd37+48];
	fma.rn.f64 	%fd72, %fd247, %fd71, %fd248;
	fma.rn.f64 	%fd274, %fd72, %fd272, %fd272;
	@%p80 bra 	$L__BB9_66;

	mov.f64 	%fd249, 0d3FF0000000000000;
	fma.rn.f64 	%fd274, %fd72, %fd71, %fd249;

$L__BB9_66:
	and.b32  	%r110, %r120, 2;
	setp.eq.s32 	%p81, %r110, 0;
	@%p81 bra 	$L__BB9_68;

	mov.f64 	%fd250, 0d0000000000000000;
	mov.f64 	%fd251, 0dBFF0000000000000;
	fma.rn.f64 	%fd274, %fd274, %fd251, %fd250;

$L__BB9_68:
	ld.param.u64 	%rd43, [bd09_to_gcj02_cuda_double_param_4];
	mul.rn.f64 	%fd252, %fd36, %fd274;
	cvta.to.global.u64 	%rd38, %rd43;
	add.s64 	%rd40, %rd38, %rd32;
	st.global.f64 	[%rd40], %fd252;

$L__BB9_69:
	ret;

}
	// .globl	gcj02_to_bd09_cuda_double
.visible .entry gcj02_to_bd09_cuda_double(
	.param .u32 gcj02_to_bd09_cuda_double_param_0,
	.param .u64 gcj02_to_bd09_cuda_double_param_1,
	.param .u64 gcj02_to_bd09_cuda_double_param_2,
	.param .u64 gcj02_to_bd09_cuda_double_param_3,
	.param .u64 gcj02_to_bd09_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot10[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<82>;
	.reg .b32 	%r<121>;
	.reg .f64 	%fd<274>;
	.reg .b64 	%rd<50>;


	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r24, [gcj02_to_bd09_cuda_double_param_0];
	ld.param.u64 	%rd6, [gcj02_to_bd09_cuda_double_param_1];
	ld.param.u64 	%rd7, [gcj02_to_bd09_cuda_double_param_2];
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r25, %ntid.x;
	mov.u32 	%r26, %ctaid.x;
	mov.u32 	%r27, %tid.x;
	mad.lo.s32 	%r1, %r26, %r25, %r27;
	setp.ge.s32 	%p4, %r1, %r24;
	@%p4 bra 	$L__BB10_69;

	cvta.to.global.u64 	%rd14, %rd6;
	mul.wide.s32 	%rd15, %r1, 8;
	add.s64 	%rd16, %rd14, %rd15;
	cvta.to.global.u64 	%rd17, %rd7;
	add.s64 	%rd18, %rd17, %rd15;
	ld.global.f64 	%fd1, [%rd18];
	ld.global.f64 	%fd2, [%rd16];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd2;
	}
	mov.f64 	%fd78, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd78;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p5, %r4, 1062207488;
	abs.f64 	%fd3, %fd2;
	{ // callseq 114, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd255, [retval0+0];
	} // callseq 114
	setp.lt.s32 	%p6, %r2, 0;
	and.pred  	%p1, %p6, %p5;
	not.pred 	%p7, %p1;
	@%p7 bra 	$L__BB10_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd255;
	}
	xor.b32  	%r29, %r28, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r30, %temp}, %fd255;
	}
	mov.b64 	%fd255, {%r30, %r29};

$L__BB10_3:
	setp.eq.f64 	%p8, %fd2, 0d0000000000000000;
	@%p8 bra 	$L__BB10_7;
	bra.uni 	$L__BB10_4;

$L__BB10_7:
	selp.b32 	%r31, %r2, 0, %p5;
	mov.u32 	%r32, 0;
	or.b32  	%r33, %r31, 2146435072;
	setp.lt.s32 	%p12, %r3, 0;
	selp.b32 	%r34, %r33, %r31, %p12;
	mov.b64 	%fd255, {%r32, %r34};
	bra.uni 	$L__BB10_8;

$L__BB10_4:
	setp.gt.s32 	%p9, %r2, -1;
	@%p9 bra 	$L__BB10_8;

	mov.f64 	%fd79, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd80, %fd79;
	setp.eq.f64 	%p10, %fd80, 0d4000000000000000;
	@%p10 bra 	$L__BB10_8;

	mov.f64 	%fd255, 0dFFF8000000000000;

$L__BB10_8:
	add.rn.f64 	%fd82, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd82;
	}
	and.b32  	%r36, %r35, 2146435072;
	setp.ne.s32 	%p13, %r36, 2146435072;
	@%p13 bra 	$L__BB10_15;

	setp.gtu.f64 	%p14, %fd3, 0d7FF0000000000000;
	@%p14 bra 	$L__BB10_14;
	bra.uni 	$L__BB10_10;

$L__BB10_14:
	mov.f64 	%fd84, 0d4000000000000000;
	add.rn.f64 	%fd255, %fd2, %fd84;
	bra.uni 	$L__BB10_15;

$L__BB10_10:
	mov.f64 	%fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd83;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p15, %r5, 2146435072;
	setp.eq.s32 	%p16, %r37, 0;
	and.pred  	%p17, %p15, %p16;
	@%p17 bra 	$L__BB10_13;
	bra.uni 	$L__BB10_11;

$L__BB10_13:
	setp.gt.f64 	%p24, %fd3, 0d3FF0000000000000;
	selp.b32 	%r44, 2146435072, 0, %p24;
	mov.u32 	%r45, 0;
	xor.b32  	%r46, %r44, 2146435072;
	setp.lt.s32 	%p25, %r3, 0;
	selp.b32 	%r47, %r46, %r44, %p25;
	setp.eq.f64 	%p26, %fd2, 0dBFF0000000000000;
	selp.b32 	%r48, 1072693248, %r47, %p26;
	mov.b64 	%fd255, {%r45, %r48};
	bra.uni 	$L__BB10_15;

$L__BB10_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r38, %temp}, %fd2;
	}
	and.b32  	%r39, %r2, 2147483647;
	setp.ne.s32 	%p18, %r39, 2146435072;
	setp.ne.s32 	%p19, %r38, 0;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	$L__BB10_15;

	setp.gt.s32 	%p21, %r3, -1;
	selp.b32 	%r40, 2146435072, 0, %p21;
	mov.u32 	%r41, 0;
	setp.ne.s32 	%p22, %r5, 1071644672;
	and.pred  	%p23, %p22, %p1;
	or.b32  	%r42, %r40, -2147483648;
	selp.b32 	%r43, %r42, %r40, %p23;
	mov.b64 	%fd255, {%r41, %r43};

$L__BB10_15:
	abs.f64 	%fd13, %fd1;
	{ // callseq 115, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd258, [retval0+0];
	} // callseq 115
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd1;
	}
	setp.lt.s32 	%p27, %r6, 0;
	and.pred  	%p2, %p27, %p5;
	not.pred 	%p29, %p2;
	@%p29 bra 	$L__BB10_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd258;
	}
	xor.b32  	%r50, %r49, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r51, %temp}, %fd258;
	}
	mov.b64 	%fd258, {%r51, %r50};

$L__BB10_17:
	setp.eq.f64 	%p30, %fd1, 0d0000000000000000;
	@%p30 bra 	$L__BB10_21;
	bra.uni 	$L__BB10_18;

$L__BB10_21:
	selp.b32 	%r52, %r6, 0, %p5;
	mov.u32 	%r53, 0;
	or.b32  	%r54, %r52, 2146435072;
	setp.lt.s32 	%p34, %r3, 0;
	selp.b32 	%r55, %r54, %r52, %p34;
	mov.b64 	%fd258, {%r53, %r55};
	bra.uni 	$L__BB10_22;

$L__BB10_18:
	setp.gt.s32 	%p31, %r6, -1;
	@%p31 bra 	$L__BB10_22;

	mov.f64 	%fd85, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd86, %fd85;
	setp.eq.f64 	%p32, %fd86, 0d4000000000000000;
	@%p32 bra 	$L__BB10_22;

	mov.f64 	%fd258, 0dFFF8000000000000;

$L__BB10_22:
	add.rn.f64 	%fd88, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd88;
	}
	and.b32  	%r57, %r56, 2146435072;
	setp.ne.s32 	%p35, %r57, 2146435072;
	@%p35 bra 	$L__BB10_29;

	setp.gtu.f64 	%p36, %fd13, 0d7FF0000000000000;
	@%p36 bra 	$L__BB10_28;
	bra.uni 	$L__BB10_24;

$L__BB10_28:
	mov.f64 	%fd90, 0d4000000000000000;
	add.rn.f64 	%fd258, %fd1, %fd90;
	bra.uni 	$L__BB10_29;

$L__BB10_24:
	mov.f64 	%fd89, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd89;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p37, %r7, 2146435072;
	setp.eq.s32 	%p38, %r58, 0;
	and.pred  	%p39, %p37, %p38;
	@%p39 bra 	$L__BB10_27;
	bra.uni 	$L__BB10_25;

$L__BB10_27:
	setp.gt.f64 	%p46, %fd13, 0d3FF0000000000000;
	selp.b32 	%r65, 2146435072, 0, %p46;
	mov.u32 	%r66, 0;
	xor.b32  	%r67, %r65, 2146435072;
	setp.lt.s32 	%p47, %r3, 0;
	selp.b32 	%r68, %r67, %r65, %p47;
	setp.eq.f64 	%p48, %fd1, 0dBFF0000000000000;
	selp.b32 	%r69, 1072693248, %r68, %p48;
	mov.b64 	%fd258, {%r66, %r69};
	bra.uni 	$L__BB10_29;

$L__BB10_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r59, %temp}, %fd1;
	}
	and.b32  	%r60, %r6, 2147483647;
	setp.ne.s32 	%p40, %r60, 2146435072;
	setp.ne.s32 	%p41, %r59, 0;
	or.pred  	%p42, %p40, %p41;
	@%p42 bra 	$L__BB10_29;

	setp.gt.s32 	%p43, %r3, -1;
	selp.b32 	%r61, 2146435072, 0, %p43;
	mov.u32 	%r62, 0;
	setp.ne.s32 	%p44, %r7, 1071644672;
	and.pred  	%p45, %p44, %p2;
	or.b32  	%r63, %r61, -2147483648;
	selp.b32 	%r64, %r63, %r61, %p45;
	mov.b64 	%fd258, {%r62, %r64};

$L__BB10_29:
	setp.eq.f64 	%p49, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd91, 0d3FF0000000000000, %fd258, %p49;
	setp.eq.f64 	%p50, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd92, 0d3FF0000000000000, %fd255, %p50;
	add.rn.f64 	%fd23, %fd92, %fd91;
	mul.rn.f64 	%fd24, %fd1, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd24;
	}
	and.b32  	%r72, %r71, 2147483647;
	setp.eq.s32 	%p51, %r72, 2146435072;
	setp.eq.s32 	%p52, %r70, 0;
	and.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB10_32;
	bra.uni 	$L__BB10_30;

$L__BB10_32:
	mov.f64 	%fd102, 0d0000000000000000;
	mul.rn.f64 	%fd259, %fd24, %fd102;
	mov.u32 	%r115, 0;
	bra.uni 	$L__BB10_33;

$L__BB10_30:
	mul.rn.f64 	%fd93, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r115, %fd93;
	st.local.u32 	[%rd1], %r115;
	cvt.rn.f64.s32 	%fd94, %r115;
	neg.f64 	%fd95, %fd94;
	mov.f64 	%fd96, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd97, %fd95, %fd96, %fd24;
	mov.f64 	%fd98, 0d3C91A62633145C00;
	fma.rn.f64 	%fd99, %fd95, %fd98, %fd97;
	mov.f64 	%fd100, 0d397B839A252049C0;
	fma.rn.f64 	%fd259, %fd95, %fd100, %fd99;
	abs.f64 	%fd101, %fd24;
	setp.ltu.f64 	%p54, %fd101, 0d41E0000000000000;
	@%p54 bra 	$L__BB10_33;

	{ // callseq 116, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 116
	ld.local.u32 	%r115, [%rd1];

$L__BB10_33:
	and.b32  	%r74, %r115, 1;
	shl.b32 	%r75, %r115, 3;
	and.b32  	%r76, %r75, 8;
	setp.eq.s32 	%p55, %r74, 0;
	selp.f64 	%fd103, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p55;
	mul.wide.s32 	%rd20, %r76, 8;
	mov.u64 	%rd21, __cudart_sin_cos_coeffs;
	add.s64 	%rd22, %rd21, %rd20;
	ld.global.nc.f64 	%fd104, [%rd22+8];
	mul.rn.f64 	%fd29, %fd259, %fd259;
	fma.rn.f64 	%fd105, %fd103, %fd29, %fd104;
	ld.global.nc.f64 	%fd106, [%rd22+16];
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd22+24];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd22+32];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd22+40];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd22+48];
	fma.rn.f64 	%fd30, %fd113, %fd29, %fd114;
	fma.rn.f64 	%fd261, %fd30, %fd259, %fd259;
	@%p55 bra 	$L__BB10_35;

	mov.f64 	%fd115, 0d3FF0000000000000;
	fma.rn.f64 	%fd261, %fd30, %fd29, %fd115;

$L__BB10_35:
	and.b32  	%r77, %r115, 2;
	setp.eq.s32 	%p56, %r77, 0;
	@%p56 bra 	$L__BB10_37;

	mov.f64 	%fd116, 0d0000000000000000;
	mov.f64 	%fd117, 0dBFF0000000000000;
	fma.rn.f64 	%fd261, %fd261, %fd117, %fd116;

$L__BB10_37:
	mul.rn.f64 	%fd118, %fd261, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd119, %fd23;
	add.rn.f64 	%fd36, %fd119, %fd118;
	setp.eq.f64 	%p57, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p58, %fd3, 0d0000000000000000;
	and.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB10_41;
	bra.uni 	$L__BB10_38;

$L__BB10_41:
	selp.f64 	%fd172, 0d400921FB54442D18, 0d0000000000000000, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r87}, %fd172;
	}
	and.b32  	%r88, %r6, -2147483648;
	or.b32  	%r89, %r87, %r88;
	mov.b64 	%fd262, {%r86, %r89};
	bra.uni 	$L__BB10_42;

$L__BB10_38:
	setp.eq.f64 	%p60, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p61, %fd13, 0d7FF0000000000000;
	and.pred  	%p62, %p60, %p61;
	@%p62 bra 	$L__BB10_40;
	bra.uni 	$L__BB10_39;

$L__BB10_40:
	selp.f64 	%fd171, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r82, %temp}, %fd171;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd171;
	}
	and.b32  	%r84, %r6, -2147483648;
	or.b32  	%r85, %r83, %r84;
	mov.b64 	%fd262, {%r82, %r85};
	bra.uni 	$L__BB10_42;

$L__BB10_39:
	min.f64 	%fd120, %fd13, %fd3;
	max.f64 	%fd121, %fd13, %fd3;
	div.rn.f64 	%fd122, %fd120, %fd121;
	mul.rn.f64 	%fd123, %fd122, %fd122;
	mov.f64 	%fd124, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd125, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd126, %fd125, %fd123, %fd124;
	mov.f64 	%fd127, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd128, %fd126, %fd123, %fd127;
	mov.f64 	%fd129, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd130, %fd128, %fd123, %fd129;
	mov.f64 	%fd131, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd132, %fd130, %fd123, %fd131;
	mov.f64 	%fd133, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd134, %fd132, %fd123, %fd133;
	mov.f64 	%fd135, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd136, %fd134, %fd123, %fd135;
	mov.f64 	%fd137, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd138, %fd136, %fd123, %fd137;
	mov.f64 	%fd139, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd140, %fd138, %fd123, %fd139;
	mov.f64 	%fd141, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd142, %fd140, %fd123, %fd141;
	mov.f64 	%fd143, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd144, %fd142, %fd123, %fd143;
	mov.f64 	%fd145, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd146, %fd144, %fd123, %fd145;
	mov.f64 	%fd147, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd148, %fd146, %fd123, %fd147;
	mov.f64 	%fd149, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd150, %fd148, %fd123, %fd149;
	mov.f64 	%fd151, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd152, %fd150, %fd123, %fd151;
	mov.f64 	%fd153, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd154, %fd152, %fd123, %fd153;
	mov.f64 	%fd155, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd156, %fd154, %fd123, %fd155;
	mov.f64 	%fd157, 0d3FC99999999840D2;
	fma.rn.f64 	%fd158, %fd156, %fd123, %fd157;
	mov.f64 	%fd159, 0dBFD555555555544C;
	fma.rn.f64 	%fd160, %fd158, %fd123, %fd159;
	mul.rn.f64 	%fd161, %fd123, %fd160;
	fma.rn.f64 	%fd162, %fd161, %fd122, %fd122;
	mov.f64 	%fd163, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd164, %fd163, %fd162;
	setp.gt.f64 	%p64, %fd13, %fd3;
	selp.f64 	%fd165, %fd164, %fd162, %p64;
	mov.f64 	%fd166, 0d400921FB54442D18;
	sub.rn.f64 	%fd167, %fd166, %fd165;
	selp.f64 	%fd168, %fd167, %fd165, %p6;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd168;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd168;
	}
	and.b32  	%r80, %r6, -2147483648;
	or.b32  	%r81, %r79, %r80;
	mov.b64 	%fd169, {%r78, %r81};
	add.rn.f64 	%fd170, %fd3, %fd13;
	setp.le.f64 	%p65, %fd170, 0d7FF0000000000000;
	selp.f64 	%fd262, %fd169, %fd170, %p65;

$L__BB10_42:
	mul.rn.f64 	%fd41, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd41;
	}
	and.b32  	%r92, %r91, 2147483647;
	setp.eq.s32 	%p68, %r92, 2146435072;
	setp.eq.s32 	%p69, %r90, 0;
	and.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB10_46;
	bra.uni 	$L__BB10_43;

$L__BB10_46:
	mov.f64 	%fd182, 0d0000000000000000;
	mul.rn.f64 	%fd264, %fd41, %fd182;
	mov.u32 	%r117, 1;
	bra.uni 	$L__BB10_47;

$L__BB10_43:
	mul.rn.f64 	%fd173, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r116, %fd173;
	st.local.u32 	[%rd1], %r116;
	cvt.rn.f64.s32 	%fd174, %r116;
	neg.f64 	%fd175, %fd174;
	mov.f64 	%fd176, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd177, %fd175, %fd176, %fd41;
	mov.f64 	%fd178, 0d3C91A62633145C00;
	fma.rn.f64 	%fd179, %fd175, %fd178, %fd177;
	mov.f64 	%fd180, 0d397B839A252049C0;
	fma.rn.f64 	%fd264, %fd175, %fd180, %fd179;
	abs.f64 	%fd181, %fd41;
	setp.ltu.f64 	%p71, %fd181, 0d41E0000000000000;
	@%p71 bra 	$L__BB10_45;

	add.u64 	%rd44, %SP, 0;
	{ // callseq 117, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd44;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd264, [retval0+0];
	} // callseq 117
	ld.local.u32 	%r116, [%rd1];

$L__BB10_45:
	add.s32 	%r117, %r116, 1;

$L__BB10_47:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r94, %r117, 1;
	shl.b32 	%r95, %r117, 3;
	and.b32  	%r96, %r95, 8;
	setp.eq.s32 	%p72, %r94, 0;
	selp.f64 	%fd183, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p72;
	mul.wide.s32 	%rd24, %r96, 8;
	add.s64 	%rd26, %rd45, %rd24;
	ld.global.nc.f64 	%fd184, [%rd26+8];
	mul.rn.f64 	%fd47, %fd264, %fd264;
	fma.rn.f64 	%fd185, %fd183, %fd47, %fd184;
	ld.global.nc.f64 	%fd186, [%rd26+16];
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd26+24];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd26+32];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd26+40];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd26+48];
	fma.rn.f64 	%fd48, %fd193, %fd47, %fd194;
	fma.rn.f64 	%fd266, %fd48, %fd264, %fd264;
	@%p72 bra 	$L__BB10_49;

	mov.f64 	%fd195, 0d3FF0000000000000;
	fma.rn.f64 	%fd266, %fd48, %fd47, %fd195;

$L__BB10_49:
	and.b32  	%r97, %r117, 2;
	setp.eq.s32 	%p73, %r97, 0;
	@%p73 bra 	$L__BB10_51;

	mov.f64 	%fd196, 0d0000000000000000;
	mov.f64 	%fd197, 0dBFF0000000000000;
	fma.rn.f64 	%fd266, %fd266, %fd197, %fd196;

$L__BB10_51:
	mul.rn.f64 	%fd198, %fd266, 0d3EC92A737110E454;
	add.rn.f64 	%fd54, %fd262, %fd198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r98, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd54;
	}
	and.b32  	%r100, %r99, 2147483647;
	setp.eq.s32 	%p74, %r100, 2146435072;
	setp.eq.s32 	%p75, %r98, 0;
	and.pred  	%p3, %p75, %p74;
	@%p3 bra 	$L__BB10_55;
	bra.uni 	$L__BB10_52;

$L__BB10_55:
	mov.f64 	%fd208, 0d0000000000000000;
	mul.rn.f64 	%fd268, %fd54, %fd208;
	mov.u32 	%r119, 1;
	bra.uni 	$L__BB10_56;

$L__BB10_52:
	mul.rn.f64 	%fd199, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd199;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd200, %r118;
	neg.f64 	%fd201, %fd200;
	mov.f64 	%fd202, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd203, %fd201, %fd202, %fd54;
	mov.f64 	%fd204, 0d3C91A62633145C00;
	fma.rn.f64 	%fd205, %fd201, %fd204, %fd203;
	mov.f64 	%fd206, 0d397B839A252049C0;
	fma.rn.f64 	%fd268, %fd201, %fd206, %fd205;
	abs.f64 	%fd207, %fd54;
	setp.ltu.f64 	%p76, %fd207, 0d41E0000000000000;
	@%p76 bra 	$L__BB10_54;

	add.u64 	%rd46, %SP, 0;
	{ // callseq 118, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd46;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd268, [retval0+0];
	} // callseq 118
	ld.local.u32 	%r118, [%rd1];

$L__BB10_54:
	add.s32 	%r119, %r118, 1;

$L__BB10_56:
	mov.u64 	%rd47, __cudart_sin_cos_coeffs;
	and.b32  	%r102, %r119, 1;
	shl.b32 	%r103, %r119, 3;
	and.b32  	%r104, %r103, 8;
	setp.eq.s32 	%p77, %r102, 0;
	selp.f64 	%fd209, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p77;
	mul.wide.s32 	%rd28, %r104, 8;
	add.s64 	%rd30, %rd47, %rd28;
	ld.global.nc.f64 	%fd210, [%rd30+8];
	mul.rn.f64 	%fd60, %fd268, %fd268;
	fma.rn.f64 	%fd211, %fd209, %fd60, %fd210;
	ld.global.nc.f64 	%fd212, [%rd30+16];
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd30+24];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd30+32];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd30+40];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd30+48];
	fma.rn.f64 	%fd61, %fd219, %fd60, %fd220;
	fma.rn.f64 	%fd270, %fd61, %fd268, %fd268;
	@%p77 bra 	$L__BB10_58;

	mov.f64 	%fd221, 0d3FF0000000000000;
	fma.rn.f64 	%fd270, %fd61, %fd60, %fd221;

$L__BB10_58:
	and.b32  	%r105, %r119, 2;
	setp.eq.s32 	%p78, %r105, 0;
	@%p78 bra 	$L__BB10_60;

	mov.f64 	%fd222, 0d0000000000000000;
	mov.f64 	%fd223, 0dBFF0000000000000;
	fma.rn.f64 	%fd270, %fd270, %fd223, %fd222;

$L__BB10_60:
	mov.u32 	%r114, %tid.x;
	mov.u32 	%r113, %ntid.x;
	mov.u32 	%r112, %ctaid.x;
	mad.lo.s32 	%r111, %r112, %r113, %r114;
	cvt.s64.s32 	%rd42, %r111;
	ld.param.u64 	%rd41, [gcj02_to_bd09_cuda_double_param_3];
	mul.rn.f64 	%fd224, %fd36, %fd270;
	add.rn.f64 	%fd225, %fd224, 0d3F7A9FBE76C8B439;
	cvta.to.global.u64 	%rd31, %rd41;
	shl.b64 	%rd32, %rd42, 3;
	add.s64 	%rd33, %rd31, %rd32;
	st.global.f64 	[%rd33], %fd225;
	@%p3 bra 	$L__BB10_63;
	bra.uni 	$L__BB10_61;

$L__BB10_63:
	mov.f64 	%fd235, 0d0000000000000000;
	mul.rn.f64 	%fd271, %fd54, %fd235;
	mov.u32 	%r120, 0;
	bra.uni 	$L__BB10_64;

$L__BB10_61:
	mul.rn.f64 	%fd226, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r120, %fd226;
	st.local.u32 	[%rd1], %r120;
	cvt.rn.f64.s32 	%fd227, %r120;
	neg.f64 	%fd228, %fd227;
	mov.f64 	%fd229, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd230, %fd228, %fd229, %fd54;
	mov.f64 	%fd231, 0d3C91A62633145C00;
	fma.rn.f64 	%fd232, %fd228, %fd231, %fd230;
	mov.f64 	%fd233, 0d397B839A252049C0;
	fma.rn.f64 	%fd271, %fd228, %fd233, %fd232;
	abs.f64 	%fd234, %fd54;
	setp.ltu.f64 	%p79, %fd234, 0d41E0000000000000;
	@%p79 bra 	$L__BB10_64;

	add.u64 	%rd48, %SP, 0;
	{ // callseq 119, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd48;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd271, [retval0+0];
	} // callseq 119
	ld.local.u32 	%r120, [%rd1];

$L__BB10_64:
	mov.u64 	%rd49, __cudart_sin_cos_coeffs;
	and.b32  	%r107, %r120, 1;
	shl.b32 	%r108, %r120, 3;
	and.b32  	%r109, %r108, 8;
	setp.eq.s32 	%p80, %r107, 0;
	selp.f64 	%fd236, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p80;
	mul.wide.s32 	%rd35, %r109, 8;
	add.s64 	%rd37, %rd49, %rd35;
	ld.global.nc.f64 	%fd237, [%rd37+8];
	mul.rn.f64 	%fd71, %fd271, %fd271;
	fma.rn.f64 	%fd238, %fd236, %fd71, %fd237;
	ld.global.nc.f64 	%fd239, [%rd37+16];
	fma.rn.f64 	%fd240, %fd238, %fd71, %fd239;
	ld.global.nc.f64 	%fd241, [%rd37+24];
	fma.rn.f64 	%fd242, %fd240, %fd71, %fd241;
	ld.global.nc.f64 	%fd243, [%rd37+32];
	fma.rn.f64 	%fd244, %fd242, %fd71, %fd243;
	ld.global.nc.f64 	%fd245, [%rd37+40];
	fma.rn.f64 	%fd246, %fd244, %fd71, %fd245;
	ld.global.nc.f64 	%fd247, [%rd37+48];
	fma.rn.f64 	%fd72, %fd246, %fd71, %fd247;
	fma.rn.f64 	%fd273, %fd72, %fd271, %fd271;
	@%p80 bra 	$L__BB10_66;

	mov.f64 	%fd248, 0d3FF0000000000000;
	fma.rn.f64 	%fd273, %fd72, %fd71, %fd248;

$L__BB10_66:
	and.b32  	%r110, %r120, 2;
	setp.eq.s32 	%p81, %r110, 0;
	@%p81 bra 	$L__BB10_68;

	mov.f64 	%fd249, 0d0000000000000000;
	mov.f64 	%fd250, 0dBFF0000000000000;
	fma.rn.f64 	%fd273, %fd273, %fd250, %fd249;

$L__BB10_68:
	ld.param.u64 	%rd43, [gcj02_to_bd09_cuda_double_param_4];
	mul.rn.f64 	%fd251, %fd36, %fd273;
	add.rn.f64 	%fd252, %fd251, 0d3F789374BC6A7EFA;
	cvta.to.global.u64 	%rd38, %rd43;
	add.s64 	%rd40, %rd38, %rd32;
	st.global.f64 	[%rd40], %fd252;

$L__BB10_69:
	ret;

}
	// .globl	gcj02_to_wgs84_cuda_double
.visible .entry gcj02_to_wgs84_cuda_double(
	.param .u32 gcj02_to_wgs84_cuda_double_param_0,
	.param .u64 gcj02_to_wgs84_cuda_double_param_1,
	.param .u64 gcj02_to_wgs84_cuda_double_param_2,
	.param .u64 gcj02_to_wgs84_cuda_double_param_3,
	.param .u64 gcj02_to_wgs84_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot11[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<119>;
	.reg .b32 	%r<202>;
	.reg .f64 	%fd<605>;
	.reg .b64 	%rd<114>;


	mov.u64 	%SPL, __local_depot11;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r46, [gcj02_to_wgs84_cuda_double_param_0];
	ld.param.u64 	%rd14, [gcj02_to_wgs84_cuda_double_param_1];
	ld.param.u64 	%rd15, [gcj02_to_wgs84_cuda_double_param_2];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r47, %ntid.x;
	mov.u32 	%r48, %ctaid.x;
	mov.u32 	%r49, %tid.x;
	mad.lo.s32 	%r1, %r48, %r47, %r49;
	setp.ge.s32 	%p4, %r1, %r46;
	@%p4 bra 	$L__BB11_127;

	cvta.to.global.u64 	%rd30, %rd14;
	mul.wide.s32 	%rd31, %r1, 8;
	add.s64 	%rd32, %rd30, %rd31;
	cvta.to.global.u64 	%rd33, %rd15;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.f64 	%fd1, [%rd32];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd34];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd9;
	}
	and.b32  	%r52, %r51, 2147483647;
	setp.eq.s32 	%p5, %r52, 2146435072;
	setp.eq.s32 	%p6, %r50, 0;
	and.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB11_4;
	bra.uni 	$L__BB11_2;

$L__BB11_4:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd562, %fd9, %fd192;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB11_5;

$L__BB11_2:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd183;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd184, %r189;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd562, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p8, %fd191, 0d41E0000000000000;
	@%p8 bra 	$L__BB11_5;

	add.u64 	%rd101, %SP, 0;
	{ // callseq 120, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd101;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd562, [retval0+0];
	} // callseq 120
	ld.local.u32 	%r189, [%rd1];

$L__BB11_5:
	and.b32  	%r54, %r189, 1;
	shl.b32 	%r55, %r189, 3;
	and.b32  	%r56, %r55, 8;
	setp.eq.s32 	%p9, %r54, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p9;
	mul.wide.s32 	%rd36, %r56, 8;
	mov.u64 	%rd37, __cudart_sin_cos_coeffs;
	add.s64 	%rd38, %rd37, %rd36;
	ld.global.nc.f64 	%fd194, [%rd38+8];
	mul.rn.f64 	%fd14, %fd562, %fd562;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd38+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd38+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd38+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd38+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd38+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd564, %fd15, %fd562, %fd562;
	@%p9 bra 	$L__BB11_7;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd564, %fd15, %fd14, %fd205;

$L__BB11_7:
	and.b32  	%r57, %r189, 2;
	setp.eq.s32 	%p10, %r57, 0;
	@%p10 bra 	$L__BB11_9;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd564, %fd564, %fd207, %fd206;

$L__BB11_9:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd21;
	}
	and.b32  	%r60, %r59, 2147483647;
	setp.eq.s32 	%p11, %r60, 2146435072;
	setp.eq.s32 	%p12, %r58, 0;
	and.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB11_12;
	bra.uni 	$L__BB11_10;

$L__BB11_12:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd565, %fd21, %fd217;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB11_13;

$L__BB11_10:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd208;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd209, %r190;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd565, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p14, %fd216, 0d41E0000000000000;
	@%p14 bra 	$L__BB11_13;

	add.u64 	%rd102, %SP, 0;
	{ // callseq 121, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd565, [retval0+0];
	} // callseq 121
	ld.local.u32 	%r190, [%rd1];

$L__BB11_13:
	mov.u64 	%rd112, __cudart_sin_cos_coeffs;
	and.b32  	%r62, %r190, 1;
	shl.b32 	%r63, %r190, 3;
	and.b32  	%r64, %r63, 8;
	setp.eq.s32 	%p15, %r62, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p15;
	mul.wide.s32 	%rd40, %r64, 8;
	add.s64 	%rd42, %rd112, %rd40;
	ld.global.nc.f64 	%fd219, [%rd42+8];
	mul.rn.f64 	%fd26, %fd565, %fd565;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd42+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd42+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd42+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd42+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd42+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd567, %fd27, %fd565, %fd565;
	@%p15 bra 	$L__BB11_15;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd567, %fd27, %fd26, %fd230;

$L__BB11_15:
	and.b32  	%r65, %r190, 2;
	setp.eq.s32 	%p16, %r65, 0;
	@%p16 bra 	$L__BB11_17;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd567, %fd567, %fd232, %fd231;

$L__BB11_17:
	mul.rn.f64 	%fd233, %fd567, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd564, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd8;
	}
	and.b32  	%r67, %r66, 2147483647;
	setp.eq.s32 	%p17, %r67, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd8;
	}
	setp.eq.s32 	%p18, %r68, 0;
	and.pred  	%p19, %p18, %p17;
	@%p19 bra 	$L__BB11_20;
	bra.uni 	$L__BB11_18;

$L__BB11_20:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd568, %fd8, %fd244;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB11_21;

$L__BB11_18:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd235;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd236, %r191;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd568, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p20, %fd243, 0d41E0000000000000;
	@%p20 bra 	$L__BB11_21;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 122, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd568, [retval0+0];
	} // callseq 122
	ld.local.u32 	%r191, [%rd1];

$L__BB11_21:
	mov.u64 	%rd113, __cudart_sin_cos_coeffs;
	and.b32  	%r70, %r191, 1;
	shl.b32 	%r71, %r191, 3;
	and.b32  	%r72, %r71, 8;
	setp.eq.s32 	%p21, %r70, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p21;
	mul.wide.s32 	%rd44, %r72, 8;
	add.s64 	%rd46, %rd113, %rd44;
	ld.global.nc.f64 	%fd246, [%rd46+8];
	mul.rn.f64 	%fd38, %fd568, %fd568;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd46+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd46+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd46+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd46+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd46+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd570, %fd39, %fd568, %fd568;
	@%p21 bra 	$L__BB11_23;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd570, %fd39, %fd38, %fd257;

$L__BB11_23:
	and.b32  	%r73, %r191, 2;
	setp.eq.s32 	%p22, %r73, 0;
	@%p22 bra 	$L__BB11_25;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd570, %fd570, %fd259, %fd258;

$L__BB11_25:
	add.rn.f64 	%fd561, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd560, %fd561, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd560, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r75}, %fd45;
	}
	and.b32  	%r76, %r75, 2147483647;
	setp.eq.s32 	%p23, %r76, 2146435072;
	setp.eq.s32 	%p24, %r74, 0;
	and.pred  	%p25, %p24, %p23;
	@%p25 bra 	$L__BB11_28;
	bra.uni 	$L__BB11_26;

$L__BB11_28:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd571, %fd45, %fd269;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB11_29;

$L__BB11_26:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd260;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd261, %r192;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd571, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p26, %fd268, 0d41E0000000000000;
	@%p26 bra 	$L__BB11_29;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 123, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd571, [retval0+0];
	} // callseq 123
	ld.local.u32 	%r192, [%rd1];

$L__BB11_29:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r78, %r192, 1;
	shl.b32 	%r79, %r192, 3;
	and.b32  	%r80, %r79, 8;
	setp.eq.s32 	%p27, %r78, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p27;
	mul.wide.s32 	%rd48, %r80, 8;
	add.s64 	%rd50, %rd103, %rd48;
	ld.global.nc.f64 	%fd271, [%rd50+8];
	mul.rn.f64 	%fd50, %fd571, %fd571;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd50+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd50+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd50+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd50+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd50+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd573, %fd51, %fd571, %fd571;
	@%p27 bra 	$L__BB11_31;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd573, %fd51, %fd50, %fd282;

$L__BB11_31:
	and.b32  	%r81, %r192, 2;
	setp.eq.s32 	%p28, %r81, 0;
	@%p28 bra 	$L__BB11_33;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd573, %fd573, %fd284, %fd283;

$L__BB11_33:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd573, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd570, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r82, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd58;
	}
	and.b32  	%r84, %r83, 2147483647;
	setp.eq.s32 	%p29, %r84, 2146435072;
	setp.eq.s32 	%p30, %r82, 0;
	and.pred  	%p31, %p30, %p29;
	@%p31 bra 	$L__BB11_36;
	bra.uni 	$L__BB11_34;

$L__BB11_36:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd574, %fd58, %fd296;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB11_37;

$L__BB11_34:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd287;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd288, %r193;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd574, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p32, %fd295, 0d41E0000000000000;
	@%p32 bra 	$L__BB11_37;

	add.u64 	%rd90, %SP, 0;
	{ // callseq 124, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd574, [retval0+0];
	} // callseq 124
	ld.local.u32 	%r193, [%rd1];

$L__BB11_37:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r86, %r193, 1;
	shl.b32 	%r87, %r193, 3;
	and.b32  	%r88, %r87, 8;
	setp.eq.s32 	%p33, %r86, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p33;
	mul.wide.s32 	%rd52, %r88, 8;
	add.s64 	%rd54, %rd104, %rd52;
	ld.global.nc.f64 	%fd298, [%rd54+8];
	mul.rn.f64 	%fd63, %fd574, %fd574;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd54+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd54+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd54+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd54+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd54+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd576, %fd64, %fd574, %fd574;
	@%p33 bra 	$L__BB11_39;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd576, %fd64, %fd63, %fd309;

$L__BB11_39:
	and.b32  	%r89, %r193, 2;
	setp.eq.s32 	%p34, %r89, 0;
	@%p34 bra 	$L__BB11_41;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd576, %fd576, %fd311, %fd310;

$L__BB11_41:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd576, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd71;
	}
	and.b32  	%r92, %r91, 2147483647;
	setp.eq.s32 	%p35, %r92, 2146435072;
	setp.eq.s32 	%p36, %r90, 0;
	and.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB11_44;
	bra.uni 	$L__BB11_42;

$L__BB11_44:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd577, %fd71, %fd322;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB11_45;

$L__BB11_42:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd313;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd314, %r194;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd577, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p38, %fd321, 0d41E0000000000000;
	@%p38 bra 	$L__BB11_45;

	add.u64 	%rd91, %SP, 0;
	{ // callseq 125, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd91;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd577, [retval0+0];
	} // callseq 125
	ld.local.u32 	%r194, [%rd1];

$L__BB11_45:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r94, %r194, 1;
	shl.b32 	%r95, %r194, 3;
	and.b32  	%r96, %r95, 8;
	setp.eq.s32 	%p39, %r94, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p39;
	mul.wide.s32 	%rd56, %r96, 8;
	add.s64 	%rd58, %rd105, %rd56;
	ld.global.nc.f64 	%fd324, [%rd58+8];
	mul.rn.f64 	%fd76, %fd577, %fd577;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd58+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd58+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd58+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd58+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd58+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd579, %fd77, %fd577, %fd577;
	@%p39 bra 	$L__BB11_47;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd579, %fd77, %fd76, %fd335;

$L__BB11_47:
	and.b32  	%r97, %r194, 2;
	setp.eq.s32 	%p40, %r97, 0;
	@%p40 bra 	$L__BB11_49;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd579, %fd579, %fd337, %fd336;

$L__BB11_49:
	mul.rn.f64 	%fd338, %fd579, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd7;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p41, %r99, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd7;
	}
	setp.eq.s32 	%p42, %r100, 0;
	and.pred  	%p43, %p42, %p41;
	@%p43 bra 	$L__BB11_52;
	bra.uni 	$L__BB11_50;

$L__BB11_52:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd580, %fd7, %fd348;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB11_53;

$L__BB11_50:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd339;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd340, %r195;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd580, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p44, %fd347, 0d41E0000000000000;
	@%p44 bra 	$L__BB11_53;

	add.u64 	%rd92, %SP, 0;
	{ // callseq 126, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd92;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd580, [retval0+0];
	} // callseq 126
	ld.local.u32 	%r195, [%rd1];

$L__BB11_53:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r102, %r195, 1;
	shl.b32 	%r103, %r195, 3;
	and.b32  	%r104, %r103, 8;
	setp.eq.s32 	%p45, %r102, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p45;
	mul.wide.s32 	%rd60, %r104, 8;
	add.s64 	%rd62, %rd106, %rd60;
	ld.global.nc.f64 	%fd350, [%rd62+8];
	mul.rn.f64 	%fd88, %fd580, %fd580;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd62+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd62+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd62+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd62+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd62+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd582, %fd89, %fd580, %fd580;
	@%p45 bra 	$L__BB11_55;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd582, %fd89, %fd88, %fd361;

$L__BB11_55:
	and.b32  	%r105, %r195, 2;
	setp.eq.s32 	%p46, %r105, 0;
	@%p46 bra 	$L__BB11_57;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd582, %fd582, %fd363, %fd362;

$L__BB11_57:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r106, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd95;
	}
	and.b32  	%r108, %r107, 2147483647;
	setp.eq.s32 	%p47, %r108, 2146435072;
	setp.eq.s32 	%p48, %r106, 0;
	and.pred  	%p49, %p48, %p47;
	@%p49 bra 	$L__BB11_60;
	bra.uni 	$L__BB11_58;

$L__BB11_60:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd583, %fd95, %fd373;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB11_61;

$L__BB11_58:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd364;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd365, %r196;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd583, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p50, %fd372, 0d41E0000000000000;
	@%p50 bra 	$L__BB11_61;

	add.u64 	%rd93, %SP, 0;
	{ // callseq 127, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd583, [retval0+0];
	} // callseq 127
	ld.local.u32 	%r196, [%rd1];

$L__BB11_61:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r110, %r196, 1;
	shl.b32 	%r111, %r196, 3;
	and.b32  	%r112, %r111, 8;
	setp.eq.s32 	%p51, %r110, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p51;
	mul.wide.s32 	%rd64, %r112, 8;
	add.s64 	%rd66, %rd107, %rd64;
	ld.global.nc.f64 	%fd375, [%rd66+8];
	mul.rn.f64 	%fd100, %fd583, %fd583;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd66+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd66+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd66+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd66+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd66+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd585, %fd101, %fd583, %fd583;
	@%p51 bra 	$L__BB11_63;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd585, %fd101, %fd100, %fd386;

$L__BB11_63:
	and.b32  	%r113, %r196, 2;
	setp.eq.s32 	%p52, %r113, 0;
	@%p52 bra 	$L__BB11_65;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd585, %fd585, %fd388, %fd387;

$L__BB11_65:
	add.rn.f64 	%fd557, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	mul.rn.f64 	%fd389, %fd585, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd582, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd556, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd108;
	}
	and.b32  	%r116, %r115, 2147483647;
	setp.eq.s32 	%p53, %r116, 2146435072;
	setp.eq.s32 	%p54, %r114, 0;
	and.pred  	%p55, %p54, %p53;
	@%p55 bra 	$L__BB11_68;
	bra.uni 	$L__BB11_66;

$L__BB11_68:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd586, %fd108, %fd400;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB11_69;

$L__BB11_66:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd391;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd392, %r197;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd586, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p56, %fd399, 0d41E0000000000000;
	@%p56 bra 	$L__BB11_69;

	add.u64 	%rd94, %SP, 0;
	{ // callseq 128, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd586, [retval0+0];
	} // callseq 128
	ld.local.u32 	%r197, [%rd1];

$L__BB11_69:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r118, %r197, 1;
	shl.b32 	%r119, %r197, 3;
	and.b32  	%r120, %r119, 8;
	setp.eq.s32 	%p57, %r118, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p57;
	mul.wide.s32 	%rd68, %r120, 8;
	add.s64 	%rd70, %rd108, %rd68;
	ld.global.nc.f64 	%fd402, [%rd70+8];
	mul.rn.f64 	%fd113, %fd586, %fd586;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd70+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd70+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd70+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd70+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd70+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd588, %fd114, %fd586, %fd586;
	@%p57 bra 	$L__BB11_71;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd588, %fd114, %fd113, %fd413;

$L__BB11_71:
	and.b32  	%r121, %r197, 2;
	setp.eq.s32 	%p58, %r121, 0;
	@%p58 bra 	$L__BB11_73;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd588, %fd588, %fd415, %fd414;

$L__BB11_73:
	add.rn.f64 	%fd559, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd558, %fd559, 0d400921FB54442D18;
	mul.rn.f64 	%fd416, %fd588, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd558, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r122, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd121;
	}
	and.b32  	%r124, %r123, 2147483647;
	setp.eq.s32 	%p59, %r124, 2146435072;
	setp.eq.s32 	%p60, %r122, 0;
	and.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB11_76;
	bra.uni 	$L__BB11_74;

$L__BB11_76:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd589, %fd121, %fd426;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB11_77;

$L__BB11_74:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd417;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd418, %r198;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd589, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p62, %fd425, 0d41E0000000000000;
	@%p62 bra 	$L__BB11_77;

	add.u64 	%rd95, %SP, 0;
	{ // callseq 129, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd95;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd589, [retval0+0];
	} // callseq 129
	ld.local.u32 	%r198, [%rd1];

$L__BB11_77:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r126, %r198, 1;
	shl.b32 	%r127, %r198, 3;
	and.b32  	%r128, %r127, 8;
	setp.eq.s32 	%p63, %r126, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p63;
	mul.wide.s32 	%rd72, %r128, 8;
	add.s64 	%rd74, %rd109, %rd72;
	ld.global.nc.f64 	%fd428, [%rd74+8];
	mul.rn.f64 	%fd126, %fd589, %fd589;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd74+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd74+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd74+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd74+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd74+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd591, %fd127, %fd589, %fd589;
	@%p63 bra 	$L__BB11_79;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd591, %fd127, %fd126, %fd439;

$L__BB11_79:
	and.b32  	%r129, %r198, 2;
	setp.eq.s32 	%p64, %r129, 0;
	@%p64 bra 	$L__BB11_81;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd591, %fd591, %fd441, %fd440;

$L__BB11_81:
	mul.rn.f64 	%fd442, %fd591, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd445;
	}
	and.b32  	%r33, %r32, 2146435072;
	setp.eq.s32 	%p65, %r33, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 130, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 130
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd4;
	}
	setp.lt.s32 	%p66, %r34, 0;
	and.pred  	%p1, %p66, %p65;
	not.pred 	%p67, %p1;
	@%p67 bra 	$L__BB11_83;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd594;
	}
	xor.b32  	%r131, %r130, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd594;
	}
	mov.b64 	%fd594, {%r132, %r131};

$L__BB11_83:
	setp.eq.f64 	%p68, %fd4, 0d0000000000000000;
	@%p68 bra 	$L__BB11_87;
	bra.uni 	$L__BB11_84;

$L__BB11_87:
	selp.b32 	%r133, %r34, 0, %p65;
	mov.u32 	%r134, 0;
	or.b32  	%r135, %r133, 2146435072;
	setp.lt.s32 	%p72, %r32, 0;
	selp.b32 	%r136, %r135, %r133, %p72;
	mov.b64 	%fd594, {%r134, %r136};
	bra.uni 	$L__BB11_88;

$L__BB11_84:
	setp.gt.s32 	%p69, %r34, -1;
	@%p69 bra 	$L__BB11_88;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p70, %fd449, 0d4000000000000000;
	@%p70 bra 	$L__BB11_88;

	mov.f64 	%fd594, 0dFFF8000000000000;

$L__BB11_88:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r137}, %fd451;
	}
	and.b32  	%r138, %r137, 2146435072;
	setp.ne.s32 	%p73, %r138, 2146435072;
	@%p73 bra 	$L__BB11_95;

	setp.gtu.f64 	%p74, %fd136, 0d7FF0000000000000;
	@%p74 bra 	$L__BB11_94;
	bra.uni 	$L__BB11_90;

$L__BB11_94:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd594, %fd4, %fd453;
	bra.uni 	$L__BB11_95;

$L__BB11_90:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd452;
	}
	and.b32  	%r35, %r32, 2147483647;
	setp.eq.s32 	%p75, %r35, 2146435072;
	setp.eq.s32 	%p76, %r139, 0;
	and.pred  	%p77, %p75, %p76;
	@%p77 bra 	$L__BB11_93;
	bra.uni 	$L__BB11_91;

$L__BB11_93:
	setp.gt.f64 	%p84, %fd136, 0d3FF0000000000000;
	selp.b32 	%r146, 2146435072, 0, %p84;
	mov.u32 	%r147, 0;
	xor.b32  	%r148, %r146, 2146435072;
	setp.lt.s32 	%p85, %r32, 0;
	selp.b32 	%r149, %r148, %r146, %p85;
	setp.eq.f64 	%p86, %fd4, 0dBFF0000000000000;
	selp.b32 	%r150, 1072693248, %r149, %p86;
	mov.b64 	%fd594, {%r147, %r150};
	bra.uni 	$L__BB11_95;

$L__BB11_91:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd4;
	}
	and.b32  	%r141, %r34, 2147483647;
	setp.ne.s32 	%p78, %r141, 2146435072;
	setp.ne.s32 	%p79, %r140, 0;
	or.pred  	%p80, %p78, %p79;
	@%p80 bra 	$L__BB11_95;

	setp.gt.s32 	%p81, %r32, -1;
	selp.b32 	%r142, 2146435072, 0, %p81;
	mov.u32 	%r143, 0;
	setp.ne.s32 	%p82, %r35, 1071644672;
	and.pred  	%p83, %p82, %p1;
	or.b32  	%r144, %r142, -2147483648;
	selp.b32 	%r145, %r144, %r142, %p83;
	mov.b64 	%fd594, {%r143, %r145};

$L__BB11_95:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd594, 0d3FC999999999999A;
	setp.eq.f64 	%p87, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p87;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 131, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd597, [retval0+0];
	} // callseq 131
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd547;
	}
	setp.lt.s32 	%p88, %r36, 0;
	and.pred  	%p2, %p88, %p65;
	not.pred 	%p90, %p2;
	@%p90 bra 	$L__BB11_97;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd597;
	}
	xor.b32  	%r152, %r151, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd597;
	}
	mov.b64 	%fd597, {%r153, %r152};

$L__BB11_97:
	setp.eq.f64 	%p91, %fd2, 0d0000000000000000;
	@%p91 bra 	$L__BB11_101;
	bra.uni 	$L__BB11_98;

$L__BB11_101:
	selp.b32 	%r154, %r36, 0, %p65;
	mov.u32 	%r155, 0;
	or.b32  	%r156, %r154, 2146435072;
	setp.lt.s32 	%p95, %r32, 0;
	selp.b32 	%r157, %r156, %r154, %p95;
	mov.b64 	%fd597, {%r155, %r157};
	bra.uni 	$L__BB11_102;

$L__BB11_98:
	setp.gt.s32 	%p92, %r36, -1;
	@%p92 bra 	$L__BB11_102;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p93, %fd465, 0d4000000000000000;
	@%p93 bra 	$L__BB11_102;

	mov.f64 	%fd597, 0dFFF8000000000000;

$L__BB11_102:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %fd467;
	}
	and.b32  	%r159, %r158, 2146435072;
	setp.ne.s32 	%p96, %r159, 2146435072;
	@%p96 bra 	$L__BB11_109;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p97, %fd548, 0d7FF0000000000000;
	@%p97 bra 	$L__BB11_108;
	bra.uni 	$L__BB11_104;

$L__BB11_108:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd597, %fd2, %fd469;
	bra.uni 	$L__BB11_109;

$L__BB11_104:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd468;
	}
	and.b32  	%r37, %r32, 2147483647;
	setp.eq.s32 	%p98, %r37, 2146435072;
	setp.eq.s32 	%p99, %r160, 0;
	and.pred  	%p100, %p98, %p99;
	@%p100 bra 	$L__BB11_107;
	bra.uni 	$L__BB11_105;

$L__BB11_107:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p107, %fd550, 0d3FF0000000000000;
	selp.b32 	%r167, 2146435072, 0, %p107;
	mov.u32 	%r168, 0;
	xor.b32  	%r169, %r167, 2146435072;
	setp.lt.s32 	%p108, %r32, 0;
	selp.b32 	%r170, %r169, %r167, %p108;
	setp.eq.f64 	%p109, %fd551, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p109;
	mov.b64 	%fd597, {%r168, %r171};
	bra.uni 	$L__BB11_109;

$L__BB11_105:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd2;
	}
	and.b32  	%r162, %r36, 2147483647;
	setp.ne.s32 	%p101, %r162, 2146435072;
	setp.ne.s32 	%p102, %r161, 0;
	or.pred  	%p103, %p101, %p102;
	@%p103 bra 	$L__BB11_109;

	setp.gt.s32 	%p104, %r32, -1;
	selp.b32 	%r163, 2146435072, 0, %p104;
	mov.u32 	%r164, 0;
	setp.ne.s32 	%p105, %r37, 1071644672;
	and.pred  	%p106, %p105, %p2;
	or.b32  	%r165, %r163, -2147483648;
	selp.b32 	%r166, %r165, %r163, %p106;
	mov.b64 	%fd597, {%r164, %r166};

$L__BB11_109:
	mul.rn.f64 	%fd470, %fd597, 0d3FB999999999999A;
	setp.eq.f64 	%p110, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p110;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r172, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd159;
	}
	and.b32  	%r174, %r173, 2147483647;
	setp.eq.s32 	%p111, %r174, 2146435072;
	setp.eq.s32 	%p112, %r172, 0;
	and.pred  	%p3, %p112, %p111;
	@%p3 bra 	$L__BB11_112;
	bra.uni 	$L__BB11_110;

$L__BB11_112:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd487;
	mov.u32 	%r199, 0;
	bra.uni 	$L__BB11_113;

$L__BB11_110:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd478;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd479, %r199;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p113, %fd486, 0d41E0000000000000;
	@%p113 bra 	$L__BB11_113;

	add.u64 	%rd96, %SP, 0;
	{ // callseq 132, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 132
	ld.local.u32 	%r199, [%rd1];

$L__BB11_113:
	mov.u64 	%rd110, __cudart_sin_cos_coeffs;
	and.b32  	%r176, %r199, 1;
	shl.b32 	%r177, %r199, 3;
	and.b32  	%r178, %r177, 8;
	setp.eq.s32 	%p114, %r176, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p114;
	mul.wide.s32 	%rd76, %r178, 8;
	add.s64 	%rd78, %rd110, %rd76;
	ld.global.nc.f64 	%fd489, [%rd78+8];
	mul.rn.f64 	%fd164, %fd598, %fd598;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd78+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd78+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd78+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd78+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd78+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd600, %fd165, %fd598, %fd598;
	@%p114 bra 	$L__BB11_115;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd165, %fd164, %fd500;

$L__BB11_115:
	and.b32  	%r179, %r199, 2;
	setp.eq.s32 	%p115, %r179, 0;
	@%p115 bra 	$L__BB11_117;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd502, %fd501;

$L__BB11_117:
	@%p3 bra 	$L__BB11_121;
	bra.uni 	$L__BB11_118;

$L__BB11_121:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd602, %fd159, %fd512;
	mov.u32 	%r201, 1;
	bra.uni 	$L__BB11_122;

$L__BB11_118:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r200, %fd503;
	st.local.u32 	[%rd1], %r200;
	cvt.rn.f64.s32 	%fd504, %r200;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd602, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p116, %fd511, 0d41E0000000000000;
	@%p116 bra 	$L__BB11_120;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 133, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd602, [retval0+0];
	} // callseq 133
	ld.local.u32 	%r200, [%rd1];

$L__BB11_120:
	add.s32 	%r201, %r200, 1;

$L__BB11_122:
	mov.u64 	%rd111, __cudart_sin_cos_coeffs;
	and.b32  	%r181, %r201, 1;
	shl.b32 	%r182, %r201, 3;
	and.b32  	%r183, %r182, 8;
	setp.eq.s32 	%p117, %r181, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p117;
	mul.wide.s32 	%rd80, %r183, 8;
	add.s64 	%rd82, %rd111, %rd80;
	ld.global.nc.f64 	%fd514, [%rd82+8];
	mul.rn.f64 	%fd176, %fd602, %fd602;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd82+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd82+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd82+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd82+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd82+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd604, %fd177, %fd602, %fd602;
	@%p117 bra 	$L__BB11_124;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd604, %fd177, %fd176, %fd525;

$L__BB11_124:
	and.b32  	%r184, %r201, 2;
	setp.eq.s32 	%p118, %r184, 0;
	@%p118 bra 	$L__BB11_126;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd604, %fd604, %fd527, %fd526;

$L__BB11_126:
	ld.param.u64 	%rd100, [gcj02_to_wgs84_cuda_double_param_4];
	mov.u32 	%r188, %tid.x;
	mov.u32 	%r187, %ntid.x;
	mov.u32 	%r186, %ctaid.x;
	mad.lo.s32 	%r185, %r186, %r187, %r188;
	cvt.s64.s32 	%rd99, %r185;
	ld.param.u64 	%rd98, [gcj02_to_wgs84_cuda_double_param_3];
	mul.rn.f64 	%fd528, %fd600, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd600, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0dC15854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd604;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	cvta.to.global.u64 	%rd83, %rd98;
	shl.b64 	%rd84, %rd99, 3;
	add.s64 	%rd85, %rd83, %rd84;
	st.global.f64 	[%rd85], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0dC1582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	cvta.to.global.u64 	%rd86, %rd100;
	add.s64 	%rd87, %rd86, %rd84;
	st.global.f64 	[%rd87], %fd545;

$L__BB11_127:
	ret;

}
	// .globl	wgs84_to_gcj02_cuda_double
.visible .entry wgs84_to_gcj02_cuda_double(
	.param .u32 wgs84_to_gcj02_cuda_double_param_0,
	.param .u64 wgs84_to_gcj02_cuda_double_param_1,
	.param .u64 wgs84_to_gcj02_cuda_double_param_2,
	.param .u64 wgs84_to_gcj02_cuda_double_param_3,
	.param .u64 wgs84_to_gcj02_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot12[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<119>;
	.reg .b32 	%r<202>;
	.reg .f64 	%fd<605>;
	.reg .b64 	%rd<114>;


	mov.u64 	%SPL, __local_depot12;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r46, [wgs84_to_gcj02_cuda_double_param_0];
	ld.param.u64 	%rd14, [wgs84_to_gcj02_cuda_double_param_1];
	ld.param.u64 	%rd15, [wgs84_to_gcj02_cuda_double_param_2];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r47, %ntid.x;
	mov.u32 	%r48, %ctaid.x;
	mov.u32 	%r49, %tid.x;
	mad.lo.s32 	%r1, %r48, %r47, %r49;
	setp.ge.s32 	%p4, %r1, %r46;
	@%p4 bra 	$L__BB12_127;

	cvta.to.global.u64 	%rd30, %rd14;
	mul.wide.s32 	%rd31, %r1, 8;
	add.s64 	%rd32, %rd30, %rd31;
	cvta.to.global.u64 	%rd33, %rd15;
	add.s64 	%rd34, %rd33, %rd31;
	ld.global.f64 	%fd1, [%rd32];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd34];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r51}, %fd9;
	}
	and.b32  	%r52, %r51, 2147483647;
	setp.eq.s32 	%p5, %r52, 2146435072;
	setp.eq.s32 	%p6, %r50, 0;
	and.pred  	%p7, %p6, %p5;
	@%p7 bra 	$L__BB12_4;
	bra.uni 	$L__BB12_2;

$L__BB12_4:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd562, %fd9, %fd192;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB12_5;

$L__BB12_2:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd183;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd184, %r189;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd562, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p8, %fd191, 0d41E0000000000000;
	@%p8 bra 	$L__BB12_5;

	add.u64 	%rd101, %SP, 0;
	{ // callseq 134, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd101;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd562, [retval0+0];
	} // callseq 134
	ld.local.u32 	%r189, [%rd1];

$L__BB12_5:
	and.b32  	%r54, %r189, 1;
	shl.b32 	%r55, %r189, 3;
	and.b32  	%r56, %r55, 8;
	setp.eq.s32 	%p9, %r54, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p9;
	mul.wide.s32 	%rd36, %r56, 8;
	mov.u64 	%rd37, __cudart_sin_cos_coeffs;
	add.s64 	%rd38, %rd37, %rd36;
	ld.global.nc.f64 	%fd194, [%rd38+8];
	mul.rn.f64 	%fd14, %fd562, %fd562;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd38+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd38+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd38+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd38+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd38+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd564, %fd15, %fd562, %fd562;
	@%p9 bra 	$L__BB12_7;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd564, %fd15, %fd14, %fd205;

$L__BB12_7:
	and.b32  	%r57, %r189, 2;
	setp.eq.s32 	%p10, %r57, 0;
	@%p10 bra 	$L__BB12_9;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd564, %fd564, %fd207, %fd206;

$L__BB12_9:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r59}, %fd21;
	}
	and.b32  	%r60, %r59, 2147483647;
	setp.eq.s32 	%p11, %r60, 2146435072;
	setp.eq.s32 	%p12, %r58, 0;
	and.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB12_12;
	bra.uni 	$L__BB12_10;

$L__BB12_12:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd565, %fd21, %fd217;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB12_13;

$L__BB12_10:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd208;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd209, %r190;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd565, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p14, %fd216, 0d41E0000000000000;
	@%p14 bra 	$L__BB12_13;

	add.u64 	%rd102, %SP, 0;
	{ // callseq 135, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd102;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd565, [retval0+0];
	} // callseq 135
	ld.local.u32 	%r190, [%rd1];

$L__BB12_13:
	mov.u64 	%rd112, __cudart_sin_cos_coeffs;
	and.b32  	%r62, %r190, 1;
	shl.b32 	%r63, %r190, 3;
	and.b32  	%r64, %r63, 8;
	setp.eq.s32 	%p15, %r62, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p15;
	mul.wide.s32 	%rd40, %r64, 8;
	add.s64 	%rd42, %rd112, %rd40;
	ld.global.nc.f64 	%fd219, [%rd42+8];
	mul.rn.f64 	%fd26, %fd565, %fd565;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd42+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd42+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd42+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd42+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd42+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd567, %fd27, %fd565, %fd565;
	@%p15 bra 	$L__BB12_15;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd567, %fd27, %fd26, %fd230;

$L__BB12_15:
	and.b32  	%r65, %r190, 2;
	setp.eq.s32 	%p16, %r65, 0;
	@%p16 bra 	$L__BB12_17;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd567, %fd567, %fd232, %fd231;

$L__BB12_17:
	mul.rn.f64 	%fd233, %fd567, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd564, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r66}, %fd8;
	}
	and.b32  	%r67, %r66, 2147483647;
	setp.eq.s32 	%p17, %r67, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r68, %temp}, %fd8;
	}
	setp.eq.s32 	%p18, %r68, 0;
	and.pred  	%p19, %p18, %p17;
	@%p19 bra 	$L__BB12_20;
	bra.uni 	$L__BB12_18;

$L__BB12_20:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd568, %fd8, %fd244;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB12_21;

$L__BB12_18:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd235;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd236, %r191;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd568, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p20, %fd243, 0d41E0000000000000;
	@%p20 bra 	$L__BB12_21;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 136, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd568, [retval0+0];
	} // callseq 136
	ld.local.u32 	%r191, [%rd1];

$L__BB12_21:
	mov.u64 	%rd113, __cudart_sin_cos_coeffs;
	and.b32  	%r70, %r191, 1;
	shl.b32 	%r71, %r191, 3;
	and.b32  	%r72, %r71, 8;
	setp.eq.s32 	%p21, %r70, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p21;
	mul.wide.s32 	%rd44, %r72, 8;
	add.s64 	%rd46, %rd113, %rd44;
	ld.global.nc.f64 	%fd246, [%rd46+8];
	mul.rn.f64 	%fd38, %fd568, %fd568;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd46+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd46+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd46+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd46+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd46+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd570, %fd39, %fd568, %fd568;
	@%p21 bra 	$L__BB12_23;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd570, %fd39, %fd38, %fd257;

$L__BB12_23:
	and.b32  	%r73, %r191, 2;
	setp.eq.s32 	%p22, %r73, 0;
	@%p22 bra 	$L__BB12_25;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd570, %fd570, %fd259, %fd258;

$L__BB12_25:
	add.rn.f64 	%fd561, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd560, %fd561, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd560, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r74, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r75}, %fd45;
	}
	and.b32  	%r76, %r75, 2147483647;
	setp.eq.s32 	%p23, %r76, 2146435072;
	setp.eq.s32 	%p24, %r74, 0;
	and.pred  	%p25, %p24, %p23;
	@%p25 bra 	$L__BB12_28;
	bra.uni 	$L__BB12_26;

$L__BB12_28:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd571, %fd45, %fd269;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB12_29;

$L__BB12_26:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd260;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd261, %r192;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd571, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p26, %fd268, 0d41E0000000000000;
	@%p26 bra 	$L__BB12_29;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 137, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd571, [retval0+0];
	} // callseq 137
	ld.local.u32 	%r192, [%rd1];

$L__BB12_29:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r78, %r192, 1;
	shl.b32 	%r79, %r192, 3;
	and.b32  	%r80, %r79, 8;
	setp.eq.s32 	%p27, %r78, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p27;
	mul.wide.s32 	%rd48, %r80, 8;
	add.s64 	%rd50, %rd103, %rd48;
	ld.global.nc.f64 	%fd271, [%rd50+8];
	mul.rn.f64 	%fd50, %fd571, %fd571;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd50+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd50+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd50+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd50+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd50+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd573, %fd51, %fd571, %fd571;
	@%p27 bra 	$L__BB12_31;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd573, %fd51, %fd50, %fd282;

$L__BB12_31:
	and.b32  	%r81, %r192, 2;
	setp.eq.s32 	%p28, %r81, 0;
	@%p28 bra 	$L__BB12_33;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd573, %fd573, %fd284, %fd283;

$L__BB12_33:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd573, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd570, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r82, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r83}, %fd58;
	}
	and.b32  	%r84, %r83, 2147483647;
	setp.eq.s32 	%p29, %r84, 2146435072;
	setp.eq.s32 	%p30, %r82, 0;
	and.pred  	%p31, %p30, %p29;
	@%p31 bra 	$L__BB12_36;
	bra.uni 	$L__BB12_34;

$L__BB12_36:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd574, %fd58, %fd296;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB12_37;

$L__BB12_34:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd287;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd288, %r193;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd574, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p32, %fd295, 0d41E0000000000000;
	@%p32 bra 	$L__BB12_37;

	add.u64 	%rd90, %SP, 0;
	{ // callseq 138, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd90;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd574, [retval0+0];
	} // callseq 138
	ld.local.u32 	%r193, [%rd1];

$L__BB12_37:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r86, %r193, 1;
	shl.b32 	%r87, %r193, 3;
	and.b32  	%r88, %r87, 8;
	setp.eq.s32 	%p33, %r86, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p33;
	mul.wide.s32 	%rd52, %r88, 8;
	add.s64 	%rd54, %rd104, %rd52;
	ld.global.nc.f64 	%fd298, [%rd54+8];
	mul.rn.f64 	%fd63, %fd574, %fd574;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd54+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd54+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd54+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd54+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd54+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd576, %fd64, %fd574, %fd574;
	@%p33 bra 	$L__BB12_39;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd576, %fd64, %fd63, %fd309;

$L__BB12_39:
	and.b32  	%r89, %r193, 2;
	setp.eq.s32 	%p34, %r89, 0;
	@%p34 bra 	$L__BB12_41;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd576, %fd576, %fd311, %fd310;

$L__BB12_41:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd576, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r90, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd71;
	}
	and.b32  	%r92, %r91, 2147483647;
	setp.eq.s32 	%p35, %r92, 2146435072;
	setp.eq.s32 	%p36, %r90, 0;
	and.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB12_44;
	bra.uni 	$L__BB12_42;

$L__BB12_44:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd577, %fd71, %fd322;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB12_45;

$L__BB12_42:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd313;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd314, %r194;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd577, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p38, %fd321, 0d41E0000000000000;
	@%p38 bra 	$L__BB12_45;

	add.u64 	%rd91, %SP, 0;
	{ // callseq 139, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd91;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd577, [retval0+0];
	} // callseq 139
	ld.local.u32 	%r194, [%rd1];

$L__BB12_45:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r94, %r194, 1;
	shl.b32 	%r95, %r194, 3;
	and.b32  	%r96, %r95, 8;
	setp.eq.s32 	%p39, %r94, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p39;
	mul.wide.s32 	%rd56, %r96, 8;
	add.s64 	%rd58, %rd105, %rd56;
	ld.global.nc.f64 	%fd324, [%rd58+8];
	mul.rn.f64 	%fd76, %fd577, %fd577;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd58+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd58+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd58+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd58+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd58+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd579, %fd77, %fd577, %fd577;
	@%p39 bra 	$L__BB12_47;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd579, %fd77, %fd76, %fd335;

$L__BB12_47:
	and.b32  	%r97, %r194, 2;
	setp.eq.s32 	%p40, %r97, 0;
	@%p40 bra 	$L__BB12_49;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd579, %fd579, %fd337, %fd336;

$L__BB12_49:
	mul.rn.f64 	%fd338, %fd579, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd7;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p41, %r99, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd7;
	}
	setp.eq.s32 	%p42, %r100, 0;
	and.pred  	%p43, %p42, %p41;
	@%p43 bra 	$L__BB12_52;
	bra.uni 	$L__BB12_50;

$L__BB12_52:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd580, %fd7, %fd348;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB12_53;

$L__BB12_50:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd339;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd340, %r195;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd580, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p44, %fd347, 0d41E0000000000000;
	@%p44 bra 	$L__BB12_53;

	add.u64 	%rd92, %SP, 0;
	{ // callseq 140, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd92;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd580, [retval0+0];
	} // callseq 140
	ld.local.u32 	%r195, [%rd1];

$L__BB12_53:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r102, %r195, 1;
	shl.b32 	%r103, %r195, 3;
	and.b32  	%r104, %r103, 8;
	setp.eq.s32 	%p45, %r102, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p45;
	mul.wide.s32 	%rd60, %r104, 8;
	add.s64 	%rd62, %rd106, %rd60;
	ld.global.nc.f64 	%fd350, [%rd62+8];
	mul.rn.f64 	%fd88, %fd580, %fd580;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd62+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd62+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd62+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd62+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd62+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd582, %fd89, %fd580, %fd580;
	@%p45 bra 	$L__BB12_55;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd582, %fd89, %fd88, %fd361;

$L__BB12_55:
	and.b32  	%r105, %r195, 2;
	setp.eq.s32 	%p46, %r105, 0;
	@%p46 bra 	$L__BB12_57;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd582, %fd582, %fd363, %fd362;

$L__BB12_57:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r106, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd95;
	}
	and.b32  	%r108, %r107, 2147483647;
	setp.eq.s32 	%p47, %r108, 2146435072;
	setp.eq.s32 	%p48, %r106, 0;
	and.pred  	%p49, %p48, %p47;
	@%p49 bra 	$L__BB12_60;
	bra.uni 	$L__BB12_58;

$L__BB12_60:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd583, %fd95, %fd373;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB12_61;

$L__BB12_58:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd364;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd365, %r196;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd583, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p50, %fd372, 0d41E0000000000000;
	@%p50 bra 	$L__BB12_61;

	add.u64 	%rd93, %SP, 0;
	{ // callseq 141, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd93;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd583, [retval0+0];
	} // callseq 141
	ld.local.u32 	%r196, [%rd1];

$L__BB12_61:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r110, %r196, 1;
	shl.b32 	%r111, %r196, 3;
	and.b32  	%r112, %r111, 8;
	setp.eq.s32 	%p51, %r110, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p51;
	mul.wide.s32 	%rd64, %r112, 8;
	add.s64 	%rd66, %rd107, %rd64;
	ld.global.nc.f64 	%fd375, [%rd66+8];
	mul.rn.f64 	%fd100, %fd583, %fd583;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd66+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd66+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd66+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd66+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd66+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd585, %fd101, %fd583, %fd583;
	@%p51 bra 	$L__BB12_63;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd585, %fd101, %fd100, %fd386;

$L__BB12_63:
	and.b32  	%r113, %r196, 2;
	setp.eq.s32 	%p52, %r113, 0;
	@%p52 bra 	$L__BB12_65;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd585, %fd585, %fd388, %fd387;

$L__BB12_65:
	add.rn.f64 	%fd557, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	mul.rn.f64 	%fd389, %fd585, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd582, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd556, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd108;
	}
	and.b32  	%r116, %r115, 2147483647;
	setp.eq.s32 	%p53, %r116, 2146435072;
	setp.eq.s32 	%p54, %r114, 0;
	and.pred  	%p55, %p54, %p53;
	@%p55 bra 	$L__BB12_68;
	bra.uni 	$L__BB12_66;

$L__BB12_68:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd586, %fd108, %fd400;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB12_69;

$L__BB12_66:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd391;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd392, %r197;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd586, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p56, %fd399, 0d41E0000000000000;
	@%p56 bra 	$L__BB12_69;

	add.u64 	%rd94, %SP, 0;
	{ // callseq 142, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd586, [retval0+0];
	} // callseq 142
	ld.local.u32 	%r197, [%rd1];

$L__BB12_69:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r118, %r197, 1;
	shl.b32 	%r119, %r197, 3;
	and.b32  	%r120, %r119, 8;
	setp.eq.s32 	%p57, %r118, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p57;
	mul.wide.s32 	%rd68, %r120, 8;
	add.s64 	%rd70, %rd108, %rd68;
	ld.global.nc.f64 	%fd402, [%rd70+8];
	mul.rn.f64 	%fd113, %fd586, %fd586;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd70+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd70+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd70+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd70+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd70+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd588, %fd114, %fd586, %fd586;
	@%p57 bra 	$L__BB12_71;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd588, %fd114, %fd113, %fd413;

$L__BB12_71:
	and.b32  	%r121, %r197, 2;
	setp.eq.s32 	%p58, %r121, 0;
	@%p58 bra 	$L__BB12_73;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd588, %fd588, %fd415, %fd414;

$L__BB12_73:
	add.rn.f64 	%fd559, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd558, %fd559, 0d400921FB54442D18;
	mul.rn.f64 	%fd416, %fd588, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd558, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r122, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd121;
	}
	and.b32  	%r124, %r123, 2147483647;
	setp.eq.s32 	%p59, %r124, 2146435072;
	setp.eq.s32 	%p60, %r122, 0;
	and.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB12_76;
	bra.uni 	$L__BB12_74;

$L__BB12_76:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd589, %fd121, %fd426;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB12_77;

$L__BB12_74:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd417;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd418, %r198;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd589, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p62, %fd425, 0d41E0000000000000;
	@%p62 bra 	$L__BB12_77;

	add.u64 	%rd95, %SP, 0;
	{ // callseq 143, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd95;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd589, [retval0+0];
	} // callseq 143
	ld.local.u32 	%r198, [%rd1];

$L__BB12_77:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r126, %r198, 1;
	shl.b32 	%r127, %r198, 3;
	and.b32  	%r128, %r127, 8;
	setp.eq.s32 	%p63, %r126, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p63;
	mul.wide.s32 	%rd72, %r128, 8;
	add.s64 	%rd74, %rd109, %rd72;
	ld.global.nc.f64 	%fd428, [%rd74+8];
	mul.rn.f64 	%fd126, %fd589, %fd589;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd74+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd74+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd74+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd74+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd74+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd591, %fd127, %fd589, %fd589;
	@%p63 bra 	$L__BB12_79;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd591, %fd127, %fd126, %fd439;

$L__BB12_79:
	and.b32  	%r129, %r198, 2;
	setp.eq.s32 	%p64, %r129, 0;
	@%p64 bra 	$L__BB12_81;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd591, %fd591, %fd441, %fd440;

$L__BB12_81:
	mul.rn.f64 	%fd442, %fd591, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd445;
	}
	and.b32  	%r33, %r32, 2146435072;
	setp.eq.s32 	%p65, %r33, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 144, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 144
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd4;
	}
	setp.lt.s32 	%p66, %r34, 0;
	and.pred  	%p1, %p66, %p65;
	not.pred 	%p67, %p1;
	@%p67 bra 	$L__BB12_83;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd594;
	}
	xor.b32  	%r131, %r130, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd594;
	}
	mov.b64 	%fd594, {%r132, %r131};

$L__BB12_83:
	setp.eq.f64 	%p68, %fd4, 0d0000000000000000;
	@%p68 bra 	$L__BB12_87;
	bra.uni 	$L__BB12_84;

$L__BB12_87:
	selp.b32 	%r133, %r34, 0, %p65;
	mov.u32 	%r134, 0;
	or.b32  	%r135, %r133, 2146435072;
	setp.lt.s32 	%p72, %r32, 0;
	selp.b32 	%r136, %r135, %r133, %p72;
	mov.b64 	%fd594, {%r134, %r136};
	bra.uni 	$L__BB12_88;

$L__BB12_84:
	setp.gt.s32 	%p69, %r34, -1;
	@%p69 bra 	$L__BB12_88;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p70, %fd449, 0d4000000000000000;
	@%p70 bra 	$L__BB12_88;

	mov.f64 	%fd594, 0dFFF8000000000000;

$L__BB12_88:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r137}, %fd451;
	}
	and.b32  	%r138, %r137, 2146435072;
	setp.ne.s32 	%p73, %r138, 2146435072;
	@%p73 bra 	$L__BB12_95;

	setp.gtu.f64 	%p74, %fd136, 0d7FF0000000000000;
	@%p74 bra 	$L__BB12_94;
	bra.uni 	$L__BB12_90;

$L__BB12_94:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd594, %fd4, %fd453;
	bra.uni 	$L__BB12_95;

$L__BB12_90:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd452;
	}
	and.b32  	%r35, %r32, 2147483647;
	setp.eq.s32 	%p75, %r35, 2146435072;
	setp.eq.s32 	%p76, %r139, 0;
	and.pred  	%p77, %p75, %p76;
	@%p77 bra 	$L__BB12_93;
	bra.uni 	$L__BB12_91;

$L__BB12_93:
	setp.gt.f64 	%p84, %fd136, 0d3FF0000000000000;
	selp.b32 	%r146, 2146435072, 0, %p84;
	mov.u32 	%r147, 0;
	xor.b32  	%r148, %r146, 2146435072;
	setp.lt.s32 	%p85, %r32, 0;
	selp.b32 	%r149, %r148, %r146, %p85;
	setp.eq.f64 	%p86, %fd4, 0dBFF0000000000000;
	selp.b32 	%r150, 1072693248, %r149, %p86;
	mov.b64 	%fd594, {%r147, %r150};
	bra.uni 	$L__BB12_95;

$L__BB12_91:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd4;
	}
	and.b32  	%r141, %r34, 2147483647;
	setp.ne.s32 	%p78, %r141, 2146435072;
	setp.ne.s32 	%p79, %r140, 0;
	or.pred  	%p80, %p78, %p79;
	@%p80 bra 	$L__BB12_95;

	setp.gt.s32 	%p81, %r32, -1;
	selp.b32 	%r142, 2146435072, 0, %p81;
	mov.u32 	%r143, 0;
	setp.ne.s32 	%p82, %r35, 1071644672;
	and.pred  	%p83, %p82, %p1;
	or.b32  	%r144, %r142, -2147483648;
	selp.b32 	%r145, %r144, %r142, %p83;
	mov.b64 	%fd594, {%r143, %r145};

$L__BB12_95:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd594, 0d3FC999999999999A;
	setp.eq.f64 	%p87, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p87;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 145, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd597, [retval0+0];
	} // callseq 145
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd547;
	}
	setp.lt.s32 	%p88, %r36, 0;
	and.pred  	%p2, %p88, %p65;
	not.pred 	%p90, %p2;
	@%p90 bra 	$L__BB12_97;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd597;
	}
	xor.b32  	%r152, %r151, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd597;
	}
	mov.b64 	%fd597, {%r153, %r152};

$L__BB12_97:
	setp.eq.f64 	%p91, %fd2, 0d0000000000000000;
	@%p91 bra 	$L__BB12_101;
	bra.uni 	$L__BB12_98;

$L__BB12_101:
	selp.b32 	%r154, %r36, 0, %p65;
	mov.u32 	%r155, 0;
	or.b32  	%r156, %r154, 2146435072;
	setp.lt.s32 	%p95, %r32, 0;
	selp.b32 	%r157, %r156, %r154, %p95;
	mov.b64 	%fd597, {%r155, %r157};
	bra.uni 	$L__BB12_102;

$L__BB12_98:
	setp.gt.s32 	%p92, %r36, -1;
	@%p92 bra 	$L__BB12_102;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p93, %fd465, 0d4000000000000000;
	@%p93 bra 	$L__BB12_102;

	mov.f64 	%fd597, 0dFFF8000000000000;

$L__BB12_102:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %fd467;
	}
	and.b32  	%r159, %r158, 2146435072;
	setp.ne.s32 	%p96, %r159, 2146435072;
	@%p96 bra 	$L__BB12_109;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p97, %fd548, 0d7FF0000000000000;
	@%p97 bra 	$L__BB12_108;
	bra.uni 	$L__BB12_104;

$L__BB12_108:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd597, %fd2, %fd469;
	bra.uni 	$L__BB12_109;

$L__BB12_104:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd468;
	}
	and.b32  	%r37, %r32, 2147483647;
	setp.eq.s32 	%p98, %r37, 2146435072;
	setp.eq.s32 	%p99, %r160, 0;
	and.pred  	%p100, %p98, %p99;
	@%p100 bra 	$L__BB12_107;
	bra.uni 	$L__BB12_105;

$L__BB12_107:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p107, %fd550, 0d3FF0000000000000;
	selp.b32 	%r167, 2146435072, 0, %p107;
	mov.u32 	%r168, 0;
	xor.b32  	%r169, %r167, 2146435072;
	setp.lt.s32 	%p108, %r32, 0;
	selp.b32 	%r170, %r169, %r167, %p108;
	setp.eq.f64 	%p109, %fd551, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p109;
	mov.b64 	%fd597, {%r168, %r171};
	bra.uni 	$L__BB12_109;

$L__BB12_105:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd2;
	}
	and.b32  	%r162, %r36, 2147483647;
	setp.ne.s32 	%p101, %r162, 2146435072;
	setp.ne.s32 	%p102, %r161, 0;
	or.pred  	%p103, %p101, %p102;
	@%p103 bra 	$L__BB12_109;

	setp.gt.s32 	%p104, %r32, -1;
	selp.b32 	%r163, 2146435072, 0, %p104;
	mov.u32 	%r164, 0;
	setp.ne.s32 	%p105, %r37, 1071644672;
	and.pred  	%p106, %p105, %p2;
	or.b32  	%r165, %r163, -2147483648;
	selp.b32 	%r166, %r165, %r163, %p106;
	mov.b64 	%fd597, {%r164, %r166};

$L__BB12_109:
	mul.rn.f64 	%fd470, %fd597, 0d3FB999999999999A;
	setp.eq.f64 	%p110, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p110;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r172, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd159;
	}
	and.b32  	%r174, %r173, 2147483647;
	setp.eq.s32 	%p111, %r174, 2146435072;
	setp.eq.s32 	%p112, %r172, 0;
	and.pred  	%p3, %p112, %p111;
	@%p3 bra 	$L__BB12_112;
	bra.uni 	$L__BB12_110;

$L__BB12_112:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd487;
	mov.u32 	%r199, 0;
	bra.uni 	$L__BB12_113;

$L__BB12_110:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd478;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd479, %r199;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p113, %fd486, 0d41E0000000000000;
	@%p113 bra 	$L__BB12_113;

	add.u64 	%rd96, %SP, 0;
	{ // callseq 146, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd96;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 146
	ld.local.u32 	%r199, [%rd1];

$L__BB12_113:
	mov.u64 	%rd110, __cudart_sin_cos_coeffs;
	and.b32  	%r176, %r199, 1;
	shl.b32 	%r177, %r199, 3;
	and.b32  	%r178, %r177, 8;
	setp.eq.s32 	%p114, %r176, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p114;
	mul.wide.s32 	%rd76, %r178, 8;
	add.s64 	%rd78, %rd110, %rd76;
	ld.global.nc.f64 	%fd489, [%rd78+8];
	mul.rn.f64 	%fd164, %fd598, %fd598;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd78+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd78+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd78+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd78+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd78+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd600, %fd165, %fd598, %fd598;
	@%p114 bra 	$L__BB12_115;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd165, %fd164, %fd500;

$L__BB12_115:
	and.b32  	%r179, %r199, 2;
	setp.eq.s32 	%p115, %r179, 0;
	@%p115 bra 	$L__BB12_117;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd502, %fd501;

$L__BB12_117:
	@%p3 bra 	$L__BB12_121;
	bra.uni 	$L__BB12_118;

$L__BB12_121:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd602, %fd159, %fd512;
	mov.u32 	%r201, 1;
	bra.uni 	$L__BB12_122;

$L__BB12_118:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r200, %fd503;
	st.local.u32 	[%rd1], %r200;
	cvt.rn.f64.s32 	%fd504, %r200;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd602, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p116, %fd511, 0d41E0000000000000;
	@%p116 bra 	$L__BB12_120;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 147, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd602, [retval0+0];
	} // callseq 147
	ld.local.u32 	%r200, [%rd1];

$L__BB12_120:
	add.s32 	%r201, %r200, 1;

$L__BB12_122:
	mov.u64 	%rd111, __cudart_sin_cos_coeffs;
	and.b32  	%r181, %r201, 1;
	shl.b32 	%r182, %r201, 3;
	and.b32  	%r183, %r182, 8;
	setp.eq.s32 	%p117, %r181, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p117;
	mul.wide.s32 	%rd80, %r183, 8;
	add.s64 	%rd82, %rd111, %rd80;
	ld.global.nc.f64 	%fd514, [%rd82+8];
	mul.rn.f64 	%fd176, %fd602, %fd602;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd82+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd82+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd82+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd82+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd82+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd604, %fd177, %fd602, %fd602;
	@%p117 bra 	$L__BB12_124;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd604, %fd177, %fd176, %fd525;

$L__BB12_124:
	and.b32  	%r184, %r201, 2;
	setp.eq.s32 	%p118, %r184, 0;
	@%p118 bra 	$L__BB12_126;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd604, %fd604, %fd527, %fd526;

$L__BB12_126:
	ld.param.u64 	%rd100, [wgs84_to_gcj02_cuda_double_param_4];
	mov.u32 	%r188, %tid.x;
	mov.u32 	%r187, %ntid.x;
	mov.u32 	%r186, %ctaid.x;
	mad.lo.s32 	%r185, %r186, %r187, %r188;
	cvt.s64.s32 	%rd99, %r185;
	ld.param.u64 	%rd98, [wgs84_to_gcj02_cuda_double_param_3];
	mul.rn.f64 	%fd528, %fd600, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd600, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0d415854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd604;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	cvta.to.global.u64 	%rd83, %rd98;
	shl.b64 	%rd84, %rd99, 3;
	add.s64 	%rd85, %rd83, %rd84;
	st.global.f64 	[%rd85], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0d41582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	cvta.to.global.u64 	%rd86, %rd100;
	add.s64 	%rd87, %rd86, %rd84;
	st.global.f64 	[%rd87], %fd545;

$L__BB12_127:
	ret;

}
	// .globl	wgs84_to_bd09_cuda_double
.visible .entry wgs84_to_bd09_cuda_double(
	.param .u32 wgs84_to_bd09_cuda_double_param_0,
	.param .u64 wgs84_to_bd09_cuda_double_param_1,
	.param .u64 wgs84_to_bd09_cuda_double_param_2,
	.param .u64 wgs84_to_bd09_cuda_double_param_3,
	.param .u64 wgs84_to_bd09_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot13[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<199>;
	.reg .b32 	%r<307>;
	.reg .f64 	%fd<878>;
	.reg .b64 	%rd<145>;


	mov.u64 	%SPL, __local_depot13;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r66, [wgs84_to_bd09_cuda_double_param_0];
	ld.param.u64 	%rd20, [wgs84_to_bd09_cuda_double_param_1];
	ld.param.u64 	%rd21, [wgs84_to_bd09_cuda_double_param_2];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r67, %ntid.x;
	mov.u32 	%r68, %ctaid.x;
	mov.u32 	%r69, %tid.x;
	mad.lo.s32 	%r1, %r68, %r67, %r69;
	setp.ge.s32 	%p7, %r1, %r66;
	@%p7 bra 	$L__BB13_194;

	cvta.to.global.u64 	%rd40, %rd20;
	cvt.s64.s32 	%rd17, %r1;
	mul.wide.s32 	%rd41, %r1, 8;
	add.s64 	%rd42, %rd40, %rd41;
	cvta.to.global.u64 	%rd43, %rd21;
	add.s64 	%rd44, %rd43, %rd41;
	ld.global.f64 	%fd1, [%rd42];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd44];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r70, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r71}, %fd9;
	}
	and.b32  	%r72, %r71, 2147483647;
	setp.eq.s32 	%p8, %r72, 2146435072;
	setp.eq.s32 	%p9, %r70, 0;
	and.pred  	%p10, %p9, %p8;
	@%p10 bra 	$L__BB13_4;
	bra.uni 	$L__BB13_2;

$L__BB13_4:
	mov.f64 	%fd270, 0d0000000000000000;
	mul.rn.f64 	%fd814, %fd9, %fd270;
	mov.u32 	%r288, 0;
	bra.uni 	$L__BB13_5;

$L__BB13_2:
	mul.rn.f64 	%fd261, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r288, %fd261;
	st.local.u32 	[%rd1], %r288;
	cvt.rn.f64.s32 	%fd262, %r288;
	neg.f64 	%fd263, %fd262;
	mov.f64 	%fd264, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd265, %fd263, %fd264, %fd9;
	mov.f64 	%fd266, 0d3C91A62633145C00;
	fma.rn.f64 	%fd267, %fd263, %fd266, %fd265;
	mov.f64 	%fd268, 0d397B839A252049C0;
	fma.rn.f64 	%fd814, %fd263, %fd268, %fd267;
	abs.f64 	%fd269, %fd9;
	setp.ltu.f64 	%p11, %fd269, 0d41E0000000000000;
	@%p11 bra 	$L__BB13_5;

	add.u64 	%rd142, %SP, 0;
	{ // callseq 148, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd142;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd814, [retval0+0];
	} // callseq 148
	ld.local.u32 	%r288, [%rd1];

$L__BB13_5:
	and.b32  	%r74, %r288, 1;
	shl.b32 	%r75, %r288, 3;
	and.b32  	%r76, %r75, 8;
	setp.eq.s32 	%p12, %r74, 0;
	selp.f64 	%fd271, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p12;
	mul.wide.s32 	%rd46, %r76, 8;
	mov.u64 	%rd47, __cudart_sin_cos_coeffs;
	add.s64 	%rd48, %rd47, %rd46;
	ld.global.nc.f64 	%fd272, [%rd48+8];
	mul.rn.f64 	%fd14, %fd814, %fd814;
	fma.rn.f64 	%fd273, %fd271, %fd14, %fd272;
	ld.global.nc.f64 	%fd274, [%rd48+16];
	fma.rn.f64 	%fd275, %fd273, %fd14, %fd274;
	ld.global.nc.f64 	%fd276, [%rd48+24];
	fma.rn.f64 	%fd277, %fd275, %fd14, %fd276;
	ld.global.nc.f64 	%fd278, [%rd48+32];
	fma.rn.f64 	%fd279, %fd277, %fd14, %fd278;
	ld.global.nc.f64 	%fd280, [%rd48+40];
	fma.rn.f64 	%fd281, %fd279, %fd14, %fd280;
	ld.global.nc.f64 	%fd282, [%rd48+48];
	fma.rn.f64 	%fd15, %fd281, %fd14, %fd282;
	fma.rn.f64 	%fd816, %fd15, %fd814, %fd814;
	@%p12 bra 	$L__BB13_7;

	mov.f64 	%fd283, 0d3FF0000000000000;
	fma.rn.f64 	%fd816, %fd15, %fd14, %fd283;

$L__BB13_7:
	and.b32  	%r77, %r288, 2;
	setp.eq.s32 	%p13, %r77, 0;
	@%p13 bra 	$L__BB13_9;

	mov.f64 	%fd284, 0d0000000000000000;
	mov.f64 	%fd285, 0dBFF0000000000000;
	fma.rn.f64 	%fd816, %fd816, %fd285, %fd284;

$L__BB13_9:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd21;
	}
	and.b32  	%r80, %r79, 2147483647;
	setp.eq.s32 	%p14, %r80, 2146435072;
	setp.eq.s32 	%p15, %r78, 0;
	and.pred  	%p16, %p15, %p14;
	@%p16 bra 	$L__BB13_12;
	bra.uni 	$L__BB13_10;

$L__BB13_12:
	mov.f64 	%fd295, 0d0000000000000000;
	mul.rn.f64 	%fd817, %fd21, %fd295;
	mov.u32 	%r289, 0;
	bra.uni 	$L__BB13_13;

$L__BB13_10:
	mul.rn.f64 	%fd286, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r289, %fd286;
	st.local.u32 	[%rd1], %r289;
	cvt.rn.f64.s32 	%fd287, %r289;
	neg.f64 	%fd288, %fd287;
	mov.f64 	%fd289, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd290, %fd288, %fd289, %fd21;
	mov.f64 	%fd291, 0d3C91A62633145C00;
	fma.rn.f64 	%fd292, %fd288, %fd291, %fd290;
	mov.f64 	%fd293, 0d397B839A252049C0;
	fma.rn.f64 	%fd817, %fd288, %fd293, %fd292;
	abs.f64 	%fd294, %fd21;
	setp.ltu.f64 	%p17, %fd294, 0d41E0000000000000;
	@%p17 bra 	$L__BB13_13;

	add.u64 	%rd143, %SP, 0;
	{ // callseq 149, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd143;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd817, [retval0+0];
	} // callseq 149
	ld.local.u32 	%r289, [%rd1];

$L__BB13_13:
	mov.u64 	%rd144, __cudart_sin_cos_coeffs;
	and.b32  	%r82, %r289, 1;
	shl.b32 	%r83, %r289, 3;
	and.b32  	%r84, %r83, 8;
	setp.eq.s32 	%p18, %r82, 0;
	selp.f64 	%fd296, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p18;
	mul.wide.s32 	%rd50, %r84, 8;
	add.s64 	%rd52, %rd144, %rd50;
	ld.global.nc.f64 	%fd297, [%rd52+8];
	mul.rn.f64 	%fd26, %fd817, %fd817;
	fma.rn.f64 	%fd298, %fd296, %fd26, %fd297;
	ld.global.nc.f64 	%fd299, [%rd52+16];
	fma.rn.f64 	%fd300, %fd298, %fd26, %fd299;
	ld.global.nc.f64 	%fd301, [%rd52+24];
	fma.rn.f64 	%fd302, %fd300, %fd26, %fd301;
	ld.global.nc.f64 	%fd303, [%rd52+32];
	fma.rn.f64 	%fd304, %fd302, %fd26, %fd303;
	ld.global.nc.f64 	%fd305, [%rd52+40];
	fma.rn.f64 	%fd306, %fd304, %fd26, %fd305;
	ld.global.nc.f64 	%fd307, [%rd52+48];
	fma.rn.f64 	%fd27, %fd306, %fd26, %fd307;
	fma.rn.f64 	%fd819, %fd27, %fd817, %fd817;
	@%p18 bra 	$L__BB13_15;

	mov.f64 	%fd308, 0d3FF0000000000000;
	fma.rn.f64 	%fd819, %fd27, %fd26, %fd308;

$L__BB13_15:
	and.b32  	%r85, %r289, 2;
	setp.eq.s32 	%p19, %r85, 0;
	@%p19 bra 	$L__BB13_17;

	mov.f64 	%fd309, 0d0000000000000000;
	mov.f64 	%fd310, 0dBFF0000000000000;
	fma.rn.f64 	%fd819, %fd819, %fd310, %fd309;

$L__BB13_17:
	mul.rn.f64 	%fd311, %fd819, 0d4034000000000000;
	mul.rn.f64 	%fd312, %fd816, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd312, %fd311;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd8;
	}
	and.b32  	%r87, %r86, 2147483647;
	setp.eq.s32 	%p20, %r87, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r88, %temp}, %fd8;
	}
	setp.eq.s32 	%p21, %r88, 0;
	and.pred  	%p22, %p21, %p20;
	@%p22 bra 	$L__BB13_20;
	bra.uni 	$L__BB13_18;

$L__BB13_20:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd820, %fd8, %fd322;
	mov.u32 	%r290, 0;
	bra.uni 	$L__BB13_21;

$L__BB13_18:
	mul.rn.f64 	%fd313, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r290, %fd313;
	st.local.u32 	[%rd1], %r290;
	cvt.rn.f64.s32 	%fd314, %r290;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd8;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd820, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd8;
	setp.ltu.f64 	%p23, %fd321, 0d41E0000000000000;
	@%p23 bra 	$L__BB13_21;

	add.u64 	%rd133, %SP, 0;
	{ // callseq 150, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd133;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd820, [retval0+0];
	} // callseq 150
	ld.local.u32 	%r290, [%rd1];

$L__BB13_21:
	mov.u64 	%rd134, __cudart_sin_cos_coeffs;
	and.b32  	%r90, %r290, 1;
	shl.b32 	%r91, %r290, 3;
	and.b32  	%r92, %r91, 8;
	setp.eq.s32 	%p24, %r90, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p24;
	mul.wide.s32 	%rd54, %r92, 8;
	add.s64 	%rd56, %rd134, %rd54;
	ld.global.nc.f64 	%fd324, [%rd56+8];
	mul.rn.f64 	%fd38, %fd820, %fd820;
	fma.rn.f64 	%fd325, %fd323, %fd38, %fd324;
	ld.global.nc.f64 	%fd326, [%rd56+16];
	fma.rn.f64 	%fd327, %fd325, %fd38, %fd326;
	ld.global.nc.f64 	%fd328, [%rd56+24];
	fma.rn.f64 	%fd329, %fd327, %fd38, %fd328;
	ld.global.nc.f64 	%fd330, [%rd56+32];
	fma.rn.f64 	%fd331, %fd329, %fd38, %fd330;
	ld.global.nc.f64 	%fd332, [%rd56+40];
	fma.rn.f64 	%fd333, %fd331, %fd38, %fd332;
	ld.global.nc.f64 	%fd334, [%rd56+48];
	fma.rn.f64 	%fd39, %fd333, %fd38, %fd334;
	fma.rn.f64 	%fd822, %fd39, %fd820, %fd820;
	@%p24 bra 	$L__BB13_23;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd822, %fd39, %fd38, %fd335;

$L__BB13_23:
	and.b32  	%r93, %r290, 2;
	setp.eq.s32 	%p25, %r93, 0;
	@%p25 bra 	$L__BB13_25;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd822, %fd822, %fd337, %fd336;

$L__BB13_25:
	add.rn.f64 	%fd811, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd810, %fd811, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd810, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r95}, %fd45;
	}
	and.b32  	%r96, %r95, 2147483647;
	setp.eq.s32 	%p26, %r96, 2146435072;
	setp.eq.s32 	%p27, %r94, 0;
	and.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB13_28;
	bra.uni 	$L__BB13_26;

$L__BB13_28:
	mov.f64 	%fd347, 0d0000000000000000;
	mul.rn.f64 	%fd823, %fd45, %fd347;
	mov.u32 	%r291, 0;
	bra.uni 	$L__BB13_29;

$L__BB13_26:
	mul.rn.f64 	%fd338, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r291, %fd338;
	st.local.u32 	[%rd1], %r291;
	cvt.rn.f64.s32 	%fd339, %r291;
	neg.f64 	%fd340, %fd339;
	mov.f64 	%fd341, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd342, %fd340, %fd341, %fd45;
	mov.f64 	%fd343, 0d3C91A62633145C00;
	fma.rn.f64 	%fd344, %fd340, %fd343, %fd342;
	mov.f64 	%fd345, 0d397B839A252049C0;
	fma.rn.f64 	%fd823, %fd340, %fd345, %fd344;
	abs.f64 	%fd346, %fd45;
	setp.ltu.f64 	%p29, %fd346, 0d41E0000000000000;
	@%p29 bra 	$L__BB13_29;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 151, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 151
	ld.local.u32 	%r291, [%rd1];

$L__BB13_29:
	mov.u64 	%rd136, __cudart_sin_cos_coeffs;
	and.b32  	%r98, %r291, 1;
	shl.b32 	%r99, %r291, 3;
	and.b32  	%r100, %r99, 8;
	setp.eq.s32 	%p30, %r98, 0;
	selp.f64 	%fd348, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	mul.wide.s32 	%rd58, %r100, 8;
	add.s64 	%rd60, %rd136, %rd58;
	ld.global.nc.f64 	%fd349, [%rd60+8];
	mul.rn.f64 	%fd50, %fd823, %fd823;
	fma.rn.f64 	%fd350, %fd348, %fd50, %fd349;
	ld.global.nc.f64 	%fd351, [%rd60+16];
	fma.rn.f64 	%fd352, %fd350, %fd50, %fd351;
	ld.global.nc.f64 	%fd353, [%rd60+24];
	fma.rn.f64 	%fd354, %fd352, %fd50, %fd353;
	ld.global.nc.f64 	%fd355, [%rd60+32];
	fma.rn.f64 	%fd356, %fd354, %fd50, %fd355;
	ld.global.nc.f64 	%fd357, [%rd60+40];
	fma.rn.f64 	%fd358, %fd356, %fd50, %fd357;
	ld.global.nc.f64 	%fd359, [%rd60+48];
	fma.rn.f64 	%fd51, %fd358, %fd50, %fd359;
	fma.rn.f64 	%fd825, %fd51, %fd823, %fd823;
	@%p30 bra 	$L__BB13_31;

	mov.f64 	%fd360, 0d3FF0000000000000;
	fma.rn.f64 	%fd825, %fd51, %fd50, %fd360;

$L__BB13_31:
	and.b32  	%r101, %r291, 2;
	setp.eq.s32 	%p31, %r101, 0;
	@%p31 bra 	$L__BB13_33;

	mov.f64 	%fd361, 0d0000000000000000;
	mov.f64 	%fd362, 0dBFF0000000000000;
	fma.rn.f64 	%fd825, %fd825, %fd362, %fd361;

$L__BB13_33:
	add.rn.f64 	%fd803, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd802, %fd803, 0d400921FB54442D18;
	mul.rn.f64 	%fd363, %fd825, 0d4044000000000000;
	mul.rn.f64 	%fd364, %fd822, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd364, %fd363;
	div.rn.f64 	%fd58, %fd802, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r102, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r103}, %fd58;
	}
	and.b32  	%r104, %r103, 2147483647;
	setp.eq.s32 	%p32, %r104, 2146435072;
	setp.eq.s32 	%p33, %r102, 0;
	and.pred  	%p34, %p33, %p32;
	@%p34 bra 	$L__BB13_36;
	bra.uni 	$L__BB13_34;

$L__BB13_36:
	mov.f64 	%fd374, 0d0000000000000000;
	mul.rn.f64 	%fd826, %fd58, %fd374;
	mov.u32 	%r292, 0;
	bra.uni 	$L__BB13_37;

$L__BB13_34:
	mul.rn.f64 	%fd365, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r292, %fd365;
	st.local.u32 	[%rd1], %r292;
	cvt.rn.f64.s32 	%fd366, %r292;
	neg.f64 	%fd367, %fd366;
	mov.f64 	%fd368, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd369, %fd367, %fd368, %fd58;
	mov.f64 	%fd370, 0d3C91A62633145C00;
	fma.rn.f64 	%fd371, %fd367, %fd370, %fd369;
	mov.f64 	%fd372, 0d397B839A252049C0;
	fma.rn.f64 	%fd826, %fd367, %fd372, %fd371;
	abs.f64 	%fd373, %fd58;
	setp.ltu.f64 	%p35, %fd373, 0d41E0000000000000;
	@%p35 bra 	$L__BB13_37;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 152, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd826, [retval0+0];
	} // callseq 152
	ld.local.u32 	%r292, [%rd1];

$L__BB13_37:
	mov.u64 	%rd138, __cudart_sin_cos_coeffs;
	and.b32  	%r106, %r292, 1;
	shl.b32 	%r107, %r292, 3;
	and.b32  	%r108, %r107, 8;
	setp.eq.s32 	%p36, %r106, 0;
	selp.f64 	%fd375, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p36;
	mul.wide.s32 	%rd62, %r108, 8;
	add.s64 	%rd64, %rd138, %rd62;
	ld.global.nc.f64 	%fd376, [%rd64+8];
	mul.rn.f64 	%fd63, %fd826, %fd826;
	fma.rn.f64 	%fd377, %fd375, %fd63, %fd376;
	ld.global.nc.f64 	%fd378, [%rd64+16];
	fma.rn.f64 	%fd379, %fd377, %fd63, %fd378;
	ld.global.nc.f64 	%fd380, [%rd64+24];
	fma.rn.f64 	%fd381, %fd379, %fd63, %fd380;
	ld.global.nc.f64 	%fd382, [%rd64+32];
	fma.rn.f64 	%fd383, %fd381, %fd63, %fd382;
	ld.global.nc.f64 	%fd384, [%rd64+40];
	fma.rn.f64 	%fd385, %fd383, %fd63, %fd384;
	ld.global.nc.f64 	%fd386, [%rd64+48];
	fma.rn.f64 	%fd64, %fd385, %fd63, %fd386;
	fma.rn.f64 	%fd828, %fd64, %fd826, %fd826;
	@%p36 bra 	$L__BB13_39;

	mov.f64 	%fd387, 0d3FF0000000000000;
	fma.rn.f64 	%fd828, %fd64, %fd63, %fd387;

$L__BB13_39:
	and.b32  	%r109, %r292, 2;
	setp.eq.s32 	%p37, %r109, 0;
	@%p37 bra 	$L__BB13_41;

	mov.f64 	%fd388, 0d0000000000000000;
	mov.f64 	%fd389, 0dBFF0000000000000;
	fma.rn.f64 	%fd828, %fd828, %fd389, %fd388;

$L__BB13_41:
	add.rn.f64 	%fd805, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd804, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd390, %fd828, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd390;
	div.rn.f64 	%fd71, %fd804, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r110, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r111}, %fd71;
	}
	and.b32  	%r112, %r111, 2147483647;
	setp.eq.s32 	%p38, %r112, 2146435072;
	setp.eq.s32 	%p39, %r110, 0;
	and.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB13_44;
	bra.uni 	$L__BB13_42;

$L__BB13_44:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd829, %fd71, %fd400;
	mov.u32 	%r293, 0;
	bra.uni 	$L__BB13_45;

$L__BB13_42:
	mul.rn.f64 	%fd391, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r293, %fd391;
	st.local.u32 	[%rd1], %r293;
	cvt.rn.f64.s32 	%fd392, %r293;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd71;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd829, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd71;
	setp.ltu.f64 	%p41, %fd399, 0d41E0000000000000;
	@%p41 bra 	$L__BB13_45;

	add.u64 	%rd139, %SP, 0;
	{ // callseq 153, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd139;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd829, [retval0+0];
	} // callseq 153
	ld.local.u32 	%r293, [%rd1];

$L__BB13_45:
	mov.u64 	%rd140, __cudart_sin_cos_coeffs;
	and.b32  	%r114, %r293, 1;
	shl.b32 	%r115, %r293, 3;
	and.b32  	%r116, %r115, 8;
	setp.eq.s32 	%p42, %r114, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	mul.wide.s32 	%rd66, %r116, 8;
	add.s64 	%rd68, %rd140, %rd66;
	ld.global.nc.f64 	%fd402, [%rd68+8];
	mul.rn.f64 	%fd76, %fd829, %fd829;
	fma.rn.f64 	%fd403, %fd401, %fd76, %fd402;
	ld.global.nc.f64 	%fd404, [%rd68+16];
	fma.rn.f64 	%fd405, %fd403, %fd76, %fd404;
	ld.global.nc.f64 	%fd406, [%rd68+24];
	fma.rn.f64 	%fd407, %fd405, %fd76, %fd406;
	ld.global.nc.f64 	%fd408, [%rd68+32];
	fma.rn.f64 	%fd409, %fd407, %fd76, %fd408;
	ld.global.nc.f64 	%fd410, [%rd68+40];
	fma.rn.f64 	%fd411, %fd409, %fd76, %fd410;
	ld.global.nc.f64 	%fd412, [%rd68+48];
	fma.rn.f64 	%fd77, %fd411, %fd76, %fd412;
	fma.rn.f64 	%fd831, %fd77, %fd829, %fd829;
	@%p42 bra 	$L__BB13_47;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd831, %fd77, %fd76, %fd413;

$L__BB13_47:
	and.b32  	%r117, %r293, 2;
	setp.eq.s32 	%p43, %r117, 0;
	@%p43 bra 	$L__BB13_49;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd831, %fd831, %fd415, %fd414;

$L__BB13_49:
	mul.rn.f64 	%fd416, %fd831, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd416;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r118}, %fd7;
	}
	and.b32  	%r119, %r118, 2147483647;
	setp.eq.s32 	%p44, %r119, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r120, %temp}, %fd7;
	}
	setp.eq.s32 	%p45, %r120, 0;
	and.pred  	%p46, %p45, %p44;
	@%p46 bra 	$L__BB13_52;
	bra.uni 	$L__BB13_50;

$L__BB13_52:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd832, %fd7, %fd426;
	mov.u32 	%r294, 0;
	bra.uni 	$L__BB13_53;

$L__BB13_50:
	mul.rn.f64 	%fd417, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r294, %fd417;
	st.local.u32 	[%rd1], %r294;
	cvt.rn.f64.s32 	%fd418, %r294;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd7;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd832, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd7;
	setp.ltu.f64 	%p47, %fd425, 0d41E0000000000000;
	@%p47 bra 	$L__BB13_53;

	add.u64 	%rd114, %SP, 0;
	{ // callseq 154, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd114;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 154
	ld.local.u32 	%r294, [%rd1];

$L__BB13_53:
	mov.u64 	%rd141, __cudart_sin_cos_coeffs;
	and.b32  	%r122, %r294, 1;
	shl.b32 	%r123, %r294, 3;
	and.b32  	%r124, %r123, 8;
	setp.eq.s32 	%p48, %r122, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p48;
	mul.wide.s32 	%rd70, %r124, 8;
	add.s64 	%rd72, %rd141, %rd70;
	ld.global.nc.f64 	%fd428, [%rd72+8];
	mul.rn.f64 	%fd88, %fd832, %fd832;
	fma.rn.f64 	%fd429, %fd427, %fd88, %fd428;
	ld.global.nc.f64 	%fd430, [%rd72+16];
	fma.rn.f64 	%fd431, %fd429, %fd88, %fd430;
	ld.global.nc.f64 	%fd432, [%rd72+24];
	fma.rn.f64 	%fd433, %fd431, %fd88, %fd432;
	ld.global.nc.f64 	%fd434, [%rd72+32];
	fma.rn.f64 	%fd435, %fd433, %fd88, %fd434;
	ld.global.nc.f64 	%fd436, [%rd72+40];
	fma.rn.f64 	%fd437, %fd435, %fd88, %fd436;
	ld.global.nc.f64 	%fd438, [%rd72+48];
	fma.rn.f64 	%fd89, %fd437, %fd88, %fd438;
	fma.rn.f64 	%fd834, %fd89, %fd832, %fd832;
	@%p48 bra 	$L__BB13_55;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd89, %fd88, %fd439;

$L__BB13_55:
	and.b32  	%r125, %r294, 2;
	setp.eq.s32 	%p49, %r125, 0;
	@%p49 bra 	$L__BB13_57;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd441, %fd440;

$L__BB13_57:
	add.rn.f64 	%fd813, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd812, %fd813, 0d400921FB54442D18;
	div.rn.f64 	%fd95, %fd812, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r126, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r127}, %fd95;
	}
	and.b32  	%r128, %r127, 2147483647;
	setp.eq.s32 	%p50, %r128, 2146435072;
	setp.eq.s32 	%p51, %r126, 0;
	and.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB13_60;
	bra.uni 	$L__BB13_58;

$L__BB13_60:
	mov.f64 	%fd451, 0d0000000000000000;
	mul.rn.f64 	%fd835, %fd95, %fd451;
	mov.u32 	%r295, 0;
	bra.uni 	$L__BB13_61;

$L__BB13_58:
	mul.rn.f64 	%fd442, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r295, %fd442;
	st.local.u32 	[%rd1], %r295;
	cvt.rn.f64.s32 	%fd443, %r295;
	neg.f64 	%fd444, %fd443;
	mov.f64 	%fd445, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd446, %fd444, %fd445, %fd95;
	mov.f64 	%fd447, 0d3C91A62633145C00;
	fma.rn.f64 	%fd448, %fd444, %fd447, %fd446;
	mov.f64 	%fd449, 0d397B839A252049C0;
	fma.rn.f64 	%fd835, %fd444, %fd449, %fd448;
	abs.f64 	%fd450, %fd95;
	setp.ltu.f64 	%p53, %fd450, 0d41E0000000000000;
	@%p53 bra 	$L__BB13_61;

	add.u64 	%rd115, %SP, 0;
	{ // callseq 155, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd115;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd835, [retval0+0];
	} // callseq 155
	ld.local.u32 	%r295, [%rd1];

$L__BB13_61:
	mov.u64 	%rd124, __cudart_sin_cos_coeffs;
	and.b32  	%r130, %r295, 1;
	shl.b32 	%r131, %r295, 3;
	and.b32  	%r132, %r131, 8;
	setp.eq.s32 	%p54, %r130, 0;
	selp.f64 	%fd452, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	mul.wide.s32 	%rd74, %r132, 8;
	add.s64 	%rd76, %rd124, %rd74;
	ld.global.nc.f64 	%fd453, [%rd76+8];
	mul.rn.f64 	%fd100, %fd835, %fd835;
	fma.rn.f64 	%fd454, %fd452, %fd100, %fd453;
	ld.global.nc.f64 	%fd455, [%rd76+16];
	fma.rn.f64 	%fd456, %fd454, %fd100, %fd455;
	ld.global.nc.f64 	%fd457, [%rd76+24];
	fma.rn.f64 	%fd458, %fd456, %fd100, %fd457;
	ld.global.nc.f64 	%fd459, [%rd76+32];
	fma.rn.f64 	%fd460, %fd458, %fd100, %fd459;
	ld.global.nc.f64 	%fd461, [%rd76+40];
	fma.rn.f64 	%fd462, %fd460, %fd100, %fd461;
	ld.global.nc.f64 	%fd463, [%rd76+48];
	fma.rn.f64 	%fd101, %fd462, %fd100, %fd463;
	fma.rn.f64 	%fd837, %fd101, %fd835, %fd835;
	@%p54 bra 	$L__BB13_63;

	mov.f64 	%fd464, 0d3FF0000000000000;
	fma.rn.f64 	%fd837, %fd101, %fd100, %fd464;

$L__BB13_63:
	and.b32  	%r133, %r295, 2;
	setp.eq.s32 	%p55, %r133, 0;
	@%p55 bra 	$L__BB13_65;

	mov.f64 	%fd465, 0d0000000000000000;
	mov.f64 	%fd466, 0dBFF0000000000000;
	fma.rn.f64 	%fd837, %fd837, %fd466, %fd465;

$L__BB13_65:
	add.rn.f64 	%fd807, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd806, %fd807, 0d400921FB54442D18;
	mul.rn.f64 	%fd467, %fd837, 0d4044000000000000;
	mul.rn.f64 	%fd468, %fd834, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd468, %fd467;
	div.rn.f64 	%fd108, %fd806, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r134, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r135}, %fd108;
	}
	and.b32  	%r136, %r135, 2147483647;
	setp.eq.s32 	%p56, %r136, 2146435072;
	setp.eq.s32 	%p57, %r134, 0;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB13_68;
	bra.uni 	$L__BB13_66;

$L__BB13_68:
	mov.f64 	%fd478, 0d0000000000000000;
	mul.rn.f64 	%fd838, %fd108, %fd478;
	mov.u32 	%r296, 0;
	bra.uni 	$L__BB13_69;

$L__BB13_66:
	mul.rn.f64 	%fd469, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r296, %fd469;
	st.local.u32 	[%rd1], %r296;
	cvt.rn.f64.s32 	%fd470, %r296;
	neg.f64 	%fd471, %fd470;
	mov.f64 	%fd472, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd473, %fd471, %fd472, %fd108;
	mov.f64 	%fd474, 0d3C91A62633145C00;
	fma.rn.f64 	%fd475, %fd471, %fd474, %fd473;
	mov.f64 	%fd476, 0d397B839A252049C0;
	fma.rn.f64 	%fd838, %fd471, %fd476, %fd475;
	abs.f64 	%fd477, %fd108;
	setp.ltu.f64 	%p59, %fd477, 0d41E0000000000000;
	@%p59 bra 	$L__BB13_69;

	add.u64 	%rd116, %SP, 0;
	{ // callseq 156, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd116;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd838, [retval0+0];
	} // callseq 156
	ld.local.u32 	%r296, [%rd1];

$L__BB13_69:
	mov.u64 	%rd125, __cudart_sin_cos_coeffs;
	and.b32  	%r138, %r296, 1;
	shl.b32 	%r139, %r296, 3;
	and.b32  	%r140, %r139, 8;
	setp.eq.s32 	%p60, %r138, 0;
	selp.f64 	%fd479, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p60;
	mul.wide.s32 	%rd78, %r140, 8;
	add.s64 	%rd80, %rd125, %rd78;
	ld.global.nc.f64 	%fd480, [%rd80+8];
	mul.rn.f64 	%fd113, %fd838, %fd838;
	fma.rn.f64 	%fd481, %fd479, %fd113, %fd480;
	ld.global.nc.f64 	%fd482, [%rd80+16];
	fma.rn.f64 	%fd483, %fd481, %fd113, %fd482;
	ld.global.nc.f64 	%fd484, [%rd80+24];
	fma.rn.f64 	%fd485, %fd483, %fd113, %fd484;
	ld.global.nc.f64 	%fd486, [%rd80+32];
	fma.rn.f64 	%fd487, %fd485, %fd113, %fd486;
	ld.global.nc.f64 	%fd488, [%rd80+40];
	fma.rn.f64 	%fd489, %fd487, %fd113, %fd488;
	ld.global.nc.f64 	%fd490, [%rd80+48];
	fma.rn.f64 	%fd114, %fd489, %fd113, %fd490;
	fma.rn.f64 	%fd840, %fd114, %fd838, %fd838;
	@%p60 bra 	$L__BB13_71;

	mov.f64 	%fd491, 0d3FF0000000000000;
	fma.rn.f64 	%fd840, %fd114, %fd113, %fd491;

$L__BB13_71:
	and.b32  	%r141, %r296, 2;
	setp.eq.s32 	%p61, %r141, 0;
	@%p61 bra 	$L__BB13_73;

	mov.f64 	%fd492, 0d0000000000000000;
	mov.f64 	%fd493, 0dBFF0000000000000;
	fma.rn.f64 	%fd840, %fd840, %fd493, %fd492;

$L__BB13_73:
	add.rn.f64 	%fd809, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd808, %fd809, 0d400921FB54442D18;
	mul.rn.f64 	%fd494, %fd840, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd494;
	div.rn.f64 	%fd121, %fd808, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r142, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r143}, %fd121;
	}
	and.b32  	%r144, %r143, 2147483647;
	setp.eq.s32 	%p62, %r144, 2146435072;
	setp.eq.s32 	%p63, %r142, 0;
	and.pred  	%p64, %p63, %p62;
	@%p64 bra 	$L__BB13_76;
	bra.uni 	$L__BB13_74;

$L__BB13_76:
	mov.f64 	%fd504, 0d0000000000000000;
	mul.rn.f64 	%fd841, %fd121, %fd504;
	mov.u32 	%r297, 0;
	bra.uni 	$L__BB13_77;

$L__BB13_74:
	mul.rn.f64 	%fd495, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r297, %fd495;
	st.local.u32 	[%rd1], %r297;
	cvt.rn.f64.s32 	%fd496, %r297;
	neg.f64 	%fd497, %fd496;
	mov.f64 	%fd498, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd499, %fd497, %fd498, %fd121;
	mov.f64 	%fd500, 0d3C91A62633145C00;
	fma.rn.f64 	%fd501, %fd497, %fd500, %fd499;
	mov.f64 	%fd502, 0d397B839A252049C0;
	fma.rn.f64 	%fd841, %fd497, %fd502, %fd501;
	abs.f64 	%fd503, %fd121;
	setp.ltu.f64 	%p65, %fd503, 0d41E0000000000000;
	@%p65 bra 	$L__BB13_77;

	add.u64 	%rd117, %SP, 0;
	{ // callseq 157, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd117;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd841, [retval0+0];
	} // callseq 157
	ld.local.u32 	%r297, [%rd1];

$L__BB13_77:
	mov.u64 	%rd126, __cudart_sin_cos_coeffs;
	and.b32  	%r146, %r297, 1;
	shl.b32 	%r147, %r297, 3;
	and.b32  	%r148, %r147, 8;
	setp.eq.s32 	%p66, %r146, 0;
	selp.f64 	%fd505, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p66;
	mul.wide.s32 	%rd82, %r148, 8;
	add.s64 	%rd84, %rd126, %rd82;
	ld.global.nc.f64 	%fd506, [%rd84+8];
	mul.rn.f64 	%fd126, %fd841, %fd841;
	fma.rn.f64 	%fd507, %fd505, %fd126, %fd506;
	ld.global.nc.f64 	%fd508, [%rd84+16];
	fma.rn.f64 	%fd509, %fd507, %fd126, %fd508;
	ld.global.nc.f64 	%fd510, [%rd84+24];
	fma.rn.f64 	%fd511, %fd509, %fd126, %fd510;
	ld.global.nc.f64 	%fd512, [%rd84+32];
	fma.rn.f64 	%fd513, %fd511, %fd126, %fd512;
	ld.global.nc.f64 	%fd514, [%rd84+40];
	fma.rn.f64 	%fd515, %fd513, %fd126, %fd514;
	ld.global.nc.f64 	%fd516, [%rd84+48];
	fma.rn.f64 	%fd127, %fd515, %fd126, %fd516;
	fma.rn.f64 	%fd843, %fd127, %fd841, %fd841;
	@%p66 bra 	$L__BB13_79;

	mov.f64 	%fd517, 0d3FF0000000000000;
	fma.rn.f64 	%fd843, %fd127, %fd126, %fd517;

$L__BB13_79:
	and.b32  	%r149, %r297, 2;
	setp.eq.s32 	%p67, %r149, 0;
	@%p67 bra 	$L__BB13_81;

	mov.f64 	%fd518, 0d0000000000000000;
	mov.f64 	%fd519, 0dBFF0000000000000;
	fma.rn.f64 	%fd843, %fd843, %fd519, %fd518;

$L__BB13_81:
	mul.rn.f64 	%fd520, %fd843, 0d4072C00000000000;
	add.rn.f64 	%fd133, %fd120, %fd520;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd521, %fd2, %fd2;
	mov.f64 	%fd522, 0d4000000000000000;
	add.rn.f64 	%fd523, %fd521, 0dC059000000000000;
	mul.rn.f64 	%fd524, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd523, %fd524;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd522;
	}
	and.b32  	%r33, %r32, 2146435072;
	setp.eq.s32 	%p68, %r33, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 158, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd846, [retval0+0];
	} // callseq 158
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd4;
	}
	setp.lt.s32 	%p69, %r34, 0;
	and.pred  	%p1, %p69, %p68;
	not.pred 	%p70, %p1;
	@%p70 bra 	$L__BB13_83;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd846;
	}
	xor.b32  	%r151, %r150, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd846;
	}
	mov.b64 	%fd846, {%r152, %r151};

$L__BB13_83:
	setp.eq.f64 	%p71, %fd4, 0d0000000000000000;
	add.rn.f64 	%fd140, %fd33, %fd133;
	@%p71 bra 	$L__BB13_87;
	bra.uni 	$L__BB13_84;

$L__BB13_87:
	selp.b32 	%r153, %r34, 0, %p68;
	mov.u32 	%r154, 0;
	or.b32  	%r155, %r153, 2146435072;
	setp.lt.s32 	%p75, %r32, 0;
	selp.b32 	%r156, %r155, %r153, %p75;
	mov.b64 	%fd846, {%r154, %r156};
	bra.uni 	$L__BB13_88;

$L__BB13_84:
	setp.gt.s32 	%p72, %r34, -1;
	@%p72 bra 	$L__BB13_88;

	mov.f64 	%fd525, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd526, %fd525;
	setp.eq.f64 	%p73, %fd526, 0d4000000000000000;
	@%p73 bra 	$L__BB13_88;

	mov.f64 	%fd846, 0dFFF8000000000000;

$L__BB13_88:
	add.rn.f64 	%fd528, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd528;
	}
	and.b32  	%r158, %r157, 2146435072;
	setp.ne.s32 	%p76, %r158, 2146435072;
	@%p76 bra 	$L__BB13_95;

	setp.gtu.f64 	%p77, %fd136, 0d7FF0000000000000;
	@%p77 bra 	$L__BB13_94;
	bra.uni 	$L__BB13_90;

$L__BB13_94:
	mov.f64 	%fd530, 0d4000000000000000;
	add.rn.f64 	%fd846, %fd4, %fd530;
	bra.uni 	$L__BB13_95;

$L__BB13_90:
	mov.f64 	%fd529, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd529;
	}
	and.b32  	%r35, %r32, 2147483647;
	setp.eq.s32 	%p78, %r35, 2146435072;
	setp.eq.s32 	%p79, %r159, 0;
	and.pred  	%p80, %p78, %p79;
	@%p80 bra 	$L__BB13_93;
	bra.uni 	$L__BB13_91;

$L__BB13_93:
	setp.gt.f64 	%p87, %fd136, 0d3FF0000000000000;
	selp.b32 	%r166, 2146435072, 0, %p87;
	mov.u32 	%r167, 0;
	xor.b32  	%r168, %r166, 2146435072;
	setp.lt.s32 	%p88, %r32, 0;
	selp.b32 	%r169, %r168, %r166, %p88;
	setp.eq.f64 	%p89, %fd4, 0dBFF0000000000000;
	selp.b32 	%r170, 1072693248, %r169, %p89;
	mov.b64 	%fd846, {%r167, %r170};
	bra.uni 	$L__BB13_95;

$L__BB13_91:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd4;
	}
	and.b32  	%r161, %r34, 2147483647;
	setp.ne.s32 	%p81, %r161, 2146435072;
	setp.ne.s32 	%p82, %r160, 0;
	or.pred  	%p83, %p81, %p82;
	@%p83 bra 	$L__BB13_95;

	setp.gt.s32 	%p84, %r32, -1;
	selp.b32 	%r162, 2146435072, 0, %p84;
	mov.u32 	%r163, 0;
	setp.ne.s32 	%p85, %r35, 1071644672;
	and.pred  	%p86, %p85, %p1;
	or.b32  	%r164, %r162, -2147483648;
	selp.b32 	%r165, %r164, %r162, %p86;
	mov.b64 	%fd846, {%r163, %r165};

$L__BB13_95:
	add.rn.f64 	%fd797, %fd1, 0dC05A400000000000;
	abs.f64 	%fd796, %fd797;
	mul.rn.f64 	%fd531, %fd846, 0d3FC999999999999A;
	setp.eq.f64 	%p90, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd532, 0d3FC999999999999A, %fd531, %p90;
	add.rn.f64 	%fd533, %fd135, %fd532;
	mul.rn.f64 	%fd534, %fd797, %fd4;
	mul.rn.f64 	%fd147, %fd534, 0d3FB999999999999A;
	add.rn.f64 	%fd535, %fd147, %fd533;
	mul.rn.f64 	%fd536, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd537, %fd536, %fd535;
	mul.rn.f64 	%fd538, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd148, %fd538, %fd537;
	add.rn.f64 	%fd539, %fd4, %fd4;
	add.rn.f64 	%fd540, %fd797, 0d4072C00000000000;
	add.rn.f64 	%fd149, %fd540, %fd539;
	{ // callseq 159, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd796;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd849, [retval0+0];
	} // callseq 159
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd797;
	}
	setp.lt.s32 	%p91, %r36, 0;
	and.pred  	%p2, %p91, %p68;
	not.pred 	%p93, %p2;
	@%p93 bra 	$L__BB13_97;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd849;
	}
	xor.b32  	%r172, %r171, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r173, %temp}, %fd849;
	}
	mov.b64 	%fd849, {%r173, %r172};

$L__BB13_97:
	setp.eq.f64 	%p94, %fd2, 0d0000000000000000;
	@%p94 bra 	$L__BB13_101;
	bra.uni 	$L__BB13_98;

$L__BB13_101:
	selp.b32 	%r174, %r36, 0, %p68;
	mov.u32 	%r175, 0;
	or.b32  	%r176, %r174, 2146435072;
	setp.lt.s32 	%p98, %r32, 0;
	selp.b32 	%r177, %r176, %r174, %p98;
	mov.b64 	%fd849, {%r175, %r177};
	bra.uni 	$L__BB13_102;

$L__BB13_98:
	setp.gt.s32 	%p95, %r36, -1;
	@%p95 bra 	$L__BB13_102;

	mov.f64 	%fd541, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd542, %fd541;
	setp.eq.f64 	%p96, %fd542, 0d4000000000000000;
	@%p96 bra 	$L__BB13_102;

	mov.f64 	%fd849, 0dFFF8000000000000;

$L__BB13_102:
	add.rn.f64 	%fd544, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %fd544;
	}
	and.b32  	%r179, %r178, 2146435072;
	setp.ne.s32 	%p99, %r179, 2146435072;
	@%p99 bra 	$L__BB13_109;

	add.rn.f64 	%fd799, %fd1, 0dC05A400000000000;
	abs.f64 	%fd798, %fd799;
	setp.gtu.f64 	%p100, %fd798, 0d7FF0000000000000;
	@%p100 bra 	$L__BB13_108;
	bra.uni 	$L__BB13_104;

$L__BB13_108:
	mov.f64 	%fd546, 0d4000000000000000;
	add.rn.f64 	%fd849, %fd2, %fd546;
	bra.uni 	$L__BB13_109;

$L__BB13_104:
	mov.f64 	%fd545, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r180, %temp}, %fd545;
	}
	and.b32  	%r37, %r32, 2147483647;
	setp.eq.s32 	%p101, %r37, 2146435072;
	setp.eq.s32 	%p102, %r180, 0;
	and.pred  	%p103, %p101, %p102;
	@%p103 bra 	$L__BB13_107;
	bra.uni 	$L__BB13_105;

$L__BB13_107:
	add.rn.f64 	%fd801, %fd1, 0dC05A400000000000;
	abs.f64 	%fd800, %fd801;
	setp.gt.f64 	%p110, %fd800, 0d3FF0000000000000;
	selp.b32 	%r187, 2146435072, 0, %p110;
	mov.u32 	%r188, 0;
	xor.b32  	%r189, %r187, 2146435072;
	setp.lt.s32 	%p111, %r32, 0;
	selp.b32 	%r190, %r189, %r187, %p111;
	setp.eq.f64 	%p112, %fd801, 0dBFF0000000000000;
	selp.b32 	%r191, 1072693248, %r190, %p112;
	mov.b64 	%fd849, {%r188, %r191};
	bra.uni 	$L__BB13_109;

$L__BB13_105:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %fd2;
	}
	and.b32  	%r182, %r36, 2147483647;
	setp.ne.s32 	%p104, %r182, 2146435072;
	setp.ne.s32 	%p105, %r181, 0;
	or.pred  	%p106, %p104, %p105;
	@%p106 bra 	$L__BB13_109;

	setp.gt.s32 	%p107, %r32, -1;
	selp.b32 	%r183, 2146435072, 0, %p107;
	mov.u32 	%r184, 0;
	setp.ne.s32 	%p108, %r37, 1071644672;
	and.pred  	%p109, %p108, %p2;
	or.b32  	%r185, %r183, -2147483648;
	selp.b32 	%r186, %r185, %r183, %p109;
	mov.b64 	%fd849, {%r184, %r186};

$L__BB13_109:
	mul.rn.f64 	%fd547, %fd849, 0d3FB999999999999A;
	setp.eq.f64 	%p113, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd548, 0d3FB999999999999A, %fd547, %p113;
	add.rn.f64 	%fd549, %fd149, %fd548;
	add.rn.f64 	%fd550, %fd147, %fd549;
	mul.rn.f64 	%fd551, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd552, %fd551, %fd550;
	mul.rn.f64 	%fd553, %fd140, 0d3FE5555555555555;
	add.rn.f64 	%fd159, %fd553, %fd552;
	div.rn.f64 	%fd554, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd160, %fd554, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r192, %temp}, %fd160;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd160;
	}
	and.b32  	%r194, %r193, 2147483647;
	setp.eq.s32 	%p114, %r194, 2146435072;
	setp.eq.s32 	%p115, %r192, 0;
	and.pred  	%p3, %p115, %p114;
	@%p3 bra 	$L__BB13_112;
	bra.uni 	$L__BB13_110;

$L__BB13_112:
	mov.f64 	%fd564, 0d0000000000000000;
	mul.rn.f64 	%fd850, %fd160, %fd564;
	mov.u32 	%r298, 0;
	bra.uni 	$L__BB13_113;

$L__BB13_110:
	mul.rn.f64 	%fd555, %fd160, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r298, %fd555;
	st.local.u32 	[%rd1], %r298;
	cvt.rn.f64.s32 	%fd556, %r298;
	neg.f64 	%fd557, %fd556;
	mov.f64 	%fd558, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd559, %fd557, %fd558, %fd160;
	mov.f64 	%fd560, 0d3C91A62633145C00;
	fma.rn.f64 	%fd561, %fd557, %fd560, %fd559;
	mov.f64 	%fd562, 0d397B839A252049C0;
	fma.rn.f64 	%fd850, %fd557, %fd562, %fd561;
	abs.f64 	%fd563, %fd160;
	setp.ltu.f64 	%p116, %fd563, 0d41E0000000000000;
	@%p116 bra 	$L__BB13_113;

	add.u64 	%rd118, %SP, 0;
	{ // callseq 160, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd160;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd118;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 160
	ld.local.u32 	%r298, [%rd1];

$L__BB13_113:
	mov.u64 	%rd127, __cudart_sin_cos_coeffs;
	and.b32  	%r196, %r298, 1;
	shl.b32 	%r197, %r298, 3;
	and.b32  	%r198, %r197, 8;
	setp.eq.s32 	%p117, %r196, 0;
	selp.f64 	%fd565, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p117;
	mul.wide.s32 	%rd86, %r198, 8;
	add.s64 	%rd88, %rd127, %rd86;
	ld.global.nc.f64 	%fd566, [%rd88+8];
	mul.rn.f64 	%fd165, %fd850, %fd850;
	fma.rn.f64 	%fd567, %fd565, %fd165, %fd566;
	ld.global.nc.f64 	%fd568, [%rd88+16];
	fma.rn.f64 	%fd569, %fd567, %fd165, %fd568;
	ld.global.nc.f64 	%fd570, [%rd88+24];
	fma.rn.f64 	%fd571, %fd569, %fd165, %fd570;
	ld.global.nc.f64 	%fd572, [%rd88+32];
	fma.rn.f64 	%fd573, %fd571, %fd165, %fd572;
	ld.global.nc.f64 	%fd574, [%rd88+40];
	fma.rn.f64 	%fd575, %fd573, %fd165, %fd574;
	ld.global.nc.f64 	%fd576, [%rd88+48];
	fma.rn.f64 	%fd166, %fd575, %fd165, %fd576;
	fma.rn.f64 	%fd852, %fd166, %fd850, %fd850;
	@%p117 bra 	$L__BB13_115;

	mov.f64 	%fd577, 0d3FF0000000000000;
	fma.rn.f64 	%fd852, %fd166, %fd165, %fd577;

$L__BB13_115:
	and.b32  	%r199, %r298, 2;
	setp.eq.s32 	%p118, %r199, 0;
	@%p118 bra 	$L__BB13_117;

	mov.f64 	%fd578, 0d0000000000000000;
	mov.f64 	%fd579, 0dBFF0000000000000;
	fma.rn.f64 	%fd852, %fd852, %fd579, %fd578;

$L__BB13_117:
	@%p3 bra 	$L__BB13_121;
	bra.uni 	$L__BB13_118;

$L__BB13_121:
	mov.f64 	%fd589, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd160, %fd589;
	mov.u32 	%r300, 1;
	bra.uni 	$L__BB13_122;

$L__BB13_118:
	mul.rn.f64 	%fd580, %fd160, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd580;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd581, %r299;
	neg.f64 	%fd582, %fd581;
	mov.f64 	%fd583, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd584, %fd582, %fd583, %fd160;
	mov.f64 	%fd585, 0d3C91A62633145C00;
	fma.rn.f64 	%fd586, %fd582, %fd585, %fd584;
	mov.f64 	%fd587, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd582, %fd587, %fd586;
	abs.f64 	%fd588, %fd160;
	setp.ltu.f64 	%p119, %fd588, 0d41E0000000000000;
	@%p119 bra 	$L__BB13_120;

	add.u64 	%rd119, %SP, 0;
	{ // callseq 161, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd160;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd119;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 161
	ld.local.u32 	%r299, [%rd1];

$L__BB13_120:
	add.s32 	%r300, %r299, 1;

$L__BB13_122:
	mov.u64 	%rd128, __cudart_sin_cos_coeffs;
	and.b32  	%r201, %r300, 1;
	shl.b32 	%r202, %r300, 3;
	and.b32  	%r203, %r202, 8;
	setp.eq.s32 	%p120, %r201, 0;
	selp.f64 	%fd590, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p120;
	mul.wide.s32 	%rd90, %r203, 8;
	add.s64 	%rd92, %rd128, %rd90;
	ld.global.nc.f64 	%fd591, [%rd92+8];
	mul.rn.f64 	%fd177, %fd854, %fd854;
	fma.rn.f64 	%fd592, %fd590, %fd177, %fd591;
	ld.global.nc.f64 	%fd593, [%rd92+16];
	fma.rn.f64 	%fd594, %fd592, %fd177, %fd593;
	ld.global.nc.f64 	%fd595, [%rd92+24];
	fma.rn.f64 	%fd596, %fd594, %fd177, %fd595;
	ld.global.nc.f64 	%fd597, [%rd92+32];
	fma.rn.f64 	%fd598, %fd596, %fd177, %fd597;
	ld.global.nc.f64 	%fd599, [%rd92+40];
	fma.rn.f64 	%fd600, %fd598, %fd177, %fd599;
	ld.global.nc.f64 	%fd601, [%rd92+48];
	fma.rn.f64 	%fd178, %fd600, %fd177, %fd601;
	fma.rn.f64 	%fd856, %fd178, %fd854, %fd854;
	@%p120 bra 	$L__BB13_124;

	mov.f64 	%fd602, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd178, %fd177, %fd602;

$L__BB13_124:
	and.b32  	%r204, %r300, 2;
	setp.eq.s32 	%p121, %r204, 0;
	@%p121 bra 	$L__BB13_126;

	mov.f64 	%fd603, 0d0000000000000000;
	mov.f64 	%fd604, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd604, %fd603;

$L__BB13_126:
	ld.param.u64 	%rd113, [wgs84_to_bd09_cuda_double_param_4];
	ld.param.u64 	%rd112, [wgs84_to_bd09_cuda_double_param_3];
	cvta.to.global.u64 	%rd93, %rd112;
	shl.b64 	%rd94, %rd17, 3;
	add.s64 	%rd18, %rd93, %rd94;
	cvta.to.global.u64 	%rd95, %rd113;
	add.s64 	%rd19, %rd95, %rd94;
	mul.rn.f64 	%fd605, %fd852, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd606, %fd852, %fd605;
	add.rn.f64 	%fd607, %fd606, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd608, %fd607;
	mov.f64 	%fd609, 0d415854C140000000;
	div.rn.f64 	%fd610, %fd609, %fd608;
	mul.rn.f64 	%fd611, %fd610, %fd856;
	mul.rn.f64 	%fd612, %fd611, 0d400921FB54442D18;
	mul.rn.f64 	%fd613, %fd159, 0d4066800000000000;
	div.rn.f64 	%fd614, %fd613, %fd612;
	add.rn.f64 	%fd615, %fd1, %fd614;
	st.global.f64 	[%rd18], %fd615;
	mul.rn.f64 	%fd616, %fd148, 0d4066800000000000;
	mul.rn.f64 	%fd617, %fd608, %fd607;
	mov.f64 	%fd618, 0d41582B102DE355C1;
	div.rn.f64 	%fd619, %fd618, %fd617;
	mul.rn.f64 	%fd620, %fd619, 0d400921FB54442D18;
	div.rn.f64 	%fd621, %fd616, %fd620;
	add.rn.f64 	%fd184, %fd3, %fd621;
	st.global.f64 	[%rd19], %fd184;
	ld.global.f64 	%fd185, [%rd18];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r46}, %fd185;
	}
	abs.f64 	%fd186, %fd185;
	{ // callseq 162, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd186;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd859, [retval0+0];
	} // callseq 162
	setp.lt.s32 	%p122, %r46, 0;
	and.pred  	%p4, %p122, %p68;
	not.pred 	%p124, %p4;
	@%p124 bra 	$L__BB13_128;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r205}, %fd859;
	}
	xor.b32  	%r206, %r205, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd859;
	}
	mov.b64 	%fd859, {%r207, %r206};

$L__BB13_128:
	setp.eq.f64 	%p125, %fd185, 0d0000000000000000;
	@%p125 bra 	$L__BB13_132;
	bra.uni 	$L__BB13_129;

$L__BB13_132:
	selp.b32 	%r208, %r46, 0, %p68;
	mov.u32 	%r209, 0;
	or.b32  	%r210, %r208, 2146435072;
	setp.lt.s32 	%p129, %r32, 0;
	selp.b32 	%r211, %r210, %r208, %p129;
	mov.b64 	%fd859, {%r209, %r211};
	bra.uni 	$L__BB13_133;

$L__BB13_129:
	setp.gt.s32 	%p126, %r46, -1;
	@%p126 bra 	$L__BB13_133;

	mov.f64 	%fd622, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd623, %fd622;
	setp.eq.f64 	%p127, %fd623, 0d4000000000000000;
	@%p127 bra 	$L__BB13_133;

	mov.f64 	%fd859, 0dFFF8000000000000;

$L__BB13_133:
	add.rn.f64 	%fd625, %fd185, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd625;
	}
	and.b32  	%r213, %r212, 2146435072;
	setp.ne.s32 	%p130, %r213, 2146435072;
	@%p130 bra 	$L__BB13_140;

	setp.gtu.f64 	%p131, %fd186, 0d7FF0000000000000;
	@%p131 bra 	$L__BB13_139;
	bra.uni 	$L__BB13_135;

$L__BB13_139:
	mov.f64 	%fd627, 0d4000000000000000;
	add.rn.f64 	%fd859, %fd185, %fd627;
	bra.uni 	$L__BB13_140;

$L__BB13_135:
	mov.f64 	%fd626, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd626;
	}
	and.b32  	%r47, %r32, 2147483647;
	setp.eq.s32 	%p132, %r47, 2146435072;
	setp.eq.s32 	%p133, %r214, 0;
	and.pred  	%p134, %p132, %p133;
	@%p134 bra 	$L__BB13_138;
	bra.uni 	$L__BB13_136;

$L__BB13_138:
	setp.gt.f64 	%p141, %fd186, 0d3FF0000000000000;
	selp.b32 	%r221, 2146435072, 0, %p141;
	mov.u32 	%r222, 0;
	xor.b32  	%r223, %r221, 2146435072;
	setp.lt.s32 	%p142, %r32, 0;
	selp.b32 	%r224, %r223, %r221, %p142;
	setp.eq.f64 	%p143, %fd185, 0dBFF0000000000000;
	selp.b32 	%r225, 1072693248, %r224, %p143;
	mov.b64 	%fd859, {%r222, %r225};
	bra.uni 	$L__BB13_140;

$L__BB13_136:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd185;
	}
	and.b32  	%r216, %r46, 2147483647;
	setp.ne.s32 	%p135, %r216, 2146435072;
	setp.ne.s32 	%p136, %r215, 0;
	or.pred  	%p137, %p135, %p136;
	@%p137 bra 	$L__BB13_140;

	setp.gt.s32 	%p138, %r32, -1;
	selp.b32 	%r217, 2146435072, 0, %p138;
	mov.u32 	%r218, 0;
	setp.ne.s32 	%p139, %r47, 1071644672;
	and.pred  	%p140, %p139, %p4;
	or.b32  	%r219, %r217, -2147483648;
	selp.b32 	%r220, %r219, %r217, %p140;
	mov.b64 	%fd859, {%r218, %r220};

$L__BB13_140:
	abs.f64 	%fd196, %fd184;
	{ // callseq 163, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd196;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd862, [retval0+0];
	} // callseq 163
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd184;
	}
	setp.lt.s32 	%p144, %r48, 0;
	and.pred  	%p5, %p144, %p68;
	not.pred 	%p146, %p5;
	@%p146 bra 	$L__BB13_142;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r226}, %fd862;
	}
	xor.b32  	%r227, %r226, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r228, %temp}, %fd862;
	}
	mov.b64 	%fd862, {%r228, %r227};

$L__BB13_142:
	setp.eq.f64 	%p147, %fd184, 0d0000000000000000;
	@%p147 bra 	$L__BB13_146;
	bra.uni 	$L__BB13_143;

$L__BB13_146:
	selp.b32 	%r229, %r48, 0, %p68;
	mov.u32 	%r230, 0;
	or.b32  	%r231, %r229, 2146435072;
	setp.lt.s32 	%p151, %r32, 0;
	selp.b32 	%r232, %r231, %r229, %p151;
	mov.b64 	%fd862, {%r230, %r232};
	bra.uni 	$L__BB13_147;

$L__BB13_143:
	setp.gt.s32 	%p148, %r48, -1;
	@%p148 bra 	$L__BB13_147;

	mov.f64 	%fd628, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd629, %fd628;
	setp.eq.f64 	%p149, %fd629, 0d4000000000000000;
	@%p149 bra 	$L__BB13_147;

	mov.f64 	%fd862, 0dFFF8000000000000;

$L__BB13_147:
	add.rn.f64 	%fd631, %fd184, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r233}, %fd631;
	}
	and.b32  	%r234, %r233, 2146435072;
	setp.ne.s32 	%p152, %r234, 2146435072;
	@%p152 bra 	$L__BB13_154;

	setp.gtu.f64 	%p153, %fd196, 0d7FF0000000000000;
	@%p153 bra 	$L__BB13_153;
	bra.uni 	$L__BB13_149;

$L__BB13_153:
	mov.f64 	%fd633, 0d4000000000000000;
	add.rn.f64 	%fd862, %fd184, %fd633;
	bra.uni 	$L__BB13_154;

$L__BB13_149:
	mov.f64 	%fd632, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd632;
	}
	and.b32  	%r49, %r32, 2147483647;
	setp.eq.s32 	%p154, %r49, 2146435072;
	setp.eq.s32 	%p155, %r235, 0;
	and.pred  	%p156, %p154, %p155;
	@%p156 bra 	$L__BB13_152;
	bra.uni 	$L__BB13_150;

$L__BB13_152:
	setp.gt.f64 	%p163, %fd196, 0d3FF0000000000000;
	selp.b32 	%r242, 2146435072, 0, %p163;
	mov.u32 	%r243, 0;
	xor.b32  	%r244, %r242, 2146435072;
	setp.lt.s32 	%p164, %r32, 0;
	selp.b32 	%r245, %r244, %r242, %p164;
	setp.eq.f64 	%p165, %fd184, 0dBFF0000000000000;
	selp.b32 	%r246, 1072693248, %r245, %p165;
	mov.b64 	%fd862, {%r243, %r246};
	bra.uni 	$L__BB13_154;

$L__BB13_150:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r236, %temp}, %fd184;
	}
	and.b32  	%r237, %r48, 2147483647;
	setp.ne.s32 	%p157, %r237, 2146435072;
	setp.ne.s32 	%p158, %r236, 0;
	or.pred  	%p159, %p157, %p158;
	@%p159 bra 	$L__BB13_154;

	setp.gt.s32 	%p160, %r32, -1;
	selp.b32 	%r238, 2146435072, 0, %p160;
	mov.u32 	%r239, 0;
	setp.ne.s32 	%p161, %r49, 1071644672;
	and.pred  	%p162, %p161, %p5;
	or.b32  	%r240, %r238, -2147483648;
	selp.b32 	%r241, %r240, %r238, %p162;
	mov.b64 	%fd862, {%r239, %r241};

$L__BB13_154:
	setp.eq.f64 	%p166, %fd184, 0d3FF0000000000000;
	selp.f64 	%fd634, 0d3FF0000000000000, %fd862, %p166;
	setp.eq.f64 	%p167, %fd185, 0d3FF0000000000000;
	selp.f64 	%fd635, 0d3FF0000000000000, %fd859, %p167;
	add.rn.f64 	%fd206, %fd635, %fd634;
	mul.rn.f64 	%fd207, %fd184, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r247, %temp}, %fd207;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %fd207;
	}
	and.b32  	%r249, %r248, 2147483647;
	setp.eq.s32 	%p168, %r249, 2146435072;
	setp.eq.s32 	%p169, %r247, 0;
	and.pred  	%p170, %p169, %p168;
	@%p170 bra 	$L__BB13_157;
	bra.uni 	$L__BB13_155;

$L__BB13_157:
	mov.f64 	%fd645, 0d0000000000000000;
	mul.rn.f64 	%fd863, %fd207, %fd645;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB13_158;

$L__BB13_155:
	mul.rn.f64 	%fd636, %fd207, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd636;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd637, %r301;
	neg.f64 	%fd638, %fd637;
	mov.f64 	%fd639, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd640, %fd638, %fd639, %fd207;
	mov.f64 	%fd641, 0d3C91A62633145C00;
	fma.rn.f64 	%fd642, %fd638, %fd641, %fd640;
	mov.f64 	%fd643, 0d397B839A252049C0;
	fma.rn.f64 	%fd863, %fd638, %fd643, %fd642;
	abs.f64 	%fd644, %fd207;
	setp.ltu.f64 	%p171, %fd644, 0d41E0000000000000;
	@%p171 bra 	$L__BB13_158;

	add.u64 	%rd120, %SP, 0;
	{ // callseq 164, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd207;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd120;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd863, [retval0+0];
	} // callseq 164
	ld.local.u32 	%r301, [%rd1];

$L__BB13_158:
	mov.u64 	%rd129, __cudart_sin_cos_coeffs;
	and.b32  	%r251, %r301, 1;
	shl.b32 	%r252, %r301, 3;
	and.b32  	%r253, %r252, 8;
	setp.eq.s32 	%p172, %r251, 0;
	selp.f64 	%fd646, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p172;
	mul.wide.s32 	%rd97, %r253, 8;
	add.s64 	%rd99, %rd129, %rd97;
	ld.global.nc.f64 	%fd647, [%rd99+8];
	mul.rn.f64 	%fd212, %fd863, %fd863;
	fma.rn.f64 	%fd648, %fd646, %fd212, %fd647;
	ld.global.nc.f64 	%fd649, [%rd99+16];
	fma.rn.f64 	%fd650, %fd648, %fd212, %fd649;
	ld.global.nc.f64 	%fd651, [%rd99+24];
	fma.rn.f64 	%fd652, %fd650, %fd212, %fd651;
	ld.global.nc.f64 	%fd653, [%rd99+32];
	fma.rn.f64 	%fd654, %fd652, %fd212, %fd653;
	ld.global.nc.f64 	%fd655, [%rd99+40];
	fma.rn.f64 	%fd656, %fd654, %fd212, %fd655;
	ld.global.nc.f64 	%fd657, [%rd99+48];
	fma.rn.f64 	%fd213, %fd656, %fd212, %fd657;
	fma.rn.f64 	%fd865, %fd213, %fd863, %fd863;
	@%p172 bra 	$L__BB13_160;

	mov.f64 	%fd658, 0d3FF0000000000000;
	fma.rn.f64 	%fd865, %fd213, %fd212, %fd658;

$L__BB13_160:
	and.b32  	%r254, %r301, 2;
	setp.eq.s32 	%p173, %r254, 0;
	@%p173 bra 	$L__BB13_162;

	mov.f64 	%fd659, 0d0000000000000000;
	mov.f64 	%fd660, 0dBFF0000000000000;
	fma.rn.f64 	%fd865, %fd865, %fd660, %fd659;

$L__BB13_162:
	mul.rn.f64 	%fd661, %fd865, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd662, %fd206;
	add.rn.f64 	%fd219, %fd662, %fd661;
	setp.eq.f64 	%p174, %fd196, 0d0000000000000000;
	setp.eq.f64 	%p175, %fd186, 0d0000000000000000;
	and.pred  	%p176, %p175, %p174;
	@%p176 bra 	$L__BB13_166;
	bra.uni 	$L__BB13_163;

$L__BB13_166:
	selp.f64 	%fd715, 0d400921FB54442D18, 0d0000000000000000, %p122;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd715;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r264}, %fd715;
	}
	and.b32  	%r265, %r48, -2147483648;
	or.b32  	%r266, %r264, %r265;
	mov.b64 	%fd866, {%r263, %r266};
	bra.uni 	$L__BB13_167;

$L__BB13_163:
	setp.eq.f64 	%p177, %fd186, 0d7FF0000000000000;
	setp.eq.f64 	%p178, %fd196, 0d7FF0000000000000;
	and.pred  	%p179, %p177, %p178;
	@%p179 bra 	$L__BB13_165;
	bra.uni 	$L__BB13_164;

$L__BB13_165:
	selp.f64 	%fd714, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p122;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r259, %temp}, %fd714;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd714;
	}
	and.b32  	%r261, %r48, -2147483648;
	or.b32  	%r262, %r260, %r261;
	mov.b64 	%fd866, {%r259, %r262};
	bra.uni 	$L__BB13_167;

$L__BB13_164:
	min.f64 	%fd663, %fd196, %fd186;
	max.f64 	%fd664, %fd196, %fd186;
	div.rn.f64 	%fd665, %fd663, %fd664;
	mul.rn.f64 	%fd666, %fd665, %fd665;
	mov.f64 	%fd667, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd668, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd669, %fd668, %fd666, %fd667;
	mov.f64 	%fd670, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd671, %fd669, %fd666, %fd670;
	mov.f64 	%fd672, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd673, %fd671, %fd666, %fd672;
	mov.f64 	%fd674, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd675, %fd673, %fd666, %fd674;
	mov.f64 	%fd676, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd677, %fd675, %fd666, %fd676;
	mov.f64 	%fd678, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd679, %fd677, %fd666, %fd678;
	mov.f64 	%fd680, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd681, %fd679, %fd666, %fd680;
	mov.f64 	%fd682, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd683, %fd681, %fd666, %fd682;
	mov.f64 	%fd684, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd685, %fd683, %fd666, %fd684;
	mov.f64 	%fd686, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd687, %fd685, %fd666, %fd686;
	mov.f64 	%fd688, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd689, %fd687, %fd666, %fd688;
	mov.f64 	%fd690, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd691, %fd689, %fd666, %fd690;
	mov.f64 	%fd692, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd693, %fd691, %fd666, %fd692;
	mov.f64 	%fd694, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd695, %fd693, %fd666, %fd694;
	mov.f64 	%fd696, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd697, %fd695, %fd666, %fd696;
	mov.f64 	%fd698, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd699, %fd697, %fd666, %fd698;
	mov.f64 	%fd700, 0d3FC99999999840D2;
	fma.rn.f64 	%fd701, %fd699, %fd666, %fd700;
	mov.f64 	%fd702, 0dBFD555555555544C;
	fma.rn.f64 	%fd703, %fd701, %fd666, %fd702;
	mul.rn.f64 	%fd704, %fd666, %fd703;
	fma.rn.f64 	%fd705, %fd704, %fd665, %fd665;
	mov.f64 	%fd706, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd707, %fd706, %fd705;
	setp.gt.f64 	%p181, %fd196, %fd186;
	selp.f64 	%fd708, %fd707, %fd705, %p181;
	mov.f64 	%fd709, 0d400921FB54442D18;
	sub.rn.f64 	%fd710, %fd709, %fd708;
	selp.f64 	%fd711, %fd710, %fd708, %p122;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %fd711;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r256}, %fd711;
	}
	and.b32  	%r257, %r48, -2147483648;
	or.b32  	%r258, %r256, %r257;
	mov.b64 	%fd712, {%r255, %r258};
	add.rn.f64 	%fd713, %fd186, %fd196;
	setp.le.f64 	%p182, %fd713, 0d7FF0000000000000;
	selp.f64 	%fd866, %fd712, %fd713, %p182;

$L__BB13_167:
	mul.rn.f64 	%fd224, %fd185, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r267, %temp}, %fd224;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r268}, %fd224;
	}
	and.b32  	%r269, %r268, 2147483647;
	setp.eq.s32 	%p185, %r269, 2146435072;
	setp.eq.s32 	%p186, %r267, 0;
	and.pred  	%p187, %p186, %p185;
	@%p187 bra 	$L__BB13_171;
	bra.uni 	$L__BB13_168;

$L__BB13_171:
	mov.f64 	%fd725, 0d0000000000000000;
	mul.rn.f64 	%fd868, %fd224, %fd725;
	mov.u32 	%r303, 1;
	bra.uni 	$L__BB13_172;

$L__BB13_168:
	mul.rn.f64 	%fd716, %fd224, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd716;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd717, %r302;
	neg.f64 	%fd718, %fd717;
	mov.f64 	%fd719, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd720, %fd718, %fd719, %fd224;
	mov.f64 	%fd721, 0d3C91A62633145C00;
	fma.rn.f64 	%fd722, %fd718, %fd721, %fd720;
	mov.f64 	%fd723, 0d397B839A252049C0;
	fma.rn.f64 	%fd868, %fd718, %fd723, %fd722;
	abs.f64 	%fd724, %fd224;
	setp.ltu.f64 	%p188, %fd724, 0d41E0000000000000;
	@%p188 bra 	$L__BB13_170;

	add.u64 	%rd121, %SP, 0;
	{ // callseq 165, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd224;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd121;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd868, [retval0+0];
	} // callseq 165
	ld.local.u32 	%r302, [%rd1];

$L__BB13_170:
	add.s32 	%r303, %r302, 1;

$L__BB13_172:
	mov.u64 	%rd130, __cudart_sin_cos_coeffs;
	and.b32  	%r271, %r303, 1;
	shl.b32 	%r272, %r303, 3;
	and.b32  	%r273, %r272, 8;
	setp.eq.s32 	%p189, %r271, 0;
	selp.f64 	%fd726, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p189;
	mul.wide.s32 	%rd101, %r273, 8;
	add.s64 	%rd103, %rd130, %rd101;
	ld.global.nc.f64 	%fd727, [%rd103+8];
	mul.rn.f64 	%fd230, %fd868, %fd868;
	fma.rn.f64 	%fd728, %fd726, %fd230, %fd727;
	ld.global.nc.f64 	%fd729, [%rd103+16];
	fma.rn.f64 	%fd730, %fd728, %fd230, %fd729;
	ld.global.nc.f64 	%fd731, [%rd103+24];
	fma.rn.f64 	%fd732, %fd730, %fd230, %fd731;
	ld.global.nc.f64 	%fd733, [%rd103+32];
	fma.rn.f64 	%fd734, %fd732, %fd230, %fd733;
	ld.global.nc.f64 	%fd735, [%rd103+40];
	fma.rn.f64 	%fd736, %fd734, %fd230, %fd735;
	ld.global.nc.f64 	%fd737, [%rd103+48];
	fma.rn.f64 	%fd231, %fd736, %fd230, %fd737;
	fma.rn.f64 	%fd870, %fd231, %fd868, %fd868;
	@%p189 bra 	$L__BB13_174;

	mov.f64 	%fd738, 0d3FF0000000000000;
	fma.rn.f64 	%fd870, %fd231, %fd230, %fd738;

$L__BB13_174:
	and.b32  	%r274, %r303, 2;
	setp.eq.s32 	%p190, %r274, 0;
	@%p190 bra 	$L__BB13_176;

	mov.f64 	%fd739, 0d0000000000000000;
	mov.f64 	%fd740, 0dBFF0000000000000;
	fma.rn.f64 	%fd870, %fd870, %fd740, %fd739;

$L__BB13_176:
	mul.rn.f64 	%fd741, %fd870, 0d3EC92A737110E454;
	add.rn.f64 	%fd237, %fd866, %fd741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r275, %temp}, %fd237;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd237;
	}
	and.b32  	%r277, %r276, 2147483647;
	setp.eq.s32 	%p191, %r277, 2146435072;
	setp.eq.s32 	%p192, %r275, 0;
	and.pred  	%p6, %p192, %p191;
	@%p6 bra 	$L__BB13_180;
	bra.uni 	$L__BB13_177;

$L__BB13_180:
	mov.f64 	%fd751, 0d0000000000000000;
	mul.rn.f64 	%fd872, %fd237, %fd751;
	mov.u32 	%r305, 1;
	bra.uni 	$L__BB13_181;

$L__BB13_177:
	mul.rn.f64 	%fd742, %fd237, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd742;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd743, %r304;
	neg.f64 	%fd744, %fd743;
	mov.f64 	%fd745, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd746, %fd744, %fd745, %fd237;
	mov.f64 	%fd747, 0d3C91A62633145C00;
	fma.rn.f64 	%fd748, %fd744, %fd747, %fd746;
	mov.f64 	%fd749, 0d397B839A252049C0;
	fma.rn.f64 	%fd872, %fd744, %fd749, %fd748;
	abs.f64 	%fd750, %fd237;
	setp.ltu.f64 	%p193, %fd750, 0d41E0000000000000;
	@%p193 bra 	$L__BB13_179;

	add.u64 	%rd122, %SP, 0;
	{ // callseq 166, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd237;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd122;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd872, [retval0+0];
	} // callseq 166
	ld.local.u32 	%r304, [%rd1];

$L__BB13_179:
	add.s32 	%r305, %r304, 1;

$L__BB13_181:
	mov.u64 	%rd131, __cudart_sin_cos_coeffs;
	and.b32  	%r279, %r305, 1;
	shl.b32 	%r280, %r305, 3;
	and.b32  	%r281, %r280, 8;
	setp.eq.s32 	%p194, %r279, 0;
	selp.f64 	%fd752, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p194;
	mul.wide.s32 	%rd105, %r281, 8;
	add.s64 	%rd107, %rd131, %rd105;
	ld.global.nc.f64 	%fd753, [%rd107+8];
	mul.rn.f64 	%fd243, %fd872, %fd872;
	fma.rn.f64 	%fd754, %fd752, %fd243, %fd753;
	ld.global.nc.f64 	%fd755, [%rd107+16];
	fma.rn.f64 	%fd756, %fd754, %fd243, %fd755;
	ld.global.nc.f64 	%fd757, [%rd107+24];
	fma.rn.f64 	%fd758, %fd756, %fd243, %fd757;
	ld.global.nc.f64 	%fd759, [%rd107+32];
	fma.rn.f64 	%fd760, %fd758, %fd243, %fd759;
	ld.global.nc.f64 	%fd761, [%rd107+40];
	fma.rn.f64 	%fd762, %fd760, %fd243, %fd761;
	ld.global.nc.f64 	%fd763, [%rd107+48];
	fma.rn.f64 	%fd244, %fd762, %fd243, %fd763;
	fma.rn.f64 	%fd874, %fd244, %fd872, %fd872;
	@%p194 bra 	$L__BB13_183;

	mov.f64 	%fd764, 0d3FF0000000000000;
	fma.rn.f64 	%fd874, %fd244, %fd243, %fd764;

$L__BB13_183:
	and.b32  	%r282, %r305, 2;
	setp.eq.s32 	%p195, %r282, 0;
	@%p195 bra 	$L__BB13_185;

	mov.f64 	%fd765, 0d0000000000000000;
	mov.f64 	%fd766, 0dBFF0000000000000;
	fma.rn.f64 	%fd874, %fd874, %fd766, %fd765;

$L__BB13_185:
	mul.rn.f64 	%fd767, %fd219, %fd874;
	add.rn.f64 	%fd768, %fd767, 0d3F7A9FBE76C8B439;
	st.global.f64 	[%rd18], %fd768;
	@%p6 bra 	$L__BB13_188;
	bra.uni 	$L__BB13_186;

$L__BB13_188:
	mov.f64 	%fd778, 0d0000000000000000;
	mul.rn.f64 	%fd875, %fd237, %fd778;
	mov.u32 	%r306, 0;
	bra.uni 	$L__BB13_189;

$L__BB13_186:
	mul.rn.f64 	%fd769, %fd237, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r306, %fd769;
	st.local.u32 	[%rd1], %r306;
	cvt.rn.f64.s32 	%fd770, %r306;
	neg.f64 	%fd771, %fd770;
	mov.f64 	%fd772, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd773, %fd771, %fd772, %fd237;
	mov.f64 	%fd774, 0d3C91A62633145C00;
	fma.rn.f64 	%fd775, %fd771, %fd774, %fd773;
	mov.f64 	%fd776, 0d397B839A252049C0;
	fma.rn.f64 	%fd875, %fd771, %fd776, %fd775;
	abs.f64 	%fd777, %fd237;
	setp.ltu.f64 	%p196, %fd777, 0d41E0000000000000;
	@%p196 bra 	$L__BB13_189;

	add.u64 	%rd123, %SP, 0;
	{ // callseq 167, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd237;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd123;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd875, [retval0+0];
	} // callseq 167
	ld.local.u32 	%r306, [%rd1];

$L__BB13_189:
	mov.u64 	%rd132, __cudart_sin_cos_coeffs;
	and.b32  	%r284, %r306, 1;
	shl.b32 	%r285, %r306, 3;
	and.b32  	%r286, %r285, 8;
	setp.eq.s32 	%p197, %r284, 0;
	selp.f64 	%fd779, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p197;
	mul.wide.s32 	%rd109, %r286, 8;
	add.s64 	%rd111, %rd132, %rd109;
	ld.global.nc.f64 	%fd780, [%rd111+8];
	mul.rn.f64 	%fd254, %fd875, %fd875;
	fma.rn.f64 	%fd781, %fd779, %fd254, %fd780;
	ld.global.nc.f64 	%fd782, [%rd111+16];
	fma.rn.f64 	%fd783, %fd781, %fd254, %fd782;
	ld.global.nc.f64 	%fd784, [%rd111+24];
	fma.rn.f64 	%fd785, %fd783, %fd254, %fd784;
	ld.global.nc.f64 	%fd786, [%rd111+32];
	fma.rn.f64 	%fd787, %fd785, %fd254, %fd786;
	ld.global.nc.f64 	%fd788, [%rd111+40];
	fma.rn.f64 	%fd789, %fd787, %fd254, %fd788;
	ld.global.nc.f64 	%fd790, [%rd111+48];
	fma.rn.f64 	%fd255, %fd789, %fd254, %fd790;
	fma.rn.f64 	%fd877, %fd255, %fd875, %fd875;
	@%p197 bra 	$L__BB13_191;

	mov.f64 	%fd791, 0d3FF0000000000000;
	fma.rn.f64 	%fd877, %fd255, %fd254, %fd791;

$L__BB13_191:
	and.b32  	%r287, %r306, 2;
	setp.eq.s32 	%p198, %r287, 0;
	@%p198 bra 	$L__BB13_193;

	mov.f64 	%fd792, 0d0000000000000000;
	mov.f64 	%fd793, 0dBFF0000000000000;
	fma.rn.f64 	%fd877, %fd877, %fd793, %fd792;

$L__BB13_193:
	mul.rn.f64 	%fd794, %fd219, %fd877;
	add.rn.f64 	%fd795, %fd794, 0d3F789374BC6A7EFA;
	st.global.f64 	[%rd19], %fd795;

$L__BB13_194:
	ret;

}
	// .globl	bd09_to_wgs84_cuda_double
.visible .entry bd09_to_wgs84_cuda_double(
	.param .u32 bd09_to_wgs84_cuda_double_param_0,
	.param .u64 bd09_to_wgs84_cuda_double_param_1,
	.param .u64 bd09_to_wgs84_cuda_double_param_2,
	.param .u64 bd09_to_wgs84_cuda_double_param_3,
	.param .u64 bd09_to_wgs84_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot14[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<199>;
	.reg .b32 	%r<307>;
	.reg .f64 	%fd<861>;
	.reg .b64 	%rd<112>;


	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r66, [bd09_to_wgs84_cuda_double_param_0];
	ld.param.u64 	%rd20, [bd09_to_wgs84_cuda_double_param_1];
	ld.param.u64 	%rd21, [bd09_to_wgs84_cuda_double_param_2];
	ld.param.u64 	%rd22, [bd09_to_wgs84_cuda_double_param_3];
	ld.param.u64 	%rd23, [bd09_to_wgs84_cuda_double_param_4];
	add.u64 	%rd24, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r67, %ntid.x;
	mov.u32 	%r68, %ctaid.x;
	mov.u32 	%r69, %tid.x;
	mad.lo.s32 	%r1, %r68, %r67, %r69;
	setp.ge.s32 	%p7, %r1, %r66;
	@%p7 bra 	$L__BB14_194;

	cvta.to.global.u64 	%rd40, %rd20;
	cvt.s64.s32 	%rd17, %r1;
	mul.wide.s32 	%rd41, %r1, 8;
	add.s64 	%rd42, %rd40, %rd41;
	cvta.to.global.u64 	%rd43, %rd21;
	add.s64 	%rd44, %rd43, %rd41;
	ld.global.f64 	%fd260, [%rd42];
	add.rn.f64 	%fd1, %fd260, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd261, [%rd44];
	add.rn.f64 	%fd2, %fd261, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd1;
	}
	mov.f64 	%fd262, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd262;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p8, %r4, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 168, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd799, [retval0+0];
	} // callseq 168
	setp.lt.s32 	%p9, %r2, 0;
	and.pred  	%p1, %p9, %p8;
	not.pred 	%p10, %p1;
	@%p10 bra 	$L__BB14_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd799;
	}
	xor.b32  	%r71, %r70, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd799;
	}
	mov.b64 	%fd799, {%r72, %r71};

$L__BB14_3:
	setp.eq.f64 	%p11, %fd1, 0d0000000000000000;
	@%p11 bra 	$L__BB14_7;
	bra.uni 	$L__BB14_4;

$L__BB14_7:
	selp.b32 	%r73, %r2, 0, %p8;
	mov.u32 	%r74, 0;
	or.b32  	%r75, %r73, 2146435072;
	setp.lt.s32 	%p15, %r3, 0;
	selp.b32 	%r76, %r75, %r73, %p15;
	mov.b64 	%fd799, {%r74, %r76};
	bra.uni 	$L__BB14_8;

$L__BB14_4:
	setp.gt.s32 	%p12, %r2, -1;
	@%p12 bra 	$L__BB14_8;

	mov.f64 	%fd263, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd264, %fd263;
	setp.eq.f64 	%p13, %fd264, 0d4000000000000000;
	@%p13 bra 	$L__BB14_8;

	mov.f64 	%fd799, 0dFFF8000000000000;

$L__BB14_8:
	add.rn.f64 	%fd266, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r77}, %fd266;
	}
	and.b32  	%r78, %r77, 2146435072;
	setp.ne.s32 	%p16, %r78, 2146435072;
	@%p16 bra 	$L__BB14_15;

	setp.gtu.f64 	%p17, %fd3, 0d7FF0000000000000;
	@%p17 bra 	$L__BB14_14;
	bra.uni 	$L__BB14_10;

$L__BB14_14:
	mov.f64 	%fd268, 0d4000000000000000;
	add.rn.f64 	%fd799, %fd1, %fd268;
	bra.uni 	$L__BB14_15;

$L__BB14_10:
	mov.f64 	%fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd267;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p18, %r5, 2146435072;
	setp.eq.s32 	%p19, %r79, 0;
	and.pred  	%p20, %p18, %p19;
	@%p20 bra 	$L__BB14_13;
	bra.uni 	$L__BB14_11;

$L__BB14_13:
	setp.gt.f64 	%p27, %fd3, 0d3FF0000000000000;
	selp.b32 	%r86, 2146435072, 0, %p27;
	mov.u32 	%r87, 0;
	xor.b32  	%r88, %r86, 2146435072;
	setp.lt.s32 	%p28, %r3, 0;
	selp.b32 	%r89, %r88, %r86, %p28;
	setp.eq.f64 	%p29, %fd1, 0dBFF0000000000000;
	selp.b32 	%r90, 1072693248, %r89, %p29;
	mov.b64 	%fd799, {%r87, %r90};
	bra.uni 	$L__BB14_15;

$L__BB14_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r80, %temp}, %fd1;
	}
	and.b32  	%r81, %r2, 2147483647;
	setp.ne.s32 	%p21, %r81, 2146435072;
	setp.ne.s32 	%p22, %r80, 0;
	or.pred  	%p23, %p21, %p22;
	@%p23 bra 	$L__BB14_15;

	setp.gt.s32 	%p24, %r3, -1;
	selp.b32 	%r82, 2146435072, 0, %p24;
	mov.u32 	%r83, 0;
	setp.ne.s32 	%p25, %r5, 1071644672;
	and.pred  	%p26, %p25, %p1;
	or.b32  	%r84, %r82, -2147483648;
	selp.b32 	%r85, %r84, %r82, %p26;
	mov.b64 	%fd799, {%r83, %r85};

$L__BB14_15:
	abs.f64 	%fd13, %fd2;
	{ // callseq 169, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd802, [retval0+0];
	} // callseq 169
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd2;
	}
	setp.lt.s32 	%p30, %r6, 0;
	and.pred  	%p2, %p30, %p8;
	not.pred 	%p32, %p2;
	@%p32 bra 	$L__BB14_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd802;
	}
	xor.b32  	%r92, %r91, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd802;
	}
	mov.b64 	%fd802, {%r93, %r92};

$L__BB14_17:
	setp.eq.f64 	%p33, %fd2, 0d0000000000000000;
	@%p33 bra 	$L__BB14_21;
	bra.uni 	$L__BB14_18;

$L__BB14_21:
	selp.b32 	%r94, %r6, 0, %p8;
	mov.u32 	%r95, 0;
	or.b32  	%r96, %r94, 2146435072;
	setp.lt.s32 	%p37, %r3, 0;
	selp.b32 	%r97, %r96, %r94, %p37;
	mov.b64 	%fd802, {%r95, %r97};
	bra.uni 	$L__BB14_22;

$L__BB14_18:
	setp.gt.s32 	%p34, %r6, -1;
	@%p34 bra 	$L__BB14_22;

	mov.f64 	%fd269, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd270, %fd269;
	setp.eq.f64 	%p35, %fd270, 0d4000000000000000;
	@%p35 bra 	$L__BB14_22;

	mov.f64 	%fd802, 0dFFF8000000000000;

$L__BB14_22:
	add.rn.f64 	%fd272, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd272;
	}
	and.b32  	%r99, %r98, 2146435072;
	setp.ne.s32 	%p38, %r99, 2146435072;
	@%p38 bra 	$L__BB14_29;

	setp.gtu.f64 	%p39, %fd13, 0d7FF0000000000000;
	@%p39 bra 	$L__BB14_28;
	bra.uni 	$L__BB14_24;

$L__BB14_28:
	mov.f64 	%fd274, 0d4000000000000000;
	add.rn.f64 	%fd802, %fd2, %fd274;
	bra.uni 	$L__BB14_29;

$L__BB14_24:
	mov.f64 	%fd273, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd273;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p40, %r7, 2146435072;
	setp.eq.s32 	%p41, %r100, 0;
	and.pred  	%p42, %p40, %p41;
	@%p42 bra 	$L__BB14_27;
	bra.uni 	$L__BB14_25;

$L__BB14_27:
	setp.gt.f64 	%p49, %fd13, 0d3FF0000000000000;
	selp.b32 	%r107, 2146435072, 0, %p49;
	mov.u32 	%r108, 0;
	xor.b32  	%r109, %r107, 2146435072;
	setp.lt.s32 	%p50, %r3, 0;
	selp.b32 	%r110, %r109, %r107, %p50;
	setp.eq.f64 	%p51, %fd2, 0dBFF0000000000000;
	selp.b32 	%r111, 1072693248, %r110, %p51;
	mov.b64 	%fd802, {%r108, %r111};
	bra.uni 	$L__BB14_29;

$L__BB14_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r101, %temp}, %fd2;
	}
	and.b32  	%r102, %r6, 2147483647;
	setp.ne.s32 	%p43, %r102, 2146435072;
	setp.ne.s32 	%p44, %r101, 0;
	or.pred  	%p45, %p43, %p44;
	@%p45 bra 	$L__BB14_29;

	setp.gt.s32 	%p46, %r3, -1;
	selp.b32 	%r103, 2146435072, 0, %p46;
	mov.u32 	%r104, 0;
	setp.ne.s32 	%p47, %r7, 1071644672;
	and.pred  	%p48, %p47, %p2;
	or.b32  	%r105, %r103, -2147483648;
	selp.b32 	%r106, %r105, %r103, %p48;
	mov.b64 	%fd802, {%r104, %r106};

$L__BB14_29:
	cvta.to.global.u64 	%rd45, %rd22;
	shl.b64 	%rd46, %rd17, 3;
	add.s64 	%rd18, %rd45, %rd46;
	cvta.to.global.u64 	%rd47, %rd23;
	add.s64 	%rd19, %rd47, %rd46;
	setp.eq.f64 	%p52, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd275, 0d3FF0000000000000, %fd802, %p52;
	setp.eq.f64 	%p53, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd276, 0d3FF0000000000000, %fd799, %p53;
	add.rn.f64 	%fd23, %fd276, %fd275;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r112, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd24;
	}
	and.b32  	%r114, %r113, 2147483647;
	setp.eq.s32 	%p54, %r114, 2146435072;
	setp.eq.s32 	%p55, %r112, 0;
	and.pred  	%p56, %p55, %p54;
	@%p56 bra 	$L__BB14_32;
	bra.uni 	$L__BB14_30;

$L__BB14_32:
	mov.f64 	%fd286, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd24, %fd286;
	mov.u32 	%r288, 0;
	bra.uni 	$L__BB14_33;

$L__BB14_30:
	mul.rn.f64 	%fd277, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r288, %fd277;
	st.local.u32 	[%rd1], %r288;
	cvt.rn.f64.s32 	%fd278, %r288;
	neg.f64 	%fd279, %fd278;
	mov.f64 	%fd280, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd281, %fd279, %fd280, %fd24;
	mov.f64 	%fd282, 0d3C91A62633145C00;
	fma.rn.f64 	%fd283, %fd279, %fd282, %fd281;
	mov.f64 	%fd284, 0d397B839A252049C0;
	fma.rn.f64 	%fd803, %fd279, %fd284, %fd283;
	abs.f64 	%fd285, %fd24;
	setp.ltu.f64 	%p57, %fd285, 0d41E0000000000000;
	@%p57 bra 	$L__BB14_33;

	{ // callseq 170, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd803, [retval0+0];
	} // callseq 170
	ld.local.u32 	%r288, [%rd1];

$L__BB14_33:
	and.b32  	%r116, %r288, 1;
	shl.b32 	%r117, %r288, 3;
	and.b32  	%r118, %r117, 8;
	setp.eq.s32 	%p58, %r116, 0;
	selp.f64 	%fd287, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p58;
	mul.wide.s32 	%rd49, %r118, 8;
	mov.u64 	%rd50, __cudart_sin_cos_coeffs;
	add.s64 	%rd51, %rd50, %rd49;
	ld.global.nc.f64 	%fd288, [%rd51+8];
	mul.rn.f64 	%fd29, %fd803, %fd803;
	fma.rn.f64 	%fd289, %fd287, %fd29, %fd288;
	ld.global.nc.f64 	%fd290, [%rd51+16];
	fma.rn.f64 	%fd291, %fd289, %fd29, %fd290;
	ld.global.nc.f64 	%fd292, [%rd51+24];
	fma.rn.f64 	%fd293, %fd291, %fd29, %fd292;
	ld.global.nc.f64 	%fd294, [%rd51+32];
	fma.rn.f64 	%fd295, %fd293, %fd29, %fd294;
	ld.global.nc.f64 	%fd296, [%rd51+40];
	fma.rn.f64 	%fd297, %fd295, %fd29, %fd296;
	ld.global.nc.f64 	%fd298, [%rd51+48];
	fma.rn.f64 	%fd30, %fd297, %fd29, %fd298;
	fma.rn.f64 	%fd805, %fd30, %fd803, %fd803;
	@%p58 bra 	$L__BB14_35;

	mov.f64 	%fd299, 0d3FF0000000000000;
	fma.rn.f64 	%fd805, %fd30, %fd29, %fd299;

$L__BB14_35:
	and.b32  	%r119, %r288, 2;
	setp.eq.s32 	%p59, %r119, 0;
	@%p59 bra 	$L__BB14_37;

	mov.f64 	%fd300, 0d0000000000000000;
	mov.f64 	%fd301, 0dBFF0000000000000;
	fma.rn.f64 	%fd805, %fd805, %fd301, %fd300;

$L__BB14_37:
	mul.rn.f64 	%fd302, %fd805, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd303, %fd23;
	add.rn.f64 	%fd36, %fd303, %fd302;
	setp.eq.f64 	%p60, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p61, %fd3, 0d0000000000000000;
	and.pred  	%p62, %p61, %p60;
	@%p62 bra 	$L__BB14_41;
	bra.uni 	$L__BB14_38;

$L__BB14_41:
	selp.f64 	%fd356, 0d400921FB54442D18, 0d0000000000000000, %p9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r128, %temp}, %fd356;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd356;
	}
	and.b32  	%r130, %r6, -2147483648;
	or.b32  	%r131, %r129, %r130;
	mov.b64 	%fd806, {%r128, %r131};
	bra.uni 	$L__BB14_42;

$L__BB14_38:
	setp.eq.f64 	%p63, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p64, %fd13, 0d7FF0000000000000;
	and.pred  	%p65, %p63, %p64;
	@%p65 bra 	$L__BB14_40;
	bra.uni 	$L__BB14_39;

$L__BB14_40:
	selp.f64 	%fd355, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd355;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r125}, %fd355;
	}
	and.b32  	%r126, %r6, -2147483648;
	or.b32  	%r127, %r125, %r126;
	mov.b64 	%fd806, {%r124, %r127};
	bra.uni 	$L__BB14_42;

$L__BB14_39:
	min.f64 	%fd304, %fd13, %fd3;
	max.f64 	%fd305, %fd13, %fd3;
	div.rn.f64 	%fd306, %fd304, %fd305;
	mul.rn.f64 	%fd307, %fd306, %fd306;
	mov.f64 	%fd308, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd309, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd310, %fd309, %fd307, %fd308;
	mov.f64 	%fd311, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd312, %fd310, %fd307, %fd311;
	mov.f64 	%fd313, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd314, %fd312, %fd307, %fd313;
	mov.f64 	%fd315, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd316, %fd314, %fd307, %fd315;
	mov.f64 	%fd317, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd318, %fd316, %fd307, %fd317;
	mov.f64 	%fd319, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd320, %fd318, %fd307, %fd319;
	mov.f64 	%fd321, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd322, %fd320, %fd307, %fd321;
	mov.f64 	%fd323, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd324, %fd322, %fd307, %fd323;
	mov.f64 	%fd325, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd326, %fd324, %fd307, %fd325;
	mov.f64 	%fd327, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd328, %fd326, %fd307, %fd327;
	mov.f64 	%fd329, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd330, %fd328, %fd307, %fd329;
	mov.f64 	%fd331, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd332, %fd330, %fd307, %fd331;
	mov.f64 	%fd333, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd334, %fd332, %fd307, %fd333;
	mov.f64 	%fd335, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd336, %fd334, %fd307, %fd335;
	mov.f64 	%fd337, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd338, %fd336, %fd307, %fd337;
	mov.f64 	%fd339, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd340, %fd338, %fd307, %fd339;
	mov.f64 	%fd341, 0d3FC99999999840D2;
	fma.rn.f64 	%fd342, %fd340, %fd307, %fd341;
	mov.f64 	%fd343, 0dBFD555555555544C;
	fma.rn.f64 	%fd344, %fd342, %fd307, %fd343;
	mul.rn.f64 	%fd345, %fd307, %fd344;
	fma.rn.f64 	%fd346, %fd345, %fd306, %fd306;
	mov.f64 	%fd347, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd348, %fd347, %fd346;
	setp.gt.f64 	%p67, %fd13, %fd3;
	selp.f64 	%fd349, %fd348, %fd346, %p67;
	mov.f64 	%fd350, 0d400921FB54442D18;
	sub.rn.f64 	%fd351, %fd350, %fd349;
	selp.f64 	%fd352, %fd351, %fd349, %p9;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r120, %temp}, %fd352;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd352;
	}
	and.b32  	%r122, %r6, -2147483648;
	or.b32  	%r123, %r121, %r122;
	mov.b64 	%fd353, {%r120, %r123};
	add.rn.f64 	%fd354, %fd3, %fd13;
	setp.le.f64 	%p68, %fd354, 0d7FF0000000000000;
	selp.f64 	%fd806, %fd353, %fd354, %p68;

$L__BB14_42:
	add.rn.f64 	%fd796, %fd260, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd796, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r133}, %fd41;
	}
	and.b32  	%r134, %r133, 2147483647;
	setp.eq.s32 	%p71, %r134, 2146435072;
	setp.eq.s32 	%p72, %r132, 0;
	and.pred  	%p73, %p72, %p71;
	@%p73 bra 	$L__BB14_46;
	bra.uni 	$L__BB14_43;

$L__BB14_46:
	mov.f64 	%fd366, 0d0000000000000000;
	mul.rn.f64 	%fd808, %fd41, %fd366;
	mov.u32 	%r290, 1;
	bra.uni 	$L__BB14_47;

$L__BB14_43:
	mul.rn.f64 	%fd357, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r289, %fd357;
	st.local.u32 	[%rd1], %r289;
	cvt.rn.f64.s32 	%fd358, %r289;
	neg.f64 	%fd359, %fd358;
	mov.f64 	%fd360, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd361, %fd359, %fd360, %fd41;
	mov.f64 	%fd362, 0d3C91A62633145C00;
	fma.rn.f64 	%fd363, %fd359, %fd362, %fd361;
	mov.f64 	%fd364, 0d397B839A252049C0;
	fma.rn.f64 	%fd808, %fd359, %fd364, %fd363;
	abs.f64 	%fd365, %fd41;
	setp.ltu.f64 	%p74, %fd365, 0d41E0000000000000;
	@%p74 bra 	$L__BB14_45;

	{ // callseq 171, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 171
	ld.local.u32 	%r289, [%rd1];

$L__BB14_45:
	add.s32 	%r290, %r289, 1;

$L__BB14_47:
	and.b32  	%r136, %r290, 1;
	shl.b32 	%r137, %r290, 3;
	and.b32  	%r138, %r137, 8;
	setp.eq.s32 	%p75, %r136, 0;
	selp.f64 	%fd367, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p75;
	mul.wide.s32 	%rd53, %r138, 8;
	add.s64 	%rd55, %rd50, %rd53;
	ld.global.nc.f64 	%fd368, [%rd55+8];
	mul.rn.f64 	%fd47, %fd808, %fd808;
	fma.rn.f64 	%fd369, %fd367, %fd47, %fd368;
	ld.global.nc.f64 	%fd370, [%rd55+16];
	fma.rn.f64 	%fd371, %fd369, %fd47, %fd370;
	ld.global.nc.f64 	%fd372, [%rd55+24];
	fma.rn.f64 	%fd373, %fd371, %fd47, %fd372;
	ld.global.nc.f64 	%fd374, [%rd55+32];
	fma.rn.f64 	%fd375, %fd373, %fd47, %fd374;
	ld.global.nc.f64 	%fd376, [%rd55+40];
	fma.rn.f64 	%fd377, %fd375, %fd47, %fd376;
	ld.global.nc.f64 	%fd378, [%rd55+48];
	fma.rn.f64 	%fd48, %fd377, %fd47, %fd378;
	fma.rn.f64 	%fd810, %fd48, %fd808, %fd808;
	@%p75 bra 	$L__BB14_49;

	mov.f64 	%fd379, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd48, %fd47, %fd379;

$L__BB14_49:
	and.b32  	%r139, %r290, 2;
	setp.eq.s32 	%p76, %r139, 0;
	@%p76 bra 	$L__BB14_51;

	mov.f64 	%fd380, 0d0000000000000000;
	mov.f64 	%fd381, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd381, %fd380;

$L__BB14_51:
	mul.rn.f64 	%fd382, %fd810, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd806, %fd382;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd54;
	}
	and.b32  	%r142, %r141, 2147483647;
	setp.eq.s32 	%p77, %r142, 2146435072;
	setp.eq.s32 	%p78, %r140, 0;
	and.pred  	%p3, %p78, %p77;
	@%p3 bra 	$L__BB14_55;
	bra.uni 	$L__BB14_52;

$L__BB14_55:
	mov.f64 	%fd392, 0d0000000000000000;
	mul.rn.f64 	%fd812, %fd54, %fd392;
	mov.u32 	%r292, 1;
	bra.uni 	$L__BB14_56;

$L__BB14_52:
	mul.rn.f64 	%fd383, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r291, %fd383;
	st.local.u32 	[%rd1], %r291;
	cvt.rn.f64.s32 	%fd384, %r291;
	neg.f64 	%fd385, %fd384;
	mov.f64 	%fd386, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd387, %fd385, %fd386, %fd54;
	mov.f64 	%fd388, 0d3C91A62633145C00;
	fma.rn.f64 	%fd389, %fd385, %fd388, %fd387;
	mov.f64 	%fd390, 0d397B839A252049C0;
	fma.rn.f64 	%fd812, %fd385, %fd390, %fd389;
	abs.f64 	%fd391, %fd54;
	setp.ltu.f64 	%p79, %fd391, 0d41E0000000000000;
	@%p79 bra 	$L__BB14_54;

	{ // callseq 172, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 172
	ld.local.u32 	%r291, [%rd1];

$L__BB14_54:
	add.s32 	%r292, %r291, 1;

$L__BB14_56:
	and.b32  	%r144, %r292, 1;
	shl.b32 	%r145, %r292, 3;
	and.b32  	%r146, %r145, 8;
	setp.eq.s32 	%p80, %r144, 0;
	selp.f64 	%fd393, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p80;
	mul.wide.s32 	%rd57, %r146, 8;
	add.s64 	%rd59, %rd50, %rd57;
	ld.global.nc.f64 	%fd394, [%rd59+8];
	mul.rn.f64 	%fd60, %fd812, %fd812;
	fma.rn.f64 	%fd395, %fd393, %fd60, %fd394;
	ld.global.nc.f64 	%fd396, [%rd59+16];
	fma.rn.f64 	%fd397, %fd395, %fd60, %fd396;
	ld.global.nc.f64 	%fd398, [%rd59+24];
	fma.rn.f64 	%fd399, %fd397, %fd60, %fd398;
	ld.global.nc.f64 	%fd400, [%rd59+32];
	fma.rn.f64 	%fd401, %fd399, %fd60, %fd400;
	ld.global.nc.f64 	%fd402, [%rd59+40];
	fma.rn.f64 	%fd403, %fd401, %fd60, %fd402;
	ld.global.nc.f64 	%fd404, [%rd59+48];
	fma.rn.f64 	%fd61, %fd403, %fd60, %fd404;
	fma.rn.f64 	%fd814, %fd61, %fd812, %fd812;
	@%p80 bra 	$L__BB14_58;

	mov.f64 	%fd405, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd61, %fd60, %fd405;

$L__BB14_58:
	and.b32  	%r147, %r292, 2;
	setp.eq.s32 	%p81, %r147, 0;
	@%p81 bra 	$L__BB14_60;

	mov.f64 	%fd406, 0d0000000000000000;
	mov.f64 	%fd407, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd407, %fd406;

$L__BB14_60:
	mul.rn.f64 	%fd408, %fd36, %fd814;
	st.global.f64 	[%rd18], %fd408;
	@%p3 bra 	$L__BB14_63;
	bra.uni 	$L__BB14_61;

$L__BB14_63:
	mov.f64 	%fd418, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd54, %fd418;
	mov.u32 	%r293, 0;
	bra.uni 	$L__BB14_64;

$L__BB14_61:
	mul.rn.f64 	%fd409, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r293, %fd409;
	st.local.u32 	[%rd1], %r293;
	cvt.rn.f64.s32 	%fd410, %r293;
	neg.f64 	%fd411, %fd410;
	mov.f64 	%fd412, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd413, %fd411, %fd412, %fd54;
	mov.f64 	%fd414, 0d3C91A62633145C00;
	fma.rn.f64 	%fd415, %fd411, %fd414, %fd413;
	mov.f64 	%fd416, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd411, %fd416, %fd415;
	abs.f64 	%fd417, %fd54;
	setp.ltu.f64 	%p82, %fd417, 0d41E0000000000000;
	@%p82 bra 	$L__BB14_64;

	{ // callseq 173, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 173
	ld.local.u32 	%r293, [%rd1];

$L__BB14_64:
	and.b32  	%r149, %r293, 1;
	shl.b32 	%r150, %r293, 3;
	and.b32  	%r151, %r150, 8;
	setp.eq.s32 	%p83, %r149, 0;
	selp.f64 	%fd419, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p83;
	mul.wide.s32 	%rd61, %r151, 8;
	add.s64 	%rd63, %rd50, %rd61;
	ld.global.nc.f64 	%fd420, [%rd63+8];
	mul.rn.f64 	%fd71, %fd815, %fd815;
	fma.rn.f64 	%fd421, %fd419, %fd71, %fd420;
	ld.global.nc.f64 	%fd422, [%rd63+16];
	fma.rn.f64 	%fd423, %fd421, %fd71, %fd422;
	ld.global.nc.f64 	%fd424, [%rd63+24];
	fma.rn.f64 	%fd425, %fd423, %fd71, %fd424;
	ld.global.nc.f64 	%fd426, [%rd63+32];
	fma.rn.f64 	%fd427, %fd425, %fd71, %fd426;
	ld.global.nc.f64 	%fd428, [%rd63+40];
	fma.rn.f64 	%fd429, %fd427, %fd71, %fd428;
	ld.global.nc.f64 	%fd430, [%rd63+48];
	fma.rn.f64 	%fd72, %fd429, %fd71, %fd430;
	fma.rn.f64 	%fd817, %fd72, %fd815, %fd815;
	@%p83 bra 	$L__BB14_66;

	mov.f64 	%fd431, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd72, %fd71, %fd431;

$L__BB14_66:
	and.b32  	%r152, %r293, 2;
	setp.eq.s32 	%p84, %r152, 0;
	@%p84 bra 	$L__BB14_68;

	mov.f64 	%fd432, 0d0000000000000000;
	mov.f64 	%fd433, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd433, %fd432;

$L__BB14_68:
	mul.rn.f64 	%fd78, %fd36, %fd817;
	st.global.f64 	[%rd19], %fd78;
	ld.global.f64 	%fd79, [%rd18];
	add.rn.f64 	%fd80, %fd79, 0dC05A400000000000;
	add.rn.f64 	%fd81, %fd78, 0dC041800000000000;
	abs.f64 	%fd82, %fd80;
	sqrt.rn.f64 	%fd83, %fd82;
	mul.rn.f64 	%fd84, %fd80, 0d400921FB54442D18;
	mul.rn.f64 	%fd85, %fd81, 0d400921FB54442D18;
	mul.rn.f64 	%fd86, %fd84, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd86;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd86;
	}
	and.b32  	%r155, %r154, 2147483647;
	setp.eq.s32 	%p85, %r155, 2146435072;
	setp.eq.s32 	%p86, %r153, 0;
	and.pred  	%p87, %p86, %p85;
	@%p87 bra 	$L__BB14_71;
	bra.uni 	$L__BB14_69;

$L__BB14_71:
	mov.f64 	%fd443, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd86, %fd443;
	mov.u32 	%r294, 0;
	bra.uni 	$L__BB14_72;

$L__BB14_69:
	mul.rn.f64 	%fd434, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r294, %fd434;
	st.local.u32 	[%rd1], %r294;
	cvt.rn.f64.s32 	%fd435, %r294;
	neg.f64 	%fd436, %fd435;
	mov.f64 	%fd437, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd438, %fd436, %fd437, %fd86;
	mov.f64 	%fd439, 0d3C91A62633145C00;
	fma.rn.f64 	%fd440, %fd436, %fd439, %fd438;
	mov.f64 	%fd441, 0d397B839A252049C0;
	fma.rn.f64 	%fd818, %fd436, %fd441, %fd440;
	abs.f64 	%fd442, %fd86;
	setp.ltu.f64 	%p88, %fd442, 0d41E0000000000000;
	@%p88 bra 	$L__BB14_72;

	{ // callseq 174, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd818, [retval0+0];
	} // callseq 174
	ld.local.u32 	%r294, [%rd1];

$L__BB14_72:
	and.b32  	%r157, %r294, 1;
	shl.b32 	%r158, %r294, 3;
	and.b32  	%r159, %r158, 8;
	setp.eq.s32 	%p89, %r157, 0;
	selp.f64 	%fd444, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p89;
	mul.wide.s32 	%rd65, %r159, 8;
	add.s64 	%rd67, %rd50, %rd65;
	ld.global.nc.f64 	%fd445, [%rd67+8];
	mul.rn.f64 	%fd91, %fd818, %fd818;
	fma.rn.f64 	%fd446, %fd444, %fd91, %fd445;
	ld.global.nc.f64 	%fd447, [%rd67+16];
	fma.rn.f64 	%fd448, %fd446, %fd91, %fd447;
	ld.global.nc.f64 	%fd449, [%rd67+24];
	fma.rn.f64 	%fd450, %fd448, %fd91, %fd449;
	ld.global.nc.f64 	%fd451, [%rd67+32];
	fma.rn.f64 	%fd452, %fd450, %fd91, %fd451;
	ld.global.nc.f64 	%fd453, [%rd67+40];
	fma.rn.f64 	%fd454, %fd452, %fd91, %fd453;
	ld.global.nc.f64 	%fd455, [%rd67+48];
	fma.rn.f64 	%fd92, %fd454, %fd91, %fd455;
	fma.rn.f64 	%fd820, %fd92, %fd818, %fd818;
	@%p89 bra 	$L__BB14_74;

	mov.f64 	%fd456, 0d3FF0000000000000;
	fma.rn.f64 	%fd820, %fd92, %fd91, %fd456;

$L__BB14_74:
	and.b32  	%r160, %r294, 2;
	setp.eq.s32 	%p90, %r160, 0;
	@%p90 bra 	$L__BB14_76;

	mov.f64 	%fd457, 0d0000000000000000;
	mov.f64 	%fd458, 0dBFF0000000000000;
	fma.rn.f64 	%fd820, %fd820, %fd458, %fd457;

$L__BB14_76:
	add.rn.f64 	%fd98, %fd84, %fd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd98;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd98;
	}
	and.b32  	%r163, %r162, 2147483647;
	setp.eq.s32 	%p91, %r163, 2146435072;
	setp.eq.s32 	%p92, %r161, 0;
	and.pred  	%p93, %p92, %p91;
	@%p93 bra 	$L__BB14_79;
	bra.uni 	$L__BB14_77;

$L__BB14_79:
	mov.f64 	%fd468, 0d0000000000000000;
	mul.rn.f64 	%fd821, %fd98, %fd468;
	mov.u32 	%r295, 0;
	bra.uni 	$L__BB14_80;

$L__BB14_77:
	mul.rn.f64 	%fd459, %fd98, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r295, %fd459;
	st.local.u32 	[%rd1], %r295;
	cvt.rn.f64.s32 	%fd460, %r295;
	neg.f64 	%fd461, %fd460;
	mov.f64 	%fd462, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd463, %fd461, %fd462, %fd98;
	mov.f64 	%fd464, 0d3C91A62633145C00;
	fma.rn.f64 	%fd465, %fd461, %fd464, %fd463;
	mov.f64 	%fd466, 0d397B839A252049C0;
	fma.rn.f64 	%fd821, %fd461, %fd466, %fd465;
	abs.f64 	%fd467, %fd98;
	setp.ltu.f64 	%p94, %fd467, 0d41E0000000000000;
	@%p94 bra 	$L__BB14_80;

	{ // callseq 175, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd98;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd821, [retval0+0];
	} // callseq 175
	ld.local.u32 	%r295, [%rd1];

$L__BB14_80:
	and.b32  	%r165, %r295, 1;
	shl.b32 	%r166, %r295, 3;
	and.b32  	%r167, %r166, 8;
	setp.eq.s32 	%p95, %r165, 0;
	selp.f64 	%fd469, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p95;
	mul.wide.s32 	%rd69, %r167, 8;
	add.s64 	%rd71, %rd50, %rd69;
	ld.global.nc.f64 	%fd470, [%rd71+8];
	mul.rn.f64 	%fd103, %fd821, %fd821;
	fma.rn.f64 	%fd471, %fd469, %fd103, %fd470;
	ld.global.nc.f64 	%fd472, [%rd71+16];
	fma.rn.f64 	%fd473, %fd471, %fd103, %fd472;
	ld.global.nc.f64 	%fd474, [%rd71+24];
	fma.rn.f64 	%fd475, %fd473, %fd103, %fd474;
	ld.global.nc.f64 	%fd476, [%rd71+32];
	fma.rn.f64 	%fd477, %fd475, %fd103, %fd476;
	ld.global.nc.f64 	%fd478, [%rd71+40];
	fma.rn.f64 	%fd479, %fd477, %fd103, %fd478;
	ld.global.nc.f64 	%fd480, [%rd71+48];
	fma.rn.f64 	%fd104, %fd479, %fd103, %fd480;
	fma.rn.f64 	%fd823, %fd104, %fd821, %fd821;
	@%p95 bra 	$L__BB14_82;

	mov.f64 	%fd481, 0d3FF0000000000000;
	fma.rn.f64 	%fd823, %fd104, %fd103, %fd481;

$L__BB14_82:
	and.b32  	%r168, %r295, 2;
	setp.eq.s32 	%p96, %r168, 0;
	@%p96 bra 	$L__BB14_84;

	mov.f64 	%fd482, 0d0000000000000000;
	mov.f64 	%fd483, 0dBFF0000000000000;
	fma.rn.f64 	%fd823, %fd823, %fd483, %fd482;

$L__BB14_84:
	mul.rn.f64 	%fd484, %fd823, 0d4034000000000000;
	mul.rn.f64 	%fd485, %fd820, 0d4034000000000000;
	add.rn.f64 	%fd110, %fd485, %fd484;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r169}, %fd85;
	}
	and.b32  	%r170, %r169, 2147483647;
	setp.eq.s32 	%p97, %r170, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd85;
	}
	setp.eq.s32 	%p98, %r171, 0;
	and.pred  	%p99, %p98, %p97;
	@%p99 bra 	$L__BB14_87;
	bra.uni 	$L__BB14_85;

$L__BB14_87:
	mov.f64 	%fd495, 0d0000000000000000;
	mul.rn.f64 	%fd824, %fd85, %fd495;
	mov.u32 	%r296, 0;
	bra.uni 	$L__BB14_88;

$L__BB14_85:
	mul.rn.f64 	%fd486, %fd85, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r296, %fd486;
	st.local.u32 	[%rd1], %r296;
	cvt.rn.f64.s32 	%fd487, %r296;
	neg.f64 	%fd488, %fd487;
	mov.f64 	%fd489, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd490, %fd488, %fd489, %fd85;
	mov.f64 	%fd491, 0d3C91A62633145C00;
	fma.rn.f64 	%fd492, %fd488, %fd491, %fd490;
	mov.f64 	%fd493, 0d397B839A252049C0;
	fma.rn.f64 	%fd824, %fd488, %fd493, %fd492;
	abs.f64 	%fd494, %fd85;
	setp.ltu.f64 	%p100, %fd494, 0d41E0000000000000;
	@%p100 bra 	$L__BB14_88;

	{ // callseq 176, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd824, [retval0+0];
	} // callseq 176
	ld.local.u32 	%r296, [%rd1];

$L__BB14_88:
	and.b32  	%r173, %r296, 1;
	shl.b32 	%r174, %r296, 3;
	and.b32  	%r175, %r174, 8;
	setp.eq.s32 	%p101, %r173, 0;
	selp.f64 	%fd496, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p101;
	mul.wide.s32 	%rd73, %r175, 8;
	add.s64 	%rd75, %rd50, %rd73;
	ld.global.nc.f64 	%fd497, [%rd75+8];
	mul.rn.f64 	%fd115, %fd824, %fd824;
	fma.rn.f64 	%fd498, %fd496, %fd115, %fd497;
	ld.global.nc.f64 	%fd499, [%rd75+16];
	fma.rn.f64 	%fd500, %fd498, %fd115, %fd499;
	ld.global.nc.f64 	%fd501, [%rd75+24];
	fma.rn.f64 	%fd502, %fd500, %fd115, %fd501;
	ld.global.nc.f64 	%fd503, [%rd75+32];
	fma.rn.f64 	%fd504, %fd502, %fd115, %fd503;
	ld.global.nc.f64 	%fd505, [%rd75+40];
	fma.rn.f64 	%fd506, %fd504, %fd115, %fd505;
	ld.global.nc.f64 	%fd507, [%rd75+48];
	fma.rn.f64 	%fd116, %fd506, %fd115, %fd507;
	fma.rn.f64 	%fd826, %fd116, %fd824, %fd824;
	@%p101 bra 	$L__BB14_90;

	mov.f64 	%fd508, 0d3FF0000000000000;
	fma.rn.f64 	%fd826, %fd116, %fd115, %fd508;

$L__BB14_90:
	and.b32  	%r176, %r296, 2;
	setp.eq.s32 	%p102, %r176, 0;
	@%p102 bra 	$L__BB14_92;

	mov.f64 	%fd509, 0d0000000000000000;
	mov.f64 	%fd510, 0dBFF0000000000000;
	fma.rn.f64 	%fd826, %fd826, %fd510, %fd509;

$L__BB14_92:
	div.rn.f64 	%fd122, %fd85, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r177, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %fd122;
	}
	and.b32  	%r179, %r178, 2147483647;
	setp.eq.s32 	%p103, %r179, 2146435072;
	setp.eq.s32 	%p104, %r177, 0;
	and.pred  	%p105, %p104, %p103;
	@%p105 bra 	$L__BB14_95;
	bra.uni 	$L__BB14_93;

$L__BB14_95:
	mov.f64 	%fd520, 0d0000000000000000;
	mul.rn.f64 	%fd827, %fd122, %fd520;
	mov.u32 	%r297, 0;
	bra.uni 	$L__BB14_96;

$L__BB14_93:
	mul.rn.f64 	%fd511, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r297, %fd511;
	st.local.u32 	[%rd1], %r297;
	cvt.rn.f64.s32 	%fd512, %r297;
	neg.f64 	%fd513, %fd512;
	mov.f64 	%fd514, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd515, %fd513, %fd514, %fd122;
	mov.f64 	%fd516, 0d3C91A62633145C00;
	fma.rn.f64 	%fd517, %fd513, %fd516, %fd515;
	mov.f64 	%fd518, 0d397B839A252049C0;
	fma.rn.f64 	%fd827, %fd513, %fd518, %fd517;
	abs.f64 	%fd519, %fd122;
	setp.ltu.f64 	%p106, %fd519, 0d41E0000000000000;
	@%p106 bra 	$L__BB14_96;

	{ // callseq 177, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd827, [retval0+0];
	} // callseq 177
	ld.local.u32 	%r297, [%rd1];

$L__BB14_96:
	and.b32  	%r181, %r297, 1;
	shl.b32 	%r182, %r297, 3;
	and.b32  	%r183, %r182, 8;
	setp.eq.s32 	%p107, %r181, 0;
	selp.f64 	%fd521, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p107;
	mul.wide.s32 	%rd77, %r183, 8;
	add.s64 	%rd79, %rd50, %rd77;
	ld.global.nc.f64 	%fd522, [%rd79+8];
	mul.rn.f64 	%fd127, %fd827, %fd827;
	fma.rn.f64 	%fd523, %fd521, %fd127, %fd522;
	ld.global.nc.f64 	%fd524, [%rd79+16];
	fma.rn.f64 	%fd525, %fd523, %fd127, %fd524;
	ld.global.nc.f64 	%fd526, [%rd79+24];
	fma.rn.f64 	%fd527, %fd525, %fd127, %fd526;
	ld.global.nc.f64 	%fd528, [%rd79+32];
	fma.rn.f64 	%fd529, %fd527, %fd127, %fd528;
	ld.global.nc.f64 	%fd530, [%rd79+40];
	fma.rn.f64 	%fd531, %fd529, %fd127, %fd530;
	ld.global.nc.f64 	%fd532, [%rd79+48];
	fma.rn.f64 	%fd128, %fd531, %fd127, %fd532;
	fma.rn.f64 	%fd829, %fd128, %fd827, %fd827;
	@%p107 bra 	$L__BB14_98;

	mov.f64 	%fd533, 0d3FF0000000000000;
	fma.rn.f64 	%fd829, %fd128, %fd127, %fd533;

$L__BB14_98:
	and.b32  	%r184, %r297, 2;
	setp.eq.s32 	%p108, %r184, 0;
	@%p108 bra 	$L__BB14_100;

	mov.f64 	%fd534, 0d0000000000000000;
	mov.f64 	%fd535, 0dBFF0000000000000;
	fma.rn.f64 	%fd829, %fd829, %fd535, %fd534;

$L__BB14_100:
	mul.rn.f64 	%fd536, %fd829, 0d4044000000000000;
	mul.rn.f64 	%fd537, %fd826, 0d4034000000000000;
	add.rn.f64 	%fd134, %fd537, %fd536;
	div.rn.f64 	%fd135, %fd85, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r185, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %fd135;
	}
	and.b32  	%r187, %r186, 2147483647;
	setp.eq.s32 	%p109, %r187, 2146435072;
	setp.eq.s32 	%p110, %r185, 0;
	and.pred  	%p111, %p110, %p109;
	@%p111 bra 	$L__BB14_103;
	bra.uni 	$L__BB14_101;

$L__BB14_103:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd830, %fd135, %fd547;
	mov.u32 	%r298, 0;
	bra.uni 	$L__BB14_104;

$L__BB14_101:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r298, %fd538;
	st.local.u32 	[%rd1], %r298;
	cvt.rn.f64.s32 	%fd539, %r298;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd830, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p112, %fd546, 0d41E0000000000000;
	@%p112 bra 	$L__BB14_104;

	{ // callseq 178, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd830, [retval0+0];
	} // callseq 178
	ld.local.u32 	%r298, [%rd1];

$L__BB14_104:
	and.b32  	%r189, %r298, 1;
	shl.b32 	%r190, %r298, 3;
	and.b32  	%r191, %r190, 8;
	setp.eq.s32 	%p113, %r189, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd81, %r191, 8;
	add.s64 	%rd83, %rd50, %rd81;
	ld.global.nc.f64 	%fd549, [%rd83+8];
	mul.rn.f64 	%fd140, %fd830, %fd830;
	fma.rn.f64 	%fd550, %fd548, %fd140, %fd549;
	ld.global.nc.f64 	%fd551, [%rd83+16];
	fma.rn.f64 	%fd552, %fd550, %fd140, %fd551;
	ld.global.nc.f64 	%fd553, [%rd83+24];
	fma.rn.f64 	%fd554, %fd552, %fd140, %fd553;
	ld.global.nc.f64 	%fd555, [%rd83+32];
	fma.rn.f64 	%fd556, %fd554, %fd140, %fd555;
	ld.global.nc.f64 	%fd557, [%rd83+40];
	fma.rn.f64 	%fd558, %fd556, %fd140, %fd557;
	ld.global.nc.f64 	%fd559, [%rd83+48];
	fma.rn.f64 	%fd141, %fd558, %fd140, %fd559;
	fma.rn.f64 	%fd832, %fd141, %fd830, %fd830;
	@%p113 bra 	$L__BB14_106;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd832, %fd141, %fd140, %fd560;

$L__BB14_106:
	and.b32  	%r192, %r298, 2;
	setp.eq.s32 	%p114, %r192, 0;
	@%p114 bra 	$L__BB14_108;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd832, %fd832, %fd562, %fd561;

$L__BB14_108:
	mul.rn.f64 	%fd563, %fd832, 0d4064000000000000;
	add.rn.f64 	%fd147, %fd134, %fd563;
	div.rn.f64 	%fd148, %fd85, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd148;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd148;
	}
	and.b32  	%r195, %r194, 2147483647;
	setp.eq.s32 	%p115, %r195, 2146435072;
	setp.eq.s32 	%p116, %r193, 0;
	and.pred  	%p117, %p116, %p115;
	@%p117 bra 	$L__BB14_111;
	bra.uni 	$L__BB14_109;

$L__BB14_111:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd833, %fd148, %fd573;
	mov.u32 	%r299, 0;
	bra.uni 	$L__BB14_112;

$L__BB14_109:
	mul.rn.f64 	%fd564, %fd148, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd564;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd565, %r299;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd148;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd833, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd148;
	setp.ltu.f64 	%p118, %fd572, 0d41E0000000000000;
	@%p118 bra 	$L__BB14_112;

	{ // callseq 179, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd833, [retval0+0];
	} // callseq 179
	ld.local.u32 	%r299, [%rd1];

$L__BB14_112:
	and.b32  	%r197, %r299, 1;
	shl.b32 	%r198, %r299, 3;
	and.b32  	%r199, %r198, 8;
	setp.eq.s32 	%p119, %r197, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p119;
	mul.wide.s32 	%rd85, %r199, 8;
	add.s64 	%rd87, %rd50, %rd85;
	ld.global.nc.f64 	%fd575, [%rd87+8];
	mul.rn.f64 	%fd153, %fd833, %fd833;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd87+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd87+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd87+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd87+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd87+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd835, %fd154, %fd833, %fd833;
	@%p119 bra 	$L__BB14_114;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd835, %fd154, %fd153, %fd586;

$L__BB14_114:
	and.b32  	%r200, %r299, 2;
	setp.eq.s32 	%p120, %r200, 0;
	@%p120 bra 	$L__BB14_116;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd835, %fd835, %fd588, %fd587;

$L__BB14_116:
	mul.rn.f64 	%fd589, %fd835, 0d4074000000000000;
	add.rn.f64 	%fd160, %fd147, %fd589;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd84;
	}
	and.b32  	%r202, %r201, 2147483647;
	setp.eq.s32 	%p121, %r202, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd84;
	}
	setp.eq.s32 	%p122, %r203, 0;
	and.pred  	%p123, %p122, %p121;
	@%p123 bra 	$L__BB14_119;
	bra.uni 	$L__BB14_117;

$L__BB14_119:
	mov.f64 	%fd599, 0d0000000000000000;
	mul.rn.f64 	%fd836, %fd84, %fd599;
	mov.u32 	%r300, 0;
	bra.uni 	$L__BB14_120;

$L__BB14_117:
	mul.rn.f64 	%fd590, %fd84, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r300, %fd590;
	st.local.u32 	[%rd1], %r300;
	cvt.rn.f64.s32 	%fd591, %r300;
	neg.f64 	%fd592, %fd591;
	mov.f64 	%fd593, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd594, %fd592, %fd593, %fd84;
	mov.f64 	%fd595, 0d3C91A62633145C00;
	fma.rn.f64 	%fd596, %fd592, %fd595, %fd594;
	mov.f64 	%fd597, 0d397B839A252049C0;
	fma.rn.f64 	%fd836, %fd592, %fd597, %fd596;
	abs.f64 	%fd598, %fd84;
	setp.ltu.f64 	%p124, %fd598, 0d41E0000000000000;
	@%p124 bra 	$L__BB14_120;

	{ // callseq 180, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd836, [retval0+0];
	} // callseq 180
	ld.local.u32 	%r300, [%rd1];

$L__BB14_120:
	and.b32  	%r205, %r300, 1;
	shl.b32 	%r206, %r300, 3;
	and.b32  	%r207, %r206, 8;
	setp.eq.s32 	%p125, %r205, 0;
	selp.f64 	%fd600, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p125;
	mul.wide.s32 	%rd89, %r207, 8;
	add.s64 	%rd91, %rd50, %rd89;
	ld.global.nc.f64 	%fd601, [%rd91+8];
	mul.rn.f64 	%fd165, %fd836, %fd836;
	fma.rn.f64 	%fd602, %fd600, %fd165, %fd601;
	ld.global.nc.f64 	%fd603, [%rd91+16];
	fma.rn.f64 	%fd604, %fd602, %fd165, %fd603;
	ld.global.nc.f64 	%fd605, [%rd91+24];
	fma.rn.f64 	%fd606, %fd604, %fd165, %fd605;
	ld.global.nc.f64 	%fd607, [%rd91+32];
	fma.rn.f64 	%fd608, %fd606, %fd165, %fd607;
	ld.global.nc.f64 	%fd609, [%rd91+40];
	fma.rn.f64 	%fd610, %fd608, %fd165, %fd609;
	ld.global.nc.f64 	%fd611, [%rd91+48];
	fma.rn.f64 	%fd166, %fd610, %fd165, %fd611;
	fma.rn.f64 	%fd838, %fd166, %fd836, %fd836;
	@%p125 bra 	$L__BB14_122;

	mov.f64 	%fd612, 0d3FF0000000000000;
	fma.rn.f64 	%fd838, %fd166, %fd165, %fd612;

$L__BB14_122:
	and.b32  	%r208, %r300, 2;
	setp.eq.s32 	%p126, %r208, 0;
	@%p126 bra 	$L__BB14_124;

	mov.f64 	%fd613, 0d0000000000000000;
	mov.f64 	%fd614, 0dBFF0000000000000;
	fma.rn.f64 	%fd838, %fd838, %fd614, %fd613;

$L__BB14_124:
	div.rn.f64 	%fd172, %fd84, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r209, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd172;
	}
	and.b32  	%r211, %r210, 2147483647;
	setp.eq.s32 	%p127, %r211, 2146435072;
	setp.eq.s32 	%p128, %r209, 0;
	and.pred  	%p129, %p128, %p127;
	@%p129 bra 	$L__BB14_127;
	bra.uni 	$L__BB14_125;

$L__BB14_127:
	mov.f64 	%fd624, 0d0000000000000000;
	mul.rn.f64 	%fd839, %fd172, %fd624;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB14_128;

$L__BB14_125:
	mul.rn.f64 	%fd615, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd615;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd616, %r301;
	neg.f64 	%fd617, %fd616;
	mov.f64 	%fd618, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd619, %fd617, %fd618, %fd172;
	mov.f64 	%fd620, 0d3C91A62633145C00;
	fma.rn.f64 	%fd621, %fd617, %fd620, %fd619;
	mov.f64 	%fd622, 0d397B839A252049C0;
	fma.rn.f64 	%fd839, %fd617, %fd622, %fd621;
	abs.f64 	%fd623, %fd172;
	setp.ltu.f64 	%p130, %fd623, 0d41E0000000000000;
	@%p130 bra 	$L__BB14_128;

	{ // callseq 181, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd839, [retval0+0];
	} // callseq 181
	ld.local.u32 	%r301, [%rd1];

$L__BB14_128:
	and.b32  	%r213, %r301, 1;
	shl.b32 	%r214, %r301, 3;
	and.b32  	%r215, %r214, 8;
	setp.eq.s32 	%p131, %r213, 0;
	selp.f64 	%fd625, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p131;
	mul.wide.s32 	%rd93, %r215, 8;
	add.s64 	%rd95, %rd50, %rd93;
	ld.global.nc.f64 	%fd626, [%rd95+8];
	mul.rn.f64 	%fd177, %fd839, %fd839;
	fma.rn.f64 	%fd627, %fd625, %fd177, %fd626;
	ld.global.nc.f64 	%fd628, [%rd95+16];
	fma.rn.f64 	%fd629, %fd627, %fd177, %fd628;
	ld.global.nc.f64 	%fd630, [%rd95+24];
	fma.rn.f64 	%fd631, %fd629, %fd177, %fd630;
	ld.global.nc.f64 	%fd632, [%rd95+32];
	fma.rn.f64 	%fd633, %fd631, %fd177, %fd632;
	ld.global.nc.f64 	%fd634, [%rd95+40];
	fma.rn.f64 	%fd635, %fd633, %fd177, %fd634;
	ld.global.nc.f64 	%fd636, [%rd95+48];
	fma.rn.f64 	%fd178, %fd635, %fd177, %fd636;
	fma.rn.f64 	%fd841, %fd178, %fd839, %fd839;
	@%p131 bra 	$L__BB14_130;

	mov.f64 	%fd637, 0d3FF0000000000000;
	fma.rn.f64 	%fd841, %fd178, %fd177, %fd637;

$L__BB14_130:
	and.b32  	%r216, %r301, 2;
	setp.eq.s32 	%p132, %r216, 0;
	@%p132 bra 	$L__BB14_132;

	mov.f64 	%fd638, 0d0000000000000000;
	mov.f64 	%fd639, 0dBFF0000000000000;
	fma.rn.f64 	%fd841, %fd841, %fd639, %fd638;

$L__BB14_132:
	mul.rn.f64 	%fd640, %fd841, 0d4044000000000000;
	mul.rn.f64 	%fd641, %fd838, 0d4034000000000000;
	add.rn.f64 	%fd184, %fd641, %fd640;
	div.rn.f64 	%fd185, %fd84, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r217, %temp}, %fd185;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r218}, %fd185;
	}
	and.b32  	%r219, %r218, 2147483647;
	setp.eq.s32 	%p133, %r219, 2146435072;
	setp.eq.s32 	%p134, %r217, 0;
	and.pred  	%p135, %p134, %p133;
	@%p135 bra 	$L__BB14_135;
	bra.uni 	$L__BB14_133;

$L__BB14_135:
	mov.f64 	%fd651, 0d0000000000000000;
	mul.rn.f64 	%fd842, %fd185, %fd651;
	mov.u32 	%r302, 0;
	bra.uni 	$L__BB14_136;

$L__BB14_133:
	mul.rn.f64 	%fd642, %fd185, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd642;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd643, %r302;
	neg.f64 	%fd644, %fd643;
	mov.f64 	%fd645, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd646, %fd644, %fd645, %fd185;
	mov.f64 	%fd647, 0d3C91A62633145C00;
	fma.rn.f64 	%fd648, %fd644, %fd647, %fd646;
	mov.f64 	%fd649, 0d397B839A252049C0;
	fma.rn.f64 	%fd842, %fd644, %fd649, %fd648;
	abs.f64 	%fd650, %fd185;
	setp.ltu.f64 	%p136, %fd650, 0d41E0000000000000;
	@%p136 bra 	$L__BB14_136;

	{ // callseq 182, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd185;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd842, [retval0+0];
	} // callseq 182
	ld.local.u32 	%r302, [%rd1];

$L__BB14_136:
	and.b32  	%r221, %r302, 1;
	shl.b32 	%r222, %r302, 3;
	and.b32  	%r223, %r222, 8;
	setp.eq.s32 	%p137, %r221, 0;
	selp.f64 	%fd652, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p137;
	mul.wide.s32 	%rd97, %r223, 8;
	add.s64 	%rd99, %rd50, %rd97;
	ld.global.nc.f64 	%fd653, [%rd99+8];
	mul.rn.f64 	%fd190, %fd842, %fd842;
	fma.rn.f64 	%fd654, %fd652, %fd190, %fd653;
	ld.global.nc.f64 	%fd655, [%rd99+16];
	fma.rn.f64 	%fd656, %fd654, %fd190, %fd655;
	ld.global.nc.f64 	%fd657, [%rd99+24];
	fma.rn.f64 	%fd658, %fd656, %fd190, %fd657;
	ld.global.nc.f64 	%fd659, [%rd99+32];
	fma.rn.f64 	%fd660, %fd658, %fd190, %fd659;
	ld.global.nc.f64 	%fd661, [%rd99+40];
	fma.rn.f64 	%fd662, %fd660, %fd190, %fd661;
	ld.global.nc.f64 	%fd663, [%rd99+48];
	fma.rn.f64 	%fd191, %fd662, %fd190, %fd663;
	fma.rn.f64 	%fd844, %fd191, %fd842, %fd842;
	@%p137 bra 	$L__BB14_138;

	mov.f64 	%fd664, 0d3FF0000000000000;
	fma.rn.f64 	%fd844, %fd191, %fd190, %fd664;

$L__BB14_138:
	and.b32  	%r224, %r302, 2;
	setp.eq.s32 	%p138, %r224, 0;
	@%p138 bra 	$L__BB14_140;

	mov.f64 	%fd665, 0d0000000000000000;
	mov.f64 	%fd666, 0dBFF0000000000000;
	fma.rn.f64 	%fd844, %fd844, %fd666, %fd665;

$L__BB14_140:
	mul.rn.f64 	%fd667, %fd844, 0d4062C00000000000;
	add.rn.f64 	%fd197, %fd184, %fd667;
	div.rn.f64 	%fd198, %fd84, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r225, %temp}, %fd198;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r226}, %fd198;
	}
	and.b32  	%r227, %r226, 2147483647;
	setp.eq.s32 	%p139, %r227, 2146435072;
	setp.eq.s32 	%p140, %r225, 0;
	and.pred  	%p141, %p140, %p139;
	@%p141 bra 	$L__BB14_143;
	bra.uni 	$L__BB14_141;

$L__BB14_143:
	mov.f64 	%fd677, 0d0000000000000000;
	mul.rn.f64 	%fd845, %fd198, %fd677;
	mov.u32 	%r303, 0;
	bra.uni 	$L__BB14_144;

$L__BB14_141:
	mul.rn.f64 	%fd668, %fd198, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r303, %fd668;
	st.local.u32 	[%rd1], %r303;
	cvt.rn.f64.s32 	%fd669, %r303;
	neg.f64 	%fd670, %fd669;
	mov.f64 	%fd671, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd672, %fd670, %fd671, %fd198;
	mov.f64 	%fd673, 0d3C91A62633145C00;
	fma.rn.f64 	%fd674, %fd670, %fd673, %fd672;
	mov.f64 	%fd675, 0d397B839A252049C0;
	fma.rn.f64 	%fd845, %fd670, %fd675, %fd674;
	abs.f64 	%fd676, %fd198;
	setp.ltu.f64 	%p142, %fd676, 0d41E0000000000000;
	@%p142 bra 	$L__BB14_144;

	{ // callseq 183, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd198;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd845, [retval0+0];
	} // callseq 183
	ld.local.u32 	%r303, [%rd1];

$L__BB14_144:
	and.b32  	%r229, %r303, 1;
	shl.b32 	%r230, %r303, 3;
	and.b32  	%r231, %r230, 8;
	setp.eq.s32 	%p143, %r229, 0;
	selp.f64 	%fd678, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p143;
	mul.wide.s32 	%rd101, %r231, 8;
	add.s64 	%rd103, %rd50, %rd101;
	ld.global.nc.f64 	%fd679, [%rd103+8];
	mul.rn.f64 	%fd203, %fd845, %fd845;
	fma.rn.f64 	%fd680, %fd678, %fd203, %fd679;
	ld.global.nc.f64 	%fd681, [%rd103+16];
	fma.rn.f64 	%fd682, %fd680, %fd203, %fd681;
	ld.global.nc.f64 	%fd683, [%rd103+24];
	fma.rn.f64 	%fd684, %fd682, %fd203, %fd683;
	ld.global.nc.f64 	%fd685, [%rd103+32];
	fma.rn.f64 	%fd686, %fd684, %fd203, %fd685;
	ld.global.nc.f64 	%fd687, [%rd103+40];
	fma.rn.f64 	%fd688, %fd686, %fd203, %fd687;
	ld.global.nc.f64 	%fd689, [%rd103+48];
	fma.rn.f64 	%fd204, %fd688, %fd203, %fd689;
	fma.rn.f64 	%fd847, %fd204, %fd845, %fd845;
	@%p143 bra 	$L__BB14_146;

	mov.f64 	%fd690, 0d3FF0000000000000;
	fma.rn.f64 	%fd847, %fd204, %fd203, %fd690;

$L__BB14_146:
	and.b32  	%r232, %r303, 2;
	setp.eq.s32 	%p144, %r232, 0;
	@%p144 bra 	$L__BB14_148;

	mov.f64 	%fd691, 0d0000000000000000;
	mov.f64 	%fd692, 0dBFF0000000000000;
	fma.rn.f64 	%fd847, %fd847, %fd692, %fd691;

$L__BB14_148:
	mul.rn.f64 	%fd693, %fd847, 0d4072C00000000000;
	add.rn.f64 	%fd694, %fd197, %fd693;
	add.rn.f64 	%fd210, %fd110, %fd694;
	add.rn.f64 	%fd211, %fd110, %fd160;
	add.rn.f64 	%fd695, %fd80, %fd80;
	add.rn.f64 	%fd696, %fd695, 0dC059000000000000;
	mul.rn.f64 	%fd697, %fd81, 0d4008000000000000;
	add.rn.f64 	%fd212, %fd697, %fd696;
	abs.f64 	%fd213, %fd81;
	{ // callseq 184, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd213;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 184
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd81;
	}
	setp.lt.s32 	%p145, %r54, 0;
	and.pred  	%p4, %p145, %p8;
	not.pred 	%p147, %p4;
	@%p147 bra 	$L__BB14_150;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r233}, %fd850;
	}
	xor.b32  	%r234, %r233, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd850;
	}
	mov.b64 	%fd850, {%r235, %r234};

$L__BB14_150:
	setp.eq.f64 	%p148, %fd81, 0d0000000000000000;
	@%p148 bra 	$L__BB14_154;
	bra.uni 	$L__BB14_151;

$L__BB14_154:
	selp.b32 	%r236, %r54, 0, %p8;
	mov.u32 	%r237, 0;
	or.b32  	%r238, %r236, 2146435072;
	setp.lt.s32 	%p152, %r3, 0;
	selp.b32 	%r239, %r238, %r236, %p152;
	mov.b64 	%fd850, {%r237, %r239};
	bra.uni 	$L__BB14_155;

$L__BB14_151:
	setp.gt.s32 	%p149, %r54, -1;
	@%p149 bra 	$L__BB14_155;

	mov.f64 	%fd698, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd699, %fd698;
	setp.eq.f64 	%p150, %fd699, 0d4000000000000000;
	@%p150 bra 	$L__BB14_155;

	mov.f64 	%fd850, 0dFFF8000000000000;

$L__BB14_155:
	add.rn.f64 	%fd701, %fd81, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %fd701;
	}
	and.b32  	%r241, %r240, 2146435072;
	setp.ne.s32 	%p153, %r241, 2146435072;
	@%p153 bra 	$L__BB14_162;

	setp.gtu.f64 	%p154, %fd213, 0d7FF0000000000000;
	@%p154 bra 	$L__BB14_161;
	bra.uni 	$L__BB14_157;

$L__BB14_161:
	mov.f64 	%fd703, 0d4000000000000000;
	add.rn.f64 	%fd850, %fd81, %fd703;
	bra.uni 	$L__BB14_162;

$L__BB14_157:
	mov.f64 	%fd702, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd702;
	}
	and.b32  	%r55, %r3, 2147483647;
	setp.eq.s32 	%p155, %r55, 2146435072;
	setp.eq.s32 	%p156, %r242, 0;
	and.pred  	%p157, %p155, %p156;
	@%p157 bra 	$L__BB14_160;
	bra.uni 	$L__BB14_158;

$L__BB14_160:
	setp.gt.f64 	%p164, %fd213, 0d3FF0000000000000;
	selp.b32 	%r249, 2146435072, 0, %p164;
	mov.u32 	%r250, 0;
	xor.b32  	%r251, %r249, 2146435072;
	setp.lt.s32 	%p165, %r3, 0;
	selp.b32 	%r252, %r251, %r249, %p165;
	setp.eq.f64 	%p166, %fd81, 0dBFF0000000000000;
	selp.b32 	%r253, 1072693248, %r252, %p166;
	mov.b64 	%fd850, {%r250, %r253};
	bra.uni 	$L__BB14_162;

$L__BB14_158:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd81;
	}
	and.b32  	%r244, %r54, 2147483647;
	setp.ne.s32 	%p158, %r244, 2146435072;
	setp.ne.s32 	%p159, %r243, 0;
	or.pred  	%p160, %p158, %p159;
	@%p160 bra 	$L__BB14_162;

	setp.gt.s32 	%p161, %r3, -1;
	selp.b32 	%r245, 2146435072, 0, %p161;
	mov.u32 	%r246, 0;
	setp.ne.s32 	%p162, %r55, 1071644672;
	and.pred  	%p163, %p162, %p4;
	or.b32  	%r247, %r245, -2147483648;
	selp.b32 	%r248, %r247, %r245, %p163;
	mov.b64 	%fd850, {%r246, %r248};

$L__BB14_162:
	mul.rn.f64 	%fd704, %fd850, 0d3FC999999999999A;
	setp.eq.f64 	%p167, %fd81, 0d3FF0000000000000;
	selp.f64 	%fd705, 0d3FC999999999999A, %fd704, %p167;
	add.rn.f64 	%fd706, %fd212, %fd705;
	mul.rn.f64 	%fd707, %fd81, %fd80;
	mul.rn.f64 	%fd223, %fd707, 0d3FB999999999999A;
	add.rn.f64 	%fd708, %fd223, %fd706;
	mul.rn.f64 	%fd709, %fd83, 0d3FC999999999999A;
	add.rn.f64 	%fd710, %fd709, %fd708;
	mul.rn.f64 	%fd711, %fd211, 0d3FE5555555555555;
	add.rn.f64 	%fd224, %fd711, %fd710;
	add.rn.f64 	%fd712, %fd81, %fd81;
	add.rn.f64 	%fd713, %fd80, 0d4072C00000000000;
	add.rn.f64 	%fd225, %fd712, %fd713;
	{ // callseq 185, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd853, [retval0+0];
	} // callseq 185
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd80;
	}
	setp.lt.s32 	%p168, %r56, 0;
	and.pred  	%p5, %p168, %p8;
	not.pred 	%p170, %p5;
	@%p170 bra 	$L__BB14_164;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r254}, %fd853;
	}
	xor.b32  	%r255, %r254, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r256, %temp}, %fd853;
	}
	mov.b64 	%fd853, {%r256, %r255};

$L__BB14_164:
	setp.eq.f64 	%p171, %fd80, 0d0000000000000000;
	@%p171 bra 	$L__BB14_168;
	bra.uni 	$L__BB14_165;

$L__BB14_168:
	selp.b32 	%r257, %r56, 0, %p8;
	mov.u32 	%r258, 0;
	or.b32  	%r259, %r257, 2146435072;
	setp.lt.s32 	%p175, %r3, 0;
	selp.b32 	%r260, %r259, %r257, %p175;
	mov.b64 	%fd853, {%r258, %r260};
	bra.uni 	$L__BB14_169;

$L__BB14_165:
	setp.gt.s32 	%p172, %r56, -1;
	@%p172 bra 	$L__BB14_169;

	mov.f64 	%fd714, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd715, %fd714;
	setp.eq.f64 	%p173, %fd715, 0d4000000000000000;
	@%p173 bra 	$L__BB14_169;

	mov.f64 	%fd853, 0dFFF8000000000000;

$L__BB14_169:
	add.rn.f64 	%fd717, %fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r261}, %fd717;
	}
	and.b32  	%r262, %r261, 2146435072;
	setp.ne.s32 	%p176, %r262, 2146435072;
	@%p176 bra 	$L__BB14_176;

	setp.gtu.f64 	%p177, %fd82, 0d7FF0000000000000;
	@%p177 bra 	$L__BB14_175;
	bra.uni 	$L__BB14_171;

$L__BB14_175:
	mov.f64 	%fd719, 0d4000000000000000;
	add.rn.f64 	%fd853, %fd80, %fd719;
	bra.uni 	$L__BB14_176;

$L__BB14_171:
	mov.f64 	%fd718, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd718;
	}
	and.b32  	%r57, %r3, 2147483647;
	setp.eq.s32 	%p178, %r57, 2146435072;
	setp.eq.s32 	%p179, %r263, 0;
	and.pred  	%p180, %p178, %p179;
	@%p180 bra 	$L__BB14_174;
	bra.uni 	$L__BB14_172;

$L__BB14_174:
	setp.gt.f64 	%p187, %fd82, 0d3FF0000000000000;
	selp.b32 	%r270, 2146435072, 0, %p187;
	mov.u32 	%r271, 0;
	xor.b32  	%r272, %r270, 2146435072;
	setp.lt.s32 	%p188, %r3, 0;
	selp.b32 	%r273, %r272, %r270, %p188;
	setp.eq.f64 	%p189, %fd80, 0dBFF0000000000000;
	selp.b32 	%r274, 1072693248, %r273, %p189;
	mov.b64 	%fd853, {%r271, %r274};
	bra.uni 	$L__BB14_176;

$L__BB14_172:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r264, %temp}, %fd80;
	}
	and.b32  	%r265, %r56, 2147483647;
	setp.ne.s32 	%p181, %r265, 2146435072;
	setp.ne.s32 	%p182, %r264, 0;
	or.pred  	%p183, %p181, %p182;
	@%p183 bra 	$L__BB14_176;

	setp.gt.s32 	%p184, %r3, -1;
	selp.b32 	%r266, 2146435072, 0, %p184;
	mov.u32 	%r267, 0;
	setp.ne.s32 	%p185, %r57, 1071644672;
	and.pred  	%p186, %p185, %p5;
	or.b32  	%r268, %r266, -2147483648;
	selp.b32 	%r269, %r268, %r266, %p186;
	mov.b64 	%fd853, {%r267, %r269};

$L__BB14_176:
	mul.rn.f64 	%fd720, %fd853, 0d3FB999999999999A;
	setp.eq.f64 	%p190, %fd80, 0d3FF0000000000000;
	selp.f64 	%fd721, 0d3FB999999999999A, %fd720, %p190;
	add.rn.f64 	%fd722, %fd225, %fd721;
	add.rn.f64 	%fd723, %fd223, %fd722;
	mul.rn.f64 	%fd724, %fd83, 0d3FB999999999999A;
	add.rn.f64 	%fd725, %fd724, %fd723;
	mul.rn.f64 	%fd726, %fd210, 0d3FE5555555555555;
	add.rn.f64 	%fd235, %fd726, %fd725;
	div.rn.f64 	%fd727, %fd78, 0d4066800000000000;
	mul.rn.f64 	%fd236, %fd727, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r275, %temp}, %fd236;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd236;
	}
	and.b32  	%r277, %r276, 2147483647;
	setp.eq.s32 	%p191, %r277, 2146435072;
	setp.eq.s32 	%p192, %r275, 0;
	and.pred  	%p6, %p192, %p191;
	@%p6 bra 	$L__BB14_179;
	bra.uni 	$L__BB14_177;

$L__BB14_179:
	mov.f64 	%fd737, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd236, %fd737;
	mov.u32 	%r304, 0;
	bra.uni 	$L__BB14_180;

$L__BB14_177:
	mul.rn.f64 	%fd728, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd728;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd729, %r304;
	neg.f64 	%fd730, %fd729;
	mov.f64 	%fd731, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd732, %fd730, %fd731, %fd236;
	mov.f64 	%fd733, 0d3C91A62633145C00;
	fma.rn.f64 	%fd734, %fd730, %fd733, %fd732;
	mov.f64 	%fd735, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd730, %fd735, %fd734;
	abs.f64 	%fd736, %fd236;
	setp.ltu.f64 	%p193, %fd736, 0d41E0000000000000;
	@%p193 bra 	$L__BB14_180;

	{ // callseq 186, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 186
	ld.local.u32 	%r304, [%rd1];

$L__BB14_180:
	and.b32  	%r279, %r304, 1;
	shl.b32 	%r280, %r304, 3;
	and.b32  	%r281, %r280, 8;
	setp.eq.s32 	%p194, %r279, 0;
	selp.f64 	%fd738, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p194;
	mul.wide.s32 	%rd105, %r281, 8;
	add.s64 	%rd107, %rd50, %rd105;
	ld.global.nc.f64 	%fd739, [%rd107+8];
	mul.rn.f64 	%fd241, %fd854, %fd854;
	fma.rn.f64 	%fd740, %fd738, %fd241, %fd739;
	ld.global.nc.f64 	%fd741, [%rd107+16];
	fma.rn.f64 	%fd742, %fd740, %fd241, %fd741;
	ld.global.nc.f64 	%fd743, [%rd107+24];
	fma.rn.f64 	%fd744, %fd742, %fd241, %fd743;
	ld.global.nc.f64 	%fd745, [%rd107+32];
	fma.rn.f64 	%fd746, %fd744, %fd241, %fd745;
	ld.global.nc.f64 	%fd747, [%rd107+40];
	fma.rn.f64 	%fd748, %fd746, %fd241, %fd747;
	ld.global.nc.f64 	%fd749, [%rd107+48];
	fma.rn.f64 	%fd242, %fd748, %fd241, %fd749;
	fma.rn.f64 	%fd856, %fd242, %fd854, %fd854;
	@%p194 bra 	$L__BB14_182;

	mov.f64 	%fd750, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd242, %fd241, %fd750;

$L__BB14_182:
	and.b32  	%r282, %r304, 2;
	setp.eq.s32 	%p195, %r282, 0;
	@%p195 bra 	$L__BB14_184;

	mov.f64 	%fd751, 0d0000000000000000;
	mov.f64 	%fd752, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd752, %fd751;

$L__BB14_184:
	@%p6 bra 	$L__BB14_188;
	bra.uni 	$L__BB14_185;

$L__BB14_188:
	mov.f64 	%fd762, 0d0000000000000000;
	mul.rn.f64 	%fd858, %fd236, %fd762;
	mov.u32 	%r306, 1;
	bra.uni 	$L__BB14_189;

$L__BB14_185:
	mul.rn.f64 	%fd753, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r305, %fd753;
	st.local.u32 	[%rd1], %r305;
	cvt.rn.f64.s32 	%fd754, %r305;
	neg.f64 	%fd755, %fd754;
	mov.f64 	%fd756, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd757, %fd755, %fd756, %fd236;
	mov.f64 	%fd758, 0d3C91A62633145C00;
	fma.rn.f64 	%fd759, %fd755, %fd758, %fd757;
	mov.f64 	%fd760, 0d397B839A252049C0;
	fma.rn.f64 	%fd858, %fd755, %fd760, %fd759;
	abs.f64 	%fd761, %fd236;
	setp.ltu.f64 	%p196, %fd761, 0d41E0000000000000;
	@%p196 bra 	$L__BB14_187;

	{ // callseq 187, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd24;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd858, [retval0+0];
	} // callseq 187
	ld.local.u32 	%r305, [%rd1];

$L__BB14_187:
	add.s32 	%r306, %r305, 1;

$L__BB14_189:
	and.b32  	%r284, %r306, 1;
	shl.b32 	%r285, %r306, 3;
	and.b32  	%r286, %r285, 8;
	setp.eq.s32 	%p197, %r284, 0;
	selp.f64 	%fd763, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p197;
	mul.wide.s32 	%rd109, %r286, 8;
	add.s64 	%rd111, %rd50, %rd109;
	ld.global.nc.f64 	%fd764, [%rd111+8];
	mul.rn.f64 	%fd253, %fd858, %fd858;
	fma.rn.f64 	%fd765, %fd763, %fd253, %fd764;
	ld.global.nc.f64 	%fd766, [%rd111+16];
	fma.rn.f64 	%fd767, %fd765, %fd253, %fd766;
	ld.global.nc.f64 	%fd768, [%rd111+24];
	fma.rn.f64 	%fd769, %fd767, %fd253, %fd768;
	ld.global.nc.f64 	%fd770, [%rd111+32];
	fma.rn.f64 	%fd771, %fd769, %fd253, %fd770;
	ld.global.nc.f64 	%fd772, [%rd111+40];
	fma.rn.f64 	%fd773, %fd771, %fd253, %fd772;
	ld.global.nc.f64 	%fd774, [%rd111+48];
	fma.rn.f64 	%fd254, %fd773, %fd253, %fd774;
	fma.rn.f64 	%fd860, %fd254, %fd858, %fd858;
	@%p197 bra 	$L__BB14_191;

	mov.f64 	%fd775, 0d3FF0000000000000;
	fma.rn.f64 	%fd860, %fd254, %fd253, %fd775;

$L__BB14_191:
	and.b32  	%r287, %r306, 2;
	setp.eq.s32 	%p198, %r287, 0;
	@%p198 bra 	$L__BB14_193;

	mov.f64 	%fd776, 0d0000000000000000;
	mov.f64 	%fd777, 0dBFF0000000000000;
	fma.rn.f64 	%fd860, %fd860, %fd777, %fd776;

$L__BB14_193:
	mul.rn.f64 	%fd778, %fd856, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd779, %fd856, %fd778;
	add.rn.f64 	%fd780, %fd779, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd781, %fd780;
	mov.f64 	%fd782, 0dC15854C140000000;
	div.rn.f64 	%fd783, %fd782, %fd781;
	mul.rn.f64 	%fd784, %fd783, %fd860;
	mul.rn.f64 	%fd785, %fd784, 0d400921FB54442D18;
	mul.rn.f64 	%fd786, %fd235, 0d4066800000000000;
	div.rn.f64 	%fd787, %fd786, %fd785;
	add.rn.f64 	%fd788, %fd79, %fd787;
	st.global.f64 	[%rd18], %fd788;
	mul.rn.f64 	%fd789, %fd224, 0d4066800000000000;
	mul.rn.f64 	%fd790, %fd781, %fd780;
	mov.f64 	%fd791, 0dC1582B102DE355C1;
	div.rn.f64 	%fd792, %fd791, %fd790;
	mul.rn.f64 	%fd793, %fd792, 0d400921FB54442D18;
	div.rn.f64 	%fd794, %fd789, %fd793;
	add.rn.f64 	%fd795, %fd78, %fd794;
	st.global.f64 	[%rd19], %fd795;

$L__BB14_194:
	ret;

}
	// .globl	gcj02_to_wgs84_exact_cuda_double
.visible .entry gcj02_to_wgs84_exact_cuda_double(
	.param .u32 gcj02_to_wgs84_exact_cuda_double_param_0,
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_1,
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_2,
	.param .f64 gcj02_to_wgs84_exact_cuda_double_param_3,
	.param .u8 gcj02_to_wgs84_exact_cuda_double_param_4,
	.param .u32 gcj02_to_wgs84_exact_cuda_double_param_5,
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_6,
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_7
)
{
	.local .align 4 .b8 	__local_depot15[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<322>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<512>;
	.reg .f64 	%fd<1482>;
	.reg .b64 	%rd<190>;


	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r110, [gcj02_to_wgs84_exact_cuda_double_param_0];
	ld.param.u64 	%rd31, [gcj02_to_wgs84_exact_cuda_double_param_1];
	ld.param.u64 	%rd32, [gcj02_to_wgs84_exact_cuda_double_param_2];
	ld.param.f64 	%fd453, [gcj02_to_wgs84_exact_cuda_double_param_3];
	add.u64 	%rd35, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r111, %ntid.x;
	mov.u32 	%r112, %ctaid.x;
	mov.u32 	%r113, %tid.x;
	mad.lo.s32 	%r1, %r112, %r111, %r113;
	setp.ge.s32 	%p9, %r1, %r110;
	@%p9 bra 	$L__BB15_326;

	cvta.to.global.u64 	%rd63, %rd31;
	mul.wide.s32 	%rd64, %r1, 8;
	add.s64 	%rd65, %rd63, %rd64;
	cvta.to.global.u64 	%rd66, %rd32;
	add.s64 	%rd67, %rd66, %rd64;
	ld.global.f64 	%fd1, [%rd65];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd67];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r115}, %fd9;
	}
	and.b32  	%r116, %r115, 2147483647;
	setp.eq.s32 	%p10, %r116, 2146435072;
	setp.eq.s32 	%p11, %r114, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB15_4;
	bra.uni 	$L__BB15_2;

$L__BB15_4:
	mov.f64 	%fd463, 0d0000000000000000;
	mul.rn.f64 	%fd1371, %fd9, %fd463;
	mov.u32 	%r479, 0;
	bra.uni 	$L__BB15_5;

$L__BB15_2:
	mul.rn.f64 	%fd454, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r479, %fd454;
	st.local.u32 	[%rd1], %r479;
	cvt.rn.f64.s32 	%fd455, %r479;
	neg.f64 	%fd456, %fd455;
	mov.f64 	%fd457, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd458, %fd456, %fd457, %fd9;
	mov.f64 	%fd459, 0d3C91A62633145C00;
	fma.rn.f64 	%fd460, %fd456, %fd459, %fd458;
	mov.f64 	%fd461, 0d397B839A252049C0;
	fma.rn.f64 	%fd1371, %fd456, %fd461, %fd460;
	abs.f64 	%fd462, %fd9;
	setp.ltu.f64 	%p13, %fd462, 0d41E0000000000000;
	@%p13 bra 	$L__BB15_5;

	{ // callseq 188, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1371, [retval0+0];
	} // callseq 188
	ld.local.u32 	%r479, [%rd1];

$L__BB15_5:
	and.b32  	%r118, %r479, 1;
	shl.b32 	%r119, %r479, 3;
	and.b32  	%r120, %r119, 8;
	setp.eq.s32 	%p14, %r118, 0;
	selp.f64 	%fd464, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd71, %r120, 8;
	mov.u64 	%rd72, __cudart_sin_cos_coeffs;
	add.s64 	%rd73, %rd72, %rd71;
	ld.global.nc.f64 	%fd465, [%rd73+8];
	mul.rn.f64 	%fd14, %fd1371, %fd1371;
	fma.rn.f64 	%fd466, %fd464, %fd14, %fd465;
	ld.global.nc.f64 	%fd467, [%rd73+16];
	fma.rn.f64 	%fd468, %fd466, %fd14, %fd467;
	ld.global.nc.f64 	%fd469, [%rd73+24];
	fma.rn.f64 	%fd470, %fd468, %fd14, %fd469;
	ld.global.nc.f64 	%fd471, [%rd73+32];
	fma.rn.f64 	%fd472, %fd470, %fd14, %fd471;
	ld.global.nc.f64 	%fd473, [%rd73+40];
	fma.rn.f64 	%fd474, %fd472, %fd14, %fd473;
	ld.global.nc.f64 	%fd475, [%rd73+48];
	fma.rn.f64 	%fd15, %fd474, %fd14, %fd475;
	fma.rn.f64 	%fd1373, %fd15, %fd1371, %fd1371;
	@%p14 bra 	$L__BB15_7;

	mov.f64 	%fd476, 0d3FF0000000000000;
	fma.rn.f64 	%fd1373, %fd15, %fd14, %fd476;

$L__BB15_7:
	and.b32  	%r121, %r479, 2;
	setp.eq.s32 	%p15, %r121, 0;
	@%p15 bra 	$L__BB15_9;

	mov.f64 	%fd477, 0d0000000000000000;
	mov.f64 	%fd478, 0dBFF0000000000000;
	fma.rn.f64 	%fd1373, %fd1373, %fd478, %fd477;

$L__BB15_9:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r122, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r123}, %fd21;
	}
	and.b32  	%r124, %r123, 2147483647;
	setp.eq.s32 	%p16, %r124, 2146435072;
	setp.eq.s32 	%p17, %r122, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB15_12;
	bra.uni 	$L__BB15_10;

$L__BB15_12:
	mov.f64 	%fd488, 0d0000000000000000;
	mul.rn.f64 	%fd1374, %fd21, %fd488;
	mov.u32 	%r480, 0;
	bra.uni 	$L__BB15_13;

$L__BB15_10:
	mul.rn.f64 	%fd479, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r480, %fd479;
	st.local.u32 	[%rd1], %r480;
	cvt.rn.f64.s32 	%fd480, %r480;
	neg.f64 	%fd481, %fd480;
	mov.f64 	%fd482, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd483, %fd481, %fd482, %fd21;
	mov.f64 	%fd484, 0d3C91A62633145C00;
	fma.rn.f64 	%fd485, %fd481, %fd484, %fd483;
	mov.f64 	%fd486, 0d397B839A252049C0;
	fma.rn.f64 	%fd1374, %fd481, %fd486, %fd485;
	abs.f64 	%fd487, %fd21;
	setp.ltu.f64 	%p19, %fd487, 0d41E0000000000000;
	@%p19 bra 	$L__BB15_13;

	{ // callseq 189, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1374, [retval0+0];
	} // callseq 189
	ld.local.u32 	%r480, [%rd1];

$L__BB15_13:
	and.b32  	%r126, %r480, 1;
	shl.b32 	%r127, %r480, 3;
	and.b32  	%r128, %r127, 8;
	setp.eq.s32 	%p20, %r126, 0;
	selp.f64 	%fd489, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd75, %r128, 8;
	add.s64 	%rd77, %rd72, %rd75;
	ld.global.nc.f64 	%fd490, [%rd77+8];
	mul.rn.f64 	%fd26, %fd1374, %fd1374;
	fma.rn.f64 	%fd491, %fd489, %fd26, %fd490;
	ld.global.nc.f64 	%fd492, [%rd77+16];
	fma.rn.f64 	%fd493, %fd491, %fd26, %fd492;
	ld.global.nc.f64 	%fd494, [%rd77+24];
	fma.rn.f64 	%fd495, %fd493, %fd26, %fd494;
	ld.global.nc.f64 	%fd496, [%rd77+32];
	fma.rn.f64 	%fd497, %fd495, %fd26, %fd496;
	ld.global.nc.f64 	%fd498, [%rd77+40];
	fma.rn.f64 	%fd499, %fd497, %fd26, %fd498;
	ld.global.nc.f64 	%fd500, [%rd77+48];
	fma.rn.f64 	%fd27, %fd499, %fd26, %fd500;
	fma.rn.f64 	%fd1376, %fd27, %fd1374, %fd1374;
	@%p20 bra 	$L__BB15_15;

	mov.f64 	%fd501, 0d3FF0000000000000;
	fma.rn.f64 	%fd1376, %fd27, %fd26, %fd501;

$L__BB15_15:
	and.b32  	%r129, %r480, 2;
	setp.eq.s32 	%p21, %r129, 0;
	@%p21 bra 	$L__BB15_17;

	mov.f64 	%fd502, 0d0000000000000000;
	mov.f64 	%fd503, 0dBFF0000000000000;
	fma.rn.f64 	%fd1376, %fd1376, %fd503, %fd502;

$L__BB15_17:
	mul.rn.f64 	%fd504, %fd1376, 0d4034000000000000;
	mul.rn.f64 	%fd505, %fd1373, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd505, %fd504;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd8;
	}
	and.b32  	%r131, %r130, 2147483647;
	setp.eq.s32 	%p22, %r131, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd8;
	}
	setp.eq.s32 	%p23, %r132, 0;
	and.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB15_20;
	bra.uni 	$L__BB15_18;

$L__BB15_20:
	mov.f64 	%fd515, 0d0000000000000000;
	mul.rn.f64 	%fd1377, %fd8, %fd515;
	mov.u32 	%r481, 0;
	bra.uni 	$L__BB15_21;

$L__BB15_18:
	mul.rn.f64 	%fd506, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r481, %fd506;
	st.local.u32 	[%rd1], %r481;
	cvt.rn.f64.s32 	%fd507, %r481;
	neg.f64 	%fd508, %fd507;
	mov.f64 	%fd509, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd510, %fd508, %fd509, %fd8;
	mov.f64 	%fd511, 0d3C91A62633145C00;
	fma.rn.f64 	%fd512, %fd508, %fd511, %fd510;
	mov.f64 	%fd513, 0d397B839A252049C0;
	fma.rn.f64 	%fd1377, %fd508, %fd513, %fd512;
	abs.f64 	%fd514, %fd8;
	setp.ltu.f64 	%p25, %fd514, 0d41E0000000000000;
	@%p25 bra 	$L__BB15_21;

	{ // callseq 190, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1377, [retval0+0];
	} // callseq 190
	ld.local.u32 	%r481, [%rd1];

$L__BB15_21:
	and.b32  	%r134, %r481, 1;
	shl.b32 	%r135, %r481, 3;
	and.b32  	%r136, %r135, 8;
	setp.eq.s32 	%p26, %r134, 0;
	selp.f64 	%fd516, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	mul.wide.s32 	%rd79, %r136, 8;
	add.s64 	%rd81, %rd72, %rd79;
	ld.global.nc.f64 	%fd517, [%rd81+8];
	mul.rn.f64 	%fd38, %fd1377, %fd1377;
	fma.rn.f64 	%fd518, %fd516, %fd38, %fd517;
	ld.global.nc.f64 	%fd519, [%rd81+16];
	fma.rn.f64 	%fd520, %fd518, %fd38, %fd519;
	ld.global.nc.f64 	%fd521, [%rd81+24];
	fma.rn.f64 	%fd522, %fd520, %fd38, %fd521;
	ld.global.nc.f64 	%fd523, [%rd81+32];
	fma.rn.f64 	%fd524, %fd522, %fd38, %fd523;
	ld.global.nc.f64 	%fd525, [%rd81+40];
	fma.rn.f64 	%fd526, %fd524, %fd38, %fd525;
	ld.global.nc.f64 	%fd527, [%rd81+48];
	fma.rn.f64 	%fd39, %fd526, %fd38, %fd527;
	fma.rn.f64 	%fd1379, %fd39, %fd1377, %fd1377;
	@%p26 bra 	$L__BB15_23;

	mov.f64 	%fd528, 0d3FF0000000000000;
	fma.rn.f64 	%fd1379, %fd39, %fd38, %fd528;

$L__BB15_23:
	and.b32  	%r137, %r481, 2;
	setp.eq.s32 	%p27, %r137, 0;
	@%p27 bra 	$L__BB15_25;

	mov.f64 	%fd529, 0d0000000000000000;
	mov.f64 	%fd530, 0dBFF0000000000000;
	fma.rn.f64 	%fd1379, %fd1379, %fd530, %fd529;

$L__BB15_25:
	add.rn.f64 	%fd1370, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1369, %fd1370, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd1369, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r139}, %fd45;
	}
	and.b32  	%r140, %r139, 2147483647;
	setp.eq.s32 	%p28, %r140, 2146435072;
	setp.eq.s32 	%p29, %r138, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB15_28;
	bra.uni 	$L__BB15_26;

$L__BB15_28:
	mov.f64 	%fd540, 0d0000000000000000;
	mul.rn.f64 	%fd1380, %fd45, %fd540;
	mov.u32 	%r482, 0;
	bra.uni 	$L__BB15_29;

$L__BB15_26:
	mul.rn.f64 	%fd531, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r482, %fd531;
	st.local.u32 	[%rd1], %r482;
	cvt.rn.f64.s32 	%fd532, %r482;
	neg.f64 	%fd533, %fd532;
	mov.f64 	%fd534, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd535, %fd533, %fd534, %fd45;
	mov.f64 	%fd536, 0d3C91A62633145C00;
	fma.rn.f64 	%fd537, %fd533, %fd536, %fd535;
	mov.f64 	%fd538, 0d397B839A252049C0;
	fma.rn.f64 	%fd1380, %fd533, %fd538, %fd537;
	abs.f64 	%fd539, %fd45;
	setp.ltu.f64 	%p31, %fd539, 0d41E0000000000000;
	@%p31 bra 	$L__BB15_29;

	{ // callseq 191, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1380, [retval0+0];
	} // callseq 191
	ld.local.u32 	%r482, [%rd1];

$L__BB15_29:
	and.b32  	%r142, %r482, 1;
	shl.b32 	%r143, %r482, 3;
	and.b32  	%r144, %r143, 8;
	setp.eq.s32 	%p32, %r142, 0;
	selp.f64 	%fd541, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd83, %r144, 8;
	add.s64 	%rd85, %rd72, %rd83;
	ld.global.nc.f64 	%fd542, [%rd85+8];
	mul.rn.f64 	%fd50, %fd1380, %fd1380;
	fma.rn.f64 	%fd543, %fd541, %fd50, %fd542;
	ld.global.nc.f64 	%fd544, [%rd85+16];
	fma.rn.f64 	%fd545, %fd543, %fd50, %fd544;
	ld.global.nc.f64 	%fd546, [%rd85+24];
	fma.rn.f64 	%fd547, %fd545, %fd50, %fd546;
	ld.global.nc.f64 	%fd548, [%rd85+32];
	fma.rn.f64 	%fd549, %fd547, %fd50, %fd548;
	ld.global.nc.f64 	%fd550, [%rd85+40];
	fma.rn.f64 	%fd551, %fd549, %fd50, %fd550;
	ld.global.nc.f64 	%fd552, [%rd85+48];
	fma.rn.f64 	%fd51, %fd551, %fd50, %fd552;
	fma.rn.f64 	%fd1382, %fd51, %fd1380, %fd1380;
	@%p32 bra 	$L__BB15_31;

	mov.f64 	%fd553, 0d3FF0000000000000;
	fma.rn.f64 	%fd1382, %fd51, %fd50, %fd553;

$L__BB15_31:
	and.b32  	%r145, %r482, 2;
	setp.eq.s32 	%p33, %r145, 0;
	@%p33 bra 	$L__BB15_33;

	mov.f64 	%fd554, 0d0000000000000000;
	mov.f64 	%fd555, 0dBFF0000000000000;
	fma.rn.f64 	%fd1382, %fd1382, %fd555, %fd554;

$L__BB15_33:
	add.rn.f64 	%fd1366, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1365, %fd1366, 0d400921FB54442D18;
	mul.rn.f64 	%fd556, %fd1382, 0d4044000000000000;
	mul.rn.f64 	%fd557, %fd1379, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd557, %fd556;
	div.rn.f64 	%fd58, %fd1365, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r146, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r147}, %fd58;
	}
	and.b32  	%r148, %r147, 2147483647;
	setp.eq.s32 	%p34, %r148, 2146435072;
	setp.eq.s32 	%p35, %r146, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB15_36;
	bra.uni 	$L__BB15_34;

$L__BB15_36:
	mov.f64 	%fd567, 0d0000000000000000;
	mul.rn.f64 	%fd1383, %fd58, %fd567;
	mov.u32 	%r483, 0;
	bra.uni 	$L__BB15_37;

$L__BB15_34:
	mul.rn.f64 	%fd558, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r483, %fd558;
	st.local.u32 	[%rd1], %r483;
	cvt.rn.f64.s32 	%fd559, %r483;
	neg.f64 	%fd560, %fd559;
	mov.f64 	%fd561, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd562, %fd560, %fd561, %fd58;
	mov.f64 	%fd563, 0d3C91A62633145C00;
	fma.rn.f64 	%fd564, %fd560, %fd563, %fd562;
	mov.f64 	%fd565, 0d397B839A252049C0;
	fma.rn.f64 	%fd1383, %fd560, %fd565, %fd564;
	abs.f64 	%fd566, %fd58;
	setp.ltu.f64 	%p37, %fd566, 0d41E0000000000000;
	@%p37 bra 	$L__BB15_37;

	{ // callseq 192, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1383, [retval0+0];
	} // callseq 192
	ld.local.u32 	%r483, [%rd1];

$L__BB15_37:
	and.b32  	%r150, %r483, 1;
	shl.b32 	%r151, %r483, 3;
	and.b32  	%r152, %r151, 8;
	setp.eq.s32 	%p38, %r150, 0;
	selp.f64 	%fd568, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd87, %r152, 8;
	add.s64 	%rd89, %rd72, %rd87;
	ld.global.nc.f64 	%fd569, [%rd89+8];
	mul.rn.f64 	%fd63, %fd1383, %fd1383;
	fma.rn.f64 	%fd570, %fd568, %fd63, %fd569;
	ld.global.nc.f64 	%fd571, [%rd89+16];
	fma.rn.f64 	%fd572, %fd570, %fd63, %fd571;
	ld.global.nc.f64 	%fd573, [%rd89+24];
	fma.rn.f64 	%fd574, %fd572, %fd63, %fd573;
	ld.global.nc.f64 	%fd575, [%rd89+32];
	fma.rn.f64 	%fd576, %fd574, %fd63, %fd575;
	ld.global.nc.f64 	%fd577, [%rd89+40];
	fma.rn.f64 	%fd578, %fd576, %fd63, %fd577;
	ld.global.nc.f64 	%fd579, [%rd89+48];
	fma.rn.f64 	%fd64, %fd578, %fd63, %fd579;
	fma.rn.f64 	%fd1385, %fd64, %fd1383, %fd1383;
	@%p38 bra 	$L__BB15_39;

	mov.f64 	%fd580, 0d3FF0000000000000;
	fma.rn.f64 	%fd1385, %fd64, %fd63, %fd580;

$L__BB15_39:
	and.b32  	%r153, %r483, 2;
	setp.eq.s32 	%p39, %r153, 0;
	@%p39 bra 	$L__BB15_41;

	mov.f64 	%fd581, 0d0000000000000000;
	mov.f64 	%fd582, 0dBFF0000000000000;
	fma.rn.f64 	%fd1385, %fd1385, %fd582, %fd581;

$L__BB15_41:
	add.rn.f64 	%fd1368, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1367, %fd1368, 0d400921FB54442D18;
	mul.rn.f64 	%fd583, %fd1385, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd583;
	div.rn.f64 	%fd71, %fd1367, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r154, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r155}, %fd71;
	}
	and.b32  	%r156, %r155, 2147483647;
	setp.eq.s32 	%p40, %r156, 2146435072;
	setp.eq.s32 	%p41, %r154, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB15_44;
	bra.uni 	$L__BB15_42;

$L__BB15_44:
	mov.f64 	%fd593, 0d0000000000000000;
	mul.rn.f64 	%fd1386, %fd71, %fd593;
	mov.u32 	%r484, 0;
	bra.uni 	$L__BB15_45;

$L__BB15_42:
	mul.rn.f64 	%fd584, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r484, %fd584;
	st.local.u32 	[%rd1], %r484;
	cvt.rn.f64.s32 	%fd585, %r484;
	neg.f64 	%fd586, %fd585;
	mov.f64 	%fd587, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd588, %fd586, %fd587, %fd71;
	mov.f64 	%fd589, 0d3C91A62633145C00;
	fma.rn.f64 	%fd590, %fd586, %fd589, %fd588;
	mov.f64 	%fd591, 0d397B839A252049C0;
	fma.rn.f64 	%fd1386, %fd586, %fd591, %fd590;
	abs.f64 	%fd592, %fd71;
	setp.ltu.f64 	%p43, %fd592, 0d41E0000000000000;
	@%p43 bra 	$L__BB15_45;

	{ // callseq 193, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1386, [retval0+0];
	} // callseq 193
	ld.local.u32 	%r484, [%rd1];

$L__BB15_45:
	and.b32  	%r158, %r484, 1;
	shl.b32 	%r159, %r484, 3;
	and.b32  	%r160, %r159, 8;
	setp.eq.s32 	%p44, %r158, 0;
	selp.f64 	%fd594, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd91, %r160, 8;
	add.s64 	%rd93, %rd72, %rd91;
	ld.global.nc.f64 	%fd595, [%rd93+8];
	mul.rn.f64 	%fd76, %fd1386, %fd1386;
	fma.rn.f64 	%fd596, %fd594, %fd76, %fd595;
	ld.global.nc.f64 	%fd597, [%rd93+16];
	fma.rn.f64 	%fd598, %fd596, %fd76, %fd597;
	ld.global.nc.f64 	%fd599, [%rd93+24];
	fma.rn.f64 	%fd600, %fd598, %fd76, %fd599;
	ld.global.nc.f64 	%fd601, [%rd93+32];
	fma.rn.f64 	%fd602, %fd600, %fd76, %fd601;
	ld.global.nc.f64 	%fd603, [%rd93+40];
	fma.rn.f64 	%fd604, %fd602, %fd76, %fd603;
	ld.global.nc.f64 	%fd605, [%rd93+48];
	fma.rn.f64 	%fd77, %fd604, %fd76, %fd605;
	fma.rn.f64 	%fd1388, %fd77, %fd1386, %fd1386;
	@%p44 bra 	$L__BB15_47;

	mov.f64 	%fd606, 0d3FF0000000000000;
	fma.rn.f64 	%fd1388, %fd77, %fd76, %fd606;

$L__BB15_47:
	and.b32  	%r161, %r484, 2;
	setp.eq.s32 	%p45, %r161, 0;
	@%p45 bra 	$L__BB15_49;

	mov.f64 	%fd607, 0d0000000000000000;
	mov.f64 	%fd608, 0dBFF0000000000000;
	fma.rn.f64 	%fd1388, %fd1388, %fd608, %fd607;

$L__BB15_49:
	mul.rn.f64 	%fd609, %fd1388, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd609;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd7;
	}
	and.b32  	%r163, %r162, 2147483647;
	setp.eq.s32 	%p46, %r163, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r164, %temp}, %fd7;
	}
	setp.eq.s32 	%p47, %r164, 0;
	and.pred  	%p48, %p47, %p46;
	@%p48 bra 	$L__BB15_52;
	bra.uni 	$L__BB15_50;

$L__BB15_52:
	mov.f64 	%fd619, 0d0000000000000000;
	mul.rn.f64 	%fd1389, %fd7, %fd619;
	mov.u32 	%r485, 0;
	bra.uni 	$L__BB15_53;

$L__BB15_50:
	mul.rn.f64 	%fd610, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r485, %fd610;
	st.local.u32 	[%rd1], %r485;
	cvt.rn.f64.s32 	%fd611, %r485;
	neg.f64 	%fd612, %fd611;
	mov.f64 	%fd613, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd614, %fd612, %fd613, %fd7;
	mov.f64 	%fd615, 0d3C91A62633145C00;
	fma.rn.f64 	%fd616, %fd612, %fd615, %fd614;
	mov.f64 	%fd617, 0d397B839A252049C0;
	fma.rn.f64 	%fd1389, %fd612, %fd617, %fd616;
	abs.f64 	%fd618, %fd7;
	setp.ltu.f64 	%p49, %fd618, 0d41E0000000000000;
	@%p49 bra 	$L__BB15_53;

	{ // callseq 194, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1389, [retval0+0];
	} // callseq 194
	ld.local.u32 	%r485, [%rd1];

$L__BB15_53:
	and.b32  	%r166, %r485, 1;
	shl.b32 	%r167, %r485, 3;
	and.b32  	%r168, %r167, 8;
	setp.eq.s32 	%p50, %r166, 0;
	selp.f64 	%fd620, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	mul.wide.s32 	%rd95, %r168, 8;
	add.s64 	%rd97, %rd72, %rd95;
	ld.global.nc.f64 	%fd621, [%rd97+8];
	mul.rn.f64 	%fd88, %fd1389, %fd1389;
	fma.rn.f64 	%fd622, %fd620, %fd88, %fd621;
	ld.global.nc.f64 	%fd623, [%rd97+16];
	fma.rn.f64 	%fd624, %fd622, %fd88, %fd623;
	ld.global.nc.f64 	%fd625, [%rd97+24];
	fma.rn.f64 	%fd626, %fd624, %fd88, %fd625;
	ld.global.nc.f64 	%fd627, [%rd97+32];
	fma.rn.f64 	%fd628, %fd626, %fd88, %fd627;
	ld.global.nc.f64 	%fd629, [%rd97+40];
	fma.rn.f64 	%fd630, %fd628, %fd88, %fd629;
	ld.global.nc.f64 	%fd631, [%rd97+48];
	fma.rn.f64 	%fd89, %fd630, %fd88, %fd631;
	fma.rn.f64 	%fd1391, %fd89, %fd1389, %fd1389;
	@%p50 bra 	$L__BB15_55;

	mov.f64 	%fd632, 0d3FF0000000000000;
	fma.rn.f64 	%fd1391, %fd89, %fd88, %fd632;

$L__BB15_55:
	and.b32  	%r169, %r485, 2;
	setp.eq.s32 	%p51, %r169, 0;
	@%p51 bra 	$L__BB15_57;

	mov.f64 	%fd633, 0d0000000000000000;
	mov.f64 	%fd634, 0dBFF0000000000000;
	fma.rn.f64 	%fd1391, %fd1391, %fd634, %fd633;

$L__BB15_57:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r170, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r171}, %fd95;
	}
	and.b32  	%r172, %r171, 2147483647;
	setp.eq.s32 	%p52, %r172, 2146435072;
	setp.eq.s32 	%p53, %r170, 0;
	and.pred  	%p54, %p53, %p52;
	@%p54 bra 	$L__BB15_60;
	bra.uni 	$L__BB15_58;

$L__BB15_60:
	mov.f64 	%fd644, 0d0000000000000000;
	mul.rn.f64 	%fd1392, %fd95, %fd644;
	mov.u32 	%r486, 0;
	bra.uni 	$L__BB15_61;

$L__BB15_58:
	mul.rn.f64 	%fd635, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r486, %fd635;
	st.local.u32 	[%rd1], %r486;
	cvt.rn.f64.s32 	%fd636, %r486;
	neg.f64 	%fd637, %fd636;
	mov.f64 	%fd638, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd639, %fd637, %fd638, %fd95;
	mov.f64 	%fd640, 0d3C91A62633145C00;
	fma.rn.f64 	%fd641, %fd637, %fd640, %fd639;
	mov.f64 	%fd642, 0d397B839A252049C0;
	fma.rn.f64 	%fd1392, %fd637, %fd642, %fd641;
	abs.f64 	%fd643, %fd95;
	setp.ltu.f64 	%p55, %fd643, 0d41E0000000000000;
	@%p55 bra 	$L__BB15_61;

	{ // callseq 195, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1392, [retval0+0];
	} // callseq 195
	ld.local.u32 	%r486, [%rd1];

$L__BB15_61:
	and.b32  	%r174, %r486, 1;
	shl.b32 	%r175, %r486, 3;
	and.b32  	%r176, %r175, 8;
	setp.eq.s32 	%p56, %r174, 0;
	selp.f64 	%fd645, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p56;
	mul.wide.s32 	%rd99, %r176, 8;
	add.s64 	%rd101, %rd72, %rd99;
	ld.global.nc.f64 	%fd646, [%rd101+8];
	mul.rn.f64 	%fd100, %fd1392, %fd1392;
	fma.rn.f64 	%fd647, %fd645, %fd100, %fd646;
	ld.global.nc.f64 	%fd648, [%rd101+16];
	fma.rn.f64 	%fd649, %fd647, %fd100, %fd648;
	ld.global.nc.f64 	%fd650, [%rd101+24];
	fma.rn.f64 	%fd651, %fd649, %fd100, %fd650;
	ld.global.nc.f64 	%fd652, [%rd101+32];
	fma.rn.f64 	%fd653, %fd651, %fd100, %fd652;
	ld.global.nc.f64 	%fd654, [%rd101+40];
	fma.rn.f64 	%fd655, %fd653, %fd100, %fd654;
	ld.global.nc.f64 	%fd656, [%rd101+48];
	fma.rn.f64 	%fd101, %fd655, %fd100, %fd656;
	fma.rn.f64 	%fd1394, %fd101, %fd1392, %fd1392;
	@%p56 bra 	$L__BB15_63;

	mov.f64 	%fd657, 0d3FF0000000000000;
	fma.rn.f64 	%fd1394, %fd101, %fd100, %fd657;

$L__BB15_63:
	and.b32  	%r177, %r486, 2;
	setp.eq.s32 	%p57, %r177, 0;
	@%p57 bra 	$L__BB15_65;

	mov.f64 	%fd658, 0d0000000000000000;
	mov.f64 	%fd659, 0dBFF0000000000000;
	fma.rn.f64 	%fd1394, %fd1394, %fd659, %fd658;

$L__BB15_65:
	mul.rn.f64 	%fd660, %fd1394, 0d4044000000000000;
	mul.rn.f64 	%fd661, %fd1391, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd661, %fd660;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r178, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd108;
	}
	and.b32  	%r180, %r179, 2147483647;
	setp.eq.s32 	%p58, %r180, 2146435072;
	setp.eq.s32 	%p59, %r178, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB15_68;
	bra.uni 	$L__BB15_66;

$L__BB15_68:
	mov.f64 	%fd671, 0d0000000000000000;
	mul.rn.f64 	%fd1395, %fd108, %fd671;
	mov.u32 	%r487, 0;
	bra.uni 	$L__BB15_69;

$L__BB15_66:
	mul.rn.f64 	%fd662, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r487, %fd662;
	st.local.u32 	[%rd1], %r487;
	cvt.rn.f64.s32 	%fd663, %r487;
	neg.f64 	%fd664, %fd663;
	mov.f64 	%fd665, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd666, %fd664, %fd665, %fd108;
	mov.f64 	%fd667, 0d3C91A62633145C00;
	fma.rn.f64 	%fd668, %fd664, %fd667, %fd666;
	mov.f64 	%fd669, 0d397B839A252049C0;
	fma.rn.f64 	%fd1395, %fd664, %fd669, %fd668;
	abs.f64 	%fd670, %fd108;
	setp.ltu.f64 	%p61, %fd670, 0d41E0000000000000;
	@%p61 bra 	$L__BB15_69;

	{ // callseq 196, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1395, [retval0+0];
	} // callseq 196
	ld.local.u32 	%r487, [%rd1];

$L__BB15_69:
	and.b32  	%r182, %r487, 1;
	shl.b32 	%r183, %r487, 3;
	and.b32  	%r184, %r183, 8;
	setp.eq.s32 	%p62, %r182, 0;
	selp.f64 	%fd672, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd103, %r184, 8;
	add.s64 	%rd105, %rd72, %rd103;
	ld.global.nc.f64 	%fd673, [%rd105+8];
	mul.rn.f64 	%fd113, %fd1395, %fd1395;
	fma.rn.f64 	%fd674, %fd672, %fd113, %fd673;
	ld.global.nc.f64 	%fd675, [%rd105+16];
	fma.rn.f64 	%fd676, %fd674, %fd113, %fd675;
	ld.global.nc.f64 	%fd677, [%rd105+24];
	fma.rn.f64 	%fd678, %fd676, %fd113, %fd677;
	ld.global.nc.f64 	%fd679, [%rd105+32];
	fma.rn.f64 	%fd680, %fd678, %fd113, %fd679;
	ld.global.nc.f64 	%fd681, [%rd105+40];
	fma.rn.f64 	%fd682, %fd680, %fd113, %fd681;
	ld.global.nc.f64 	%fd683, [%rd105+48];
	fma.rn.f64 	%fd114, %fd682, %fd113, %fd683;
	fma.rn.f64 	%fd1397, %fd114, %fd1395, %fd1395;
	@%p62 bra 	$L__BB15_71;

	mov.f64 	%fd684, 0d3FF0000000000000;
	fma.rn.f64 	%fd1397, %fd114, %fd113, %fd684;

$L__BB15_71:
	and.b32  	%r185, %r487, 2;
	setp.eq.s32 	%p63, %r185, 0;
	@%p63 bra 	$L__BB15_73;

	mov.f64 	%fd685, 0d0000000000000000;
	mov.f64 	%fd686, 0dBFF0000000000000;
	fma.rn.f64 	%fd1397, %fd1397, %fd686, %fd685;

$L__BB15_73:
	mul.rn.f64 	%fd687, %fd1397, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd687;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r186, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r187}, %fd121;
	}
	and.b32  	%r188, %r187, 2147483647;
	setp.eq.s32 	%p64, %r188, 2146435072;
	setp.eq.s32 	%p65, %r186, 0;
	and.pred  	%p66, %p65, %p64;
	@%p66 bra 	$L__BB15_76;
	bra.uni 	$L__BB15_74;

$L__BB15_76:
	mov.f64 	%fd697, 0d0000000000000000;
	mul.rn.f64 	%fd1398, %fd121, %fd697;
	mov.u32 	%r488, 0;
	bra.uni 	$L__BB15_77;

$L__BB15_74:
	mul.rn.f64 	%fd688, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r488, %fd688;
	st.local.u32 	[%rd1], %r488;
	cvt.rn.f64.s32 	%fd689, %r488;
	neg.f64 	%fd690, %fd689;
	mov.f64 	%fd691, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd692, %fd690, %fd691, %fd121;
	mov.f64 	%fd693, 0d3C91A62633145C00;
	fma.rn.f64 	%fd694, %fd690, %fd693, %fd692;
	mov.f64 	%fd695, 0d397B839A252049C0;
	fma.rn.f64 	%fd1398, %fd690, %fd695, %fd694;
	abs.f64 	%fd696, %fd121;
	setp.ltu.f64 	%p67, %fd696, 0d41E0000000000000;
	@%p67 bra 	$L__BB15_77;

	{ // callseq 197, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1398, [retval0+0];
	} // callseq 197
	ld.local.u32 	%r488, [%rd1];

$L__BB15_77:
	and.b32  	%r190, %r488, 1;
	shl.b32 	%r191, %r488, 3;
	and.b32  	%r192, %r191, 8;
	setp.eq.s32 	%p68, %r190, 0;
	selp.f64 	%fd698, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p68;
	mul.wide.s32 	%rd107, %r192, 8;
	add.s64 	%rd109, %rd72, %rd107;
	ld.global.nc.f64 	%fd699, [%rd109+8];
	mul.rn.f64 	%fd126, %fd1398, %fd1398;
	fma.rn.f64 	%fd700, %fd698, %fd126, %fd699;
	ld.global.nc.f64 	%fd701, [%rd109+16];
	fma.rn.f64 	%fd702, %fd700, %fd126, %fd701;
	ld.global.nc.f64 	%fd703, [%rd109+24];
	fma.rn.f64 	%fd704, %fd702, %fd126, %fd703;
	ld.global.nc.f64 	%fd705, [%rd109+32];
	fma.rn.f64 	%fd706, %fd704, %fd126, %fd705;
	ld.global.nc.f64 	%fd707, [%rd109+40];
	fma.rn.f64 	%fd708, %fd706, %fd126, %fd707;
	ld.global.nc.f64 	%fd709, [%rd109+48];
	fma.rn.f64 	%fd127, %fd708, %fd126, %fd709;
	fma.rn.f64 	%fd1400, %fd127, %fd1398, %fd1398;
	@%p68 bra 	$L__BB15_79;

	mov.f64 	%fd710, 0d3FF0000000000000;
	fma.rn.f64 	%fd1400, %fd127, %fd126, %fd710;

$L__BB15_79:
	and.b32  	%r193, %r488, 2;
	setp.eq.s32 	%p69, %r193, 0;
	@%p69 bra 	$L__BB15_81;

	mov.f64 	%fd711, 0d0000000000000000;
	mov.f64 	%fd712, 0dBFF0000000000000;
	fma.rn.f64 	%fd1400, %fd1400, %fd712, %fd711;

$L__BB15_81:
	mul.rn.f64 	%fd713, %fd1400, 0d4072C00000000000;
	add.rn.f64 	%fd714, %fd120, %fd713;
	add.rn.f64 	%fd133, %fd33, %fd714;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd715, %fd2, %fd2;
	mov.f64 	%fd716, 0d4000000000000000;
	add.rn.f64 	%fd717, %fd715, 0dC059000000000000;
	mul.rn.f64 	%fd718, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd717, %fd718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r32}, %fd716;
	}
	and.b32  	%r33, %r32, 2146435072;
	setp.eq.s32 	%p70, %r33, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 198, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1403, [retval0+0];
	} // callseq 198
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd4;
	}
	setp.lt.s32 	%p71, %r34, 0;
	and.pred  	%p1, %p71, %p70;
	not.pred 	%p72, %p1;
	@%p72 bra 	$L__BB15_83;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd1403;
	}
	xor.b32  	%r195, %r194, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r196, %temp}, %fd1403;
	}
	mov.b64 	%fd1403, {%r196, %r195};

$L__BB15_83:
	setp.eq.f64 	%p73, %fd4, 0d0000000000000000;
	@%p73 bra 	$L__BB15_87;
	bra.uni 	$L__BB15_84;

$L__BB15_87:
	selp.b32 	%r197, %r34, 0, %p70;
	mov.u32 	%r198, 0;
	or.b32  	%r199, %r197, 2146435072;
	setp.lt.s32 	%p77, %r32, 0;
	selp.b32 	%r200, %r199, %r197, %p77;
	mov.b64 	%fd1403, {%r198, %r200};
	bra.uni 	$L__BB15_88;

$L__BB15_84:
	setp.gt.s32 	%p74, %r34, -1;
	@%p74 bra 	$L__BB15_88;

	mov.f64 	%fd719, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd720, %fd719;
	setp.eq.f64 	%p75, %fd720, 0d4000000000000000;
	@%p75 bra 	$L__BB15_88;

	mov.f64 	%fd1403, 0dFFF8000000000000;

$L__BB15_88:
	add.rn.f64 	%fd722, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd722;
	}
	and.b32  	%r202, %r201, 2146435072;
	setp.ne.s32 	%p78, %r202, 2146435072;
	@%p78 bra 	$L__BB15_95;

	setp.gtu.f64 	%p79, %fd136, 0d7FF0000000000000;
	@%p79 bra 	$L__BB15_94;
	bra.uni 	$L__BB15_90;

$L__BB15_94:
	mov.f64 	%fd724, 0d4000000000000000;
	add.rn.f64 	%fd1403, %fd4, %fd724;
	bra.uni 	$L__BB15_95;

$L__BB15_90:
	mov.f64 	%fd723, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd723;
	}
	and.b32  	%r35, %r32, 2147483647;
	setp.eq.s32 	%p80, %r35, 2146435072;
	setp.eq.s32 	%p81, %r203, 0;
	and.pred  	%p82, %p80, %p81;
	@%p82 bra 	$L__BB15_93;
	bra.uni 	$L__BB15_91;

$L__BB15_93:
	setp.gt.f64 	%p89, %fd136, 0d3FF0000000000000;
	selp.b32 	%r210, 2146435072, 0, %p89;
	mov.u32 	%r211, 0;
	xor.b32  	%r212, %r210, 2146435072;
	setp.lt.s32 	%p90, %r32, 0;
	selp.b32 	%r213, %r212, %r210, %p90;
	setp.eq.f64 	%p91, %fd4, 0dBFF0000000000000;
	selp.b32 	%r214, 1072693248, %r213, %p91;
	mov.b64 	%fd1403, {%r211, %r214};
	bra.uni 	$L__BB15_95;

$L__BB15_91:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r204, %temp}, %fd4;
	}
	and.b32  	%r205, %r34, 2147483647;
	setp.ne.s32 	%p83, %r205, 2146435072;
	setp.ne.s32 	%p84, %r204, 0;
	or.pred  	%p85, %p83, %p84;
	@%p85 bra 	$L__BB15_95;

	setp.gt.s32 	%p86, %r32, -1;
	selp.b32 	%r206, 2146435072, 0, %p86;
	mov.u32 	%r207, 0;
	setp.ne.s32 	%p87, %r35, 1071644672;
	and.pred  	%p88, %p87, %p1;
	or.b32  	%r208, %r206, -2147483648;
	selp.b32 	%r209, %r208, %r206, %p88;
	mov.b64 	%fd1403, {%r207, %r209};

$L__BB15_95:
	add.rn.f64 	%fd1360, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1359, %fd1360;
	mul.rn.f64 	%fd725, %fd1403, 0d3FC999999999999A;
	setp.eq.f64 	%p92, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd726, 0d3FC999999999999A, %fd725, %p92;
	add.rn.f64 	%fd727, %fd135, %fd726;
	mul.rn.f64 	%fd728, %fd1360, %fd4;
	mul.rn.f64 	%fd146, %fd728, 0d3FB999999999999A;
	add.rn.f64 	%fd729, %fd146, %fd727;
	mul.rn.f64 	%fd730, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd731, %fd730, %fd729;
	mul.rn.f64 	%fd732, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd732, %fd731;
	add.rn.f64 	%fd733, %fd4, %fd4;
	add.rn.f64 	%fd734, %fd1360, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd734, %fd733;
	{ // callseq 199, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1359;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1406, [retval0+0];
	} // callseq 199
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r36}, %fd1360;
	}
	setp.lt.s32 	%p93, %r36, 0;
	and.pred  	%p2, %p93, %p70;
	not.pred 	%p95, %p2;
	@%p95 bra 	$L__BB15_97;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd1406;
	}
	xor.b32  	%r216, %r215, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r217, %temp}, %fd1406;
	}
	mov.b64 	%fd1406, {%r217, %r216};

$L__BB15_97:
	setp.eq.f64 	%p96, %fd2, 0d0000000000000000;
	@%p96 bra 	$L__BB15_101;
	bra.uni 	$L__BB15_98;

$L__BB15_101:
	selp.b32 	%r218, %r36, 0, %p70;
	mov.u32 	%r219, 0;
	or.b32  	%r220, %r218, 2146435072;
	setp.lt.s32 	%p100, %r32, 0;
	selp.b32 	%r221, %r220, %r218, %p100;
	mov.b64 	%fd1406, {%r219, %r221};
	bra.uni 	$L__BB15_102;

$L__BB15_98:
	setp.gt.s32 	%p97, %r36, -1;
	@%p97 bra 	$L__BB15_102;

	mov.f64 	%fd735, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd736, %fd735;
	setp.eq.f64 	%p98, %fd736, 0d4000000000000000;
	@%p98 bra 	$L__BB15_102;

	mov.f64 	%fd1406, 0dFFF8000000000000;

$L__BB15_102:
	add.rn.f64 	%fd738, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r222}, %fd738;
	}
	and.b32  	%r223, %r222, 2146435072;
	setp.ne.s32 	%p101, %r223, 2146435072;
	@%p101 bra 	$L__BB15_109;

	add.rn.f64 	%fd1362, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1361, %fd1362;
	setp.gtu.f64 	%p102, %fd1361, 0d7FF0000000000000;
	@%p102 bra 	$L__BB15_108;
	bra.uni 	$L__BB15_104;

$L__BB15_108:
	mov.f64 	%fd740, 0d4000000000000000;
	add.rn.f64 	%fd1406, %fd2, %fd740;
	bra.uni 	$L__BB15_109;

$L__BB15_104:
	mov.f64 	%fd739, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd739;
	}
	and.b32  	%r37, %r32, 2147483647;
	setp.eq.s32 	%p103, %r37, 2146435072;
	setp.eq.s32 	%p104, %r224, 0;
	and.pred  	%p105, %p103, %p104;
	@%p105 bra 	$L__BB15_107;
	bra.uni 	$L__BB15_105;

$L__BB15_107:
	add.rn.f64 	%fd1364, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1363, %fd1364;
	setp.gt.f64 	%p112, %fd1363, 0d3FF0000000000000;
	selp.b32 	%r231, 2146435072, 0, %p112;
	mov.u32 	%r232, 0;
	xor.b32  	%r233, %r231, 2146435072;
	setp.lt.s32 	%p113, %r32, 0;
	selp.b32 	%r234, %r233, %r231, %p113;
	setp.eq.f64 	%p114, %fd1364, 0dBFF0000000000000;
	selp.b32 	%r235, 1072693248, %r234, %p114;
	mov.b64 	%fd1406, {%r232, %r235};
	bra.uni 	$L__BB15_109;

$L__BB15_105:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r225, %temp}, %fd2;
	}
	and.b32  	%r226, %r36, 2147483647;
	setp.ne.s32 	%p106, %r226, 2146435072;
	setp.ne.s32 	%p107, %r225, 0;
	or.pred  	%p108, %p106, %p107;
	@%p108 bra 	$L__BB15_109;

	setp.gt.s32 	%p109, %r32, -1;
	selp.b32 	%r227, 2146435072, 0, %p109;
	mov.u32 	%r228, 0;
	setp.ne.s32 	%p110, %r37, 1071644672;
	and.pred  	%p111, %p110, %p2;
	or.b32  	%r229, %r227, -2147483648;
	selp.b32 	%r230, %r229, %r227, %p111;
	mov.b64 	%fd1406, {%r228, %r230};

$L__BB15_109:
	mul.rn.f64 	%fd741, %fd1406, 0d3FB999999999999A;
	setp.eq.f64 	%p115, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd742, 0d3FB999999999999A, %fd741, %p115;
	add.rn.f64 	%fd743, %fd148, %fd742;
	add.rn.f64 	%fd744, %fd146, %fd743;
	mul.rn.f64 	%fd745, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd746, %fd745, %fd744;
	mul.rn.f64 	%fd747, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd747, %fd746;
	div.rn.f64 	%fd748, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd748, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r236, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r237}, %fd159;
	}
	and.b32  	%r238, %r237, 2147483647;
	setp.eq.s32 	%p116, %r238, 2146435072;
	setp.eq.s32 	%p117, %r236, 0;
	and.pred  	%p3, %p117, %p116;
	@%p3 bra 	$L__BB15_112;
	bra.uni 	$L__BB15_110;

$L__BB15_112:
	mov.f64 	%fd758, 0d0000000000000000;
	mul.rn.f64 	%fd1407, %fd159, %fd758;
	mov.u32 	%r489, 0;
	bra.uni 	$L__BB15_113;

$L__BB15_110:
	mul.rn.f64 	%fd749, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r489, %fd749;
	st.local.u32 	[%rd1], %r489;
	cvt.rn.f64.s32 	%fd750, %r489;
	neg.f64 	%fd751, %fd750;
	mov.f64 	%fd752, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd753, %fd751, %fd752, %fd159;
	mov.f64 	%fd754, 0d3C91A62633145C00;
	fma.rn.f64 	%fd755, %fd751, %fd754, %fd753;
	mov.f64 	%fd756, 0d397B839A252049C0;
	fma.rn.f64 	%fd1407, %fd751, %fd756, %fd755;
	abs.f64 	%fd757, %fd159;
	setp.ltu.f64 	%p118, %fd757, 0d41E0000000000000;
	@%p118 bra 	$L__BB15_113;

	{ // callseq 200, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1407, [retval0+0];
	} // callseq 200
	ld.local.u32 	%r489, [%rd1];

$L__BB15_113:
	and.b32  	%r240, %r489, 1;
	shl.b32 	%r241, %r489, 3;
	and.b32  	%r242, %r241, 8;
	setp.eq.s32 	%p119, %r240, 0;
	selp.f64 	%fd759, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p119;
	mul.wide.s32 	%rd111, %r242, 8;
	add.s64 	%rd113, %rd72, %rd111;
	ld.global.nc.f64 	%fd760, [%rd113+8];
	mul.rn.f64 	%fd164, %fd1407, %fd1407;
	fma.rn.f64 	%fd761, %fd759, %fd164, %fd760;
	ld.global.nc.f64 	%fd762, [%rd113+16];
	fma.rn.f64 	%fd763, %fd761, %fd164, %fd762;
	ld.global.nc.f64 	%fd764, [%rd113+24];
	fma.rn.f64 	%fd765, %fd763, %fd164, %fd764;
	ld.global.nc.f64 	%fd766, [%rd113+32];
	fma.rn.f64 	%fd767, %fd765, %fd164, %fd766;
	ld.global.nc.f64 	%fd768, [%rd113+40];
	fma.rn.f64 	%fd769, %fd767, %fd164, %fd768;
	ld.global.nc.f64 	%fd770, [%rd113+48];
	fma.rn.f64 	%fd165, %fd769, %fd164, %fd770;
	fma.rn.f64 	%fd1409, %fd165, %fd1407, %fd1407;
	@%p119 bra 	$L__BB15_115;

	mov.f64 	%fd771, 0d3FF0000000000000;
	fma.rn.f64 	%fd1409, %fd165, %fd164, %fd771;

$L__BB15_115:
	and.b32  	%r243, %r489, 2;
	setp.eq.s32 	%p120, %r243, 0;
	@%p120 bra 	$L__BB15_117;

	mov.f64 	%fd772, 0d0000000000000000;
	mov.f64 	%fd773, 0dBFF0000000000000;
	fma.rn.f64 	%fd1409, %fd1409, %fd773, %fd772;

$L__BB15_117:
	@%p3 bra 	$L__BB15_121;
	bra.uni 	$L__BB15_118;

$L__BB15_121:
	mov.f64 	%fd783, 0d0000000000000000;
	mul.rn.f64 	%fd1411, %fd159, %fd783;
	mov.u32 	%r491, 1;
	bra.uni 	$L__BB15_122;

$L__BB15_118:
	mul.rn.f64 	%fd774, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r490, %fd774;
	st.local.u32 	[%rd1], %r490;
	cvt.rn.f64.s32 	%fd775, %r490;
	neg.f64 	%fd776, %fd775;
	mov.f64 	%fd777, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd778, %fd776, %fd777, %fd159;
	mov.f64 	%fd779, 0d3C91A62633145C00;
	fma.rn.f64 	%fd780, %fd776, %fd779, %fd778;
	mov.f64 	%fd781, 0d397B839A252049C0;
	fma.rn.f64 	%fd1411, %fd776, %fd781, %fd780;
	abs.f64 	%fd782, %fd159;
	setp.ltu.f64 	%p121, %fd782, 0d41E0000000000000;
	@%p121 bra 	$L__BB15_120;

	{ // callseq 201, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1411, [retval0+0];
	} // callseq 201
	ld.local.u32 	%r490, [%rd1];

$L__BB15_120:
	add.s32 	%r491, %r490, 1;

$L__BB15_122:
	and.b32  	%r245, %r491, 1;
	shl.b32 	%r246, %r491, 3;
	and.b32  	%r247, %r246, 8;
	setp.eq.s32 	%p122, %r245, 0;
	selp.f64 	%fd784, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p122;
	mul.wide.s32 	%rd115, %r247, 8;
	add.s64 	%rd117, %rd72, %rd115;
	ld.global.nc.f64 	%fd785, [%rd117+8];
	mul.rn.f64 	%fd176, %fd1411, %fd1411;
	fma.rn.f64 	%fd786, %fd784, %fd176, %fd785;
	ld.global.nc.f64 	%fd787, [%rd117+16];
	fma.rn.f64 	%fd788, %fd786, %fd176, %fd787;
	ld.global.nc.f64 	%fd789, [%rd117+24];
	fma.rn.f64 	%fd790, %fd788, %fd176, %fd789;
	ld.global.nc.f64 	%fd791, [%rd117+32];
	fma.rn.f64 	%fd792, %fd790, %fd176, %fd791;
	ld.global.nc.f64 	%fd793, [%rd117+40];
	fma.rn.f64 	%fd794, %fd792, %fd176, %fd793;
	ld.global.nc.f64 	%fd795, [%rd117+48];
	fma.rn.f64 	%fd177, %fd794, %fd176, %fd795;
	fma.rn.f64 	%fd1413, %fd177, %fd1411, %fd1411;
	@%p122 bra 	$L__BB15_124;

	mov.f64 	%fd796, 0d3FF0000000000000;
	fma.rn.f64 	%fd1413, %fd177, %fd176, %fd796;

$L__BB15_124:
	and.b32  	%r248, %r491, 2;
	setp.eq.s32 	%p123, %r248, 0;
	@%p123 bra 	$L__BB15_126;

	mov.f64 	%fd797, 0d0000000000000000;
	mov.f64 	%fd798, 0dBFF0000000000000;
	fma.rn.f64 	%fd1413, %fd1413, %fd798, %fd797;

$L__BB15_126:
	ld.param.u32 	%r474, [gcj02_to_wgs84_exact_cuda_double_param_5];
	mul.rn.f64 	%fd799, %fd1409, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd800, %fd1409, %fd799;
	add.rn.f64 	%fd801, %fd800, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd802, %fd801;
	mov.f64 	%fd803, 0dC15854C140000000;
	div.rn.f64 	%fd804, %fd803, %fd802;
	mul.rn.f64 	%fd805, %fd804, %fd1413;
	mul.rn.f64 	%fd806, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd807, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd808, %fd807, %fd806;
	add.rn.f64 	%fd1480, %fd1, %fd808;
	mul.rn.f64 	%fd809, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd810, %fd802, %fd801;
	mov.f64 	%fd811, 0dC1582B102DE355C1;
	div.rn.f64 	%fd812, %fd811, %fd810;
	mul.rn.f64 	%fd813, %fd812, 0d400921FB54442D18;
	div.rn.f64 	%fd814, %fd809, %fd813;
	add.rn.f64 	%fd1481, %fd3, %fd814;
	setp.lt.s32 	%p124, %r474, 1;
	@%p124 bra 	$L__BB15_325;

	and.b32  	%r46, %r32, 2147483647;
	setp.gt.s32 	%p125, %r32, -1;
	selp.b32 	%r47, 2146435072, 0, %p125;
	mov.u32 	%r492, 0;
	or.b32  	%r48, %r47, -2147483648;
	mov.f64 	%fd1414, %fd1481;
	mov.f64 	%fd1415, %fd1480;

$L__BB15_128:
	mov.f64 	%fd1480, %fd1415;
	mov.f64 	%fd1481, %fd1414;
	add.rn.f64 	%fd187, %fd1481, 0dC041800000000000;
	add.rn.f64 	%fd188, %fd1480, 0dC05A400000000000;
	abs.f64 	%fd189, %fd188;
	sqrt.rn.f64 	%fd190, %fd189;
	mul.rn.f64 	%fd191, %fd188, 0d400921FB54442D18;
	mul.rn.f64 	%fd192, %fd187, 0d400921FB54442D18;
	mul.rn.f64 	%fd193, %fd191, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r250, %temp}, %fd193;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r251}, %fd193;
	}
	and.b32  	%r252, %r251, 2147483647;
	setp.eq.s32 	%p126, %r252, 2146435072;
	setp.eq.s32 	%p127, %r250, 0;
	and.pred  	%p128, %p127, %p126;
	@%p128 bra 	$L__BB15_131;
	bra.uni 	$L__BB15_129;

$L__BB15_131:
	mov.f64 	%fd824, 0d0000000000000000;
	mul.rn.f64 	%fd1416, %fd193, %fd824;
	mov.u32 	%r493, 0;
	bra.uni 	$L__BB15_132;

$L__BB15_129:
	mul.rn.f64 	%fd815, %fd193, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r493, %fd815;
	st.local.u32 	[%rd1], %r493;
	cvt.rn.f64.s32 	%fd816, %r493;
	neg.f64 	%fd817, %fd816;
	mov.f64 	%fd818, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd819, %fd817, %fd818, %fd193;
	mov.f64 	%fd820, 0d3C91A62633145C00;
	fma.rn.f64 	%fd821, %fd817, %fd820, %fd819;
	mov.f64 	%fd822, 0d397B839A252049C0;
	fma.rn.f64 	%fd1416, %fd817, %fd822, %fd821;
	abs.f64 	%fd823, %fd193;
	setp.ltu.f64 	%p129, %fd823, 0d41E0000000000000;
	@%p129 bra 	$L__BB15_132;

	{ // callseq 202, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd193;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1416, [retval0+0];
	} // callseq 202
	ld.local.u32 	%r493, [%rd1];

$L__BB15_132:
	and.b32  	%r254, %r493, 1;
	shl.b32 	%r255, %r493, 3;
	and.b32  	%r256, %r255, 8;
	setp.eq.s32 	%p130, %r254, 0;
	selp.f64 	%fd825, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p130;
	mul.wide.s32 	%rd119, %r256, 8;
	add.s64 	%rd121, %rd72, %rd119;
	ld.global.nc.f64 	%fd826, [%rd121+8];
	mul.rn.f64 	%fd198, %fd1416, %fd1416;
	fma.rn.f64 	%fd827, %fd825, %fd198, %fd826;
	ld.global.nc.f64 	%fd828, [%rd121+16];
	fma.rn.f64 	%fd829, %fd827, %fd198, %fd828;
	ld.global.nc.f64 	%fd830, [%rd121+24];
	fma.rn.f64 	%fd831, %fd829, %fd198, %fd830;
	ld.global.nc.f64 	%fd832, [%rd121+32];
	fma.rn.f64 	%fd833, %fd831, %fd198, %fd832;
	ld.global.nc.f64 	%fd834, [%rd121+40];
	fma.rn.f64 	%fd835, %fd833, %fd198, %fd834;
	ld.global.nc.f64 	%fd836, [%rd121+48];
	fma.rn.f64 	%fd199, %fd835, %fd198, %fd836;
	fma.rn.f64 	%fd1418, %fd199, %fd1416, %fd1416;
	@%p130 bra 	$L__BB15_134;

	mov.f64 	%fd837, 0d3FF0000000000000;
	fma.rn.f64 	%fd1418, %fd199, %fd198, %fd837;

$L__BB15_134:
	and.b32  	%r257, %r493, 2;
	setp.eq.s32 	%p131, %r257, 0;
	@%p131 bra 	$L__BB15_136;

	mov.f64 	%fd838, 0d0000000000000000;
	mov.f64 	%fd839, 0dBFF0000000000000;
	fma.rn.f64 	%fd1418, %fd1418, %fd839, %fd838;

$L__BB15_136:
	add.rn.f64 	%fd205, %fd191, %fd191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r258, %temp}, %fd205;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd205;
	}
	and.b32  	%r260, %r259, 2147483647;
	setp.eq.s32 	%p132, %r260, 2146435072;
	setp.eq.s32 	%p133, %r258, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB15_139;
	bra.uni 	$L__BB15_137;

$L__BB15_139:
	mov.f64 	%fd849, 0d0000000000000000;
	mul.rn.f64 	%fd1419, %fd205, %fd849;
	mov.u32 	%r494, 0;
	bra.uni 	$L__BB15_140;

$L__BB15_137:
	mul.rn.f64 	%fd840, %fd205, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r494, %fd840;
	st.local.u32 	[%rd1], %r494;
	cvt.rn.f64.s32 	%fd841, %r494;
	neg.f64 	%fd842, %fd841;
	mov.f64 	%fd843, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd844, %fd842, %fd843, %fd205;
	mov.f64 	%fd845, 0d3C91A62633145C00;
	fma.rn.f64 	%fd846, %fd842, %fd845, %fd844;
	mov.f64 	%fd847, 0d397B839A252049C0;
	fma.rn.f64 	%fd1419, %fd842, %fd847, %fd846;
	abs.f64 	%fd848, %fd205;
	setp.ltu.f64 	%p135, %fd848, 0d41E0000000000000;
	@%p135 bra 	$L__BB15_140;

	{ // callseq 203, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd205;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1419, [retval0+0];
	} // callseq 203
	ld.local.u32 	%r494, [%rd1];

$L__BB15_140:
	and.b32  	%r262, %r494, 1;
	shl.b32 	%r263, %r494, 3;
	and.b32  	%r264, %r263, 8;
	setp.eq.s32 	%p136, %r262, 0;
	selp.f64 	%fd850, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd123, %r264, 8;
	add.s64 	%rd125, %rd72, %rd123;
	ld.global.nc.f64 	%fd851, [%rd125+8];
	mul.rn.f64 	%fd210, %fd1419, %fd1419;
	fma.rn.f64 	%fd852, %fd850, %fd210, %fd851;
	ld.global.nc.f64 	%fd853, [%rd125+16];
	fma.rn.f64 	%fd854, %fd852, %fd210, %fd853;
	ld.global.nc.f64 	%fd855, [%rd125+24];
	fma.rn.f64 	%fd856, %fd854, %fd210, %fd855;
	ld.global.nc.f64 	%fd857, [%rd125+32];
	fma.rn.f64 	%fd858, %fd856, %fd210, %fd857;
	ld.global.nc.f64 	%fd859, [%rd125+40];
	fma.rn.f64 	%fd860, %fd858, %fd210, %fd859;
	ld.global.nc.f64 	%fd861, [%rd125+48];
	fma.rn.f64 	%fd211, %fd860, %fd210, %fd861;
	fma.rn.f64 	%fd1421, %fd211, %fd1419, %fd1419;
	@%p136 bra 	$L__BB15_142;

	mov.f64 	%fd862, 0d3FF0000000000000;
	fma.rn.f64 	%fd1421, %fd211, %fd210, %fd862;

$L__BB15_142:
	and.b32  	%r265, %r494, 2;
	setp.eq.s32 	%p137, %r265, 0;
	@%p137 bra 	$L__BB15_144;

	mov.f64 	%fd863, 0d0000000000000000;
	mov.f64 	%fd864, 0dBFF0000000000000;
	fma.rn.f64 	%fd1421, %fd1421, %fd864, %fd863;

$L__BB15_144:
	mul.rn.f64 	%fd865, %fd1421, 0d4034000000000000;
	mul.rn.f64 	%fd866, %fd1418, 0d4034000000000000;
	add.rn.f64 	%fd217, %fd866, %fd865;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r266}, %fd192;
	}
	and.b32  	%r267, %r266, 2147483647;
	setp.eq.s32 	%p138, %r267, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r268, %temp}, %fd192;
	}
	setp.eq.s32 	%p139, %r268, 0;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB15_147;
	bra.uni 	$L__BB15_145;

$L__BB15_147:
	mov.f64 	%fd876, 0d0000000000000000;
	mul.rn.f64 	%fd1422, %fd192, %fd876;
	mov.u32 	%r495, 0;
	bra.uni 	$L__BB15_148;

$L__BB15_145:
	mul.rn.f64 	%fd867, %fd192, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r495, %fd867;
	st.local.u32 	[%rd1], %r495;
	cvt.rn.f64.s32 	%fd868, %r495;
	neg.f64 	%fd869, %fd868;
	mov.f64 	%fd870, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd871, %fd869, %fd870, %fd192;
	mov.f64 	%fd872, 0d3C91A62633145C00;
	fma.rn.f64 	%fd873, %fd869, %fd872, %fd871;
	mov.f64 	%fd874, 0d397B839A252049C0;
	fma.rn.f64 	%fd1422, %fd869, %fd874, %fd873;
	abs.f64 	%fd875, %fd192;
	setp.ltu.f64 	%p141, %fd875, 0d41E0000000000000;
	@%p141 bra 	$L__BB15_148;

	{ // callseq 204, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd192;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1422, [retval0+0];
	} // callseq 204
	ld.local.u32 	%r495, [%rd1];

$L__BB15_148:
	and.b32  	%r270, %r495, 1;
	shl.b32 	%r271, %r495, 3;
	and.b32  	%r272, %r271, 8;
	setp.eq.s32 	%p142, %r270, 0;
	selp.f64 	%fd877, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd127, %r272, 8;
	add.s64 	%rd129, %rd72, %rd127;
	ld.global.nc.f64 	%fd878, [%rd129+8];
	mul.rn.f64 	%fd222, %fd1422, %fd1422;
	fma.rn.f64 	%fd879, %fd877, %fd222, %fd878;
	ld.global.nc.f64 	%fd880, [%rd129+16];
	fma.rn.f64 	%fd881, %fd879, %fd222, %fd880;
	ld.global.nc.f64 	%fd882, [%rd129+24];
	fma.rn.f64 	%fd883, %fd881, %fd222, %fd882;
	ld.global.nc.f64 	%fd884, [%rd129+32];
	fma.rn.f64 	%fd885, %fd883, %fd222, %fd884;
	ld.global.nc.f64 	%fd886, [%rd129+40];
	fma.rn.f64 	%fd887, %fd885, %fd222, %fd886;
	ld.global.nc.f64 	%fd888, [%rd129+48];
	fma.rn.f64 	%fd223, %fd887, %fd222, %fd888;
	fma.rn.f64 	%fd1424, %fd223, %fd1422, %fd1422;
	@%p142 bra 	$L__BB15_150;

	mov.f64 	%fd889, 0d3FF0000000000000;
	fma.rn.f64 	%fd1424, %fd223, %fd222, %fd889;

$L__BB15_150:
	and.b32  	%r273, %r495, 2;
	setp.eq.s32 	%p143, %r273, 0;
	@%p143 bra 	$L__BB15_152;

	mov.f64 	%fd890, 0d0000000000000000;
	mov.f64 	%fd891, 0dBFF0000000000000;
	fma.rn.f64 	%fd1424, %fd1424, %fd891, %fd890;

$L__BB15_152:
	div.rn.f64 	%fd229, %fd192, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd229;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd229;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p144, %r276, 2146435072;
	setp.eq.s32 	%p145, %r274, 0;
	and.pred  	%p146, %p145, %p144;
	@%p146 bra 	$L__BB15_155;
	bra.uni 	$L__BB15_153;

$L__BB15_155:
	mov.f64 	%fd901, 0d0000000000000000;
	mul.rn.f64 	%fd1425, %fd229, %fd901;
	mov.u32 	%r496, 0;
	bra.uni 	$L__BB15_156;

$L__BB15_153:
	mul.rn.f64 	%fd892, %fd229, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r496, %fd892;
	st.local.u32 	[%rd1], %r496;
	cvt.rn.f64.s32 	%fd893, %r496;
	neg.f64 	%fd894, %fd893;
	mov.f64 	%fd895, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd896, %fd894, %fd895, %fd229;
	mov.f64 	%fd897, 0d3C91A62633145C00;
	fma.rn.f64 	%fd898, %fd894, %fd897, %fd896;
	mov.f64 	%fd899, 0d397B839A252049C0;
	fma.rn.f64 	%fd1425, %fd894, %fd899, %fd898;
	abs.f64 	%fd900, %fd229;
	setp.ltu.f64 	%p147, %fd900, 0d41E0000000000000;
	@%p147 bra 	$L__BB15_156;

	{ // callseq 205, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd229;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1425, [retval0+0];
	} // callseq 205
	ld.local.u32 	%r496, [%rd1];

$L__BB15_156:
	and.b32  	%r278, %r496, 1;
	shl.b32 	%r279, %r496, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p148, %r278, 0;
	selp.f64 	%fd902, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p148;
	mul.wide.s32 	%rd131, %r280, 8;
	add.s64 	%rd133, %rd72, %rd131;
	ld.global.nc.f64 	%fd903, [%rd133+8];
	mul.rn.f64 	%fd234, %fd1425, %fd1425;
	fma.rn.f64 	%fd904, %fd902, %fd234, %fd903;
	ld.global.nc.f64 	%fd905, [%rd133+16];
	fma.rn.f64 	%fd906, %fd904, %fd234, %fd905;
	ld.global.nc.f64 	%fd907, [%rd133+24];
	fma.rn.f64 	%fd908, %fd906, %fd234, %fd907;
	ld.global.nc.f64 	%fd909, [%rd133+32];
	fma.rn.f64 	%fd910, %fd908, %fd234, %fd909;
	ld.global.nc.f64 	%fd911, [%rd133+40];
	fma.rn.f64 	%fd912, %fd910, %fd234, %fd911;
	ld.global.nc.f64 	%fd913, [%rd133+48];
	fma.rn.f64 	%fd235, %fd912, %fd234, %fd913;
	fma.rn.f64 	%fd1427, %fd235, %fd1425, %fd1425;
	@%p148 bra 	$L__BB15_158;

	mov.f64 	%fd914, 0d3FF0000000000000;
	fma.rn.f64 	%fd1427, %fd235, %fd234, %fd914;

$L__BB15_158:
	and.b32  	%r281, %r496, 2;
	setp.eq.s32 	%p149, %r281, 0;
	@%p149 bra 	$L__BB15_160;

	mov.f64 	%fd915, 0d0000000000000000;
	mov.f64 	%fd916, 0dBFF0000000000000;
	fma.rn.f64 	%fd1427, %fd1427, %fd916, %fd915;

$L__BB15_160:
	mul.rn.f64 	%fd917, %fd1427, 0d4044000000000000;
	mul.rn.f64 	%fd918, %fd1424, 0d4034000000000000;
	add.rn.f64 	%fd241, %fd918, %fd917;
	div.rn.f64 	%fd242, %fd192, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r282, %temp}, %fd242;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd242;
	}
	and.b32  	%r284, %r283, 2147483647;
	setp.eq.s32 	%p150, %r284, 2146435072;
	setp.eq.s32 	%p151, %r282, 0;
	and.pred  	%p152, %p151, %p150;
	@%p152 bra 	$L__BB15_163;
	bra.uni 	$L__BB15_161;

$L__BB15_163:
	mov.f64 	%fd928, 0d0000000000000000;
	mul.rn.f64 	%fd1428, %fd242, %fd928;
	mov.u32 	%r497, 0;
	bra.uni 	$L__BB15_164;

$L__BB15_161:
	mul.rn.f64 	%fd919, %fd242, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r497, %fd919;
	st.local.u32 	[%rd1], %r497;
	cvt.rn.f64.s32 	%fd920, %r497;
	neg.f64 	%fd921, %fd920;
	mov.f64 	%fd922, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd923, %fd921, %fd922, %fd242;
	mov.f64 	%fd924, 0d3C91A62633145C00;
	fma.rn.f64 	%fd925, %fd921, %fd924, %fd923;
	mov.f64 	%fd926, 0d397B839A252049C0;
	fma.rn.f64 	%fd1428, %fd921, %fd926, %fd925;
	abs.f64 	%fd927, %fd242;
	setp.ltu.f64 	%p153, %fd927, 0d41E0000000000000;
	@%p153 bra 	$L__BB15_164;

	{ // callseq 206, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd242;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1428, [retval0+0];
	} // callseq 206
	ld.local.u32 	%r497, [%rd1];

$L__BB15_164:
	and.b32  	%r286, %r497, 1;
	shl.b32 	%r287, %r497, 3;
	and.b32  	%r288, %r287, 8;
	setp.eq.s32 	%p154, %r286, 0;
	selp.f64 	%fd929, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p154;
	mul.wide.s32 	%rd135, %r288, 8;
	add.s64 	%rd137, %rd72, %rd135;
	ld.global.nc.f64 	%fd930, [%rd137+8];
	mul.rn.f64 	%fd247, %fd1428, %fd1428;
	fma.rn.f64 	%fd931, %fd929, %fd247, %fd930;
	ld.global.nc.f64 	%fd932, [%rd137+16];
	fma.rn.f64 	%fd933, %fd931, %fd247, %fd932;
	ld.global.nc.f64 	%fd934, [%rd137+24];
	fma.rn.f64 	%fd935, %fd933, %fd247, %fd934;
	ld.global.nc.f64 	%fd936, [%rd137+32];
	fma.rn.f64 	%fd937, %fd935, %fd247, %fd936;
	ld.global.nc.f64 	%fd938, [%rd137+40];
	fma.rn.f64 	%fd939, %fd937, %fd247, %fd938;
	ld.global.nc.f64 	%fd940, [%rd137+48];
	fma.rn.f64 	%fd248, %fd939, %fd247, %fd940;
	fma.rn.f64 	%fd1430, %fd248, %fd1428, %fd1428;
	@%p154 bra 	$L__BB15_166;

	mov.f64 	%fd941, 0d3FF0000000000000;
	fma.rn.f64 	%fd1430, %fd248, %fd247, %fd941;

$L__BB15_166:
	and.b32  	%r289, %r497, 2;
	setp.eq.s32 	%p155, %r289, 0;
	@%p155 bra 	$L__BB15_168;

	mov.f64 	%fd942, 0d0000000000000000;
	mov.f64 	%fd943, 0dBFF0000000000000;
	fma.rn.f64 	%fd1430, %fd1430, %fd943, %fd942;

$L__BB15_168:
	mul.rn.f64 	%fd944, %fd1430, 0d4064000000000000;
	add.rn.f64 	%fd254, %fd241, %fd944;
	div.rn.f64 	%fd255, %fd192, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r290, %temp}, %fd255;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd255;
	}
	and.b32  	%r292, %r291, 2147483647;
	setp.eq.s32 	%p156, %r292, 2146435072;
	setp.eq.s32 	%p157, %r290, 0;
	and.pred  	%p158, %p157, %p156;
	@%p158 bra 	$L__BB15_171;
	bra.uni 	$L__BB15_169;

$L__BB15_171:
	mov.f64 	%fd954, 0d0000000000000000;
	mul.rn.f64 	%fd1431, %fd255, %fd954;
	mov.u32 	%r498, 0;
	bra.uni 	$L__BB15_172;

$L__BB15_169:
	mul.rn.f64 	%fd945, %fd255, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r498, %fd945;
	st.local.u32 	[%rd1], %r498;
	cvt.rn.f64.s32 	%fd946, %r498;
	neg.f64 	%fd947, %fd946;
	mov.f64 	%fd948, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd949, %fd947, %fd948, %fd255;
	mov.f64 	%fd950, 0d3C91A62633145C00;
	fma.rn.f64 	%fd951, %fd947, %fd950, %fd949;
	mov.f64 	%fd952, 0d397B839A252049C0;
	fma.rn.f64 	%fd1431, %fd947, %fd952, %fd951;
	abs.f64 	%fd953, %fd255;
	setp.ltu.f64 	%p159, %fd953, 0d41E0000000000000;
	@%p159 bra 	$L__BB15_172;

	{ // callseq 207, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd255;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1431, [retval0+0];
	} // callseq 207
	ld.local.u32 	%r498, [%rd1];

$L__BB15_172:
	and.b32  	%r294, %r498, 1;
	shl.b32 	%r295, %r498, 3;
	and.b32  	%r296, %r295, 8;
	setp.eq.s32 	%p160, %r294, 0;
	selp.f64 	%fd955, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p160;
	mul.wide.s32 	%rd139, %r296, 8;
	add.s64 	%rd141, %rd72, %rd139;
	ld.global.nc.f64 	%fd956, [%rd141+8];
	mul.rn.f64 	%fd260, %fd1431, %fd1431;
	fma.rn.f64 	%fd957, %fd955, %fd260, %fd956;
	ld.global.nc.f64 	%fd958, [%rd141+16];
	fma.rn.f64 	%fd959, %fd957, %fd260, %fd958;
	ld.global.nc.f64 	%fd960, [%rd141+24];
	fma.rn.f64 	%fd961, %fd959, %fd260, %fd960;
	ld.global.nc.f64 	%fd962, [%rd141+32];
	fma.rn.f64 	%fd963, %fd961, %fd260, %fd962;
	ld.global.nc.f64 	%fd964, [%rd141+40];
	fma.rn.f64 	%fd965, %fd963, %fd260, %fd964;
	ld.global.nc.f64 	%fd966, [%rd141+48];
	fma.rn.f64 	%fd261, %fd965, %fd260, %fd966;
	fma.rn.f64 	%fd1433, %fd261, %fd1431, %fd1431;
	@%p160 bra 	$L__BB15_174;

	mov.f64 	%fd967, 0d3FF0000000000000;
	fma.rn.f64 	%fd1433, %fd261, %fd260, %fd967;

$L__BB15_174:
	and.b32  	%r297, %r498, 2;
	setp.eq.s32 	%p161, %r297, 0;
	@%p161 bra 	$L__BB15_176;

	mov.f64 	%fd968, 0d0000000000000000;
	mov.f64 	%fd969, 0dBFF0000000000000;
	fma.rn.f64 	%fd1433, %fd1433, %fd969, %fd968;

$L__BB15_176:
	mul.rn.f64 	%fd970, %fd1433, 0d4074000000000000;
	add.rn.f64 	%fd267, %fd254, %fd970;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r298}, %fd191;
	}
	and.b32  	%r299, %r298, 2147483647;
	setp.eq.s32 	%p162, %r299, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r300, %temp}, %fd191;
	}
	setp.eq.s32 	%p163, %r300, 0;
	and.pred  	%p164, %p163, %p162;
	@%p164 bra 	$L__BB15_179;
	bra.uni 	$L__BB15_177;

$L__BB15_179:
	mov.f64 	%fd980, 0d0000000000000000;
	mul.rn.f64 	%fd1434, %fd191, %fd980;
	mov.u32 	%r499, 0;
	bra.uni 	$L__BB15_180;

$L__BB15_177:
	mul.rn.f64 	%fd971, %fd191, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r499, %fd971;
	st.local.u32 	[%rd1], %r499;
	cvt.rn.f64.s32 	%fd972, %r499;
	neg.f64 	%fd973, %fd972;
	mov.f64 	%fd974, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd975, %fd973, %fd974, %fd191;
	mov.f64 	%fd976, 0d3C91A62633145C00;
	fma.rn.f64 	%fd977, %fd973, %fd976, %fd975;
	mov.f64 	%fd978, 0d397B839A252049C0;
	fma.rn.f64 	%fd1434, %fd973, %fd978, %fd977;
	abs.f64 	%fd979, %fd191;
	setp.ltu.f64 	%p165, %fd979, 0d41E0000000000000;
	@%p165 bra 	$L__BB15_180;

	{ // callseq 208, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1434, [retval0+0];
	} // callseq 208
	ld.local.u32 	%r499, [%rd1];

$L__BB15_180:
	and.b32  	%r302, %r499, 1;
	shl.b32 	%r303, %r499, 3;
	and.b32  	%r304, %r303, 8;
	setp.eq.s32 	%p166, %r302, 0;
	selp.f64 	%fd981, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p166;
	mul.wide.s32 	%rd143, %r304, 8;
	add.s64 	%rd145, %rd72, %rd143;
	ld.global.nc.f64 	%fd982, [%rd145+8];
	mul.rn.f64 	%fd272, %fd1434, %fd1434;
	fma.rn.f64 	%fd983, %fd981, %fd272, %fd982;
	ld.global.nc.f64 	%fd984, [%rd145+16];
	fma.rn.f64 	%fd985, %fd983, %fd272, %fd984;
	ld.global.nc.f64 	%fd986, [%rd145+24];
	fma.rn.f64 	%fd987, %fd985, %fd272, %fd986;
	ld.global.nc.f64 	%fd988, [%rd145+32];
	fma.rn.f64 	%fd989, %fd987, %fd272, %fd988;
	ld.global.nc.f64 	%fd990, [%rd145+40];
	fma.rn.f64 	%fd991, %fd989, %fd272, %fd990;
	ld.global.nc.f64 	%fd992, [%rd145+48];
	fma.rn.f64 	%fd273, %fd991, %fd272, %fd992;
	fma.rn.f64 	%fd1436, %fd273, %fd1434, %fd1434;
	@%p166 bra 	$L__BB15_182;

	mov.f64 	%fd993, 0d3FF0000000000000;
	fma.rn.f64 	%fd1436, %fd273, %fd272, %fd993;

$L__BB15_182:
	and.b32  	%r305, %r499, 2;
	setp.eq.s32 	%p167, %r305, 0;
	@%p167 bra 	$L__BB15_184;

	mov.f64 	%fd994, 0d0000000000000000;
	mov.f64 	%fd995, 0dBFF0000000000000;
	fma.rn.f64 	%fd1436, %fd1436, %fd995, %fd994;

$L__BB15_184:
	div.rn.f64 	%fd279, %fd191, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r306, %temp}, %fd279;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r307}, %fd279;
	}
	and.b32  	%r308, %r307, 2147483647;
	setp.eq.s32 	%p168, %r308, 2146435072;
	setp.eq.s32 	%p169, %r306, 0;
	and.pred  	%p170, %p169, %p168;
	@%p170 bra 	$L__BB15_187;
	bra.uni 	$L__BB15_185;

$L__BB15_187:
	mov.f64 	%fd1005, 0d0000000000000000;
	mul.rn.f64 	%fd1437, %fd279, %fd1005;
	mov.u32 	%r500, 0;
	bra.uni 	$L__BB15_188;

$L__BB15_185:
	mul.rn.f64 	%fd996, %fd279, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r500, %fd996;
	st.local.u32 	[%rd1], %r500;
	cvt.rn.f64.s32 	%fd997, %r500;
	neg.f64 	%fd998, %fd997;
	mov.f64 	%fd999, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1000, %fd998, %fd999, %fd279;
	mov.f64 	%fd1001, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1002, %fd998, %fd1001, %fd1000;
	mov.f64 	%fd1003, 0d397B839A252049C0;
	fma.rn.f64 	%fd1437, %fd998, %fd1003, %fd1002;
	abs.f64 	%fd1004, %fd279;
	setp.ltu.f64 	%p171, %fd1004, 0d41E0000000000000;
	@%p171 bra 	$L__BB15_188;

	{ // callseq 209, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd279;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1437, [retval0+0];
	} // callseq 209
	ld.local.u32 	%r500, [%rd1];

$L__BB15_188:
	and.b32  	%r310, %r500, 1;
	shl.b32 	%r311, %r500, 3;
	and.b32  	%r312, %r311, 8;
	setp.eq.s32 	%p172, %r310, 0;
	selp.f64 	%fd1006, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p172;
	mul.wide.s32 	%rd147, %r312, 8;
	add.s64 	%rd149, %rd72, %rd147;
	ld.global.nc.f64 	%fd1007, [%rd149+8];
	mul.rn.f64 	%fd284, %fd1437, %fd1437;
	fma.rn.f64 	%fd1008, %fd1006, %fd284, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd149+16];
	fma.rn.f64 	%fd1010, %fd1008, %fd284, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd149+24];
	fma.rn.f64 	%fd1012, %fd1010, %fd284, %fd1011;
	ld.global.nc.f64 	%fd1013, [%rd149+32];
	fma.rn.f64 	%fd1014, %fd1012, %fd284, %fd1013;
	ld.global.nc.f64 	%fd1015, [%rd149+40];
	fma.rn.f64 	%fd1016, %fd1014, %fd284, %fd1015;
	ld.global.nc.f64 	%fd1017, [%rd149+48];
	fma.rn.f64 	%fd285, %fd1016, %fd284, %fd1017;
	fma.rn.f64 	%fd1439, %fd285, %fd1437, %fd1437;
	@%p172 bra 	$L__BB15_190;

	mov.f64 	%fd1018, 0d3FF0000000000000;
	fma.rn.f64 	%fd1439, %fd285, %fd284, %fd1018;

$L__BB15_190:
	and.b32  	%r313, %r500, 2;
	setp.eq.s32 	%p173, %r313, 0;
	@%p173 bra 	$L__BB15_192;

	mov.f64 	%fd1019, 0d0000000000000000;
	mov.f64 	%fd1020, 0dBFF0000000000000;
	fma.rn.f64 	%fd1439, %fd1439, %fd1020, %fd1019;

$L__BB15_192:
	mul.rn.f64 	%fd1021, %fd1439, 0d4044000000000000;
	mul.rn.f64 	%fd1022, %fd1436, 0d4034000000000000;
	add.rn.f64 	%fd291, %fd1022, %fd1021;
	div.rn.f64 	%fd292, %fd191, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r314, %temp}, %fd292;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r315}, %fd292;
	}
	and.b32  	%r316, %r315, 2147483647;
	setp.eq.s32 	%p174, %r316, 2146435072;
	setp.eq.s32 	%p175, %r314, 0;
	and.pred  	%p176, %p175, %p174;
	@%p176 bra 	$L__BB15_195;
	bra.uni 	$L__BB15_193;

$L__BB15_195:
	mov.f64 	%fd1032, 0d0000000000000000;
	mul.rn.f64 	%fd1440, %fd292, %fd1032;
	mov.u32 	%r501, 0;
	bra.uni 	$L__BB15_196;

$L__BB15_193:
	mul.rn.f64 	%fd1023, %fd292, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r501, %fd1023;
	st.local.u32 	[%rd1], %r501;
	cvt.rn.f64.s32 	%fd1024, %r501;
	neg.f64 	%fd1025, %fd1024;
	mov.f64 	%fd1026, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1027, %fd1025, %fd1026, %fd292;
	mov.f64 	%fd1028, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1029, %fd1025, %fd1028, %fd1027;
	mov.f64 	%fd1030, 0d397B839A252049C0;
	fma.rn.f64 	%fd1440, %fd1025, %fd1030, %fd1029;
	abs.f64 	%fd1031, %fd292;
	setp.ltu.f64 	%p177, %fd1031, 0d41E0000000000000;
	@%p177 bra 	$L__BB15_196;

	{ // callseq 210, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd292;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1440, [retval0+0];
	} // callseq 210
	ld.local.u32 	%r501, [%rd1];

$L__BB15_196:
	and.b32  	%r318, %r501, 1;
	shl.b32 	%r319, %r501, 3;
	and.b32  	%r320, %r319, 8;
	setp.eq.s32 	%p178, %r318, 0;
	selp.f64 	%fd1033, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p178;
	mul.wide.s32 	%rd151, %r320, 8;
	add.s64 	%rd153, %rd72, %rd151;
	ld.global.nc.f64 	%fd1034, [%rd153+8];
	mul.rn.f64 	%fd297, %fd1440, %fd1440;
	fma.rn.f64 	%fd1035, %fd1033, %fd297, %fd1034;
	ld.global.nc.f64 	%fd1036, [%rd153+16];
	fma.rn.f64 	%fd1037, %fd1035, %fd297, %fd1036;
	ld.global.nc.f64 	%fd1038, [%rd153+24];
	fma.rn.f64 	%fd1039, %fd1037, %fd297, %fd1038;
	ld.global.nc.f64 	%fd1040, [%rd153+32];
	fma.rn.f64 	%fd1041, %fd1039, %fd297, %fd1040;
	ld.global.nc.f64 	%fd1042, [%rd153+40];
	fma.rn.f64 	%fd1043, %fd1041, %fd297, %fd1042;
	ld.global.nc.f64 	%fd1044, [%rd153+48];
	fma.rn.f64 	%fd298, %fd1043, %fd297, %fd1044;
	fma.rn.f64 	%fd1442, %fd298, %fd1440, %fd1440;
	@%p178 bra 	$L__BB15_198;

	mov.f64 	%fd1045, 0d3FF0000000000000;
	fma.rn.f64 	%fd1442, %fd298, %fd297, %fd1045;

$L__BB15_198:
	and.b32  	%r321, %r501, 2;
	setp.eq.s32 	%p179, %r321, 0;
	@%p179 bra 	$L__BB15_200;

	mov.f64 	%fd1046, 0d0000000000000000;
	mov.f64 	%fd1047, 0dBFF0000000000000;
	fma.rn.f64 	%fd1442, %fd1442, %fd1047, %fd1046;

$L__BB15_200:
	mul.rn.f64 	%fd1048, %fd1442, 0d4062C00000000000;
	add.rn.f64 	%fd304, %fd291, %fd1048;
	div.rn.f64 	%fd305, %fd191, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r322, %temp}, %fd305;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r323}, %fd305;
	}
	and.b32  	%r324, %r323, 2147483647;
	setp.eq.s32 	%p180, %r324, 2146435072;
	setp.eq.s32 	%p181, %r322, 0;
	and.pred  	%p182, %p181, %p180;
	@%p182 bra 	$L__BB15_203;
	bra.uni 	$L__BB15_201;

$L__BB15_203:
	mov.f64 	%fd1058, 0d0000000000000000;
	mul.rn.f64 	%fd1443, %fd305, %fd1058;
	mov.u32 	%r502, 0;
	bra.uni 	$L__BB15_204;

$L__BB15_201:
	mul.rn.f64 	%fd1049, %fd305, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r502, %fd1049;
	st.local.u32 	[%rd1], %r502;
	cvt.rn.f64.s32 	%fd1050, %r502;
	neg.f64 	%fd1051, %fd1050;
	mov.f64 	%fd1052, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1053, %fd1051, %fd1052, %fd305;
	mov.f64 	%fd1054, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1055, %fd1051, %fd1054, %fd1053;
	mov.f64 	%fd1056, 0d397B839A252049C0;
	fma.rn.f64 	%fd1443, %fd1051, %fd1056, %fd1055;
	abs.f64 	%fd1057, %fd305;
	setp.ltu.f64 	%p183, %fd1057, 0d41E0000000000000;
	@%p183 bra 	$L__BB15_204;

	{ // callseq 211, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd305;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1443, [retval0+0];
	} // callseq 211
	ld.local.u32 	%r502, [%rd1];

$L__BB15_204:
	and.b32  	%r326, %r502, 1;
	shl.b32 	%r327, %r502, 3;
	and.b32  	%r328, %r327, 8;
	setp.eq.s32 	%p184, %r326, 0;
	selp.f64 	%fd1059, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p184;
	mul.wide.s32 	%rd155, %r328, 8;
	add.s64 	%rd157, %rd72, %rd155;
	ld.global.nc.f64 	%fd1060, [%rd157+8];
	mul.rn.f64 	%fd310, %fd1443, %fd1443;
	fma.rn.f64 	%fd1061, %fd1059, %fd310, %fd1060;
	ld.global.nc.f64 	%fd1062, [%rd157+16];
	fma.rn.f64 	%fd1063, %fd1061, %fd310, %fd1062;
	ld.global.nc.f64 	%fd1064, [%rd157+24];
	fma.rn.f64 	%fd1065, %fd1063, %fd310, %fd1064;
	ld.global.nc.f64 	%fd1066, [%rd157+32];
	fma.rn.f64 	%fd1067, %fd1065, %fd310, %fd1066;
	ld.global.nc.f64 	%fd1068, [%rd157+40];
	fma.rn.f64 	%fd1069, %fd1067, %fd310, %fd1068;
	ld.global.nc.f64 	%fd1070, [%rd157+48];
	fma.rn.f64 	%fd311, %fd1069, %fd310, %fd1070;
	fma.rn.f64 	%fd1445, %fd311, %fd1443, %fd1443;
	@%p184 bra 	$L__BB15_206;

	mov.f64 	%fd1071, 0d3FF0000000000000;
	fma.rn.f64 	%fd1445, %fd311, %fd310, %fd1071;

$L__BB15_206:
	and.b32  	%r329, %r502, 2;
	setp.eq.s32 	%p185, %r329, 0;
	@%p185 bra 	$L__BB15_208;

	mov.f64 	%fd1072, 0d0000000000000000;
	mov.f64 	%fd1073, 0dBFF0000000000000;
	fma.rn.f64 	%fd1445, %fd1445, %fd1073, %fd1072;

$L__BB15_208:
	mul.rn.f64 	%fd1074, %fd1445, 0d4072C00000000000;
	add.rn.f64 	%fd1075, %fd304, %fd1074;
	add.rn.f64 	%fd317, %fd217, %fd1075;
	add.rn.f64 	%fd318, %fd217, %fd267;
	add.rn.f64 	%fd1076, %fd188, %fd188;
	add.rn.f64 	%fd1077, %fd1076, 0dC059000000000000;
	mul.rn.f64 	%fd1078, %fd187, 0d4008000000000000;
	add.rn.f64 	%fd319, %fd1077, %fd1078;
	abs.f64 	%fd320, %fd187;
	{ // callseq 212, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd320;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1448, [retval0+0];
	} // callseq 212
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd187;
	}
	setp.lt.s32 	%p186, %r80, 0;
	and.pred  	%p4, %p186, %p70;
	not.pred 	%p188, %p4;
	@%p188 bra 	$L__BB15_210;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r330}, %fd1448;
	}
	xor.b32  	%r331, %r330, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r332, %temp}, %fd1448;
	}
	mov.b64 	%fd1448, {%r332, %r331};

$L__BB15_210:
	setp.eq.f64 	%p189, %fd187, 0d0000000000000000;
	@%p189 bra 	$L__BB15_214;
	bra.uni 	$L__BB15_211;

$L__BB15_214:
	setp.lt.s32 	%p192, %r32, 0;
	mov.u32 	%r333, 0;
	selp.b32 	%r334, %r80, 0, %p70;
	or.b32  	%r335, %r334, 2146435072;
	selp.b32 	%r336, %r335, %r334, %p192;
	mov.b64 	%fd1448, {%r333, %r336};
	bra.uni 	$L__BB15_215;

$L__BB15_211:
	setp.gt.s32 	%p190, %r80, -1;
	@%p190 bra 	$L__BB15_215;

	mov.f64 	%fd1079, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1080, %fd1079;
	setp.eq.f64 	%p191, %fd1080, 0d4000000000000000;
	@%p191 bra 	$L__BB15_215;

	mov.f64 	%fd1448, 0dFFF8000000000000;

$L__BB15_215:
	add.rn.f64 	%fd1082, %fd187, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r337}, %fd1082;
	}
	and.b32  	%r338, %r337, 2146435072;
	setp.ne.s32 	%p194, %r338, 2146435072;
	@%p194 bra 	$L__BB15_222;

	setp.gtu.f64 	%p195, %fd320, 0d7FF0000000000000;
	@%p195 bra 	$L__BB15_221;
	bra.uni 	$L__BB15_217;

$L__BB15_221:
	mov.f64 	%fd1084, 0d4000000000000000;
	add.rn.f64 	%fd1448, %fd187, %fd1084;
	bra.uni 	$L__BB15_222;

$L__BB15_217:
	setp.eq.s32 	%p196, %r46, 2146435072;
	mov.f64 	%fd1083, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd1083;
	}
	setp.eq.s32 	%p197, %r339, 0;
	and.pred  	%p198, %p196, %p197;
	@%p198 bra 	$L__BB15_220;
	bra.uni 	$L__BB15_218;

$L__BB15_220:
	setp.lt.s32 	%p204, %r32, 0;
	mov.u32 	%r344, 0;
	setp.gt.f64 	%p205, %fd320, 0d3FF0000000000000;
	selp.b32 	%r345, 2146435072, 0, %p205;
	xor.b32  	%r346, %r345, 2146435072;
	selp.b32 	%r347, %r346, %r345, %p204;
	setp.eq.f64 	%p206, %fd187, 0dBFF0000000000000;
	selp.b32 	%r348, 1072693248, %r347, %p206;
	mov.b64 	%fd1448, {%r344, %r348};
	bra.uni 	$L__BB15_222;

$L__BB15_218:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r340, %temp}, %fd187;
	}
	and.b32  	%r341, %r80, 2147483647;
	setp.ne.s32 	%p199, %r341, 2146435072;
	setp.ne.s32 	%p200, %r340, 0;
	or.pred  	%p201, %p199, %p200;
	@%p201 bra 	$L__BB15_222;

	setp.ne.s32 	%p202, %r46, 1071644672;
	and.pred  	%p203, %p202, %p4;
	selp.b32 	%r342, %r48, %r47, %p203;
	mov.u32 	%r343, 0;
	mov.b64 	%fd1448, {%r343, %r342};

$L__BB15_222:
	mul.rn.f64 	%fd1085, %fd1448, 0d3FC999999999999A;
	setp.eq.f64 	%p207, %fd187, 0d3FF0000000000000;
	selp.f64 	%fd1086, 0d3FC999999999999A, %fd1085, %p207;
	add.rn.f64 	%fd1087, %fd319, %fd1086;
	mul.rn.f64 	%fd1088, %fd188, %fd187;
	mul.rn.f64 	%fd330, %fd1088, 0d3FB999999999999A;
	add.rn.f64 	%fd1089, %fd330, %fd1087;
	mul.rn.f64 	%fd1090, %fd190, 0d3FC999999999999A;
	add.rn.f64 	%fd1091, %fd1090, %fd1089;
	mul.rn.f64 	%fd1092, %fd318, 0d3FE5555555555555;
	add.rn.f64 	%fd331, %fd1092, %fd1091;
	add.rn.f64 	%fd1093, %fd187, %fd187;
	add.rn.f64 	%fd1094, %fd188, 0d4072C00000000000;
	add.rn.f64 	%fd332, %fd1094, %fd1093;
	{ // callseq 213, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd189;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1451, [retval0+0];
	} // callseq 213
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r81}, %fd188;
	}
	setp.lt.s32 	%p208, %r81, 0;
	and.pred  	%p5, %p208, %p70;
	not.pred 	%p210, %p5;
	@%p210 bra 	$L__BB15_224;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r349}, %fd1451;
	}
	xor.b32  	%r350, %r349, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r351, %temp}, %fd1451;
	}
	mov.b64 	%fd1451, {%r351, %r350};

$L__BB15_224:
	setp.eq.f64 	%p211, %fd188, 0d0000000000000000;
	@%p211 bra 	$L__BB15_228;
	bra.uni 	$L__BB15_225;

$L__BB15_228:
	setp.lt.s32 	%p214, %r32, 0;
	mov.u32 	%r352, 0;
	selp.b32 	%r353, %r81, 0, %p70;
	or.b32  	%r354, %r353, 2146435072;
	selp.b32 	%r355, %r354, %r353, %p214;
	mov.b64 	%fd1451, {%r352, %r355};
	bra.uni 	$L__BB15_229;

$L__BB15_225:
	setp.gt.s32 	%p212, %r81, -1;
	@%p212 bra 	$L__BB15_229;

	mov.f64 	%fd1095, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1096, %fd1095;
	setp.eq.f64 	%p213, %fd1096, 0d4000000000000000;
	@%p213 bra 	$L__BB15_229;

	mov.f64 	%fd1451, 0dFFF8000000000000;

$L__BB15_229:
	add.rn.f64 	%fd1098, %fd188, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r356}, %fd1098;
	}
	and.b32  	%r357, %r356, 2146435072;
	setp.ne.s32 	%p216, %r357, 2146435072;
	@%p216 bra 	$L__BB15_236;

	setp.gtu.f64 	%p217, %fd189, 0d7FF0000000000000;
	@%p217 bra 	$L__BB15_235;
	bra.uni 	$L__BB15_231;

$L__BB15_235:
	mov.f64 	%fd1100, 0d4000000000000000;
	add.rn.f64 	%fd1451, %fd188, %fd1100;
	bra.uni 	$L__BB15_236;

$L__BB15_231:
	setp.eq.s32 	%p218, %r46, 2146435072;
	mov.f64 	%fd1099, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r358, %temp}, %fd1099;
	}
	setp.eq.s32 	%p219, %r358, 0;
	and.pred  	%p220, %p218, %p219;
	@%p220 bra 	$L__BB15_234;
	bra.uni 	$L__BB15_232;

$L__BB15_234:
	setp.lt.s32 	%p226, %r32, 0;
	mov.u32 	%r363, 0;
	setp.gt.f64 	%p227, %fd189, 0d3FF0000000000000;
	selp.b32 	%r364, 2146435072, 0, %p227;
	xor.b32  	%r365, %r364, 2146435072;
	selp.b32 	%r366, %r365, %r364, %p226;
	setp.eq.f64 	%p228, %fd188, 0dBFF0000000000000;
	selp.b32 	%r367, 1072693248, %r366, %p228;
	mov.b64 	%fd1451, {%r363, %r367};
	bra.uni 	$L__BB15_236;

$L__BB15_232:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd188;
	}
	and.b32  	%r360, %r81, 2147483647;
	setp.ne.s32 	%p221, %r360, 2146435072;
	setp.ne.s32 	%p222, %r359, 0;
	or.pred  	%p223, %p221, %p222;
	@%p223 bra 	$L__BB15_236;

	setp.ne.s32 	%p224, %r46, 1071644672;
	and.pred  	%p225, %p224, %p5;
	selp.b32 	%r361, %r48, %r47, %p225;
	mov.u32 	%r362, 0;
	mov.b64 	%fd1451, {%r362, %r361};

$L__BB15_236:
	mul.rn.f64 	%fd1101, %fd1451, 0d3FB999999999999A;
	setp.eq.f64 	%p229, %fd188, 0d3FF0000000000000;
	selp.f64 	%fd1102, 0d3FB999999999999A, %fd1101, %p229;
	add.rn.f64 	%fd1103, %fd332, %fd1102;
	add.rn.f64 	%fd1104, %fd330, %fd1103;
	mul.rn.f64 	%fd1105, %fd190, 0d3FB999999999999A;
	add.rn.f64 	%fd1106, %fd1105, %fd1104;
	mul.rn.f64 	%fd1107, %fd317, 0d3FE5555555555555;
	add.rn.f64 	%fd342, %fd1107, %fd1106;
	div.rn.f64 	%fd1108, %fd1481, 0d4066800000000000;
	mul.rn.f64 	%fd343, %fd1108, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r368, %temp}, %fd343;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r369}, %fd343;
	}
	and.b32  	%r370, %r369, 2147483647;
	setp.eq.s32 	%p230, %r370, 2146435072;
	setp.eq.s32 	%p231, %r368, 0;
	and.pred  	%p6, %p231, %p230;
	@%p6 bra 	$L__BB15_239;
	bra.uni 	$L__BB15_237;

$L__BB15_239:
	mov.f64 	%fd1118, 0d0000000000000000;
	mul.rn.f64 	%fd1452, %fd343, %fd1118;
	mov.u32 	%r503, 0;
	bra.uni 	$L__BB15_240;

$L__BB15_237:
	mul.rn.f64 	%fd1109, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r503, %fd1109;
	st.local.u32 	[%rd1], %r503;
	cvt.rn.f64.s32 	%fd1110, %r503;
	neg.f64 	%fd1111, %fd1110;
	mov.f64 	%fd1112, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1113, %fd1111, %fd1112, %fd343;
	mov.f64 	%fd1114, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1115, %fd1111, %fd1114, %fd1113;
	mov.f64 	%fd1116, 0d397B839A252049C0;
	fma.rn.f64 	%fd1452, %fd1111, %fd1116, %fd1115;
	abs.f64 	%fd1117, %fd343;
	setp.ltu.f64 	%p232, %fd1117, 0d41E0000000000000;
	@%p232 bra 	$L__BB15_240;

	{ // callseq 214, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1452, [retval0+0];
	} // callseq 214
	ld.local.u32 	%r503, [%rd1];

$L__BB15_240:
	and.b32  	%r372, %r503, 1;
	shl.b32 	%r373, %r503, 3;
	and.b32  	%r374, %r373, 8;
	setp.eq.s32 	%p233, %r372, 0;
	selp.f64 	%fd1119, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p233;
	mul.wide.s32 	%rd159, %r374, 8;
	add.s64 	%rd161, %rd72, %rd159;
	ld.global.nc.f64 	%fd1120, [%rd161+8];
	mul.rn.f64 	%fd348, %fd1452, %fd1452;
	fma.rn.f64 	%fd1121, %fd1119, %fd348, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd161+16];
	fma.rn.f64 	%fd1123, %fd1121, %fd348, %fd1122;
	ld.global.nc.f64 	%fd1124, [%rd161+24];
	fma.rn.f64 	%fd1125, %fd1123, %fd348, %fd1124;
	ld.global.nc.f64 	%fd1126, [%rd161+32];
	fma.rn.f64 	%fd1127, %fd1125, %fd348, %fd1126;
	ld.global.nc.f64 	%fd1128, [%rd161+40];
	fma.rn.f64 	%fd1129, %fd1127, %fd348, %fd1128;
	ld.global.nc.f64 	%fd1130, [%rd161+48];
	fma.rn.f64 	%fd349, %fd1129, %fd348, %fd1130;
	fma.rn.f64 	%fd1454, %fd349, %fd1452, %fd1452;
	@%p233 bra 	$L__BB15_242;

	mov.f64 	%fd1131, 0d3FF0000000000000;
	fma.rn.f64 	%fd1454, %fd349, %fd348, %fd1131;

$L__BB15_242:
	and.b32  	%r375, %r503, 2;
	setp.eq.s32 	%p234, %r375, 0;
	@%p234 bra 	$L__BB15_244;

	mov.f64 	%fd1132, 0d0000000000000000;
	mov.f64 	%fd1133, 0dBFF0000000000000;
	fma.rn.f64 	%fd1454, %fd1454, %fd1133, %fd1132;

$L__BB15_244:
	@%p6 bra 	$L__BB15_248;
	bra.uni 	$L__BB15_245;

$L__BB15_248:
	mov.f64 	%fd1143, 0d0000000000000000;
	mul.rn.f64 	%fd1456, %fd343, %fd1143;
	mov.u32 	%r505, 1;
	bra.uni 	$L__BB15_249;

$L__BB15_245:
	mul.rn.f64 	%fd1134, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r504, %fd1134;
	st.local.u32 	[%rd1], %r504;
	cvt.rn.f64.s32 	%fd1135, %r504;
	neg.f64 	%fd1136, %fd1135;
	mov.f64 	%fd1137, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1138, %fd1136, %fd1137, %fd343;
	mov.f64 	%fd1139, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1140, %fd1136, %fd1139, %fd1138;
	mov.f64 	%fd1141, 0d397B839A252049C0;
	fma.rn.f64 	%fd1456, %fd1136, %fd1141, %fd1140;
	abs.f64 	%fd1142, %fd343;
	setp.ltu.f64 	%p235, %fd1142, 0d41E0000000000000;
	@%p235 bra 	$L__BB15_247;

	{ // callseq 215, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1456, [retval0+0];
	} // callseq 215
	ld.local.u32 	%r504, [%rd1];

$L__BB15_247:
	add.s32 	%r505, %r504, 1;

$L__BB15_249:
	and.b32  	%r377, %r505, 1;
	shl.b32 	%r378, %r505, 3;
	and.b32  	%r379, %r378, 8;
	setp.eq.s32 	%p236, %r377, 0;
	selp.f64 	%fd1144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p236;
	mul.wide.s32 	%rd163, %r379, 8;
	add.s64 	%rd165, %rd72, %rd163;
	ld.global.nc.f64 	%fd1145, [%rd165+8];
	mul.rn.f64 	%fd360, %fd1456, %fd1456;
	fma.rn.f64 	%fd1146, %fd1144, %fd360, %fd1145;
	ld.global.nc.f64 	%fd1147, [%rd165+16];
	fma.rn.f64 	%fd1148, %fd1146, %fd360, %fd1147;
	ld.global.nc.f64 	%fd1149, [%rd165+24];
	fma.rn.f64 	%fd1150, %fd1148, %fd360, %fd1149;
	ld.global.nc.f64 	%fd1151, [%rd165+32];
	fma.rn.f64 	%fd1152, %fd1150, %fd360, %fd1151;
	ld.global.nc.f64 	%fd1153, [%rd165+40];
	fma.rn.f64 	%fd1154, %fd1152, %fd360, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd165+48];
	fma.rn.f64 	%fd361, %fd1154, %fd360, %fd1155;
	fma.rn.f64 	%fd1458, %fd361, %fd1456, %fd1456;
	@%p236 bra 	$L__BB15_251;

	mov.f64 	%fd1156, 0d3FF0000000000000;
	fma.rn.f64 	%fd1458, %fd361, %fd360, %fd1156;

$L__BB15_251:
	and.b32  	%r380, %r505, 2;
	setp.eq.s32 	%p237, %r380, 0;
	@%p237 bra 	$L__BB15_253;

	mov.f64 	%fd1157, 0d0000000000000000;
	mov.f64 	%fd1158, 0dBFF0000000000000;
	fma.rn.f64 	%fd1458, %fd1458, %fd1158, %fd1157;

$L__BB15_253:
	ld.param.s8 	%rs2, [gcj02_to_wgs84_exact_cuda_double_param_4];
	mul.rn.f64 	%fd1159, %fd1454, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1160, %fd1454, %fd1159;
	add.rn.f64 	%fd1161, %fd1160, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1162, %fd1161;
	mov.f64 	%fd1163, 0d415854C140000000;
	div.rn.f64 	%fd1164, %fd1163, %fd1162;
	mul.rn.f64 	%fd1165, %fd1164, %fd1458;
	mul.rn.f64 	%fd1166, %fd1165, 0d400921FB54442D18;
	mul.rn.f64 	%fd1167, %fd342, 0d4066800000000000;
	div.rn.f64 	%fd1168, %fd1167, %fd1166;
	add.rn.f64 	%fd1169, %fd1480, %fd1168;
	sub.rn.f64 	%fd367, %fd1, %fd1169;
	mul.rn.f64 	%fd1170, %fd331, 0d4066800000000000;
	mul.rn.f64 	%fd1171, %fd1162, %fd1161;
	mov.f64 	%fd1172, 0d41582B102DE355C1;
	div.rn.f64 	%fd1173, %fd1172, %fd1171;
	mul.rn.f64 	%fd1174, %fd1173, 0d400921FB54442D18;
	div.rn.f64 	%fd1175, %fd1170, %fd1174;
	add.rn.f64 	%fd1176, %fd1481, %fd1175;
	sub.rn.f64 	%fd368, %fd3, %fd1176;
	add.rn.f64 	%fd1415, %fd1480, %fd367;
	add.rn.f64 	%fd1414, %fd1481, %fd368;
	setp.eq.s16 	%p238, %rs2, 0;
	@%p238 bra 	$L__BB15_322;

	mul.rn.f64 	%fd1177, %fd1481, 0d400921FB54442D18;
	div.rn.f64 	%fd371, %fd1177, 0d4066800000000000;
	mul.rn.f64 	%fd1178, %fd1414, 0d400921FB54442D18;
	div.rn.f64 	%fd372, %fd1178, 0d4066800000000000;
	sub.rn.f64 	%fd1179, %fd372, %fd371;
	mul.rn.f64 	%fd373, %fd1179, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r381, %temp}, %fd373;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r382}, %fd373;
	}
	and.b32  	%r383, %r382, 2147483647;
	setp.eq.s32 	%p239, %r383, 2146435072;
	setp.eq.s32 	%p240, %r381, 0;
	and.pred  	%p241, %p240, %p239;
	@%p241 bra 	$L__BB15_257;
	bra.uni 	$L__BB15_255;

$L__BB15_257:
	mov.f64 	%fd1189, 0d0000000000000000;
	mul.rn.f64 	%fd1459, %fd373, %fd1189;
	mov.u32 	%r506, 0;
	bra.uni 	$L__BB15_258;

$L__BB15_322:
	abs.f64 	%fd1357, %fd367;
	setp.geu.f64 	%p319, %fd1357, %fd453;
	@%p319 bra 	$L__BB15_324;

	abs.f64 	%fd1358, %fd368;
	setp.lt.f64 	%p320, %fd1358, %fd453;
	@%p320 bra 	$L__BB15_325;
	bra.uni 	$L__BB15_324;

$L__BB15_255:
	mul.rn.f64 	%fd1180, %fd373, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r506, %fd1180;
	st.local.u32 	[%rd1], %r506;
	cvt.rn.f64.s32 	%fd1181, %r506;
	neg.f64 	%fd1182, %fd1181;
	mov.f64 	%fd1183, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1184, %fd1182, %fd1183, %fd373;
	mov.f64 	%fd1185, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1186, %fd1182, %fd1185, %fd1184;
	mov.f64 	%fd1187, 0d397B839A252049C0;
	fma.rn.f64 	%fd1459, %fd1182, %fd1187, %fd1186;
	abs.f64 	%fd1188, %fd373;
	setp.ltu.f64 	%p242, %fd1188, 0d41E0000000000000;
	@%p242 bra 	$L__BB15_258;

	{ // callseq 216, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd373;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1459, [retval0+0];
	} // callseq 216
	ld.local.u32 	%r506, [%rd1];

$L__BB15_258:
	and.b32  	%r385, %r506, 1;
	shl.b32 	%r386, %r506, 3;
	and.b32  	%r387, %r386, 8;
	setp.eq.s32 	%p243, %r385, 0;
	selp.f64 	%fd1190, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p243;
	mul.wide.s32 	%rd167, %r387, 8;
	add.s64 	%rd169, %rd72, %rd167;
	ld.global.nc.f64 	%fd1191, [%rd169+8];
	mul.rn.f64 	%fd378, %fd1459, %fd1459;
	fma.rn.f64 	%fd1192, %fd1190, %fd378, %fd1191;
	ld.global.nc.f64 	%fd1193, [%rd169+16];
	fma.rn.f64 	%fd1194, %fd1192, %fd378, %fd1193;
	ld.global.nc.f64 	%fd1195, [%rd169+24];
	fma.rn.f64 	%fd1196, %fd1194, %fd378, %fd1195;
	ld.global.nc.f64 	%fd1197, [%rd169+32];
	fma.rn.f64 	%fd1198, %fd1196, %fd378, %fd1197;
	ld.global.nc.f64 	%fd1199, [%rd169+40];
	fma.rn.f64 	%fd1200, %fd1198, %fd378, %fd1199;
	ld.global.nc.f64 	%fd1201, [%rd169+48];
	fma.rn.f64 	%fd379, %fd1200, %fd378, %fd1201;
	fma.rn.f64 	%fd1461, %fd379, %fd1459, %fd1459;
	@%p243 bra 	$L__BB15_260;

	mov.f64 	%fd1202, 0d3FF0000000000000;
	fma.rn.f64 	%fd1461, %fd379, %fd378, %fd1202;

$L__BB15_260:
	and.b32  	%r388, %r506, 2;
	setp.eq.s32 	%p244, %r388, 0;
	@%p244 bra 	$L__BB15_262;

	mov.f64 	%fd1203, 0d0000000000000000;
	mov.f64 	%fd1204, 0dBFF0000000000000;
	fma.rn.f64 	%fd1461, %fd1461, %fd1204, %fd1203;

$L__BB15_262:
	abs.f64 	%fd385, %fd1461;
	{ // callseq 217, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd385;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1464, [retval0+0];
	} // callseq 217
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r93}, %fd1461;
	}
	setp.lt.s32 	%p245, %r93, 0;
	and.pred  	%p7, %p245, %p70;
	not.pred 	%p247, %p7;
	@%p247 bra 	$L__BB15_264;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r389}, %fd1464;
	}
	xor.b32  	%r390, %r389, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r391, %temp}, %fd1464;
	}
	mov.b64 	%fd1464, {%r391, %r390};

$L__BB15_264:
	setp.eq.f64 	%p248, %fd1461, 0d0000000000000000;
	@%p248 bra 	$L__BB15_268;
	bra.uni 	$L__BB15_265;

$L__BB15_268:
	setp.lt.s32 	%p251, %r32, 0;
	mov.u32 	%r392, 0;
	selp.b32 	%r393, %r93, 0, %p70;
	or.b32  	%r394, %r393, 2146435072;
	selp.b32 	%r395, %r394, %r393, %p251;
	mov.b64 	%fd1464, {%r392, %r395};
	bra.uni 	$L__BB15_269;

$L__BB15_265:
	setp.gt.s32 	%p249, %r93, -1;
	@%p249 bra 	$L__BB15_269;

	mov.f64 	%fd1205, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1206, %fd1205;
	setp.eq.f64 	%p250, %fd1206, 0d4000000000000000;
	@%p250 bra 	$L__BB15_269;

	mov.f64 	%fd1464, 0dFFF8000000000000;

$L__BB15_269:
	add.rn.f64 	%fd1208, %fd1461, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r396}, %fd1208;
	}
	and.b32  	%r397, %r396, 2146435072;
	setp.ne.s32 	%p253, %r397, 2146435072;
	@%p253 bra 	$L__BB15_276;

	setp.gtu.f64 	%p254, %fd385, 0d7FF0000000000000;
	@%p254 bra 	$L__BB15_275;
	bra.uni 	$L__BB15_271;

$L__BB15_275:
	mov.f64 	%fd1210, 0d4000000000000000;
	add.rn.f64 	%fd1464, %fd1461, %fd1210;
	bra.uni 	$L__BB15_276;

$L__BB15_271:
	setp.eq.s32 	%p255, %r46, 2146435072;
	mov.f64 	%fd1209, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r398, %temp}, %fd1209;
	}
	setp.eq.s32 	%p256, %r398, 0;
	and.pred  	%p257, %p255, %p256;
	@%p257 bra 	$L__BB15_274;
	bra.uni 	$L__BB15_272;

$L__BB15_274:
	setp.lt.s32 	%p263, %r32, 0;
	mov.u32 	%r403, 0;
	setp.gt.f64 	%p264, %fd385, 0d3FF0000000000000;
	selp.b32 	%r404, 2146435072, 0, %p264;
	xor.b32  	%r405, %r404, 2146435072;
	selp.b32 	%r406, %r405, %r404, %p263;
	setp.eq.f64 	%p265, %fd1461, 0dBFF0000000000000;
	selp.b32 	%r407, 1072693248, %r406, %p265;
	mov.b64 	%fd1464, {%r403, %r407};
	bra.uni 	$L__BB15_276;

$L__BB15_272:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r399, %temp}, %fd1461;
	}
	and.b32  	%r400, %r93, 2147483647;
	setp.ne.s32 	%p258, %r400, 2146435072;
	setp.ne.s32 	%p259, %r399, 0;
	or.pred  	%p260, %p258, %p259;
	@%p260 bra 	$L__BB15_276;

	setp.ne.s32 	%p261, %r46, 1071644672;
	and.pred  	%p262, %p261, %p7;
	selp.b32 	%r401, %r48, %r47, %p262;
	mov.u32 	%r402, 0;
	mov.b64 	%fd1464, {%r402, %r401};

$L__BB15_276:
	setp.eq.f64 	%p266, %fd1461, 0d3FF0000000000000;
	selp.f64 	%fd395, 0d3FF0000000000000, %fd1464, %p266;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r408}, %fd371;
	}
	and.b32  	%r409, %r408, 2147483647;
	setp.eq.s32 	%p267, %r409, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r410, %temp}, %fd371;
	}
	setp.eq.s32 	%p268, %r410, 0;
	and.pred  	%p269, %p268, %p267;
	@%p269 bra 	$L__BB15_280;
	bra.uni 	$L__BB15_277;

$L__BB15_280:
	mov.f64 	%fd1220, 0d0000000000000000;
	mul.rn.f64 	%fd1466, %fd371, %fd1220;
	mov.u32 	%r508, 1;
	bra.uni 	$L__BB15_281;

$L__BB15_277:
	mul.rn.f64 	%fd1211, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r507, %fd1211;
	st.local.u32 	[%rd1], %r507;
	cvt.rn.f64.s32 	%fd1212, %r507;
	neg.f64 	%fd1213, %fd1212;
	mov.f64 	%fd1214, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1215, %fd1213, %fd1214, %fd371;
	mov.f64 	%fd1216, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1217, %fd1213, %fd1216, %fd1215;
	mov.f64 	%fd1218, 0d397B839A252049C0;
	fma.rn.f64 	%fd1466, %fd1213, %fd1218, %fd1217;
	abs.f64 	%fd1219, %fd371;
	setp.ltu.f64 	%p270, %fd1219, 0d41E0000000000000;
	@%p270 bra 	$L__BB15_279;

	{ // callseq 218, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1466, [retval0+0];
	} // callseq 218
	ld.local.u32 	%r507, [%rd1];

$L__BB15_279:
	add.s32 	%r508, %r507, 1;

$L__BB15_281:
	and.b32  	%r412, %r508, 1;
	shl.b32 	%r413, %r508, 3;
	and.b32  	%r414, %r413, 8;
	setp.eq.s32 	%p271, %r412, 0;
	selp.f64 	%fd1221, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p271;
	mul.wide.s32 	%rd171, %r414, 8;
	add.s64 	%rd173, %rd72, %rd171;
	ld.global.nc.f64 	%fd1222, [%rd173+8];
	mul.rn.f64 	%fd401, %fd1466, %fd1466;
	fma.rn.f64 	%fd1223, %fd1221, %fd401, %fd1222;
	ld.global.nc.f64 	%fd1224, [%rd173+16];
	fma.rn.f64 	%fd1225, %fd1223, %fd401, %fd1224;
	ld.global.nc.f64 	%fd1226, [%rd173+24];
	fma.rn.f64 	%fd1227, %fd1225, %fd401, %fd1226;
	ld.global.nc.f64 	%fd1228, [%rd173+32];
	fma.rn.f64 	%fd1229, %fd1227, %fd401, %fd1228;
	ld.global.nc.f64 	%fd1230, [%rd173+40];
	fma.rn.f64 	%fd1231, %fd1229, %fd401, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd173+48];
	fma.rn.f64 	%fd402, %fd1231, %fd401, %fd1232;
	fma.rn.f64 	%fd1468, %fd402, %fd1466, %fd1466;
	@%p271 bra 	$L__BB15_283;

	mov.f64 	%fd1233, 0d3FF0000000000000;
	fma.rn.f64 	%fd1468, %fd402, %fd401, %fd1233;

$L__BB15_283:
	and.b32  	%r415, %r508, 2;
	setp.eq.s32 	%p272, %r415, 0;
	@%p272 bra 	$L__BB15_285;

	mov.f64 	%fd1234, 0d0000000000000000;
	mov.f64 	%fd1235, 0dBFF0000000000000;
	fma.rn.f64 	%fd1468, %fd1468, %fd1235, %fd1234;

$L__BB15_285:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r416}, %fd372;
	}
	and.b32  	%r417, %r416, 2147483647;
	setp.eq.s32 	%p273, %r417, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r418, %temp}, %fd372;
	}
	setp.eq.s32 	%p274, %r418, 0;
	and.pred  	%p275, %p274, %p273;
	@%p275 bra 	$L__BB15_289;
	bra.uni 	$L__BB15_286;

$L__BB15_289:
	mov.f64 	%fd1245, 0d0000000000000000;
	mul.rn.f64 	%fd1470, %fd372, %fd1245;
	mov.u32 	%r510, 1;
	bra.uni 	$L__BB15_290;

$L__BB15_286:
	mul.rn.f64 	%fd1236, %fd372, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r509, %fd1236;
	st.local.u32 	[%rd1], %r509;
	cvt.rn.f64.s32 	%fd1237, %r509;
	neg.f64 	%fd1238, %fd1237;
	mov.f64 	%fd1239, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1240, %fd1238, %fd1239, %fd372;
	mov.f64 	%fd1241, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1242, %fd1238, %fd1241, %fd1240;
	mov.f64 	%fd1243, 0d397B839A252049C0;
	fma.rn.f64 	%fd1470, %fd1238, %fd1243, %fd1242;
	abs.f64 	%fd1244, %fd372;
	setp.ltu.f64 	%p276, %fd1244, 0d41E0000000000000;
	@%p276 bra 	$L__BB15_288;

	{ // callseq 219, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd372;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1470, [retval0+0];
	} // callseq 219
	ld.local.u32 	%r509, [%rd1];

$L__BB15_288:
	add.s32 	%r510, %r509, 1;

$L__BB15_290:
	and.b32  	%r420, %r510, 1;
	shl.b32 	%r421, %r510, 3;
	and.b32  	%r422, %r421, 8;
	setp.eq.s32 	%p277, %r420, 0;
	selp.f64 	%fd1246, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p277;
	mul.wide.s32 	%rd175, %r422, 8;
	add.s64 	%rd177, %rd72, %rd175;
	ld.global.nc.f64 	%fd1247, [%rd177+8];
	mul.rn.f64 	%fd413, %fd1470, %fd1470;
	fma.rn.f64 	%fd1248, %fd1246, %fd413, %fd1247;
	ld.global.nc.f64 	%fd1249, [%rd177+16];
	fma.rn.f64 	%fd1250, %fd1248, %fd413, %fd1249;
	ld.global.nc.f64 	%fd1251, [%rd177+24];
	fma.rn.f64 	%fd1252, %fd1250, %fd413, %fd1251;
	ld.global.nc.f64 	%fd1253, [%rd177+32];
	fma.rn.f64 	%fd1254, %fd1252, %fd413, %fd1253;
	ld.global.nc.f64 	%fd1255, [%rd177+40];
	fma.rn.f64 	%fd1256, %fd1254, %fd413, %fd1255;
	ld.global.nc.f64 	%fd1257, [%rd177+48];
	fma.rn.f64 	%fd414, %fd1256, %fd413, %fd1257;
	fma.rn.f64 	%fd1472, %fd414, %fd1470, %fd1470;
	@%p277 bra 	$L__BB15_292;

	mov.f64 	%fd1258, 0d3FF0000000000000;
	fma.rn.f64 	%fd1472, %fd414, %fd413, %fd1258;

$L__BB15_292:
	and.b32  	%r423, %r510, 2;
	setp.eq.s32 	%p278, %r423, 0;
	@%p278 bra 	$L__BB15_294;

	mov.f64 	%fd1259, 0d0000000000000000;
	mov.f64 	%fd1260, 0dBFF0000000000000;
	fma.rn.f64 	%fd1472, %fd1472, %fd1260, %fd1259;

$L__BB15_294:
	mul.rn.f64 	%fd420, %fd1468, %fd1472;
	mul.rn.f64 	%fd1261, %fd1480, 0d400921FB54442D18;
	div.rn.f64 	%fd1262, %fd1261, 0d4066800000000000;
	mul.rn.f64 	%fd1263, %fd1415, 0d400921FB54442D18;
	div.rn.f64 	%fd1264, %fd1263, 0d4066800000000000;
	sub.rn.f64 	%fd1265, %fd1264, %fd1262;
	mul.rn.f64 	%fd421, %fd1265, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r424, %temp}, %fd421;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r425}, %fd421;
	}
	and.b32  	%r426, %r425, 2147483647;
	setp.eq.s32 	%p279, %r426, 2146435072;
	setp.eq.s32 	%p280, %r424, 0;
	and.pred  	%p281, %p280, %p279;
	@%p281 bra 	$L__BB15_297;
	bra.uni 	$L__BB15_295;

$L__BB15_297:
	mov.f64 	%fd1275, 0d0000000000000000;
	mul.rn.f64 	%fd1473, %fd421, %fd1275;
	mov.u32 	%r511, 0;
	bra.uni 	$L__BB15_298;

$L__BB15_295:
	mul.rn.f64 	%fd1266, %fd421, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r511, %fd1266;
	st.local.u32 	[%rd1], %r511;
	cvt.rn.f64.s32 	%fd1267, %r511;
	neg.f64 	%fd1268, %fd1267;
	mov.f64 	%fd1269, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1270, %fd1268, %fd1269, %fd421;
	mov.f64 	%fd1271, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1272, %fd1268, %fd1271, %fd1270;
	mov.f64 	%fd1273, 0d397B839A252049C0;
	fma.rn.f64 	%fd1473, %fd1268, %fd1273, %fd1272;
	abs.f64 	%fd1274, %fd421;
	setp.ltu.f64 	%p282, %fd1274, 0d41E0000000000000;
	@%p282 bra 	$L__BB15_298;

	{ // callseq 220, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd421;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd35;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1473, [retval0+0];
	} // callseq 220
	ld.local.u32 	%r511, [%rd1];

$L__BB15_298:
	and.b32  	%r428, %r511, 1;
	shl.b32 	%r429, %r511, 3;
	and.b32  	%r430, %r429, 8;
	setp.eq.s32 	%p283, %r428, 0;
	selp.f64 	%fd1276, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p283;
	mul.wide.s32 	%rd179, %r430, 8;
	add.s64 	%rd181, %rd72, %rd179;
	ld.global.nc.f64 	%fd1277, [%rd181+8];
	mul.rn.f64 	%fd426, %fd1473, %fd1473;
	fma.rn.f64 	%fd1278, %fd1276, %fd426, %fd1277;
	ld.global.nc.f64 	%fd1279, [%rd181+16];
	fma.rn.f64 	%fd1280, %fd1278, %fd426, %fd1279;
	ld.global.nc.f64 	%fd1281, [%rd181+24];
	fma.rn.f64 	%fd1282, %fd1280, %fd426, %fd1281;
	ld.global.nc.f64 	%fd1283, [%rd181+32];
	fma.rn.f64 	%fd1284, %fd1282, %fd426, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd181+40];
	fma.rn.f64 	%fd1286, %fd1284, %fd426, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd181+48];
	fma.rn.f64 	%fd427, %fd1286, %fd426, %fd1287;
	fma.rn.f64 	%fd1475, %fd427, %fd1473, %fd1473;
	@%p283 bra 	$L__BB15_300;

	mov.f64 	%fd1288, 0d3FF0000000000000;
	fma.rn.f64 	%fd1475, %fd427, %fd426, %fd1288;

$L__BB15_300:
	and.b32  	%r431, %r511, 2;
	setp.eq.s32 	%p284, %r431, 0;
	@%p284 bra 	$L__BB15_302;

	mov.f64 	%fd1289, 0d0000000000000000;
	mov.f64 	%fd1290, 0dBFF0000000000000;
	fma.rn.f64 	%fd1475, %fd1475, %fd1290, %fd1289;

$L__BB15_302:
	abs.f64 	%fd433, %fd1475;
	{ // callseq 221, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd433;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1478, [retval0+0];
	} // callseq 221
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r107}, %fd1475;
	}
	setp.lt.s32 	%p285, %r107, 0;
	and.pred  	%p8, %p285, %p70;
	not.pred 	%p287, %p8;
	@%p287 bra 	$L__BB15_304;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r432}, %fd1478;
	}
	xor.b32  	%r433, %r432, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r434, %temp}, %fd1478;
	}
	mov.b64 	%fd1478, {%r434, %r433};

$L__BB15_304:
	setp.eq.f64 	%p288, %fd1475, 0d0000000000000000;
	@%p288 bra 	$L__BB15_308;
	bra.uni 	$L__BB15_305;

$L__BB15_308:
	setp.lt.s32 	%p291, %r32, 0;
	mov.u32 	%r435, 0;
	selp.b32 	%r436, %r107, 0, %p70;
	or.b32  	%r437, %r436, 2146435072;
	selp.b32 	%r438, %r437, %r436, %p291;
	mov.b64 	%fd1478, {%r435, %r438};
	bra.uni 	$L__BB15_309;

$L__BB15_305:
	setp.gt.s32 	%p289, %r107, -1;
	@%p289 bra 	$L__BB15_309;

	mov.f64 	%fd1291, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1292, %fd1291;
	setp.eq.f64 	%p290, %fd1292, 0d4000000000000000;
	@%p290 bra 	$L__BB15_309;

	mov.f64 	%fd1478, 0dFFF8000000000000;

$L__BB15_309:
	add.rn.f64 	%fd1294, %fd1475, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r439}, %fd1294;
	}
	and.b32  	%r440, %r439, 2146435072;
	setp.ne.s32 	%p293, %r440, 2146435072;
	@%p293 bra 	$L__BB15_316;

	setp.gtu.f64 	%p294, %fd433, 0d7FF0000000000000;
	@%p294 bra 	$L__BB15_315;
	bra.uni 	$L__BB15_311;

$L__BB15_315:
	mov.f64 	%fd1296, 0d4000000000000000;
	add.rn.f64 	%fd1478, %fd1475, %fd1296;
	bra.uni 	$L__BB15_316;

$L__BB15_311:
	setp.eq.s32 	%p295, %r46, 2146435072;
	mov.f64 	%fd1295, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd1295;
	}
	setp.eq.s32 	%p296, %r441, 0;
	and.pred  	%p297, %p295, %p296;
	@%p297 bra 	$L__BB15_314;
	bra.uni 	$L__BB15_312;

$L__BB15_314:
	setp.lt.s32 	%p303, %r32, 0;
	mov.u32 	%r446, 0;
	setp.gt.f64 	%p304, %fd433, 0d3FF0000000000000;
	selp.b32 	%r447, 2146435072, 0, %p304;
	xor.b32  	%r448, %r447, 2146435072;
	selp.b32 	%r449, %r448, %r447, %p303;
	setp.eq.f64 	%p305, %fd1475, 0dBFF0000000000000;
	selp.b32 	%r450, 1072693248, %r449, %p305;
	mov.b64 	%fd1478, {%r446, %r450};
	bra.uni 	$L__BB15_316;

$L__BB15_312:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r442, %temp}, %fd1475;
	}
	and.b32  	%r443, %r107, 2147483647;
	setp.ne.s32 	%p298, %r443, 2146435072;
	setp.ne.s32 	%p299, %r442, 0;
	or.pred  	%p300, %p298, %p299;
	@%p300 bra 	$L__BB15_316;

	setp.ne.s32 	%p301, %r46, 1071644672;
	and.pred  	%p302, %p301, %p8;
	selp.b32 	%r444, %r48, %r47, %p302;
	mov.u32 	%r445, 0;
	mov.b64 	%fd1478, {%r445, %r444};

$L__BB15_316:
	setp.eq.f64 	%p306, %fd1475, 0d3FF0000000000000;
	mov.f64 	%fd1297, 0d3FF0000000000000;
	selp.f64 	%fd1298, 0d3FF0000000000000, %fd1478, %p306;
	mul.rn.f64 	%fd1299, %fd420, %fd1298;
	add.rn.f64 	%fd1300, %fd395, %fd1299;
	sqrt.rn.f64 	%fd443, %fd1300;
	sub.rn.f64 	%fd1301, %fd1297, %fd1300;
	sqrt.rn.f64 	%fd444, %fd1301;
	abs.f64 	%fd445, %fd444;
	abs.f64 	%fd446, %fd443;
	setp.eq.f64 	%p307, %fd445, 0d0000000000000000;
	setp.eq.f64 	%p308, %fd446, 0d0000000000000000;
	and.pred  	%p309, %p307, %p308;
	@%p309 bra 	$L__BB15_320;
	bra.uni 	$L__BB15_317;

$L__BB15_320:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r463}, %fd444;
	}
	setp.lt.s32 	%p317, %r463, 0;
	selp.f64 	%fd1354, 0d400921FB54442D18, 0d0000000000000000, %p317;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r464, %temp}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r465}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r466}, %fd443;
	}
	and.b32  	%r467, %r466, -2147483648;
	or.b32  	%r468, %r465, %r467;
	mov.b64 	%fd1479, {%r464, %r468};
	bra.uni 	$L__BB15_321;

$L__BB15_317:
	setp.eq.f64 	%p310, %fd445, 0d7FF0000000000000;
	setp.eq.f64 	%p311, %fd446, 0d7FF0000000000000;
	and.pred  	%p312, %p310, %p311;
	@%p312 bra 	$L__BB15_319;
	bra.uni 	$L__BB15_318;

$L__BB15_319:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r457}, %fd444;
	}
	setp.lt.s32 	%p316, %r457, 0;
	selp.f64 	%fd1353, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p316;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r458, %temp}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r459}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r460}, %fd443;
	}
	and.b32  	%r461, %r460, -2147483648;
	or.b32  	%r462, %r459, %r461;
	mov.b64 	%fd1479, {%r458, %r462};
	bra.uni 	$L__BB15_321;

$L__BB15_318:
	max.f64 	%fd1302, %fd446, %fd445;
	min.f64 	%fd1303, %fd446, %fd445;
	div.rn.f64 	%fd1304, %fd1303, %fd1302;
	mul.rn.f64 	%fd1305, %fd1304, %fd1304;
	mov.f64 	%fd1306, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1307, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1308, %fd1307, %fd1305, %fd1306;
	mov.f64 	%fd1309, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1310, %fd1308, %fd1305, %fd1309;
	mov.f64 	%fd1311, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1312, %fd1310, %fd1305, %fd1311;
	mov.f64 	%fd1313, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1314, %fd1312, %fd1305, %fd1313;
	mov.f64 	%fd1315, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1316, %fd1314, %fd1305, %fd1315;
	mov.f64 	%fd1317, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1318, %fd1316, %fd1305, %fd1317;
	mov.f64 	%fd1319, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1320, %fd1318, %fd1305, %fd1319;
	mov.f64 	%fd1321, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1322, %fd1320, %fd1305, %fd1321;
	mov.f64 	%fd1323, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1324, %fd1322, %fd1305, %fd1323;
	mov.f64 	%fd1325, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1326, %fd1324, %fd1305, %fd1325;
	mov.f64 	%fd1327, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1328, %fd1326, %fd1305, %fd1327;
	mov.f64 	%fd1329, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1330, %fd1328, %fd1305, %fd1329;
	mov.f64 	%fd1331, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1332, %fd1330, %fd1305, %fd1331;
	mov.f64 	%fd1333, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1334, %fd1332, %fd1305, %fd1333;
	mov.f64 	%fd1335, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1336, %fd1334, %fd1305, %fd1335;
	mov.f64 	%fd1337, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1338, %fd1336, %fd1305, %fd1337;
	mov.f64 	%fd1339, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1340, %fd1338, %fd1305, %fd1339;
	mov.f64 	%fd1341, 0dBFD555555555544C;
	fma.rn.f64 	%fd1342, %fd1340, %fd1305, %fd1341;
	mul.rn.f64 	%fd1343, %fd1305, %fd1342;
	fma.rn.f64 	%fd1344, %fd1343, %fd1304, %fd1304;
	mov.f64 	%fd1345, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1346, %fd1345, %fd1344;
	setp.gt.f64 	%p313, %fd446, %fd445;
	selp.f64 	%fd1347, %fd1346, %fd1344, %p313;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r451}, %fd444;
	}
	setp.lt.s32 	%p314, %r451, 0;
	mov.f64 	%fd1348, 0d400921FB54442D18;
	sub.rn.f64 	%fd1349, %fd1348, %fd1347;
	selp.f64 	%fd1350, %fd1349, %fd1347, %p314;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r452, %temp}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r453}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r454}, %fd443;
	}
	and.b32  	%r455, %r454, -2147483648;
	or.b32  	%r456, %r453, %r455;
	mov.b64 	%fd1351, {%r452, %r456};
	add.rn.f64 	%fd1352, %fd445, %fd446;
	setp.le.f64 	%p315, %fd1352, 0d7FF0000000000000;
	selp.f64 	%fd1479, %fd1351, %fd1352, %p315;

$L__BB15_321:
	add.rn.f64 	%fd1355, %fd1479, %fd1479;
	mul.rn.f64 	%fd1356, %fd1355, 0d415854A640000000;
	setp.lt.f64 	%p318, %fd1356, %fd453;
	@%p318 bra 	$L__BB15_325;

$L__BB15_324:
	ld.param.u32 	%r469, [gcj02_to_wgs84_exact_cuda_double_param_5];
	add.s32 	%r492, %r492, 1;
	setp.lt.s32 	%p321, %r492, %r469;
	mov.f64 	%fd1480, %fd1415;
	mov.f64 	%fd1481, %fd1414;
	@%p321 bra 	$L__BB15_128;

$L__BB15_325:
	ld.param.u64 	%rd189, [gcj02_to_wgs84_exact_cuda_double_param_7];
	mov.u32 	%r478, %tid.x;
	mov.u32 	%r477, %ntid.x;
	mov.u32 	%r476, %ctaid.x;
	mad.lo.s32 	%r475, %r476, %r477, %r478;
	mul.wide.s32 	%rd188, %r475, 8;
	cvta.to.global.u64 	%rd187, %rd189;
	add.s64 	%rd186, %rd187, %rd188;
	ld.param.u64 	%rd185, [gcj02_to_wgs84_exact_cuda_double_param_6];
	mov.u32 	%r473, %tid.x;
	mov.u32 	%r472, %ntid.x;
	mov.u32 	%r471, %ctaid.x;
	mad.lo.s32 	%r470, %r471, %r472, %r473;
	mul.wide.s32 	%rd184, %r470, 8;
	cvta.to.global.u64 	%rd183, %rd185;
	add.s64 	%rd182, %rd183, %rd184;
	st.global.f64 	[%rd182], %fd1480;
	st.global.f64 	[%rd186], %fd1481;

$L__BB15_326:
	ret;

}
	// .globl	bd09_to_wgs84_exact_cuda_double
.visible .entry bd09_to_wgs84_exact_cuda_double(
	.param .u32 bd09_to_wgs84_exact_cuda_double_param_0,
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_1,
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_2,
	.param .f64 bd09_to_wgs84_exact_cuda_double_param_3,
	.param .u8 bd09_to_wgs84_exact_cuda_double_param_4,
	.param .u32 bd09_to_wgs84_exact_cuda_double_param_5,
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_6,
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_7
)
{
	.local .align 4 .b8 	__local_depot16[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<480>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<722>;
	.reg .f64 	%fd<2011>;
	.reg .b64 	%rd<238>;


	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r148, [bd09_to_wgs84_exact_cuda_double_param_0];
	ld.param.u64 	%rd39, [bd09_to_wgs84_exact_cuda_double_param_1];
	ld.param.u64 	%rd40, [bd09_to_wgs84_exact_cuda_double_param_2];
	ld.param.f64 	%fd610, [bd09_to_wgs84_exact_cuda_double_param_3];
	ld.param.u32 	%r147, [bd09_to_wgs84_exact_cuda_double_param_5];
	add.u64 	%rd43, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r149, %ntid.x;
	mov.u32 	%r150, %ctaid.x;
	mov.u32 	%r151, %tid.x;
	mad.lo.s32 	%r1, %r150, %r149, %r151;
	setp.ge.s32 	%p15, %r1, %r148;
	@%p15 bra 	$L__BB16_460;

	cvta.to.global.u64 	%rd79, %rd39;
	mul.wide.s32 	%rd80, %r1, 8;
	add.s64 	%rd81, %rd79, %rd80;
	cvta.to.global.u64 	%rd82, %rd40;
	add.s64 	%rd83, %rd82, %rd80;
	ld.global.f64 	%fd1, [%rd81];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd83];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd2;
	}
	mov.f64 	%fd611, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd611;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p16, %r4, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 222, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1860, [retval0+0];
	} // callseq 222
	setp.lt.s32 	%p17, %r2, 0;
	and.pred  	%p1, %p17, %p16;
	not.pred 	%p18, %p1;
	@%p18 bra 	$L__BB16_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r152}, %fd1860;
	}
	xor.b32  	%r153, %r152, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r154, %temp}, %fd1860;
	}
	mov.b64 	%fd1860, {%r154, %r153};

$L__BB16_3:
	setp.eq.f64 	%p19, %fd2, 0d0000000000000000;
	@%p19 bra 	$L__BB16_7;
	bra.uni 	$L__BB16_4;

$L__BB16_7:
	selp.b32 	%r155, %r2, 0, %p16;
	mov.u32 	%r156, 0;
	or.b32  	%r157, %r155, 2146435072;
	setp.lt.s32 	%p23, %r3, 0;
	selp.b32 	%r158, %r157, %r155, %p23;
	mov.b64 	%fd1860, {%r156, %r158};
	bra.uni 	$L__BB16_8;

$L__BB16_4:
	setp.gt.s32 	%p20, %r2, -1;
	@%p20 bra 	$L__BB16_8;

	mov.f64 	%fd612, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd613, %fd612;
	setp.eq.f64 	%p21, %fd613, 0d4000000000000000;
	@%p21 bra 	$L__BB16_8;

	mov.f64 	%fd1860, 0dFFF8000000000000;

$L__BB16_8:
	add.rn.f64 	%fd615, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r159}, %fd615;
	}
	and.b32  	%r160, %r159, 2146435072;
	setp.ne.s32 	%p24, %r160, 2146435072;
	@%p24 bra 	$L__BB16_15;

	setp.gtu.f64 	%p25, %fd5, 0d7FF0000000000000;
	@%p25 bra 	$L__BB16_14;
	bra.uni 	$L__BB16_10;

$L__BB16_14:
	mov.f64 	%fd617, 0d4000000000000000;
	add.rn.f64 	%fd1860, %fd2, %fd617;
	bra.uni 	$L__BB16_15;

$L__BB16_10:
	mov.f64 	%fd616, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd616;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p26, %r5, 2146435072;
	setp.eq.s32 	%p27, %r161, 0;
	and.pred  	%p28, %p26, %p27;
	@%p28 bra 	$L__BB16_13;
	bra.uni 	$L__BB16_11;

$L__BB16_13:
	setp.gt.f64 	%p35, %fd5, 0d3FF0000000000000;
	selp.b32 	%r168, 2146435072, 0, %p35;
	mov.u32 	%r169, 0;
	xor.b32  	%r170, %r168, 2146435072;
	setp.lt.s32 	%p36, %r3, 0;
	selp.b32 	%r171, %r170, %r168, %p36;
	setp.eq.f64 	%p37, %fd2, 0dBFF0000000000000;
	selp.b32 	%r172, 1072693248, %r171, %p37;
	mov.b64 	%fd1860, {%r169, %r172};
	bra.uni 	$L__BB16_15;

$L__BB16_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r162, %temp}, %fd2;
	}
	and.b32  	%r163, %r2, 2147483647;
	setp.ne.s32 	%p29, %r163, 2146435072;
	setp.ne.s32 	%p30, %r162, 0;
	or.pred  	%p31, %p29, %p30;
	@%p31 bra 	$L__BB16_15;

	setp.gt.s32 	%p32, %r3, -1;
	selp.b32 	%r164, 2146435072, 0, %p32;
	mov.u32 	%r165, 0;
	setp.ne.s32 	%p33, %r5, 1071644672;
	and.pred  	%p34, %p33, %p1;
	or.b32  	%r166, %r164, -2147483648;
	selp.b32 	%r167, %r166, %r164, %p34;
	mov.b64 	%fd1860, {%r165, %r167};

$L__BB16_15:
	abs.f64 	%fd15, %fd4;
	{ // callseq 223, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1863, [retval0+0];
	} // callseq 223
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd4;
	}
	setp.lt.s32 	%p38, %r6, 0;
	and.pred  	%p2, %p38, %p16;
	not.pred 	%p40, %p2;
	@%p40 bra 	$L__BB16_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd1863;
	}
	xor.b32  	%r174, %r173, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r175, %temp}, %fd1863;
	}
	mov.b64 	%fd1863, {%r175, %r174};

$L__BB16_17:
	setp.eq.f64 	%p41, %fd4, 0d0000000000000000;
	@%p41 bra 	$L__BB16_21;
	bra.uni 	$L__BB16_18;

$L__BB16_21:
	selp.b32 	%r176, %r6, 0, %p16;
	mov.u32 	%r177, 0;
	or.b32  	%r178, %r176, 2146435072;
	setp.lt.s32 	%p45, %r3, 0;
	selp.b32 	%r179, %r178, %r176, %p45;
	mov.b64 	%fd1863, {%r177, %r179};
	bra.uni 	$L__BB16_22;

$L__BB16_18:
	setp.gt.s32 	%p42, %r6, -1;
	@%p42 bra 	$L__BB16_22;

	mov.f64 	%fd618, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd619, %fd618;
	setp.eq.f64 	%p43, %fd619, 0d4000000000000000;
	@%p43 bra 	$L__BB16_22;

	mov.f64 	%fd1863, 0dFFF8000000000000;

$L__BB16_22:
	add.rn.f64 	%fd621, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r180}, %fd621;
	}
	and.b32  	%r181, %r180, 2146435072;
	setp.ne.s32 	%p46, %r181, 2146435072;
	@%p46 bra 	$L__BB16_29;

	setp.gtu.f64 	%p47, %fd15, 0d7FF0000000000000;
	@%p47 bra 	$L__BB16_28;
	bra.uni 	$L__BB16_24;

$L__BB16_28:
	mov.f64 	%fd623, 0d4000000000000000;
	add.rn.f64 	%fd1863, %fd4, %fd623;
	bra.uni 	$L__BB16_29;

$L__BB16_24:
	mov.f64 	%fd622, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd622;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p48, %r7, 2146435072;
	setp.eq.s32 	%p49, %r182, 0;
	and.pred  	%p50, %p48, %p49;
	@%p50 bra 	$L__BB16_27;
	bra.uni 	$L__BB16_25;

$L__BB16_27:
	setp.gt.f64 	%p57, %fd15, 0d3FF0000000000000;
	selp.b32 	%r189, 2146435072, 0, %p57;
	mov.u32 	%r190, 0;
	xor.b32  	%r191, %r189, 2146435072;
	setp.lt.s32 	%p58, %r3, 0;
	selp.b32 	%r192, %r191, %r189, %p58;
	setp.eq.f64 	%p59, %fd4, 0dBFF0000000000000;
	selp.b32 	%r193, 1072693248, %r192, %p59;
	mov.b64 	%fd1863, {%r190, %r193};
	bra.uni 	$L__BB16_29;

$L__BB16_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r183, %temp}, %fd4;
	}
	and.b32  	%r184, %r6, 2147483647;
	setp.ne.s32 	%p51, %r184, 2146435072;
	setp.ne.s32 	%p52, %r183, 0;
	or.pred  	%p53, %p51, %p52;
	@%p53 bra 	$L__BB16_29;

	setp.gt.s32 	%p54, %r3, -1;
	selp.b32 	%r185, 2146435072, 0, %p54;
	mov.u32 	%r186, 0;
	setp.ne.s32 	%p55, %r7, 1071644672;
	and.pred  	%p56, %p55, %p2;
	or.b32  	%r187, %r185, -2147483648;
	selp.b32 	%r188, %r187, %r185, %p56;
	mov.b64 	%fd1863, {%r186, %r188};

$L__BB16_29:
	setp.eq.f64 	%p60, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd624, 0d3FF0000000000000, %fd1863, %p60;
	setp.eq.f64 	%p61, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd625, 0d3FF0000000000000, %fd1860, %p61;
	add.rn.f64 	%fd25, %fd625, %fd624;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r194, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r195}, %fd26;
	}
	and.b32  	%r196, %r195, 2147483647;
	setp.eq.s32 	%p62, %r196, 2146435072;
	setp.eq.s32 	%p63, %r194, 0;
	and.pred  	%p64, %p63, %p62;
	@%p64 bra 	$L__BB16_32;
	bra.uni 	$L__BB16_30;

$L__BB16_32:
	mov.f64 	%fd635, 0d0000000000000000;
	mul.rn.f64 	%fd1864, %fd26, %fd635;
	mov.u32 	%r677, 0;
	bra.uni 	$L__BB16_33;

$L__BB16_30:
	mul.rn.f64 	%fd626, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r677, %fd626;
	st.local.u32 	[%rd1], %r677;
	cvt.rn.f64.s32 	%fd627, %r677;
	neg.f64 	%fd628, %fd627;
	mov.f64 	%fd629, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd630, %fd628, %fd629, %fd26;
	mov.f64 	%fd631, 0d3C91A62633145C00;
	fma.rn.f64 	%fd632, %fd628, %fd631, %fd630;
	mov.f64 	%fd633, 0d397B839A252049C0;
	fma.rn.f64 	%fd1864, %fd628, %fd633, %fd632;
	abs.f64 	%fd634, %fd26;
	setp.ltu.f64 	%p65, %fd634, 0d41E0000000000000;
	@%p65 bra 	$L__BB16_33;

	{ // callseq 224, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1864, [retval0+0];
	} // callseq 224
	ld.local.u32 	%r677, [%rd1];

$L__BB16_33:
	and.b32  	%r198, %r677, 1;
	shl.b32 	%r199, %r677, 3;
	and.b32  	%r200, %r199, 8;
	setp.eq.s32 	%p66, %r198, 0;
	selp.f64 	%fd636, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p66;
	mul.wide.s32 	%rd87, %r200, 8;
	mov.u64 	%rd88, __cudart_sin_cos_coeffs;
	add.s64 	%rd89, %rd88, %rd87;
	ld.global.nc.f64 	%fd637, [%rd89+8];
	mul.rn.f64 	%fd31, %fd1864, %fd1864;
	fma.rn.f64 	%fd638, %fd636, %fd31, %fd637;
	ld.global.nc.f64 	%fd639, [%rd89+16];
	fma.rn.f64 	%fd640, %fd638, %fd31, %fd639;
	ld.global.nc.f64 	%fd641, [%rd89+24];
	fma.rn.f64 	%fd642, %fd640, %fd31, %fd641;
	ld.global.nc.f64 	%fd643, [%rd89+32];
	fma.rn.f64 	%fd644, %fd642, %fd31, %fd643;
	ld.global.nc.f64 	%fd645, [%rd89+40];
	fma.rn.f64 	%fd646, %fd644, %fd31, %fd645;
	ld.global.nc.f64 	%fd647, [%rd89+48];
	fma.rn.f64 	%fd32, %fd646, %fd31, %fd647;
	fma.rn.f64 	%fd1866, %fd32, %fd1864, %fd1864;
	@%p66 bra 	$L__BB16_35;

	mov.f64 	%fd648, 0d3FF0000000000000;
	fma.rn.f64 	%fd1866, %fd32, %fd31, %fd648;

$L__BB16_35:
	and.b32  	%r201, %r677, 2;
	setp.eq.s32 	%p67, %r201, 0;
	@%p67 bra 	$L__BB16_37;

	mov.f64 	%fd649, 0d0000000000000000;
	mov.f64 	%fd650, 0dBFF0000000000000;
	fma.rn.f64 	%fd1866, %fd1866, %fd650, %fd649;

$L__BB16_37:
	mul.rn.f64 	%fd651, %fd1866, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd652, %fd25;
	add.rn.f64 	%fd38, %fd652, %fd651;
	setp.eq.f64 	%p68, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p69, %fd5, 0d0000000000000000;
	and.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB16_41;
	bra.uni 	$L__BB16_38;

$L__BB16_41:
	selp.f64 	%fd705, 0d400921FB54442D18, 0d0000000000000000, %p17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r210, %temp}, %fd705;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd705;
	}
	and.b32  	%r212, %r6, -2147483648;
	or.b32  	%r213, %r211, %r212;
	mov.b64 	%fd1867, {%r210, %r213};
	bra.uni 	$L__BB16_42;

$L__BB16_38:
	setp.eq.f64 	%p71, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p72, %fd15, 0d7FF0000000000000;
	and.pred  	%p73, %p71, %p72;
	@%p73 bra 	$L__BB16_40;
	bra.uni 	$L__BB16_39;

$L__BB16_40:
	selp.f64 	%fd704, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r206, %temp}, %fd704;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r207}, %fd704;
	}
	and.b32  	%r208, %r6, -2147483648;
	or.b32  	%r209, %r207, %r208;
	mov.b64 	%fd1867, {%r206, %r209};
	bra.uni 	$L__BB16_42;

$L__BB16_39:
	min.f64 	%fd653, %fd15, %fd5;
	max.f64 	%fd654, %fd15, %fd5;
	div.rn.f64 	%fd655, %fd653, %fd654;
	mul.rn.f64 	%fd656, %fd655, %fd655;
	mov.f64 	%fd657, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd658, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd659, %fd658, %fd656, %fd657;
	mov.f64 	%fd660, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd661, %fd659, %fd656, %fd660;
	mov.f64 	%fd662, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd663, %fd661, %fd656, %fd662;
	mov.f64 	%fd664, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd665, %fd663, %fd656, %fd664;
	mov.f64 	%fd666, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd667, %fd665, %fd656, %fd666;
	mov.f64 	%fd668, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd669, %fd667, %fd656, %fd668;
	mov.f64 	%fd670, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd671, %fd669, %fd656, %fd670;
	mov.f64 	%fd672, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd673, %fd671, %fd656, %fd672;
	mov.f64 	%fd674, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd675, %fd673, %fd656, %fd674;
	mov.f64 	%fd676, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd677, %fd675, %fd656, %fd676;
	mov.f64 	%fd678, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd679, %fd677, %fd656, %fd678;
	mov.f64 	%fd680, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd681, %fd679, %fd656, %fd680;
	mov.f64 	%fd682, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd683, %fd681, %fd656, %fd682;
	mov.f64 	%fd684, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd685, %fd683, %fd656, %fd684;
	mov.f64 	%fd686, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd687, %fd685, %fd656, %fd686;
	mov.f64 	%fd688, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd689, %fd687, %fd656, %fd688;
	mov.f64 	%fd690, 0d3FC99999999840D2;
	fma.rn.f64 	%fd691, %fd689, %fd656, %fd690;
	mov.f64 	%fd692, 0dBFD555555555544C;
	fma.rn.f64 	%fd693, %fd691, %fd656, %fd692;
	mul.rn.f64 	%fd694, %fd656, %fd693;
	fma.rn.f64 	%fd695, %fd694, %fd655, %fd655;
	mov.f64 	%fd696, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd697, %fd696, %fd695;
	setp.gt.f64 	%p75, %fd15, %fd5;
	selp.f64 	%fd698, %fd697, %fd695, %p75;
	mov.f64 	%fd699, 0d400921FB54442D18;
	sub.rn.f64 	%fd700, %fd699, %fd698;
	selp.f64 	%fd701, %fd700, %fd698, %p17;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r202, %temp}, %fd701;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r203}, %fd701;
	}
	and.b32  	%r204, %r6, -2147483648;
	or.b32  	%r205, %r203, %r204;
	mov.b64 	%fd702, {%r202, %r205};
	add.rn.f64 	%fd703, %fd5, %fd15;
	setp.le.f64 	%p76, %fd703, 0d7FF0000000000000;
	selp.f64 	%fd1867, %fd702, %fd703, %p76;

$L__BB16_42:
	add.rn.f64 	%fd1857, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd1857, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd43;
	}
	and.b32  	%r216, %r215, 2147483647;
	setp.eq.s32 	%p79, %r216, 2146435072;
	setp.eq.s32 	%p80, %r214, 0;
	and.pred  	%p81, %p80, %p79;
	@%p81 bra 	$L__BB16_46;
	bra.uni 	$L__BB16_43;

$L__BB16_46:
	mov.f64 	%fd715, 0d0000000000000000;
	mul.rn.f64 	%fd1869, %fd43, %fd715;
	mov.u32 	%r679, 1;
	bra.uni 	$L__BB16_47;

$L__BB16_43:
	mul.rn.f64 	%fd706, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r678, %fd706;
	st.local.u32 	[%rd1], %r678;
	cvt.rn.f64.s32 	%fd707, %r678;
	neg.f64 	%fd708, %fd707;
	mov.f64 	%fd709, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd710, %fd708, %fd709, %fd43;
	mov.f64 	%fd711, 0d3C91A62633145C00;
	fma.rn.f64 	%fd712, %fd708, %fd711, %fd710;
	mov.f64 	%fd713, 0d397B839A252049C0;
	fma.rn.f64 	%fd1869, %fd708, %fd713, %fd712;
	abs.f64 	%fd714, %fd43;
	setp.ltu.f64 	%p82, %fd714, 0d41E0000000000000;
	@%p82 bra 	$L__BB16_45;

	{ // callseq 225, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1869, [retval0+0];
	} // callseq 225
	ld.local.u32 	%r678, [%rd1];

$L__BB16_45:
	add.s32 	%r679, %r678, 1;

$L__BB16_47:
	and.b32  	%r218, %r679, 1;
	shl.b32 	%r219, %r679, 3;
	and.b32  	%r220, %r219, 8;
	setp.eq.s32 	%p83, %r218, 0;
	selp.f64 	%fd716, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p83;
	mul.wide.s32 	%rd91, %r220, 8;
	add.s64 	%rd93, %rd88, %rd91;
	ld.global.nc.f64 	%fd717, [%rd93+8];
	mul.rn.f64 	%fd49, %fd1869, %fd1869;
	fma.rn.f64 	%fd718, %fd716, %fd49, %fd717;
	ld.global.nc.f64 	%fd719, [%rd93+16];
	fma.rn.f64 	%fd720, %fd718, %fd49, %fd719;
	ld.global.nc.f64 	%fd721, [%rd93+24];
	fma.rn.f64 	%fd722, %fd720, %fd49, %fd721;
	ld.global.nc.f64 	%fd723, [%rd93+32];
	fma.rn.f64 	%fd724, %fd722, %fd49, %fd723;
	ld.global.nc.f64 	%fd725, [%rd93+40];
	fma.rn.f64 	%fd726, %fd724, %fd49, %fd725;
	ld.global.nc.f64 	%fd727, [%rd93+48];
	fma.rn.f64 	%fd50, %fd726, %fd49, %fd727;
	fma.rn.f64 	%fd1871, %fd50, %fd1869, %fd1869;
	@%p83 bra 	$L__BB16_49;

	mov.f64 	%fd728, 0d3FF0000000000000;
	fma.rn.f64 	%fd1871, %fd50, %fd49, %fd728;

$L__BB16_49:
	and.b32  	%r221, %r679, 2;
	setp.eq.s32 	%p84, %r221, 0;
	@%p84 bra 	$L__BB16_51;

	mov.f64 	%fd729, 0d0000000000000000;
	mov.f64 	%fd730, 0dBFF0000000000000;
	fma.rn.f64 	%fd1871, %fd1871, %fd730, %fd729;

$L__BB16_51:
	mul.rn.f64 	%fd731, %fd1871, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd1867, %fd731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r222, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r223}, %fd56;
	}
	and.b32  	%r224, %r223, 2147483647;
	setp.eq.s32 	%p85, %r224, 2146435072;
	setp.eq.s32 	%p86, %r222, 0;
	and.pred  	%p3, %p86, %p85;
	@%p3 bra 	$L__BB16_55;
	bra.uni 	$L__BB16_52;

$L__BB16_55:
	mov.f64 	%fd741, 0d0000000000000000;
	mul.rn.f64 	%fd1873, %fd56, %fd741;
	mov.u32 	%r681, 1;
	bra.uni 	$L__BB16_56;

$L__BB16_52:
	mul.rn.f64 	%fd732, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r680, %fd732;
	st.local.u32 	[%rd1], %r680;
	cvt.rn.f64.s32 	%fd733, %r680;
	neg.f64 	%fd734, %fd733;
	mov.f64 	%fd735, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd736, %fd734, %fd735, %fd56;
	mov.f64 	%fd737, 0d3C91A62633145C00;
	fma.rn.f64 	%fd738, %fd734, %fd737, %fd736;
	mov.f64 	%fd739, 0d397B839A252049C0;
	fma.rn.f64 	%fd1873, %fd734, %fd739, %fd738;
	abs.f64 	%fd740, %fd56;
	setp.ltu.f64 	%p87, %fd740, 0d41E0000000000000;
	@%p87 bra 	$L__BB16_54;

	{ // callseq 226, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1873, [retval0+0];
	} // callseq 226
	ld.local.u32 	%r680, [%rd1];

$L__BB16_54:
	add.s32 	%r681, %r680, 1;

$L__BB16_56:
	and.b32  	%r226, %r681, 1;
	shl.b32 	%r227, %r681, 3;
	and.b32  	%r228, %r227, 8;
	setp.eq.s32 	%p88, %r226, 0;
	selp.f64 	%fd742, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p88;
	mul.wide.s32 	%rd95, %r228, 8;
	add.s64 	%rd97, %rd88, %rd95;
	ld.global.nc.f64 	%fd743, [%rd97+8];
	mul.rn.f64 	%fd62, %fd1873, %fd1873;
	fma.rn.f64 	%fd744, %fd742, %fd62, %fd743;
	ld.global.nc.f64 	%fd745, [%rd97+16];
	fma.rn.f64 	%fd746, %fd744, %fd62, %fd745;
	ld.global.nc.f64 	%fd747, [%rd97+24];
	fma.rn.f64 	%fd748, %fd746, %fd62, %fd747;
	ld.global.nc.f64 	%fd749, [%rd97+32];
	fma.rn.f64 	%fd750, %fd748, %fd62, %fd749;
	ld.global.nc.f64 	%fd751, [%rd97+40];
	fma.rn.f64 	%fd752, %fd750, %fd62, %fd751;
	ld.global.nc.f64 	%fd753, [%rd97+48];
	fma.rn.f64 	%fd63, %fd752, %fd62, %fd753;
	fma.rn.f64 	%fd1875, %fd63, %fd1873, %fd1873;
	@%p88 bra 	$L__BB16_58;

	mov.f64 	%fd754, 0d3FF0000000000000;
	fma.rn.f64 	%fd1875, %fd63, %fd62, %fd754;

$L__BB16_58:
	and.b32  	%r229, %r681, 2;
	setp.eq.s32 	%p89, %r229, 0;
	@%p89 bra 	$L__BB16_60;

	mov.f64 	%fd755, 0d0000000000000000;
	mov.f64 	%fd756, 0dBFF0000000000000;
	fma.rn.f64 	%fd1875, %fd1875, %fd756, %fd755;

$L__BB16_60:
	mul.rn.f64 	%fd69, %fd38, %fd1875;
	@%p3 bra 	$L__BB16_63;
	bra.uni 	$L__BB16_61;

$L__BB16_63:
	mov.f64 	%fd766, 0d0000000000000000;
	mul.rn.f64 	%fd1876, %fd56, %fd766;
	mov.u32 	%r682, 0;
	bra.uni 	$L__BB16_64;

$L__BB16_61:
	mul.rn.f64 	%fd757, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r682, %fd757;
	st.local.u32 	[%rd1], %r682;
	cvt.rn.f64.s32 	%fd758, %r682;
	neg.f64 	%fd759, %fd758;
	mov.f64 	%fd760, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd761, %fd759, %fd760, %fd56;
	mov.f64 	%fd762, 0d3C91A62633145C00;
	fma.rn.f64 	%fd763, %fd759, %fd762, %fd761;
	mov.f64 	%fd764, 0d397B839A252049C0;
	fma.rn.f64 	%fd1876, %fd759, %fd764, %fd763;
	abs.f64 	%fd765, %fd56;
	setp.ltu.f64 	%p90, %fd765, 0d41E0000000000000;
	@%p90 bra 	$L__BB16_64;

	{ // callseq 227, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1876, [retval0+0];
	} // callseq 227
	ld.local.u32 	%r682, [%rd1];

$L__BB16_64:
	and.b32  	%r231, %r682, 1;
	shl.b32 	%r232, %r682, 3;
	and.b32  	%r233, %r232, 8;
	setp.eq.s32 	%p91, %r231, 0;
	selp.f64 	%fd767, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p91;
	mul.wide.s32 	%rd99, %r233, 8;
	add.s64 	%rd101, %rd88, %rd99;
	ld.global.nc.f64 	%fd768, [%rd101+8];
	mul.rn.f64 	%fd74, %fd1876, %fd1876;
	fma.rn.f64 	%fd769, %fd767, %fd74, %fd768;
	ld.global.nc.f64 	%fd770, [%rd101+16];
	fma.rn.f64 	%fd771, %fd769, %fd74, %fd770;
	ld.global.nc.f64 	%fd772, [%rd101+24];
	fma.rn.f64 	%fd773, %fd771, %fd74, %fd772;
	ld.global.nc.f64 	%fd774, [%rd101+32];
	fma.rn.f64 	%fd775, %fd773, %fd74, %fd774;
	ld.global.nc.f64 	%fd776, [%rd101+40];
	fma.rn.f64 	%fd777, %fd775, %fd74, %fd776;
	ld.global.nc.f64 	%fd778, [%rd101+48];
	fma.rn.f64 	%fd75, %fd777, %fd74, %fd778;
	fma.rn.f64 	%fd1878, %fd75, %fd1876, %fd1876;
	@%p91 bra 	$L__BB16_66;

	mov.f64 	%fd779, 0d3FF0000000000000;
	fma.rn.f64 	%fd1878, %fd75, %fd74, %fd779;

$L__BB16_66:
	and.b32  	%r234, %r682, 2;
	setp.eq.s32 	%p92, %r234, 0;
	@%p92 bra 	$L__BB16_68;

	mov.f64 	%fd780, 0d0000000000000000;
	mov.f64 	%fd781, 0dBFF0000000000000;
	fma.rn.f64 	%fd1878, %fd1878, %fd781, %fd780;

$L__BB16_68:
	mul.rn.f64 	%fd81, %fd38, %fd1878;
	add.rn.f64 	%fd82, %fd81, 0dC041800000000000;
	add.rn.f64 	%fd83, %fd69, 0dC05A400000000000;
	abs.f64 	%fd84, %fd83;
	sqrt.rn.f64 	%fd85, %fd84;
	mul.rn.f64 	%fd86, %fd83, 0d400921FB54442D18;
	mul.rn.f64 	%fd87, %fd82, 0d400921FB54442D18;
	mul.rn.f64 	%fd88, %fd86, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r236}, %fd88;
	}
	and.b32  	%r237, %r236, 2147483647;
	setp.eq.s32 	%p93, %r237, 2146435072;
	setp.eq.s32 	%p94, %r235, 0;
	and.pred  	%p95, %p94, %p93;
	@%p95 bra 	$L__BB16_71;
	bra.uni 	$L__BB16_69;

$L__BB16_71:
	mov.f64 	%fd791, 0d0000000000000000;
	mul.rn.f64 	%fd1879, %fd88, %fd791;
	mov.u32 	%r683, 0;
	bra.uni 	$L__BB16_72;

$L__BB16_69:
	mul.rn.f64 	%fd782, %fd88, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r683, %fd782;
	st.local.u32 	[%rd1], %r683;
	cvt.rn.f64.s32 	%fd783, %r683;
	neg.f64 	%fd784, %fd783;
	mov.f64 	%fd785, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd786, %fd784, %fd785, %fd88;
	mov.f64 	%fd787, 0d3C91A62633145C00;
	fma.rn.f64 	%fd788, %fd784, %fd787, %fd786;
	mov.f64 	%fd789, 0d397B839A252049C0;
	fma.rn.f64 	%fd1879, %fd784, %fd789, %fd788;
	abs.f64 	%fd790, %fd88;
	setp.ltu.f64 	%p96, %fd790, 0d41E0000000000000;
	@%p96 bra 	$L__BB16_72;

	{ // callseq 228, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd88;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1879, [retval0+0];
	} // callseq 228
	ld.local.u32 	%r683, [%rd1];

$L__BB16_72:
	and.b32  	%r239, %r683, 1;
	shl.b32 	%r240, %r683, 3;
	and.b32  	%r241, %r240, 8;
	setp.eq.s32 	%p97, %r239, 0;
	selp.f64 	%fd792, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p97;
	mul.wide.s32 	%rd103, %r241, 8;
	add.s64 	%rd105, %rd88, %rd103;
	ld.global.nc.f64 	%fd793, [%rd105+8];
	mul.rn.f64 	%fd93, %fd1879, %fd1879;
	fma.rn.f64 	%fd794, %fd792, %fd93, %fd793;
	ld.global.nc.f64 	%fd795, [%rd105+16];
	fma.rn.f64 	%fd796, %fd794, %fd93, %fd795;
	ld.global.nc.f64 	%fd797, [%rd105+24];
	fma.rn.f64 	%fd798, %fd796, %fd93, %fd797;
	ld.global.nc.f64 	%fd799, [%rd105+32];
	fma.rn.f64 	%fd800, %fd798, %fd93, %fd799;
	ld.global.nc.f64 	%fd801, [%rd105+40];
	fma.rn.f64 	%fd802, %fd800, %fd93, %fd801;
	ld.global.nc.f64 	%fd803, [%rd105+48];
	fma.rn.f64 	%fd94, %fd802, %fd93, %fd803;
	fma.rn.f64 	%fd1881, %fd94, %fd1879, %fd1879;
	@%p97 bra 	$L__BB16_74;

	mov.f64 	%fd804, 0d3FF0000000000000;
	fma.rn.f64 	%fd1881, %fd94, %fd93, %fd804;

$L__BB16_74:
	and.b32  	%r242, %r683, 2;
	setp.eq.s32 	%p98, %r242, 0;
	@%p98 bra 	$L__BB16_76;

	mov.f64 	%fd805, 0d0000000000000000;
	mov.f64 	%fd806, 0dBFF0000000000000;
	fma.rn.f64 	%fd1881, %fd1881, %fd806, %fd805;

$L__BB16_76:
	add.rn.f64 	%fd100, %fd86, %fd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd100;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r244}, %fd100;
	}
	and.b32  	%r245, %r244, 2147483647;
	setp.eq.s32 	%p99, %r245, 2146435072;
	setp.eq.s32 	%p100, %r243, 0;
	and.pred  	%p101, %p100, %p99;
	@%p101 bra 	$L__BB16_79;
	bra.uni 	$L__BB16_77;

$L__BB16_79:
	mov.f64 	%fd816, 0d0000000000000000;
	mul.rn.f64 	%fd1882, %fd100, %fd816;
	mov.u32 	%r684, 0;
	bra.uni 	$L__BB16_80;

$L__BB16_77:
	mul.rn.f64 	%fd807, %fd100, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r684, %fd807;
	st.local.u32 	[%rd1], %r684;
	cvt.rn.f64.s32 	%fd808, %r684;
	neg.f64 	%fd809, %fd808;
	mov.f64 	%fd810, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd811, %fd809, %fd810, %fd100;
	mov.f64 	%fd812, 0d3C91A62633145C00;
	fma.rn.f64 	%fd813, %fd809, %fd812, %fd811;
	mov.f64 	%fd814, 0d397B839A252049C0;
	fma.rn.f64 	%fd1882, %fd809, %fd814, %fd813;
	abs.f64 	%fd815, %fd100;
	setp.ltu.f64 	%p102, %fd815, 0d41E0000000000000;
	@%p102 bra 	$L__BB16_80;

	{ // callseq 229, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1882, [retval0+0];
	} // callseq 229
	ld.local.u32 	%r684, [%rd1];

$L__BB16_80:
	and.b32  	%r247, %r684, 1;
	shl.b32 	%r248, %r684, 3;
	and.b32  	%r249, %r248, 8;
	setp.eq.s32 	%p103, %r247, 0;
	selp.f64 	%fd817, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p103;
	mul.wide.s32 	%rd107, %r249, 8;
	add.s64 	%rd109, %rd88, %rd107;
	ld.global.nc.f64 	%fd818, [%rd109+8];
	mul.rn.f64 	%fd105, %fd1882, %fd1882;
	fma.rn.f64 	%fd819, %fd817, %fd105, %fd818;
	ld.global.nc.f64 	%fd820, [%rd109+16];
	fma.rn.f64 	%fd821, %fd819, %fd105, %fd820;
	ld.global.nc.f64 	%fd822, [%rd109+24];
	fma.rn.f64 	%fd823, %fd821, %fd105, %fd822;
	ld.global.nc.f64 	%fd824, [%rd109+32];
	fma.rn.f64 	%fd825, %fd823, %fd105, %fd824;
	ld.global.nc.f64 	%fd826, [%rd109+40];
	fma.rn.f64 	%fd827, %fd825, %fd105, %fd826;
	ld.global.nc.f64 	%fd828, [%rd109+48];
	fma.rn.f64 	%fd106, %fd827, %fd105, %fd828;
	fma.rn.f64 	%fd1884, %fd106, %fd1882, %fd1882;
	@%p103 bra 	$L__BB16_82;

	mov.f64 	%fd829, 0d3FF0000000000000;
	fma.rn.f64 	%fd1884, %fd106, %fd105, %fd829;

$L__BB16_82:
	and.b32  	%r250, %r684, 2;
	setp.eq.s32 	%p104, %r250, 0;
	@%p104 bra 	$L__BB16_84;

	mov.f64 	%fd830, 0d0000000000000000;
	mov.f64 	%fd831, 0dBFF0000000000000;
	fma.rn.f64 	%fd1884, %fd1884, %fd831, %fd830;

$L__BB16_84:
	mul.rn.f64 	%fd832, %fd1884, 0d4034000000000000;
	mul.rn.f64 	%fd833, %fd1881, 0d4034000000000000;
	add.rn.f64 	%fd112, %fd833, %fd832;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r251}, %fd87;
	}
	and.b32  	%r252, %r251, 2147483647;
	setp.eq.s32 	%p105, %r252, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r253, %temp}, %fd87;
	}
	setp.eq.s32 	%p106, %r253, 0;
	and.pred  	%p107, %p106, %p105;
	@%p107 bra 	$L__BB16_87;
	bra.uni 	$L__BB16_85;

$L__BB16_87:
	mov.f64 	%fd843, 0d0000000000000000;
	mul.rn.f64 	%fd1885, %fd87, %fd843;
	mov.u32 	%r685, 0;
	bra.uni 	$L__BB16_88;

$L__BB16_85:
	mul.rn.f64 	%fd834, %fd87, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r685, %fd834;
	st.local.u32 	[%rd1], %r685;
	cvt.rn.f64.s32 	%fd835, %r685;
	neg.f64 	%fd836, %fd835;
	mov.f64 	%fd837, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd838, %fd836, %fd837, %fd87;
	mov.f64 	%fd839, 0d3C91A62633145C00;
	fma.rn.f64 	%fd840, %fd836, %fd839, %fd838;
	mov.f64 	%fd841, 0d397B839A252049C0;
	fma.rn.f64 	%fd1885, %fd836, %fd841, %fd840;
	abs.f64 	%fd842, %fd87;
	setp.ltu.f64 	%p108, %fd842, 0d41E0000000000000;
	@%p108 bra 	$L__BB16_88;

	{ // callseq 230, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1885, [retval0+0];
	} // callseq 230
	ld.local.u32 	%r685, [%rd1];

$L__BB16_88:
	and.b32  	%r255, %r685, 1;
	shl.b32 	%r256, %r685, 3;
	and.b32  	%r257, %r256, 8;
	setp.eq.s32 	%p109, %r255, 0;
	selp.f64 	%fd844, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p109;
	mul.wide.s32 	%rd111, %r257, 8;
	add.s64 	%rd113, %rd88, %rd111;
	ld.global.nc.f64 	%fd845, [%rd113+8];
	mul.rn.f64 	%fd117, %fd1885, %fd1885;
	fma.rn.f64 	%fd846, %fd844, %fd117, %fd845;
	ld.global.nc.f64 	%fd847, [%rd113+16];
	fma.rn.f64 	%fd848, %fd846, %fd117, %fd847;
	ld.global.nc.f64 	%fd849, [%rd113+24];
	fma.rn.f64 	%fd850, %fd848, %fd117, %fd849;
	ld.global.nc.f64 	%fd851, [%rd113+32];
	fma.rn.f64 	%fd852, %fd850, %fd117, %fd851;
	ld.global.nc.f64 	%fd853, [%rd113+40];
	fma.rn.f64 	%fd854, %fd852, %fd117, %fd853;
	ld.global.nc.f64 	%fd855, [%rd113+48];
	fma.rn.f64 	%fd118, %fd854, %fd117, %fd855;
	fma.rn.f64 	%fd1887, %fd118, %fd1885, %fd1885;
	@%p109 bra 	$L__BB16_90;

	mov.f64 	%fd856, 0d3FF0000000000000;
	fma.rn.f64 	%fd1887, %fd118, %fd117, %fd856;

$L__BB16_90:
	and.b32  	%r258, %r685, 2;
	setp.eq.s32 	%p110, %r258, 0;
	@%p110 bra 	$L__BB16_92;

	mov.f64 	%fd857, 0d0000000000000000;
	mov.f64 	%fd858, 0dBFF0000000000000;
	fma.rn.f64 	%fd1887, %fd1887, %fd858, %fd857;

$L__BB16_92:
	div.rn.f64 	%fd124, %fd87, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r259, %temp}, %fd124;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd124;
	}
	and.b32  	%r261, %r260, 2147483647;
	setp.eq.s32 	%p111, %r261, 2146435072;
	setp.eq.s32 	%p112, %r259, 0;
	and.pred  	%p113, %p112, %p111;
	@%p113 bra 	$L__BB16_95;
	bra.uni 	$L__BB16_93;

$L__BB16_95:
	mov.f64 	%fd868, 0d0000000000000000;
	mul.rn.f64 	%fd1888, %fd124, %fd868;
	mov.u32 	%r686, 0;
	bra.uni 	$L__BB16_96;

$L__BB16_93:
	mul.rn.f64 	%fd859, %fd124, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r686, %fd859;
	st.local.u32 	[%rd1], %r686;
	cvt.rn.f64.s32 	%fd860, %r686;
	neg.f64 	%fd861, %fd860;
	mov.f64 	%fd862, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd863, %fd861, %fd862, %fd124;
	mov.f64 	%fd864, 0d3C91A62633145C00;
	fma.rn.f64 	%fd865, %fd861, %fd864, %fd863;
	mov.f64 	%fd866, 0d397B839A252049C0;
	fma.rn.f64 	%fd1888, %fd861, %fd866, %fd865;
	abs.f64 	%fd867, %fd124;
	setp.ltu.f64 	%p114, %fd867, 0d41E0000000000000;
	@%p114 bra 	$L__BB16_96;

	{ // callseq 231, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd124;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1888, [retval0+0];
	} // callseq 231
	ld.local.u32 	%r686, [%rd1];

$L__BB16_96:
	and.b32  	%r263, %r686, 1;
	shl.b32 	%r264, %r686, 3;
	and.b32  	%r265, %r264, 8;
	setp.eq.s32 	%p115, %r263, 0;
	selp.f64 	%fd869, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p115;
	mul.wide.s32 	%rd115, %r265, 8;
	add.s64 	%rd117, %rd88, %rd115;
	ld.global.nc.f64 	%fd870, [%rd117+8];
	mul.rn.f64 	%fd129, %fd1888, %fd1888;
	fma.rn.f64 	%fd871, %fd869, %fd129, %fd870;
	ld.global.nc.f64 	%fd872, [%rd117+16];
	fma.rn.f64 	%fd873, %fd871, %fd129, %fd872;
	ld.global.nc.f64 	%fd874, [%rd117+24];
	fma.rn.f64 	%fd875, %fd873, %fd129, %fd874;
	ld.global.nc.f64 	%fd876, [%rd117+32];
	fma.rn.f64 	%fd877, %fd875, %fd129, %fd876;
	ld.global.nc.f64 	%fd878, [%rd117+40];
	fma.rn.f64 	%fd879, %fd877, %fd129, %fd878;
	ld.global.nc.f64 	%fd880, [%rd117+48];
	fma.rn.f64 	%fd130, %fd879, %fd129, %fd880;
	fma.rn.f64 	%fd1890, %fd130, %fd1888, %fd1888;
	@%p115 bra 	$L__BB16_98;

	mov.f64 	%fd881, 0d3FF0000000000000;
	fma.rn.f64 	%fd1890, %fd130, %fd129, %fd881;

$L__BB16_98:
	and.b32  	%r266, %r686, 2;
	setp.eq.s32 	%p116, %r266, 0;
	@%p116 bra 	$L__BB16_100;

	mov.f64 	%fd882, 0d0000000000000000;
	mov.f64 	%fd883, 0dBFF0000000000000;
	fma.rn.f64 	%fd1890, %fd1890, %fd883, %fd882;

$L__BB16_100:
	mul.rn.f64 	%fd884, %fd1890, 0d4044000000000000;
	mul.rn.f64 	%fd885, %fd1887, 0d4034000000000000;
	add.rn.f64 	%fd136, %fd885, %fd884;
	div.rn.f64 	%fd137, %fd87, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r267, %temp}, %fd137;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r268}, %fd137;
	}
	and.b32  	%r269, %r268, 2147483647;
	setp.eq.s32 	%p117, %r269, 2146435072;
	setp.eq.s32 	%p118, %r267, 0;
	and.pred  	%p119, %p118, %p117;
	@%p119 bra 	$L__BB16_103;
	bra.uni 	$L__BB16_101;

$L__BB16_103:
	mov.f64 	%fd895, 0d0000000000000000;
	mul.rn.f64 	%fd1891, %fd137, %fd895;
	mov.u32 	%r687, 0;
	bra.uni 	$L__BB16_104;

$L__BB16_101:
	mul.rn.f64 	%fd886, %fd137, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r687, %fd886;
	st.local.u32 	[%rd1], %r687;
	cvt.rn.f64.s32 	%fd887, %r687;
	neg.f64 	%fd888, %fd887;
	mov.f64 	%fd889, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd890, %fd888, %fd889, %fd137;
	mov.f64 	%fd891, 0d3C91A62633145C00;
	fma.rn.f64 	%fd892, %fd888, %fd891, %fd890;
	mov.f64 	%fd893, 0d397B839A252049C0;
	fma.rn.f64 	%fd1891, %fd888, %fd893, %fd892;
	abs.f64 	%fd894, %fd137;
	setp.ltu.f64 	%p120, %fd894, 0d41E0000000000000;
	@%p120 bra 	$L__BB16_104;

	{ // callseq 232, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd137;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1891, [retval0+0];
	} // callseq 232
	ld.local.u32 	%r687, [%rd1];

$L__BB16_104:
	and.b32  	%r271, %r687, 1;
	shl.b32 	%r272, %r687, 3;
	and.b32  	%r273, %r272, 8;
	setp.eq.s32 	%p121, %r271, 0;
	selp.f64 	%fd896, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p121;
	mul.wide.s32 	%rd119, %r273, 8;
	add.s64 	%rd121, %rd88, %rd119;
	ld.global.nc.f64 	%fd897, [%rd121+8];
	mul.rn.f64 	%fd142, %fd1891, %fd1891;
	fma.rn.f64 	%fd898, %fd896, %fd142, %fd897;
	ld.global.nc.f64 	%fd899, [%rd121+16];
	fma.rn.f64 	%fd900, %fd898, %fd142, %fd899;
	ld.global.nc.f64 	%fd901, [%rd121+24];
	fma.rn.f64 	%fd902, %fd900, %fd142, %fd901;
	ld.global.nc.f64 	%fd903, [%rd121+32];
	fma.rn.f64 	%fd904, %fd902, %fd142, %fd903;
	ld.global.nc.f64 	%fd905, [%rd121+40];
	fma.rn.f64 	%fd906, %fd904, %fd142, %fd905;
	ld.global.nc.f64 	%fd907, [%rd121+48];
	fma.rn.f64 	%fd143, %fd906, %fd142, %fd907;
	fma.rn.f64 	%fd1893, %fd143, %fd1891, %fd1891;
	@%p121 bra 	$L__BB16_106;

	mov.f64 	%fd908, 0d3FF0000000000000;
	fma.rn.f64 	%fd1893, %fd143, %fd142, %fd908;

$L__BB16_106:
	and.b32  	%r274, %r687, 2;
	setp.eq.s32 	%p122, %r274, 0;
	@%p122 bra 	$L__BB16_108;

	mov.f64 	%fd909, 0d0000000000000000;
	mov.f64 	%fd910, 0dBFF0000000000000;
	fma.rn.f64 	%fd1893, %fd1893, %fd910, %fd909;

$L__BB16_108:
	mul.rn.f64 	%fd911, %fd1893, 0d4064000000000000;
	add.rn.f64 	%fd149, %fd136, %fd911;
	div.rn.f64 	%fd150, %fd87, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r275, %temp}, %fd150;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd150;
	}
	and.b32  	%r277, %r276, 2147483647;
	setp.eq.s32 	%p123, %r277, 2146435072;
	setp.eq.s32 	%p124, %r275, 0;
	and.pred  	%p125, %p124, %p123;
	@%p125 bra 	$L__BB16_111;
	bra.uni 	$L__BB16_109;

$L__BB16_111:
	mov.f64 	%fd921, 0d0000000000000000;
	mul.rn.f64 	%fd1894, %fd150, %fd921;
	mov.u32 	%r688, 0;
	bra.uni 	$L__BB16_112;

$L__BB16_109:
	mul.rn.f64 	%fd912, %fd150, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r688, %fd912;
	st.local.u32 	[%rd1], %r688;
	cvt.rn.f64.s32 	%fd913, %r688;
	neg.f64 	%fd914, %fd913;
	mov.f64 	%fd915, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd916, %fd914, %fd915, %fd150;
	mov.f64 	%fd917, 0d3C91A62633145C00;
	fma.rn.f64 	%fd918, %fd914, %fd917, %fd916;
	mov.f64 	%fd919, 0d397B839A252049C0;
	fma.rn.f64 	%fd1894, %fd914, %fd919, %fd918;
	abs.f64 	%fd920, %fd150;
	setp.ltu.f64 	%p126, %fd920, 0d41E0000000000000;
	@%p126 bra 	$L__BB16_112;

	{ // callseq 233, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd150;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1894, [retval0+0];
	} // callseq 233
	ld.local.u32 	%r688, [%rd1];

$L__BB16_112:
	and.b32  	%r279, %r688, 1;
	shl.b32 	%r280, %r688, 3;
	and.b32  	%r281, %r280, 8;
	setp.eq.s32 	%p127, %r279, 0;
	selp.f64 	%fd922, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p127;
	mul.wide.s32 	%rd123, %r281, 8;
	add.s64 	%rd125, %rd88, %rd123;
	ld.global.nc.f64 	%fd923, [%rd125+8];
	mul.rn.f64 	%fd155, %fd1894, %fd1894;
	fma.rn.f64 	%fd924, %fd922, %fd155, %fd923;
	ld.global.nc.f64 	%fd925, [%rd125+16];
	fma.rn.f64 	%fd926, %fd924, %fd155, %fd925;
	ld.global.nc.f64 	%fd927, [%rd125+24];
	fma.rn.f64 	%fd928, %fd926, %fd155, %fd927;
	ld.global.nc.f64 	%fd929, [%rd125+32];
	fma.rn.f64 	%fd930, %fd928, %fd155, %fd929;
	ld.global.nc.f64 	%fd931, [%rd125+40];
	fma.rn.f64 	%fd932, %fd930, %fd155, %fd931;
	ld.global.nc.f64 	%fd933, [%rd125+48];
	fma.rn.f64 	%fd156, %fd932, %fd155, %fd933;
	fma.rn.f64 	%fd1896, %fd156, %fd1894, %fd1894;
	@%p127 bra 	$L__BB16_114;

	mov.f64 	%fd934, 0d3FF0000000000000;
	fma.rn.f64 	%fd1896, %fd156, %fd155, %fd934;

$L__BB16_114:
	and.b32  	%r282, %r688, 2;
	setp.eq.s32 	%p128, %r282, 0;
	@%p128 bra 	$L__BB16_116;

	mov.f64 	%fd935, 0d0000000000000000;
	mov.f64 	%fd936, 0dBFF0000000000000;
	fma.rn.f64 	%fd1896, %fd1896, %fd936, %fd935;

$L__BB16_116:
	mul.rn.f64 	%fd937, %fd1896, 0d4074000000000000;
	add.rn.f64 	%fd162, %fd149, %fd937;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd86;
	}
	and.b32  	%r284, %r283, 2147483647;
	setp.eq.s32 	%p129, %r284, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd86;
	}
	setp.eq.s32 	%p130, %r285, 0;
	and.pred  	%p131, %p130, %p129;
	@%p131 bra 	$L__BB16_119;
	bra.uni 	$L__BB16_117;

$L__BB16_119:
	mov.f64 	%fd947, 0d0000000000000000;
	mul.rn.f64 	%fd1897, %fd86, %fd947;
	mov.u32 	%r689, 0;
	bra.uni 	$L__BB16_120;

$L__BB16_117:
	mul.rn.f64 	%fd938, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r689, %fd938;
	st.local.u32 	[%rd1], %r689;
	cvt.rn.f64.s32 	%fd939, %r689;
	neg.f64 	%fd940, %fd939;
	mov.f64 	%fd941, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd942, %fd940, %fd941, %fd86;
	mov.f64 	%fd943, 0d3C91A62633145C00;
	fma.rn.f64 	%fd944, %fd940, %fd943, %fd942;
	mov.f64 	%fd945, 0d397B839A252049C0;
	fma.rn.f64 	%fd1897, %fd940, %fd945, %fd944;
	abs.f64 	%fd946, %fd86;
	setp.ltu.f64 	%p132, %fd946, 0d41E0000000000000;
	@%p132 bra 	$L__BB16_120;

	{ // callseq 234, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1897, [retval0+0];
	} // callseq 234
	ld.local.u32 	%r689, [%rd1];

$L__BB16_120:
	and.b32  	%r287, %r689, 1;
	shl.b32 	%r288, %r689, 3;
	and.b32  	%r289, %r288, 8;
	setp.eq.s32 	%p133, %r287, 0;
	selp.f64 	%fd948, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p133;
	mul.wide.s32 	%rd127, %r289, 8;
	add.s64 	%rd129, %rd88, %rd127;
	ld.global.nc.f64 	%fd949, [%rd129+8];
	mul.rn.f64 	%fd167, %fd1897, %fd1897;
	fma.rn.f64 	%fd950, %fd948, %fd167, %fd949;
	ld.global.nc.f64 	%fd951, [%rd129+16];
	fma.rn.f64 	%fd952, %fd950, %fd167, %fd951;
	ld.global.nc.f64 	%fd953, [%rd129+24];
	fma.rn.f64 	%fd954, %fd952, %fd167, %fd953;
	ld.global.nc.f64 	%fd955, [%rd129+32];
	fma.rn.f64 	%fd956, %fd954, %fd167, %fd955;
	ld.global.nc.f64 	%fd957, [%rd129+40];
	fma.rn.f64 	%fd958, %fd956, %fd167, %fd957;
	ld.global.nc.f64 	%fd959, [%rd129+48];
	fma.rn.f64 	%fd168, %fd958, %fd167, %fd959;
	fma.rn.f64 	%fd1899, %fd168, %fd1897, %fd1897;
	@%p133 bra 	$L__BB16_122;

	mov.f64 	%fd960, 0d3FF0000000000000;
	fma.rn.f64 	%fd1899, %fd168, %fd167, %fd960;

$L__BB16_122:
	and.b32  	%r290, %r689, 2;
	setp.eq.s32 	%p134, %r290, 0;
	@%p134 bra 	$L__BB16_124;

	mov.f64 	%fd961, 0d0000000000000000;
	mov.f64 	%fd962, 0dBFF0000000000000;
	fma.rn.f64 	%fd1899, %fd1899, %fd962, %fd961;

$L__BB16_124:
	div.rn.f64 	%fd174, %fd86, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r291, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r292}, %fd174;
	}
	and.b32  	%r293, %r292, 2147483647;
	setp.eq.s32 	%p135, %r293, 2146435072;
	setp.eq.s32 	%p136, %r291, 0;
	and.pred  	%p137, %p136, %p135;
	@%p137 bra 	$L__BB16_127;
	bra.uni 	$L__BB16_125;

$L__BB16_127:
	mov.f64 	%fd972, 0d0000000000000000;
	mul.rn.f64 	%fd1900, %fd174, %fd972;
	mov.u32 	%r690, 0;
	bra.uni 	$L__BB16_128;

$L__BB16_125:
	mul.rn.f64 	%fd963, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r690, %fd963;
	st.local.u32 	[%rd1], %r690;
	cvt.rn.f64.s32 	%fd964, %r690;
	neg.f64 	%fd965, %fd964;
	mov.f64 	%fd966, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd967, %fd965, %fd966, %fd174;
	mov.f64 	%fd968, 0d3C91A62633145C00;
	fma.rn.f64 	%fd969, %fd965, %fd968, %fd967;
	mov.f64 	%fd970, 0d397B839A252049C0;
	fma.rn.f64 	%fd1900, %fd965, %fd970, %fd969;
	abs.f64 	%fd971, %fd174;
	setp.ltu.f64 	%p138, %fd971, 0d41E0000000000000;
	@%p138 bra 	$L__BB16_128;

	{ // callseq 235, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1900, [retval0+0];
	} // callseq 235
	ld.local.u32 	%r690, [%rd1];

$L__BB16_128:
	and.b32  	%r295, %r690, 1;
	shl.b32 	%r296, %r690, 3;
	and.b32  	%r297, %r296, 8;
	setp.eq.s32 	%p139, %r295, 0;
	selp.f64 	%fd973, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p139;
	mul.wide.s32 	%rd131, %r297, 8;
	add.s64 	%rd133, %rd88, %rd131;
	ld.global.nc.f64 	%fd974, [%rd133+8];
	mul.rn.f64 	%fd179, %fd1900, %fd1900;
	fma.rn.f64 	%fd975, %fd973, %fd179, %fd974;
	ld.global.nc.f64 	%fd976, [%rd133+16];
	fma.rn.f64 	%fd977, %fd975, %fd179, %fd976;
	ld.global.nc.f64 	%fd978, [%rd133+24];
	fma.rn.f64 	%fd979, %fd977, %fd179, %fd978;
	ld.global.nc.f64 	%fd980, [%rd133+32];
	fma.rn.f64 	%fd981, %fd979, %fd179, %fd980;
	ld.global.nc.f64 	%fd982, [%rd133+40];
	fma.rn.f64 	%fd983, %fd981, %fd179, %fd982;
	ld.global.nc.f64 	%fd984, [%rd133+48];
	fma.rn.f64 	%fd180, %fd983, %fd179, %fd984;
	fma.rn.f64 	%fd1902, %fd180, %fd1900, %fd1900;
	@%p139 bra 	$L__BB16_130;

	mov.f64 	%fd985, 0d3FF0000000000000;
	fma.rn.f64 	%fd1902, %fd180, %fd179, %fd985;

$L__BB16_130:
	and.b32  	%r298, %r690, 2;
	setp.eq.s32 	%p140, %r298, 0;
	@%p140 bra 	$L__BB16_132;

	mov.f64 	%fd986, 0d0000000000000000;
	mov.f64 	%fd987, 0dBFF0000000000000;
	fma.rn.f64 	%fd1902, %fd1902, %fd987, %fd986;

$L__BB16_132:
	mul.rn.f64 	%fd988, %fd1902, 0d4044000000000000;
	mul.rn.f64 	%fd989, %fd1899, 0d4034000000000000;
	add.rn.f64 	%fd186, %fd989, %fd988;
	div.rn.f64 	%fd187, %fd86, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r299, %temp}, %fd187;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r300}, %fd187;
	}
	and.b32  	%r301, %r300, 2147483647;
	setp.eq.s32 	%p141, %r301, 2146435072;
	setp.eq.s32 	%p142, %r299, 0;
	and.pred  	%p143, %p142, %p141;
	@%p143 bra 	$L__BB16_135;
	bra.uni 	$L__BB16_133;

$L__BB16_135:
	mov.f64 	%fd999, 0d0000000000000000;
	mul.rn.f64 	%fd1903, %fd187, %fd999;
	mov.u32 	%r691, 0;
	bra.uni 	$L__BB16_136;

$L__BB16_133:
	mul.rn.f64 	%fd990, %fd187, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r691, %fd990;
	st.local.u32 	[%rd1], %r691;
	cvt.rn.f64.s32 	%fd991, %r691;
	neg.f64 	%fd992, %fd991;
	mov.f64 	%fd993, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd994, %fd992, %fd993, %fd187;
	mov.f64 	%fd995, 0d3C91A62633145C00;
	fma.rn.f64 	%fd996, %fd992, %fd995, %fd994;
	mov.f64 	%fd997, 0d397B839A252049C0;
	fma.rn.f64 	%fd1903, %fd992, %fd997, %fd996;
	abs.f64 	%fd998, %fd187;
	setp.ltu.f64 	%p144, %fd998, 0d41E0000000000000;
	@%p144 bra 	$L__BB16_136;

	{ // callseq 236, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd187;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1903, [retval0+0];
	} // callseq 236
	ld.local.u32 	%r691, [%rd1];

$L__BB16_136:
	and.b32  	%r303, %r691, 1;
	shl.b32 	%r304, %r691, 3;
	and.b32  	%r305, %r304, 8;
	setp.eq.s32 	%p145, %r303, 0;
	selp.f64 	%fd1000, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p145;
	mul.wide.s32 	%rd135, %r305, 8;
	add.s64 	%rd137, %rd88, %rd135;
	ld.global.nc.f64 	%fd1001, [%rd137+8];
	mul.rn.f64 	%fd192, %fd1903, %fd1903;
	fma.rn.f64 	%fd1002, %fd1000, %fd192, %fd1001;
	ld.global.nc.f64 	%fd1003, [%rd137+16];
	fma.rn.f64 	%fd1004, %fd1002, %fd192, %fd1003;
	ld.global.nc.f64 	%fd1005, [%rd137+24];
	fma.rn.f64 	%fd1006, %fd1004, %fd192, %fd1005;
	ld.global.nc.f64 	%fd1007, [%rd137+32];
	fma.rn.f64 	%fd1008, %fd1006, %fd192, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd137+40];
	fma.rn.f64 	%fd1010, %fd1008, %fd192, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd137+48];
	fma.rn.f64 	%fd193, %fd1010, %fd192, %fd1011;
	fma.rn.f64 	%fd1905, %fd193, %fd1903, %fd1903;
	@%p145 bra 	$L__BB16_138;

	mov.f64 	%fd1012, 0d3FF0000000000000;
	fma.rn.f64 	%fd1905, %fd193, %fd192, %fd1012;

$L__BB16_138:
	and.b32  	%r306, %r691, 2;
	setp.eq.s32 	%p146, %r306, 0;
	@%p146 bra 	$L__BB16_140;

	mov.f64 	%fd1013, 0d0000000000000000;
	mov.f64 	%fd1014, 0dBFF0000000000000;
	fma.rn.f64 	%fd1905, %fd1905, %fd1014, %fd1013;

$L__BB16_140:
	mul.rn.f64 	%fd1015, %fd1905, 0d4062C00000000000;
	add.rn.f64 	%fd199, %fd186, %fd1015;
	div.rn.f64 	%fd200, %fd86, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r307, %temp}, %fd200;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r308}, %fd200;
	}
	and.b32  	%r309, %r308, 2147483647;
	setp.eq.s32 	%p147, %r309, 2146435072;
	setp.eq.s32 	%p148, %r307, 0;
	and.pred  	%p149, %p148, %p147;
	@%p149 bra 	$L__BB16_143;
	bra.uni 	$L__BB16_141;

$L__BB16_143:
	mov.f64 	%fd1025, 0d0000000000000000;
	mul.rn.f64 	%fd1906, %fd200, %fd1025;
	mov.u32 	%r692, 0;
	bra.uni 	$L__BB16_144;

$L__BB16_141:
	mul.rn.f64 	%fd1016, %fd200, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r692, %fd1016;
	st.local.u32 	[%rd1], %r692;
	cvt.rn.f64.s32 	%fd1017, %r692;
	neg.f64 	%fd1018, %fd1017;
	mov.f64 	%fd1019, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1020, %fd1018, %fd1019, %fd200;
	mov.f64 	%fd1021, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1022, %fd1018, %fd1021, %fd1020;
	mov.f64 	%fd1023, 0d397B839A252049C0;
	fma.rn.f64 	%fd1906, %fd1018, %fd1023, %fd1022;
	abs.f64 	%fd1024, %fd200;
	setp.ltu.f64 	%p150, %fd1024, 0d41E0000000000000;
	@%p150 bra 	$L__BB16_144;

	{ // callseq 237, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd200;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1906, [retval0+0];
	} // callseq 237
	ld.local.u32 	%r692, [%rd1];

$L__BB16_144:
	and.b32  	%r311, %r692, 1;
	shl.b32 	%r312, %r692, 3;
	and.b32  	%r313, %r312, 8;
	setp.eq.s32 	%p151, %r311, 0;
	selp.f64 	%fd1026, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p151;
	mul.wide.s32 	%rd139, %r313, 8;
	add.s64 	%rd141, %rd88, %rd139;
	ld.global.nc.f64 	%fd1027, [%rd141+8];
	mul.rn.f64 	%fd205, %fd1906, %fd1906;
	fma.rn.f64 	%fd1028, %fd1026, %fd205, %fd1027;
	ld.global.nc.f64 	%fd1029, [%rd141+16];
	fma.rn.f64 	%fd1030, %fd1028, %fd205, %fd1029;
	ld.global.nc.f64 	%fd1031, [%rd141+24];
	fma.rn.f64 	%fd1032, %fd1030, %fd205, %fd1031;
	ld.global.nc.f64 	%fd1033, [%rd141+32];
	fma.rn.f64 	%fd1034, %fd1032, %fd205, %fd1033;
	ld.global.nc.f64 	%fd1035, [%rd141+40];
	fma.rn.f64 	%fd1036, %fd1034, %fd205, %fd1035;
	ld.global.nc.f64 	%fd1037, [%rd141+48];
	fma.rn.f64 	%fd206, %fd1036, %fd205, %fd1037;
	fma.rn.f64 	%fd1908, %fd206, %fd1906, %fd1906;
	@%p151 bra 	$L__BB16_146;

	mov.f64 	%fd1038, 0d3FF0000000000000;
	fma.rn.f64 	%fd1908, %fd206, %fd205, %fd1038;

$L__BB16_146:
	and.b32  	%r314, %r692, 2;
	setp.eq.s32 	%p152, %r314, 0;
	@%p152 bra 	$L__BB16_148;

	mov.f64 	%fd1039, 0d0000000000000000;
	mov.f64 	%fd1040, 0dBFF0000000000000;
	fma.rn.f64 	%fd1908, %fd1908, %fd1040, %fd1039;

$L__BB16_148:
	mul.rn.f64 	%fd1041, %fd1908, 0d4072C00000000000;
	add.rn.f64 	%fd1042, %fd199, %fd1041;
	add.rn.f64 	%fd212, %fd112, %fd1042;
	add.rn.f64 	%fd213, %fd112, %fd162;
	add.rn.f64 	%fd1043, %fd83, %fd83;
	add.rn.f64 	%fd1044, %fd1043, 0dC059000000000000;
	mul.rn.f64 	%fd1045, %fd82, 0d4008000000000000;
	add.rn.f64 	%fd214, %fd1044, %fd1045;
	abs.f64 	%fd215, %fd82;
	{ // callseq 238, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1911, [retval0+0];
	} // callseq 238
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r54}, %fd82;
	}
	setp.lt.s32 	%p153, %r54, 0;
	and.pred  	%p4, %p153, %p16;
	not.pred 	%p155, %p4;
	@%p155 bra 	$L__BB16_150;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r315}, %fd1911;
	}
	xor.b32  	%r316, %r315, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r317, %temp}, %fd1911;
	}
	mov.b64 	%fd1911, {%r317, %r316};

$L__BB16_150:
	setp.eq.f64 	%p156, %fd82, 0d0000000000000000;
	@%p156 bra 	$L__BB16_154;
	bra.uni 	$L__BB16_151;

$L__BB16_154:
	selp.b32 	%r318, %r54, 0, %p16;
	mov.u32 	%r319, 0;
	or.b32  	%r320, %r318, 2146435072;
	setp.lt.s32 	%p160, %r3, 0;
	selp.b32 	%r321, %r320, %r318, %p160;
	mov.b64 	%fd1911, {%r319, %r321};
	bra.uni 	$L__BB16_155;

$L__BB16_151:
	setp.gt.s32 	%p157, %r54, -1;
	@%p157 bra 	$L__BB16_155;

	mov.f64 	%fd1046, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1047, %fd1046;
	setp.eq.f64 	%p158, %fd1047, 0d4000000000000000;
	@%p158 bra 	$L__BB16_155;

	mov.f64 	%fd1911, 0dFFF8000000000000;

$L__BB16_155:
	add.rn.f64 	%fd1049, %fd82, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r322}, %fd1049;
	}
	and.b32  	%r323, %r322, 2146435072;
	setp.ne.s32 	%p161, %r323, 2146435072;
	@%p161 bra 	$L__BB16_162;

	setp.gtu.f64 	%p162, %fd215, 0d7FF0000000000000;
	@%p162 bra 	$L__BB16_161;
	bra.uni 	$L__BB16_157;

$L__BB16_161:
	mov.f64 	%fd1051, 0d4000000000000000;
	add.rn.f64 	%fd1911, %fd82, %fd1051;
	bra.uni 	$L__BB16_162;

$L__BB16_157:
	mov.f64 	%fd1050, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r324, %temp}, %fd1050;
	}
	and.b32  	%r55, %r3, 2147483647;
	setp.eq.s32 	%p163, %r55, 2146435072;
	setp.eq.s32 	%p164, %r324, 0;
	and.pred  	%p165, %p163, %p164;
	@%p165 bra 	$L__BB16_160;
	bra.uni 	$L__BB16_158;

$L__BB16_160:
	setp.gt.f64 	%p172, %fd215, 0d3FF0000000000000;
	selp.b32 	%r331, 2146435072, 0, %p172;
	mov.u32 	%r332, 0;
	xor.b32  	%r333, %r331, 2146435072;
	setp.lt.s32 	%p173, %r3, 0;
	selp.b32 	%r334, %r333, %r331, %p173;
	setp.eq.f64 	%p174, %fd82, 0dBFF0000000000000;
	selp.b32 	%r335, 1072693248, %r334, %p174;
	mov.b64 	%fd1911, {%r332, %r335};
	bra.uni 	$L__BB16_162;

$L__BB16_158:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r325, %temp}, %fd82;
	}
	and.b32  	%r326, %r54, 2147483647;
	setp.ne.s32 	%p166, %r326, 2146435072;
	setp.ne.s32 	%p167, %r325, 0;
	or.pred  	%p168, %p166, %p167;
	@%p168 bra 	$L__BB16_162;

	setp.gt.s32 	%p169, %r3, -1;
	selp.b32 	%r327, 2146435072, 0, %p169;
	mov.u32 	%r328, 0;
	setp.ne.s32 	%p170, %r55, 1071644672;
	and.pred  	%p171, %p170, %p4;
	or.b32  	%r329, %r327, -2147483648;
	selp.b32 	%r330, %r329, %r327, %p171;
	mov.b64 	%fd1911, {%r328, %r330};

$L__BB16_162:
	mul.rn.f64 	%fd1052, %fd1911, 0d3FC999999999999A;
	setp.eq.f64 	%p175, %fd82, 0d3FF0000000000000;
	selp.f64 	%fd1053, 0d3FC999999999999A, %fd1052, %p175;
	add.rn.f64 	%fd1054, %fd214, %fd1053;
	mul.rn.f64 	%fd1055, %fd83, %fd82;
	mul.rn.f64 	%fd225, %fd1055, 0d3FB999999999999A;
	add.rn.f64 	%fd1056, %fd225, %fd1054;
	mul.rn.f64 	%fd1057, %fd85, 0d3FC999999999999A;
	add.rn.f64 	%fd1058, %fd1057, %fd1056;
	mul.rn.f64 	%fd1059, %fd213, 0d3FE5555555555555;
	add.rn.f64 	%fd226, %fd1059, %fd1058;
	add.rn.f64 	%fd1060, %fd82, %fd82;
	add.rn.f64 	%fd1061, %fd83, 0d4072C00000000000;
	add.rn.f64 	%fd227, %fd1061, %fd1060;
	{ // callseq 239, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1914, [retval0+0];
	} // callseq 239
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r56}, %fd83;
	}
	setp.lt.s32 	%p176, %r56, 0;
	and.pred  	%p5, %p176, %p16;
	not.pred 	%p178, %p5;
	@%p178 bra 	$L__BB16_164;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd1914;
	}
	xor.b32  	%r337, %r336, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd1914;
	}
	mov.b64 	%fd1914, {%r338, %r337};

$L__BB16_164:
	setp.eq.f64 	%p179, %fd83, 0d0000000000000000;
	@%p179 bra 	$L__BB16_168;
	bra.uni 	$L__BB16_165;

$L__BB16_168:
	selp.b32 	%r339, %r56, 0, %p16;
	mov.u32 	%r340, 0;
	or.b32  	%r341, %r339, 2146435072;
	setp.lt.s32 	%p183, %r3, 0;
	selp.b32 	%r342, %r341, %r339, %p183;
	mov.b64 	%fd1914, {%r340, %r342};
	bra.uni 	$L__BB16_169;

$L__BB16_165:
	setp.gt.s32 	%p180, %r56, -1;
	@%p180 bra 	$L__BB16_169;

	mov.f64 	%fd1062, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1063, %fd1062;
	setp.eq.f64 	%p181, %fd1063, 0d4000000000000000;
	@%p181 bra 	$L__BB16_169;

	mov.f64 	%fd1914, 0dFFF8000000000000;

$L__BB16_169:
	add.rn.f64 	%fd1065, %fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r343}, %fd1065;
	}
	and.b32  	%r344, %r343, 2146435072;
	setp.ne.s32 	%p184, %r344, 2146435072;
	@%p184 bra 	$L__BB16_176;

	setp.gtu.f64 	%p185, %fd84, 0d7FF0000000000000;
	@%p185 bra 	$L__BB16_175;
	bra.uni 	$L__BB16_171;

$L__BB16_175:
	mov.f64 	%fd1067, 0d4000000000000000;
	add.rn.f64 	%fd1914, %fd83, %fd1067;
	bra.uni 	$L__BB16_176;

$L__BB16_171:
	mov.f64 	%fd1066, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd1066;
	}
	and.b32  	%r57, %r3, 2147483647;
	setp.eq.s32 	%p186, %r57, 2146435072;
	setp.eq.s32 	%p187, %r345, 0;
	and.pred  	%p188, %p186, %p187;
	@%p188 bra 	$L__BB16_174;
	bra.uni 	$L__BB16_172;

$L__BB16_174:
	setp.gt.f64 	%p195, %fd84, 0d3FF0000000000000;
	selp.b32 	%r352, 2146435072, 0, %p195;
	mov.u32 	%r353, 0;
	xor.b32  	%r354, %r352, 2146435072;
	setp.lt.s32 	%p196, %r3, 0;
	selp.b32 	%r355, %r354, %r352, %p196;
	setp.eq.f64 	%p197, %fd83, 0dBFF0000000000000;
	selp.b32 	%r356, 1072693248, %r355, %p197;
	mov.b64 	%fd1914, {%r353, %r356};
	bra.uni 	$L__BB16_176;

$L__BB16_172:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r346, %temp}, %fd83;
	}
	and.b32  	%r347, %r56, 2147483647;
	setp.ne.s32 	%p189, %r347, 2146435072;
	setp.ne.s32 	%p190, %r346, 0;
	or.pred  	%p191, %p189, %p190;
	@%p191 bra 	$L__BB16_176;

	setp.gt.s32 	%p192, %r3, -1;
	selp.b32 	%r348, 2146435072, 0, %p192;
	mov.u32 	%r349, 0;
	setp.ne.s32 	%p193, %r57, 1071644672;
	and.pred  	%p194, %p193, %p5;
	or.b32  	%r350, %r348, -2147483648;
	selp.b32 	%r351, %r350, %r348, %p194;
	mov.b64 	%fd1914, {%r349, %r351};

$L__BB16_176:
	mul.rn.f64 	%fd1068, %fd1914, 0d3FB999999999999A;
	setp.eq.f64 	%p198, %fd83, 0d3FF0000000000000;
	selp.f64 	%fd1069, 0d3FB999999999999A, %fd1068, %p198;
	add.rn.f64 	%fd1070, %fd227, %fd1069;
	add.rn.f64 	%fd1071, %fd225, %fd1070;
	mul.rn.f64 	%fd1072, %fd85, 0d3FB999999999999A;
	add.rn.f64 	%fd1073, %fd1072, %fd1071;
	mul.rn.f64 	%fd1074, %fd212, 0d3FE5555555555555;
	add.rn.f64 	%fd237, %fd1074, %fd1073;
	div.rn.f64 	%fd1075, %fd81, 0d4066800000000000;
	mul.rn.f64 	%fd238, %fd1075, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r357, %temp}, %fd238;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r358}, %fd238;
	}
	and.b32  	%r359, %r358, 2147483647;
	setp.eq.s32 	%p199, %r359, 2146435072;
	setp.eq.s32 	%p200, %r357, 0;
	and.pred  	%p6, %p200, %p199;
	@%p6 bra 	$L__BB16_179;
	bra.uni 	$L__BB16_177;

$L__BB16_179:
	mov.f64 	%fd1085, 0d0000000000000000;
	mul.rn.f64 	%fd1915, %fd238, %fd1085;
	mov.u32 	%r693, 0;
	bra.uni 	$L__BB16_180;

$L__BB16_177:
	mul.rn.f64 	%fd1076, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r693, %fd1076;
	st.local.u32 	[%rd1], %r693;
	cvt.rn.f64.s32 	%fd1077, %r693;
	neg.f64 	%fd1078, %fd1077;
	mov.f64 	%fd1079, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1080, %fd1078, %fd1079, %fd238;
	mov.f64 	%fd1081, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1082, %fd1078, %fd1081, %fd1080;
	mov.f64 	%fd1083, 0d397B839A252049C0;
	fma.rn.f64 	%fd1915, %fd1078, %fd1083, %fd1082;
	abs.f64 	%fd1084, %fd238;
	setp.ltu.f64 	%p201, %fd1084, 0d41E0000000000000;
	@%p201 bra 	$L__BB16_180;

	{ // callseq 240, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1915, [retval0+0];
	} // callseq 240
	ld.local.u32 	%r693, [%rd1];

$L__BB16_180:
	and.b32  	%r361, %r693, 1;
	shl.b32 	%r362, %r693, 3;
	and.b32  	%r363, %r362, 8;
	setp.eq.s32 	%p202, %r361, 0;
	selp.f64 	%fd1086, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p202;
	mul.wide.s32 	%rd143, %r363, 8;
	add.s64 	%rd145, %rd88, %rd143;
	ld.global.nc.f64 	%fd1087, [%rd145+8];
	mul.rn.f64 	%fd243, %fd1915, %fd1915;
	fma.rn.f64 	%fd1088, %fd1086, %fd243, %fd1087;
	ld.global.nc.f64 	%fd1089, [%rd145+16];
	fma.rn.f64 	%fd1090, %fd1088, %fd243, %fd1089;
	ld.global.nc.f64 	%fd1091, [%rd145+24];
	fma.rn.f64 	%fd1092, %fd1090, %fd243, %fd1091;
	ld.global.nc.f64 	%fd1093, [%rd145+32];
	fma.rn.f64 	%fd1094, %fd1092, %fd243, %fd1093;
	ld.global.nc.f64 	%fd1095, [%rd145+40];
	fma.rn.f64 	%fd1096, %fd1094, %fd243, %fd1095;
	ld.global.nc.f64 	%fd1097, [%rd145+48];
	fma.rn.f64 	%fd244, %fd1096, %fd243, %fd1097;
	fma.rn.f64 	%fd1917, %fd244, %fd1915, %fd1915;
	@%p202 bra 	$L__BB16_182;

	mov.f64 	%fd1098, 0d3FF0000000000000;
	fma.rn.f64 	%fd1917, %fd244, %fd243, %fd1098;

$L__BB16_182:
	and.b32  	%r364, %r693, 2;
	setp.eq.s32 	%p203, %r364, 0;
	@%p203 bra 	$L__BB16_184;

	mov.f64 	%fd1099, 0d0000000000000000;
	mov.f64 	%fd1100, 0dBFF0000000000000;
	fma.rn.f64 	%fd1917, %fd1917, %fd1100, %fd1099;

$L__BB16_184:
	@%p6 bra 	$L__BB16_188;
	bra.uni 	$L__BB16_185;

$L__BB16_188:
	mov.f64 	%fd1110, 0d0000000000000000;
	mul.rn.f64 	%fd1919, %fd238, %fd1110;
	mov.u32 	%r695, 1;
	bra.uni 	$L__BB16_189;

$L__BB16_185:
	mul.rn.f64 	%fd1101, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r694, %fd1101;
	st.local.u32 	[%rd1], %r694;
	cvt.rn.f64.s32 	%fd1102, %r694;
	neg.f64 	%fd1103, %fd1102;
	mov.f64 	%fd1104, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1105, %fd1103, %fd1104, %fd238;
	mov.f64 	%fd1106, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1107, %fd1103, %fd1106, %fd1105;
	mov.f64 	%fd1108, 0d397B839A252049C0;
	fma.rn.f64 	%fd1919, %fd1103, %fd1108, %fd1107;
	abs.f64 	%fd1109, %fd238;
	setp.ltu.f64 	%p204, %fd1109, 0d41E0000000000000;
	@%p204 bra 	$L__BB16_187;

	{ // callseq 241, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1919, [retval0+0];
	} // callseq 241
	ld.local.u32 	%r694, [%rd1];

$L__BB16_187:
	add.s32 	%r695, %r694, 1;

$L__BB16_189:
	and.b32  	%r366, %r695, 1;
	shl.b32 	%r367, %r695, 3;
	and.b32  	%r368, %r367, 8;
	setp.eq.s32 	%p205, %r366, 0;
	selp.f64 	%fd1111, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p205;
	mul.wide.s32 	%rd147, %r368, 8;
	add.s64 	%rd149, %rd88, %rd147;
	ld.global.nc.f64 	%fd1112, [%rd149+8];
	mul.rn.f64 	%fd255, %fd1919, %fd1919;
	fma.rn.f64 	%fd1113, %fd1111, %fd255, %fd1112;
	ld.global.nc.f64 	%fd1114, [%rd149+16];
	fma.rn.f64 	%fd1115, %fd1113, %fd255, %fd1114;
	ld.global.nc.f64 	%fd1116, [%rd149+24];
	fma.rn.f64 	%fd1117, %fd1115, %fd255, %fd1116;
	ld.global.nc.f64 	%fd1118, [%rd149+32];
	fma.rn.f64 	%fd1119, %fd1117, %fd255, %fd1118;
	ld.global.nc.f64 	%fd1120, [%rd149+40];
	fma.rn.f64 	%fd1121, %fd1119, %fd255, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd149+48];
	fma.rn.f64 	%fd256, %fd1121, %fd255, %fd1122;
	fma.rn.f64 	%fd1921, %fd256, %fd1919, %fd1919;
	@%p205 bra 	$L__BB16_191;

	mov.f64 	%fd1123, 0d3FF0000000000000;
	fma.rn.f64 	%fd1921, %fd256, %fd255, %fd1123;

$L__BB16_191:
	and.b32  	%r369, %r695, 2;
	setp.eq.s32 	%p206, %r369, 0;
	@%p206 bra 	$L__BB16_193;

	mov.f64 	%fd1124, 0d0000000000000000;
	mov.f64 	%fd1125, 0dBFF0000000000000;
	fma.rn.f64 	%fd1921, %fd1921, %fd1125, %fd1124;

$L__BB16_193:
	mul.rn.f64 	%fd1126, %fd1917, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1127, %fd1917, %fd1126;
	add.rn.f64 	%fd1128, %fd1127, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1129, %fd1128;
	mov.f64 	%fd1130, 0dC15854C140000000;
	div.rn.f64 	%fd1131, %fd1130, %fd1129;
	mul.rn.f64 	%fd1132, %fd1131, %fd1921;
	mul.rn.f64 	%fd1133, %fd1132, 0d400921FB54442D18;
	mul.rn.f64 	%fd1134, %fd237, 0d4066800000000000;
	div.rn.f64 	%fd1135, %fd1134, %fd1133;
	add.rn.f64 	%fd2009, %fd69, %fd1135;
	mul.rn.f64 	%fd1136, %fd226, 0d4066800000000000;
	mul.rn.f64 	%fd1137, %fd1129, %fd1128;
	mov.f64 	%fd1138, 0dC1582B102DE355C1;
	div.rn.f64 	%fd1139, %fd1138, %fd1137;
	mul.rn.f64 	%fd1140, %fd1139, 0d400921FB54442D18;
	div.rn.f64 	%fd1141, %fd1136, %fd1140;
	add.rn.f64 	%fd2010, %fd81, %fd1141;
	setp.lt.s32 	%p207, %r147, 1;
	@%p207 bra 	$L__BB16_459;

	and.b32  	%r66, %r3, 2147483647;
	setp.gt.s32 	%p208, %r3, -1;
	selp.b32 	%r67, 2146435072, 0, %p208;
	mov.u32 	%r696, 0;
	or.b32  	%r68, %r67, -2147483648;
	mov.f64 	%fd1922, %fd2010;
	mov.f64 	%fd1923, %fd2009;

$L__BB16_195:
	mov.f64 	%fd2009, %fd1923;
	mov.f64 	%fd2010, %fd1922;
	add.rn.f64 	%fd266, %fd2010, 0dC041800000000000;
	add.rn.f64 	%fd267, %fd2009, 0dC05A400000000000;
	abs.f64 	%fd268, %fd267;
	sqrt.rn.f64 	%fd269, %fd268;
	mul.rn.f64 	%fd270, %fd267, 0d400921FB54442D18;
	mul.rn.f64 	%fd271, %fd266, 0d400921FB54442D18;
	mul.rn.f64 	%fd272, %fd270, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r371, %temp}, %fd272;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r372}, %fd272;
	}
	and.b32  	%r373, %r372, 2147483647;
	setp.eq.s32 	%p209, %r373, 2146435072;
	setp.eq.s32 	%p210, %r371, 0;
	and.pred  	%p211, %p210, %p209;
	@%p211 bra 	$L__BB16_198;
	bra.uni 	$L__BB16_196;

$L__BB16_198:
	mov.f64 	%fd1151, 0d0000000000000000;
	mul.rn.f64 	%fd1924, %fd272, %fd1151;
	mov.u32 	%r697, 0;
	bra.uni 	$L__BB16_199;

$L__BB16_196:
	mul.rn.f64 	%fd1142, %fd272, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r697, %fd1142;
	st.local.u32 	[%rd1], %r697;
	cvt.rn.f64.s32 	%fd1143, %r697;
	neg.f64 	%fd1144, %fd1143;
	mov.f64 	%fd1145, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1146, %fd1144, %fd1145, %fd272;
	mov.f64 	%fd1147, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1148, %fd1144, %fd1147, %fd1146;
	mov.f64 	%fd1149, 0d397B839A252049C0;
	fma.rn.f64 	%fd1924, %fd1144, %fd1149, %fd1148;
	abs.f64 	%fd1150, %fd272;
	setp.ltu.f64 	%p212, %fd1150, 0d41E0000000000000;
	@%p212 bra 	$L__BB16_199;

	{ // callseq 242, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1924, [retval0+0];
	} // callseq 242
	ld.local.u32 	%r697, [%rd1];

$L__BB16_199:
	and.b32  	%r375, %r697, 1;
	shl.b32 	%r376, %r697, 3;
	and.b32  	%r377, %r376, 8;
	setp.eq.s32 	%p213, %r375, 0;
	selp.f64 	%fd1152, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p213;
	mul.wide.s32 	%rd151, %r377, 8;
	add.s64 	%rd153, %rd88, %rd151;
	ld.global.nc.f64 	%fd1153, [%rd153+8];
	mul.rn.f64 	%fd277, %fd1924, %fd1924;
	fma.rn.f64 	%fd1154, %fd1152, %fd277, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd153+16];
	fma.rn.f64 	%fd1156, %fd1154, %fd277, %fd1155;
	ld.global.nc.f64 	%fd1157, [%rd153+24];
	fma.rn.f64 	%fd1158, %fd1156, %fd277, %fd1157;
	ld.global.nc.f64 	%fd1159, [%rd153+32];
	fma.rn.f64 	%fd1160, %fd1158, %fd277, %fd1159;
	ld.global.nc.f64 	%fd1161, [%rd153+40];
	fma.rn.f64 	%fd1162, %fd1160, %fd277, %fd1161;
	ld.global.nc.f64 	%fd1163, [%rd153+48];
	fma.rn.f64 	%fd278, %fd1162, %fd277, %fd1163;
	fma.rn.f64 	%fd1926, %fd278, %fd1924, %fd1924;
	@%p213 bra 	$L__BB16_201;

	mov.f64 	%fd1164, 0d3FF0000000000000;
	fma.rn.f64 	%fd1926, %fd278, %fd277, %fd1164;

$L__BB16_201:
	and.b32  	%r378, %r697, 2;
	setp.eq.s32 	%p214, %r378, 0;
	@%p214 bra 	$L__BB16_203;

	mov.f64 	%fd1165, 0d0000000000000000;
	mov.f64 	%fd1166, 0dBFF0000000000000;
	fma.rn.f64 	%fd1926, %fd1926, %fd1166, %fd1165;

$L__BB16_203:
	add.rn.f64 	%fd284, %fd270, %fd270;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r379, %temp}, %fd284;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r380}, %fd284;
	}
	and.b32  	%r381, %r380, 2147483647;
	setp.eq.s32 	%p215, %r381, 2146435072;
	setp.eq.s32 	%p216, %r379, 0;
	and.pred  	%p217, %p216, %p215;
	@%p217 bra 	$L__BB16_206;
	bra.uni 	$L__BB16_204;

$L__BB16_206:
	mov.f64 	%fd1176, 0d0000000000000000;
	mul.rn.f64 	%fd1927, %fd284, %fd1176;
	mov.u32 	%r698, 0;
	bra.uni 	$L__BB16_207;

$L__BB16_204:
	mul.rn.f64 	%fd1167, %fd284, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r698, %fd1167;
	st.local.u32 	[%rd1], %r698;
	cvt.rn.f64.s32 	%fd1168, %r698;
	neg.f64 	%fd1169, %fd1168;
	mov.f64 	%fd1170, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1171, %fd1169, %fd1170, %fd284;
	mov.f64 	%fd1172, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1173, %fd1169, %fd1172, %fd1171;
	mov.f64 	%fd1174, 0d397B839A252049C0;
	fma.rn.f64 	%fd1927, %fd1169, %fd1174, %fd1173;
	abs.f64 	%fd1175, %fd284;
	setp.ltu.f64 	%p218, %fd1175, 0d41E0000000000000;
	@%p218 bra 	$L__BB16_207;

	{ // callseq 243, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd284;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1927, [retval0+0];
	} // callseq 243
	ld.local.u32 	%r698, [%rd1];

$L__BB16_207:
	and.b32  	%r383, %r698, 1;
	shl.b32 	%r384, %r698, 3;
	and.b32  	%r385, %r384, 8;
	setp.eq.s32 	%p219, %r383, 0;
	selp.f64 	%fd1177, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p219;
	mul.wide.s32 	%rd155, %r385, 8;
	add.s64 	%rd157, %rd88, %rd155;
	ld.global.nc.f64 	%fd1178, [%rd157+8];
	mul.rn.f64 	%fd289, %fd1927, %fd1927;
	fma.rn.f64 	%fd1179, %fd1177, %fd289, %fd1178;
	ld.global.nc.f64 	%fd1180, [%rd157+16];
	fma.rn.f64 	%fd1181, %fd1179, %fd289, %fd1180;
	ld.global.nc.f64 	%fd1182, [%rd157+24];
	fma.rn.f64 	%fd1183, %fd1181, %fd289, %fd1182;
	ld.global.nc.f64 	%fd1184, [%rd157+32];
	fma.rn.f64 	%fd1185, %fd1183, %fd289, %fd1184;
	ld.global.nc.f64 	%fd1186, [%rd157+40];
	fma.rn.f64 	%fd1187, %fd1185, %fd289, %fd1186;
	ld.global.nc.f64 	%fd1188, [%rd157+48];
	fma.rn.f64 	%fd290, %fd1187, %fd289, %fd1188;
	fma.rn.f64 	%fd1929, %fd290, %fd1927, %fd1927;
	@%p219 bra 	$L__BB16_209;

	mov.f64 	%fd1189, 0d3FF0000000000000;
	fma.rn.f64 	%fd1929, %fd290, %fd289, %fd1189;

$L__BB16_209:
	and.b32  	%r386, %r698, 2;
	setp.eq.s32 	%p220, %r386, 0;
	@%p220 bra 	$L__BB16_211;

	mov.f64 	%fd1190, 0d0000000000000000;
	mov.f64 	%fd1191, 0dBFF0000000000000;
	fma.rn.f64 	%fd1929, %fd1929, %fd1191, %fd1190;

$L__BB16_211:
	mul.rn.f64 	%fd1192, %fd1929, 0d4034000000000000;
	mul.rn.f64 	%fd1193, %fd1926, 0d4034000000000000;
	add.rn.f64 	%fd296, %fd1193, %fd1192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r387}, %fd271;
	}
	and.b32  	%r388, %r387, 2147483647;
	setp.eq.s32 	%p221, %r388, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r389, %temp}, %fd271;
	}
	setp.eq.s32 	%p222, %r389, 0;
	and.pred  	%p223, %p222, %p221;
	@%p223 bra 	$L__BB16_214;
	bra.uni 	$L__BB16_212;

$L__BB16_214:
	mov.f64 	%fd1203, 0d0000000000000000;
	mul.rn.f64 	%fd1930, %fd271, %fd1203;
	mov.u32 	%r699, 0;
	bra.uni 	$L__BB16_215;

$L__BB16_212:
	mul.rn.f64 	%fd1194, %fd271, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r699, %fd1194;
	st.local.u32 	[%rd1], %r699;
	cvt.rn.f64.s32 	%fd1195, %r699;
	neg.f64 	%fd1196, %fd1195;
	mov.f64 	%fd1197, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1198, %fd1196, %fd1197, %fd271;
	mov.f64 	%fd1199, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1200, %fd1196, %fd1199, %fd1198;
	mov.f64 	%fd1201, 0d397B839A252049C0;
	fma.rn.f64 	%fd1930, %fd1196, %fd1201, %fd1200;
	abs.f64 	%fd1202, %fd271;
	setp.ltu.f64 	%p224, %fd1202, 0d41E0000000000000;
	@%p224 bra 	$L__BB16_215;

	{ // callseq 244, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd271;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1930, [retval0+0];
	} // callseq 244
	ld.local.u32 	%r699, [%rd1];

$L__BB16_215:
	and.b32  	%r391, %r699, 1;
	shl.b32 	%r392, %r699, 3;
	and.b32  	%r393, %r392, 8;
	setp.eq.s32 	%p225, %r391, 0;
	selp.f64 	%fd1204, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p225;
	mul.wide.s32 	%rd159, %r393, 8;
	add.s64 	%rd161, %rd88, %rd159;
	ld.global.nc.f64 	%fd1205, [%rd161+8];
	mul.rn.f64 	%fd301, %fd1930, %fd1930;
	fma.rn.f64 	%fd1206, %fd1204, %fd301, %fd1205;
	ld.global.nc.f64 	%fd1207, [%rd161+16];
	fma.rn.f64 	%fd1208, %fd1206, %fd301, %fd1207;
	ld.global.nc.f64 	%fd1209, [%rd161+24];
	fma.rn.f64 	%fd1210, %fd1208, %fd301, %fd1209;
	ld.global.nc.f64 	%fd1211, [%rd161+32];
	fma.rn.f64 	%fd1212, %fd1210, %fd301, %fd1211;
	ld.global.nc.f64 	%fd1213, [%rd161+40];
	fma.rn.f64 	%fd1214, %fd1212, %fd301, %fd1213;
	ld.global.nc.f64 	%fd1215, [%rd161+48];
	fma.rn.f64 	%fd302, %fd1214, %fd301, %fd1215;
	fma.rn.f64 	%fd1932, %fd302, %fd1930, %fd1930;
	@%p225 bra 	$L__BB16_217;

	mov.f64 	%fd1216, 0d3FF0000000000000;
	fma.rn.f64 	%fd1932, %fd302, %fd301, %fd1216;

$L__BB16_217:
	and.b32  	%r394, %r699, 2;
	setp.eq.s32 	%p226, %r394, 0;
	@%p226 bra 	$L__BB16_219;

	mov.f64 	%fd1217, 0d0000000000000000;
	mov.f64 	%fd1218, 0dBFF0000000000000;
	fma.rn.f64 	%fd1932, %fd1932, %fd1218, %fd1217;

$L__BB16_219:
	div.rn.f64 	%fd308, %fd271, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r395, %temp}, %fd308;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r396}, %fd308;
	}
	and.b32  	%r397, %r396, 2147483647;
	setp.eq.s32 	%p227, %r397, 2146435072;
	setp.eq.s32 	%p228, %r395, 0;
	and.pred  	%p229, %p228, %p227;
	@%p229 bra 	$L__BB16_222;
	bra.uni 	$L__BB16_220;

$L__BB16_222:
	mov.f64 	%fd1228, 0d0000000000000000;
	mul.rn.f64 	%fd1933, %fd308, %fd1228;
	mov.u32 	%r700, 0;
	bra.uni 	$L__BB16_223;

$L__BB16_220:
	mul.rn.f64 	%fd1219, %fd308, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r700, %fd1219;
	st.local.u32 	[%rd1], %r700;
	cvt.rn.f64.s32 	%fd1220, %r700;
	neg.f64 	%fd1221, %fd1220;
	mov.f64 	%fd1222, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1223, %fd1221, %fd1222, %fd308;
	mov.f64 	%fd1224, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1225, %fd1221, %fd1224, %fd1223;
	mov.f64 	%fd1226, 0d397B839A252049C0;
	fma.rn.f64 	%fd1933, %fd1221, %fd1226, %fd1225;
	abs.f64 	%fd1227, %fd308;
	setp.ltu.f64 	%p230, %fd1227, 0d41E0000000000000;
	@%p230 bra 	$L__BB16_223;

	{ // callseq 245, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd308;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1933, [retval0+0];
	} // callseq 245
	ld.local.u32 	%r700, [%rd1];

$L__BB16_223:
	and.b32  	%r399, %r700, 1;
	shl.b32 	%r400, %r700, 3;
	and.b32  	%r401, %r400, 8;
	setp.eq.s32 	%p231, %r399, 0;
	selp.f64 	%fd1229, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p231;
	mul.wide.s32 	%rd163, %r401, 8;
	add.s64 	%rd165, %rd88, %rd163;
	ld.global.nc.f64 	%fd1230, [%rd165+8];
	mul.rn.f64 	%fd313, %fd1933, %fd1933;
	fma.rn.f64 	%fd1231, %fd1229, %fd313, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd165+16];
	fma.rn.f64 	%fd1233, %fd1231, %fd313, %fd1232;
	ld.global.nc.f64 	%fd1234, [%rd165+24];
	fma.rn.f64 	%fd1235, %fd1233, %fd313, %fd1234;
	ld.global.nc.f64 	%fd1236, [%rd165+32];
	fma.rn.f64 	%fd1237, %fd1235, %fd313, %fd1236;
	ld.global.nc.f64 	%fd1238, [%rd165+40];
	fma.rn.f64 	%fd1239, %fd1237, %fd313, %fd1238;
	ld.global.nc.f64 	%fd1240, [%rd165+48];
	fma.rn.f64 	%fd314, %fd1239, %fd313, %fd1240;
	fma.rn.f64 	%fd1935, %fd314, %fd1933, %fd1933;
	@%p231 bra 	$L__BB16_225;

	mov.f64 	%fd1241, 0d3FF0000000000000;
	fma.rn.f64 	%fd1935, %fd314, %fd313, %fd1241;

$L__BB16_225:
	and.b32  	%r402, %r700, 2;
	setp.eq.s32 	%p232, %r402, 0;
	@%p232 bra 	$L__BB16_227;

	mov.f64 	%fd1242, 0d0000000000000000;
	mov.f64 	%fd1243, 0dBFF0000000000000;
	fma.rn.f64 	%fd1935, %fd1935, %fd1243, %fd1242;

$L__BB16_227:
	mul.rn.f64 	%fd1244, %fd1935, 0d4044000000000000;
	mul.rn.f64 	%fd1245, %fd1932, 0d4034000000000000;
	add.rn.f64 	%fd320, %fd1245, %fd1244;
	div.rn.f64 	%fd321, %fd271, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r403, %temp}, %fd321;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r404}, %fd321;
	}
	and.b32  	%r405, %r404, 2147483647;
	setp.eq.s32 	%p233, %r405, 2146435072;
	setp.eq.s32 	%p234, %r403, 0;
	and.pred  	%p235, %p234, %p233;
	@%p235 bra 	$L__BB16_230;
	bra.uni 	$L__BB16_228;

$L__BB16_230:
	mov.f64 	%fd1255, 0d0000000000000000;
	mul.rn.f64 	%fd1936, %fd321, %fd1255;
	mov.u32 	%r701, 0;
	bra.uni 	$L__BB16_231;

$L__BB16_228:
	mul.rn.f64 	%fd1246, %fd321, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r701, %fd1246;
	st.local.u32 	[%rd1], %r701;
	cvt.rn.f64.s32 	%fd1247, %r701;
	neg.f64 	%fd1248, %fd1247;
	mov.f64 	%fd1249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1250, %fd1248, %fd1249, %fd321;
	mov.f64 	%fd1251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1252, %fd1248, %fd1251, %fd1250;
	mov.f64 	%fd1253, 0d397B839A252049C0;
	fma.rn.f64 	%fd1936, %fd1248, %fd1253, %fd1252;
	abs.f64 	%fd1254, %fd321;
	setp.ltu.f64 	%p236, %fd1254, 0d41E0000000000000;
	@%p236 bra 	$L__BB16_231;

	{ // callseq 246, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd321;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1936, [retval0+0];
	} // callseq 246
	ld.local.u32 	%r701, [%rd1];

$L__BB16_231:
	and.b32  	%r407, %r701, 1;
	shl.b32 	%r408, %r701, 3;
	and.b32  	%r409, %r408, 8;
	setp.eq.s32 	%p237, %r407, 0;
	selp.f64 	%fd1256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p237;
	mul.wide.s32 	%rd167, %r409, 8;
	add.s64 	%rd169, %rd88, %rd167;
	ld.global.nc.f64 	%fd1257, [%rd169+8];
	mul.rn.f64 	%fd326, %fd1936, %fd1936;
	fma.rn.f64 	%fd1258, %fd1256, %fd326, %fd1257;
	ld.global.nc.f64 	%fd1259, [%rd169+16];
	fma.rn.f64 	%fd1260, %fd1258, %fd326, %fd1259;
	ld.global.nc.f64 	%fd1261, [%rd169+24];
	fma.rn.f64 	%fd1262, %fd1260, %fd326, %fd1261;
	ld.global.nc.f64 	%fd1263, [%rd169+32];
	fma.rn.f64 	%fd1264, %fd1262, %fd326, %fd1263;
	ld.global.nc.f64 	%fd1265, [%rd169+40];
	fma.rn.f64 	%fd1266, %fd1264, %fd326, %fd1265;
	ld.global.nc.f64 	%fd1267, [%rd169+48];
	fma.rn.f64 	%fd327, %fd1266, %fd326, %fd1267;
	fma.rn.f64 	%fd1938, %fd327, %fd1936, %fd1936;
	@%p237 bra 	$L__BB16_233;

	mov.f64 	%fd1268, 0d3FF0000000000000;
	fma.rn.f64 	%fd1938, %fd327, %fd326, %fd1268;

$L__BB16_233:
	and.b32  	%r410, %r701, 2;
	setp.eq.s32 	%p238, %r410, 0;
	@%p238 bra 	$L__BB16_235;

	mov.f64 	%fd1269, 0d0000000000000000;
	mov.f64 	%fd1270, 0dBFF0000000000000;
	fma.rn.f64 	%fd1938, %fd1938, %fd1270, %fd1269;

$L__BB16_235:
	mul.rn.f64 	%fd1271, %fd1938, 0d4064000000000000;
	add.rn.f64 	%fd333, %fd320, %fd1271;
	div.rn.f64 	%fd334, %fd271, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r411, %temp}, %fd334;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r412}, %fd334;
	}
	and.b32  	%r413, %r412, 2147483647;
	setp.eq.s32 	%p239, %r413, 2146435072;
	setp.eq.s32 	%p240, %r411, 0;
	and.pred  	%p241, %p240, %p239;
	@%p241 bra 	$L__BB16_238;
	bra.uni 	$L__BB16_236;

$L__BB16_238:
	mov.f64 	%fd1281, 0d0000000000000000;
	mul.rn.f64 	%fd1939, %fd334, %fd1281;
	mov.u32 	%r702, 0;
	bra.uni 	$L__BB16_239;

$L__BB16_236:
	mul.rn.f64 	%fd1272, %fd334, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r702, %fd1272;
	st.local.u32 	[%rd1], %r702;
	cvt.rn.f64.s32 	%fd1273, %r702;
	neg.f64 	%fd1274, %fd1273;
	mov.f64 	%fd1275, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1276, %fd1274, %fd1275, %fd334;
	mov.f64 	%fd1277, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1278, %fd1274, %fd1277, %fd1276;
	mov.f64 	%fd1279, 0d397B839A252049C0;
	fma.rn.f64 	%fd1939, %fd1274, %fd1279, %fd1278;
	abs.f64 	%fd1280, %fd334;
	setp.ltu.f64 	%p242, %fd1280, 0d41E0000000000000;
	@%p242 bra 	$L__BB16_239;

	{ // callseq 247, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd334;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1939, [retval0+0];
	} // callseq 247
	ld.local.u32 	%r702, [%rd1];

$L__BB16_239:
	and.b32  	%r415, %r702, 1;
	shl.b32 	%r416, %r702, 3;
	and.b32  	%r417, %r416, 8;
	setp.eq.s32 	%p243, %r415, 0;
	selp.f64 	%fd1282, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p243;
	mul.wide.s32 	%rd171, %r417, 8;
	add.s64 	%rd173, %rd88, %rd171;
	ld.global.nc.f64 	%fd1283, [%rd173+8];
	mul.rn.f64 	%fd339, %fd1939, %fd1939;
	fma.rn.f64 	%fd1284, %fd1282, %fd339, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd173+16];
	fma.rn.f64 	%fd1286, %fd1284, %fd339, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd173+24];
	fma.rn.f64 	%fd1288, %fd1286, %fd339, %fd1287;
	ld.global.nc.f64 	%fd1289, [%rd173+32];
	fma.rn.f64 	%fd1290, %fd1288, %fd339, %fd1289;
	ld.global.nc.f64 	%fd1291, [%rd173+40];
	fma.rn.f64 	%fd1292, %fd1290, %fd339, %fd1291;
	ld.global.nc.f64 	%fd1293, [%rd173+48];
	fma.rn.f64 	%fd340, %fd1292, %fd339, %fd1293;
	fma.rn.f64 	%fd1941, %fd340, %fd1939, %fd1939;
	@%p243 bra 	$L__BB16_241;

	mov.f64 	%fd1294, 0d3FF0000000000000;
	fma.rn.f64 	%fd1941, %fd340, %fd339, %fd1294;

$L__BB16_241:
	and.b32  	%r418, %r702, 2;
	setp.eq.s32 	%p244, %r418, 0;
	@%p244 bra 	$L__BB16_243;

	mov.f64 	%fd1295, 0d0000000000000000;
	mov.f64 	%fd1296, 0dBFF0000000000000;
	fma.rn.f64 	%fd1941, %fd1941, %fd1296, %fd1295;

$L__BB16_243:
	mul.rn.f64 	%fd1297, %fd1941, 0d4074000000000000;
	add.rn.f64 	%fd346, %fd333, %fd1297;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r419}, %fd270;
	}
	and.b32  	%r420, %r419, 2147483647;
	setp.eq.s32 	%p245, %r420, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r421, %temp}, %fd270;
	}
	setp.eq.s32 	%p246, %r421, 0;
	and.pred  	%p247, %p246, %p245;
	@%p247 bra 	$L__BB16_246;
	bra.uni 	$L__BB16_244;

$L__BB16_246:
	mov.f64 	%fd1307, 0d0000000000000000;
	mul.rn.f64 	%fd1942, %fd270, %fd1307;
	mov.u32 	%r703, 0;
	bra.uni 	$L__BB16_247;

$L__BB16_244:
	mul.rn.f64 	%fd1298, %fd270, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r703, %fd1298;
	st.local.u32 	[%rd1], %r703;
	cvt.rn.f64.s32 	%fd1299, %r703;
	neg.f64 	%fd1300, %fd1299;
	mov.f64 	%fd1301, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1302, %fd1300, %fd1301, %fd270;
	mov.f64 	%fd1303, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1304, %fd1300, %fd1303, %fd1302;
	mov.f64 	%fd1305, 0d397B839A252049C0;
	fma.rn.f64 	%fd1942, %fd1300, %fd1305, %fd1304;
	abs.f64 	%fd1306, %fd270;
	setp.ltu.f64 	%p248, %fd1306, 0d41E0000000000000;
	@%p248 bra 	$L__BB16_247;

	{ // callseq 248, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd270;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1942, [retval0+0];
	} // callseq 248
	ld.local.u32 	%r703, [%rd1];

$L__BB16_247:
	and.b32  	%r423, %r703, 1;
	shl.b32 	%r424, %r703, 3;
	and.b32  	%r425, %r424, 8;
	setp.eq.s32 	%p249, %r423, 0;
	selp.f64 	%fd1308, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p249;
	mul.wide.s32 	%rd175, %r425, 8;
	add.s64 	%rd177, %rd88, %rd175;
	ld.global.nc.f64 	%fd1309, [%rd177+8];
	mul.rn.f64 	%fd351, %fd1942, %fd1942;
	fma.rn.f64 	%fd1310, %fd1308, %fd351, %fd1309;
	ld.global.nc.f64 	%fd1311, [%rd177+16];
	fma.rn.f64 	%fd1312, %fd1310, %fd351, %fd1311;
	ld.global.nc.f64 	%fd1313, [%rd177+24];
	fma.rn.f64 	%fd1314, %fd1312, %fd351, %fd1313;
	ld.global.nc.f64 	%fd1315, [%rd177+32];
	fma.rn.f64 	%fd1316, %fd1314, %fd351, %fd1315;
	ld.global.nc.f64 	%fd1317, [%rd177+40];
	fma.rn.f64 	%fd1318, %fd1316, %fd351, %fd1317;
	ld.global.nc.f64 	%fd1319, [%rd177+48];
	fma.rn.f64 	%fd352, %fd1318, %fd351, %fd1319;
	fma.rn.f64 	%fd1944, %fd352, %fd1942, %fd1942;
	@%p249 bra 	$L__BB16_249;

	mov.f64 	%fd1320, 0d3FF0000000000000;
	fma.rn.f64 	%fd1944, %fd352, %fd351, %fd1320;

$L__BB16_249:
	and.b32  	%r426, %r703, 2;
	setp.eq.s32 	%p250, %r426, 0;
	@%p250 bra 	$L__BB16_251;

	mov.f64 	%fd1321, 0d0000000000000000;
	mov.f64 	%fd1322, 0dBFF0000000000000;
	fma.rn.f64 	%fd1944, %fd1944, %fd1322, %fd1321;

$L__BB16_251:
	div.rn.f64 	%fd358, %fd270, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r427, %temp}, %fd358;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r428}, %fd358;
	}
	and.b32  	%r429, %r428, 2147483647;
	setp.eq.s32 	%p251, %r429, 2146435072;
	setp.eq.s32 	%p252, %r427, 0;
	and.pred  	%p253, %p252, %p251;
	@%p253 bra 	$L__BB16_254;
	bra.uni 	$L__BB16_252;

$L__BB16_254:
	mov.f64 	%fd1332, 0d0000000000000000;
	mul.rn.f64 	%fd1945, %fd358, %fd1332;
	mov.u32 	%r704, 0;
	bra.uni 	$L__BB16_255;

$L__BB16_252:
	mul.rn.f64 	%fd1323, %fd358, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r704, %fd1323;
	st.local.u32 	[%rd1], %r704;
	cvt.rn.f64.s32 	%fd1324, %r704;
	neg.f64 	%fd1325, %fd1324;
	mov.f64 	%fd1326, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1327, %fd1325, %fd1326, %fd358;
	mov.f64 	%fd1328, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1329, %fd1325, %fd1328, %fd1327;
	mov.f64 	%fd1330, 0d397B839A252049C0;
	fma.rn.f64 	%fd1945, %fd1325, %fd1330, %fd1329;
	abs.f64 	%fd1331, %fd358;
	setp.ltu.f64 	%p254, %fd1331, 0d41E0000000000000;
	@%p254 bra 	$L__BB16_255;

	{ // callseq 249, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd358;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1945, [retval0+0];
	} // callseq 249
	ld.local.u32 	%r704, [%rd1];

$L__BB16_255:
	and.b32  	%r431, %r704, 1;
	shl.b32 	%r432, %r704, 3;
	and.b32  	%r433, %r432, 8;
	setp.eq.s32 	%p255, %r431, 0;
	selp.f64 	%fd1333, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p255;
	mul.wide.s32 	%rd179, %r433, 8;
	add.s64 	%rd181, %rd88, %rd179;
	ld.global.nc.f64 	%fd1334, [%rd181+8];
	mul.rn.f64 	%fd363, %fd1945, %fd1945;
	fma.rn.f64 	%fd1335, %fd1333, %fd363, %fd1334;
	ld.global.nc.f64 	%fd1336, [%rd181+16];
	fma.rn.f64 	%fd1337, %fd1335, %fd363, %fd1336;
	ld.global.nc.f64 	%fd1338, [%rd181+24];
	fma.rn.f64 	%fd1339, %fd1337, %fd363, %fd1338;
	ld.global.nc.f64 	%fd1340, [%rd181+32];
	fma.rn.f64 	%fd1341, %fd1339, %fd363, %fd1340;
	ld.global.nc.f64 	%fd1342, [%rd181+40];
	fma.rn.f64 	%fd1343, %fd1341, %fd363, %fd1342;
	ld.global.nc.f64 	%fd1344, [%rd181+48];
	fma.rn.f64 	%fd364, %fd1343, %fd363, %fd1344;
	fma.rn.f64 	%fd1947, %fd364, %fd1945, %fd1945;
	@%p255 bra 	$L__BB16_257;

	mov.f64 	%fd1345, 0d3FF0000000000000;
	fma.rn.f64 	%fd1947, %fd364, %fd363, %fd1345;

$L__BB16_257:
	and.b32  	%r434, %r704, 2;
	setp.eq.s32 	%p256, %r434, 0;
	@%p256 bra 	$L__BB16_259;

	mov.f64 	%fd1346, 0d0000000000000000;
	mov.f64 	%fd1347, 0dBFF0000000000000;
	fma.rn.f64 	%fd1947, %fd1947, %fd1347, %fd1346;

$L__BB16_259:
	mul.rn.f64 	%fd1348, %fd1947, 0d4044000000000000;
	mul.rn.f64 	%fd1349, %fd1944, 0d4034000000000000;
	add.rn.f64 	%fd370, %fd1349, %fd1348;
	div.rn.f64 	%fd371, %fd270, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r435, %temp}, %fd371;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r436}, %fd371;
	}
	and.b32  	%r437, %r436, 2147483647;
	setp.eq.s32 	%p257, %r437, 2146435072;
	setp.eq.s32 	%p258, %r435, 0;
	and.pred  	%p259, %p258, %p257;
	@%p259 bra 	$L__BB16_262;
	bra.uni 	$L__BB16_260;

$L__BB16_262:
	mov.f64 	%fd1359, 0d0000000000000000;
	mul.rn.f64 	%fd1948, %fd371, %fd1359;
	mov.u32 	%r705, 0;
	bra.uni 	$L__BB16_263;

$L__BB16_260:
	mul.rn.f64 	%fd1350, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r705, %fd1350;
	st.local.u32 	[%rd1], %r705;
	cvt.rn.f64.s32 	%fd1351, %r705;
	neg.f64 	%fd1352, %fd1351;
	mov.f64 	%fd1353, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1354, %fd1352, %fd1353, %fd371;
	mov.f64 	%fd1355, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1356, %fd1352, %fd1355, %fd1354;
	mov.f64 	%fd1357, 0d397B839A252049C0;
	fma.rn.f64 	%fd1948, %fd1352, %fd1357, %fd1356;
	abs.f64 	%fd1358, %fd371;
	setp.ltu.f64 	%p260, %fd1358, 0d41E0000000000000;
	@%p260 bra 	$L__BB16_263;

	{ // callseq 250, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1948, [retval0+0];
	} // callseq 250
	ld.local.u32 	%r705, [%rd1];

$L__BB16_263:
	and.b32  	%r439, %r705, 1;
	shl.b32 	%r440, %r705, 3;
	and.b32  	%r441, %r440, 8;
	setp.eq.s32 	%p261, %r439, 0;
	selp.f64 	%fd1360, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p261;
	mul.wide.s32 	%rd183, %r441, 8;
	add.s64 	%rd185, %rd88, %rd183;
	ld.global.nc.f64 	%fd1361, [%rd185+8];
	mul.rn.f64 	%fd376, %fd1948, %fd1948;
	fma.rn.f64 	%fd1362, %fd1360, %fd376, %fd1361;
	ld.global.nc.f64 	%fd1363, [%rd185+16];
	fma.rn.f64 	%fd1364, %fd1362, %fd376, %fd1363;
	ld.global.nc.f64 	%fd1365, [%rd185+24];
	fma.rn.f64 	%fd1366, %fd1364, %fd376, %fd1365;
	ld.global.nc.f64 	%fd1367, [%rd185+32];
	fma.rn.f64 	%fd1368, %fd1366, %fd376, %fd1367;
	ld.global.nc.f64 	%fd1369, [%rd185+40];
	fma.rn.f64 	%fd1370, %fd1368, %fd376, %fd1369;
	ld.global.nc.f64 	%fd1371, [%rd185+48];
	fma.rn.f64 	%fd377, %fd1370, %fd376, %fd1371;
	fma.rn.f64 	%fd1950, %fd377, %fd1948, %fd1948;
	@%p261 bra 	$L__BB16_265;

	mov.f64 	%fd1372, 0d3FF0000000000000;
	fma.rn.f64 	%fd1950, %fd377, %fd376, %fd1372;

$L__BB16_265:
	and.b32  	%r442, %r705, 2;
	setp.eq.s32 	%p262, %r442, 0;
	@%p262 bra 	$L__BB16_267;

	mov.f64 	%fd1373, 0d0000000000000000;
	mov.f64 	%fd1374, 0dBFF0000000000000;
	fma.rn.f64 	%fd1950, %fd1950, %fd1374, %fd1373;

$L__BB16_267:
	mul.rn.f64 	%fd1375, %fd1950, 0d4062C00000000000;
	add.rn.f64 	%fd383, %fd370, %fd1375;
	div.rn.f64 	%fd384, %fd270, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r443, %temp}, %fd384;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r444}, %fd384;
	}
	and.b32  	%r445, %r444, 2147483647;
	setp.eq.s32 	%p263, %r445, 2146435072;
	setp.eq.s32 	%p264, %r443, 0;
	and.pred  	%p265, %p264, %p263;
	@%p265 bra 	$L__BB16_270;
	bra.uni 	$L__BB16_268;

$L__BB16_270:
	mov.f64 	%fd1385, 0d0000000000000000;
	mul.rn.f64 	%fd1951, %fd384, %fd1385;
	mov.u32 	%r706, 0;
	bra.uni 	$L__BB16_271;

$L__BB16_268:
	mul.rn.f64 	%fd1376, %fd384, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r706, %fd1376;
	st.local.u32 	[%rd1], %r706;
	cvt.rn.f64.s32 	%fd1377, %r706;
	neg.f64 	%fd1378, %fd1377;
	mov.f64 	%fd1379, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1380, %fd1378, %fd1379, %fd384;
	mov.f64 	%fd1381, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1382, %fd1378, %fd1381, %fd1380;
	mov.f64 	%fd1383, 0d397B839A252049C0;
	fma.rn.f64 	%fd1951, %fd1378, %fd1383, %fd1382;
	abs.f64 	%fd1384, %fd384;
	setp.ltu.f64 	%p266, %fd1384, 0d41E0000000000000;
	@%p266 bra 	$L__BB16_271;

	{ // callseq 251, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd384;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1951, [retval0+0];
	} // callseq 251
	ld.local.u32 	%r706, [%rd1];

$L__BB16_271:
	and.b32  	%r447, %r706, 1;
	shl.b32 	%r448, %r706, 3;
	and.b32  	%r449, %r448, 8;
	setp.eq.s32 	%p267, %r447, 0;
	selp.f64 	%fd1386, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p267;
	mul.wide.s32 	%rd187, %r449, 8;
	add.s64 	%rd189, %rd88, %rd187;
	ld.global.nc.f64 	%fd1387, [%rd189+8];
	mul.rn.f64 	%fd389, %fd1951, %fd1951;
	fma.rn.f64 	%fd1388, %fd1386, %fd389, %fd1387;
	ld.global.nc.f64 	%fd1389, [%rd189+16];
	fma.rn.f64 	%fd1390, %fd1388, %fd389, %fd1389;
	ld.global.nc.f64 	%fd1391, [%rd189+24];
	fma.rn.f64 	%fd1392, %fd1390, %fd389, %fd1391;
	ld.global.nc.f64 	%fd1393, [%rd189+32];
	fma.rn.f64 	%fd1394, %fd1392, %fd389, %fd1393;
	ld.global.nc.f64 	%fd1395, [%rd189+40];
	fma.rn.f64 	%fd1396, %fd1394, %fd389, %fd1395;
	ld.global.nc.f64 	%fd1397, [%rd189+48];
	fma.rn.f64 	%fd390, %fd1396, %fd389, %fd1397;
	fma.rn.f64 	%fd1953, %fd390, %fd1951, %fd1951;
	@%p267 bra 	$L__BB16_273;

	mov.f64 	%fd1398, 0d3FF0000000000000;
	fma.rn.f64 	%fd1953, %fd390, %fd389, %fd1398;

$L__BB16_273:
	and.b32  	%r450, %r706, 2;
	setp.eq.s32 	%p268, %r450, 0;
	@%p268 bra 	$L__BB16_275;

	mov.f64 	%fd1399, 0d0000000000000000;
	mov.f64 	%fd1400, 0dBFF0000000000000;
	fma.rn.f64 	%fd1953, %fd1953, %fd1400, %fd1399;

$L__BB16_275:
	mul.rn.f64 	%fd1401, %fd1953, 0d4072C00000000000;
	add.rn.f64 	%fd1402, %fd383, %fd1401;
	add.rn.f64 	%fd396, %fd296, %fd1402;
	add.rn.f64 	%fd397, %fd296, %fd346;
	add.rn.f64 	%fd1403, %fd267, %fd267;
	add.rn.f64 	%fd1404, %fd1403, 0dC059000000000000;
	mul.rn.f64 	%fd1405, %fd266, 0d4008000000000000;
	add.rn.f64 	%fd398, %fd1404, %fd1405;
	abs.f64 	%fd399, %fd266;
	{ // callseq 252, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd399;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1956, [retval0+0];
	} // callseq 252
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r100}, %fd266;
	}
	setp.lt.s32 	%p269, %r100, 0;
	and.pred  	%p7, %p269, %p16;
	not.pred 	%p271, %p7;
	@%p271 bra 	$L__BB16_277;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r451}, %fd1956;
	}
	xor.b32  	%r452, %r451, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r453, %temp}, %fd1956;
	}
	mov.b64 	%fd1956, {%r453, %r452};

$L__BB16_277:
	setp.eq.f64 	%p272, %fd266, 0d0000000000000000;
	@%p272 bra 	$L__BB16_281;
	bra.uni 	$L__BB16_278;

$L__BB16_281:
	setp.lt.s32 	%p275, %r3, 0;
	mov.u32 	%r454, 0;
	selp.b32 	%r455, %r100, 0, %p16;
	or.b32  	%r456, %r455, 2146435072;
	selp.b32 	%r457, %r456, %r455, %p275;
	mov.b64 	%fd1956, {%r454, %r457};
	bra.uni 	$L__BB16_282;

$L__BB16_278:
	setp.gt.s32 	%p273, %r100, -1;
	@%p273 bra 	$L__BB16_282;

	mov.f64 	%fd1406, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1407, %fd1406;
	setp.eq.f64 	%p274, %fd1407, 0d4000000000000000;
	@%p274 bra 	$L__BB16_282;

	mov.f64 	%fd1956, 0dFFF8000000000000;

$L__BB16_282:
	add.rn.f64 	%fd1409, %fd266, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r458}, %fd1409;
	}
	and.b32  	%r459, %r458, 2146435072;
	setp.ne.s32 	%p277, %r459, 2146435072;
	@%p277 bra 	$L__BB16_289;

	setp.gtu.f64 	%p278, %fd399, 0d7FF0000000000000;
	@%p278 bra 	$L__BB16_288;
	bra.uni 	$L__BB16_284;

$L__BB16_288:
	mov.f64 	%fd1411, 0d4000000000000000;
	add.rn.f64 	%fd1956, %fd266, %fd1411;
	bra.uni 	$L__BB16_289;

$L__BB16_284:
	setp.eq.s32 	%p279, %r66, 2146435072;
	mov.f64 	%fd1410, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r460, %temp}, %fd1410;
	}
	setp.eq.s32 	%p280, %r460, 0;
	and.pred  	%p281, %p279, %p280;
	@%p281 bra 	$L__BB16_287;
	bra.uni 	$L__BB16_285;

$L__BB16_287:
	setp.lt.s32 	%p287, %r3, 0;
	mov.u32 	%r465, 0;
	setp.gt.f64 	%p288, %fd399, 0d3FF0000000000000;
	selp.b32 	%r466, 2146435072, 0, %p288;
	xor.b32  	%r467, %r466, 2146435072;
	selp.b32 	%r468, %r467, %r466, %p287;
	setp.eq.f64 	%p289, %fd266, 0dBFF0000000000000;
	selp.b32 	%r469, 1072693248, %r468, %p289;
	mov.b64 	%fd1956, {%r465, %r469};
	bra.uni 	$L__BB16_289;

$L__BB16_285:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r461, %temp}, %fd266;
	}
	and.b32  	%r462, %r100, 2147483647;
	setp.ne.s32 	%p282, %r462, 2146435072;
	setp.ne.s32 	%p283, %r461, 0;
	or.pred  	%p284, %p282, %p283;
	@%p284 bra 	$L__BB16_289;

	setp.ne.s32 	%p285, %r66, 1071644672;
	and.pred  	%p286, %p285, %p7;
	selp.b32 	%r463, %r68, %r67, %p286;
	mov.u32 	%r464, 0;
	mov.b64 	%fd1956, {%r464, %r463};

$L__BB16_289:
	mul.rn.f64 	%fd1412, %fd1956, 0d3FC999999999999A;
	setp.eq.f64 	%p290, %fd266, 0d3FF0000000000000;
	selp.f64 	%fd1413, 0d3FC999999999999A, %fd1412, %p290;
	add.rn.f64 	%fd1414, %fd398, %fd1413;
	mul.rn.f64 	%fd1415, %fd267, %fd266;
	mul.rn.f64 	%fd409, %fd1415, 0d3FB999999999999A;
	add.rn.f64 	%fd1416, %fd409, %fd1414;
	mul.rn.f64 	%fd1417, %fd269, 0d3FC999999999999A;
	add.rn.f64 	%fd1418, %fd1417, %fd1416;
	mul.rn.f64 	%fd1419, %fd397, 0d3FE5555555555555;
	add.rn.f64 	%fd410, %fd1419, %fd1418;
	add.rn.f64 	%fd1420, %fd266, %fd266;
	add.rn.f64 	%fd1421, %fd267, 0d4072C00000000000;
	add.rn.f64 	%fd411, %fd1421, %fd1420;
	{ // callseq 253, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd268;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1959, [retval0+0];
	} // callseq 253
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r101}, %fd267;
	}
	setp.lt.s32 	%p291, %r101, 0;
	and.pred  	%p8, %p291, %p16;
	not.pred 	%p293, %p8;
	@%p293 bra 	$L__BB16_291;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r470}, %fd1959;
	}
	xor.b32  	%r471, %r470, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r472, %temp}, %fd1959;
	}
	mov.b64 	%fd1959, {%r472, %r471};

$L__BB16_291:
	setp.eq.f64 	%p294, %fd267, 0d0000000000000000;
	@%p294 bra 	$L__BB16_295;
	bra.uni 	$L__BB16_292;

$L__BB16_295:
	setp.lt.s32 	%p297, %r3, 0;
	mov.u32 	%r473, 0;
	selp.b32 	%r474, %r101, 0, %p16;
	or.b32  	%r475, %r474, 2146435072;
	selp.b32 	%r476, %r475, %r474, %p297;
	mov.b64 	%fd1959, {%r473, %r476};
	bra.uni 	$L__BB16_296;

$L__BB16_292:
	setp.gt.s32 	%p295, %r101, -1;
	@%p295 bra 	$L__BB16_296;

	mov.f64 	%fd1422, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1423, %fd1422;
	setp.eq.f64 	%p296, %fd1423, 0d4000000000000000;
	@%p296 bra 	$L__BB16_296;

	mov.f64 	%fd1959, 0dFFF8000000000000;

$L__BB16_296:
	add.rn.f64 	%fd1425, %fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r477}, %fd1425;
	}
	and.b32  	%r478, %r477, 2146435072;
	setp.ne.s32 	%p299, %r478, 2146435072;
	@%p299 bra 	$L__BB16_303;

	setp.gtu.f64 	%p300, %fd268, 0d7FF0000000000000;
	@%p300 bra 	$L__BB16_302;
	bra.uni 	$L__BB16_298;

$L__BB16_302:
	mov.f64 	%fd1427, 0d4000000000000000;
	add.rn.f64 	%fd1959, %fd267, %fd1427;
	bra.uni 	$L__BB16_303;

$L__BB16_298:
	setp.eq.s32 	%p301, %r66, 2146435072;
	mov.f64 	%fd1426, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r479, %temp}, %fd1426;
	}
	setp.eq.s32 	%p302, %r479, 0;
	and.pred  	%p303, %p301, %p302;
	@%p303 bra 	$L__BB16_301;
	bra.uni 	$L__BB16_299;

$L__BB16_301:
	setp.lt.s32 	%p309, %r3, 0;
	mov.u32 	%r484, 0;
	setp.gt.f64 	%p310, %fd268, 0d3FF0000000000000;
	selp.b32 	%r485, 2146435072, 0, %p310;
	xor.b32  	%r486, %r485, 2146435072;
	selp.b32 	%r487, %r486, %r485, %p309;
	setp.eq.f64 	%p311, %fd267, 0dBFF0000000000000;
	selp.b32 	%r488, 1072693248, %r487, %p311;
	mov.b64 	%fd1959, {%r484, %r488};
	bra.uni 	$L__BB16_303;

$L__BB16_299:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r480, %temp}, %fd267;
	}
	and.b32  	%r481, %r101, 2147483647;
	setp.ne.s32 	%p304, %r481, 2146435072;
	setp.ne.s32 	%p305, %r480, 0;
	or.pred  	%p306, %p304, %p305;
	@%p306 bra 	$L__BB16_303;

	setp.ne.s32 	%p307, %r66, 1071644672;
	and.pred  	%p308, %p307, %p8;
	selp.b32 	%r482, %r68, %r67, %p308;
	mov.u32 	%r483, 0;
	mov.b64 	%fd1959, {%r483, %r482};

$L__BB16_303:
	mul.rn.f64 	%fd1428, %fd1959, 0d3FB999999999999A;
	setp.eq.f64 	%p312, %fd267, 0d3FF0000000000000;
	selp.f64 	%fd1429, 0d3FB999999999999A, %fd1428, %p312;
	add.rn.f64 	%fd1430, %fd411, %fd1429;
	add.rn.f64 	%fd1431, %fd409, %fd1430;
	mul.rn.f64 	%fd1432, %fd269, 0d3FB999999999999A;
	add.rn.f64 	%fd1433, %fd1432, %fd1431;
	mul.rn.f64 	%fd1434, %fd396, 0d3FE5555555555555;
	add.rn.f64 	%fd421, %fd1434, %fd1433;
	div.rn.f64 	%fd1435, %fd2010, 0d4066800000000000;
	mul.rn.f64 	%fd422, %fd1435, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r489, %temp}, %fd422;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r490}, %fd422;
	}
	and.b32  	%r491, %r490, 2147483647;
	setp.eq.s32 	%p313, %r491, 2146435072;
	setp.eq.s32 	%p314, %r489, 0;
	and.pred  	%p9, %p314, %p313;
	@%p9 bra 	$L__BB16_306;
	bra.uni 	$L__BB16_304;

$L__BB16_306:
	mov.f64 	%fd1445, 0d0000000000000000;
	mul.rn.f64 	%fd1960, %fd422, %fd1445;
	mov.u32 	%r707, 0;
	bra.uni 	$L__BB16_307;

$L__BB16_304:
	mul.rn.f64 	%fd1436, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r707, %fd1436;
	st.local.u32 	[%rd1], %r707;
	cvt.rn.f64.s32 	%fd1437, %r707;
	neg.f64 	%fd1438, %fd1437;
	mov.f64 	%fd1439, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1440, %fd1438, %fd1439, %fd422;
	mov.f64 	%fd1441, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1442, %fd1438, %fd1441, %fd1440;
	mov.f64 	%fd1443, 0d397B839A252049C0;
	fma.rn.f64 	%fd1960, %fd1438, %fd1443, %fd1442;
	abs.f64 	%fd1444, %fd422;
	setp.ltu.f64 	%p315, %fd1444, 0d41E0000000000000;
	@%p315 bra 	$L__BB16_307;

	{ // callseq 254, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1960, [retval0+0];
	} // callseq 254
	ld.local.u32 	%r707, [%rd1];

$L__BB16_307:
	and.b32  	%r493, %r707, 1;
	shl.b32 	%r494, %r707, 3;
	and.b32  	%r495, %r494, 8;
	setp.eq.s32 	%p316, %r493, 0;
	selp.f64 	%fd1446, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p316;
	mul.wide.s32 	%rd191, %r495, 8;
	add.s64 	%rd193, %rd88, %rd191;
	ld.global.nc.f64 	%fd1447, [%rd193+8];
	mul.rn.f64 	%fd427, %fd1960, %fd1960;
	fma.rn.f64 	%fd1448, %fd1446, %fd427, %fd1447;
	ld.global.nc.f64 	%fd1449, [%rd193+16];
	fma.rn.f64 	%fd1450, %fd1448, %fd427, %fd1449;
	ld.global.nc.f64 	%fd1451, [%rd193+24];
	fma.rn.f64 	%fd1452, %fd1450, %fd427, %fd1451;
	ld.global.nc.f64 	%fd1453, [%rd193+32];
	fma.rn.f64 	%fd1454, %fd1452, %fd427, %fd1453;
	ld.global.nc.f64 	%fd1455, [%rd193+40];
	fma.rn.f64 	%fd1456, %fd1454, %fd427, %fd1455;
	ld.global.nc.f64 	%fd1457, [%rd193+48];
	fma.rn.f64 	%fd428, %fd1456, %fd427, %fd1457;
	fma.rn.f64 	%fd1962, %fd428, %fd1960, %fd1960;
	@%p316 bra 	$L__BB16_309;

	mov.f64 	%fd1458, 0d3FF0000000000000;
	fma.rn.f64 	%fd1962, %fd428, %fd427, %fd1458;

$L__BB16_309:
	and.b32  	%r496, %r707, 2;
	setp.eq.s32 	%p317, %r496, 0;
	@%p317 bra 	$L__BB16_311;

	mov.f64 	%fd1459, 0d0000000000000000;
	mov.f64 	%fd1460, 0dBFF0000000000000;
	fma.rn.f64 	%fd1962, %fd1962, %fd1460, %fd1459;

$L__BB16_311:
	@%p9 bra 	$L__BB16_315;
	bra.uni 	$L__BB16_312;

$L__BB16_315:
	mov.f64 	%fd1470, 0d0000000000000000;
	mul.rn.f64 	%fd1964, %fd422, %fd1470;
	mov.u32 	%r709, 1;
	bra.uni 	$L__BB16_316;

$L__BB16_312:
	mul.rn.f64 	%fd1461, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r708, %fd1461;
	st.local.u32 	[%rd1], %r708;
	cvt.rn.f64.s32 	%fd1462, %r708;
	neg.f64 	%fd1463, %fd1462;
	mov.f64 	%fd1464, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1465, %fd1463, %fd1464, %fd422;
	mov.f64 	%fd1466, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1467, %fd1463, %fd1466, %fd1465;
	mov.f64 	%fd1468, 0d397B839A252049C0;
	fma.rn.f64 	%fd1964, %fd1463, %fd1468, %fd1467;
	abs.f64 	%fd1469, %fd422;
	setp.ltu.f64 	%p318, %fd1469, 0d41E0000000000000;
	@%p318 bra 	$L__BB16_314;

	{ // callseq 255, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1964, [retval0+0];
	} // callseq 255
	ld.local.u32 	%r708, [%rd1];

$L__BB16_314:
	add.s32 	%r709, %r708, 1;

$L__BB16_316:
	and.b32  	%r498, %r709, 1;
	shl.b32 	%r499, %r709, 3;
	and.b32  	%r500, %r499, 8;
	setp.eq.s32 	%p319, %r498, 0;
	selp.f64 	%fd1471, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p319;
	mul.wide.s32 	%rd195, %r500, 8;
	add.s64 	%rd197, %rd88, %rd195;
	ld.global.nc.f64 	%fd1472, [%rd197+8];
	mul.rn.f64 	%fd439, %fd1964, %fd1964;
	fma.rn.f64 	%fd1473, %fd1471, %fd439, %fd1472;
	ld.global.nc.f64 	%fd1474, [%rd197+16];
	fma.rn.f64 	%fd1475, %fd1473, %fd439, %fd1474;
	ld.global.nc.f64 	%fd1476, [%rd197+24];
	fma.rn.f64 	%fd1477, %fd1475, %fd439, %fd1476;
	ld.global.nc.f64 	%fd1478, [%rd197+32];
	fma.rn.f64 	%fd1479, %fd1477, %fd439, %fd1478;
	ld.global.nc.f64 	%fd1480, [%rd197+40];
	fma.rn.f64 	%fd1481, %fd1479, %fd439, %fd1480;
	ld.global.nc.f64 	%fd1482, [%rd197+48];
	fma.rn.f64 	%fd440, %fd1481, %fd439, %fd1482;
	fma.rn.f64 	%fd1966, %fd440, %fd1964, %fd1964;
	@%p319 bra 	$L__BB16_318;

	mov.f64 	%fd1483, 0d3FF0000000000000;
	fma.rn.f64 	%fd1966, %fd440, %fd439, %fd1483;

$L__BB16_318:
	and.b32  	%r501, %r709, 2;
	setp.eq.s32 	%p320, %r501, 0;
	@%p320 bra 	$L__BB16_320;

	mov.f64 	%fd1484, 0d0000000000000000;
	mov.f64 	%fd1485, 0dBFF0000000000000;
	fma.rn.f64 	%fd1966, %fd1966, %fd1485, %fd1484;

$L__BB16_320:
	mul.rn.f64 	%fd1486, %fd1962, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1487, %fd1962, %fd1486;
	add.rn.f64 	%fd1488, %fd1487, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1489, %fd1488;
	mov.f64 	%fd1490, 0d415854C140000000;
	div.rn.f64 	%fd1491, %fd1490, %fd1489;
	mul.rn.f64 	%fd1492, %fd1491, %fd1966;
	mul.rn.f64 	%fd1493, %fd1492, 0d400921FB54442D18;
	mul.rn.f64 	%fd1494, %fd421, 0d4066800000000000;
	div.rn.f64 	%fd1495, %fd1494, %fd1493;
	add.rn.f64 	%fd446, %fd2009, %fd1495;
	mul.rn.f64 	%fd1496, %fd410, 0d4066800000000000;
	mul.rn.f64 	%fd1497, %fd1489, %fd1488;
	mov.f64 	%fd1498, 0d41582B102DE355C1;
	div.rn.f64 	%fd1499, %fd1498, %fd1497;
	mul.rn.f64 	%fd1500, %fd1499, 0d400921FB54442D18;
	div.rn.f64 	%fd1501, %fd1496, %fd1500;
	add.rn.f64 	%fd447, %fd2010, %fd1501;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd446;
	}
	abs.f64 	%fd448, %fd446;
	{ // callseq 256, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd448;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1969, [retval0+0];
	} // callseq 256
	setp.lt.s32 	%p321, %r110, 0;
	and.pred  	%p10, %p321, %p16;
	not.pred 	%p323, %p10;
	@%p323 bra 	$L__BB16_322;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r502}, %fd1969;
	}
	xor.b32  	%r503, %r502, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r504, %temp}, %fd1969;
	}
	mov.b64 	%fd1969, {%r504, %r503};

$L__BB16_322:
	setp.eq.f64 	%p324, %fd446, 0d0000000000000000;
	@%p324 bra 	$L__BB16_326;
	bra.uni 	$L__BB16_323;

$L__BB16_326:
	setp.lt.s32 	%p327, %r3, 0;
	mov.u32 	%r505, 0;
	selp.b32 	%r506, %r110, 0, %p16;
	or.b32  	%r507, %r506, 2146435072;
	selp.b32 	%r508, %r507, %r506, %p327;
	mov.b64 	%fd1969, {%r505, %r508};
	bra.uni 	$L__BB16_327;

$L__BB16_323:
	setp.gt.s32 	%p325, %r110, -1;
	@%p325 bra 	$L__BB16_327;

	mov.f64 	%fd1502, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1503, %fd1502;
	setp.eq.f64 	%p326, %fd1503, 0d4000000000000000;
	@%p326 bra 	$L__BB16_327;

	mov.f64 	%fd1969, 0dFFF8000000000000;

$L__BB16_327:
	add.rn.f64 	%fd1505, %fd446, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r509}, %fd1505;
	}
	and.b32  	%r510, %r509, 2146435072;
	setp.ne.s32 	%p329, %r510, 2146435072;
	@%p329 bra 	$L__BB16_334;

	setp.gtu.f64 	%p330, %fd448, 0d7FF0000000000000;
	@%p330 bra 	$L__BB16_333;
	bra.uni 	$L__BB16_329;

$L__BB16_333:
	mov.f64 	%fd1507, 0d4000000000000000;
	add.rn.f64 	%fd1969, %fd446, %fd1507;
	bra.uni 	$L__BB16_334;

$L__BB16_329:
	setp.eq.s32 	%p331, %r66, 2146435072;
	mov.f64 	%fd1506, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r511, %temp}, %fd1506;
	}
	setp.eq.s32 	%p332, %r511, 0;
	and.pred  	%p333, %p331, %p332;
	@%p333 bra 	$L__BB16_332;
	bra.uni 	$L__BB16_330;

$L__BB16_332:
	setp.lt.s32 	%p339, %r3, 0;
	mov.u32 	%r516, 0;
	setp.gt.f64 	%p340, %fd448, 0d3FF0000000000000;
	selp.b32 	%r517, 2146435072, 0, %p340;
	xor.b32  	%r518, %r517, 2146435072;
	selp.b32 	%r519, %r518, %r517, %p339;
	setp.eq.f64 	%p341, %fd446, 0dBFF0000000000000;
	selp.b32 	%r520, 1072693248, %r519, %p341;
	mov.b64 	%fd1969, {%r516, %r520};
	bra.uni 	$L__BB16_334;

$L__BB16_330:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r512, %temp}, %fd446;
	}
	and.b32  	%r513, %r110, 2147483647;
	setp.ne.s32 	%p334, %r513, 2146435072;
	setp.ne.s32 	%p335, %r512, 0;
	or.pred  	%p336, %p334, %p335;
	@%p336 bra 	$L__BB16_334;

	setp.ne.s32 	%p337, %r66, 1071644672;
	and.pred  	%p338, %p337, %p10;
	selp.b32 	%r514, %r68, %r67, %p338;
	mov.u32 	%r515, 0;
	mov.b64 	%fd1969, {%r515, %r514};

$L__BB16_334:
	abs.f64 	%fd458, %fd447;
	{ // callseq 257, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd458;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1972, [retval0+0];
	} // callseq 257
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r111}, %fd447;
	}
	setp.lt.s32 	%p342, %r111, 0;
	and.pred  	%p11, %p342, %p16;
	not.pred 	%p344, %p11;
	@%p344 bra 	$L__BB16_336;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r521}, %fd1972;
	}
	xor.b32  	%r522, %r521, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r523, %temp}, %fd1972;
	}
	mov.b64 	%fd1972, {%r523, %r522};

$L__BB16_336:
	setp.eq.f64 	%p345, %fd447, 0d0000000000000000;
	@%p345 bra 	$L__BB16_340;
	bra.uni 	$L__BB16_337;

$L__BB16_340:
	setp.lt.s32 	%p348, %r3, 0;
	mov.u32 	%r524, 0;
	selp.b32 	%r525, %r111, 0, %p16;
	or.b32  	%r526, %r525, 2146435072;
	selp.b32 	%r527, %r526, %r525, %p348;
	mov.b64 	%fd1972, {%r524, %r527};
	bra.uni 	$L__BB16_341;

$L__BB16_337:
	setp.gt.s32 	%p346, %r111, -1;
	@%p346 bra 	$L__BB16_341;

	mov.f64 	%fd1508, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1509, %fd1508;
	setp.eq.f64 	%p347, %fd1509, 0d4000000000000000;
	@%p347 bra 	$L__BB16_341;

	mov.f64 	%fd1972, 0dFFF8000000000000;

$L__BB16_341:
	add.rn.f64 	%fd1511, %fd447, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r528}, %fd1511;
	}
	and.b32  	%r529, %r528, 2146435072;
	setp.ne.s32 	%p350, %r529, 2146435072;
	@%p350 bra 	$L__BB16_348;

	setp.gtu.f64 	%p351, %fd458, 0d7FF0000000000000;
	@%p351 bra 	$L__BB16_347;
	bra.uni 	$L__BB16_343;

$L__BB16_347:
	mov.f64 	%fd1513, 0d4000000000000000;
	add.rn.f64 	%fd1972, %fd447, %fd1513;
	bra.uni 	$L__BB16_348;

$L__BB16_343:
	setp.eq.s32 	%p352, %r66, 2146435072;
	mov.f64 	%fd1512, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r530, %temp}, %fd1512;
	}
	setp.eq.s32 	%p353, %r530, 0;
	and.pred  	%p354, %p352, %p353;
	@%p354 bra 	$L__BB16_346;
	bra.uni 	$L__BB16_344;

$L__BB16_346:
	setp.lt.s32 	%p360, %r3, 0;
	mov.u32 	%r535, 0;
	setp.gt.f64 	%p361, %fd458, 0d3FF0000000000000;
	selp.b32 	%r536, 2146435072, 0, %p361;
	xor.b32  	%r537, %r536, 2146435072;
	selp.b32 	%r538, %r537, %r536, %p360;
	setp.eq.f64 	%p362, %fd447, 0dBFF0000000000000;
	selp.b32 	%r539, 1072693248, %r538, %p362;
	mov.b64 	%fd1972, {%r535, %r539};
	bra.uni 	$L__BB16_348;

$L__BB16_344:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r531, %temp}, %fd447;
	}
	and.b32  	%r532, %r111, 2147483647;
	setp.ne.s32 	%p355, %r532, 2146435072;
	setp.ne.s32 	%p356, %r531, 0;
	or.pred  	%p357, %p355, %p356;
	@%p357 bra 	$L__BB16_348;

	setp.ne.s32 	%p358, %r66, 1071644672;
	and.pred  	%p359, %p358, %p11;
	selp.b32 	%r533, %r68, %r67, %p359;
	mov.u32 	%r534, 0;
	mov.b64 	%fd1972, {%r534, %r533};

$L__BB16_348:
	setp.eq.f64 	%p363, %fd447, 0d3FF0000000000000;
	selp.f64 	%fd1514, 0d3FF0000000000000, %fd1972, %p363;
	setp.eq.f64 	%p364, %fd446, 0d3FF0000000000000;
	selp.f64 	%fd1515, 0d3FF0000000000000, %fd1969, %p364;
	add.rn.f64 	%fd468, %fd1515, %fd1514;
	mul.rn.f64 	%fd469, %fd447, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r540, %temp}, %fd469;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r541}, %fd469;
	}
	and.b32  	%r542, %r541, 2147483647;
	setp.eq.s32 	%p365, %r542, 2146435072;
	setp.eq.s32 	%p366, %r540, 0;
	and.pred  	%p367, %p366, %p365;
	@%p367 bra 	$L__BB16_351;
	bra.uni 	$L__BB16_349;

$L__BB16_351:
	mov.f64 	%fd1525, 0d0000000000000000;
	mul.rn.f64 	%fd1973, %fd469, %fd1525;
	mov.u32 	%r710, 0;
	bra.uni 	$L__BB16_352;

$L__BB16_349:
	mul.rn.f64 	%fd1516, %fd469, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r710, %fd1516;
	st.local.u32 	[%rd1], %r710;
	cvt.rn.f64.s32 	%fd1517, %r710;
	neg.f64 	%fd1518, %fd1517;
	mov.f64 	%fd1519, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1520, %fd1518, %fd1519, %fd469;
	mov.f64 	%fd1521, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1522, %fd1518, %fd1521, %fd1520;
	mov.f64 	%fd1523, 0d397B839A252049C0;
	fma.rn.f64 	%fd1973, %fd1518, %fd1523, %fd1522;
	abs.f64 	%fd1524, %fd469;
	setp.ltu.f64 	%p368, %fd1524, 0d41E0000000000000;
	@%p368 bra 	$L__BB16_352;

	{ // callseq 258, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd469;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1973, [retval0+0];
	} // callseq 258
	ld.local.u32 	%r710, [%rd1];

$L__BB16_352:
	and.b32  	%r544, %r710, 1;
	shl.b32 	%r545, %r710, 3;
	and.b32  	%r546, %r545, 8;
	setp.eq.s32 	%p369, %r544, 0;
	selp.f64 	%fd1526, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p369;
	mul.wide.s32 	%rd199, %r546, 8;
	add.s64 	%rd201, %rd88, %rd199;
	ld.global.nc.f64 	%fd1527, [%rd201+8];
	mul.rn.f64 	%fd474, %fd1973, %fd1973;
	fma.rn.f64 	%fd1528, %fd1526, %fd474, %fd1527;
	ld.global.nc.f64 	%fd1529, [%rd201+16];
	fma.rn.f64 	%fd1530, %fd1528, %fd474, %fd1529;
	ld.global.nc.f64 	%fd1531, [%rd201+24];
	fma.rn.f64 	%fd1532, %fd1530, %fd474, %fd1531;
	ld.global.nc.f64 	%fd1533, [%rd201+32];
	fma.rn.f64 	%fd1534, %fd1532, %fd474, %fd1533;
	ld.global.nc.f64 	%fd1535, [%rd201+40];
	fma.rn.f64 	%fd1536, %fd1534, %fd474, %fd1535;
	ld.global.nc.f64 	%fd1537, [%rd201+48];
	fma.rn.f64 	%fd475, %fd1536, %fd474, %fd1537;
	fma.rn.f64 	%fd1975, %fd475, %fd1973, %fd1973;
	@%p369 bra 	$L__BB16_354;

	mov.f64 	%fd1538, 0d3FF0000000000000;
	fma.rn.f64 	%fd1975, %fd475, %fd474, %fd1538;

$L__BB16_354:
	and.b32  	%r547, %r710, 2;
	setp.eq.s32 	%p370, %r547, 0;
	@%p370 bra 	$L__BB16_356;

	mov.f64 	%fd1539, 0d0000000000000000;
	mov.f64 	%fd1540, 0dBFF0000000000000;
	fma.rn.f64 	%fd1975, %fd1975, %fd1540, %fd1539;

$L__BB16_356:
	mul.rn.f64 	%fd1541, %fd1975, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd1542, %fd468;
	add.rn.f64 	%fd481, %fd1542, %fd1541;
	setp.eq.f64 	%p371, %fd458, 0d0000000000000000;
	setp.eq.f64 	%p372, %fd448, 0d0000000000000000;
	and.pred  	%p373, %p372, %p371;
	@%p373 bra 	$L__BB16_360;
	bra.uni 	$L__BB16_357;

$L__BB16_360:
	selp.f64 	%fd1595, 0d400921FB54442D18, 0d0000000000000000, %p321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r556, %temp}, %fd1595;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r557}, %fd1595;
	}
	and.b32  	%r558, %r111, -2147483648;
	or.b32  	%r559, %r557, %r558;
	mov.b64 	%fd1976, {%r556, %r559};
	bra.uni 	$L__BB16_361;

$L__BB16_357:
	setp.eq.f64 	%p374, %fd448, 0d7FF0000000000000;
	setp.eq.f64 	%p375, %fd458, 0d7FF0000000000000;
	and.pred  	%p376, %p374, %p375;
	@%p376 bra 	$L__BB16_359;
	bra.uni 	$L__BB16_358;

$L__BB16_359:
	selp.f64 	%fd1594, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r552, %temp}, %fd1594;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r553}, %fd1594;
	}
	and.b32  	%r554, %r111, -2147483648;
	or.b32  	%r555, %r553, %r554;
	mov.b64 	%fd1976, {%r552, %r555};
	bra.uni 	$L__BB16_361;

$L__BB16_358:
	min.f64 	%fd1543, %fd458, %fd448;
	max.f64 	%fd1544, %fd458, %fd448;
	div.rn.f64 	%fd1545, %fd1543, %fd1544;
	mul.rn.f64 	%fd1546, %fd1545, %fd1545;
	mov.f64 	%fd1547, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1548, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1549, %fd1548, %fd1546, %fd1547;
	mov.f64 	%fd1550, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1551, %fd1549, %fd1546, %fd1550;
	mov.f64 	%fd1552, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1553, %fd1551, %fd1546, %fd1552;
	mov.f64 	%fd1554, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1555, %fd1553, %fd1546, %fd1554;
	mov.f64 	%fd1556, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1557, %fd1555, %fd1546, %fd1556;
	mov.f64 	%fd1558, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1559, %fd1557, %fd1546, %fd1558;
	mov.f64 	%fd1560, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1561, %fd1559, %fd1546, %fd1560;
	mov.f64 	%fd1562, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1563, %fd1561, %fd1546, %fd1562;
	mov.f64 	%fd1564, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1565, %fd1563, %fd1546, %fd1564;
	mov.f64 	%fd1566, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1567, %fd1565, %fd1546, %fd1566;
	mov.f64 	%fd1568, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1569, %fd1567, %fd1546, %fd1568;
	mov.f64 	%fd1570, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1571, %fd1569, %fd1546, %fd1570;
	mov.f64 	%fd1572, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1573, %fd1571, %fd1546, %fd1572;
	mov.f64 	%fd1574, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1575, %fd1573, %fd1546, %fd1574;
	mov.f64 	%fd1576, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1577, %fd1575, %fd1546, %fd1576;
	mov.f64 	%fd1578, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1579, %fd1577, %fd1546, %fd1578;
	mov.f64 	%fd1580, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1581, %fd1579, %fd1546, %fd1580;
	mov.f64 	%fd1582, 0dBFD555555555544C;
	fma.rn.f64 	%fd1583, %fd1581, %fd1546, %fd1582;
	mul.rn.f64 	%fd1584, %fd1546, %fd1583;
	fma.rn.f64 	%fd1585, %fd1584, %fd1545, %fd1545;
	mov.f64 	%fd1586, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1587, %fd1586, %fd1585;
	setp.gt.f64 	%p378, %fd458, %fd448;
	selp.f64 	%fd1588, %fd1587, %fd1585, %p378;
	mov.f64 	%fd1589, 0d400921FB54442D18;
	sub.rn.f64 	%fd1590, %fd1589, %fd1588;
	selp.f64 	%fd1591, %fd1590, %fd1588, %p321;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r548, %temp}, %fd1591;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r549}, %fd1591;
	}
	and.b32  	%r550, %r111, -2147483648;
	or.b32  	%r551, %r549, %r550;
	mov.b64 	%fd1592, {%r548, %r551};
	add.rn.f64 	%fd1593, %fd448, %fd458;
	setp.le.f64 	%p379, %fd1593, 0d7FF0000000000000;
	selp.f64 	%fd1976, %fd1592, %fd1593, %p379;

$L__BB16_361:
	mul.rn.f64 	%fd486, %fd446, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r560, %temp}, %fd486;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r561}, %fd486;
	}
	and.b32  	%r562, %r561, 2147483647;
	setp.eq.s32 	%p382, %r562, 2146435072;
	setp.eq.s32 	%p383, %r560, 0;
	and.pred  	%p384, %p383, %p382;
	@%p384 bra 	$L__BB16_365;
	bra.uni 	$L__BB16_362;

$L__BB16_365:
	mov.f64 	%fd1605, 0d0000000000000000;
	mul.rn.f64 	%fd1978, %fd486, %fd1605;
	mov.u32 	%r712, 1;
	bra.uni 	$L__BB16_366;

$L__BB16_362:
	mul.rn.f64 	%fd1596, %fd486, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r711, %fd1596;
	st.local.u32 	[%rd1], %r711;
	cvt.rn.f64.s32 	%fd1597, %r711;
	neg.f64 	%fd1598, %fd1597;
	mov.f64 	%fd1599, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1600, %fd1598, %fd1599, %fd486;
	mov.f64 	%fd1601, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1602, %fd1598, %fd1601, %fd1600;
	mov.f64 	%fd1603, 0d397B839A252049C0;
	fma.rn.f64 	%fd1978, %fd1598, %fd1603, %fd1602;
	abs.f64 	%fd1604, %fd486;
	setp.ltu.f64 	%p385, %fd1604, 0d41E0000000000000;
	@%p385 bra 	$L__BB16_364;

	{ // callseq 259, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd486;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1978, [retval0+0];
	} // callseq 259
	ld.local.u32 	%r711, [%rd1];

$L__BB16_364:
	add.s32 	%r712, %r711, 1;

$L__BB16_366:
	and.b32  	%r564, %r712, 1;
	shl.b32 	%r565, %r712, 3;
	and.b32  	%r566, %r565, 8;
	setp.eq.s32 	%p386, %r564, 0;
	selp.f64 	%fd1606, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p386;
	mul.wide.s32 	%rd203, %r566, 8;
	add.s64 	%rd205, %rd88, %rd203;
	ld.global.nc.f64 	%fd1607, [%rd205+8];
	mul.rn.f64 	%fd492, %fd1978, %fd1978;
	fma.rn.f64 	%fd1608, %fd1606, %fd492, %fd1607;
	ld.global.nc.f64 	%fd1609, [%rd205+16];
	fma.rn.f64 	%fd1610, %fd1608, %fd492, %fd1609;
	ld.global.nc.f64 	%fd1611, [%rd205+24];
	fma.rn.f64 	%fd1612, %fd1610, %fd492, %fd1611;
	ld.global.nc.f64 	%fd1613, [%rd205+32];
	fma.rn.f64 	%fd1614, %fd1612, %fd492, %fd1613;
	ld.global.nc.f64 	%fd1615, [%rd205+40];
	fma.rn.f64 	%fd1616, %fd1614, %fd492, %fd1615;
	ld.global.nc.f64 	%fd1617, [%rd205+48];
	fma.rn.f64 	%fd493, %fd1616, %fd492, %fd1617;
	fma.rn.f64 	%fd1980, %fd493, %fd1978, %fd1978;
	@%p386 bra 	$L__BB16_368;

	mov.f64 	%fd1618, 0d3FF0000000000000;
	fma.rn.f64 	%fd1980, %fd493, %fd492, %fd1618;

$L__BB16_368:
	and.b32  	%r567, %r712, 2;
	setp.eq.s32 	%p387, %r567, 0;
	@%p387 bra 	$L__BB16_370;

	mov.f64 	%fd1619, 0d0000000000000000;
	mov.f64 	%fd1620, 0dBFF0000000000000;
	fma.rn.f64 	%fd1980, %fd1980, %fd1620, %fd1619;

$L__BB16_370:
	mul.rn.f64 	%fd1621, %fd1980, 0d3EC92A737110E454;
	add.rn.f64 	%fd499, %fd1976, %fd1621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r568, %temp}, %fd499;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r569}, %fd499;
	}
	and.b32  	%r570, %r569, 2147483647;
	setp.eq.s32 	%p388, %r570, 2146435072;
	setp.eq.s32 	%p389, %r568, 0;
	and.pred  	%p12, %p389, %p388;
	@%p12 bra 	$L__BB16_374;
	bra.uni 	$L__BB16_371;

$L__BB16_374:
	mov.f64 	%fd1631, 0d0000000000000000;
	mul.rn.f64 	%fd1982, %fd499, %fd1631;
	mov.u32 	%r714, 1;
	bra.uni 	$L__BB16_375;

$L__BB16_371:
	mul.rn.f64 	%fd1622, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r713, %fd1622;
	st.local.u32 	[%rd1], %r713;
	cvt.rn.f64.s32 	%fd1623, %r713;
	neg.f64 	%fd1624, %fd1623;
	mov.f64 	%fd1625, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1626, %fd1624, %fd1625, %fd499;
	mov.f64 	%fd1627, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1628, %fd1624, %fd1627, %fd1626;
	mov.f64 	%fd1629, 0d397B839A252049C0;
	fma.rn.f64 	%fd1982, %fd1624, %fd1629, %fd1628;
	abs.f64 	%fd1630, %fd499;
	setp.ltu.f64 	%p390, %fd1630, 0d41E0000000000000;
	@%p390 bra 	$L__BB16_373;

	{ // callseq 260, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1982, [retval0+0];
	} // callseq 260
	ld.local.u32 	%r713, [%rd1];

$L__BB16_373:
	add.s32 	%r714, %r713, 1;

$L__BB16_375:
	and.b32  	%r572, %r714, 1;
	shl.b32 	%r573, %r714, 3;
	and.b32  	%r574, %r573, 8;
	setp.eq.s32 	%p391, %r572, 0;
	selp.f64 	%fd1632, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p391;
	mul.wide.s32 	%rd207, %r574, 8;
	add.s64 	%rd209, %rd88, %rd207;
	ld.global.nc.f64 	%fd1633, [%rd209+8];
	mul.rn.f64 	%fd505, %fd1982, %fd1982;
	fma.rn.f64 	%fd1634, %fd1632, %fd505, %fd1633;
	ld.global.nc.f64 	%fd1635, [%rd209+16];
	fma.rn.f64 	%fd1636, %fd1634, %fd505, %fd1635;
	ld.global.nc.f64 	%fd1637, [%rd209+24];
	fma.rn.f64 	%fd1638, %fd1636, %fd505, %fd1637;
	ld.global.nc.f64 	%fd1639, [%rd209+32];
	fma.rn.f64 	%fd1640, %fd1638, %fd505, %fd1639;
	ld.global.nc.f64 	%fd1641, [%rd209+40];
	fma.rn.f64 	%fd1642, %fd1640, %fd505, %fd1641;
	ld.global.nc.f64 	%fd1643, [%rd209+48];
	fma.rn.f64 	%fd506, %fd1642, %fd505, %fd1643;
	fma.rn.f64 	%fd1984, %fd506, %fd1982, %fd1982;
	@%p391 bra 	$L__BB16_377;

	mov.f64 	%fd1644, 0d3FF0000000000000;
	fma.rn.f64 	%fd1984, %fd506, %fd505, %fd1644;

$L__BB16_377:
	and.b32  	%r575, %r714, 2;
	setp.eq.s32 	%p392, %r575, 0;
	@%p392 bra 	$L__BB16_379;

	mov.f64 	%fd1645, 0d0000000000000000;
	mov.f64 	%fd1646, 0dBFF0000000000000;
	fma.rn.f64 	%fd1984, %fd1984, %fd1646, %fd1645;

$L__BB16_379:
	mul.rn.f64 	%fd1647, %fd481, %fd1984;
	add.rn.f64 	%fd512, %fd1647, 0d3F7A9FBE76C8B439;
	@%p12 bra 	$L__BB16_382;
	bra.uni 	$L__BB16_380;

$L__BB16_382:
	mov.f64 	%fd1657, 0d0000000000000000;
	mul.rn.f64 	%fd1985, %fd499, %fd1657;
	mov.u32 	%r715, 0;
	bra.uni 	$L__BB16_383;

$L__BB16_380:
	mul.rn.f64 	%fd1648, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r715, %fd1648;
	st.local.u32 	[%rd1], %r715;
	cvt.rn.f64.s32 	%fd1649, %r715;
	neg.f64 	%fd1650, %fd1649;
	mov.f64 	%fd1651, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1652, %fd1650, %fd1651, %fd499;
	mov.f64 	%fd1653, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1654, %fd1650, %fd1653, %fd1652;
	mov.f64 	%fd1655, 0d397B839A252049C0;
	fma.rn.f64 	%fd1985, %fd1650, %fd1655, %fd1654;
	abs.f64 	%fd1656, %fd499;
	setp.ltu.f64 	%p393, %fd1656, 0d41E0000000000000;
	@%p393 bra 	$L__BB16_383;

	{ // callseq 261, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1985, [retval0+0];
	} // callseq 261
	ld.local.u32 	%r715, [%rd1];

$L__BB16_383:
	and.b32  	%r577, %r715, 1;
	shl.b32 	%r578, %r715, 3;
	and.b32  	%r579, %r578, 8;
	setp.eq.s32 	%p394, %r577, 0;
	selp.f64 	%fd1658, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p394;
	mul.wide.s32 	%rd211, %r579, 8;
	add.s64 	%rd213, %rd88, %rd211;
	ld.global.nc.f64 	%fd1659, [%rd213+8];
	mul.rn.f64 	%fd517, %fd1985, %fd1985;
	fma.rn.f64 	%fd1660, %fd1658, %fd517, %fd1659;
	ld.global.nc.f64 	%fd1661, [%rd213+16];
	fma.rn.f64 	%fd1662, %fd1660, %fd517, %fd1661;
	ld.global.nc.f64 	%fd1663, [%rd213+24];
	fma.rn.f64 	%fd1664, %fd1662, %fd517, %fd1663;
	ld.global.nc.f64 	%fd1665, [%rd213+32];
	fma.rn.f64 	%fd1666, %fd1664, %fd517, %fd1665;
	ld.global.nc.f64 	%fd1667, [%rd213+40];
	fma.rn.f64 	%fd1668, %fd1666, %fd517, %fd1667;
	ld.global.nc.f64 	%fd1669, [%rd213+48];
	fma.rn.f64 	%fd518, %fd1668, %fd517, %fd1669;
	fma.rn.f64 	%fd1987, %fd518, %fd1985, %fd1985;
	@%p394 bra 	$L__BB16_385;

	mov.f64 	%fd1670, 0d3FF0000000000000;
	fma.rn.f64 	%fd1987, %fd518, %fd517, %fd1670;

$L__BB16_385:
	and.b32  	%r580, %r715, 2;
	setp.eq.s32 	%p395, %r580, 0;
	@%p395 bra 	$L__BB16_387;

	mov.f64 	%fd1671, 0d0000000000000000;
	mov.f64 	%fd1672, 0dBFF0000000000000;
	fma.rn.f64 	%fd1987, %fd1987, %fd1672, %fd1671;

$L__BB16_387:
	ld.param.s8 	%rs2, [bd09_to_wgs84_exact_cuda_double_param_4];
	mul.rn.f64 	%fd1673, %fd481, %fd1987;
	add.rn.f64 	%fd1674, %fd1673, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd524, %fd3, %fd1674;
	sub.rn.f64 	%fd525, %fd1, %fd512;
	add.rn.f64 	%fd1923, %fd2009, %fd525;
	add.rn.f64 	%fd1922, %fd2010, %fd524;
	setp.eq.s16 	%p396, %rs2, 0;
	@%p396 bra 	$L__BB16_456;

	mul.rn.f64 	%fd1675, %fd2010, 0d400921FB54442D18;
	div.rn.f64 	%fd528, %fd1675, 0d4066800000000000;
	mul.rn.f64 	%fd1676, %fd1922, 0d400921FB54442D18;
	div.rn.f64 	%fd529, %fd1676, 0d4066800000000000;
	sub.rn.f64 	%fd1677, %fd529, %fd528;
	mul.rn.f64 	%fd530, %fd1677, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r581, %temp}, %fd530;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r582}, %fd530;
	}
	and.b32  	%r583, %r582, 2147483647;
	setp.eq.s32 	%p397, %r583, 2146435072;
	setp.eq.s32 	%p398, %r581, 0;
	and.pred  	%p399, %p398, %p397;
	@%p399 bra 	$L__BB16_391;
	bra.uni 	$L__BB16_389;

$L__BB16_391:
	mov.f64 	%fd1687, 0d0000000000000000;
	mul.rn.f64 	%fd1988, %fd530, %fd1687;
	mov.u32 	%r716, 0;
	bra.uni 	$L__BB16_392;

$L__BB16_456:
	abs.f64 	%fd1855, %fd525;
	setp.geu.f64 	%p477, %fd1855, %fd610;
	@%p477 bra 	$L__BB16_458;

	abs.f64 	%fd1856, %fd524;
	setp.lt.f64 	%p478, %fd1856, %fd610;
	@%p478 bra 	$L__BB16_459;
	bra.uni 	$L__BB16_458;

$L__BB16_389:
	mul.rn.f64 	%fd1678, %fd530, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r716, %fd1678;
	st.local.u32 	[%rd1], %r716;
	cvt.rn.f64.s32 	%fd1679, %r716;
	neg.f64 	%fd1680, %fd1679;
	mov.f64 	%fd1681, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1682, %fd1680, %fd1681, %fd530;
	mov.f64 	%fd1683, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1684, %fd1680, %fd1683, %fd1682;
	mov.f64 	%fd1685, 0d397B839A252049C0;
	fma.rn.f64 	%fd1988, %fd1680, %fd1685, %fd1684;
	abs.f64 	%fd1686, %fd530;
	setp.ltu.f64 	%p400, %fd1686, 0d41E0000000000000;
	@%p400 bra 	$L__BB16_392;

	{ // callseq 262, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd530;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1988, [retval0+0];
	} // callseq 262
	ld.local.u32 	%r716, [%rd1];

$L__BB16_392:
	and.b32  	%r585, %r716, 1;
	shl.b32 	%r586, %r716, 3;
	and.b32  	%r587, %r586, 8;
	setp.eq.s32 	%p401, %r585, 0;
	selp.f64 	%fd1688, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p401;
	mul.wide.s32 	%rd215, %r587, 8;
	add.s64 	%rd217, %rd88, %rd215;
	ld.global.nc.f64 	%fd1689, [%rd217+8];
	mul.rn.f64 	%fd535, %fd1988, %fd1988;
	fma.rn.f64 	%fd1690, %fd1688, %fd535, %fd1689;
	ld.global.nc.f64 	%fd1691, [%rd217+16];
	fma.rn.f64 	%fd1692, %fd1690, %fd535, %fd1691;
	ld.global.nc.f64 	%fd1693, [%rd217+24];
	fma.rn.f64 	%fd1694, %fd1692, %fd535, %fd1693;
	ld.global.nc.f64 	%fd1695, [%rd217+32];
	fma.rn.f64 	%fd1696, %fd1694, %fd535, %fd1695;
	ld.global.nc.f64 	%fd1697, [%rd217+40];
	fma.rn.f64 	%fd1698, %fd1696, %fd535, %fd1697;
	ld.global.nc.f64 	%fd1699, [%rd217+48];
	fma.rn.f64 	%fd536, %fd1698, %fd535, %fd1699;
	fma.rn.f64 	%fd1990, %fd536, %fd1988, %fd1988;
	@%p401 bra 	$L__BB16_394;

	mov.f64 	%fd1700, 0d3FF0000000000000;
	fma.rn.f64 	%fd1990, %fd536, %fd535, %fd1700;

$L__BB16_394:
	and.b32  	%r588, %r716, 2;
	setp.eq.s32 	%p402, %r588, 0;
	@%p402 bra 	$L__BB16_396;

	mov.f64 	%fd1701, 0d0000000000000000;
	mov.f64 	%fd1702, 0dBFF0000000000000;
	fma.rn.f64 	%fd1990, %fd1990, %fd1702, %fd1701;

$L__BB16_396:
	abs.f64 	%fd542, %fd1990;
	{ // callseq 263, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd542;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1993, [retval0+0];
	} // callseq 263
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r131}, %fd1990;
	}
	setp.lt.s32 	%p403, %r131, 0;
	and.pred  	%p13, %p403, %p16;
	not.pred 	%p405, %p13;
	@%p405 bra 	$L__BB16_398;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r589}, %fd1993;
	}
	xor.b32  	%r590, %r589, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r591, %temp}, %fd1993;
	}
	mov.b64 	%fd1993, {%r591, %r590};

$L__BB16_398:
	setp.eq.f64 	%p406, %fd1990, 0d0000000000000000;
	@%p406 bra 	$L__BB16_402;
	bra.uni 	$L__BB16_399;

$L__BB16_402:
	setp.lt.s32 	%p409, %r3, 0;
	mov.u32 	%r592, 0;
	selp.b32 	%r593, %r131, 0, %p16;
	or.b32  	%r594, %r593, 2146435072;
	selp.b32 	%r595, %r594, %r593, %p409;
	mov.b64 	%fd1993, {%r592, %r595};
	bra.uni 	$L__BB16_403;

$L__BB16_399:
	setp.gt.s32 	%p407, %r131, -1;
	@%p407 bra 	$L__BB16_403;

	mov.f64 	%fd1703, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1704, %fd1703;
	setp.eq.f64 	%p408, %fd1704, 0d4000000000000000;
	@%p408 bra 	$L__BB16_403;

	mov.f64 	%fd1993, 0dFFF8000000000000;

$L__BB16_403:
	add.rn.f64 	%fd1706, %fd1990, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r596}, %fd1706;
	}
	and.b32  	%r597, %r596, 2146435072;
	setp.ne.s32 	%p411, %r597, 2146435072;
	@%p411 bra 	$L__BB16_410;

	setp.gtu.f64 	%p412, %fd542, 0d7FF0000000000000;
	@%p412 bra 	$L__BB16_409;
	bra.uni 	$L__BB16_405;

$L__BB16_409:
	mov.f64 	%fd1708, 0d4000000000000000;
	add.rn.f64 	%fd1993, %fd1990, %fd1708;
	bra.uni 	$L__BB16_410;

$L__BB16_405:
	setp.eq.s32 	%p413, %r66, 2146435072;
	mov.f64 	%fd1707, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r598, %temp}, %fd1707;
	}
	setp.eq.s32 	%p414, %r598, 0;
	and.pred  	%p415, %p413, %p414;
	@%p415 bra 	$L__BB16_408;
	bra.uni 	$L__BB16_406;

$L__BB16_408:
	setp.lt.s32 	%p421, %r3, 0;
	mov.u32 	%r603, 0;
	setp.gt.f64 	%p422, %fd542, 0d3FF0000000000000;
	selp.b32 	%r604, 2146435072, 0, %p422;
	xor.b32  	%r605, %r604, 2146435072;
	selp.b32 	%r606, %r605, %r604, %p421;
	setp.eq.f64 	%p423, %fd1990, 0dBFF0000000000000;
	selp.b32 	%r607, 1072693248, %r606, %p423;
	mov.b64 	%fd1993, {%r603, %r607};
	bra.uni 	$L__BB16_410;

$L__BB16_406:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r599, %temp}, %fd1990;
	}
	and.b32  	%r600, %r131, 2147483647;
	setp.ne.s32 	%p416, %r600, 2146435072;
	setp.ne.s32 	%p417, %r599, 0;
	or.pred  	%p418, %p416, %p417;
	@%p418 bra 	$L__BB16_410;

	setp.ne.s32 	%p419, %r66, 1071644672;
	and.pred  	%p420, %p419, %p13;
	selp.b32 	%r601, %r68, %r67, %p420;
	mov.u32 	%r602, 0;
	mov.b64 	%fd1993, {%r602, %r601};

$L__BB16_410:
	setp.eq.f64 	%p424, %fd1990, 0d3FF0000000000000;
	selp.f64 	%fd552, 0d3FF0000000000000, %fd1993, %p424;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r608}, %fd528;
	}
	and.b32  	%r609, %r608, 2147483647;
	setp.eq.s32 	%p425, %r609, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r610, %temp}, %fd528;
	}
	setp.eq.s32 	%p426, %r610, 0;
	and.pred  	%p427, %p426, %p425;
	@%p427 bra 	$L__BB16_414;
	bra.uni 	$L__BB16_411;

$L__BB16_414:
	mov.f64 	%fd1718, 0d0000000000000000;
	mul.rn.f64 	%fd1995, %fd528, %fd1718;
	mov.u32 	%r718, 1;
	bra.uni 	$L__BB16_415;

$L__BB16_411:
	mul.rn.f64 	%fd1709, %fd528, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r717, %fd1709;
	st.local.u32 	[%rd1], %r717;
	cvt.rn.f64.s32 	%fd1710, %r717;
	neg.f64 	%fd1711, %fd1710;
	mov.f64 	%fd1712, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1713, %fd1711, %fd1712, %fd528;
	mov.f64 	%fd1714, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1715, %fd1711, %fd1714, %fd1713;
	mov.f64 	%fd1716, 0d397B839A252049C0;
	fma.rn.f64 	%fd1995, %fd1711, %fd1716, %fd1715;
	abs.f64 	%fd1717, %fd528;
	setp.ltu.f64 	%p428, %fd1717, 0d41E0000000000000;
	@%p428 bra 	$L__BB16_413;

	{ // callseq 264, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd528;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1995, [retval0+0];
	} // callseq 264
	ld.local.u32 	%r717, [%rd1];

$L__BB16_413:
	add.s32 	%r718, %r717, 1;

$L__BB16_415:
	and.b32  	%r612, %r718, 1;
	shl.b32 	%r613, %r718, 3;
	and.b32  	%r614, %r613, 8;
	setp.eq.s32 	%p429, %r612, 0;
	selp.f64 	%fd1719, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p429;
	mul.wide.s32 	%rd219, %r614, 8;
	add.s64 	%rd221, %rd88, %rd219;
	ld.global.nc.f64 	%fd1720, [%rd221+8];
	mul.rn.f64 	%fd558, %fd1995, %fd1995;
	fma.rn.f64 	%fd1721, %fd1719, %fd558, %fd1720;
	ld.global.nc.f64 	%fd1722, [%rd221+16];
	fma.rn.f64 	%fd1723, %fd1721, %fd558, %fd1722;
	ld.global.nc.f64 	%fd1724, [%rd221+24];
	fma.rn.f64 	%fd1725, %fd1723, %fd558, %fd1724;
	ld.global.nc.f64 	%fd1726, [%rd221+32];
	fma.rn.f64 	%fd1727, %fd1725, %fd558, %fd1726;
	ld.global.nc.f64 	%fd1728, [%rd221+40];
	fma.rn.f64 	%fd1729, %fd1727, %fd558, %fd1728;
	ld.global.nc.f64 	%fd1730, [%rd221+48];
	fma.rn.f64 	%fd559, %fd1729, %fd558, %fd1730;
	fma.rn.f64 	%fd1997, %fd559, %fd1995, %fd1995;
	@%p429 bra 	$L__BB16_417;

	mov.f64 	%fd1731, 0d3FF0000000000000;
	fma.rn.f64 	%fd1997, %fd559, %fd558, %fd1731;

$L__BB16_417:
	and.b32  	%r615, %r718, 2;
	setp.eq.s32 	%p430, %r615, 0;
	@%p430 bra 	$L__BB16_419;

	mov.f64 	%fd1732, 0d0000000000000000;
	mov.f64 	%fd1733, 0dBFF0000000000000;
	fma.rn.f64 	%fd1997, %fd1997, %fd1733, %fd1732;

$L__BB16_419:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r616}, %fd529;
	}
	and.b32  	%r617, %r616, 2147483647;
	setp.eq.s32 	%p431, %r617, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r618, %temp}, %fd529;
	}
	setp.eq.s32 	%p432, %r618, 0;
	and.pred  	%p433, %p432, %p431;
	@%p433 bra 	$L__BB16_423;
	bra.uni 	$L__BB16_420;

$L__BB16_423:
	mov.f64 	%fd1743, 0d0000000000000000;
	mul.rn.f64 	%fd1999, %fd529, %fd1743;
	mov.u32 	%r720, 1;
	bra.uni 	$L__BB16_424;

$L__BB16_420:
	mul.rn.f64 	%fd1734, %fd529, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r719, %fd1734;
	st.local.u32 	[%rd1], %r719;
	cvt.rn.f64.s32 	%fd1735, %r719;
	neg.f64 	%fd1736, %fd1735;
	mov.f64 	%fd1737, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1738, %fd1736, %fd1737, %fd529;
	mov.f64 	%fd1739, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1740, %fd1736, %fd1739, %fd1738;
	mov.f64 	%fd1741, 0d397B839A252049C0;
	fma.rn.f64 	%fd1999, %fd1736, %fd1741, %fd1740;
	abs.f64 	%fd1742, %fd529;
	setp.ltu.f64 	%p434, %fd1742, 0d41E0000000000000;
	@%p434 bra 	$L__BB16_422;

	{ // callseq 265, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd529;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1999, [retval0+0];
	} // callseq 265
	ld.local.u32 	%r719, [%rd1];

$L__BB16_422:
	add.s32 	%r720, %r719, 1;

$L__BB16_424:
	and.b32  	%r620, %r720, 1;
	shl.b32 	%r621, %r720, 3;
	and.b32  	%r622, %r621, 8;
	setp.eq.s32 	%p435, %r620, 0;
	selp.f64 	%fd1744, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p435;
	mul.wide.s32 	%rd223, %r622, 8;
	add.s64 	%rd225, %rd88, %rd223;
	ld.global.nc.f64 	%fd1745, [%rd225+8];
	mul.rn.f64 	%fd570, %fd1999, %fd1999;
	fma.rn.f64 	%fd1746, %fd1744, %fd570, %fd1745;
	ld.global.nc.f64 	%fd1747, [%rd225+16];
	fma.rn.f64 	%fd1748, %fd1746, %fd570, %fd1747;
	ld.global.nc.f64 	%fd1749, [%rd225+24];
	fma.rn.f64 	%fd1750, %fd1748, %fd570, %fd1749;
	ld.global.nc.f64 	%fd1751, [%rd225+32];
	fma.rn.f64 	%fd1752, %fd1750, %fd570, %fd1751;
	ld.global.nc.f64 	%fd1753, [%rd225+40];
	fma.rn.f64 	%fd1754, %fd1752, %fd570, %fd1753;
	ld.global.nc.f64 	%fd1755, [%rd225+48];
	fma.rn.f64 	%fd571, %fd1754, %fd570, %fd1755;
	fma.rn.f64 	%fd2001, %fd571, %fd1999, %fd1999;
	@%p435 bra 	$L__BB16_426;

	mov.f64 	%fd1756, 0d3FF0000000000000;
	fma.rn.f64 	%fd2001, %fd571, %fd570, %fd1756;

$L__BB16_426:
	and.b32  	%r623, %r720, 2;
	setp.eq.s32 	%p436, %r623, 0;
	@%p436 bra 	$L__BB16_428;

	mov.f64 	%fd1757, 0d0000000000000000;
	mov.f64 	%fd1758, 0dBFF0000000000000;
	fma.rn.f64 	%fd2001, %fd2001, %fd1758, %fd1757;

$L__BB16_428:
	mul.rn.f64 	%fd577, %fd1997, %fd2001;
	mul.rn.f64 	%fd1759, %fd2009, 0d400921FB54442D18;
	div.rn.f64 	%fd1760, %fd1759, 0d4066800000000000;
	mul.rn.f64 	%fd1761, %fd1923, 0d400921FB54442D18;
	div.rn.f64 	%fd1762, %fd1761, 0d4066800000000000;
	sub.rn.f64 	%fd1763, %fd1762, %fd1760;
	mul.rn.f64 	%fd578, %fd1763, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r624, %temp}, %fd578;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r625}, %fd578;
	}
	and.b32  	%r626, %r625, 2147483647;
	setp.eq.s32 	%p437, %r626, 2146435072;
	setp.eq.s32 	%p438, %r624, 0;
	and.pred  	%p439, %p438, %p437;
	@%p439 bra 	$L__BB16_431;
	bra.uni 	$L__BB16_429;

$L__BB16_431:
	mov.f64 	%fd1773, 0d0000000000000000;
	mul.rn.f64 	%fd2002, %fd578, %fd1773;
	mov.u32 	%r721, 0;
	bra.uni 	$L__BB16_432;

$L__BB16_429:
	mul.rn.f64 	%fd1764, %fd578, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r721, %fd1764;
	st.local.u32 	[%rd1], %r721;
	cvt.rn.f64.s32 	%fd1765, %r721;
	neg.f64 	%fd1766, %fd1765;
	mov.f64 	%fd1767, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1768, %fd1766, %fd1767, %fd578;
	mov.f64 	%fd1769, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1770, %fd1766, %fd1769, %fd1768;
	mov.f64 	%fd1771, 0d397B839A252049C0;
	fma.rn.f64 	%fd2002, %fd1766, %fd1771, %fd1770;
	abs.f64 	%fd1772, %fd578;
	setp.ltu.f64 	%p440, %fd1772, 0d41E0000000000000;
	@%p440 bra 	$L__BB16_432;

	{ // callseq 266, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd578;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd43;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd2002, [retval0+0];
	} // callseq 266
	ld.local.u32 	%r721, [%rd1];

$L__BB16_432:
	and.b32  	%r628, %r721, 1;
	shl.b32 	%r629, %r721, 3;
	and.b32  	%r630, %r629, 8;
	setp.eq.s32 	%p441, %r628, 0;
	selp.f64 	%fd1774, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p441;
	mul.wide.s32 	%rd227, %r630, 8;
	add.s64 	%rd229, %rd88, %rd227;
	ld.global.nc.f64 	%fd1775, [%rd229+8];
	mul.rn.f64 	%fd583, %fd2002, %fd2002;
	fma.rn.f64 	%fd1776, %fd1774, %fd583, %fd1775;
	ld.global.nc.f64 	%fd1777, [%rd229+16];
	fma.rn.f64 	%fd1778, %fd1776, %fd583, %fd1777;
	ld.global.nc.f64 	%fd1779, [%rd229+24];
	fma.rn.f64 	%fd1780, %fd1778, %fd583, %fd1779;
	ld.global.nc.f64 	%fd1781, [%rd229+32];
	fma.rn.f64 	%fd1782, %fd1780, %fd583, %fd1781;
	ld.global.nc.f64 	%fd1783, [%rd229+40];
	fma.rn.f64 	%fd1784, %fd1782, %fd583, %fd1783;
	ld.global.nc.f64 	%fd1785, [%rd229+48];
	fma.rn.f64 	%fd584, %fd1784, %fd583, %fd1785;
	fma.rn.f64 	%fd2004, %fd584, %fd2002, %fd2002;
	@%p441 bra 	$L__BB16_434;

	mov.f64 	%fd1786, 0d3FF0000000000000;
	fma.rn.f64 	%fd2004, %fd584, %fd583, %fd1786;

$L__BB16_434:
	and.b32  	%r631, %r721, 2;
	setp.eq.s32 	%p442, %r631, 0;
	@%p442 bra 	$L__BB16_436;

	mov.f64 	%fd1787, 0d0000000000000000;
	mov.f64 	%fd1788, 0dBFF0000000000000;
	fma.rn.f64 	%fd2004, %fd2004, %fd1788, %fd1787;

$L__BB16_436:
	abs.f64 	%fd590, %fd2004;
	{ // callseq 267, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd590;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd2007, [retval0+0];
	} // callseq 267
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r145}, %fd2004;
	}
	setp.lt.s32 	%p443, %r145, 0;
	and.pred  	%p14, %p443, %p16;
	not.pred 	%p445, %p14;
	@%p445 bra 	$L__BB16_438;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r632}, %fd2007;
	}
	xor.b32  	%r633, %r632, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r634, %temp}, %fd2007;
	}
	mov.b64 	%fd2007, {%r634, %r633};

$L__BB16_438:
	setp.eq.f64 	%p446, %fd2004, 0d0000000000000000;
	@%p446 bra 	$L__BB16_442;
	bra.uni 	$L__BB16_439;

$L__BB16_442:
	setp.lt.s32 	%p449, %r3, 0;
	mov.u32 	%r635, 0;
	selp.b32 	%r636, %r145, 0, %p16;
	or.b32  	%r637, %r636, 2146435072;
	selp.b32 	%r638, %r637, %r636, %p449;
	mov.b64 	%fd2007, {%r635, %r638};
	bra.uni 	$L__BB16_443;

$L__BB16_439:
	setp.gt.s32 	%p447, %r145, -1;
	@%p447 bra 	$L__BB16_443;

	mov.f64 	%fd1789, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1790, %fd1789;
	setp.eq.f64 	%p448, %fd1790, 0d4000000000000000;
	@%p448 bra 	$L__BB16_443;

	mov.f64 	%fd2007, 0dFFF8000000000000;

$L__BB16_443:
	add.rn.f64 	%fd1792, %fd2004, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r639}, %fd1792;
	}
	and.b32  	%r640, %r639, 2146435072;
	setp.ne.s32 	%p451, %r640, 2146435072;
	@%p451 bra 	$L__BB16_450;

	setp.gtu.f64 	%p452, %fd590, 0d7FF0000000000000;
	@%p452 bra 	$L__BB16_449;
	bra.uni 	$L__BB16_445;

$L__BB16_449:
	mov.f64 	%fd1794, 0d4000000000000000;
	add.rn.f64 	%fd2007, %fd2004, %fd1794;
	bra.uni 	$L__BB16_450;

$L__BB16_445:
	setp.eq.s32 	%p453, %r66, 2146435072;
	mov.f64 	%fd1793, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r641, %temp}, %fd1793;
	}
	setp.eq.s32 	%p454, %r641, 0;
	and.pred  	%p455, %p453, %p454;
	@%p455 bra 	$L__BB16_448;
	bra.uni 	$L__BB16_446;

$L__BB16_448:
	setp.lt.s32 	%p461, %r3, 0;
	mov.u32 	%r646, 0;
	setp.gt.f64 	%p462, %fd590, 0d3FF0000000000000;
	selp.b32 	%r647, 2146435072, 0, %p462;
	xor.b32  	%r648, %r647, 2146435072;
	selp.b32 	%r649, %r648, %r647, %p461;
	setp.eq.f64 	%p463, %fd2004, 0dBFF0000000000000;
	selp.b32 	%r650, 1072693248, %r649, %p463;
	mov.b64 	%fd2007, {%r646, %r650};
	bra.uni 	$L__BB16_450;

$L__BB16_446:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r642, %temp}, %fd2004;
	}
	and.b32  	%r643, %r145, 2147483647;
	setp.ne.s32 	%p456, %r643, 2146435072;
	setp.ne.s32 	%p457, %r642, 0;
	or.pred  	%p458, %p456, %p457;
	@%p458 bra 	$L__BB16_450;

	setp.ne.s32 	%p459, %r66, 1071644672;
	and.pred  	%p460, %p459, %p14;
	selp.b32 	%r644, %r68, %r67, %p460;
	mov.u32 	%r645, 0;
	mov.b64 	%fd2007, {%r645, %r644};

$L__BB16_450:
	setp.eq.f64 	%p464, %fd2004, 0d3FF0000000000000;
	mov.f64 	%fd1795, 0d3FF0000000000000;
	selp.f64 	%fd1796, 0d3FF0000000000000, %fd2007, %p464;
	mul.rn.f64 	%fd1797, %fd577, %fd1796;
	add.rn.f64 	%fd1798, %fd552, %fd1797;
	sqrt.rn.f64 	%fd600, %fd1798;
	sub.rn.f64 	%fd1799, %fd1795, %fd1798;
	sqrt.rn.f64 	%fd601, %fd1799;
	abs.f64 	%fd602, %fd601;
	abs.f64 	%fd603, %fd600;
	setp.eq.f64 	%p465, %fd602, 0d0000000000000000;
	setp.eq.f64 	%p466, %fd603, 0d0000000000000000;
	and.pred  	%p467, %p465, %p466;
	@%p467 bra 	$L__BB16_454;
	bra.uni 	$L__BB16_451;

$L__BB16_454:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r663}, %fd601;
	}
	setp.lt.s32 	%p475, %r663, 0;
	selp.f64 	%fd1852, 0d400921FB54442D18, 0d0000000000000000, %p475;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r664, %temp}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r665}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r666}, %fd600;
	}
	and.b32  	%r667, %r666, -2147483648;
	or.b32  	%r668, %r665, %r667;
	mov.b64 	%fd2008, {%r664, %r668};
	bra.uni 	$L__BB16_455;

$L__BB16_451:
	setp.eq.f64 	%p468, %fd602, 0d7FF0000000000000;
	setp.eq.f64 	%p469, %fd603, 0d7FF0000000000000;
	and.pred  	%p470, %p468, %p469;
	@%p470 bra 	$L__BB16_453;
	bra.uni 	$L__BB16_452;

$L__BB16_453:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r657}, %fd601;
	}
	setp.lt.s32 	%p474, %r657, 0;
	selp.f64 	%fd1851, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p474;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r658, %temp}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r659}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r660}, %fd600;
	}
	and.b32  	%r661, %r660, -2147483648;
	or.b32  	%r662, %r659, %r661;
	mov.b64 	%fd2008, {%r658, %r662};
	bra.uni 	$L__BB16_455;

$L__BB16_452:
	max.f64 	%fd1800, %fd603, %fd602;
	min.f64 	%fd1801, %fd603, %fd602;
	div.rn.f64 	%fd1802, %fd1801, %fd1800;
	mul.rn.f64 	%fd1803, %fd1802, %fd1802;
	mov.f64 	%fd1804, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1805, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1806, %fd1805, %fd1803, %fd1804;
	mov.f64 	%fd1807, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1808, %fd1806, %fd1803, %fd1807;
	mov.f64 	%fd1809, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1810, %fd1808, %fd1803, %fd1809;
	mov.f64 	%fd1811, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1812, %fd1810, %fd1803, %fd1811;
	mov.f64 	%fd1813, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1814, %fd1812, %fd1803, %fd1813;
	mov.f64 	%fd1815, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1816, %fd1814, %fd1803, %fd1815;
	mov.f64 	%fd1817, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1818, %fd1816, %fd1803, %fd1817;
	mov.f64 	%fd1819, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1820, %fd1818, %fd1803, %fd1819;
	mov.f64 	%fd1821, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1822, %fd1820, %fd1803, %fd1821;
	mov.f64 	%fd1823, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1824, %fd1822, %fd1803, %fd1823;
	mov.f64 	%fd1825, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1826, %fd1824, %fd1803, %fd1825;
	mov.f64 	%fd1827, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1828, %fd1826, %fd1803, %fd1827;
	mov.f64 	%fd1829, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1830, %fd1828, %fd1803, %fd1829;
	mov.f64 	%fd1831, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1832, %fd1830, %fd1803, %fd1831;
	mov.f64 	%fd1833, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1834, %fd1832, %fd1803, %fd1833;
	mov.f64 	%fd1835, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1836, %fd1834, %fd1803, %fd1835;
	mov.f64 	%fd1837, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1838, %fd1836, %fd1803, %fd1837;
	mov.f64 	%fd1839, 0dBFD555555555544C;
	fma.rn.f64 	%fd1840, %fd1838, %fd1803, %fd1839;
	mul.rn.f64 	%fd1841, %fd1803, %fd1840;
	fma.rn.f64 	%fd1842, %fd1841, %fd1802, %fd1802;
	mov.f64 	%fd1843, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1844, %fd1843, %fd1842;
	setp.gt.f64 	%p471, %fd603, %fd602;
	selp.f64 	%fd1845, %fd1844, %fd1842, %p471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r651}, %fd601;
	}
	setp.lt.s32 	%p472, %r651, 0;
	mov.f64 	%fd1846, 0d400921FB54442D18;
	sub.rn.f64 	%fd1847, %fd1846, %fd1845;
	selp.f64 	%fd1848, %fd1847, %fd1845, %p472;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r652, %temp}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r653}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r654}, %fd600;
	}
	and.b32  	%r655, %r654, -2147483648;
	or.b32  	%r656, %r653, %r655;
	mov.b64 	%fd1849, {%r652, %r656};
	add.rn.f64 	%fd1850, %fd602, %fd603;
	setp.le.f64 	%p473, %fd1850, 0d7FF0000000000000;
	selp.f64 	%fd2008, %fd1849, %fd1850, %p473;

$L__BB16_455:
	add.rn.f64 	%fd1853, %fd2008, %fd2008;
	mul.rn.f64 	%fd1854, %fd1853, 0d415854A640000000;
	setp.lt.f64 	%p476, %fd1854, %fd610;
	@%p476 bra 	$L__BB16_459;

$L__BB16_458:
	add.s32 	%r696, %r696, 1;
	setp.lt.s32 	%p479, %r696, %r147;
	mov.f64 	%fd2009, %fd1923;
	mov.f64 	%fd2010, %fd1922;
	@%p479 bra 	$L__BB16_195;

$L__BB16_459:
	ld.param.u64 	%rd237, [bd09_to_wgs84_exact_cuda_double_param_7];
	mov.u32 	%r676, %tid.x;
	mov.u32 	%r675, %ntid.x;
	mov.u32 	%r674, %ctaid.x;
	mad.lo.s32 	%r673, %r674, %r675, %r676;
	mul.wide.s32 	%rd236, %r673, 8;
	cvta.to.global.u64 	%rd235, %rd237;
	add.s64 	%rd234, %rd235, %rd236;
	ld.param.u64 	%rd233, [bd09_to_wgs84_exact_cuda_double_param_6];
	mov.u32 	%r672, %tid.x;
	mov.u32 	%r671, %ntid.x;
	mov.u32 	%r670, %ctaid.x;
	mad.lo.s32 	%r669, %r670, %r671, %r672;
	mul.wide.s32 	%rd232, %r669, 8;
	cvta.to.global.u64 	%rd231, %rd233;
	add.s64 	%rd230, %rd231, %rd232;
	st.global.f64 	[%rd230], %fd2009;
	st.global.f64 	[%rd234], %fd2010;

$L__BB16_460:
	ret;

}
	// .globl	bd09_to_gcj02_exact_cuda_double
.visible .entry bd09_to_gcj02_exact_cuda_double(
	.param .u32 bd09_to_gcj02_exact_cuda_double_param_0,
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_1,
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_2,
	.param .f64 bd09_to_gcj02_exact_cuda_double_param_3,
	.param .u8 bd09_to_gcj02_exact_cuda_double_param_4,
	.param .u32 bd09_to_gcj02_exact_cuda_double_param_5,
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_6,
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_7
)
{
	.local .align 4 .b8 	__local_depot17[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<248>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<350>;
	.reg .f64 	%fd<841>;
	.reg .b64 	%rd<94>;


	mov.u64 	%SPL, __local_depot17;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u32 	%r66, [bd09_to_gcj02_exact_cuda_double_param_0];
	ld.param.u64 	%rd15, [bd09_to_gcj02_exact_cuda_double_param_1];
	ld.param.u64 	%rd16, [bd09_to_gcj02_exact_cuda_double_param_2];
	ld.param.f64 	%fd246, [bd09_to_gcj02_exact_cuda_double_param_3];
	add.u64 	%rd19, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r67, %ntid.x;
	mov.u32 	%r68, %ctaid.x;
	mov.u32 	%r69, %tid.x;
	mad.lo.s32 	%r1, %r68, %r67, %r69;
	setp.ge.s32 	%p9, %r1, %r66;
	@%p9 bra 	$L__BB17_210;

	cvta.to.global.u64 	%rd31, %rd15;
	mul.wide.s32 	%rd32, %r1, 8;
	add.s64 	%rd33, %rd31, %rd32;
	cvta.to.global.u64 	%rd34, %rd16;
	add.s64 	%rd35, %rd34, %rd32;
	ld.global.f64 	%fd1, [%rd33];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd35];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd2;
	}
	mov.f64 	%fd247, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r3}, %fd247;
	}
	and.b32  	%r4, %r3, 2146435072;
	setp.eq.s32 	%p10, %r4, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 268, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd776, [retval0+0];
	} // callseq 268
	setp.lt.s32 	%p11, %r2, 0;
	and.pred  	%p1, %p11, %p10;
	not.pred 	%p12, %p1;
	@%p12 bra 	$L__BB17_3;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd776;
	}
	xor.b32  	%r71, %r70, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r72, %temp}, %fd776;
	}
	mov.b64 	%fd776, {%r72, %r71};

$L__BB17_3:
	setp.eq.f64 	%p13, %fd2, 0d0000000000000000;
	@%p13 bra 	$L__BB17_7;
	bra.uni 	$L__BB17_4;

$L__BB17_7:
	selp.b32 	%r73, %r2, 0, %p10;
	mov.u32 	%r74, 0;
	or.b32  	%r75, %r73, 2146435072;
	setp.lt.s32 	%p17, %r3, 0;
	selp.b32 	%r76, %r75, %r73, %p17;
	mov.b64 	%fd776, {%r74, %r76};
	bra.uni 	$L__BB17_8;

$L__BB17_4:
	setp.gt.s32 	%p14, %r2, -1;
	@%p14 bra 	$L__BB17_8;

	mov.f64 	%fd248, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd249, %fd248;
	setp.eq.f64 	%p15, %fd249, 0d4000000000000000;
	@%p15 bra 	$L__BB17_8;

	mov.f64 	%fd776, 0dFFF8000000000000;

$L__BB17_8:
	add.rn.f64 	%fd251, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r77}, %fd251;
	}
	and.b32  	%r78, %r77, 2146435072;
	setp.ne.s32 	%p18, %r78, 2146435072;
	@%p18 bra 	$L__BB17_15;

	setp.gtu.f64 	%p19, %fd5, 0d7FF0000000000000;
	@%p19 bra 	$L__BB17_14;
	bra.uni 	$L__BB17_10;

$L__BB17_14:
	mov.f64 	%fd253, 0d4000000000000000;
	add.rn.f64 	%fd776, %fd2, %fd253;
	bra.uni 	$L__BB17_15;

$L__BB17_10:
	mov.f64 	%fd252, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd252;
	}
	and.b32  	%r5, %r3, 2147483647;
	setp.eq.s32 	%p20, %r5, 2146435072;
	setp.eq.s32 	%p21, %r79, 0;
	and.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB17_13;
	bra.uni 	$L__BB17_11;

$L__BB17_13:
	setp.gt.f64 	%p29, %fd5, 0d3FF0000000000000;
	selp.b32 	%r86, 2146435072, 0, %p29;
	mov.u32 	%r87, 0;
	xor.b32  	%r88, %r86, 2146435072;
	setp.lt.s32 	%p30, %r3, 0;
	selp.b32 	%r89, %r88, %r86, %p30;
	setp.eq.f64 	%p31, %fd2, 0dBFF0000000000000;
	selp.b32 	%r90, 1072693248, %r89, %p31;
	mov.b64 	%fd776, {%r87, %r90};
	bra.uni 	$L__BB17_15;

$L__BB17_11:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r80, %temp}, %fd2;
	}
	and.b32  	%r81, %r2, 2147483647;
	setp.ne.s32 	%p23, %r81, 2146435072;
	setp.ne.s32 	%p24, %r80, 0;
	or.pred  	%p25, %p23, %p24;
	@%p25 bra 	$L__BB17_15;

	setp.gt.s32 	%p26, %r3, -1;
	selp.b32 	%r82, 2146435072, 0, %p26;
	mov.u32 	%r83, 0;
	setp.ne.s32 	%p27, %r5, 1071644672;
	and.pred  	%p28, %p27, %p1;
	or.b32  	%r84, %r82, -2147483648;
	selp.b32 	%r85, %r84, %r82, %p28;
	mov.b64 	%fd776, {%r83, %r85};

$L__BB17_15:
	abs.f64 	%fd15, %fd4;
	{ // callseq 269, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd779, [retval0+0];
	} // callseq 269
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r6}, %fd4;
	}
	setp.lt.s32 	%p32, %r6, 0;
	and.pred  	%p2, %p32, %p10;
	not.pred 	%p34, %p2;
	@%p34 bra 	$L__BB17_17;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd779;
	}
	xor.b32  	%r92, %r91, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd779;
	}
	mov.b64 	%fd779, {%r93, %r92};

$L__BB17_17:
	setp.eq.f64 	%p35, %fd4, 0d0000000000000000;
	@%p35 bra 	$L__BB17_21;
	bra.uni 	$L__BB17_18;

$L__BB17_21:
	selp.b32 	%r94, %r6, 0, %p10;
	mov.u32 	%r95, 0;
	or.b32  	%r96, %r94, 2146435072;
	setp.lt.s32 	%p39, %r3, 0;
	selp.b32 	%r97, %r96, %r94, %p39;
	mov.b64 	%fd779, {%r95, %r97};
	bra.uni 	$L__BB17_22;

$L__BB17_18:
	setp.gt.s32 	%p36, %r6, -1;
	@%p36 bra 	$L__BB17_22;

	mov.f64 	%fd254, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd255, %fd254;
	setp.eq.f64 	%p37, %fd255, 0d4000000000000000;
	@%p37 bra 	$L__BB17_22;

	mov.f64 	%fd779, 0dFFF8000000000000;

$L__BB17_22:
	add.rn.f64 	%fd257, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd257;
	}
	and.b32  	%r99, %r98, 2146435072;
	setp.ne.s32 	%p40, %r99, 2146435072;
	@%p40 bra 	$L__BB17_29;

	setp.gtu.f64 	%p41, %fd15, 0d7FF0000000000000;
	@%p41 bra 	$L__BB17_28;
	bra.uni 	$L__BB17_24;

$L__BB17_28:
	mov.f64 	%fd259, 0d4000000000000000;
	add.rn.f64 	%fd779, %fd4, %fd259;
	bra.uni 	$L__BB17_29;

$L__BB17_24:
	mov.f64 	%fd258, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd258;
	}
	and.b32  	%r7, %r3, 2147483647;
	setp.eq.s32 	%p42, %r7, 2146435072;
	setp.eq.s32 	%p43, %r100, 0;
	and.pred  	%p44, %p42, %p43;
	@%p44 bra 	$L__BB17_27;
	bra.uni 	$L__BB17_25;

$L__BB17_27:
	setp.gt.f64 	%p51, %fd15, 0d3FF0000000000000;
	selp.b32 	%r107, 2146435072, 0, %p51;
	mov.u32 	%r108, 0;
	xor.b32  	%r109, %r107, 2146435072;
	setp.lt.s32 	%p52, %r3, 0;
	selp.b32 	%r110, %r109, %r107, %p52;
	setp.eq.f64 	%p53, %fd4, 0dBFF0000000000000;
	selp.b32 	%r111, 1072693248, %r110, %p53;
	mov.b64 	%fd779, {%r108, %r111};
	bra.uni 	$L__BB17_29;

$L__BB17_25:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r101, %temp}, %fd4;
	}
	and.b32  	%r102, %r6, 2147483647;
	setp.ne.s32 	%p45, %r102, 2146435072;
	setp.ne.s32 	%p46, %r101, 0;
	or.pred  	%p47, %p45, %p46;
	@%p47 bra 	$L__BB17_29;

	setp.gt.s32 	%p48, %r3, -1;
	selp.b32 	%r103, 2146435072, 0, %p48;
	mov.u32 	%r104, 0;
	setp.ne.s32 	%p49, %r7, 1071644672;
	and.pred  	%p50, %p49, %p2;
	or.b32  	%r105, %r103, -2147483648;
	selp.b32 	%r106, %r105, %r103, %p50;
	mov.b64 	%fd779, {%r104, %r106};

$L__BB17_29:
	setp.eq.f64 	%p54, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd260, 0d3FF0000000000000, %fd779, %p54;
	setp.eq.f64 	%p55, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd261, 0d3FF0000000000000, %fd776, %p55;
	add.rn.f64 	%fd25, %fd261, %fd260;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r112, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r113}, %fd26;
	}
	and.b32  	%r114, %r113, 2147483647;
	setp.eq.s32 	%p56, %r114, 2146435072;
	setp.eq.s32 	%p57, %r112, 0;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB17_32;
	bra.uni 	$L__BB17_30;

$L__BB17_32:
	mov.f64 	%fd271, 0d0000000000000000;
	mul.rn.f64 	%fd780, %fd26, %fd271;
	mov.u32 	%r331, 0;
	bra.uni 	$L__BB17_33;

$L__BB17_30:
	mul.rn.f64 	%fd262, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r331, %fd262;
	st.local.u32 	[%rd1], %r331;
	cvt.rn.f64.s32 	%fd263, %r331;
	neg.f64 	%fd264, %fd263;
	mov.f64 	%fd265, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd266, %fd264, %fd265, %fd26;
	mov.f64 	%fd267, 0d3C91A62633145C00;
	fma.rn.f64 	%fd268, %fd264, %fd267, %fd266;
	mov.f64 	%fd269, 0d397B839A252049C0;
	fma.rn.f64 	%fd780, %fd264, %fd269, %fd268;
	abs.f64 	%fd270, %fd26;
	setp.ltu.f64 	%p59, %fd270, 0d41E0000000000000;
	@%p59 bra 	$L__BB17_33;

	{ // callseq 270, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd780, [retval0+0];
	} // callseq 270
	ld.local.u32 	%r331, [%rd1];

$L__BB17_33:
	and.b32  	%r116, %r331, 1;
	shl.b32 	%r117, %r331, 3;
	and.b32  	%r118, %r117, 8;
	setp.eq.s32 	%p60, %r116, 0;
	selp.f64 	%fd272, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p60;
	mul.wide.s32 	%rd39, %r118, 8;
	mov.u64 	%rd40, __cudart_sin_cos_coeffs;
	add.s64 	%rd41, %rd40, %rd39;
	ld.global.nc.f64 	%fd273, [%rd41+8];
	mul.rn.f64 	%fd31, %fd780, %fd780;
	fma.rn.f64 	%fd274, %fd272, %fd31, %fd273;
	ld.global.nc.f64 	%fd275, [%rd41+16];
	fma.rn.f64 	%fd276, %fd274, %fd31, %fd275;
	ld.global.nc.f64 	%fd277, [%rd41+24];
	fma.rn.f64 	%fd278, %fd276, %fd31, %fd277;
	ld.global.nc.f64 	%fd279, [%rd41+32];
	fma.rn.f64 	%fd280, %fd278, %fd31, %fd279;
	ld.global.nc.f64 	%fd281, [%rd41+40];
	fma.rn.f64 	%fd282, %fd280, %fd31, %fd281;
	ld.global.nc.f64 	%fd283, [%rd41+48];
	fma.rn.f64 	%fd32, %fd282, %fd31, %fd283;
	fma.rn.f64 	%fd782, %fd32, %fd780, %fd780;
	@%p60 bra 	$L__BB17_35;

	mov.f64 	%fd284, 0d3FF0000000000000;
	fma.rn.f64 	%fd782, %fd32, %fd31, %fd284;

$L__BB17_35:
	and.b32  	%r119, %r331, 2;
	setp.eq.s32 	%p61, %r119, 0;
	@%p61 bra 	$L__BB17_37;

	mov.f64 	%fd285, 0d0000000000000000;
	mov.f64 	%fd286, 0dBFF0000000000000;
	fma.rn.f64 	%fd782, %fd782, %fd286, %fd285;

$L__BB17_37:
	mul.rn.f64 	%fd287, %fd782, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd288, %fd25;
	add.rn.f64 	%fd38, %fd288, %fd287;
	setp.eq.f64 	%p62, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p63, %fd5, 0d0000000000000000;
	and.pred  	%p64, %p63, %p62;
	@%p64 bra 	$L__BB17_41;
	bra.uni 	$L__BB17_38;

$L__BB17_41:
	selp.f64 	%fd341, 0d400921FB54442D18, 0d0000000000000000, %p11;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r128, %temp}, %fd341;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd341;
	}
	and.b32  	%r130, %r6, -2147483648;
	or.b32  	%r131, %r129, %r130;
	mov.b64 	%fd783, {%r128, %r131};
	bra.uni 	$L__BB17_42;

$L__BB17_38:
	setp.eq.f64 	%p65, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p66, %fd15, 0d7FF0000000000000;
	and.pred  	%p67, %p65, %p66;
	@%p67 bra 	$L__BB17_40;
	bra.uni 	$L__BB17_39;

$L__BB17_40:
	selp.f64 	%fd340, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p11;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r124, %temp}, %fd340;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r125}, %fd340;
	}
	and.b32  	%r126, %r6, -2147483648;
	or.b32  	%r127, %r125, %r126;
	mov.b64 	%fd783, {%r124, %r127};
	bra.uni 	$L__BB17_42;

$L__BB17_39:
	min.f64 	%fd289, %fd15, %fd5;
	max.f64 	%fd290, %fd15, %fd5;
	div.rn.f64 	%fd291, %fd289, %fd290;
	mul.rn.f64 	%fd292, %fd291, %fd291;
	mov.f64 	%fd293, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd294, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd295, %fd294, %fd292, %fd293;
	mov.f64 	%fd296, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd297, %fd295, %fd292, %fd296;
	mov.f64 	%fd298, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd299, %fd297, %fd292, %fd298;
	mov.f64 	%fd300, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd301, %fd299, %fd292, %fd300;
	mov.f64 	%fd302, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd303, %fd301, %fd292, %fd302;
	mov.f64 	%fd304, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd305, %fd303, %fd292, %fd304;
	mov.f64 	%fd306, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd307, %fd305, %fd292, %fd306;
	mov.f64 	%fd308, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd309, %fd307, %fd292, %fd308;
	mov.f64 	%fd310, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd311, %fd309, %fd292, %fd310;
	mov.f64 	%fd312, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd313, %fd311, %fd292, %fd312;
	mov.f64 	%fd314, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd315, %fd313, %fd292, %fd314;
	mov.f64 	%fd316, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd317, %fd315, %fd292, %fd316;
	mov.f64 	%fd318, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd319, %fd317, %fd292, %fd318;
	mov.f64 	%fd320, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd321, %fd319, %fd292, %fd320;
	mov.f64 	%fd322, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd323, %fd321, %fd292, %fd322;
	mov.f64 	%fd324, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd325, %fd323, %fd292, %fd324;
	mov.f64 	%fd326, 0d3FC99999999840D2;
	fma.rn.f64 	%fd327, %fd325, %fd292, %fd326;
	mov.f64 	%fd328, 0dBFD555555555544C;
	fma.rn.f64 	%fd329, %fd327, %fd292, %fd328;
	mul.rn.f64 	%fd330, %fd292, %fd329;
	fma.rn.f64 	%fd331, %fd330, %fd291, %fd291;
	mov.f64 	%fd332, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd333, %fd332, %fd331;
	setp.gt.f64 	%p69, %fd15, %fd5;
	selp.f64 	%fd334, %fd333, %fd331, %p69;
	mov.f64 	%fd335, 0d400921FB54442D18;
	sub.rn.f64 	%fd336, %fd335, %fd334;
	selp.f64 	%fd337, %fd336, %fd334, %p11;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r120, %temp}, %fd337;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r121}, %fd337;
	}
	and.b32  	%r122, %r6, -2147483648;
	or.b32  	%r123, %r121, %r122;
	mov.b64 	%fd338, {%r120, %r123};
	add.rn.f64 	%fd339, %fd5, %fd15;
	setp.le.f64 	%p70, %fd339, 0d7FF0000000000000;
	selp.f64 	%fd783, %fd338, %fd339, %p70;

$L__BB17_42:
	add.rn.f64 	%fd773, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd773, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r132, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r133}, %fd43;
	}
	and.b32  	%r134, %r133, 2147483647;
	setp.eq.s32 	%p73, %r134, 2146435072;
	setp.eq.s32 	%p74, %r132, 0;
	and.pred  	%p75, %p74, %p73;
	@%p75 bra 	$L__BB17_46;
	bra.uni 	$L__BB17_43;

$L__BB17_46:
	mov.f64 	%fd351, 0d0000000000000000;
	mul.rn.f64 	%fd785, %fd43, %fd351;
	mov.u32 	%r333, 1;
	bra.uni 	$L__BB17_47;

$L__BB17_43:
	mul.rn.f64 	%fd342, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r332, %fd342;
	st.local.u32 	[%rd1], %r332;
	cvt.rn.f64.s32 	%fd343, %r332;
	neg.f64 	%fd344, %fd343;
	mov.f64 	%fd345, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd346, %fd344, %fd345, %fd43;
	mov.f64 	%fd347, 0d3C91A62633145C00;
	fma.rn.f64 	%fd348, %fd344, %fd347, %fd346;
	mov.f64 	%fd349, 0d397B839A252049C0;
	fma.rn.f64 	%fd785, %fd344, %fd349, %fd348;
	abs.f64 	%fd350, %fd43;
	setp.ltu.f64 	%p76, %fd350, 0d41E0000000000000;
	@%p76 bra 	$L__BB17_45;

	{ // callseq 271, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd785, [retval0+0];
	} // callseq 271
	ld.local.u32 	%r332, [%rd1];

$L__BB17_45:
	add.s32 	%r333, %r332, 1;

$L__BB17_47:
	and.b32  	%r136, %r333, 1;
	shl.b32 	%r137, %r333, 3;
	and.b32  	%r138, %r137, 8;
	setp.eq.s32 	%p77, %r136, 0;
	selp.f64 	%fd352, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p77;
	mul.wide.s32 	%rd43, %r138, 8;
	add.s64 	%rd45, %rd40, %rd43;
	ld.global.nc.f64 	%fd353, [%rd45+8];
	mul.rn.f64 	%fd49, %fd785, %fd785;
	fma.rn.f64 	%fd354, %fd352, %fd49, %fd353;
	ld.global.nc.f64 	%fd355, [%rd45+16];
	fma.rn.f64 	%fd356, %fd354, %fd49, %fd355;
	ld.global.nc.f64 	%fd357, [%rd45+24];
	fma.rn.f64 	%fd358, %fd356, %fd49, %fd357;
	ld.global.nc.f64 	%fd359, [%rd45+32];
	fma.rn.f64 	%fd360, %fd358, %fd49, %fd359;
	ld.global.nc.f64 	%fd361, [%rd45+40];
	fma.rn.f64 	%fd362, %fd360, %fd49, %fd361;
	ld.global.nc.f64 	%fd363, [%rd45+48];
	fma.rn.f64 	%fd50, %fd362, %fd49, %fd363;
	fma.rn.f64 	%fd787, %fd50, %fd785, %fd785;
	@%p77 bra 	$L__BB17_49;

	mov.f64 	%fd364, 0d3FF0000000000000;
	fma.rn.f64 	%fd787, %fd50, %fd49, %fd364;

$L__BB17_49:
	and.b32  	%r139, %r333, 2;
	setp.eq.s32 	%p78, %r139, 0;
	@%p78 bra 	$L__BB17_51;

	mov.f64 	%fd365, 0d0000000000000000;
	mov.f64 	%fd366, 0dBFF0000000000000;
	fma.rn.f64 	%fd787, %fd787, %fd366, %fd365;

$L__BB17_51:
	mul.rn.f64 	%fd367, %fd787, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd783, %fd367;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r140, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r141}, %fd56;
	}
	and.b32  	%r142, %r141, 2147483647;
	setp.eq.s32 	%p79, %r142, 2146435072;
	setp.eq.s32 	%p80, %r140, 0;
	and.pred  	%p3, %p80, %p79;
	@%p3 bra 	$L__BB17_55;
	bra.uni 	$L__BB17_52;

$L__BB17_55:
	mov.f64 	%fd377, 0d0000000000000000;
	mul.rn.f64 	%fd789, %fd56, %fd377;
	mov.u32 	%r335, 1;
	bra.uni 	$L__BB17_56;

$L__BB17_52:
	mul.rn.f64 	%fd368, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r334, %fd368;
	st.local.u32 	[%rd1], %r334;
	cvt.rn.f64.s32 	%fd369, %r334;
	neg.f64 	%fd370, %fd369;
	mov.f64 	%fd371, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd372, %fd370, %fd371, %fd56;
	mov.f64 	%fd373, 0d3C91A62633145C00;
	fma.rn.f64 	%fd374, %fd370, %fd373, %fd372;
	mov.f64 	%fd375, 0d397B839A252049C0;
	fma.rn.f64 	%fd789, %fd370, %fd375, %fd374;
	abs.f64 	%fd376, %fd56;
	setp.ltu.f64 	%p81, %fd376, 0d41E0000000000000;
	@%p81 bra 	$L__BB17_54;

	{ // callseq 272, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd789, [retval0+0];
	} // callseq 272
	ld.local.u32 	%r334, [%rd1];

$L__BB17_54:
	add.s32 	%r335, %r334, 1;

$L__BB17_56:
	and.b32  	%r144, %r335, 1;
	shl.b32 	%r145, %r335, 3;
	and.b32  	%r146, %r145, 8;
	setp.eq.s32 	%p82, %r144, 0;
	selp.f64 	%fd378, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p82;
	mul.wide.s32 	%rd47, %r146, 8;
	add.s64 	%rd49, %rd40, %rd47;
	ld.global.nc.f64 	%fd379, [%rd49+8];
	mul.rn.f64 	%fd62, %fd789, %fd789;
	fma.rn.f64 	%fd380, %fd378, %fd62, %fd379;
	ld.global.nc.f64 	%fd381, [%rd49+16];
	fma.rn.f64 	%fd382, %fd380, %fd62, %fd381;
	ld.global.nc.f64 	%fd383, [%rd49+24];
	fma.rn.f64 	%fd384, %fd382, %fd62, %fd383;
	ld.global.nc.f64 	%fd385, [%rd49+32];
	fma.rn.f64 	%fd386, %fd384, %fd62, %fd385;
	ld.global.nc.f64 	%fd387, [%rd49+40];
	fma.rn.f64 	%fd388, %fd386, %fd62, %fd387;
	ld.global.nc.f64 	%fd389, [%rd49+48];
	fma.rn.f64 	%fd63, %fd388, %fd62, %fd389;
	fma.rn.f64 	%fd791, %fd63, %fd789, %fd789;
	@%p82 bra 	$L__BB17_58;

	mov.f64 	%fd390, 0d3FF0000000000000;
	fma.rn.f64 	%fd791, %fd63, %fd62, %fd390;

$L__BB17_58:
	and.b32  	%r147, %r335, 2;
	setp.eq.s32 	%p83, %r147, 0;
	@%p83 bra 	$L__BB17_60;

	mov.f64 	%fd391, 0d0000000000000000;
	mov.f64 	%fd392, 0dBFF0000000000000;
	fma.rn.f64 	%fd791, %fd791, %fd392, %fd391;

$L__BB17_60:
	mul.rn.f64 	%fd839, %fd38, %fd791;
	@%p3 bra 	$L__BB17_63;
	bra.uni 	$L__BB17_61;

$L__BB17_63:
	mov.f64 	%fd402, 0d0000000000000000;
	mul.rn.f64 	%fd792, %fd56, %fd402;
	mov.u32 	%r336, 0;
	bra.uni 	$L__BB17_64;

$L__BB17_61:
	mul.rn.f64 	%fd393, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r336, %fd393;
	st.local.u32 	[%rd1], %r336;
	cvt.rn.f64.s32 	%fd394, %r336;
	neg.f64 	%fd395, %fd394;
	mov.f64 	%fd396, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd397, %fd395, %fd396, %fd56;
	mov.f64 	%fd398, 0d3C91A62633145C00;
	fma.rn.f64 	%fd399, %fd395, %fd398, %fd397;
	mov.f64 	%fd400, 0d397B839A252049C0;
	fma.rn.f64 	%fd792, %fd395, %fd400, %fd399;
	abs.f64 	%fd401, %fd56;
	setp.ltu.f64 	%p84, %fd401, 0d41E0000000000000;
	@%p84 bra 	$L__BB17_64;

	{ // callseq 273, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd792, [retval0+0];
	} // callseq 273
	ld.local.u32 	%r336, [%rd1];

$L__BB17_64:
	and.b32  	%r149, %r336, 1;
	shl.b32 	%r150, %r336, 3;
	and.b32  	%r151, %r150, 8;
	setp.eq.s32 	%p85, %r149, 0;
	selp.f64 	%fd403, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p85;
	mul.wide.s32 	%rd51, %r151, 8;
	add.s64 	%rd53, %rd40, %rd51;
	ld.global.nc.f64 	%fd404, [%rd53+8];
	mul.rn.f64 	%fd74, %fd792, %fd792;
	fma.rn.f64 	%fd405, %fd403, %fd74, %fd404;
	ld.global.nc.f64 	%fd406, [%rd53+16];
	fma.rn.f64 	%fd407, %fd405, %fd74, %fd406;
	ld.global.nc.f64 	%fd408, [%rd53+24];
	fma.rn.f64 	%fd409, %fd407, %fd74, %fd408;
	ld.global.nc.f64 	%fd410, [%rd53+32];
	fma.rn.f64 	%fd411, %fd409, %fd74, %fd410;
	ld.global.nc.f64 	%fd412, [%rd53+40];
	fma.rn.f64 	%fd413, %fd411, %fd74, %fd412;
	ld.global.nc.f64 	%fd414, [%rd53+48];
	fma.rn.f64 	%fd75, %fd413, %fd74, %fd414;
	fma.rn.f64 	%fd794, %fd75, %fd792, %fd792;
	@%p85 bra 	$L__BB17_66;

	mov.f64 	%fd415, 0d3FF0000000000000;
	fma.rn.f64 	%fd794, %fd75, %fd74, %fd415;

$L__BB17_66:
	and.b32  	%r152, %r336, 2;
	setp.eq.s32 	%p86, %r152, 0;
	@%p86 bra 	$L__BB17_68;

	mov.f64 	%fd416, 0d0000000000000000;
	mov.f64 	%fd417, 0dBFF0000000000000;
	fma.rn.f64 	%fd794, %fd794, %fd417, %fd416;

$L__BB17_68:
	ld.param.u32 	%r330, [bd09_to_gcj02_exact_cuda_double_param_5];
	mul.rn.f64 	%fd840, %fd38, %fd794;
	setp.lt.s32 	%p87, %r330, 1;
	@%p87 bra 	$L__BB17_209;

	and.b32  	%r24, %r3, 2147483647;
	setp.gt.s32 	%p88, %r3, -1;
	selp.b32 	%r25, 2146435072, 0, %p88;
	mov.u32 	%r337, 0;
	or.b32  	%r26, %r25, -2147483648;
	mov.f64 	%fd795, %fd840;
	mov.f64 	%fd796, %fd839;

$L__BB17_70:
	mov.f64 	%fd839, %fd796;
	mov.f64 	%fd840, %fd795;
	abs.f64 	%fd84, %fd839;
	{ // callseq 274, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd799, [retval0+0];
	} // callseq 274
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd839;
	}
	setp.lt.s32 	%p89, %r28, 0;
	and.pred  	%p4, %p89, %p10;
	not.pred 	%p91, %p4;
	@%p91 bra 	$L__BB17_72;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd799;
	}
	xor.b32  	%r155, %r154, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r156, %temp}, %fd799;
	}
	mov.b64 	%fd799, {%r156, %r155};

$L__BB17_72:
	setp.eq.f64 	%p92, %fd839, 0d0000000000000000;
	@%p92 bra 	$L__BB17_76;
	bra.uni 	$L__BB17_73;

$L__BB17_76:
	setp.lt.s32 	%p95, %r3, 0;
	mov.u32 	%r157, 0;
	selp.b32 	%r158, %r28, 0, %p10;
	or.b32  	%r159, %r158, 2146435072;
	selp.b32 	%r160, %r159, %r158, %p95;
	mov.b64 	%fd799, {%r157, %r160};
	bra.uni 	$L__BB17_77;

$L__BB17_73:
	setp.gt.s32 	%p93, %r28, -1;
	@%p93 bra 	$L__BB17_77;

	mov.f64 	%fd418, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd419, %fd418;
	setp.eq.f64 	%p94, %fd419, 0d4000000000000000;
	@%p94 bra 	$L__BB17_77;

	mov.f64 	%fd799, 0dFFF8000000000000;

$L__BB17_77:
	add.rn.f64 	%fd421, %fd839, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd421;
	}
	and.b32  	%r162, %r161, 2146435072;
	setp.ne.s32 	%p97, %r162, 2146435072;
	@%p97 bra 	$L__BB17_84;

	setp.gtu.f64 	%p98, %fd84, 0d7FF0000000000000;
	@%p98 bra 	$L__BB17_83;
	bra.uni 	$L__BB17_79;

$L__BB17_83:
	mov.f64 	%fd423, 0d4000000000000000;
	add.rn.f64 	%fd799, %fd839, %fd423;
	bra.uni 	$L__BB17_84;

$L__BB17_79:
	setp.eq.s32 	%p99, %r24, 2146435072;
	mov.f64 	%fd422, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r163, %temp}, %fd422;
	}
	setp.eq.s32 	%p100, %r163, 0;
	and.pred  	%p101, %p99, %p100;
	@%p101 bra 	$L__BB17_82;
	bra.uni 	$L__BB17_80;

$L__BB17_82:
	setp.lt.s32 	%p107, %r3, 0;
	mov.u32 	%r168, 0;
	setp.gt.f64 	%p108, %fd84, 0d3FF0000000000000;
	selp.b32 	%r169, 2146435072, 0, %p108;
	xor.b32  	%r170, %r169, 2146435072;
	selp.b32 	%r171, %r170, %r169, %p107;
	setp.eq.f64 	%p109, %fd839, 0dBFF0000000000000;
	selp.b32 	%r172, 1072693248, %r171, %p109;
	mov.b64 	%fd799, {%r168, %r172};
	bra.uni 	$L__BB17_84;

$L__BB17_80:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r164, %temp}, %fd839;
	}
	and.b32  	%r165, %r28, 2147483647;
	setp.ne.s32 	%p102, %r165, 2146435072;
	setp.ne.s32 	%p103, %r164, 0;
	or.pred  	%p104, %p102, %p103;
	@%p104 bra 	$L__BB17_84;

	setp.ne.s32 	%p105, %r24, 1071644672;
	and.pred  	%p106, %p105, %p4;
	selp.b32 	%r166, %r26, %r25, %p106;
	mov.u32 	%r167, 0;
	mov.b64 	%fd799, {%r167, %r166};

$L__BB17_84:
	abs.f64 	%fd94, %fd840;
	{ // callseq 275, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd802, [retval0+0];
	} // callseq 275
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r29}, %fd840;
	}
	setp.lt.s32 	%p110, %r29, 0;
	and.pred  	%p5, %p110, %p10;
	not.pred 	%p112, %p5;
	@%p112 bra 	$L__BB17_86;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r173}, %fd802;
	}
	xor.b32  	%r174, %r173, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r175, %temp}, %fd802;
	}
	mov.b64 	%fd802, {%r175, %r174};

$L__BB17_86:
	setp.eq.f64 	%p113, %fd840, 0d0000000000000000;
	@%p113 bra 	$L__BB17_90;
	bra.uni 	$L__BB17_87;

$L__BB17_90:
	setp.lt.s32 	%p116, %r3, 0;
	mov.u32 	%r176, 0;
	selp.b32 	%r177, %r29, 0, %p10;
	or.b32  	%r178, %r177, 2146435072;
	selp.b32 	%r179, %r178, %r177, %p116;
	mov.b64 	%fd802, {%r176, %r179};
	bra.uni 	$L__BB17_91;

$L__BB17_87:
	setp.gt.s32 	%p114, %r29, -1;
	@%p114 bra 	$L__BB17_91;

	mov.f64 	%fd424, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd425, %fd424;
	setp.eq.f64 	%p115, %fd425, 0d4000000000000000;
	@%p115 bra 	$L__BB17_91;

	mov.f64 	%fd802, 0dFFF8000000000000;

$L__BB17_91:
	add.rn.f64 	%fd427, %fd840, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r180}, %fd427;
	}
	and.b32  	%r181, %r180, 2146435072;
	setp.ne.s32 	%p118, %r181, 2146435072;
	@%p118 bra 	$L__BB17_98;

	setp.gtu.f64 	%p119, %fd94, 0d7FF0000000000000;
	@%p119 bra 	$L__BB17_97;
	bra.uni 	$L__BB17_93;

$L__BB17_97:
	mov.f64 	%fd429, 0d4000000000000000;
	add.rn.f64 	%fd802, %fd840, %fd429;
	bra.uni 	$L__BB17_98;

$L__BB17_93:
	setp.eq.s32 	%p120, %r24, 2146435072;
	mov.f64 	%fd428, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd428;
	}
	setp.eq.s32 	%p121, %r182, 0;
	and.pred  	%p122, %p120, %p121;
	@%p122 bra 	$L__BB17_96;
	bra.uni 	$L__BB17_94;

$L__BB17_96:
	setp.lt.s32 	%p128, %r3, 0;
	mov.u32 	%r187, 0;
	setp.gt.f64 	%p129, %fd94, 0d3FF0000000000000;
	selp.b32 	%r188, 2146435072, 0, %p129;
	xor.b32  	%r189, %r188, 2146435072;
	selp.b32 	%r190, %r189, %r188, %p128;
	setp.eq.f64 	%p130, %fd840, 0dBFF0000000000000;
	selp.b32 	%r191, 1072693248, %r190, %p130;
	mov.b64 	%fd802, {%r187, %r191};
	bra.uni 	$L__BB17_98;

$L__BB17_94:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r183, %temp}, %fd840;
	}
	and.b32  	%r184, %r29, 2147483647;
	setp.ne.s32 	%p123, %r184, 2146435072;
	setp.ne.s32 	%p124, %r183, 0;
	or.pred  	%p125, %p123, %p124;
	@%p125 bra 	$L__BB17_98;

	setp.ne.s32 	%p126, %r24, 1071644672;
	and.pred  	%p127, %p126, %p5;
	selp.b32 	%r185, %r26, %r25, %p127;
	mov.u32 	%r186, 0;
	mov.b64 	%fd802, {%r186, %r185};

$L__BB17_98:
	setp.eq.f64 	%p131, %fd840, 0d3FF0000000000000;
	selp.f64 	%fd430, 0d3FF0000000000000, %fd802, %p131;
	setp.eq.f64 	%p132, %fd839, 0d3FF0000000000000;
	selp.f64 	%fd431, 0d3FF0000000000000, %fd799, %p132;
	add.rn.f64 	%fd104, %fd431, %fd430;
	mul.rn.f64 	%fd105, %fd840, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r192, %temp}, %fd105;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd105;
	}
	and.b32  	%r194, %r193, 2147483647;
	setp.eq.s32 	%p133, %r194, 2146435072;
	setp.eq.s32 	%p134, %r192, 0;
	and.pred  	%p135, %p134, %p133;
	@%p135 bra 	$L__BB17_101;
	bra.uni 	$L__BB17_99;

$L__BB17_101:
	mov.f64 	%fd441, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd105, %fd441;
	mov.u32 	%r338, 0;
	bra.uni 	$L__BB17_102;

$L__BB17_99:
	mul.rn.f64 	%fd432, %fd105, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd432;
	st.local.u32 	[%rd1], %r338;
	cvt.rn.f64.s32 	%fd433, %r338;
	neg.f64 	%fd434, %fd433;
	mov.f64 	%fd435, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd436, %fd434, %fd435, %fd105;
	mov.f64 	%fd437, 0d3C91A62633145C00;
	fma.rn.f64 	%fd438, %fd434, %fd437, %fd436;
	mov.f64 	%fd439, 0d397B839A252049C0;
	fma.rn.f64 	%fd803, %fd434, %fd439, %fd438;
	abs.f64 	%fd440, %fd105;
	setp.ltu.f64 	%p136, %fd440, 0d41E0000000000000;
	@%p136 bra 	$L__BB17_102;

	{ // callseq 276, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd803, [retval0+0];
	} // callseq 276
	ld.local.u32 	%r338, [%rd1];

$L__BB17_102:
	and.b32  	%r196, %r338, 1;
	shl.b32 	%r197, %r338, 3;
	and.b32  	%r198, %r197, 8;
	setp.eq.s32 	%p137, %r196, 0;
	selp.f64 	%fd442, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p137;
	mul.wide.s32 	%rd55, %r198, 8;
	add.s64 	%rd57, %rd40, %rd55;
	ld.global.nc.f64 	%fd443, [%rd57+8];
	mul.rn.f64 	%fd110, %fd803, %fd803;
	fma.rn.f64 	%fd444, %fd442, %fd110, %fd443;
	ld.global.nc.f64 	%fd445, [%rd57+16];
	fma.rn.f64 	%fd446, %fd444, %fd110, %fd445;
	ld.global.nc.f64 	%fd447, [%rd57+24];
	fma.rn.f64 	%fd448, %fd446, %fd110, %fd447;
	ld.global.nc.f64 	%fd449, [%rd57+32];
	fma.rn.f64 	%fd450, %fd448, %fd110, %fd449;
	ld.global.nc.f64 	%fd451, [%rd57+40];
	fma.rn.f64 	%fd452, %fd450, %fd110, %fd451;
	ld.global.nc.f64 	%fd453, [%rd57+48];
	fma.rn.f64 	%fd111, %fd452, %fd110, %fd453;
	fma.rn.f64 	%fd805, %fd111, %fd803, %fd803;
	@%p137 bra 	$L__BB17_104;

	mov.f64 	%fd454, 0d3FF0000000000000;
	fma.rn.f64 	%fd805, %fd111, %fd110, %fd454;

$L__BB17_104:
	and.b32  	%r199, %r338, 2;
	setp.eq.s32 	%p138, %r199, 0;
	@%p138 bra 	$L__BB17_106;

	mov.f64 	%fd455, 0d0000000000000000;
	mov.f64 	%fd456, 0dBFF0000000000000;
	fma.rn.f64 	%fd805, %fd805, %fd456, %fd455;

$L__BB17_106:
	mul.rn.f64 	%fd457, %fd805, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd458, %fd104;
	add.rn.f64 	%fd117, %fd458, %fd457;
	setp.eq.f64 	%p139, %fd94, 0d0000000000000000;
	setp.eq.f64 	%p140, %fd84, 0d0000000000000000;
	and.pred  	%p141, %p140, %p139;
	@%p141 bra 	$L__BB17_110;
	bra.uni 	$L__BB17_107;

$L__BB17_110:
	selp.f64 	%fd511, 0d400921FB54442D18, 0d0000000000000000, %p89;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd511;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd511;
	}
	and.b32  	%r210, %r29, -2147483648;
	or.b32  	%r211, %r209, %r210;
	mov.b64 	%fd806, {%r208, %r211};
	bra.uni 	$L__BB17_111;

$L__BB17_107:
	setp.eq.f64 	%p142, %fd84, 0d7FF0000000000000;
	setp.eq.f64 	%p143, %fd94, 0d7FF0000000000000;
	and.pred  	%p144, %p142, %p143;
	@%p144 bra 	$L__BB17_109;
	bra.uni 	$L__BB17_108;

$L__BB17_109:
	selp.f64 	%fd510, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p89;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r204, %temp}, %fd510;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r205}, %fd510;
	}
	and.b32  	%r206, %r29, -2147483648;
	or.b32  	%r207, %r205, %r206;
	mov.b64 	%fd806, {%r204, %r207};
	bra.uni 	$L__BB17_111;

$L__BB17_108:
	min.f64 	%fd459, %fd94, %fd84;
	max.f64 	%fd460, %fd94, %fd84;
	div.rn.f64 	%fd461, %fd459, %fd460;
	mul.rn.f64 	%fd462, %fd461, %fd461;
	mov.f64 	%fd463, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd464, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd465, %fd464, %fd462, %fd463;
	mov.f64 	%fd466, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd467, %fd465, %fd462, %fd466;
	mov.f64 	%fd468, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd469, %fd467, %fd462, %fd468;
	mov.f64 	%fd470, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd471, %fd469, %fd462, %fd470;
	mov.f64 	%fd472, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd473, %fd471, %fd462, %fd472;
	mov.f64 	%fd474, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd475, %fd473, %fd462, %fd474;
	mov.f64 	%fd476, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd477, %fd475, %fd462, %fd476;
	mov.f64 	%fd478, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd479, %fd477, %fd462, %fd478;
	mov.f64 	%fd480, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd481, %fd479, %fd462, %fd480;
	mov.f64 	%fd482, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd483, %fd481, %fd462, %fd482;
	mov.f64 	%fd484, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd485, %fd483, %fd462, %fd484;
	mov.f64 	%fd486, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd487, %fd485, %fd462, %fd486;
	mov.f64 	%fd488, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd489, %fd487, %fd462, %fd488;
	mov.f64 	%fd490, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd491, %fd489, %fd462, %fd490;
	mov.f64 	%fd492, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd493, %fd491, %fd462, %fd492;
	mov.f64 	%fd494, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd495, %fd493, %fd462, %fd494;
	mov.f64 	%fd496, 0d3FC99999999840D2;
	fma.rn.f64 	%fd497, %fd495, %fd462, %fd496;
	mov.f64 	%fd498, 0dBFD555555555544C;
	fma.rn.f64 	%fd499, %fd497, %fd462, %fd498;
	mul.rn.f64 	%fd500, %fd462, %fd499;
	fma.rn.f64 	%fd501, %fd500, %fd461, %fd461;
	mov.f64 	%fd502, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd503, %fd502, %fd501;
	setp.gt.f64 	%p146, %fd94, %fd84;
	selp.f64 	%fd504, %fd503, %fd501, %p146;
	mov.f64 	%fd505, 0d400921FB54442D18;
	sub.rn.f64 	%fd506, %fd505, %fd504;
	selp.f64 	%fd507, %fd506, %fd504, %p89;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r200, %temp}, %fd507;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r201}, %fd507;
	}
	and.b32  	%r202, %r29, -2147483648;
	or.b32  	%r203, %r201, %r202;
	mov.b64 	%fd508, {%r200, %r203};
	add.rn.f64 	%fd509, %fd84, %fd94;
	setp.le.f64 	%p147, %fd509, 0d7FF0000000000000;
	selp.f64 	%fd806, %fd508, %fd509, %p147;

$L__BB17_111:
	mul.rn.f64 	%fd122, %fd839, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r212, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r213}, %fd122;
	}
	and.b32  	%r214, %r213, 2147483647;
	setp.eq.s32 	%p150, %r214, 2146435072;
	setp.eq.s32 	%p151, %r212, 0;
	and.pred  	%p152, %p151, %p150;
	@%p152 bra 	$L__BB17_115;
	bra.uni 	$L__BB17_112;

$L__BB17_115:
	mov.f64 	%fd521, 0d0000000000000000;
	mul.rn.f64 	%fd808, %fd122, %fd521;
	mov.u32 	%r340, 1;
	bra.uni 	$L__BB17_116;

$L__BB17_112:
	mul.rn.f64 	%fd512, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r339, %fd512;
	st.local.u32 	[%rd1], %r339;
	cvt.rn.f64.s32 	%fd513, %r339;
	neg.f64 	%fd514, %fd513;
	mov.f64 	%fd515, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd516, %fd514, %fd515, %fd122;
	mov.f64 	%fd517, 0d3C91A62633145C00;
	fma.rn.f64 	%fd518, %fd514, %fd517, %fd516;
	mov.f64 	%fd519, 0d397B839A252049C0;
	fma.rn.f64 	%fd808, %fd514, %fd519, %fd518;
	abs.f64 	%fd520, %fd122;
	setp.ltu.f64 	%p153, %fd520, 0d41E0000000000000;
	@%p153 bra 	$L__BB17_114;

	{ // callseq 277, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 277
	ld.local.u32 	%r339, [%rd1];

$L__BB17_114:
	add.s32 	%r340, %r339, 1;

$L__BB17_116:
	and.b32  	%r216, %r340, 1;
	shl.b32 	%r217, %r340, 3;
	and.b32  	%r218, %r217, 8;
	setp.eq.s32 	%p154, %r216, 0;
	selp.f64 	%fd522, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p154;
	mul.wide.s32 	%rd59, %r218, 8;
	add.s64 	%rd61, %rd40, %rd59;
	ld.global.nc.f64 	%fd523, [%rd61+8];
	mul.rn.f64 	%fd128, %fd808, %fd808;
	fma.rn.f64 	%fd524, %fd522, %fd128, %fd523;
	ld.global.nc.f64 	%fd525, [%rd61+16];
	fma.rn.f64 	%fd526, %fd524, %fd128, %fd525;
	ld.global.nc.f64 	%fd527, [%rd61+24];
	fma.rn.f64 	%fd528, %fd526, %fd128, %fd527;
	ld.global.nc.f64 	%fd529, [%rd61+32];
	fma.rn.f64 	%fd530, %fd528, %fd128, %fd529;
	ld.global.nc.f64 	%fd531, [%rd61+40];
	fma.rn.f64 	%fd532, %fd530, %fd128, %fd531;
	ld.global.nc.f64 	%fd533, [%rd61+48];
	fma.rn.f64 	%fd129, %fd532, %fd128, %fd533;
	fma.rn.f64 	%fd810, %fd129, %fd808, %fd808;
	@%p154 bra 	$L__BB17_118;

	mov.f64 	%fd534, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd129, %fd128, %fd534;

$L__BB17_118:
	and.b32  	%r219, %r340, 2;
	setp.eq.s32 	%p155, %r219, 0;
	@%p155 bra 	$L__BB17_120;

	mov.f64 	%fd535, 0d0000000000000000;
	mov.f64 	%fd536, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd536, %fd535;

$L__BB17_120:
	mul.rn.f64 	%fd537, %fd810, 0d3EC92A737110E454;
	add.rn.f64 	%fd135, %fd806, %fd537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r220, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r221}, %fd135;
	}
	and.b32  	%r222, %r221, 2147483647;
	setp.eq.s32 	%p156, %r222, 2146435072;
	setp.eq.s32 	%p157, %r220, 0;
	and.pred  	%p6, %p157, %p156;
	@%p6 bra 	$L__BB17_124;
	bra.uni 	$L__BB17_121;

$L__BB17_124:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd812, %fd135, %fd547;
	mov.u32 	%r342, 1;
	bra.uni 	$L__BB17_125;

$L__BB17_121:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r341, %fd538;
	st.local.u32 	[%rd1], %r341;
	cvt.rn.f64.s32 	%fd539, %r341;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd812, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p158, %fd546, 0d41E0000000000000;
	@%p158 bra 	$L__BB17_123;

	{ // callseq 278, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 278
	ld.local.u32 	%r341, [%rd1];

$L__BB17_123:
	add.s32 	%r342, %r341, 1;

$L__BB17_125:
	and.b32  	%r224, %r342, 1;
	shl.b32 	%r225, %r342, 3;
	and.b32  	%r226, %r225, 8;
	setp.eq.s32 	%p159, %r224, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p159;
	mul.wide.s32 	%rd63, %r226, 8;
	add.s64 	%rd65, %rd40, %rd63;
	ld.global.nc.f64 	%fd549, [%rd65+8];
	mul.rn.f64 	%fd141, %fd812, %fd812;
	fma.rn.f64 	%fd550, %fd548, %fd141, %fd549;
	ld.global.nc.f64 	%fd551, [%rd65+16];
	fma.rn.f64 	%fd552, %fd550, %fd141, %fd551;
	ld.global.nc.f64 	%fd553, [%rd65+24];
	fma.rn.f64 	%fd554, %fd552, %fd141, %fd553;
	ld.global.nc.f64 	%fd555, [%rd65+32];
	fma.rn.f64 	%fd556, %fd554, %fd141, %fd555;
	ld.global.nc.f64 	%fd557, [%rd65+40];
	fma.rn.f64 	%fd558, %fd556, %fd141, %fd557;
	ld.global.nc.f64 	%fd559, [%rd65+48];
	fma.rn.f64 	%fd142, %fd558, %fd141, %fd559;
	fma.rn.f64 	%fd814, %fd142, %fd812, %fd812;
	@%p159 bra 	$L__BB17_127;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd142, %fd141, %fd560;

$L__BB17_127:
	and.b32  	%r227, %r342, 2;
	setp.eq.s32 	%p160, %r227, 0;
	@%p160 bra 	$L__BB17_129;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd562, %fd561;

$L__BB17_129:
	mul.rn.f64 	%fd563, %fd117, %fd814;
	add.rn.f64 	%fd148, %fd563, 0d3F7A9FBE76C8B439;
	@%p6 bra 	$L__BB17_132;
	bra.uni 	$L__BB17_130;

$L__BB17_132:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd135, %fd573;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB17_133;

$L__BB17_130:
	mul.rn.f64 	%fd564, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r343, %fd564;
	st.local.u32 	[%rd1], %r343;
	cvt.rn.f64.s32 	%fd565, %r343;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd135;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd135;
	setp.ltu.f64 	%p161, %fd572, 0d41E0000000000000;
	@%p161 bra 	$L__BB17_133;

	{ // callseq 279, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 279
	ld.local.u32 	%r343, [%rd1];

$L__BB17_133:
	and.b32  	%r229, %r343, 1;
	shl.b32 	%r230, %r343, 3;
	and.b32  	%r231, %r230, 8;
	setp.eq.s32 	%p162, %r229, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p162;
	mul.wide.s32 	%rd67, %r231, 8;
	add.s64 	%rd69, %rd40, %rd67;
	ld.global.nc.f64 	%fd575, [%rd69+8];
	mul.rn.f64 	%fd153, %fd815, %fd815;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd69+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd69+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd69+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd69+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd69+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd817, %fd154, %fd815, %fd815;
	@%p162 bra 	$L__BB17_135;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd154, %fd153, %fd586;

$L__BB17_135:
	and.b32  	%r232, %r343, 2;
	setp.eq.s32 	%p163, %r232, 0;
	@%p163 bra 	$L__BB17_137;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd588, %fd587;

$L__BB17_137:
	ld.param.s8 	%rs2, [bd09_to_gcj02_exact_cuda_double_param_4];
	mul.rn.f64 	%fd589, %fd117, %fd817;
	add.rn.f64 	%fd590, %fd589, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd160, %fd3, %fd590;
	sub.rn.f64 	%fd161, %fd1, %fd148;
	add.rn.f64 	%fd796, %fd839, %fd161;
	add.rn.f64 	%fd795, %fd840, %fd160;
	setp.eq.s16 	%p164, %rs2, 0;
	@%p164 bra 	$L__BB17_206;

	mul.rn.f64 	%fd591, %fd840, 0d400921FB54442D18;
	div.rn.f64 	%fd164, %fd591, 0d4066800000000000;
	mul.rn.f64 	%fd592, %fd795, 0d400921FB54442D18;
	div.rn.f64 	%fd165, %fd592, 0d4066800000000000;
	sub.rn.f64 	%fd593, %fd165, %fd164;
	mul.rn.f64 	%fd166, %fd593, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd166;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r234}, %fd166;
	}
	and.b32  	%r235, %r234, 2147483647;
	setp.eq.s32 	%p165, %r235, 2146435072;
	setp.eq.s32 	%p166, %r233, 0;
	and.pred  	%p167, %p166, %p165;
	@%p167 bra 	$L__BB17_141;
	bra.uni 	$L__BB17_139;

$L__BB17_141:
	mov.f64 	%fd603, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd166, %fd603;
	mov.u32 	%r344, 0;
	bra.uni 	$L__BB17_142;

$L__BB17_206:
	abs.f64 	%fd771, %fd161;
	setp.geu.f64 	%p245, %fd771, %fd246;
	@%p245 bra 	$L__BB17_208;

	abs.f64 	%fd772, %fd160;
	setp.lt.f64 	%p246, %fd772, %fd246;
	@%p246 bra 	$L__BB17_209;
	bra.uni 	$L__BB17_208;

$L__BB17_139:
	mul.rn.f64 	%fd594, %fd166, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd594;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd595, %r344;
	neg.f64 	%fd596, %fd595;
	mov.f64 	%fd597, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd598, %fd596, %fd597, %fd166;
	mov.f64 	%fd599, 0d3C91A62633145C00;
	fma.rn.f64 	%fd600, %fd596, %fd599, %fd598;
	mov.f64 	%fd601, 0d397B839A252049C0;
	fma.rn.f64 	%fd818, %fd596, %fd601, %fd600;
	abs.f64 	%fd602, %fd166;
	setp.ltu.f64 	%p168, %fd602, 0d41E0000000000000;
	@%p168 bra 	$L__BB17_142;

	{ // callseq 280, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd166;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd818, [retval0+0];
	} // callseq 280
	ld.local.u32 	%r344, [%rd1];

$L__BB17_142:
	and.b32  	%r237, %r344, 1;
	shl.b32 	%r238, %r344, 3;
	and.b32  	%r239, %r238, 8;
	setp.eq.s32 	%p169, %r237, 0;
	selp.f64 	%fd604, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p169;
	mul.wide.s32 	%rd71, %r239, 8;
	add.s64 	%rd73, %rd40, %rd71;
	ld.global.nc.f64 	%fd605, [%rd73+8];
	mul.rn.f64 	%fd171, %fd818, %fd818;
	fma.rn.f64 	%fd606, %fd604, %fd171, %fd605;
	ld.global.nc.f64 	%fd607, [%rd73+16];
	fma.rn.f64 	%fd608, %fd606, %fd171, %fd607;
	ld.global.nc.f64 	%fd609, [%rd73+24];
	fma.rn.f64 	%fd610, %fd608, %fd171, %fd609;
	ld.global.nc.f64 	%fd611, [%rd73+32];
	fma.rn.f64 	%fd612, %fd610, %fd171, %fd611;
	ld.global.nc.f64 	%fd613, [%rd73+40];
	fma.rn.f64 	%fd614, %fd612, %fd171, %fd613;
	ld.global.nc.f64 	%fd615, [%rd73+48];
	fma.rn.f64 	%fd172, %fd614, %fd171, %fd615;
	fma.rn.f64 	%fd820, %fd172, %fd818, %fd818;
	@%p169 bra 	$L__BB17_144;

	mov.f64 	%fd616, 0d3FF0000000000000;
	fma.rn.f64 	%fd820, %fd172, %fd171, %fd616;

$L__BB17_144:
	and.b32  	%r240, %r344, 2;
	setp.eq.s32 	%p170, %r240, 0;
	@%p170 bra 	$L__BB17_146;

	mov.f64 	%fd617, 0d0000000000000000;
	mov.f64 	%fd618, 0dBFF0000000000000;
	fma.rn.f64 	%fd820, %fd820, %fd618, %fd617;

$L__BB17_146:
	abs.f64 	%fd178, %fd820;
	{ // callseq 281, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 281
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r49}, %fd820;
	}
	setp.lt.s32 	%p171, %r49, 0;
	and.pred  	%p7, %p171, %p10;
	not.pred 	%p173, %p7;
	@%p173 bra 	$L__BB17_148;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r241}, %fd823;
	}
	xor.b32  	%r242, %r241, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r243, %temp}, %fd823;
	}
	mov.b64 	%fd823, {%r243, %r242};

$L__BB17_148:
	setp.eq.f64 	%p174, %fd820, 0d0000000000000000;
	@%p174 bra 	$L__BB17_152;
	bra.uni 	$L__BB17_149;

$L__BB17_152:
	setp.lt.s32 	%p177, %r3, 0;
	mov.u32 	%r244, 0;
	selp.b32 	%r245, %r49, 0, %p10;
	or.b32  	%r246, %r245, 2146435072;
	selp.b32 	%r247, %r246, %r245, %p177;
	mov.b64 	%fd823, {%r244, %r247};
	bra.uni 	$L__BB17_153;

$L__BB17_149:
	setp.gt.s32 	%p175, %r49, -1;
	@%p175 bra 	$L__BB17_153;

	mov.f64 	%fd619, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd620, %fd619;
	setp.eq.f64 	%p176, %fd620, 0d4000000000000000;
	@%p176 bra 	$L__BB17_153;

	mov.f64 	%fd823, 0dFFF8000000000000;

$L__BB17_153:
	add.rn.f64 	%fd622, %fd820, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r248}, %fd622;
	}
	and.b32  	%r249, %r248, 2146435072;
	setp.ne.s32 	%p179, %r249, 2146435072;
	@%p179 bra 	$L__BB17_160;

	setp.gtu.f64 	%p180, %fd178, 0d7FF0000000000000;
	@%p180 bra 	$L__BB17_159;
	bra.uni 	$L__BB17_155;

$L__BB17_159:
	mov.f64 	%fd624, 0d4000000000000000;
	add.rn.f64 	%fd823, %fd820, %fd624;
	bra.uni 	$L__BB17_160;

$L__BB17_155:
	setp.eq.s32 	%p181, %r24, 2146435072;
	mov.f64 	%fd623, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r250, %temp}, %fd623;
	}
	setp.eq.s32 	%p182, %r250, 0;
	and.pred  	%p183, %p181, %p182;
	@%p183 bra 	$L__BB17_158;
	bra.uni 	$L__BB17_156;

$L__BB17_158:
	setp.lt.s32 	%p189, %r3, 0;
	mov.u32 	%r255, 0;
	setp.gt.f64 	%p190, %fd178, 0d3FF0000000000000;
	selp.b32 	%r256, 2146435072, 0, %p190;
	xor.b32  	%r257, %r256, 2146435072;
	selp.b32 	%r258, %r257, %r256, %p189;
	setp.eq.f64 	%p191, %fd820, 0dBFF0000000000000;
	selp.b32 	%r259, 1072693248, %r258, %p191;
	mov.b64 	%fd823, {%r255, %r259};
	bra.uni 	$L__BB17_160;

$L__BB17_156:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r251, %temp}, %fd820;
	}
	and.b32  	%r252, %r49, 2147483647;
	setp.ne.s32 	%p184, %r252, 2146435072;
	setp.ne.s32 	%p185, %r251, 0;
	or.pred  	%p186, %p184, %p185;
	@%p186 bra 	$L__BB17_160;

	setp.ne.s32 	%p187, %r24, 1071644672;
	and.pred  	%p188, %p187, %p7;
	selp.b32 	%r253, %r26, %r25, %p188;
	mov.u32 	%r254, 0;
	mov.b64 	%fd823, {%r254, %r253};

$L__BB17_160:
	setp.eq.f64 	%p192, %fd820, 0d3FF0000000000000;
	selp.f64 	%fd188, 0d3FF0000000000000, %fd823, %p192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd164;
	}
	and.b32  	%r261, %r260, 2147483647;
	setp.eq.s32 	%p193, %r261, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd164;
	}
	setp.eq.s32 	%p194, %r262, 0;
	and.pred  	%p195, %p194, %p193;
	@%p195 bra 	$L__BB17_164;
	bra.uni 	$L__BB17_161;

$L__BB17_164:
	mov.f64 	%fd634, 0d0000000000000000;
	mul.rn.f64 	%fd825, %fd164, %fd634;
	mov.u32 	%r346, 1;
	bra.uni 	$L__BB17_165;

$L__BB17_161:
	mul.rn.f64 	%fd625, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r345, %fd625;
	st.local.u32 	[%rd1], %r345;
	cvt.rn.f64.s32 	%fd626, %r345;
	neg.f64 	%fd627, %fd626;
	mov.f64 	%fd628, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd629, %fd627, %fd628, %fd164;
	mov.f64 	%fd630, 0d3C91A62633145C00;
	fma.rn.f64 	%fd631, %fd627, %fd630, %fd629;
	mov.f64 	%fd632, 0d397B839A252049C0;
	fma.rn.f64 	%fd825, %fd627, %fd632, %fd631;
	abs.f64 	%fd633, %fd164;
	setp.ltu.f64 	%p196, %fd633, 0d41E0000000000000;
	@%p196 bra 	$L__BB17_163;

	{ // callseq 282, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd825, [retval0+0];
	} // callseq 282
	ld.local.u32 	%r345, [%rd1];

$L__BB17_163:
	add.s32 	%r346, %r345, 1;

$L__BB17_165:
	and.b32  	%r264, %r346, 1;
	shl.b32 	%r265, %r346, 3;
	and.b32  	%r266, %r265, 8;
	setp.eq.s32 	%p197, %r264, 0;
	selp.f64 	%fd635, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p197;
	mul.wide.s32 	%rd75, %r266, 8;
	add.s64 	%rd77, %rd40, %rd75;
	ld.global.nc.f64 	%fd636, [%rd77+8];
	mul.rn.f64 	%fd194, %fd825, %fd825;
	fma.rn.f64 	%fd637, %fd635, %fd194, %fd636;
	ld.global.nc.f64 	%fd638, [%rd77+16];
	fma.rn.f64 	%fd639, %fd637, %fd194, %fd638;
	ld.global.nc.f64 	%fd640, [%rd77+24];
	fma.rn.f64 	%fd641, %fd639, %fd194, %fd640;
	ld.global.nc.f64 	%fd642, [%rd77+32];
	fma.rn.f64 	%fd643, %fd641, %fd194, %fd642;
	ld.global.nc.f64 	%fd644, [%rd77+40];
	fma.rn.f64 	%fd645, %fd643, %fd194, %fd644;
	ld.global.nc.f64 	%fd646, [%rd77+48];
	fma.rn.f64 	%fd195, %fd645, %fd194, %fd646;
	fma.rn.f64 	%fd827, %fd195, %fd825, %fd825;
	@%p197 bra 	$L__BB17_167;

	mov.f64 	%fd647, 0d3FF0000000000000;
	fma.rn.f64 	%fd827, %fd195, %fd194, %fd647;

$L__BB17_167:
	and.b32  	%r267, %r346, 2;
	setp.eq.s32 	%p198, %r267, 0;
	@%p198 bra 	$L__BB17_169;

	mov.f64 	%fd648, 0d0000000000000000;
	mov.f64 	%fd649, 0dBFF0000000000000;
	fma.rn.f64 	%fd827, %fd827, %fd649, %fd648;

$L__BB17_169:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r268}, %fd165;
	}
	and.b32  	%r269, %r268, 2147483647;
	setp.eq.s32 	%p199, %r269, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r270, %temp}, %fd165;
	}
	setp.eq.s32 	%p200, %r270, 0;
	and.pred  	%p201, %p200, %p199;
	@%p201 bra 	$L__BB17_173;
	bra.uni 	$L__BB17_170;

$L__BB17_173:
	mov.f64 	%fd659, 0d0000000000000000;
	mul.rn.f64 	%fd829, %fd165, %fd659;
	mov.u32 	%r348, 1;
	bra.uni 	$L__BB17_174;

$L__BB17_170:
	mul.rn.f64 	%fd650, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r347, %fd650;
	st.local.u32 	[%rd1], %r347;
	cvt.rn.f64.s32 	%fd651, %r347;
	neg.f64 	%fd652, %fd651;
	mov.f64 	%fd653, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd654, %fd652, %fd653, %fd165;
	mov.f64 	%fd655, 0d3C91A62633145C00;
	fma.rn.f64 	%fd656, %fd652, %fd655, %fd654;
	mov.f64 	%fd657, 0d397B839A252049C0;
	fma.rn.f64 	%fd829, %fd652, %fd657, %fd656;
	abs.f64 	%fd658, %fd165;
	setp.ltu.f64 	%p202, %fd658, 0d41E0000000000000;
	@%p202 bra 	$L__BB17_172;

	{ // callseq 283, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd829, [retval0+0];
	} // callseq 283
	ld.local.u32 	%r347, [%rd1];

$L__BB17_172:
	add.s32 	%r348, %r347, 1;

$L__BB17_174:
	and.b32  	%r272, %r348, 1;
	shl.b32 	%r273, %r348, 3;
	and.b32  	%r274, %r273, 8;
	setp.eq.s32 	%p203, %r272, 0;
	selp.f64 	%fd660, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p203;
	mul.wide.s32 	%rd79, %r274, 8;
	add.s64 	%rd81, %rd40, %rd79;
	ld.global.nc.f64 	%fd661, [%rd81+8];
	mul.rn.f64 	%fd206, %fd829, %fd829;
	fma.rn.f64 	%fd662, %fd660, %fd206, %fd661;
	ld.global.nc.f64 	%fd663, [%rd81+16];
	fma.rn.f64 	%fd664, %fd662, %fd206, %fd663;
	ld.global.nc.f64 	%fd665, [%rd81+24];
	fma.rn.f64 	%fd666, %fd664, %fd206, %fd665;
	ld.global.nc.f64 	%fd667, [%rd81+32];
	fma.rn.f64 	%fd668, %fd666, %fd206, %fd667;
	ld.global.nc.f64 	%fd669, [%rd81+40];
	fma.rn.f64 	%fd670, %fd668, %fd206, %fd669;
	ld.global.nc.f64 	%fd671, [%rd81+48];
	fma.rn.f64 	%fd207, %fd670, %fd206, %fd671;
	fma.rn.f64 	%fd831, %fd207, %fd829, %fd829;
	@%p203 bra 	$L__BB17_176;

	mov.f64 	%fd672, 0d3FF0000000000000;
	fma.rn.f64 	%fd831, %fd207, %fd206, %fd672;

$L__BB17_176:
	and.b32  	%r275, %r348, 2;
	setp.eq.s32 	%p204, %r275, 0;
	@%p204 bra 	$L__BB17_178;

	mov.f64 	%fd673, 0d0000000000000000;
	mov.f64 	%fd674, 0dBFF0000000000000;
	fma.rn.f64 	%fd831, %fd831, %fd674, %fd673;

$L__BB17_178:
	mul.rn.f64 	%fd213, %fd827, %fd831;
	mul.rn.f64 	%fd675, %fd839, 0d400921FB54442D18;
	div.rn.f64 	%fd676, %fd675, 0d4066800000000000;
	mul.rn.f64 	%fd677, %fd796, 0d400921FB54442D18;
	div.rn.f64 	%fd678, %fd677, 0d4066800000000000;
	sub.rn.f64 	%fd679, %fd678, %fd676;
	mul.rn.f64 	%fd214, %fd679, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r276, %temp}, %fd214;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r277}, %fd214;
	}
	and.b32  	%r278, %r277, 2147483647;
	setp.eq.s32 	%p205, %r278, 2146435072;
	setp.eq.s32 	%p206, %r276, 0;
	and.pred  	%p207, %p206, %p205;
	@%p207 bra 	$L__BB17_181;
	bra.uni 	$L__BB17_179;

$L__BB17_181:
	mov.f64 	%fd689, 0d0000000000000000;
	mul.rn.f64 	%fd832, %fd214, %fd689;
	mov.u32 	%r349, 0;
	bra.uni 	$L__BB17_182;

$L__BB17_179:
	mul.rn.f64 	%fd680, %fd214, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r349, %fd680;
	st.local.u32 	[%rd1], %r349;
	cvt.rn.f64.s32 	%fd681, %r349;
	neg.f64 	%fd682, %fd681;
	mov.f64 	%fd683, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd684, %fd682, %fd683, %fd214;
	mov.f64 	%fd685, 0d3C91A62633145C00;
	fma.rn.f64 	%fd686, %fd682, %fd685, %fd684;
	mov.f64 	%fd687, 0d397B839A252049C0;
	fma.rn.f64 	%fd832, %fd682, %fd687, %fd686;
	abs.f64 	%fd688, %fd214;
	setp.ltu.f64 	%p208, %fd688, 0d41E0000000000000;
	@%p208 bra 	$L__BB17_182;

	{ // callseq 284, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd214;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd19;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 284
	ld.local.u32 	%r349, [%rd1];

$L__BB17_182:
	and.b32  	%r280, %r349, 1;
	shl.b32 	%r281, %r349, 3;
	and.b32  	%r282, %r281, 8;
	setp.eq.s32 	%p209, %r280, 0;
	selp.f64 	%fd690, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p209;
	mul.wide.s32 	%rd83, %r282, 8;
	add.s64 	%rd85, %rd40, %rd83;
	ld.global.nc.f64 	%fd691, [%rd85+8];
	mul.rn.f64 	%fd219, %fd832, %fd832;
	fma.rn.f64 	%fd692, %fd690, %fd219, %fd691;
	ld.global.nc.f64 	%fd693, [%rd85+16];
	fma.rn.f64 	%fd694, %fd692, %fd219, %fd693;
	ld.global.nc.f64 	%fd695, [%rd85+24];
	fma.rn.f64 	%fd696, %fd694, %fd219, %fd695;
	ld.global.nc.f64 	%fd697, [%rd85+32];
	fma.rn.f64 	%fd698, %fd696, %fd219, %fd697;
	ld.global.nc.f64 	%fd699, [%rd85+40];
	fma.rn.f64 	%fd700, %fd698, %fd219, %fd699;
	ld.global.nc.f64 	%fd701, [%rd85+48];
	fma.rn.f64 	%fd220, %fd700, %fd219, %fd701;
	fma.rn.f64 	%fd834, %fd220, %fd832, %fd832;
	@%p209 bra 	$L__BB17_184;

	mov.f64 	%fd702, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd220, %fd219, %fd702;

$L__BB17_184:
	and.b32  	%r283, %r349, 2;
	setp.eq.s32 	%p210, %r283, 0;
	@%p210 bra 	$L__BB17_186;

	mov.f64 	%fd703, 0d0000000000000000;
	mov.f64 	%fd704, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd704, %fd703;

$L__BB17_186:
	abs.f64 	%fd226, %fd834;
	{ // callseq 285, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd226;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd837, [retval0+0];
	} // callseq 285
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd834;
	}
	setp.lt.s32 	%p211, %r63, 0;
	and.pred  	%p8, %p211, %p10;
	not.pred 	%p213, %p8;
	@%p213 bra 	$L__BB17_188;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r284}, %fd837;
	}
	xor.b32  	%r285, %r284, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r286, %temp}, %fd837;
	}
	mov.b64 	%fd837, {%r286, %r285};

$L__BB17_188:
	setp.eq.f64 	%p214, %fd834, 0d0000000000000000;
	@%p214 bra 	$L__BB17_192;
	bra.uni 	$L__BB17_189;

$L__BB17_192:
	setp.lt.s32 	%p217, %r3, 0;
	mov.u32 	%r287, 0;
	selp.b32 	%r288, %r63, 0, %p10;
	or.b32  	%r289, %r288, 2146435072;
	selp.b32 	%r290, %r289, %r288, %p217;
	mov.b64 	%fd837, {%r287, %r290};
	bra.uni 	$L__BB17_193;

$L__BB17_189:
	setp.gt.s32 	%p215, %r63, -1;
	@%p215 bra 	$L__BB17_193;

	mov.f64 	%fd705, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd706, %fd705;
	setp.eq.f64 	%p216, %fd706, 0d4000000000000000;
	@%p216 bra 	$L__BB17_193;

	mov.f64 	%fd837, 0dFFF8000000000000;

$L__BB17_193:
	add.rn.f64 	%fd708, %fd834, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd708;
	}
	and.b32  	%r292, %r291, 2146435072;
	setp.ne.s32 	%p219, %r292, 2146435072;
	@%p219 bra 	$L__BB17_200;

	setp.gtu.f64 	%p220, %fd226, 0d7FF0000000000000;
	@%p220 bra 	$L__BB17_199;
	bra.uni 	$L__BB17_195;

$L__BB17_199:
	mov.f64 	%fd710, 0d4000000000000000;
	add.rn.f64 	%fd837, %fd834, %fd710;
	bra.uni 	$L__BB17_200;

$L__BB17_195:
	setp.eq.s32 	%p221, %r24, 2146435072;
	mov.f64 	%fd709, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r293, %temp}, %fd709;
	}
	setp.eq.s32 	%p222, %r293, 0;
	and.pred  	%p223, %p221, %p222;
	@%p223 bra 	$L__BB17_198;
	bra.uni 	$L__BB17_196;

$L__BB17_198:
	setp.lt.s32 	%p229, %r3, 0;
	mov.u32 	%r298, 0;
	setp.gt.f64 	%p230, %fd226, 0d3FF0000000000000;
	selp.b32 	%r299, 2146435072, 0, %p230;
	xor.b32  	%r300, %r299, 2146435072;
	selp.b32 	%r301, %r300, %r299, %p229;
	setp.eq.f64 	%p231, %fd834, 0dBFF0000000000000;
	selp.b32 	%r302, 1072693248, %r301, %p231;
	mov.b64 	%fd837, {%r298, %r302};
	bra.uni 	$L__BB17_200;

$L__BB17_196:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r294, %temp}, %fd834;
	}
	and.b32  	%r295, %r63, 2147483647;
	setp.ne.s32 	%p224, %r295, 2146435072;
	setp.ne.s32 	%p225, %r294, 0;
	or.pred  	%p226, %p224, %p225;
	@%p226 bra 	$L__BB17_200;

	setp.ne.s32 	%p227, %r24, 1071644672;
	and.pred  	%p228, %p227, %p8;
	selp.b32 	%r296, %r26, %r25, %p228;
	mov.u32 	%r297, 0;
	mov.b64 	%fd837, {%r297, %r296};

$L__BB17_200:
	setp.eq.f64 	%p232, %fd834, 0d3FF0000000000000;
	mov.f64 	%fd711, 0d3FF0000000000000;
	selp.f64 	%fd712, 0d3FF0000000000000, %fd837, %p232;
	mul.rn.f64 	%fd713, %fd213, %fd712;
	add.rn.f64 	%fd714, %fd188, %fd713;
	sqrt.rn.f64 	%fd236, %fd714;
	sub.rn.f64 	%fd715, %fd711, %fd714;
	sqrt.rn.f64 	%fd237, %fd715;
	abs.f64 	%fd238, %fd237;
	abs.f64 	%fd239, %fd236;
	setp.eq.f64 	%p233, %fd238, 0d0000000000000000;
	setp.eq.f64 	%p234, %fd239, 0d0000000000000000;
	and.pred  	%p235, %p233, %p234;
	@%p235 bra 	$L__BB17_204;
	bra.uni 	$L__BB17_201;

$L__BB17_204:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r315}, %fd237;
	}
	setp.lt.s32 	%p243, %r315, 0;
	selp.f64 	%fd768, 0d400921FB54442D18, 0d0000000000000000, %p243;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r316, %temp}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r318}, %fd236;
	}
	and.b32  	%r319, %r318, -2147483648;
	or.b32  	%r320, %r317, %r319;
	mov.b64 	%fd838, {%r316, %r320};
	bra.uni 	$L__BB17_205;

$L__BB17_201:
	setp.eq.f64 	%p236, %fd238, 0d7FF0000000000000;
	setp.eq.f64 	%p237, %fd239, 0d7FF0000000000000;
	and.pred  	%p238, %p236, %p237;
	@%p238 bra 	$L__BB17_203;
	bra.uni 	$L__BB17_202;

$L__BB17_203:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r309}, %fd237;
	}
	setp.lt.s32 	%p242, %r309, 0;
	selp.f64 	%fd767, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r310, %temp}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r311}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r312}, %fd236;
	}
	and.b32  	%r313, %r312, -2147483648;
	or.b32  	%r314, %r311, %r313;
	mov.b64 	%fd838, {%r310, %r314};
	bra.uni 	$L__BB17_205;

$L__BB17_202:
	max.f64 	%fd716, %fd239, %fd238;
	min.f64 	%fd717, %fd239, %fd238;
	div.rn.f64 	%fd718, %fd717, %fd716;
	mul.rn.f64 	%fd719, %fd718, %fd718;
	mov.f64 	%fd720, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd721, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd722, %fd721, %fd719, %fd720;
	mov.f64 	%fd723, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd724, %fd722, %fd719, %fd723;
	mov.f64 	%fd725, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd726, %fd724, %fd719, %fd725;
	mov.f64 	%fd727, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd728, %fd726, %fd719, %fd727;
	mov.f64 	%fd729, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd730, %fd728, %fd719, %fd729;
	mov.f64 	%fd731, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd732, %fd730, %fd719, %fd731;
	mov.f64 	%fd733, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd734, %fd732, %fd719, %fd733;
	mov.f64 	%fd735, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd736, %fd734, %fd719, %fd735;
	mov.f64 	%fd737, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd738, %fd736, %fd719, %fd737;
	mov.f64 	%fd739, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd740, %fd738, %fd719, %fd739;
	mov.f64 	%fd741, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd742, %fd740, %fd719, %fd741;
	mov.f64 	%fd743, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd744, %fd742, %fd719, %fd743;
	mov.f64 	%fd745, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd746, %fd744, %fd719, %fd745;
	mov.f64 	%fd747, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd748, %fd746, %fd719, %fd747;
	mov.f64 	%fd749, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd750, %fd748, %fd719, %fd749;
	mov.f64 	%fd751, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd752, %fd750, %fd719, %fd751;
	mov.f64 	%fd753, 0d3FC99999999840D2;
	fma.rn.f64 	%fd754, %fd752, %fd719, %fd753;
	mov.f64 	%fd755, 0dBFD555555555544C;
	fma.rn.f64 	%fd756, %fd754, %fd719, %fd755;
	mul.rn.f64 	%fd757, %fd719, %fd756;
	fma.rn.f64 	%fd758, %fd757, %fd718, %fd718;
	mov.f64 	%fd759, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd760, %fd759, %fd758;
	setp.gt.f64 	%p239, %fd239, %fd238;
	selp.f64 	%fd761, %fd760, %fd758, %p239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r303}, %fd237;
	}
	setp.lt.s32 	%p240, %r303, 0;
	mov.f64 	%fd762, 0d400921FB54442D18;
	sub.rn.f64 	%fd763, %fd762, %fd761;
	selp.f64 	%fd764, %fd763, %fd761, %p240;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r304, %temp}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r305}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r306}, %fd236;
	}
	and.b32  	%r307, %r306, -2147483648;
	or.b32  	%r308, %r305, %r307;
	mov.b64 	%fd765, {%r304, %r308};
	add.rn.f64 	%fd766, %fd238, %fd239;
	setp.le.f64 	%p241, %fd766, 0d7FF0000000000000;
	selp.f64 	%fd838, %fd765, %fd766, %p241;

$L__BB17_205:
	add.rn.f64 	%fd769, %fd838, %fd838;
	mul.rn.f64 	%fd770, %fd769, 0d415854A640000000;
	setp.lt.f64 	%p244, %fd770, %fd246;
	@%p244 bra 	$L__BB17_209;

$L__BB17_208:
	ld.param.u32 	%r325, [bd09_to_gcj02_exact_cuda_double_param_5];
	add.s32 	%r337, %r337, 1;
	setp.lt.s32 	%p247, %r337, %r325;
	mov.f64 	%fd839, %fd796;
	mov.f64 	%fd840, %fd795;
	@%p247 bra 	$L__BB17_70;

$L__BB17_209:
	ld.param.u64 	%rd93, [bd09_to_gcj02_exact_cuda_double_param_7];
	mov.u32 	%r329, %tid.x;
	mov.u32 	%r328, %ntid.x;
	mov.u32 	%r327, %ctaid.x;
	mad.lo.s32 	%r326, %r327, %r328, %r329;
	mul.wide.s32 	%rd92, %r326, 8;
	cvta.to.global.u64 	%rd91, %rd93;
	add.s64 	%rd90, %rd91, %rd92;
	ld.param.u64 	%rd89, [bd09_to_gcj02_exact_cuda_double_param_6];
	mov.u32 	%r324, %tid.x;
	mov.u32 	%r323, %ntid.x;
	mov.u32 	%r322, %ctaid.x;
	mad.lo.s32 	%r321, %r322, %r323, %r324;
	mul.wide.s32 	%rd88, %r321, 8;
	cvta.to.global.u64 	%rd87, %rd89;
	add.s64 	%rd86, %rd87, %rd88;
	st.global.f64 	[%rd86], %fd839;
	st.global.f64 	[%rd90], %fd840;

$L__BB17_210:
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot18[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot18;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB18_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r12, %r11, %r10;
	mov.u32 	%r13, 15;
	sub.s32 	%r4, %r13, %r10;
	mov.u32 	%r14, 19;
	sub.s32 	%r15, %r14, %r10;
	setp.gt.s32 	%p2, %r12, 14;
	selp.b32 	%r5, 18, %r15, %p2;
	setp.gt.s32 	%p3, %r12, %r5;
	mov.u64 	%rd76, 0;
	mov.u32 	%r31, %r4;
	@%p3 bra 	$L__BB18_4;

	mul.wide.s32 	%rd22, %r4, 8;
	mov.u64 	%rd23, __cudart_i2opi_d;
	add.s64 	%rd74, %rd23, %rd22;
	mov.b64 	%rd24, %fd4;
	shl.b64 	%rd25, %rd24, 11;
	or.b64  	%rd3, %rd25, -9223372036854775808;
	mov.u64 	%rd76, 0;
	mov.u64 	%rd73, %rd1;
	mov.u32 	%r31, %r4;

$L__BB18_3:
	.pragma "nounroll";
	ld.global.nc.u64 	%rd26, [%rd74];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd26;
	mov.b64 	{%blo,%bhi}, %rd3;
	mov.b64 	{%clo,%chi}, %rd76;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd27, {%r0,%r1};
	mov.b64 	%rd76, {%r2,%r3};
	}
	st.local.u64 	[%rd73], %rd27;
	add.s64 	%rd74, %rd74, 8;
	add.s64 	%rd73, %rd73, 8;
	add.s32 	%r31, %r31, 1;
	setp.lt.s32 	%p4, %r31, %r5;
	@%p4 bra 	$L__BB18_3;

$L__BB18_4:
	sub.s32 	%r16, %r31, %r4;
	mul.wide.s32 	%rd28, %r16, 8;
	add.s64 	%rd29, %rd1, %rd28;
	st.local.u64 	[%rd29], %rd76;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB18_6;

	mov.u32 	%r17, 64;
	sub.s32 	%r18, %r17, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r18;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r18;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB18_6:
	and.b32  	%r19, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r20, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r21, %rd39;
	and.b32  	%r22, %r21, 1;
	add.s32 	%r23, %r22, %r20;
	neg.s32 	%r24, %r23;
	setp.eq.s32 	%p6, %r19, 0;
	selp.b32 	%r25, %r23, %r24, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r25;
	setp.eq.s32 	%p7, %r22, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r26, %r19, -2147483648;
	selp.b32 	%r27, %r19, %r26, %p7;
	clz.b64 	%r28, %rd45;
	cvt.u64.u32 	%rd47, %r28;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r28;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r29, %rd50;
	shr.u64 	%rd51, %rd46, %r29;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r27;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB18_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}
.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<139>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32 	%p1, %r51, 0;
	@%p1 bra 	$L__BB19_2;

	mul.rn.f64 	%fd13, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd13;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd13;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

$L__BB19_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd136, {%r49, %r18};
	setp.lt.u32 	%p2, %r18, 1073127583;
	@%p2 bra 	$L__BB19_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd136;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd136;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd136, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

$L__BB19_4:
	add.rn.f64 	%fd14, %fd136, 0d3FF0000000000000;
	mov.f64 	%fd15, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd16, %fd14;
	neg.f64 	%fd17, %fd14;
	fma.rn.f64 	%fd18, %fd17, %fd16, %fd15;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd16, %fd16;
	add.rn.f64 	%fd21, %fd136, 0dBFF0000000000000;
	mul.rn.f64 	%fd22, %fd21, %fd20;
	add.rn.f64 	%fd23, %fd22, %fd22;
	mul.rn.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd26, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F6249249242B910;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F89999999999DFB;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mul.rn.f64 	%fd38, %fd24, %fd37;
	sub.rn.f64 	%fd39, %fd21, %fd23;
	add.rn.f64 	%fd40, %fd39, %fd39;
	mov.f64 	%fd41, 0d4000000000000000;
	neg.f64 	%fd42, %fd23;
	fma.rn.f64 	%fd43, %fd42, %fd21, %fd40;
	mul.rn.f64 	%fd44, %fd20, %fd43;
	add.rn.f64 	%fd45, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd46, 0d3FB5555555555555;
	sub.rn.f64 	%fd47, %fd46, %fd45;
	add.rn.f64 	%fd48, %fd38, %fd47;
	add.rn.f64 	%fd49, %fd48, 0d0000000000000000;
	add.rn.f64 	%fd50, %fd49, 0dBC46A4CB00B9E7B0;
	add.rn.f64 	%fd51, %fd45, %fd50;
	sub.rn.f64 	%fd52, %fd45, %fd51;
	add.rn.f64 	%fd53, %fd50, %fd52;
	mul.rn.f64 	%fd54, %fd23, %fd23;
	neg.f64 	%fd55, %fd54;
	fma.rn.f64 	%fd56, %fd23, %fd23, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd44;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd57, {%r22, %r24};
	fma.rn.f64 	%fd58, %fd23, %fd57, %fd56;
	mul.rn.f64 	%fd59, %fd54, %fd23;
	neg.f64 	%fd60, %fd59;
	fma.rn.f64 	%fd61, %fd54, %fd23, %fd60;
	fma.rn.f64 	%fd62, %fd54, %fd44, %fd61;
	fma.rn.f64 	%fd63, %fd58, %fd23, %fd62;
	mul.rn.f64 	%fd64, %fd51, %fd59;
	neg.f64 	%fd65, %fd64;
	fma.rn.f64 	%fd66, %fd51, %fd59, %fd65;
	fma.rn.f64 	%fd67, %fd51, %fd63, %fd66;
	fma.rn.f64 	%fd68, %fd53, %fd59, %fd67;
	add.rn.f64 	%fd69, %fd64, %fd68;
	sub.rn.f64 	%fd70, %fd64, %fd69;
	add.rn.f64 	%fd71, %fd68, %fd70;
	add.rn.f64 	%fd72, %fd23, %fd69;
	sub.rn.f64 	%fd73, %fd23, %fd72;
	add.rn.f64 	%fd74, %fd69, %fd73;
	add.rn.f64 	%fd75, %fd71, %fd74;
	add.rn.f64 	%fd76, %fd44, %fd75;
	add.rn.f64 	%fd77, %fd72, %fd76;
	sub.rn.f64 	%fd78, %fd72, %fd77;
	add.rn.f64 	%fd79, %fd76, %fd78;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, -2147483648;
	mov.u32 	%r27, 1127219200;
	mov.b64 	%fd80, {%r25, %r27};
	mov.b64 	%fd81, {%r26, %r27};
	sub.rn.f64 	%fd82, %fd80, %fd81;
	mov.f64 	%fd83, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd84, %fd82, %fd83, %fd77;
	neg.f64 	%fd85, %fd82;
	fma.rn.f64 	%fd86, %fd85, %fd83, %fd84;
	sub.rn.f64 	%fd87, %fd86, %fd77;
	sub.rn.f64 	%fd88, %fd79, %fd87;
	mov.f64 	%fd89, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd90, %fd82, %fd89, %fd88;
	add.rn.f64 	%fd91, %fd84, %fd90;
	sub.rn.f64 	%fd92, %fd84, %fd91;
	add.rn.f64 	%fd93, %fd90, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd41;
	}
	shl.b32 	%r29, %r28, 1;
	setp.gt.u32 	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32 	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd41;
	}
	mov.b64 	%fd94, {%r32, %r31};
	mul.rn.f64 	%fd95, %fd91, %fd94;
	neg.f64 	%fd96, %fd95;
	fma.rn.f64 	%fd97, %fd91, %fd94, %fd96;
	fma.rn.f64 	%fd98, %fd93, %fd94, %fd97;
	add.rn.f64 	%fd4, %fd95, %fd98;
	sub.rn.f64 	%fd99, %fd95, %fd4;
	add.rn.f64 	%fd5, %fd98, %fd99;
	mov.f64 	%fd100, 0d4338000000000000;
	mov.f64 	%fd101, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd102, %fd4, %fd101, %fd100;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd102;
	}
	mov.f64 	%fd103, 0dC338000000000000;
	add.rn.f64 	%fd104, %fd102, %fd103;
	mov.f64 	%fd105, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd106, %fd104, %fd105, %fd4;
	mov.f64 	%fd107, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd108, %fd104, %fd107, %fd106;
	mov.f64 	%fd109, 0d3E928AF3FCA213EA;
	mov.f64 	%fd110, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd111, %fd110, %fd108, %fd109;
	mov.f64 	%fd112, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd113, %fd111, %fd108, %fd112;
	mov.f64 	%fd114, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd115, %fd113, %fd108, %fd114;
	mov.f64 	%fd116, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd117, %fd115, %fd108, %fd116;
	mov.f64 	%fd118, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd119, %fd117, %fd108, %fd118;
	mov.f64 	%fd120, 0d3F81111111122322;
	fma.rn.f64 	%fd121, %fd119, %fd108, %fd120;
	mov.f64 	%fd122, 0d3FA55555555502A1;
	fma.rn.f64 	%fd123, %fd121, %fd108, %fd122;
	mov.f64 	%fd124, 0d3FC5555555555511;
	fma.rn.f64 	%fd125, %fd123, %fd108, %fd124;
	mov.f64 	%fd126, 0d3FE000000000000B;
	fma.rn.f64 	%fd127, %fd125, %fd108, %fd126;
	fma.rn.f64 	%fd128, %fd127, %fd108, %fd15;
	fma.rn.f64 	%fd129, %fd128, %fd108, %fd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd129;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd129;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd137, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	%f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p4, %f1, 0f4086232B;
	@%p4 bra 	$L__BB19_7;

	setp.lt.f64 	%p5, %fd4, 0d0000000000000000;
	add.rn.f64 	%fd130, %fd4, 0d7FF0000000000000;
	selp.f64 	%fd137, 0d0000000000000000, %fd130, %p5;
	setp.geu.f32 	%p6, %f1, 0f40874800;
	@%p6 bra 	$L__BB19_7;

	mov.f64 	%fd135, 0d4338000000000000;
	mov.f64 	%fd134, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd133, %fd4, %fd134, %fd135;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd133;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r15, %r39;
	mov.b64 	%fd131, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd132, {%r44, %r43};
	mul.rn.f64 	%fd137, %fd131, %fd132;

$L__BB19_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd137;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.eq.s32 	%p7, %r46, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd137;
	}
	setp.eq.s32 	%p8, %r47, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB19_9;

	fma.rn.f64 	%fd137, %fd137, %fd5, %fd137;

$L__BB19_9:
	st.param.f64 	[func_retval0+0], %fd137;
	ret;

}

