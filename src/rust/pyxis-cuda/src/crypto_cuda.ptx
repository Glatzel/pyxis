//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35404655
// Cuda compilation tools, release 12.8, V12.8.61
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_52
.address_size 64

	// .globl	bd09_to_gcj02_cuda
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0
)
;
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry bd09_to_gcj02_cuda(
	.param .u64 bd09_to_gcj02_cuda_param_0,
	.param .u64 bd09_to_gcj02_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot0[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<81>;
	.reg .b32 	%r<124>;
	.reg .f64 	%fd<275>;
	.reg .b64 	%rd<46>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [bd09_to_gcj02_cuda_param_0];
	ld.param.u64 	%rd8, [bd09_to_gcj02_cuda_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r26, %r24, %r23, %r25;
	cvta.to.global.u64 	%rd14, %rd7;
	mul.wide.s32 	%rd15, %r26, 8;
	add.s64 	%rd5, %rd14, %rd15;
	add.s64 	%rd6, %rd9, %rd15;
	ld.global.f64 	%fd78, [%rd5];
	add.rn.f64 	%fd1, %fd78, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd79, [%rd6];
	add.rn.f64 	%fd2, %fd79, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd80;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p4, %r3, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd256, [retval0+0];
	} // callseq 0
	setp.lt.s32 	%p5, %r1, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB0_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd256;
	}
	xor.b32  	%r28, %r27, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd256;
	}
	mov.b64 	%fd256, {%r29, %r28};

$L__BB0_2:
	setp.eq.f64 	%p7, %fd1, 0d0000000000000000;
	@%p7 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_3;

$L__BB0_6:
	selp.b32 	%r30, %r1, 0, %p4;
	mov.u32 	%r31, 0;
	or.b32  	%r32, %r30, 2146435072;
	setp.lt.s32 	%p11, %r2, 0;
	selp.b32 	%r33, %r32, %r30, %p11;
	mov.b64 	%fd256, {%r31, %r33};
	bra.uni 	$L__BB0_7;

$L__BB0_3:
	setp.gt.s32 	%p8, %r1, -1;
	@%p8 bra 	$L__BB0_7;

	mov.f64 	%fd81, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd82, %fd81;
	setp.eq.f64 	%p9, %fd82, 0d4000000000000000;
	@%p9 bra 	$L__BB0_7;

	mov.f64 	%fd256, 0dFFF8000000000000;

$L__BB0_7:
	add.rn.f64 	%fd84, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd84;
	}
	and.b32  	%r35, %r34, 2146435072;
	setp.ne.s32 	%p12, %r35, 2146435072;
	@%p12 bra 	$L__BB0_14;

	setp.gtu.f64 	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_9;

$L__BB0_13:
	mov.f64 	%fd86, 0d4000000000000000;
	add.rn.f64 	%fd256, %fd1, %fd86;
	bra.uni 	$L__BB0_14;

$L__BB0_9:
	mov.f64 	%fd85, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd85;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p14, %r4, 2146435072;
	setp.eq.s32 	%p15, %r36, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_10;

$L__BB0_12:
	setp.gt.f64 	%p23, %fd3, 0d3FF0000000000000;
	selp.b32 	%r43, 2146435072, 0, %p23;
	mov.u32 	%r44, 0;
	xor.b32  	%r45, %r43, 2146435072;
	setp.lt.s32 	%p24, %r2, 0;
	selp.b32 	%r46, %r45, %r43, %p24;
	setp.eq.f64 	%p25, %fd1, 0dBFF0000000000000;
	selp.b32 	%r47, 1072693248, %r46, %p25;
	mov.b64 	%fd256, {%r44, %r47};
	bra.uni 	$L__BB0_14;

$L__BB0_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd1;
	}
	and.b32  	%r38, %r1, 2147483647;
	setp.ne.s32 	%p17, %r38, 2146435072;
	setp.ne.s32 	%p18, %r37, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB0_14;

	setp.gt.s32 	%p20, %r2, -1;
	selp.b32 	%r39, 2146435072, 0, %p20;
	mov.u32 	%r40, 0;
	setp.ne.s32 	%p21, %r4, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r41, %r39, -2147483648;
	selp.b32 	%r42, %r41, %r39, %p22;
	mov.b64 	%fd256, {%r40, %r42};

$L__BB0_14:
	abs.f64 	%fd13, %fd2;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 1
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd2;
	}
	setp.lt.s32 	%p26, %r5, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB0_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd259;
	}
	xor.b32  	%r49, %r48, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd259;
	}
	mov.b64 	%fd259, {%r50, %r49};

$L__BB0_16:
	setp.eq.f64 	%p29, %fd2, 0d0000000000000000;
	@%p29 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_17;

$L__BB0_20:
	selp.b32 	%r51, %r5, 0, %p4;
	mov.u32 	%r52, 0;
	or.b32  	%r53, %r51, 2146435072;
	setp.lt.s32 	%p33, %r2, 0;
	selp.b32 	%r54, %r53, %r51, %p33;
	mov.b64 	%fd259, {%r52, %r54};
	bra.uni 	$L__BB0_21;

$L__BB0_17:
	setp.gt.s32 	%p30, %r5, -1;
	@%p30 bra 	$L__BB0_21;

	mov.f64 	%fd87, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd88, %fd87;
	setp.eq.f64 	%p31, %fd88, 0d4000000000000000;
	@%p31 bra 	$L__BB0_21;

	mov.f64 	%fd259, 0dFFF8000000000000;

$L__BB0_21:
	add.rn.f64 	%fd90, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd90;
	}
	and.b32  	%r56, %r55, 2146435072;
	setp.ne.s32 	%p34, %r56, 2146435072;
	@%p34 bra 	$L__BB0_28;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_23;

$L__BB0_27:
	mov.f64 	%fd92, 0d4000000000000000;
	add.rn.f64 	%fd259, %fd2, %fd92;
	bra.uni 	$L__BB0_28;

$L__BB0_23:
	mov.f64 	%fd91, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd91;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p36, %r6, 2146435072;
	setp.eq.s32 	%p37, %r57, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_24;

$L__BB0_26:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r64, 2146435072, 0, %p45;
	mov.u32 	%r65, 0;
	xor.b32  	%r66, %r64, 2146435072;
	setp.lt.s32 	%p46, %r2, 0;
	selp.b32 	%r67, %r66, %r64, %p46;
	setp.eq.f64 	%p47, %fd2, 0dBFF0000000000000;
	selp.b32 	%r68, 1072693248, %r67, %p47;
	mov.b64 	%fd259, {%r65, %r68};
	bra.uni 	$L__BB0_28;

$L__BB0_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd2;
	}
	and.b32  	%r59, %r5, 2147483647;
	setp.ne.s32 	%p39, %r59, 2146435072;
	setp.ne.s32 	%p40, %r58, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB0_28;

	setp.gt.s32 	%p42, %r2, -1;
	selp.b32 	%r60, 2146435072, 0, %p42;
	mov.u32 	%r61, 0;
	setp.ne.s32 	%p43, %r6, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r62, %r60, -2147483648;
	selp.b32 	%r63, %r62, %r60, %p44;
	mov.b64 	%fd259, {%r61, %r63};

$L__BB0_28:
	setp.eq.f64 	%p48, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd93, 0d3FF0000000000000, %fd259, %p48;
	setp.eq.f64 	%p49, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd94, 0d3FF0000000000000, %fd256, %p49;
	add.rn.f64 	%fd23, %fd94, %fd93;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd24;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p50, %r71, 2146435072;
	setp.eq.s32 	%p51, %r69, 0;
	and.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB0_31;
	bra.uni 	$L__BB0_29;

$L__BB0_31:
	mov.f64 	%fd104, 0d0000000000000000;
	mul.rn.f64 	%fd260, %fd24, %fd104;
	mov.u32 	%r118, 0;
	bra.uni 	$L__BB0_32;

$L__BB0_29:
	mul.rn.f64 	%fd95, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd95;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd96, %r118;
	neg.f64 	%fd97, %fd96;
	mov.f64 	%fd98, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd99, %fd97, %fd98, %fd24;
	mov.f64 	%fd100, 0d3C91A62633145C00;
	fma.rn.f64 	%fd101, %fd97, %fd100, %fd99;
	mov.f64 	%fd102, 0d397B839A252049C0;
	fma.rn.f64 	%fd260, %fd97, %fd102, %fd101;
	abs.f64 	%fd103, %fd24;
	setp.ltu.f64 	%p53, %fd103, 0d41E0000000000000;
	@%p53 bra 	$L__BB0_32;

	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd260, [retval0+0];
	} // callseq 2
	ld.local.u32 	%r118, [%rd1];

$L__BB0_32:
	and.b32  	%r73, %r118, 1;
	shl.b32 	%r74, %r118, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p54, %r73, 0;
	selp.f64 	%fd105, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	mul.wide.s32 	%rd17, %r75, 8;
	mov.u64 	%rd18, __cudart_sin_cos_coeffs;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.nc.f64 	%fd106, [%rd19+8];
	mul.rn.f64 	%fd29, %fd260, %fd260;
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd19+16];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd19+24];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd19+32];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd19+40];
	fma.rn.f64 	%fd115, %fd113, %fd29, %fd114;
	ld.global.nc.f64 	%fd116, [%rd19+48];
	fma.rn.f64 	%fd30, %fd115, %fd29, %fd116;
	fma.rn.f64 	%fd262, %fd30, %fd260, %fd260;
	@%p54 bra 	$L__BB0_34;

	mov.f64 	%fd117, 0d3FF0000000000000;
	fma.rn.f64 	%fd262, %fd30, %fd29, %fd117;

$L__BB0_34:
	and.b32  	%r76, %r118, 2;
	setp.eq.s32 	%p55, %r76, 0;
	@%p55 bra 	$L__BB0_36;

	mov.f64 	%fd118, 0d0000000000000000;
	mov.f64 	%fd119, 0dBFF0000000000000;
	fma.rn.f64 	%fd262, %fd262, %fd119, %fd118;

$L__BB0_36:
	mul.rn.f64 	%fd120, %fd262, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd121, %fd23;
	add.rn.f64 	%fd36, %fd121, %fd120;
	setp.eq.f64 	%p56, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p57, %fd3, 0d0000000000000000;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB0_40;
	bra.uni 	$L__BB0_37;

$L__BB0_40:
	selp.f64 	%fd174, 0d400921FB54442D18, 0d0000000000000000, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd174;
	}
	and.b32  	%r87, %r5, -2147483648;
	or.b32  	%r88, %r86, %r87;
	mov.b64 	%fd263, {%r85, %r88};
	bra.uni 	$L__BB0_41;

$L__BB0_37:
	setp.eq.f64 	%p59, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p60, %fd13, 0d7FF0000000000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB0_39;
	bra.uni 	$L__BB0_38;

$L__BB0_39:
	selp.f64 	%fd173, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd173;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd173;
	}
	and.b32  	%r83, %r5, -2147483648;
	or.b32  	%r84, %r82, %r83;
	mov.b64 	%fd263, {%r81, %r84};
	bra.uni 	$L__BB0_41;

$L__BB0_38:
	min.f64 	%fd122, %fd13, %fd3;
	max.f64 	%fd123, %fd13, %fd3;
	div.rn.f64 	%fd124, %fd122, %fd123;
	mul.rn.f64 	%fd125, %fd124, %fd124;
	mov.f64 	%fd126, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd127, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd128, %fd127, %fd125, %fd126;
	mov.f64 	%fd129, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd130, %fd128, %fd125, %fd129;
	mov.f64 	%fd131, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd132, %fd130, %fd125, %fd131;
	mov.f64 	%fd133, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd134, %fd132, %fd125, %fd133;
	mov.f64 	%fd135, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd136, %fd134, %fd125, %fd135;
	mov.f64 	%fd137, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd138, %fd136, %fd125, %fd137;
	mov.f64 	%fd139, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd140, %fd138, %fd125, %fd139;
	mov.f64 	%fd141, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd142, %fd140, %fd125, %fd141;
	mov.f64 	%fd143, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd144, %fd142, %fd125, %fd143;
	mov.f64 	%fd145, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd146, %fd144, %fd125, %fd145;
	mov.f64 	%fd147, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd148, %fd146, %fd125, %fd147;
	mov.f64 	%fd149, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd150, %fd148, %fd125, %fd149;
	mov.f64 	%fd151, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd152, %fd150, %fd125, %fd151;
	mov.f64 	%fd153, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd154, %fd152, %fd125, %fd153;
	mov.f64 	%fd155, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd156, %fd154, %fd125, %fd155;
	mov.f64 	%fd157, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd158, %fd156, %fd125, %fd157;
	mov.f64 	%fd159, 0d3FC99999999840D2;
	fma.rn.f64 	%fd160, %fd158, %fd125, %fd159;
	mov.f64 	%fd161, 0dBFD555555555544C;
	fma.rn.f64 	%fd162, %fd160, %fd125, %fd161;
	mul.rn.f64 	%fd163, %fd125, %fd162;
	fma.rn.f64 	%fd164, %fd163, %fd124, %fd124;
	mov.f64 	%fd165, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd166, %fd165, %fd164;
	setp.gt.f64 	%p63, %fd13, %fd3;
	selp.f64 	%fd167, %fd166, %fd164, %p63;
	mov.f64 	%fd168, 0d400921FB54442D18;
	sub.rn.f64 	%fd169, %fd168, %fd167;
	selp.f64 	%fd170, %fd169, %fd167, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd170;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd170;
	}
	and.b32  	%r79, %r5, -2147483648;
	or.b32  	%r80, %r78, %r79;
	mov.b64 	%fd171, {%r77, %r80};
	add.rn.f64 	%fd172, %fd3, %fd13;
	setp.le.f64 	%p64, %fd172, 0d7FF0000000000000;
	selp.f64 	%fd263, %fd171, %fd172, %p64;

$L__BB0_41:
	add.rn.f64 	%fd253, %fd78, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd253, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd41;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p67, %r91, 2146435072;
	setp.eq.s32 	%p68, %r89, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB0_45;
	bra.uni 	$L__BB0_42;

$L__BB0_45:
	mov.f64 	%fd184, 0d0000000000000000;
	mul.rn.f64 	%fd265, %fd41, %fd184;
	mov.u32 	%r120, 1;
	bra.uni 	$L__BB0_46;

$L__BB0_42:
	mul.rn.f64 	%fd175, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r119, %fd175;
	st.local.u32 	[%rd1], %r119;
	cvt.rn.f64.s32 	%fd176, %r119;
	neg.f64 	%fd177, %fd176;
	mov.f64 	%fd178, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd179, %fd177, %fd178, %fd41;
	mov.f64 	%fd180, 0d3C91A62633145C00;
	fma.rn.f64 	%fd181, %fd177, %fd180, %fd179;
	mov.f64 	%fd182, 0d397B839A252049C0;
	fma.rn.f64 	%fd265, %fd177, %fd182, %fd181;
	abs.f64 	%fd183, %fd41;
	setp.ltu.f64 	%p70, %fd183, 0d41E0000000000000;
	@%p70 bra 	$L__BB0_44;

	add.u64 	%rd40, %SP, 0;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd265, [retval0+0];
	} // callseq 3
	ld.local.u32 	%r119, [%rd1];

$L__BB0_44:
	add.s32 	%r120, %r119, 1;

$L__BB0_46:
	mov.u64 	%rd41, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r120, 1;
	shl.b32 	%r94, %r120, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p71, %r93, 0;
	selp.f64 	%fd185, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd21, %r95, 8;
	add.s64 	%rd23, %rd41, %rd21;
	ld.global.nc.f64 	%fd186, [%rd23+8];
	mul.rn.f64 	%fd47, %fd265, %fd265;
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd23+16];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd23+24];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd23+32];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd23+40];
	fma.rn.f64 	%fd195, %fd193, %fd47, %fd194;
	ld.global.nc.f64 	%fd196, [%rd23+48];
	fma.rn.f64 	%fd48, %fd195, %fd47, %fd196;
	fma.rn.f64 	%fd267, %fd48, %fd265, %fd265;
	@%p71 bra 	$L__BB0_48;

	mov.f64 	%fd197, 0d3FF0000000000000;
	fma.rn.f64 	%fd267, %fd48, %fd47, %fd197;

$L__BB0_48:
	and.b32  	%r96, %r120, 2;
	setp.eq.s32 	%p72, %r96, 0;
	@%p72 bra 	$L__BB0_50;

	mov.f64 	%fd198, 0d0000000000000000;
	mov.f64 	%fd199, 0dBFF0000000000000;
	fma.rn.f64 	%fd267, %fd267, %fd199, %fd198;

$L__BB0_50:
	mul.rn.f64 	%fd200, %fd267, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd263, %fd200;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd54;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p73, %r99, 2146435072;
	setp.eq.s32 	%p74, %r97, 0;
	and.pred  	%p3, %p74, %p73;
	@%p3 bra 	$L__BB0_54;
	bra.uni 	$L__BB0_51;

$L__BB0_54:
	mov.f64 	%fd210, 0d0000000000000000;
	mul.rn.f64 	%fd269, %fd54, %fd210;
	mov.u32 	%r122, 1;
	bra.uni 	$L__BB0_55;

$L__BB0_51:
	mul.rn.f64 	%fd201, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r121, %fd201;
	st.local.u32 	[%rd1], %r121;
	cvt.rn.f64.s32 	%fd202, %r121;
	neg.f64 	%fd203, %fd202;
	mov.f64 	%fd204, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd205, %fd203, %fd204, %fd54;
	mov.f64 	%fd206, 0d3C91A62633145C00;
	fma.rn.f64 	%fd207, %fd203, %fd206, %fd205;
	mov.f64 	%fd208, 0d397B839A252049C0;
	fma.rn.f64 	%fd269, %fd203, %fd208, %fd207;
	abs.f64 	%fd209, %fd54;
	setp.ltu.f64 	%p75, %fd209, 0d41E0000000000000;
	@%p75 bra 	$L__BB0_53;

	add.u64 	%rd42, %SP, 0;
	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd269, [retval0+0];
	} // callseq 4
	ld.local.u32 	%r121, [%rd1];

$L__BB0_53:
	add.s32 	%r122, %r121, 1;

$L__BB0_55:
	mov.u64 	%rd43, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r122, 1;
	shl.b32 	%r102, %r122, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p76, %r101, 0;
	selp.f64 	%fd211, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd25, %r103, 8;
	add.s64 	%rd27, %rd43, %rd25;
	ld.global.nc.f64 	%fd212, [%rd27+8];
	mul.rn.f64 	%fd60, %fd269, %fd269;
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd27+16];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd27+24];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd27+32];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd27+40];
	fma.rn.f64 	%fd221, %fd219, %fd60, %fd220;
	ld.global.nc.f64 	%fd222, [%rd27+48];
	fma.rn.f64 	%fd61, %fd221, %fd60, %fd222;
	fma.rn.f64 	%fd271, %fd61, %fd269, %fd269;
	@%p76 bra 	$L__BB0_57;

	mov.f64 	%fd223, 0d3FF0000000000000;
	fma.rn.f64 	%fd271, %fd61, %fd60, %fd223;

$L__BB0_57:
	and.b32  	%r104, %r122, 2;
	setp.eq.s32 	%p77, %r104, 0;
	@%p77 bra 	$L__BB0_59;

	mov.f64 	%fd224, 0d0000000000000000;
	mov.f64 	%fd225, 0dBFF0000000000000;
	fma.rn.f64 	%fd271, %fd271, %fd225, %fd224;

$L__BB0_59:
	ld.param.u64 	%rd35, [bd09_to_gcj02_cuda_param_0];
	mov.u32 	%r113, %tid.x;
	mov.u32 	%r112, %ntid.x;
	mov.u32 	%r111, %ctaid.x;
	mad.lo.s32 	%r110, %r111, %r112, %r113;
	mul.wide.s32 	%rd34, %r110, 8;
	cvta.to.global.u64 	%rd33, %rd35;
	add.s64 	%rd32, %rd33, %rd34;
	mul.rn.f64 	%fd226, %fd36, %fd271;
	st.global.f64 	[%rd32], %fd226;
	@%p3 bra 	$L__BB0_62;
	bra.uni 	$L__BB0_60;

$L__BB0_62:
	mov.f64 	%fd236, 0d0000000000000000;
	mul.rn.f64 	%fd272, %fd54, %fd236;
	mov.u32 	%r123, 0;
	bra.uni 	$L__BB0_63;

$L__BB0_60:
	mul.rn.f64 	%fd227, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r123, %fd227;
	st.local.u32 	[%rd1], %r123;
	cvt.rn.f64.s32 	%fd228, %r123;
	neg.f64 	%fd229, %fd228;
	mov.f64 	%fd230, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd231, %fd229, %fd230, %fd54;
	mov.f64 	%fd232, 0d3C91A62633145C00;
	fma.rn.f64 	%fd233, %fd229, %fd232, %fd231;
	mov.f64 	%fd234, 0d397B839A252049C0;
	fma.rn.f64 	%fd272, %fd229, %fd234, %fd233;
	abs.f64 	%fd235, %fd54;
	setp.ltu.f64 	%p78, %fd235, 0d41E0000000000000;
	@%p78 bra 	$L__BB0_63;

	add.u64 	%rd44, %SP, 0;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd44;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd272, [retval0+0];
	} // callseq 5
	ld.local.u32 	%r123, [%rd1];

$L__BB0_63:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r106, %r123, 1;
	shl.b32 	%r107, %r123, 3;
	and.b32  	%r108, %r107, 8;
	setp.eq.s32 	%p79, %r106, 0;
	selp.f64 	%fd237, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd29, %r108, 8;
	add.s64 	%rd31, %rd45, %rd29;
	ld.global.nc.f64 	%fd238, [%rd31+8];
	mul.rn.f64 	%fd71, %fd272, %fd272;
	fma.rn.f64 	%fd239, %fd237, %fd71, %fd238;
	ld.global.nc.f64 	%fd240, [%rd31+16];
	fma.rn.f64 	%fd241, %fd239, %fd71, %fd240;
	ld.global.nc.f64 	%fd242, [%rd31+24];
	fma.rn.f64 	%fd243, %fd241, %fd71, %fd242;
	ld.global.nc.f64 	%fd244, [%rd31+32];
	fma.rn.f64 	%fd245, %fd243, %fd71, %fd244;
	ld.global.nc.f64 	%fd246, [%rd31+40];
	fma.rn.f64 	%fd247, %fd245, %fd71, %fd246;
	ld.global.nc.f64 	%fd248, [%rd31+48];
	fma.rn.f64 	%fd72, %fd247, %fd71, %fd248;
	fma.rn.f64 	%fd274, %fd72, %fd272, %fd272;
	@%p79 bra 	$L__BB0_65;

	mov.f64 	%fd249, 0d3FF0000000000000;
	fma.rn.f64 	%fd274, %fd72, %fd71, %fd249;

$L__BB0_65:
	and.b32  	%r109, %r123, 2;
	setp.eq.s32 	%p80, %r109, 0;
	@%p80 bra 	$L__BB0_67;

	mov.f64 	%fd250, 0d0000000000000000;
	mov.f64 	%fd251, 0dBFF0000000000000;
	fma.rn.f64 	%fd274, %fd274, %fd251, %fd250;

$L__BB0_67:
	ld.param.u64 	%rd39, [bd09_to_gcj02_cuda_param_1];
	mov.u32 	%r117, %tid.x;
	mov.u32 	%r116, %ntid.x;
	mov.u32 	%r115, %ctaid.x;
	mad.lo.s32 	%r114, %r115, %r116, %r117;
	mul.wide.s32 	%rd38, %r114, 8;
	cvta.to.global.u64 	%rd37, %rd39;
	add.s64 	%rd36, %rd37, %rd38;
	mul.rn.f64 	%fd252, %fd36, %fd274;
	st.global.f64 	[%rd36], %fd252;
	ret;

}
	// .globl	gcj02_to_bd09_cuda
.visible .entry gcj02_to_bd09_cuda(
	.param .u64 gcj02_to_bd09_cuda_param_0,
	.param .u64 gcj02_to_bd09_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot1[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<81>;
	.reg .b32 	%r<124>;
	.reg .f64 	%fd<274>;
	.reg .b64 	%rd<46>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [gcj02_to_bd09_cuda_param_0];
	ld.param.u64 	%rd8, [gcj02_to_bd09_cuda_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r26, %r24, %r23, %r25;
	cvta.to.global.u64 	%rd14, %rd7;
	mul.wide.s32 	%rd15, %r26, 8;
	add.s64 	%rd5, %rd14, %rd15;
	add.s64 	%rd6, %rd9, %rd15;
	ld.global.f64 	%fd1, [%rd6];
	ld.global.f64 	%fd2, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd78, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd78;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p4, %r3, 1062207488;
	abs.f64 	%fd3, %fd2;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd255, [retval0+0];
	} // callseq 6
	setp.lt.s32 	%p5, %r1, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB1_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd255;
	}
	xor.b32  	%r28, %r27, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd255;
	}
	mov.b64 	%fd255, {%r29, %r28};

$L__BB1_2:
	setp.eq.f64 	%p7, %fd2, 0d0000000000000000;
	@%p7 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_3;

$L__BB1_6:
	selp.b32 	%r30, %r1, 0, %p4;
	mov.u32 	%r31, 0;
	or.b32  	%r32, %r30, 2146435072;
	setp.lt.s32 	%p11, %r2, 0;
	selp.b32 	%r33, %r32, %r30, %p11;
	mov.b64 	%fd255, {%r31, %r33};
	bra.uni 	$L__BB1_7;

$L__BB1_3:
	setp.gt.s32 	%p8, %r1, -1;
	@%p8 bra 	$L__BB1_7;

	mov.f64 	%fd79, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd80, %fd79;
	setp.eq.f64 	%p9, %fd80, 0d4000000000000000;
	@%p9 bra 	$L__BB1_7;

	mov.f64 	%fd255, 0dFFF8000000000000;

$L__BB1_7:
	add.rn.f64 	%fd82, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd82;
	}
	and.b32  	%r35, %r34, 2146435072;
	setp.ne.s32 	%p12, %r35, 2146435072;
	@%p12 bra 	$L__BB1_14;

	setp.gtu.f64 	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	$L__BB1_13;
	bra.uni 	$L__BB1_9;

$L__BB1_13:
	mov.f64 	%fd84, 0d4000000000000000;
	add.rn.f64 	%fd255, %fd2, %fd84;
	bra.uni 	$L__BB1_14;

$L__BB1_9:
	mov.f64 	%fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd83;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p14, %r4, 2146435072;
	setp.eq.s32 	%p15, %r36, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB1_12;
	bra.uni 	$L__BB1_10;

$L__BB1_12:
	setp.gt.f64 	%p23, %fd3, 0d3FF0000000000000;
	selp.b32 	%r43, 2146435072, 0, %p23;
	mov.u32 	%r44, 0;
	xor.b32  	%r45, %r43, 2146435072;
	setp.lt.s32 	%p24, %r2, 0;
	selp.b32 	%r46, %r45, %r43, %p24;
	setp.eq.f64 	%p25, %fd2, 0dBFF0000000000000;
	selp.b32 	%r47, 1072693248, %r46, %p25;
	mov.b64 	%fd255, {%r44, %r47};
	bra.uni 	$L__BB1_14;

$L__BB1_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd2;
	}
	and.b32  	%r38, %r1, 2147483647;
	setp.ne.s32 	%p17, %r38, 2146435072;
	setp.ne.s32 	%p18, %r37, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB1_14;

	setp.gt.s32 	%p20, %r2, -1;
	selp.b32 	%r39, 2146435072, 0, %p20;
	mov.u32 	%r40, 0;
	setp.ne.s32 	%p21, %r4, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r41, %r39, -2147483648;
	selp.b32 	%r42, %r41, %r39, %p22;
	mov.b64 	%fd255, {%r40, %r42};

$L__BB1_14:
	abs.f64 	%fd13, %fd1;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd258, [retval0+0];
	} // callseq 7
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd1;
	}
	setp.lt.s32 	%p26, %r5, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB1_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd258;
	}
	xor.b32  	%r49, %r48, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd258;
	}
	mov.b64 	%fd258, {%r50, %r49};

$L__BB1_16:
	setp.eq.f64 	%p29, %fd1, 0d0000000000000000;
	@%p29 bra 	$L__BB1_20;
	bra.uni 	$L__BB1_17;

$L__BB1_20:
	selp.b32 	%r51, %r5, 0, %p4;
	mov.u32 	%r52, 0;
	or.b32  	%r53, %r51, 2146435072;
	setp.lt.s32 	%p33, %r2, 0;
	selp.b32 	%r54, %r53, %r51, %p33;
	mov.b64 	%fd258, {%r52, %r54};
	bra.uni 	$L__BB1_21;

$L__BB1_17:
	setp.gt.s32 	%p30, %r5, -1;
	@%p30 bra 	$L__BB1_21;

	mov.f64 	%fd85, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd86, %fd85;
	setp.eq.f64 	%p31, %fd86, 0d4000000000000000;
	@%p31 bra 	$L__BB1_21;

	mov.f64 	%fd258, 0dFFF8000000000000;

$L__BB1_21:
	add.rn.f64 	%fd88, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd88;
	}
	and.b32  	%r56, %r55, 2146435072;
	setp.ne.s32 	%p34, %r56, 2146435072;
	@%p34 bra 	$L__BB1_28;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_23;

$L__BB1_27:
	mov.f64 	%fd90, 0d4000000000000000;
	add.rn.f64 	%fd258, %fd1, %fd90;
	bra.uni 	$L__BB1_28;

$L__BB1_23:
	mov.f64 	%fd89, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd89;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p36, %r6, 2146435072;
	setp.eq.s32 	%p37, %r57, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB1_26;
	bra.uni 	$L__BB1_24;

$L__BB1_26:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r64, 2146435072, 0, %p45;
	mov.u32 	%r65, 0;
	xor.b32  	%r66, %r64, 2146435072;
	setp.lt.s32 	%p46, %r2, 0;
	selp.b32 	%r67, %r66, %r64, %p46;
	setp.eq.f64 	%p47, %fd1, 0dBFF0000000000000;
	selp.b32 	%r68, 1072693248, %r67, %p47;
	mov.b64 	%fd258, {%r65, %r68};
	bra.uni 	$L__BB1_28;

$L__BB1_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd1;
	}
	and.b32  	%r59, %r5, 2147483647;
	setp.ne.s32 	%p39, %r59, 2146435072;
	setp.ne.s32 	%p40, %r58, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB1_28;

	setp.gt.s32 	%p42, %r2, -1;
	selp.b32 	%r60, 2146435072, 0, %p42;
	mov.u32 	%r61, 0;
	setp.ne.s32 	%p43, %r6, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r62, %r60, -2147483648;
	selp.b32 	%r63, %r62, %r60, %p44;
	mov.b64 	%fd258, {%r61, %r63};

$L__BB1_28:
	setp.eq.f64 	%p48, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd91, 0d3FF0000000000000, %fd258, %p48;
	setp.eq.f64 	%p49, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd92, 0d3FF0000000000000, %fd255, %p49;
	add.rn.f64 	%fd23, %fd92, %fd91;
	mul.rn.f64 	%fd24, %fd1, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd24;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p50, %r71, 2146435072;
	setp.eq.s32 	%p51, %r69, 0;
	and.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB1_31;
	bra.uni 	$L__BB1_29;

$L__BB1_31:
	mov.f64 	%fd102, 0d0000000000000000;
	mul.rn.f64 	%fd259, %fd24, %fd102;
	mov.u32 	%r118, 0;
	bra.uni 	$L__BB1_32;

$L__BB1_29:
	mul.rn.f64 	%fd93, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd93;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd94, %r118;
	neg.f64 	%fd95, %fd94;
	mov.f64 	%fd96, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd97, %fd95, %fd96, %fd24;
	mov.f64 	%fd98, 0d3C91A62633145C00;
	fma.rn.f64 	%fd99, %fd95, %fd98, %fd97;
	mov.f64 	%fd100, 0d397B839A252049C0;
	fma.rn.f64 	%fd259, %fd95, %fd100, %fd99;
	abs.f64 	%fd101, %fd24;
	setp.ltu.f64 	%p53, %fd101, 0d41E0000000000000;
	@%p53 bra 	$L__BB1_32;

	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 8
	ld.local.u32 	%r118, [%rd1];

$L__BB1_32:
	and.b32  	%r73, %r118, 1;
	shl.b32 	%r74, %r118, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p54, %r73, 0;
	selp.f64 	%fd103, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	mul.wide.s32 	%rd17, %r75, 8;
	mov.u64 	%rd18, __cudart_sin_cos_coeffs;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.nc.f64 	%fd104, [%rd19+8];
	mul.rn.f64 	%fd29, %fd259, %fd259;
	fma.rn.f64 	%fd105, %fd103, %fd29, %fd104;
	ld.global.nc.f64 	%fd106, [%rd19+16];
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd19+24];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd19+32];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd19+40];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd19+48];
	fma.rn.f64 	%fd30, %fd113, %fd29, %fd114;
	fma.rn.f64 	%fd261, %fd30, %fd259, %fd259;
	@%p54 bra 	$L__BB1_34;

	mov.f64 	%fd115, 0d3FF0000000000000;
	fma.rn.f64 	%fd261, %fd30, %fd29, %fd115;

$L__BB1_34:
	and.b32  	%r76, %r118, 2;
	setp.eq.s32 	%p55, %r76, 0;
	@%p55 bra 	$L__BB1_36;

	mov.f64 	%fd116, 0d0000000000000000;
	mov.f64 	%fd117, 0dBFF0000000000000;
	fma.rn.f64 	%fd261, %fd261, %fd117, %fd116;

$L__BB1_36:
	mul.rn.f64 	%fd118, %fd261, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd119, %fd23;
	add.rn.f64 	%fd36, %fd119, %fd118;
	setp.eq.f64 	%p56, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p57, %fd3, 0d0000000000000000;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB1_40;
	bra.uni 	$L__BB1_37;

$L__BB1_40:
	selp.f64 	%fd172, 0d400921FB54442D18, 0d0000000000000000, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd172;
	}
	and.b32  	%r87, %r5, -2147483648;
	or.b32  	%r88, %r86, %r87;
	mov.b64 	%fd262, {%r85, %r88};
	bra.uni 	$L__BB1_41;

$L__BB1_37:
	setp.eq.f64 	%p59, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p60, %fd13, 0d7FF0000000000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB1_39;
	bra.uni 	$L__BB1_38;

$L__BB1_39:
	selp.f64 	%fd171, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd171;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd171;
	}
	and.b32  	%r83, %r5, -2147483648;
	or.b32  	%r84, %r82, %r83;
	mov.b64 	%fd262, {%r81, %r84};
	bra.uni 	$L__BB1_41;

$L__BB1_38:
	min.f64 	%fd120, %fd13, %fd3;
	max.f64 	%fd121, %fd13, %fd3;
	div.rn.f64 	%fd122, %fd120, %fd121;
	mul.rn.f64 	%fd123, %fd122, %fd122;
	mov.f64 	%fd124, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd125, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd126, %fd125, %fd123, %fd124;
	mov.f64 	%fd127, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd128, %fd126, %fd123, %fd127;
	mov.f64 	%fd129, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd130, %fd128, %fd123, %fd129;
	mov.f64 	%fd131, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd132, %fd130, %fd123, %fd131;
	mov.f64 	%fd133, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd134, %fd132, %fd123, %fd133;
	mov.f64 	%fd135, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd136, %fd134, %fd123, %fd135;
	mov.f64 	%fd137, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd138, %fd136, %fd123, %fd137;
	mov.f64 	%fd139, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd140, %fd138, %fd123, %fd139;
	mov.f64 	%fd141, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd142, %fd140, %fd123, %fd141;
	mov.f64 	%fd143, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd144, %fd142, %fd123, %fd143;
	mov.f64 	%fd145, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd146, %fd144, %fd123, %fd145;
	mov.f64 	%fd147, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd148, %fd146, %fd123, %fd147;
	mov.f64 	%fd149, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd150, %fd148, %fd123, %fd149;
	mov.f64 	%fd151, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd152, %fd150, %fd123, %fd151;
	mov.f64 	%fd153, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd154, %fd152, %fd123, %fd153;
	mov.f64 	%fd155, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd156, %fd154, %fd123, %fd155;
	mov.f64 	%fd157, 0d3FC99999999840D2;
	fma.rn.f64 	%fd158, %fd156, %fd123, %fd157;
	mov.f64 	%fd159, 0dBFD555555555544C;
	fma.rn.f64 	%fd160, %fd158, %fd123, %fd159;
	mul.rn.f64 	%fd161, %fd123, %fd160;
	fma.rn.f64 	%fd162, %fd161, %fd122, %fd122;
	mov.f64 	%fd163, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd164, %fd163, %fd162;
	setp.gt.f64 	%p63, %fd13, %fd3;
	selp.f64 	%fd165, %fd164, %fd162, %p63;
	mov.f64 	%fd166, 0d400921FB54442D18;
	sub.rn.f64 	%fd167, %fd166, %fd165;
	selp.f64 	%fd168, %fd167, %fd165, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd168;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd168;
	}
	and.b32  	%r79, %r5, -2147483648;
	or.b32  	%r80, %r78, %r79;
	mov.b64 	%fd169, {%r77, %r80};
	add.rn.f64 	%fd170, %fd3, %fd13;
	setp.le.f64 	%p64, %fd170, 0d7FF0000000000000;
	selp.f64 	%fd262, %fd169, %fd170, %p64;

$L__BB1_41:
	mul.rn.f64 	%fd41, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd41;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p67, %r91, 2146435072;
	setp.eq.s32 	%p68, %r89, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB1_45;
	bra.uni 	$L__BB1_42;

$L__BB1_45:
	mov.f64 	%fd182, 0d0000000000000000;
	mul.rn.f64 	%fd264, %fd41, %fd182;
	mov.u32 	%r120, 1;
	bra.uni 	$L__BB1_46;

$L__BB1_42:
	mul.rn.f64 	%fd173, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r119, %fd173;
	st.local.u32 	[%rd1], %r119;
	cvt.rn.f64.s32 	%fd174, %r119;
	neg.f64 	%fd175, %fd174;
	mov.f64 	%fd176, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd177, %fd175, %fd176, %fd41;
	mov.f64 	%fd178, 0d3C91A62633145C00;
	fma.rn.f64 	%fd179, %fd175, %fd178, %fd177;
	mov.f64 	%fd180, 0d397B839A252049C0;
	fma.rn.f64 	%fd264, %fd175, %fd180, %fd179;
	abs.f64 	%fd181, %fd41;
	setp.ltu.f64 	%p70, %fd181, 0d41E0000000000000;
	@%p70 bra 	$L__BB1_44;

	add.u64 	%rd32, %SP, 0;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd32;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd264, [retval0+0];
	} // callseq 9
	ld.local.u32 	%r119, [%rd1];

$L__BB1_44:
	add.s32 	%r120, %r119, 1;

$L__BB1_46:
	mov.u64 	%rd43, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r120, 1;
	shl.b32 	%r94, %r120, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p71, %r93, 0;
	selp.f64 	%fd183, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd21, %r95, 8;
	add.s64 	%rd23, %rd43, %rd21;
	ld.global.nc.f64 	%fd184, [%rd23+8];
	mul.rn.f64 	%fd47, %fd264, %fd264;
	fma.rn.f64 	%fd185, %fd183, %fd47, %fd184;
	ld.global.nc.f64 	%fd186, [%rd23+16];
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd23+24];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd23+32];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd23+40];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd23+48];
	fma.rn.f64 	%fd48, %fd193, %fd47, %fd194;
	fma.rn.f64 	%fd266, %fd48, %fd264, %fd264;
	@%p71 bra 	$L__BB1_48;

	mov.f64 	%fd195, 0d3FF0000000000000;
	fma.rn.f64 	%fd266, %fd48, %fd47, %fd195;

$L__BB1_48:
	and.b32  	%r96, %r120, 2;
	setp.eq.s32 	%p72, %r96, 0;
	@%p72 bra 	$L__BB1_50;

	mov.f64 	%fd196, 0d0000000000000000;
	mov.f64 	%fd197, 0dBFF0000000000000;
	fma.rn.f64 	%fd266, %fd266, %fd197, %fd196;

$L__BB1_50:
	mul.rn.f64 	%fd198, %fd266, 0d3EC92A737110E454;
	add.rn.f64 	%fd54, %fd262, %fd198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd54;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p73, %r99, 2146435072;
	setp.eq.s32 	%p74, %r97, 0;
	and.pred  	%p3, %p74, %p73;
	@%p3 bra 	$L__BB1_54;
	bra.uni 	$L__BB1_51;

$L__BB1_54:
	mov.f64 	%fd208, 0d0000000000000000;
	mul.rn.f64 	%fd268, %fd54, %fd208;
	mov.u32 	%r122, 1;
	bra.uni 	$L__BB1_55;

$L__BB1_51:
	mul.rn.f64 	%fd199, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r121, %fd199;
	st.local.u32 	[%rd1], %r121;
	cvt.rn.f64.s32 	%fd200, %r121;
	neg.f64 	%fd201, %fd200;
	mov.f64 	%fd202, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd203, %fd201, %fd202, %fd54;
	mov.f64 	%fd204, 0d3C91A62633145C00;
	fma.rn.f64 	%fd205, %fd201, %fd204, %fd203;
	mov.f64 	%fd206, 0d397B839A252049C0;
	fma.rn.f64 	%fd268, %fd201, %fd206, %fd205;
	abs.f64 	%fd207, %fd54;
	setp.ltu.f64 	%p75, %fd207, 0d41E0000000000000;
	@%p75 bra 	$L__BB1_53;

	add.u64 	%rd33, %SP, 0;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd268, [retval0+0];
	} // callseq 10
	ld.local.u32 	%r121, [%rd1];

$L__BB1_53:
	add.s32 	%r122, %r121, 1;

$L__BB1_55:
	mov.u64 	%rd44, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r122, 1;
	shl.b32 	%r102, %r122, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p76, %r101, 0;
	selp.f64 	%fd209, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd25, %r103, 8;
	add.s64 	%rd27, %rd44, %rd25;
	ld.global.nc.f64 	%fd210, [%rd27+8];
	mul.rn.f64 	%fd60, %fd268, %fd268;
	fma.rn.f64 	%fd211, %fd209, %fd60, %fd210;
	ld.global.nc.f64 	%fd212, [%rd27+16];
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd27+24];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd27+32];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd27+40];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd27+48];
	fma.rn.f64 	%fd61, %fd219, %fd60, %fd220;
	fma.rn.f64 	%fd270, %fd61, %fd268, %fd268;
	@%p76 bra 	$L__BB1_57;

	mov.f64 	%fd221, 0d3FF0000000000000;
	fma.rn.f64 	%fd270, %fd61, %fd60, %fd221;

$L__BB1_57:
	and.b32  	%r104, %r122, 2;
	setp.eq.s32 	%p77, %r104, 0;
	@%p77 bra 	$L__BB1_59;

	mov.f64 	%fd222, 0d0000000000000000;
	mov.f64 	%fd223, 0dBFF0000000000000;
	fma.rn.f64 	%fd270, %fd270, %fd223, %fd222;

$L__BB1_59:
	ld.param.u64 	%rd37, [gcj02_to_bd09_cuda_param_0];
	mov.u32 	%r113, %tid.x;
	mov.u32 	%r112, %ntid.x;
	mov.u32 	%r111, %ctaid.x;
	mad.lo.s32 	%r110, %r111, %r112, %r113;
	mul.wide.s32 	%rd36, %r110, 8;
	cvta.to.global.u64 	%rd35, %rd37;
	add.s64 	%rd34, %rd35, %rd36;
	mul.rn.f64 	%fd224, %fd36, %fd270;
	add.rn.f64 	%fd225, %fd224, 0d3F7A9FBE76C8B439;
	st.global.f64 	[%rd34], %fd225;
	@%p3 bra 	$L__BB1_62;
	bra.uni 	$L__BB1_60;

$L__BB1_62:
	mov.f64 	%fd235, 0d0000000000000000;
	mul.rn.f64 	%fd271, %fd54, %fd235;
	mov.u32 	%r123, 0;
	bra.uni 	$L__BB1_63;

$L__BB1_60:
	mul.rn.f64 	%fd226, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r123, %fd226;
	st.local.u32 	[%rd1], %r123;
	cvt.rn.f64.s32 	%fd227, %r123;
	neg.f64 	%fd228, %fd227;
	mov.f64 	%fd229, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd230, %fd228, %fd229, %fd54;
	mov.f64 	%fd231, 0d3C91A62633145C00;
	fma.rn.f64 	%fd232, %fd228, %fd231, %fd230;
	mov.f64 	%fd233, 0d397B839A252049C0;
	fma.rn.f64 	%fd271, %fd228, %fd233, %fd232;
	abs.f64 	%fd234, %fd54;
	setp.ltu.f64 	%p78, %fd234, 0d41E0000000000000;
	@%p78 bra 	$L__BB1_63;

	add.u64 	%rd38, %SP, 0;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd38;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd271, [retval0+0];
	} // callseq 11
	ld.local.u32 	%r123, [%rd1];

$L__BB1_63:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r106, %r123, 1;
	shl.b32 	%r107, %r123, 3;
	and.b32  	%r108, %r107, 8;
	setp.eq.s32 	%p79, %r106, 0;
	selp.f64 	%fd236, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd29, %r108, 8;
	add.s64 	%rd31, %rd45, %rd29;
	ld.global.nc.f64 	%fd237, [%rd31+8];
	mul.rn.f64 	%fd71, %fd271, %fd271;
	fma.rn.f64 	%fd238, %fd236, %fd71, %fd237;
	ld.global.nc.f64 	%fd239, [%rd31+16];
	fma.rn.f64 	%fd240, %fd238, %fd71, %fd239;
	ld.global.nc.f64 	%fd241, [%rd31+24];
	fma.rn.f64 	%fd242, %fd240, %fd71, %fd241;
	ld.global.nc.f64 	%fd243, [%rd31+32];
	fma.rn.f64 	%fd244, %fd242, %fd71, %fd243;
	ld.global.nc.f64 	%fd245, [%rd31+40];
	fma.rn.f64 	%fd246, %fd244, %fd71, %fd245;
	ld.global.nc.f64 	%fd247, [%rd31+48];
	fma.rn.f64 	%fd72, %fd246, %fd71, %fd247;
	fma.rn.f64 	%fd273, %fd72, %fd271, %fd271;
	@%p79 bra 	$L__BB1_65;

	mov.f64 	%fd248, 0d3FF0000000000000;
	fma.rn.f64 	%fd273, %fd72, %fd71, %fd248;

$L__BB1_65:
	and.b32  	%r109, %r123, 2;
	setp.eq.s32 	%p80, %r109, 0;
	@%p80 bra 	$L__BB1_67;

	mov.f64 	%fd249, 0d0000000000000000;
	mov.f64 	%fd250, 0dBFF0000000000000;
	fma.rn.f64 	%fd273, %fd273, %fd250, %fd249;

$L__BB1_67:
	ld.param.u64 	%rd42, [gcj02_to_bd09_cuda_param_1];
	mov.u32 	%r117, %tid.x;
	mov.u32 	%r116, %ntid.x;
	mov.u32 	%r115, %ctaid.x;
	mad.lo.s32 	%r114, %r115, %r116, %r117;
	mul.wide.s32 	%rd41, %r114, 8;
	cvta.to.global.u64 	%rd40, %rd42;
	add.s64 	%rd39, %rd40, %rd41;
	mul.rn.f64 	%fd251, %fd36, %fd273;
	add.rn.f64 	%fd252, %fd251, 0d3F789374BC6A7EFA;
	st.global.f64 	[%rd39], %fd252;
	ret;

}
	// .globl	gcj02_to_wgs84_cuda
.visible .entry gcj02_to_wgs84_cuda(
	.param .u64 gcj02_to_wgs84_cuda_param_0,
	.param .u64 gcj02_to_wgs84_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot2[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<118>;
	.reg .b32 	%r<201>;
	.reg .f64 	%fd<601>;
	.reg .b64 	%rd<110>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [gcj02_to_wgs84_cuda_param_0];
	ld.param.u64 	%rd16, [gcj02_to_wgs84_cuda_param_1];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r48, %r46, %r45, %r47;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r48, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd9;
	}
	and.b32  	%r51, %r50, 2147483647;
	setp.eq.s32 	%p4, %r51, 2146435072;
	setp.eq.s32 	%p5, %r49, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB2_3;
	bra.uni 	$L__BB2_1;

$L__BB2_3:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd558, %fd9, %fd192;
	mov.u32 	%r188, 0;
	bra.uni 	$L__BB2_4;

$L__BB2_1:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r188, %fd183;
	st.local.u32 	[%rd1], %r188;
	cvt.rn.f64.s32 	%fd184, %r188;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd558, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p7, %fd191, 0d41E0000000000000;
	@%p7 bra 	$L__BB2_4;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd558, [retval0+0];
	} // callseq 12
	ld.local.u32 	%r188, [%rd1];

$L__BB2_4:
	and.b32  	%r53, %r188, 1;
	shl.b32 	%r54, %r188, 3;
	and.b32  	%r55, %r54, 8;
	setp.eq.s32 	%p8, %r53, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd33, %r55, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd194, [%rd35+8];
	mul.rn.f64 	%fd14, %fd558, %fd558;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd35+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd35+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd35+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd35+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd35+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd560, %fd15, %fd558, %fd558;
	@%p8 bra 	$L__BB2_6;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd560, %fd15, %fd14, %fd205;

$L__BB2_6:
	and.b32  	%r56, %r188, 2;
	setp.eq.s32 	%p9, %r56, 0;
	@%p9 bra 	$L__BB2_8;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd560, %fd560, %fd207, %fd206;

$L__BB2_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd21;
	}
	and.b32  	%r59, %r58, 2147483647;
	setp.eq.s32 	%p10, %r59, 2146435072;
	setp.eq.s32 	%p11, %r57, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB2_11;
	bra.uni 	$L__BB2_9;

$L__BB2_11:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd561, %fd21, %fd217;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB2_12;

$L__BB2_9:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd208;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd209, %r189;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd561, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p13, %fd216, 0d41E0000000000000;
	@%p13 bra 	$L__BB2_12;

	add.u64 	%rd98, %SP, 0;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd98;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd561, [retval0+0];
	} // callseq 13
	ld.local.u32 	%r189, [%rd1];

$L__BB2_12:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r61, %r189, 1;
	shl.b32 	%r62, %r189, 3;
	and.b32  	%r63, %r62, 8;
	setp.eq.s32 	%p14, %r61, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd37, %r63, 8;
	add.s64 	%rd39, %rd108, %rd37;
	ld.global.nc.f64 	%fd219, [%rd39+8];
	mul.rn.f64 	%fd26, %fd561, %fd561;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd39+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd39+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd39+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd39+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd39+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd563, %fd27, %fd561, %fd561;
	@%p14 bra 	$L__BB2_14;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd563, %fd27, %fd26, %fd230;

$L__BB2_14:
	and.b32  	%r64, %r189, 2;
	setp.eq.s32 	%p15, %r64, 0;
	@%p15 bra 	$L__BB2_16;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd563, %fd563, %fd232, %fd231;

$L__BB2_16:
	mul.rn.f64 	%fd233, %fd563, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd560, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd8;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.eq.s32 	%p16, %r66, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd8;
	}
	setp.eq.s32 	%p17, %r67, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB2_19;
	bra.uni 	$L__BB2_17;

$L__BB2_19:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd564, %fd8, %fd244;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB2_20;

$L__BB2_17:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd235;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd236, %r190;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd564, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p19, %fd243, 0d41E0000000000000;
	@%p19 bra 	$L__BB2_20;

	add.u64 	%rd80, %SP, 0;
	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd564, [retval0+0];
	} // callseq 14
	ld.local.u32 	%r190, [%rd1];

$L__BB2_20:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r69, %r190, 1;
	shl.b32 	%r70, %r190, 3;
	and.b32  	%r71, %r70, 8;
	setp.eq.s32 	%p20, %r69, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd41, %r71, 8;
	add.s64 	%rd43, %rd109, %rd41;
	ld.global.nc.f64 	%fd246, [%rd43+8];
	mul.rn.f64 	%fd38, %fd564, %fd564;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd43+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd43+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd43+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd43+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd43+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd566, %fd39, %fd564, %fd564;
	@%p20 bra 	$L__BB2_22;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd566, %fd39, %fd38, %fd257;

$L__BB2_22:
	and.b32  	%r72, %r190, 2;
	setp.eq.s32 	%p21, %r72, 0;
	@%p21 bra 	$L__BB2_24;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd566, %fd566, %fd259, %fd258;

$L__BB2_24:
	add.rn.f64 	%fd557, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd556, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd45;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.eq.s32 	%p22, %r75, 2146435072;
	setp.eq.s32 	%p23, %r73, 0;
	and.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB2_27;
	bra.uni 	$L__BB2_25;

$L__BB2_27:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd567, %fd45, %fd269;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB2_28;

$L__BB2_25:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd260;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd261, %r191;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd567, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p25, %fd268, 0d41E0000000000000;
	@%p25 bra 	$L__BB2_28;

	add.u64 	%rd81, %SP, 0;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd567, [retval0+0];
	} // callseq 15
	ld.local.u32 	%r191, [%rd1];

$L__BB2_28:
	mov.u64 	%rd99, __cudart_sin_cos_coeffs;
	and.b32  	%r77, %r191, 1;
	shl.b32 	%r78, %r191, 3;
	and.b32  	%r79, %r78, 8;
	setp.eq.s32 	%p26, %r77, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	mul.wide.s32 	%rd45, %r79, 8;
	add.s64 	%rd47, %rd99, %rd45;
	ld.global.nc.f64 	%fd271, [%rd47+8];
	mul.rn.f64 	%fd50, %fd567, %fd567;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd47+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd47+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd47+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd47+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd47+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd569, %fd51, %fd567, %fd567;
	@%p26 bra 	$L__BB2_30;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd569, %fd51, %fd50, %fd282;

$L__BB2_30:
	and.b32  	%r80, %r191, 2;
	setp.eq.s32 	%p27, %r80, 0;
	@%p27 bra 	$L__BB2_32;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd569, %fd569, %fd284, %fd283;

$L__BB2_32:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd569, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd566, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd58;
	}
	and.b32  	%r83, %r82, 2147483647;
	setp.eq.s32 	%p28, %r83, 2146435072;
	setp.eq.s32 	%p29, %r81, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB2_35;
	bra.uni 	$L__BB2_33;

$L__BB2_35:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd570, %fd58, %fd296;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB2_36;

$L__BB2_33:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd287;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd288, %r192;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd570, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p31, %fd295, 0d41E0000000000000;
	@%p31 bra 	$L__BB2_36;

	add.u64 	%rd82, %SP, 0;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd570, [retval0+0];
	} // callseq 16
	ld.local.u32 	%r192, [%rd1];

$L__BB2_36:
	mov.u64 	%rd100, __cudart_sin_cos_coeffs;
	and.b32  	%r85, %r192, 1;
	shl.b32 	%r86, %r192, 3;
	and.b32  	%r87, %r86, 8;
	setp.eq.s32 	%p32, %r85, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd49, %r87, 8;
	add.s64 	%rd51, %rd100, %rd49;
	ld.global.nc.f64 	%fd298, [%rd51+8];
	mul.rn.f64 	%fd63, %fd570, %fd570;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd51+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd51+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd51+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd51+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd51+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd572, %fd64, %fd570, %fd570;
	@%p32 bra 	$L__BB2_38;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd572, %fd64, %fd63, %fd309;

$L__BB2_38:
	and.b32  	%r88, %r192, 2;
	setp.eq.s32 	%p33, %r88, 0;
	@%p33 bra 	$L__BB2_40;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd572, %fd572, %fd311, %fd310;

$L__BB2_40:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd572, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd71;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p34, %r91, 2146435072;
	setp.eq.s32 	%p35, %r89, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB2_43;
	bra.uni 	$L__BB2_41;

$L__BB2_43:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd573, %fd71, %fd322;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB2_44;

$L__BB2_41:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd313;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd314, %r193;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd573, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p37, %fd321, 0d41E0000000000000;
	@%p37 bra 	$L__BB2_44;

	add.u64 	%rd83, %SP, 0;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd573, [retval0+0];
	} // callseq 17
	ld.local.u32 	%r193, [%rd1];

$L__BB2_44:
	mov.u64 	%rd101, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r193, 1;
	shl.b32 	%r94, %r193, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p38, %r93, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd53, %r95, 8;
	add.s64 	%rd55, %rd101, %rd53;
	ld.global.nc.f64 	%fd324, [%rd55+8];
	mul.rn.f64 	%fd76, %fd573, %fd573;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd55+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd55+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd55+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd55+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd55+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd575, %fd77, %fd573, %fd573;
	@%p38 bra 	$L__BB2_46;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd575, %fd77, %fd76, %fd335;

$L__BB2_46:
	and.b32  	%r96, %r193, 2;
	setp.eq.s32 	%p39, %r96, 0;
	@%p39 bra 	$L__BB2_48;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd575, %fd575, %fd337, %fd336;

$L__BB2_48:
	mul.rn.f64 	%fd338, %fd575, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd7;
	}
	and.b32  	%r98, %r97, 2147483647;
	setp.eq.s32 	%p40, %r98, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd7;
	}
	setp.eq.s32 	%p41, %r99, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB2_51;
	bra.uni 	$L__BB2_49;

$L__BB2_51:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd576, %fd7, %fd348;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB2_52;

$L__BB2_49:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd339;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd340, %r194;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd576, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p43, %fd347, 0d41E0000000000000;
	@%p43 bra 	$L__BB2_52;

	add.u64 	%rd84, %SP, 0;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd576, [retval0+0];
	} // callseq 18
	ld.local.u32 	%r194, [%rd1];

$L__BB2_52:
	mov.u64 	%rd102, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r194, 1;
	shl.b32 	%r102, %r194, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p44, %r101, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd57, %r103, 8;
	add.s64 	%rd59, %rd102, %rd57;
	ld.global.nc.f64 	%fd350, [%rd59+8];
	mul.rn.f64 	%fd88, %fd576, %fd576;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd59+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd59+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd59+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd59+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd59+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd578, %fd89, %fd576, %fd576;
	@%p44 bra 	$L__BB2_54;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd578, %fd89, %fd88, %fd361;

$L__BB2_54:
	and.b32  	%r104, %r194, 2;
	setp.eq.s32 	%p45, %r104, 0;
	@%p45 bra 	$L__BB2_56;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd578, %fd578, %fd363, %fd362;

$L__BB2_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r105, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd95;
	}
	and.b32  	%r107, %r106, 2147483647;
	setp.eq.s32 	%p46, %r107, 2146435072;
	setp.eq.s32 	%p47, %r105, 0;
	and.pred  	%p48, %p47, %p46;
	@%p48 bra 	$L__BB2_59;
	bra.uni 	$L__BB2_57;

$L__BB2_59:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd579, %fd95, %fd373;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB2_60;

$L__BB2_57:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd364;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd365, %r195;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd579, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p49, %fd372, 0d41E0000000000000;
	@%p49 bra 	$L__BB2_60;

	add.u64 	%rd85, %SP, 0;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd579, [retval0+0];
	} // callseq 19
	ld.local.u32 	%r195, [%rd1];

$L__BB2_60:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r109, %r195, 1;
	shl.b32 	%r110, %r195, 3;
	and.b32  	%r111, %r110, 8;
	setp.eq.s32 	%p50, %r109, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	mul.wide.s32 	%rd61, %r111, 8;
	add.s64 	%rd63, %rd103, %rd61;
	ld.global.nc.f64 	%fd375, [%rd63+8];
	mul.rn.f64 	%fd100, %fd579, %fd579;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd63+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd63+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd63+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd63+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd63+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd581, %fd101, %fd579, %fd579;
	@%p50 bra 	$L__BB2_62;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd581, %fd101, %fd100, %fd386;

$L__BB2_62:
	and.b32  	%r112, %r195, 2;
	setp.eq.s32 	%p51, %r112, 0;
	@%p51 bra 	$L__BB2_64;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd581, %fd581, %fd388, %fd387;

$L__BB2_64:
	mul.rn.f64 	%fd389, %fd581, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd578, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd108;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p52, %r115, 2146435072;
	setp.eq.s32 	%p53, %r113, 0;
	and.pred  	%p54, %p53, %p52;
	@%p54 bra 	$L__BB2_67;
	bra.uni 	$L__BB2_65;

$L__BB2_67:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd582, %fd108, %fd400;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB2_68;

$L__BB2_65:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd391;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd392, %r196;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd582, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p55, %fd399, 0d41E0000000000000;
	@%p55 bra 	$L__BB2_68;

	add.u64 	%rd86, %SP, 0;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd86;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd582, [retval0+0];
	} // callseq 20
	ld.local.u32 	%r196, [%rd1];

$L__BB2_68:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r117, %r196, 1;
	shl.b32 	%r118, %r196, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p56, %r117, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p56;
	mul.wide.s32 	%rd65, %r119, 8;
	add.s64 	%rd67, %rd104, %rd65;
	ld.global.nc.f64 	%fd402, [%rd67+8];
	mul.rn.f64 	%fd113, %fd582, %fd582;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd67+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd67+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd67+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd67+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd67+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd584, %fd114, %fd582, %fd582;
	@%p56 bra 	$L__BB2_70;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd584, %fd114, %fd113, %fd413;

$L__BB2_70:
	and.b32  	%r120, %r196, 2;
	setp.eq.s32 	%p57, %r120, 0;
	@%p57 bra 	$L__BB2_72;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd584, %fd584, %fd415, %fd414;

$L__BB2_72:
	mul.rn.f64 	%fd416, %fd584, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd121;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p58, %r123, 2146435072;
	setp.eq.s32 	%p59, %r121, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB2_75;
	bra.uni 	$L__BB2_73;

$L__BB2_75:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd585, %fd121, %fd426;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB2_76;

$L__BB2_73:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd417;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd418, %r197;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd585, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p61, %fd425, 0d41E0000000000000;
	@%p61 bra 	$L__BB2_76;

	add.u64 	%rd87, %SP, 0;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd585, [retval0+0];
	} // callseq 21
	ld.local.u32 	%r197, [%rd1];

$L__BB2_76:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r125, %r197, 1;
	shl.b32 	%r126, %r197, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p62, %r125, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd105, %rd69;
	ld.global.nc.f64 	%fd428, [%rd71+8];
	mul.rn.f64 	%fd126, %fd585, %fd585;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd71+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd71+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd71+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd71+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd71+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd587, %fd127, %fd585, %fd585;
	@%p62 bra 	$L__BB2_78;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd587, %fd127, %fd126, %fd439;

$L__BB2_78:
	and.b32  	%r128, %r197, 2;
	setp.eq.s32 	%p63, %r128, 0;
	@%p63 bra 	$L__BB2_80;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd587, %fd587, %fd441, %fd440;

$L__BB2_80:
	mul.rn.f64 	%fd442, %fd587, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd445;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p64, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd590, [retval0+0];
	} // callseq 22
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p65, %r33, 0;
	and.pred  	%p1, %p65, %p64;
	not.pred 	%p66, %p1;
	@%p66 bra 	$L__BB2_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd590;
	}
	xor.b32  	%r130, %r129, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd590;
	}
	mov.b64 	%fd590, {%r131, %r130};

$L__BB2_82:
	setp.eq.f64 	%p67, %fd4, 0d0000000000000000;
	@%p67 bra 	$L__BB2_86;
	bra.uni 	$L__BB2_83;

$L__BB2_86:
	selp.b32 	%r132, %r33, 0, %p64;
	mov.u32 	%r133, 0;
	or.b32  	%r134, %r132, 2146435072;
	setp.lt.s32 	%p71, %r31, 0;
	selp.b32 	%r135, %r134, %r132, %p71;
	mov.b64 	%fd590, {%r133, %r135};
	bra.uni 	$L__BB2_87;

$L__BB2_83:
	setp.gt.s32 	%p68, %r33, -1;
	@%p68 bra 	$L__BB2_87;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p69, %fd449, 0d4000000000000000;
	@%p69 bra 	$L__BB2_87;

	mov.f64 	%fd590, 0dFFF8000000000000;

$L__BB2_87:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd451;
	}
	and.b32  	%r137, %r136, 2146435072;
	setp.ne.s32 	%p72, %r137, 2146435072;
	@%p72 bra 	$L__BB2_94;

	setp.gtu.f64 	%p73, %fd136, 0d7FF0000000000000;
	@%p73 bra 	$L__BB2_93;
	bra.uni 	$L__BB2_89;

$L__BB2_93:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd590, %fd4, %fd453;
	bra.uni 	$L__BB2_94;

$L__BB2_89:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd452;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p74, %r34, 2146435072;
	setp.eq.s32 	%p75, %r138, 0;
	and.pred  	%p76, %p74, %p75;
	@%p76 bra 	$L__BB2_92;
	bra.uni 	$L__BB2_90;

$L__BB2_92:
	setp.gt.f64 	%p83, %fd136, 0d3FF0000000000000;
	selp.b32 	%r145, 2146435072, 0, %p83;
	mov.u32 	%r146, 0;
	xor.b32  	%r147, %r145, 2146435072;
	setp.lt.s32 	%p84, %r31, 0;
	selp.b32 	%r148, %r147, %r145, %p84;
	setp.eq.f64 	%p85, %fd4, 0dBFF0000000000000;
	selp.b32 	%r149, 1072693248, %r148, %p85;
	mov.b64 	%fd590, {%r146, %r149};
	bra.uni 	$L__BB2_94;

$L__BB2_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd4;
	}
	and.b32  	%r140, %r33, 2147483647;
	setp.ne.s32 	%p77, %r140, 2146435072;
	setp.ne.s32 	%p78, %r139, 0;
	or.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB2_94;

	setp.gt.s32 	%p80, %r31, -1;
	selp.b32 	%r141, 2146435072, 0, %p80;
	mov.u32 	%r142, 0;
	setp.ne.s32 	%p81, %r34, 1071644672;
	and.pred  	%p82, %p81, %p1;
	or.b32  	%r143, %r141, -2147483648;
	selp.b32 	%r144, %r143, %r141, %p82;
	mov.b64 	%fd590, {%r142, %r144};

$L__BB2_94:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd590, 0d3FC999999999999A;
	setp.eq.f64 	%p86, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p86;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd593, [retval0+0];
	} // callseq 23
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd547;
	}
	setp.lt.s32 	%p87, %r35, 0;
	and.pred  	%p2, %p87, %p64;
	not.pred 	%p89, %p2;
	@%p89 bra 	$L__BB2_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd593;
	}
	xor.b32  	%r151, %r150, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd593;
	}
	mov.b64 	%fd593, {%r152, %r151};

$L__BB2_96:
	setp.eq.f64 	%p90, %fd2, 0d0000000000000000;
	@%p90 bra 	$L__BB2_100;
	bra.uni 	$L__BB2_97;

$L__BB2_100:
	selp.b32 	%r153, %r35, 0, %p64;
	mov.u32 	%r154, 0;
	or.b32  	%r155, %r153, 2146435072;
	setp.lt.s32 	%p94, %r31, 0;
	selp.b32 	%r156, %r155, %r153, %p94;
	mov.b64 	%fd593, {%r154, %r156};
	bra.uni 	$L__BB2_101;

$L__BB2_97:
	setp.gt.s32 	%p91, %r35, -1;
	@%p91 bra 	$L__BB2_101;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p92, %fd465, 0d4000000000000000;
	@%p92 bra 	$L__BB2_101;

	mov.f64 	%fd593, 0dFFF8000000000000;

$L__BB2_101:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd467;
	}
	and.b32  	%r158, %r157, 2146435072;
	setp.ne.s32 	%p95, %r158, 2146435072;
	@%p95 bra 	$L__BB2_108;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p96, %fd548, 0d7FF0000000000000;
	@%p96 bra 	$L__BB2_107;
	bra.uni 	$L__BB2_103;

$L__BB2_107:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd593, %fd2, %fd469;
	bra.uni 	$L__BB2_108;

$L__BB2_103:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd468;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p97, %r36, 2146435072;
	setp.eq.s32 	%p98, %r159, 0;
	and.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB2_106;
	bra.uni 	$L__BB2_104;

$L__BB2_106:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p106, %fd550, 0d3FF0000000000000;
	selp.b32 	%r166, 2146435072, 0, %p106;
	mov.u32 	%r167, 0;
	xor.b32  	%r168, %r166, 2146435072;
	setp.lt.s32 	%p107, %r31, 0;
	selp.b32 	%r169, %r168, %r166, %p107;
	setp.eq.f64 	%p108, %fd551, 0dBFF0000000000000;
	selp.b32 	%r170, 1072693248, %r169, %p108;
	mov.b64 	%fd593, {%r167, %r170};
	bra.uni 	$L__BB2_108;

$L__BB2_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd2;
	}
	and.b32  	%r161, %r35, 2147483647;
	setp.ne.s32 	%p100, %r161, 2146435072;
	setp.ne.s32 	%p101, %r160, 0;
	or.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB2_108;

	setp.gt.s32 	%p103, %r31, -1;
	selp.b32 	%r162, 2146435072, 0, %p103;
	mov.u32 	%r163, 0;
	setp.ne.s32 	%p104, %r36, 1071644672;
	and.pred  	%p105, %p104, %p2;
	or.b32  	%r164, %r162, -2147483648;
	selp.b32 	%r165, %r164, %r162, %p105;
	mov.b64 	%fd593, {%r163, %r165};

$L__BB2_108:
	mul.rn.f64 	%fd470, %fd593, 0d3FB999999999999A;
	setp.eq.f64 	%p109, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p109;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd159;
	}
	and.b32  	%r173, %r172, 2147483647;
	setp.eq.s32 	%p110, %r173, 2146435072;
	setp.eq.s32 	%p111, %r171, 0;
	and.pred  	%p3, %p111, %p110;
	@%p3 bra 	$L__BB2_111;
	bra.uni 	$L__BB2_109;

$L__BB2_111:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd594, %fd159, %fd487;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB2_112;

$L__BB2_109:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd478;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd479, %r198;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd594, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p112, %fd486, 0d41E0000000000000;
	@%p112 bra 	$L__BB2_112;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 24
	ld.local.u32 	%r198, [%rd1];

$L__BB2_112:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r175, %r198, 1;
	shl.b32 	%r176, %r198, 3;
	and.b32  	%r177, %r176, 8;
	setp.eq.s32 	%p113, %r175, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd73, %r177, 8;
	add.s64 	%rd75, %rd106, %rd73;
	ld.global.nc.f64 	%fd489, [%rd75+8];
	mul.rn.f64 	%fd164, %fd594, %fd594;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd75+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd75+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd75+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd75+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd75+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd596, %fd165, %fd594, %fd594;
	@%p113 bra 	$L__BB2_114;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd596, %fd165, %fd164, %fd500;

$L__BB2_114:
	and.b32  	%r178, %r198, 2;
	setp.eq.s32 	%p114, %r178, 0;
	@%p114 bra 	$L__BB2_116;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd596, %fd596, %fd502, %fd501;

$L__BB2_116:
	@%p3 bra 	$L__BB2_120;
	bra.uni 	$L__BB2_117;

$L__BB2_120:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd512;
	mov.u32 	%r200, 1;
	bra.uni 	$L__BB2_121;

$L__BB2_117:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd503;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd504, %r199;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p115, %fd511, 0d41E0000000000000;
	@%p115 bra 	$L__BB2_119;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 25
	ld.local.u32 	%r199, [%rd1];

$L__BB2_119:
	add.s32 	%r200, %r199, 1;

$L__BB2_121:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r180, %r200, 1;
	shl.b32 	%r181, %r200, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p116, %r180, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd77, %r182, 8;
	add.s64 	%rd79, %rd107, %rd77;
	ld.global.nc.f64 	%fd514, [%rd79+8];
	mul.rn.f64 	%fd176, %fd598, %fd598;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd79+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd79+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd79+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd79+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd79+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd600, %fd177, %fd598, %fd598;
	@%p116 bra 	$L__BB2_123;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd177, %fd176, %fd525;

$L__BB2_123:
	and.b32  	%r183, %r200, 2;
	setp.eq.s32 	%p117, %r183, 0;
	@%p117 bra 	$L__BB2_125;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd527, %fd526;

$L__BB2_125:
	mov.u32 	%r187, %tid.x;
	mov.u32 	%r186, %ntid.x;
	mov.u32 	%r185, %ctaid.x;
	mad.lo.s32 	%r184, %r185, %r186, %r187;
	mul.wide.s32 	%rd96, %r184, 8;
	ld.param.u64 	%rd95, [gcj02_to_wgs84_cuda_param_1];
	cvta.to.global.u64 	%rd94, %rd95;
	add.s64 	%rd93, %rd94, %rd96;
	ld.param.u64 	%rd92, [gcj02_to_wgs84_cuda_param_0];
	cvta.to.global.u64 	%rd91, %rd92;
	add.s64 	%rd90, %rd91, %rd96;
	mul.rn.f64 	%fd528, %fd596, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd596, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0dC15854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd600;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	st.global.f64 	[%rd90], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0dC1582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	st.global.f64 	[%rd93], %fd545;
	ret;

}
	// .globl	wgs84_to_gcj02_cuda
.visible .entry wgs84_to_gcj02_cuda(
	.param .u64 wgs84_to_gcj02_cuda_param_0,
	.param .u64 wgs84_to_gcj02_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot3[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<118>;
	.reg .b32 	%r<201>;
	.reg .f64 	%fd<601>;
	.reg .b64 	%rd<110>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [wgs84_to_gcj02_cuda_param_0];
	ld.param.u64 	%rd16, [wgs84_to_gcj02_cuda_param_1];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r48, %r46, %r45, %r47;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r48, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd9;
	}
	and.b32  	%r51, %r50, 2147483647;
	setp.eq.s32 	%p4, %r51, 2146435072;
	setp.eq.s32 	%p5, %r49, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB3_3;
	bra.uni 	$L__BB3_1;

$L__BB3_3:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd558, %fd9, %fd192;
	mov.u32 	%r188, 0;
	bra.uni 	$L__BB3_4;

$L__BB3_1:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r188, %fd183;
	st.local.u32 	[%rd1], %r188;
	cvt.rn.f64.s32 	%fd184, %r188;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd558, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p7, %fd191, 0d41E0000000000000;
	@%p7 bra 	$L__BB3_4;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd558, [retval0+0];
	} // callseq 26
	ld.local.u32 	%r188, [%rd1];

$L__BB3_4:
	and.b32  	%r53, %r188, 1;
	shl.b32 	%r54, %r188, 3;
	and.b32  	%r55, %r54, 8;
	setp.eq.s32 	%p8, %r53, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd33, %r55, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd194, [%rd35+8];
	mul.rn.f64 	%fd14, %fd558, %fd558;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd35+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd35+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd35+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd35+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd35+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd560, %fd15, %fd558, %fd558;
	@%p8 bra 	$L__BB3_6;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd560, %fd15, %fd14, %fd205;

$L__BB3_6:
	and.b32  	%r56, %r188, 2;
	setp.eq.s32 	%p9, %r56, 0;
	@%p9 bra 	$L__BB3_8;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd560, %fd560, %fd207, %fd206;

$L__BB3_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd21;
	}
	and.b32  	%r59, %r58, 2147483647;
	setp.eq.s32 	%p10, %r59, 2146435072;
	setp.eq.s32 	%p11, %r57, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB3_11;
	bra.uni 	$L__BB3_9;

$L__BB3_11:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd561, %fd21, %fd217;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB3_12;

$L__BB3_9:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd208;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd209, %r189;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd561, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p13, %fd216, 0d41E0000000000000;
	@%p13 bra 	$L__BB3_12;

	add.u64 	%rd98, %SP, 0;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd98;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd561, [retval0+0];
	} // callseq 27
	ld.local.u32 	%r189, [%rd1];

$L__BB3_12:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r61, %r189, 1;
	shl.b32 	%r62, %r189, 3;
	and.b32  	%r63, %r62, 8;
	setp.eq.s32 	%p14, %r61, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd37, %r63, 8;
	add.s64 	%rd39, %rd108, %rd37;
	ld.global.nc.f64 	%fd219, [%rd39+8];
	mul.rn.f64 	%fd26, %fd561, %fd561;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd39+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd39+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd39+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd39+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd39+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd563, %fd27, %fd561, %fd561;
	@%p14 bra 	$L__BB3_14;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd563, %fd27, %fd26, %fd230;

$L__BB3_14:
	and.b32  	%r64, %r189, 2;
	setp.eq.s32 	%p15, %r64, 0;
	@%p15 bra 	$L__BB3_16;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd563, %fd563, %fd232, %fd231;

$L__BB3_16:
	mul.rn.f64 	%fd233, %fd563, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd560, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd8;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.eq.s32 	%p16, %r66, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd8;
	}
	setp.eq.s32 	%p17, %r67, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB3_19;
	bra.uni 	$L__BB3_17;

$L__BB3_19:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd564, %fd8, %fd244;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB3_20;

$L__BB3_17:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd235;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd236, %r190;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd564, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p19, %fd243, 0d41E0000000000000;
	@%p19 bra 	$L__BB3_20;

	add.u64 	%rd80, %SP, 0;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd564, [retval0+0];
	} // callseq 28
	ld.local.u32 	%r190, [%rd1];

$L__BB3_20:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r69, %r190, 1;
	shl.b32 	%r70, %r190, 3;
	and.b32  	%r71, %r70, 8;
	setp.eq.s32 	%p20, %r69, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd41, %r71, 8;
	add.s64 	%rd43, %rd109, %rd41;
	ld.global.nc.f64 	%fd246, [%rd43+8];
	mul.rn.f64 	%fd38, %fd564, %fd564;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd43+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd43+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd43+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd43+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd43+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd566, %fd39, %fd564, %fd564;
	@%p20 bra 	$L__BB3_22;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd566, %fd39, %fd38, %fd257;

$L__BB3_22:
	and.b32  	%r72, %r190, 2;
	setp.eq.s32 	%p21, %r72, 0;
	@%p21 bra 	$L__BB3_24;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd566, %fd566, %fd259, %fd258;

$L__BB3_24:
	add.rn.f64 	%fd557, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd556, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd45;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.eq.s32 	%p22, %r75, 2146435072;
	setp.eq.s32 	%p23, %r73, 0;
	and.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB3_27;
	bra.uni 	$L__BB3_25;

$L__BB3_27:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd567, %fd45, %fd269;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB3_28;

$L__BB3_25:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd260;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd261, %r191;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd567, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p25, %fd268, 0d41E0000000000000;
	@%p25 bra 	$L__BB3_28;

	add.u64 	%rd81, %SP, 0;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd567, [retval0+0];
	} // callseq 29
	ld.local.u32 	%r191, [%rd1];

$L__BB3_28:
	mov.u64 	%rd99, __cudart_sin_cos_coeffs;
	and.b32  	%r77, %r191, 1;
	shl.b32 	%r78, %r191, 3;
	and.b32  	%r79, %r78, 8;
	setp.eq.s32 	%p26, %r77, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	mul.wide.s32 	%rd45, %r79, 8;
	add.s64 	%rd47, %rd99, %rd45;
	ld.global.nc.f64 	%fd271, [%rd47+8];
	mul.rn.f64 	%fd50, %fd567, %fd567;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd47+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd47+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd47+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd47+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd47+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd569, %fd51, %fd567, %fd567;
	@%p26 bra 	$L__BB3_30;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd569, %fd51, %fd50, %fd282;

$L__BB3_30:
	and.b32  	%r80, %r191, 2;
	setp.eq.s32 	%p27, %r80, 0;
	@%p27 bra 	$L__BB3_32;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd569, %fd569, %fd284, %fd283;

$L__BB3_32:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd569, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd566, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd58;
	}
	and.b32  	%r83, %r82, 2147483647;
	setp.eq.s32 	%p28, %r83, 2146435072;
	setp.eq.s32 	%p29, %r81, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB3_35;
	bra.uni 	$L__BB3_33;

$L__BB3_35:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd570, %fd58, %fd296;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB3_36;

$L__BB3_33:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd287;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd288, %r192;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd570, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p31, %fd295, 0d41E0000000000000;
	@%p31 bra 	$L__BB3_36;

	add.u64 	%rd82, %SP, 0;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd570, [retval0+0];
	} // callseq 30
	ld.local.u32 	%r192, [%rd1];

$L__BB3_36:
	mov.u64 	%rd100, __cudart_sin_cos_coeffs;
	and.b32  	%r85, %r192, 1;
	shl.b32 	%r86, %r192, 3;
	and.b32  	%r87, %r86, 8;
	setp.eq.s32 	%p32, %r85, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd49, %r87, 8;
	add.s64 	%rd51, %rd100, %rd49;
	ld.global.nc.f64 	%fd298, [%rd51+8];
	mul.rn.f64 	%fd63, %fd570, %fd570;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd51+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd51+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd51+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd51+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd51+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd572, %fd64, %fd570, %fd570;
	@%p32 bra 	$L__BB3_38;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd572, %fd64, %fd63, %fd309;

$L__BB3_38:
	and.b32  	%r88, %r192, 2;
	setp.eq.s32 	%p33, %r88, 0;
	@%p33 bra 	$L__BB3_40;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd572, %fd572, %fd311, %fd310;

$L__BB3_40:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd572, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd71;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p34, %r91, 2146435072;
	setp.eq.s32 	%p35, %r89, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB3_43;
	bra.uni 	$L__BB3_41;

$L__BB3_43:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd573, %fd71, %fd322;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB3_44;

$L__BB3_41:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd313;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd314, %r193;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd573, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p37, %fd321, 0d41E0000000000000;
	@%p37 bra 	$L__BB3_44;

	add.u64 	%rd83, %SP, 0;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd573, [retval0+0];
	} // callseq 31
	ld.local.u32 	%r193, [%rd1];

$L__BB3_44:
	mov.u64 	%rd101, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r193, 1;
	shl.b32 	%r94, %r193, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p38, %r93, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd53, %r95, 8;
	add.s64 	%rd55, %rd101, %rd53;
	ld.global.nc.f64 	%fd324, [%rd55+8];
	mul.rn.f64 	%fd76, %fd573, %fd573;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd55+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd55+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd55+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd55+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd55+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd575, %fd77, %fd573, %fd573;
	@%p38 bra 	$L__BB3_46;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd575, %fd77, %fd76, %fd335;

$L__BB3_46:
	and.b32  	%r96, %r193, 2;
	setp.eq.s32 	%p39, %r96, 0;
	@%p39 bra 	$L__BB3_48;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd575, %fd575, %fd337, %fd336;

$L__BB3_48:
	mul.rn.f64 	%fd338, %fd575, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd7;
	}
	and.b32  	%r98, %r97, 2147483647;
	setp.eq.s32 	%p40, %r98, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd7;
	}
	setp.eq.s32 	%p41, %r99, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB3_51;
	bra.uni 	$L__BB3_49;

$L__BB3_51:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd576, %fd7, %fd348;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB3_52;

$L__BB3_49:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd339;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd340, %r194;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd576, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p43, %fd347, 0d41E0000000000000;
	@%p43 bra 	$L__BB3_52;

	add.u64 	%rd84, %SP, 0;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd576, [retval0+0];
	} // callseq 32
	ld.local.u32 	%r194, [%rd1];

$L__BB3_52:
	mov.u64 	%rd102, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r194, 1;
	shl.b32 	%r102, %r194, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p44, %r101, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd57, %r103, 8;
	add.s64 	%rd59, %rd102, %rd57;
	ld.global.nc.f64 	%fd350, [%rd59+8];
	mul.rn.f64 	%fd88, %fd576, %fd576;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd59+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd59+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd59+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd59+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd59+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd578, %fd89, %fd576, %fd576;
	@%p44 bra 	$L__BB3_54;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd578, %fd89, %fd88, %fd361;

$L__BB3_54:
	and.b32  	%r104, %r194, 2;
	setp.eq.s32 	%p45, %r104, 0;
	@%p45 bra 	$L__BB3_56;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd578, %fd578, %fd363, %fd362;

$L__BB3_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r105, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd95;
	}
	and.b32  	%r107, %r106, 2147483647;
	setp.eq.s32 	%p46, %r107, 2146435072;
	setp.eq.s32 	%p47, %r105, 0;
	and.pred  	%p48, %p47, %p46;
	@%p48 bra 	$L__BB3_59;
	bra.uni 	$L__BB3_57;

$L__BB3_59:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd579, %fd95, %fd373;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB3_60;

$L__BB3_57:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd364;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd365, %r195;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd579, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p49, %fd372, 0d41E0000000000000;
	@%p49 bra 	$L__BB3_60;

	add.u64 	%rd85, %SP, 0;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd579, [retval0+0];
	} // callseq 33
	ld.local.u32 	%r195, [%rd1];

$L__BB3_60:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r109, %r195, 1;
	shl.b32 	%r110, %r195, 3;
	and.b32  	%r111, %r110, 8;
	setp.eq.s32 	%p50, %r109, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	mul.wide.s32 	%rd61, %r111, 8;
	add.s64 	%rd63, %rd103, %rd61;
	ld.global.nc.f64 	%fd375, [%rd63+8];
	mul.rn.f64 	%fd100, %fd579, %fd579;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd63+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd63+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd63+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd63+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd63+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd581, %fd101, %fd579, %fd579;
	@%p50 bra 	$L__BB3_62;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd581, %fd101, %fd100, %fd386;

$L__BB3_62:
	and.b32  	%r112, %r195, 2;
	setp.eq.s32 	%p51, %r112, 0;
	@%p51 bra 	$L__BB3_64;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd581, %fd581, %fd388, %fd387;

$L__BB3_64:
	mul.rn.f64 	%fd389, %fd581, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd578, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd108;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p52, %r115, 2146435072;
	setp.eq.s32 	%p53, %r113, 0;
	and.pred  	%p54, %p53, %p52;
	@%p54 bra 	$L__BB3_67;
	bra.uni 	$L__BB3_65;

$L__BB3_67:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd582, %fd108, %fd400;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB3_68;

$L__BB3_65:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd391;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd392, %r196;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd582, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p55, %fd399, 0d41E0000000000000;
	@%p55 bra 	$L__BB3_68;

	add.u64 	%rd86, %SP, 0;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd86;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd582, [retval0+0];
	} // callseq 34
	ld.local.u32 	%r196, [%rd1];

$L__BB3_68:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r117, %r196, 1;
	shl.b32 	%r118, %r196, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p56, %r117, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p56;
	mul.wide.s32 	%rd65, %r119, 8;
	add.s64 	%rd67, %rd104, %rd65;
	ld.global.nc.f64 	%fd402, [%rd67+8];
	mul.rn.f64 	%fd113, %fd582, %fd582;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd67+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd67+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd67+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd67+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd67+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd584, %fd114, %fd582, %fd582;
	@%p56 bra 	$L__BB3_70;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd584, %fd114, %fd113, %fd413;

$L__BB3_70:
	and.b32  	%r120, %r196, 2;
	setp.eq.s32 	%p57, %r120, 0;
	@%p57 bra 	$L__BB3_72;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd584, %fd584, %fd415, %fd414;

$L__BB3_72:
	mul.rn.f64 	%fd416, %fd584, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd121;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p58, %r123, 2146435072;
	setp.eq.s32 	%p59, %r121, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB3_75;
	bra.uni 	$L__BB3_73;

$L__BB3_75:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd585, %fd121, %fd426;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB3_76;

$L__BB3_73:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd417;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd418, %r197;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd585, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p61, %fd425, 0d41E0000000000000;
	@%p61 bra 	$L__BB3_76;

	add.u64 	%rd87, %SP, 0;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd585, [retval0+0];
	} // callseq 35
	ld.local.u32 	%r197, [%rd1];

$L__BB3_76:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r125, %r197, 1;
	shl.b32 	%r126, %r197, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p62, %r125, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd105, %rd69;
	ld.global.nc.f64 	%fd428, [%rd71+8];
	mul.rn.f64 	%fd126, %fd585, %fd585;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd71+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd71+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd71+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd71+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd71+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd587, %fd127, %fd585, %fd585;
	@%p62 bra 	$L__BB3_78;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd587, %fd127, %fd126, %fd439;

$L__BB3_78:
	and.b32  	%r128, %r197, 2;
	setp.eq.s32 	%p63, %r128, 0;
	@%p63 bra 	$L__BB3_80;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd587, %fd587, %fd441, %fd440;

$L__BB3_80:
	mul.rn.f64 	%fd442, %fd587, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd445;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p64, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd590, [retval0+0];
	} // callseq 36
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p65, %r33, 0;
	and.pred  	%p1, %p65, %p64;
	not.pred 	%p66, %p1;
	@%p66 bra 	$L__BB3_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd590;
	}
	xor.b32  	%r130, %r129, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd590;
	}
	mov.b64 	%fd590, {%r131, %r130};

$L__BB3_82:
	setp.eq.f64 	%p67, %fd4, 0d0000000000000000;
	@%p67 bra 	$L__BB3_86;
	bra.uni 	$L__BB3_83;

$L__BB3_86:
	selp.b32 	%r132, %r33, 0, %p64;
	mov.u32 	%r133, 0;
	or.b32  	%r134, %r132, 2146435072;
	setp.lt.s32 	%p71, %r31, 0;
	selp.b32 	%r135, %r134, %r132, %p71;
	mov.b64 	%fd590, {%r133, %r135};
	bra.uni 	$L__BB3_87;

$L__BB3_83:
	setp.gt.s32 	%p68, %r33, -1;
	@%p68 bra 	$L__BB3_87;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p69, %fd449, 0d4000000000000000;
	@%p69 bra 	$L__BB3_87;

	mov.f64 	%fd590, 0dFFF8000000000000;

$L__BB3_87:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd451;
	}
	and.b32  	%r137, %r136, 2146435072;
	setp.ne.s32 	%p72, %r137, 2146435072;
	@%p72 bra 	$L__BB3_94;

	setp.gtu.f64 	%p73, %fd136, 0d7FF0000000000000;
	@%p73 bra 	$L__BB3_93;
	bra.uni 	$L__BB3_89;

$L__BB3_93:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd590, %fd4, %fd453;
	bra.uni 	$L__BB3_94;

$L__BB3_89:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd452;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p74, %r34, 2146435072;
	setp.eq.s32 	%p75, %r138, 0;
	and.pred  	%p76, %p74, %p75;
	@%p76 bra 	$L__BB3_92;
	bra.uni 	$L__BB3_90;

$L__BB3_92:
	setp.gt.f64 	%p83, %fd136, 0d3FF0000000000000;
	selp.b32 	%r145, 2146435072, 0, %p83;
	mov.u32 	%r146, 0;
	xor.b32  	%r147, %r145, 2146435072;
	setp.lt.s32 	%p84, %r31, 0;
	selp.b32 	%r148, %r147, %r145, %p84;
	setp.eq.f64 	%p85, %fd4, 0dBFF0000000000000;
	selp.b32 	%r149, 1072693248, %r148, %p85;
	mov.b64 	%fd590, {%r146, %r149};
	bra.uni 	$L__BB3_94;

$L__BB3_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd4;
	}
	and.b32  	%r140, %r33, 2147483647;
	setp.ne.s32 	%p77, %r140, 2146435072;
	setp.ne.s32 	%p78, %r139, 0;
	or.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB3_94;

	setp.gt.s32 	%p80, %r31, -1;
	selp.b32 	%r141, 2146435072, 0, %p80;
	mov.u32 	%r142, 0;
	setp.ne.s32 	%p81, %r34, 1071644672;
	and.pred  	%p82, %p81, %p1;
	or.b32  	%r143, %r141, -2147483648;
	selp.b32 	%r144, %r143, %r141, %p82;
	mov.b64 	%fd590, {%r142, %r144};

$L__BB3_94:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd590, 0d3FC999999999999A;
	setp.eq.f64 	%p86, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p86;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd593, [retval0+0];
	} // callseq 37
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd547;
	}
	setp.lt.s32 	%p87, %r35, 0;
	and.pred  	%p2, %p87, %p64;
	not.pred 	%p89, %p2;
	@%p89 bra 	$L__BB3_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd593;
	}
	xor.b32  	%r151, %r150, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd593;
	}
	mov.b64 	%fd593, {%r152, %r151};

$L__BB3_96:
	setp.eq.f64 	%p90, %fd2, 0d0000000000000000;
	@%p90 bra 	$L__BB3_100;
	bra.uni 	$L__BB3_97;

$L__BB3_100:
	selp.b32 	%r153, %r35, 0, %p64;
	mov.u32 	%r154, 0;
	or.b32  	%r155, %r153, 2146435072;
	setp.lt.s32 	%p94, %r31, 0;
	selp.b32 	%r156, %r155, %r153, %p94;
	mov.b64 	%fd593, {%r154, %r156};
	bra.uni 	$L__BB3_101;

$L__BB3_97:
	setp.gt.s32 	%p91, %r35, -1;
	@%p91 bra 	$L__BB3_101;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p92, %fd465, 0d4000000000000000;
	@%p92 bra 	$L__BB3_101;

	mov.f64 	%fd593, 0dFFF8000000000000;

$L__BB3_101:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd467;
	}
	and.b32  	%r158, %r157, 2146435072;
	setp.ne.s32 	%p95, %r158, 2146435072;
	@%p95 bra 	$L__BB3_108;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p96, %fd548, 0d7FF0000000000000;
	@%p96 bra 	$L__BB3_107;
	bra.uni 	$L__BB3_103;

$L__BB3_107:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd593, %fd2, %fd469;
	bra.uni 	$L__BB3_108;

$L__BB3_103:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd468;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p97, %r36, 2146435072;
	setp.eq.s32 	%p98, %r159, 0;
	and.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB3_106;
	bra.uni 	$L__BB3_104;

$L__BB3_106:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p106, %fd550, 0d3FF0000000000000;
	selp.b32 	%r166, 2146435072, 0, %p106;
	mov.u32 	%r167, 0;
	xor.b32  	%r168, %r166, 2146435072;
	setp.lt.s32 	%p107, %r31, 0;
	selp.b32 	%r169, %r168, %r166, %p107;
	setp.eq.f64 	%p108, %fd551, 0dBFF0000000000000;
	selp.b32 	%r170, 1072693248, %r169, %p108;
	mov.b64 	%fd593, {%r167, %r170};
	bra.uni 	$L__BB3_108;

$L__BB3_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd2;
	}
	and.b32  	%r161, %r35, 2147483647;
	setp.ne.s32 	%p100, %r161, 2146435072;
	setp.ne.s32 	%p101, %r160, 0;
	or.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB3_108;

	setp.gt.s32 	%p103, %r31, -1;
	selp.b32 	%r162, 2146435072, 0, %p103;
	mov.u32 	%r163, 0;
	setp.ne.s32 	%p104, %r36, 1071644672;
	and.pred  	%p105, %p104, %p2;
	or.b32  	%r164, %r162, -2147483648;
	selp.b32 	%r165, %r164, %r162, %p105;
	mov.b64 	%fd593, {%r163, %r165};

$L__BB3_108:
	mul.rn.f64 	%fd470, %fd593, 0d3FB999999999999A;
	setp.eq.f64 	%p109, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p109;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd159;
	}
	and.b32  	%r173, %r172, 2147483647;
	setp.eq.s32 	%p110, %r173, 2146435072;
	setp.eq.s32 	%p111, %r171, 0;
	and.pred  	%p3, %p111, %p110;
	@%p3 bra 	$L__BB3_111;
	bra.uni 	$L__BB3_109;

$L__BB3_111:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd594, %fd159, %fd487;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB3_112;

$L__BB3_109:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd478;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd479, %r198;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd594, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p112, %fd486, 0d41E0000000000000;
	@%p112 bra 	$L__BB3_112;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 38
	ld.local.u32 	%r198, [%rd1];

$L__BB3_112:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r175, %r198, 1;
	shl.b32 	%r176, %r198, 3;
	and.b32  	%r177, %r176, 8;
	setp.eq.s32 	%p113, %r175, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd73, %r177, 8;
	add.s64 	%rd75, %rd106, %rd73;
	ld.global.nc.f64 	%fd489, [%rd75+8];
	mul.rn.f64 	%fd164, %fd594, %fd594;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd75+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd75+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd75+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd75+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd75+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd596, %fd165, %fd594, %fd594;
	@%p113 bra 	$L__BB3_114;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd596, %fd165, %fd164, %fd500;

$L__BB3_114:
	and.b32  	%r178, %r198, 2;
	setp.eq.s32 	%p114, %r178, 0;
	@%p114 bra 	$L__BB3_116;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd596, %fd596, %fd502, %fd501;

$L__BB3_116:
	@%p3 bra 	$L__BB3_120;
	bra.uni 	$L__BB3_117;

$L__BB3_120:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd512;
	mov.u32 	%r200, 1;
	bra.uni 	$L__BB3_121;

$L__BB3_117:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd503;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd504, %r199;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p115, %fd511, 0d41E0000000000000;
	@%p115 bra 	$L__BB3_119;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 39
	ld.local.u32 	%r199, [%rd1];

$L__BB3_119:
	add.s32 	%r200, %r199, 1;

$L__BB3_121:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r180, %r200, 1;
	shl.b32 	%r181, %r200, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p116, %r180, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd77, %r182, 8;
	add.s64 	%rd79, %rd107, %rd77;
	ld.global.nc.f64 	%fd514, [%rd79+8];
	mul.rn.f64 	%fd176, %fd598, %fd598;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd79+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd79+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd79+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd79+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd79+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd600, %fd177, %fd598, %fd598;
	@%p116 bra 	$L__BB3_123;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd177, %fd176, %fd525;

$L__BB3_123:
	and.b32  	%r183, %r200, 2;
	setp.eq.s32 	%p117, %r183, 0;
	@%p117 bra 	$L__BB3_125;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd527, %fd526;

$L__BB3_125:
	mov.u32 	%r187, %tid.x;
	mov.u32 	%r186, %ntid.x;
	mov.u32 	%r185, %ctaid.x;
	mad.lo.s32 	%r184, %r185, %r186, %r187;
	mul.wide.s32 	%rd96, %r184, 8;
	ld.param.u64 	%rd95, [wgs84_to_gcj02_cuda_param_1];
	cvta.to.global.u64 	%rd94, %rd95;
	add.s64 	%rd93, %rd94, %rd96;
	ld.param.u64 	%rd92, [wgs84_to_gcj02_cuda_param_0];
	cvta.to.global.u64 	%rd91, %rd92;
	add.s64 	%rd90, %rd91, %rd96;
	mul.rn.f64 	%fd528, %fd596, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd596, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0d415854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd600;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	st.global.f64 	[%rd90], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0d41582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	st.global.f64 	[%rd93], %fd545;
	ret;

}
	// .globl	wgs84_to_bd09_cuda
.visible .entry wgs84_to_bd09_cuda(
	.param .u64 wgs84_to_bd09_cuda_param_0,
	.param .u64 wgs84_to_bd09_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot4[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<198>;
	.reg .b32 	%r<318>;
	.reg .f64 	%fd<878>;
	.reg .b64 	%rd<150>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [wgs84_to_bd09_cuda_param_0];
	ld.param.u64 	%rd20, [wgs84_to_bd09_cuda_param_1];
	cvta.to.global.u64 	%rd21, %rd20;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd38, %rd19;
	mul.wide.s32 	%rd39, %r68, 8;
	add.s64 	%rd17, %rd38, %rd39;
	add.s64 	%rd18, %rd21, %rd39;
	ld.global.f64 	%fd1, [%rd17];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd18];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd9;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p7, %r71, 2146435072;
	setp.eq.s32 	%p8, %r69, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB4_3;
	bra.uni 	$L__BB4_1;

$L__BB4_3:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd814, %fd9, %fd269;
	mov.u32 	%r299, 0;
	bra.uni 	$L__BB4_4;

$L__BB4_1:
	mul.rn.f64 	%fd260, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd260;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd261, %r299;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd9;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd814, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd9;
	setp.ltu.f64 	%p10, %fd268, 0d41E0000000000000;
	@%p10 bra 	$L__BB4_4;

	add.u64 	%rd147, %SP, 0;
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd814, [retval0+0];
	} // callseq 40
	ld.local.u32 	%r299, [%rd1];

$L__BB4_4:
	and.b32  	%r73, %r299, 1;
	shl.b32 	%r74, %r299, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p11, %r73, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p11;
	mul.wide.s32 	%rd41, %r75, 8;
	mov.u64 	%rd42, __cudart_sin_cos_coeffs;
	add.s64 	%rd43, %rd42, %rd41;
	ld.global.nc.f64 	%fd271, [%rd43+8];
	mul.rn.f64 	%fd14, %fd814, %fd814;
	fma.rn.f64 	%fd272, %fd270, %fd14, %fd271;
	ld.global.nc.f64 	%fd273, [%rd43+16];
	fma.rn.f64 	%fd274, %fd272, %fd14, %fd273;
	ld.global.nc.f64 	%fd275, [%rd43+24];
	fma.rn.f64 	%fd276, %fd274, %fd14, %fd275;
	ld.global.nc.f64 	%fd277, [%rd43+32];
	fma.rn.f64 	%fd278, %fd276, %fd14, %fd277;
	ld.global.nc.f64 	%fd279, [%rd43+40];
	fma.rn.f64 	%fd280, %fd278, %fd14, %fd279;
	ld.global.nc.f64 	%fd281, [%rd43+48];
	fma.rn.f64 	%fd15, %fd280, %fd14, %fd281;
	fma.rn.f64 	%fd816, %fd15, %fd814, %fd814;
	@%p11 bra 	$L__BB4_6;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd816, %fd15, %fd14, %fd282;

$L__BB4_6:
	and.b32  	%r76, %r299, 2;
	setp.eq.s32 	%p12, %r76, 0;
	@%p12 bra 	$L__BB4_8;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd816, %fd816, %fd284, %fd283;

$L__BB4_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd21;
	}
	and.b32  	%r79, %r78, 2147483647;
	setp.eq.s32 	%p13, %r79, 2146435072;
	setp.eq.s32 	%p14, %r77, 0;
	and.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB4_11;
	bra.uni 	$L__BB4_9;

$L__BB4_11:
	mov.f64 	%fd294, 0d0000000000000000;
	mul.rn.f64 	%fd817, %fd21, %fd294;
	mov.u32 	%r300, 0;
	bra.uni 	$L__BB4_12;

$L__BB4_9:
	mul.rn.f64 	%fd285, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r300, %fd285;
	st.local.u32 	[%rd1], %r300;
	cvt.rn.f64.s32 	%fd286, %r300;
	neg.f64 	%fd287, %fd286;
	mov.f64 	%fd288, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd289, %fd287, %fd288, %fd21;
	mov.f64 	%fd290, 0d3C91A62633145C00;
	fma.rn.f64 	%fd291, %fd287, %fd290, %fd289;
	mov.f64 	%fd292, 0d397B839A252049C0;
	fma.rn.f64 	%fd817, %fd287, %fd292, %fd291;
	abs.f64 	%fd293, %fd21;
	setp.ltu.f64 	%p16, %fd293, 0d41E0000000000000;
	@%p16 bra 	$L__BB4_12;

	add.u64 	%rd148, %SP, 0;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd817, [retval0+0];
	} // callseq 41
	ld.local.u32 	%r300, [%rd1];

$L__BB4_12:
	mov.u64 	%rd149, __cudart_sin_cos_coeffs;
	and.b32  	%r81, %r300, 1;
	shl.b32 	%r82, %r300, 3;
	and.b32  	%r83, %r82, 8;
	setp.eq.s32 	%p17, %r81, 0;
	selp.f64 	%fd295, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	mul.wide.s32 	%rd45, %r83, 8;
	add.s64 	%rd47, %rd149, %rd45;
	ld.global.nc.f64 	%fd296, [%rd47+8];
	mul.rn.f64 	%fd26, %fd817, %fd817;
	fma.rn.f64 	%fd297, %fd295, %fd26, %fd296;
	ld.global.nc.f64 	%fd298, [%rd47+16];
	fma.rn.f64 	%fd299, %fd297, %fd26, %fd298;
	ld.global.nc.f64 	%fd300, [%rd47+24];
	fma.rn.f64 	%fd301, %fd299, %fd26, %fd300;
	ld.global.nc.f64 	%fd302, [%rd47+32];
	fma.rn.f64 	%fd303, %fd301, %fd26, %fd302;
	ld.global.nc.f64 	%fd304, [%rd47+40];
	fma.rn.f64 	%fd305, %fd303, %fd26, %fd304;
	ld.global.nc.f64 	%fd306, [%rd47+48];
	fma.rn.f64 	%fd27, %fd305, %fd26, %fd306;
	fma.rn.f64 	%fd819, %fd27, %fd817, %fd817;
	@%p17 bra 	$L__BB4_14;

	mov.f64 	%fd307, 0d3FF0000000000000;
	fma.rn.f64 	%fd819, %fd27, %fd26, %fd307;

$L__BB4_14:
	and.b32  	%r84, %r300, 2;
	setp.eq.s32 	%p18, %r84, 0;
	@%p18 bra 	$L__BB4_16;

	mov.f64 	%fd308, 0d0000000000000000;
	mov.f64 	%fd309, 0dBFF0000000000000;
	fma.rn.f64 	%fd819, %fd819, %fd309, %fd308;

$L__BB4_16:
	mul.rn.f64 	%fd310, %fd819, 0d4034000000000000;
	mul.rn.f64 	%fd311, %fd816, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd311, %fd310;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd8;
	}
	and.b32  	%r86, %r85, 2147483647;
	setp.eq.s32 	%p19, %r86, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd8;
	}
	setp.eq.s32 	%p20, %r87, 0;
	and.pred  	%p21, %p20, %p19;
	@%p21 bra 	$L__BB4_19;
	bra.uni 	$L__BB4_17;

$L__BB4_19:
	mov.f64 	%fd321, 0d0000000000000000;
	mul.rn.f64 	%fd820, %fd8, %fd321;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB4_20;

$L__BB4_17:
	mul.rn.f64 	%fd312, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd312;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd313, %r301;
	neg.f64 	%fd314, %fd313;
	mov.f64 	%fd315, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd316, %fd314, %fd315, %fd8;
	mov.f64 	%fd317, 0d3C91A62633145C00;
	fma.rn.f64 	%fd318, %fd314, %fd317, %fd316;
	mov.f64 	%fd319, 0d397B839A252049C0;
	fma.rn.f64 	%fd820, %fd314, %fd319, %fd318;
	abs.f64 	%fd320, %fd8;
	setp.ltu.f64 	%p22, %fd320, 0d41E0000000000000;
	@%p22 bra 	$L__BB4_20;

	add.u64 	%rd131, %SP, 0;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd131;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd820, [retval0+0];
	} // callseq 42
	ld.local.u32 	%r301, [%rd1];

$L__BB4_20:
	mov.u64 	%rd132, __cudart_sin_cos_coeffs;
	and.b32  	%r89, %r301, 1;
	shl.b32 	%r90, %r301, 3;
	and.b32  	%r91, %r90, 8;
	setp.eq.s32 	%p23, %r89, 0;
	selp.f64 	%fd322, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p23;
	mul.wide.s32 	%rd49, %r91, 8;
	add.s64 	%rd51, %rd132, %rd49;
	ld.global.nc.f64 	%fd323, [%rd51+8];
	mul.rn.f64 	%fd38, %fd820, %fd820;
	fma.rn.f64 	%fd324, %fd322, %fd38, %fd323;
	ld.global.nc.f64 	%fd325, [%rd51+16];
	fma.rn.f64 	%fd326, %fd324, %fd38, %fd325;
	ld.global.nc.f64 	%fd327, [%rd51+24];
	fma.rn.f64 	%fd328, %fd326, %fd38, %fd327;
	ld.global.nc.f64 	%fd329, [%rd51+32];
	fma.rn.f64 	%fd330, %fd328, %fd38, %fd329;
	ld.global.nc.f64 	%fd331, [%rd51+40];
	fma.rn.f64 	%fd332, %fd330, %fd38, %fd331;
	ld.global.nc.f64 	%fd333, [%rd51+48];
	fma.rn.f64 	%fd39, %fd332, %fd38, %fd333;
	fma.rn.f64 	%fd822, %fd39, %fd820, %fd820;
	@%p23 bra 	$L__BB4_22;

	mov.f64 	%fd334, 0d3FF0000000000000;
	fma.rn.f64 	%fd822, %fd39, %fd38, %fd334;

$L__BB4_22:
	and.b32  	%r92, %r301, 2;
	setp.eq.s32 	%p24, %r92, 0;
	@%p24 bra 	$L__BB4_24;

	mov.f64 	%fd335, 0d0000000000000000;
	mov.f64 	%fd336, 0dBFF0000000000000;
	fma.rn.f64 	%fd822, %fd822, %fd336, %fd335;

$L__BB4_24:
	add.rn.f64 	%fd811, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd810, %fd811, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd810, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd45;
	}
	and.b32  	%r95, %r94, 2147483647;
	setp.eq.s32 	%p25, %r95, 2146435072;
	setp.eq.s32 	%p26, %r93, 0;
	and.pred  	%p27, %p26, %p25;
	@%p27 bra 	$L__BB4_27;
	bra.uni 	$L__BB4_25;

$L__BB4_27:
	mov.f64 	%fd346, 0d0000000000000000;
	mul.rn.f64 	%fd823, %fd45, %fd346;
	mov.u32 	%r302, 0;
	bra.uni 	$L__BB4_28;

$L__BB4_25:
	mul.rn.f64 	%fd337, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd337;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd338, %r302;
	neg.f64 	%fd339, %fd338;
	mov.f64 	%fd340, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd341, %fd339, %fd340, %fd45;
	mov.f64 	%fd342, 0d3C91A62633145C00;
	fma.rn.f64 	%fd343, %fd339, %fd342, %fd341;
	mov.f64 	%fd344, 0d397B839A252049C0;
	fma.rn.f64 	%fd823, %fd339, %fd344, %fd343;
	abs.f64 	%fd345, %fd45;
	setp.ltu.f64 	%p28, %fd345, 0d41E0000000000000;
	@%p28 bra 	$L__BB4_28;

	add.u64 	%rd133, %SP, 0;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd133;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 43
	ld.local.u32 	%r302, [%rd1];

$L__BB4_28:
	mov.u64 	%rd134, __cudart_sin_cos_coeffs;
	and.b32  	%r97, %r302, 1;
	shl.b32 	%r98, %r302, 3;
	and.b32  	%r99, %r98, 8;
	setp.eq.s32 	%p29, %r97, 0;
	selp.f64 	%fd347, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p29;
	mul.wide.s32 	%rd53, %r99, 8;
	add.s64 	%rd55, %rd134, %rd53;
	ld.global.nc.f64 	%fd348, [%rd55+8];
	mul.rn.f64 	%fd50, %fd823, %fd823;
	fma.rn.f64 	%fd349, %fd347, %fd50, %fd348;
	ld.global.nc.f64 	%fd350, [%rd55+16];
	fma.rn.f64 	%fd351, %fd349, %fd50, %fd350;
	ld.global.nc.f64 	%fd352, [%rd55+24];
	fma.rn.f64 	%fd353, %fd351, %fd50, %fd352;
	ld.global.nc.f64 	%fd354, [%rd55+32];
	fma.rn.f64 	%fd355, %fd353, %fd50, %fd354;
	ld.global.nc.f64 	%fd356, [%rd55+40];
	fma.rn.f64 	%fd357, %fd355, %fd50, %fd356;
	ld.global.nc.f64 	%fd358, [%rd55+48];
	fma.rn.f64 	%fd51, %fd357, %fd50, %fd358;
	fma.rn.f64 	%fd825, %fd51, %fd823, %fd823;
	@%p29 bra 	$L__BB4_30;

	mov.f64 	%fd359, 0d3FF0000000000000;
	fma.rn.f64 	%fd825, %fd51, %fd50, %fd359;

$L__BB4_30:
	and.b32  	%r100, %r302, 2;
	setp.eq.s32 	%p30, %r100, 0;
	@%p30 bra 	$L__BB4_32;

	mov.f64 	%fd360, 0d0000000000000000;
	mov.f64 	%fd361, 0dBFF0000000000000;
	fma.rn.f64 	%fd825, %fd825, %fd361, %fd360;

$L__BB4_32:
	add.rn.f64 	%fd803, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd802, %fd803, 0d400921FB54442D18;
	mul.rn.f64 	%fd362, %fd825, 0d4044000000000000;
	mul.rn.f64 	%fd363, %fd822, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd363, %fd362;
	div.rn.f64 	%fd58, %fd802, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r101, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r102}, %fd58;
	}
	and.b32  	%r103, %r102, 2147483647;
	setp.eq.s32 	%p31, %r103, 2146435072;
	setp.eq.s32 	%p32, %r101, 0;
	and.pred  	%p33, %p32, %p31;
	@%p33 bra 	$L__BB4_35;
	bra.uni 	$L__BB4_33;

$L__BB4_35:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd826, %fd58, %fd373;
	mov.u32 	%r303, 0;
	bra.uni 	$L__BB4_36;

$L__BB4_33:
	mul.rn.f64 	%fd364, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r303, %fd364;
	st.local.u32 	[%rd1], %r303;
	cvt.rn.f64.s32 	%fd365, %r303;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd58;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd826, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd58;
	setp.ltu.f64 	%p34, %fd372, 0d41E0000000000000;
	@%p34 bra 	$L__BB4_36;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd826, [retval0+0];
	} // callseq 44
	ld.local.u32 	%r303, [%rd1];

$L__BB4_36:
	mov.u64 	%rd136, __cudart_sin_cos_coeffs;
	and.b32  	%r105, %r303, 1;
	shl.b32 	%r106, %r303, 3;
	and.b32  	%r107, %r106, 8;
	setp.eq.s32 	%p35, %r105, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p35;
	mul.wide.s32 	%rd57, %r107, 8;
	add.s64 	%rd59, %rd136, %rd57;
	ld.global.nc.f64 	%fd375, [%rd59+8];
	mul.rn.f64 	%fd63, %fd826, %fd826;
	fma.rn.f64 	%fd376, %fd374, %fd63, %fd375;
	ld.global.nc.f64 	%fd377, [%rd59+16];
	fma.rn.f64 	%fd378, %fd376, %fd63, %fd377;
	ld.global.nc.f64 	%fd379, [%rd59+24];
	fma.rn.f64 	%fd380, %fd378, %fd63, %fd379;
	ld.global.nc.f64 	%fd381, [%rd59+32];
	fma.rn.f64 	%fd382, %fd380, %fd63, %fd381;
	ld.global.nc.f64 	%fd383, [%rd59+40];
	fma.rn.f64 	%fd384, %fd382, %fd63, %fd383;
	ld.global.nc.f64 	%fd385, [%rd59+48];
	fma.rn.f64 	%fd64, %fd384, %fd63, %fd385;
	fma.rn.f64 	%fd828, %fd64, %fd826, %fd826;
	@%p35 bra 	$L__BB4_38;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd828, %fd64, %fd63, %fd386;

$L__BB4_38:
	and.b32  	%r108, %r303, 2;
	setp.eq.s32 	%p36, %r108, 0;
	@%p36 bra 	$L__BB4_40;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd828, %fd828, %fd388, %fd387;

$L__BB4_40:
	add.rn.f64 	%fd805, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd804, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd389, %fd828, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd389;
	div.rn.f64 	%fd71, %fd804, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r109, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd71;
	}
	and.b32  	%r111, %r110, 2147483647;
	setp.eq.s32 	%p37, %r111, 2146435072;
	setp.eq.s32 	%p38, %r109, 0;
	and.pred  	%p39, %p38, %p37;
	@%p39 bra 	$L__BB4_43;
	bra.uni 	$L__BB4_41;

$L__BB4_43:
	mov.f64 	%fd399, 0d0000000000000000;
	mul.rn.f64 	%fd829, %fd71, %fd399;
	mov.u32 	%r304, 0;
	bra.uni 	$L__BB4_44;

$L__BB4_41:
	mul.rn.f64 	%fd390, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd390;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd391, %r304;
	neg.f64 	%fd392, %fd391;
	mov.f64 	%fd393, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd394, %fd392, %fd393, %fd71;
	mov.f64 	%fd395, 0d3C91A62633145C00;
	fma.rn.f64 	%fd396, %fd392, %fd395, %fd394;
	mov.f64 	%fd397, 0d397B839A252049C0;
	fma.rn.f64 	%fd829, %fd392, %fd397, %fd396;
	abs.f64 	%fd398, %fd71;
	setp.ltu.f64 	%p40, %fd398, 0d41E0000000000000;
	@%p40 bra 	$L__BB4_44;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd829, [retval0+0];
	} // callseq 45
	ld.local.u32 	%r304, [%rd1];

$L__BB4_44:
	mov.u64 	%rd138, __cudart_sin_cos_coeffs;
	and.b32  	%r113, %r304, 1;
	shl.b32 	%r114, %r304, 3;
	and.b32  	%r115, %r114, 8;
	setp.eq.s32 	%p41, %r113, 0;
	selp.f64 	%fd400, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p41;
	mul.wide.s32 	%rd61, %r115, 8;
	add.s64 	%rd63, %rd138, %rd61;
	ld.global.nc.f64 	%fd401, [%rd63+8];
	mul.rn.f64 	%fd76, %fd829, %fd829;
	fma.rn.f64 	%fd402, %fd400, %fd76, %fd401;
	ld.global.nc.f64 	%fd403, [%rd63+16];
	fma.rn.f64 	%fd404, %fd402, %fd76, %fd403;
	ld.global.nc.f64 	%fd405, [%rd63+24];
	fma.rn.f64 	%fd406, %fd404, %fd76, %fd405;
	ld.global.nc.f64 	%fd407, [%rd63+32];
	fma.rn.f64 	%fd408, %fd406, %fd76, %fd407;
	ld.global.nc.f64 	%fd409, [%rd63+40];
	fma.rn.f64 	%fd410, %fd408, %fd76, %fd409;
	ld.global.nc.f64 	%fd411, [%rd63+48];
	fma.rn.f64 	%fd77, %fd410, %fd76, %fd411;
	fma.rn.f64 	%fd831, %fd77, %fd829, %fd829;
	@%p41 bra 	$L__BB4_46;

	mov.f64 	%fd412, 0d3FF0000000000000;
	fma.rn.f64 	%fd831, %fd77, %fd76, %fd412;

$L__BB4_46:
	and.b32  	%r116, %r304, 2;
	setp.eq.s32 	%p42, %r116, 0;
	@%p42 bra 	$L__BB4_48;

	mov.f64 	%fd413, 0d0000000000000000;
	mov.f64 	%fd414, 0dBFF0000000000000;
	fma.rn.f64 	%fd831, %fd831, %fd414, %fd413;

$L__BB4_48:
	mul.rn.f64 	%fd415, %fd831, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd415;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd7;
	}
	and.b32  	%r118, %r117, 2147483647;
	setp.eq.s32 	%p43, %r118, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd7;
	}
	setp.eq.s32 	%p44, %r119, 0;
	and.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB4_51;
	bra.uni 	$L__BB4_49;

$L__BB4_51:
	mov.f64 	%fd425, 0d0000000000000000;
	mul.rn.f64 	%fd832, %fd7, %fd425;
	mov.u32 	%r305, 0;
	bra.uni 	$L__BB4_52;

$L__BB4_49:
	mul.rn.f64 	%fd416, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r305, %fd416;
	st.local.u32 	[%rd1], %r305;
	cvt.rn.f64.s32 	%fd417, %r305;
	neg.f64 	%fd418, %fd417;
	mov.f64 	%fd419, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd420, %fd418, %fd419, %fd7;
	mov.f64 	%fd421, 0d3C91A62633145C00;
	fma.rn.f64 	%fd422, %fd418, %fd421, %fd420;
	mov.f64 	%fd423, 0d397B839A252049C0;
	fma.rn.f64 	%fd832, %fd418, %fd423, %fd422;
	abs.f64 	%fd424, %fd7;
	setp.ltu.f64 	%p46, %fd424, 0d41E0000000000000;
	@%p46 bra 	$L__BB4_52;

	add.u64 	%rd104, %SP, 0;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd104;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 46
	ld.local.u32 	%r305, [%rd1];

$L__BB4_52:
	mov.u64 	%rd139, __cudart_sin_cos_coeffs;
	and.b32  	%r121, %r305, 1;
	shl.b32 	%r122, %r305, 3;
	and.b32  	%r123, %r122, 8;
	setp.eq.s32 	%p47, %r121, 0;
	selp.f64 	%fd426, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p47;
	mul.wide.s32 	%rd65, %r123, 8;
	add.s64 	%rd67, %rd139, %rd65;
	ld.global.nc.f64 	%fd427, [%rd67+8];
	mul.rn.f64 	%fd88, %fd832, %fd832;
	fma.rn.f64 	%fd428, %fd426, %fd88, %fd427;
	ld.global.nc.f64 	%fd429, [%rd67+16];
	fma.rn.f64 	%fd430, %fd428, %fd88, %fd429;
	ld.global.nc.f64 	%fd431, [%rd67+24];
	fma.rn.f64 	%fd432, %fd430, %fd88, %fd431;
	ld.global.nc.f64 	%fd433, [%rd67+32];
	fma.rn.f64 	%fd434, %fd432, %fd88, %fd433;
	ld.global.nc.f64 	%fd435, [%rd67+40];
	fma.rn.f64 	%fd436, %fd434, %fd88, %fd435;
	ld.global.nc.f64 	%fd437, [%rd67+48];
	fma.rn.f64 	%fd89, %fd436, %fd88, %fd437;
	fma.rn.f64 	%fd834, %fd89, %fd832, %fd832;
	@%p47 bra 	$L__BB4_54;

	mov.f64 	%fd438, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd89, %fd88, %fd438;

$L__BB4_54:
	and.b32  	%r124, %r305, 2;
	setp.eq.s32 	%p48, %r124, 0;
	@%p48 bra 	$L__BB4_56;

	mov.f64 	%fd439, 0d0000000000000000;
	mov.f64 	%fd440, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd440, %fd439;

$L__BB4_56:
	add.rn.f64 	%fd813, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd812, %fd813, 0d400921FB54442D18;
	div.rn.f64 	%fd95, %fd812, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r126}, %fd95;
	}
	and.b32  	%r127, %r126, 2147483647;
	setp.eq.s32 	%p49, %r127, 2146435072;
	setp.eq.s32 	%p50, %r125, 0;
	and.pred  	%p51, %p50, %p49;
	@%p51 bra 	$L__BB4_59;
	bra.uni 	$L__BB4_57;

$L__BB4_59:
	mov.f64 	%fd450, 0d0000000000000000;
	mul.rn.f64 	%fd835, %fd95, %fd450;
	mov.u32 	%r306, 0;
	bra.uni 	$L__BB4_60;

$L__BB4_57:
	mul.rn.f64 	%fd441, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r306, %fd441;
	st.local.u32 	[%rd1], %r306;
	cvt.rn.f64.s32 	%fd442, %r306;
	neg.f64 	%fd443, %fd442;
	mov.f64 	%fd444, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd445, %fd443, %fd444, %fd95;
	mov.f64 	%fd446, 0d3C91A62633145C00;
	fma.rn.f64 	%fd447, %fd443, %fd446, %fd445;
	mov.f64 	%fd448, 0d397B839A252049C0;
	fma.rn.f64 	%fd835, %fd443, %fd448, %fd447;
	abs.f64 	%fd449, %fd95;
	setp.ltu.f64 	%p52, %fd449, 0d41E0000000000000;
	@%p52 bra 	$L__BB4_60;

	add.u64 	%rd105, %SP, 0;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd105;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd835, [retval0+0];
	} // callseq 47
	ld.local.u32 	%r306, [%rd1];

$L__BB4_60:
	mov.u64 	%rd114, __cudart_sin_cos_coeffs;
	and.b32  	%r129, %r306, 1;
	shl.b32 	%r130, %r306, 3;
	and.b32  	%r131, %r130, 8;
	setp.eq.s32 	%p53, %r129, 0;
	selp.f64 	%fd451, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p53;
	mul.wide.s32 	%rd69, %r131, 8;
	add.s64 	%rd71, %rd114, %rd69;
	ld.global.nc.f64 	%fd452, [%rd71+8];
	mul.rn.f64 	%fd100, %fd835, %fd835;
	fma.rn.f64 	%fd453, %fd451, %fd100, %fd452;
	ld.global.nc.f64 	%fd454, [%rd71+16];
	fma.rn.f64 	%fd455, %fd453, %fd100, %fd454;
	ld.global.nc.f64 	%fd456, [%rd71+24];
	fma.rn.f64 	%fd457, %fd455, %fd100, %fd456;
	ld.global.nc.f64 	%fd458, [%rd71+32];
	fma.rn.f64 	%fd459, %fd457, %fd100, %fd458;
	ld.global.nc.f64 	%fd460, [%rd71+40];
	fma.rn.f64 	%fd461, %fd459, %fd100, %fd460;
	ld.global.nc.f64 	%fd462, [%rd71+48];
	fma.rn.f64 	%fd101, %fd461, %fd100, %fd462;
	fma.rn.f64 	%fd837, %fd101, %fd835, %fd835;
	@%p53 bra 	$L__BB4_62;

	mov.f64 	%fd463, 0d3FF0000000000000;
	fma.rn.f64 	%fd837, %fd101, %fd100, %fd463;

$L__BB4_62:
	and.b32  	%r132, %r306, 2;
	setp.eq.s32 	%p54, %r132, 0;
	@%p54 bra 	$L__BB4_64;

	mov.f64 	%fd464, 0d0000000000000000;
	mov.f64 	%fd465, 0dBFF0000000000000;
	fma.rn.f64 	%fd837, %fd837, %fd465, %fd464;

$L__BB4_64:
	add.rn.f64 	%fd807, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd806, %fd807, 0d400921FB54442D18;
	mul.rn.f64 	%fd466, %fd837, 0d4044000000000000;
	mul.rn.f64 	%fd467, %fd834, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd467, %fd466;
	div.rn.f64 	%fd108, %fd806, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r133, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r134}, %fd108;
	}
	and.b32  	%r135, %r134, 2147483647;
	setp.eq.s32 	%p55, %r135, 2146435072;
	setp.eq.s32 	%p56, %r133, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB4_67;
	bra.uni 	$L__BB4_65;

$L__BB4_67:
	mov.f64 	%fd477, 0d0000000000000000;
	mul.rn.f64 	%fd838, %fd108, %fd477;
	mov.u32 	%r307, 0;
	bra.uni 	$L__BB4_68;

$L__BB4_65:
	mul.rn.f64 	%fd468, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r307, %fd468;
	st.local.u32 	[%rd1], %r307;
	cvt.rn.f64.s32 	%fd469, %r307;
	neg.f64 	%fd470, %fd469;
	mov.f64 	%fd471, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd472, %fd470, %fd471, %fd108;
	mov.f64 	%fd473, 0d3C91A62633145C00;
	fma.rn.f64 	%fd474, %fd470, %fd473, %fd472;
	mov.f64 	%fd475, 0d397B839A252049C0;
	fma.rn.f64 	%fd838, %fd470, %fd475, %fd474;
	abs.f64 	%fd476, %fd108;
	setp.ltu.f64 	%p58, %fd476, 0d41E0000000000000;
	@%p58 bra 	$L__BB4_68;

	add.u64 	%rd106, %SP, 0;
	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd838, [retval0+0];
	} // callseq 48
	ld.local.u32 	%r307, [%rd1];

$L__BB4_68:
	mov.u64 	%rd115, __cudart_sin_cos_coeffs;
	and.b32  	%r137, %r307, 1;
	shl.b32 	%r138, %r307, 3;
	and.b32  	%r139, %r138, 8;
	setp.eq.s32 	%p59, %r137, 0;
	selp.f64 	%fd478, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd73, %r139, 8;
	add.s64 	%rd75, %rd115, %rd73;
	ld.global.nc.f64 	%fd479, [%rd75+8];
	mul.rn.f64 	%fd113, %fd838, %fd838;
	fma.rn.f64 	%fd480, %fd478, %fd113, %fd479;
	ld.global.nc.f64 	%fd481, [%rd75+16];
	fma.rn.f64 	%fd482, %fd480, %fd113, %fd481;
	ld.global.nc.f64 	%fd483, [%rd75+24];
	fma.rn.f64 	%fd484, %fd482, %fd113, %fd483;
	ld.global.nc.f64 	%fd485, [%rd75+32];
	fma.rn.f64 	%fd486, %fd484, %fd113, %fd485;
	ld.global.nc.f64 	%fd487, [%rd75+40];
	fma.rn.f64 	%fd488, %fd486, %fd113, %fd487;
	ld.global.nc.f64 	%fd489, [%rd75+48];
	fma.rn.f64 	%fd114, %fd488, %fd113, %fd489;
	fma.rn.f64 	%fd840, %fd114, %fd838, %fd838;
	@%p59 bra 	$L__BB4_70;

	mov.f64 	%fd490, 0d3FF0000000000000;
	fma.rn.f64 	%fd840, %fd114, %fd113, %fd490;

$L__BB4_70:
	and.b32  	%r140, %r307, 2;
	setp.eq.s32 	%p60, %r140, 0;
	@%p60 bra 	$L__BB4_72;

	mov.f64 	%fd491, 0d0000000000000000;
	mov.f64 	%fd492, 0dBFF0000000000000;
	fma.rn.f64 	%fd840, %fd840, %fd492, %fd491;

$L__BB4_72:
	add.rn.f64 	%fd809, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd808, %fd809, 0d400921FB54442D18;
	mul.rn.f64 	%fd493, %fd840, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd493;
	div.rn.f64 	%fd121, %fd808, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd121;
	}
	and.b32  	%r143, %r142, 2147483647;
	setp.eq.s32 	%p61, %r143, 2146435072;
	setp.eq.s32 	%p62, %r141, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB4_75;
	bra.uni 	$L__BB4_73;

$L__BB4_75:
	mov.f64 	%fd503, 0d0000000000000000;
	mul.rn.f64 	%fd841, %fd121, %fd503;
	mov.u32 	%r308, 0;
	bra.uni 	$L__BB4_76;

$L__BB4_73:
	mul.rn.f64 	%fd494, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r308, %fd494;
	st.local.u32 	[%rd1], %r308;
	cvt.rn.f64.s32 	%fd495, %r308;
	neg.f64 	%fd496, %fd495;
	mov.f64 	%fd497, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd498, %fd496, %fd497, %fd121;
	mov.f64 	%fd499, 0d3C91A62633145C00;
	fma.rn.f64 	%fd500, %fd496, %fd499, %fd498;
	mov.f64 	%fd501, 0d397B839A252049C0;
	fma.rn.f64 	%fd841, %fd496, %fd501, %fd500;
	abs.f64 	%fd502, %fd121;
	setp.ltu.f64 	%p64, %fd502, 0d41E0000000000000;
	@%p64 bra 	$L__BB4_76;

	add.u64 	%rd107, %SP, 0;
	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd841, [retval0+0];
	} // callseq 49
	ld.local.u32 	%r308, [%rd1];

$L__BB4_76:
	mov.u64 	%rd116, __cudart_sin_cos_coeffs;
	and.b32  	%r145, %r308, 1;
	shl.b32 	%r146, %r308, 3;
	and.b32  	%r147, %r146, 8;
	setp.eq.s32 	%p65, %r145, 0;
	selp.f64 	%fd504, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd77, %r147, 8;
	add.s64 	%rd79, %rd116, %rd77;
	ld.global.nc.f64 	%fd505, [%rd79+8];
	mul.rn.f64 	%fd126, %fd841, %fd841;
	fma.rn.f64 	%fd506, %fd504, %fd126, %fd505;
	ld.global.nc.f64 	%fd507, [%rd79+16];
	fma.rn.f64 	%fd508, %fd506, %fd126, %fd507;
	ld.global.nc.f64 	%fd509, [%rd79+24];
	fma.rn.f64 	%fd510, %fd508, %fd126, %fd509;
	ld.global.nc.f64 	%fd511, [%rd79+32];
	fma.rn.f64 	%fd512, %fd510, %fd126, %fd511;
	ld.global.nc.f64 	%fd513, [%rd79+40];
	fma.rn.f64 	%fd514, %fd512, %fd126, %fd513;
	ld.global.nc.f64 	%fd515, [%rd79+48];
	fma.rn.f64 	%fd127, %fd514, %fd126, %fd515;
	fma.rn.f64 	%fd843, %fd127, %fd841, %fd841;
	@%p65 bra 	$L__BB4_78;

	mov.f64 	%fd516, 0d3FF0000000000000;
	fma.rn.f64 	%fd843, %fd127, %fd126, %fd516;

$L__BB4_78:
	and.b32  	%r148, %r308, 2;
	setp.eq.s32 	%p66, %r148, 0;
	@%p66 bra 	$L__BB4_80;

	mov.f64 	%fd517, 0d0000000000000000;
	mov.f64 	%fd518, 0dBFF0000000000000;
	fma.rn.f64 	%fd843, %fd843, %fd518, %fd517;

$L__BB4_80:
	mul.rn.f64 	%fd519, %fd843, 0d4072C00000000000;
	add.rn.f64 	%fd520, %fd120, %fd519;
	add.rn.f64 	%fd133, %fd33, %fd520;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd521, %fd2, %fd2;
	mov.f64 	%fd522, 0d4000000000000000;
	add.rn.f64 	%fd523, %fd521, 0dC059000000000000;
	mul.rn.f64 	%fd524, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd523, %fd524;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd522;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p67, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd846, [retval0+0];
	} // callseq 50
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p68, %r33, 0;
	and.pred  	%p1, %p68, %p67;
	not.pred 	%p69, %p1;
	@%p69 bra 	$L__BB4_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd846;
	}
	xor.b32  	%r150, %r149, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r151, %temp}, %fd846;
	}
	mov.b64 	%fd846, {%r151, %r150};

$L__BB4_82:
	setp.eq.f64 	%p70, %fd4, 0d0000000000000000;
	@%p70 bra 	$L__BB4_86;
	bra.uni 	$L__BB4_83;

$L__BB4_86:
	selp.b32 	%r152, %r33, 0, %p67;
	mov.u32 	%r153, 0;
	or.b32  	%r154, %r152, 2146435072;
	setp.lt.s32 	%p74, %r31, 0;
	selp.b32 	%r155, %r154, %r152, %p74;
	mov.b64 	%fd846, {%r153, %r155};
	bra.uni 	$L__BB4_87;

$L__BB4_83:
	setp.gt.s32 	%p71, %r33, -1;
	@%p71 bra 	$L__BB4_87;

	mov.f64 	%fd525, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd526, %fd525;
	setp.eq.f64 	%p72, %fd526, 0d4000000000000000;
	@%p72 bra 	$L__BB4_87;

	mov.f64 	%fd846, 0dFFF8000000000000;

$L__BB4_87:
	add.rn.f64 	%fd528, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r156}, %fd528;
	}
	and.b32  	%r157, %r156, 2146435072;
	setp.ne.s32 	%p75, %r157, 2146435072;
	@%p75 bra 	$L__BB4_94;

	setp.gtu.f64 	%p76, %fd136, 0d7FF0000000000000;
	@%p76 bra 	$L__BB4_93;
	bra.uni 	$L__BB4_89;

$L__BB4_93:
	mov.f64 	%fd530, 0d4000000000000000;
	add.rn.f64 	%fd846, %fd4, %fd530;
	bra.uni 	$L__BB4_94;

$L__BB4_89:
	mov.f64 	%fd529, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r158, %temp}, %fd529;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p77, %r34, 2146435072;
	setp.eq.s32 	%p78, %r158, 0;
	and.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB4_92;
	bra.uni 	$L__BB4_90;

$L__BB4_92:
	setp.gt.f64 	%p86, %fd136, 0d3FF0000000000000;
	selp.b32 	%r165, 2146435072, 0, %p86;
	mov.u32 	%r166, 0;
	xor.b32  	%r167, %r165, 2146435072;
	setp.lt.s32 	%p87, %r31, 0;
	selp.b32 	%r168, %r167, %r165, %p87;
	setp.eq.f64 	%p88, %fd4, 0dBFF0000000000000;
	selp.b32 	%r169, 1072693248, %r168, %p88;
	mov.b64 	%fd846, {%r166, %r169};
	bra.uni 	$L__BB4_94;

$L__BB4_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd4;
	}
	and.b32  	%r160, %r33, 2147483647;
	setp.ne.s32 	%p80, %r160, 2146435072;
	setp.ne.s32 	%p81, %r159, 0;
	or.pred  	%p82, %p80, %p81;
	@%p82 bra 	$L__BB4_94;

	setp.gt.s32 	%p83, %r31, -1;
	selp.b32 	%r161, 2146435072, 0, %p83;
	mov.u32 	%r162, 0;
	setp.ne.s32 	%p84, %r34, 1071644672;
	and.pred  	%p85, %p84, %p1;
	or.b32  	%r163, %r161, -2147483648;
	selp.b32 	%r164, %r163, %r161, %p85;
	mov.b64 	%fd846, {%r162, %r164};

$L__BB4_94:
	add.rn.f64 	%fd797, %fd1, 0dC05A400000000000;
	abs.f64 	%fd796, %fd797;
	mul.rn.f64 	%fd531, %fd846, 0d3FC999999999999A;
	setp.eq.f64 	%p89, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd532, 0d3FC999999999999A, %fd531, %p89;
	add.rn.f64 	%fd533, %fd135, %fd532;
	mul.rn.f64 	%fd534, %fd797, %fd4;
	mul.rn.f64 	%fd146, %fd534, 0d3FB999999999999A;
	add.rn.f64 	%fd535, %fd146, %fd533;
	mul.rn.f64 	%fd536, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd537, %fd536, %fd535;
	mul.rn.f64 	%fd538, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd538, %fd537;
	add.rn.f64 	%fd539, %fd4, %fd4;
	add.rn.f64 	%fd540, %fd797, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd540, %fd539;
	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd796;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd849, [retval0+0];
	} // callseq 51
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd797;
	}
	setp.lt.s32 	%p90, %r35, 0;
	and.pred  	%p2, %p90, %p67;
	not.pred 	%p92, %p2;
	@%p92 bra 	$L__BB4_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd849;
	}
	xor.b32  	%r171, %r170, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r172, %temp}, %fd849;
	}
	mov.b64 	%fd849, {%r172, %r171};

$L__BB4_96:
	setp.eq.f64 	%p93, %fd2, 0d0000000000000000;
	@%p93 bra 	$L__BB4_100;
	bra.uni 	$L__BB4_97;

$L__BB4_100:
	selp.b32 	%r173, %r35, 0, %p67;
	mov.u32 	%r174, 0;
	or.b32  	%r175, %r173, 2146435072;
	setp.lt.s32 	%p97, %r31, 0;
	selp.b32 	%r176, %r175, %r173, %p97;
	mov.b64 	%fd849, {%r174, %r176};
	bra.uni 	$L__BB4_101;

$L__BB4_97:
	setp.gt.s32 	%p94, %r35, -1;
	@%p94 bra 	$L__BB4_101;

	mov.f64 	%fd541, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd542, %fd541;
	setp.eq.f64 	%p95, %fd542, 0d4000000000000000;
	@%p95 bra 	$L__BB4_101;

	mov.f64 	%fd849, 0dFFF8000000000000;

$L__BB4_101:
	add.rn.f64 	%fd544, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd544;
	}
	and.b32  	%r178, %r177, 2146435072;
	setp.ne.s32 	%p98, %r178, 2146435072;
	@%p98 bra 	$L__BB4_108;

	add.rn.f64 	%fd799, %fd1, 0dC05A400000000000;
	abs.f64 	%fd798, %fd799;
	setp.gtu.f64 	%p99, %fd798, 0d7FF0000000000000;
	@%p99 bra 	$L__BB4_107;
	bra.uni 	$L__BB4_103;

$L__BB4_107:
	mov.f64 	%fd546, 0d4000000000000000;
	add.rn.f64 	%fd849, %fd2, %fd546;
	bra.uni 	$L__BB4_108;

$L__BB4_103:
	mov.f64 	%fd545, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r179, %temp}, %fd545;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p100, %r36, 2146435072;
	setp.eq.s32 	%p101, %r179, 0;
	and.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB4_106;
	bra.uni 	$L__BB4_104;

$L__BB4_106:
	add.rn.f64 	%fd801, %fd1, 0dC05A400000000000;
	abs.f64 	%fd800, %fd801;
	setp.gt.f64 	%p109, %fd800, 0d3FF0000000000000;
	selp.b32 	%r186, 2146435072, 0, %p109;
	mov.u32 	%r187, 0;
	xor.b32  	%r188, %r186, 2146435072;
	setp.lt.s32 	%p110, %r31, 0;
	selp.b32 	%r189, %r188, %r186, %p110;
	setp.eq.f64 	%p111, %fd801, 0dBFF0000000000000;
	selp.b32 	%r190, 1072693248, %r189, %p111;
	mov.b64 	%fd849, {%r187, %r190};
	bra.uni 	$L__BB4_108;

$L__BB4_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r180, %temp}, %fd2;
	}
	and.b32  	%r181, %r35, 2147483647;
	setp.ne.s32 	%p103, %r181, 2146435072;
	setp.ne.s32 	%p104, %r180, 0;
	or.pred  	%p105, %p103, %p104;
	@%p105 bra 	$L__BB4_108;

	setp.gt.s32 	%p106, %r31, -1;
	selp.b32 	%r182, 2146435072, 0, %p106;
	mov.u32 	%r183, 0;
	setp.ne.s32 	%p107, %r36, 1071644672;
	and.pred  	%p108, %p107, %p2;
	or.b32  	%r184, %r182, -2147483648;
	selp.b32 	%r185, %r184, %r182, %p108;
	mov.b64 	%fd849, {%r183, %r185};

$L__BB4_108:
	mul.rn.f64 	%fd547, %fd849, 0d3FB999999999999A;
	setp.eq.f64 	%p112, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd548, 0d3FB999999999999A, %fd547, %p112;
	add.rn.f64 	%fd549, %fd148, %fd548;
	add.rn.f64 	%fd550, %fd146, %fd549;
	mul.rn.f64 	%fd551, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd552, %fd551, %fd550;
	mul.rn.f64 	%fd553, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd553, %fd552;
	div.rn.f64 	%fd554, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd554, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r191, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd159;
	}
	and.b32  	%r193, %r192, 2147483647;
	setp.eq.s32 	%p113, %r193, 2146435072;
	setp.eq.s32 	%p114, %r191, 0;
	and.pred  	%p3, %p114, %p113;
	@%p3 bra 	$L__BB4_111;
	bra.uni 	$L__BB4_109;

$L__BB4_111:
	mov.f64 	%fd564, 0d0000000000000000;
	mul.rn.f64 	%fd850, %fd159, %fd564;
	mov.u32 	%r309, 0;
	bra.uni 	$L__BB4_112;

$L__BB4_109:
	mul.rn.f64 	%fd555, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r309, %fd555;
	st.local.u32 	[%rd1], %r309;
	cvt.rn.f64.s32 	%fd556, %r309;
	neg.f64 	%fd557, %fd556;
	mov.f64 	%fd558, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd559, %fd557, %fd558, %fd159;
	mov.f64 	%fd560, 0d3C91A62633145C00;
	fma.rn.f64 	%fd561, %fd557, %fd560, %fd559;
	mov.f64 	%fd562, 0d397B839A252049C0;
	fma.rn.f64 	%fd850, %fd557, %fd562, %fd561;
	abs.f64 	%fd563, %fd159;
	setp.ltu.f64 	%p115, %fd563, 0d41E0000000000000;
	@%p115 bra 	$L__BB4_112;

	add.u64 	%rd108, %SP, 0;
	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd108;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 52
	ld.local.u32 	%r309, [%rd1];

$L__BB4_112:
	mov.u64 	%rd117, __cudart_sin_cos_coeffs;
	and.b32  	%r195, %r309, 1;
	shl.b32 	%r196, %r309, 3;
	and.b32  	%r197, %r196, 8;
	setp.eq.s32 	%p116, %r195, 0;
	selp.f64 	%fd565, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd81, %r197, 8;
	add.s64 	%rd83, %rd117, %rd81;
	ld.global.nc.f64 	%fd566, [%rd83+8];
	mul.rn.f64 	%fd164, %fd850, %fd850;
	fma.rn.f64 	%fd567, %fd565, %fd164, %fd566;
	ld.global.nc.f64 	%fd568, [%rd83+16];
	fma.rn.f64 	%fd569, %fd567, %fd164, %fd568;
	ld.global.nc.f64 	%fd570, [%rd83+24];
	fma.rn.f64 	%fd571, %fd569, %fd164, %fd570;
	ld.global.nc.f64 	%fd572, [%rd83+32];
	fma.rn.f64 	%fd573, %fd571, %fd164, %fd572;
	ld.global.nc.f64 	%fd574, [%rd83+40];
	fma.rn.f64 	%fd575, %fd573, %fd164, %fd574;
	ld.global.nc.f64 	%fd576, [%rd83+48];
	fma.rn.f64 	%fd165, %fd575, %fd164, %fd576;
	fma.rn.f64 	%fd852, %fd165, %fd850, %fd850;
	@%p116 bra 	$L__BB4_114;

	mov.f64 	%fd577, 0d3FF0000000000000;
	fma.rn.f64 	%fd852, %fd165, %fd164, %fd577;

$L__BB4_114:
	and.b32  	%r198, %r309, 2;
	setp.eq.s32 	%p117, %r198, 0;
	@%p117 bra 	$L__BB4_116;

	mov.f64 	%fd578, 0d0000000000000000;
	mov.f64 	%fd579, 0dBFF0000000000000;
	fma.rn.f64 	%fd852, %fd852, %fd579, %fd578;

$L__BB4_116:
	@%p3 bra 	$L__BB4_120;
	bra.uni 	$L__BB4_117;

$L__BB4_120:
	mov.f64 	%fd589, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd159, %fd589;
	mov.u32 	%r311, 1;
	bra.uni 	$L__BB4_121;

$L__BB4_117:
	mul.rn.f64 	%fd580, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r310, %fd580;
	st.local.u32 	[%rd1], %r310;
	cvt.rn.f64.s32 	%fd581, %r310;
	neg.f64 	%fd582, %fd581;
	mov.f64 	%fd583, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd584, %fd582, %fd583, %fd159;
	mov.f64 	%fd585, 0d3C91A62633145C00;
	fma.rn.f64 	%fd586, %fd582, %fd585, %fd584;
	mov.f64 	%fd587, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd582, %fd587, %fd586;
	abs.f64 	%fd588, %fd159;
	setp.ltu.f64 	%p118, %fd588, 0d41E0000000000000;
	@%p118 bra 	$L__BB4_119;

	add.u64 	%rd109, %SP, 0;
	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 53
	ld.local.u32 	%r310, [%rd1];

$L__BB4_119:
	add.s32 	%r311, %r310, 1;

$L__BB4_121:
	mov.u64 	%rd118, __cudart_sin_cos_coeffs;
	and.b32  	%r200, %r311, 1;
	shl.b32 	%r201, %r311, 3;
	and.b32  	%r202, %r201, 8;
	setp.eq.s32 	%p119, %r200, 0;
	selp.f64 	%fd590, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p119;
	mul.wide.s32 	%rd85, %r202, 8;
	add.s64 	%rd87, %rd118, %rd85;
	ld.global.nc.f64 	%fd591, [%rd87+8];
	mul.rn.f64 	%fd176, %fd854, %fd854;
	fma.rn.f64 	%fd592, %fd590, %fd176, %fd591;
	ld.global.nc.f64 	%fd593, [%rd87+16];
	fma.rn.f64 	%fd594, %fd592, %fd176, %fd593;
	ld.global.nc.f64 	%fd595, [%rd87+24];
	fma.rn.f64 	%fd596, %fd594, %fd176, %fd595;
	ld.global.nc.f64 	%fd597, [%rd87+32];
	fma.rn.f64 	%fd598, %fd596, %fd176, %fd597;
	ld.global.nc.f64 	%fd599, [%rd87+40];
	fma.rn.f64 	%fd600, %fd598, %fd176, %fd599;
	ld.global.nc.f64 	%fd601, [%rd87+48];
	fma.rn.f64 	%fd177, %fd600, %fd176, %fd601;
	fma.rn.f64 	%fd856, %fd177, %fd854, %fd854;
	@%p119 bra 	$L__BB4_123;

	mov.f64 	%fd602, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd177, %fd176, %fd602;

$L__BB4_123:
	and.b32  	%r203, %r311, 2;
	setp.eq.s32 	%p120, %r203, 0;
	@%p120 bra 	$L__BB4_125;

	mov.f64 	%fd603, 0d0000000000000000;
	mov.f64 	%fd604, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd604, %fd603;

$L__BB4_125:
	mov.u32 	%r298, %tid.x;
	mov.u32 	%r297, %ntid.x;
	mov.u32 	%r296, %ctaid.x;
	mad.lo.s32 	%r295, %r296, %r297, %r298;
	mul.wide.s32 	%rd146, %r295, 8;
	ld.param.u64 	%rd145, [wgs84_to_bd09_cuda_param_1];
	cvta.to.global.u64 	%rd144, %rd145;
	add.s64 	%rd143, %rd144, %rd146;
	ld.param.u64 	%rd142, [wgs84_to_bd09_cuda_param_0];
	cvta.to.global.u64 	%rd141, %rd142;
	add.s64 	%rd140, %rd141, %rd146;
	mul.rn.f64 	%fd605, %fd852, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd606, %fd852, %fd605;
	add.rn.f64 	%fd607, %fd606, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd608, %fd607;
	mov.f64 	%fd609, 0d415854C140000000;
	div.rn.f64 	%fd610, %fd609, %fd608;
	mul.rn.f64 	%fd611, %fd610, %fd856;
	mul.rn.f64 	%fd612, %fd611, 0d400921FB54442D18;
	mul.rn.f64 	%fd613, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd614, %fd613, %fd612;
	add.rn.f64 	%fd615, %fd1, %fd614;
	st.global.f64 	[%rd140], %fd615;
	mul.rn.f64 	%fd616, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd617, %fd608, %fd607;
	mov.f64 	%fd618, 0d41582B102DE355C1;
	div.rn.f64 	%fd619, %fd618, %fd617;
	mul.rn.f64 	%fd620, %fd619, 0d400921FB54442D18;
	div.rn.f64 	%fd621, %fd616, %fd620;
	add.rn.f64 	%fd183, %fd3, %fd621;
	st.global.f64 	[%rd143], %fd183;
	ld.global.f64 	%fd184, [%rd140];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd184;
	}
	abs.f64 	%fd185, %fd184;
	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd185;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd859, [retval0+0];
	} // callseq 54
	setp.lt.s32 	%p121, %r45, 0;
	and.pred  	%p4, %p121, %p67;
	not.pred 	%p123, %p4;
	@%p123 bra 	$L__BB4_127;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd859;
	}
	xor.b32  	%r205, %r204, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r206, %temp}, %fd859;
	}
	mov.b64 	%fd859, {%r206, %r205};

$L__BB4_127:
	setp.eq.f64 	%p124, %fd184, 0d0000000000000000;
	@%p124 bra 	$L__BB4_131;
	bra.uni 	$L__BB4_128;

$L__BB4_131:
	selp.b32 	%r207, %r45, 0, %p67;
	mov.u32 	%r208, 0;
	or.b32  	%r209, %r207, 2146435072;
	setp.lt.s32 	%p128, %r31, 0;
	selp.b32 	%r210, %r209, %r207, %p128;
	mov.b64 	%fd859, {%r208, %r210};
	bra.uni 	$L__BB4_132;

$L__BB4_128:
	setp.gt.s32 	%p125, %r45, -1;
	@%p125 bra 	$L__BB4_132;

	mov.f64 	%fd622, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd623, %fd622;
	setp.eq.f64 	%p126, %fd623, 0d4000000000000000;
	@%p126 bra 	$L__BB4_132;

	mov.f64 	%fd859, 0dFFF8000000000000;

$L__BB4_132:
	add.rn.f64 	%fd625, %fd184, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd625;
	}
	and.b32  	%r212, %r211, 2146435072;
	setp.ne.s32 	%p129, %r212, 2146435072;
	@%p129 bra 	$L__BB4_139;

	setp.gtu.f64 	%p130, %fd185, 0d7FF0000000000000;
	@%p130 bra 	$L__BB4_138;
	bra.uni 	$L__BB4_134;

$L__BB4_138:
	mov.f64 	%fd627, 0d4000000000000000;
	add.rn.f64 	%fd859, %fd184, %fd627;
	bra.uni 	$L__BB4_139;

$L__BB4_134:
	mov.f64 	%fd626, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd626;
	}
	and.b32  	%r46, %r31, 2147483647;
	setp.eq.s32 	%p131, %r46, 2146435072;
	setp.eq.s32 	%p132, %r213, 0;
	and.pred  	%p133, %p131, %p132;
	@%p133 bra 	$L__BB4_137;
	bra.uni 	$L__BB4_135;

$L__BB4_137:
	setp.gt.f64 	%p140, %fd185, 0d3FF0000000000000;
	selp.b32 	%r220, 2146435072, 0, %p140;
	mov.u32 	%r221, 0;
	xor.b32  	%r222, %r220, 2146435072;
	setp.lt.s32 	%p141, %r31, 0;
	selp.b32 	%r223, %r222, %r220, %p141;
	setp.eq.f64 	%p142, %fd184, 0dBFF0000000000000;
	selp.b32 	%r224, 1072693248, %r223, %p142;
	mov.b64 	%fd859, {%r221, %r224};
	bra.uni 	$L__BB4_139;

$L__BB4_135:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd184;
	}
	and.b32  	%r215, %r45, 2147483647;
	setp.ne.s32 	%p134, %r215, 2146435072;
	setp.ne.s32 	%p135, %r214, 0;
	or.pred  	%p136, %p134, %p135;
	@%p136 bra 	$L__BB4_139;

	setp.gt.s32 	%p137, %r31, -1;
	selp.b32 	%r216, 2146435072, 0, %p137;
	mov.u32 	%r217, 0;
	setp.ne.s32 	%p138, %r46, 1071644672;
	and.pred  	%p139, %p138, %p4;
	or.b32  	%r218, %r216, -2147483648;
	selp.b32 	%r219, %r218, %r216, %p139;
	mov.b64 	%fd859, {%r217, %r219};

$L__BB4_139:
	abs.f64 	%fd195, %fd183;
	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd195;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd862, [retval0+0];
	} // callseq 55
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd183;
	}
	setp.lt.s32 	%p143, %r47, 0;
	and.pred  	%p5, %p143, %p67;
	not.pred 	%p145, %p5;
	@%p145 bra 	$L__BB4_141;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd862;
	}
	xor.b32  	%r226, %r225, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r227, %temp}, %fd862;
	}
	mov.b64 	%fd862, {%r227, %r226};

$L__BB4_141:
	setp.eq.f64 	%p146, %fd183, 0d0000000000000000;
	@%p146 bra 	$L__BB4_145;
	bra.uni 	$L__BB4_142;

$L__BB4_145:
	selp.b32 	%r228, %r47, 0, %p67;
	mov.u32 	%r229, 0;
	or.b32  	%r230, %r228, 2146435072;
	setp.lt.s32 	%p150, %r31, 0;
	selp.b32 	%r231, %r230, %r228, %p150;
	mov.b64 	%fd862, {%r229, %r231};
	bra.uni 	$L__BB4_146;

$L__BB4_142:
	setp.gt.s32 	%p147, %r47, -1;
	@%p147 bra 	$L__BB4_146;

	mov.f64 	%fd628, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd629, %fd628;
	setp.eq.f64 	%p148, %fd629, 0d4000000000000000;
	@%p148 bra 	$L__BB4_146;

	mov.f64 	%fd862, 0dFFF8000000000000;

$L__BB4_146:
	add.rn.f64 	%fd631, %fd183, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd631;
	}
	and.b32  	%r233, %r232, 2146435072;
	setp.ne.s32 	%p151, %r233, 2146435072;
	@%p151 bra 	$L__BB4_153;

	setp.gtu.f64 	%p152, %fd195, 0d7FF0000000000000;
	@%p152 bra 	$L__BB4_152;
	bra.uni 	$L__BB4_148;

$L__BB4_152:
	mov.f64 	%fd633, 0d4000000000000000;
	add.rn.f64 	%fd862, %fd183, %fd633;
	bra.uni 	$L__BB4_153;

$L__BB4_148:
	mov.f64 	%fd632, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd632;
	}
	and.b32  	%r48, %r31, 2147483647;
	setp.eq.s32 	%p153, %r48, 2146435072;
	setp.eq.s32 	%p154, %r234, 0;
	and.pred  	%p155, %p153, %p154;
	@%p155 bra 	$L__BB4_151;
	bra.uni 	$L__BB4_149;

$L__BB4_151:
	setp.gt.f64 	%p162, %fd195, 0d3FF0000000000000;
	selp.b32 	%r241, 2146435072, 0, %p162;
	mov.u32 	%r242, 0;
	xor.b32  	%r243, %r241, 2146435072;
	setp.lt.s32 	%p163, %r31, 0;
	selp.b32 	%r244, %r243, %r241, %p163;
	setp.eq.f64 	%p164, %fd183, 0dBFF0000000000000;
	selp.b32 	%r245, 1072693248, %r244, %p164;
	mov.b64 	%fd862, {%r242, %r245};
	bra.uni 	$L__BB4_153;

$L__BB4_149:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd183;
	}
	and.b32  	%r236, %r47, 2147483647;
	setp.ne.s32 	%p156, %r236, 2146435072;
	setp.ne.s32 	%p157, %r235, 0;
	or.pred  	%p158, %p156, %p157;
	@%p158 bra 	$L__BB4_153;

	setp.gt.s32 	%p159, %r31, -1;
	selp.b32 	%r237, 2146435072, 0, %p159;
	mov.u32 	%r238, 0;
	setp.ne.s32 	%p160, %r48, 1071644672;
	and.pred  	%p161, %p160, %p5;
	or.b32  	%r239, %r237, -2147483648;
	selp.b32 	%r240, %r239, %r237, %p161;
	mov.b64 	%fd862, {%r238, %r240};

$L__BB4_153:
	setp.eq.f64 	%p165, %fd183, 0d3FF0000000000000;
	selp.f64 	%fd634, 0d3FF0000000000000, %fd862, %p165;
	setp.eq.f64 	%p166, %fd184, 0d3FF0000000000000;
	selp.f64 	%fd635, 0d3FF0000000000000, %fd859, %p166;
	add.rn.f64 	%fd205, %fd635, %fd634;
	mul.rn.f64 	%fd206, %fd183, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r246, %temp}, %fd206;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd206;
	}
	and.b32  	%r248, %r247, 2147483647;
	setp.eq.s32 	%p167, %r248, 2146435072;
	setp.eq.s32 	%p168, %r246, 0;
	and.pred  	%p169, %p168, %p167;
	@%p169 bra 	$L__BB4_156;
	bra.uni 	$L__BB4_154;

$L__BB4_156:
	mov.f64 	%fd645, 0d0000000000000000;
	mul.rn.f64 	%fd863, %fd206, %fd645;
	mov.u32 	%r312, 0;
	bra.uni 	$L__BB4_157;

$L__BB4_154:
	mul.rn.f64 	%fd636, %fd206, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r312, %fd636;
	st.local.u32 	[%rd1], %r312;
	cvt.rn.f64.s32 	%fd637, %r312;
	neg.f64 	%fd638, %fd637;
	mov.f64 	%fd639, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd640, %fd638, %fd639, %fd206;
	mov.f64 	%fd641, 0d3C91A62633145C00;
	fma.rn.f64 	%fd642, %fd638, %fd641, %fd640;
	mov.f64 	%fd643, 0d397B839A252049C0;
	fma.rn.f64 	%fd863, %fd638, %fd643, %fd642;
	abs.f64 	%fd644, %fd206;
	setp.ltu.f64 	%p170, %fd644, 0d41E0000000000000;
	@%p170 bra 	$L__BB4_157;

	add.u64 	%rd110, %SP, 0;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd206;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd110;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd863, [retval0+0];
	} // callseq 56
	ld.local.u32 	%r312, [%rd1];

$L__BB4_157:
	mov.u64 	%rd119, __cudart_sin_cos_coeffs;
	and.b32  	%r250, %r312, 1;
	shl.b32 	%r251, %r312, 3;
	and.b32  	%r252, %r251, 8;
	setp.eq.s32 	%p171, %r250, 0;
	selp.f64 	%fd646, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p171;
	mul.wide.s32 	%rd89, %r252, 8;
	add.s64 	%rd91, %rd119, %rd89;
	ld.global.nc.f64 	%fd647, [%rd91+8];
	mul.rn.f64 	%fd211, %fd863, %fd863;
	fma.rn.f64 	%fd648, %fd646, %fd211, %fd647;
	ld.global.nc.f64 	%fd649, [%rd91+16];
	fma.rn.f64 	%fd650, %fd648, %fd211, %fd649;
	ld.global.nc.f64 	%fd651, [%rd91+24];
	fma.rn.f64 	%fd652, %fd650, %fd211, %fd651;
	ld.global.nc.f64 	%fd653, [%rd91+32];
	fma.rn.f64 	%fd654, %fd652, %fd211, %fd653;
	ld.global.nc.f64 	%fd655, [%rd91+40];
	fma.rn.f64 	%fd656, %fd654, %fd211, %fd655;
	ld.global.nc.f64 	%fd657, [%rd91+48];
	fma.rn.f64 	%fd212, %fd656, %fd211, %fd657;
	fma.rn.f64 	%fd865, %fd212, %fd863, %fd863;
	@%p171 bra 	$L__BB4_159;

	mov.f64 	%fd658, 0d3FF0000000000000;
	fma.rn.f64 	%fd865, %fd212, %fd211, %fd658;

$L__BB4_159:
	and.b32  	%r253, %r312, 2;
	setp.eq.s32 	%p172, %r253, 0;
	@%p172 bra 	$L__BB4_161;

	mov.f64 	%fd659, 0d0000000000000000;
	mov.f64 	%fd660, 0dBFF0000000000000;
	fma.rn.f64 	%fd865, %fd865, %fd660, %fd659;

$L__BB4_161:
	mul.rn.f64 	%fd661, %fd865, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd662, %fd205;
	add.rn.f64 	%fd218, %fd662, %fd661;
	setp.eq.f64 	%p173, %fd195, 0d0000000000000000;
	setp.eq.f64 	%p174, %fd185, 0d0000000000000000;
	and.pred  	%p175, %p174, %p173;
	@%p175 bra 	$L__BB4_165;
	bra.uni 	$L__BB4_162;

$L__BB4_165:
	selp.f64 	%fd715, 0d400921FB54442D18, 0d0000000000000000, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd715;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r263}, %fd715;
	}
	and.b32  	%r264, %r47, -2147483648;
	or.b32  	%r265, %r263, %r264;
	mov.b64 	%fd866, {%r262, %r265};
	bra.uni 	$L__BB4_166;

$L__BB4_162:
	setp.eq.f64 	%p176, %fd185, 0d7FF0000000000000;
	setp.eq.f64 	%p177, %fd195, 0d7FF0000000000000;
	and.pred  	%p178, %p176, %p177;
	@%p178 bra 	$L__BB4_164;
	bra.uni 	$L__BB4_163;

$L__BB4_164:
	selp.f64 	%fd714, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r258, %temp}, %fd714;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd714;
	}
	and.b32  	%r260, %r47, -2147483648;
	or.b32  	%r261, %r259, %r260;
	mov.b64 	%fd866, {%r258, %r261};
	bra.uni 	$L__BB4_166;

$L__BB4_163:
	min.f64 	%fd663, %fd195, %fd185;
	max.f64 	%fd664, %fd195, %fd185;
	div.rn.f64 	%fd665, %fd663, %fd664;
	mul.rn.f64 	%fd666, %fd665, %fd665;
	mov.f64 	%fd667, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd668, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd669, %fd668, %fd666, %fd667;
	mov.f64 	%fd670, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd671, %fd669, %fd666, %fd670;
	mov.f64 	%fd672, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd673, %fd671, %fd666, %fd672;
	mov.f64 	%fd674, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd675, %fd673, %fd666, %fd674;
	mov.f64 	%fd676, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd677, %fd675, %fd666, %fd676;
	mov.f64 	%fd678, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd679, %fd677, %fd666, %fd678;
	mov.f64 	%fd680, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd681, %fd679, %fd666, %fd680;
	mov.f64 	%fd682, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd683, %fd681, %fd666, %fd682;
	mov.f64 	%fd684, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd685, %fd683, %fd666, %fd684;
	mov.f64 	%fd686, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd687, %fd685, %fd666, %fd686;
	mov.f64 	%fd688, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd689, %fd687, %fd666, %fd688;
	mov.f64 	%fd690, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd691, %fd689, %fd666, %fd690;
	mov.f64 	%fd692, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd693, %fd691, %fd666, %fd692;
	mov.f64 	%fd694, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd695, %fd693, %fd666, %fd694;
	mov.f64 	%fd696, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd697, %fd695, %fd666, %fd696;
	mov.f64 	%fd698, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd699, %fd697, %fd666, %fd698;
	mov.f64 	%fd700, 0d3FC99999999840D2;
	fma.rn.f64 	%fd701, %fd699, %fd666, %fd700;
	mov.f64 	%fd702, 0dBFD555555555544C;
	fma.rn.f64 	%fd703, %fd701, %fd666, %fd702;
	mul.rn.f64 	%fd704, %fd666, %fd703;
	fma.rn.f64 	%fd705, %fd704, %fd665, %fd665;
	mov.f64 	%fd706, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd707, %fd706, %fd705;
	setp.gt.f64 	%p180, %fd195, %fd185;
	selp.f64 	%fd708, %fd707, %fd705, %p180;
	mov.f64 	%fd709, 0d400921FB54442D18;
	sub.rn.f64 	%fd710, %fd709, %fd708;
	selp.f64 	%fd711, %fd710, %fd708, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r254, %temp}, %fd711;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r255}, %fd711;
	}
	and.b32  	%r256, %r47, -2147483648;
	or.b32  	%r257, %r255, %r256;
	mov.b64 	%fd712, {%r254, %r257};
	add.rn.f64 	%fd713, %fd185, %fd195;
	setp.le.f64 	%p181, %fd713, 0d7FF0000000000000;
	selp.f64 	%fd866, %fd712, %fd713, %p181;

$L__BB4_166:
	mul.rn.f64 	%fd223, %fd184, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r266, %temp}, %fd223;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd223;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p184, %r268, 2146435072;
	setp.eq.s32 	%p185, %r266, 0;
	and.pred  	%p186, %p185, %p184;
	@%p186 bra 	$L__BB4_170;
	bra.uni 	$L__BB4_167;

$L__BB4_170:
	mov.f64 	%fd725, 0d0000000000000000;
	mul.rn.f64 	%fd868, %fd223, %fd725;
	mov.u32 	%r314, 1;
	bra.uni 	$L__BB4_171;

$L__BB4_167:
	mul.rn.f64 	%fd716, %fd223, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r313, %fd716;
	st.local.u32 	[%rd1], %r313;
	cvt.rn.f64.s32 	%fd717, %r313;
	neg.f64 	%fd718, %fd717;
	mov.f64 	%fd719, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd720, %fd718, %fd719, %fd223;
	mov.f64 	%fd721, 0d3C91A62633145C00;
	fma.rn.f64 	%fd722, %fd718, %fd721, %fd720;
	mov.f64 	%fd723, 0d397B839A252049C0;
	fma.rn.f64 	%fd868, %fd718, %fd723, %fd722;
	abs.f64 	%fd724, %fd223;
	setp.ltu.f64 	%p187, %fd724, 0d41E0000000000000;
	@%p187 bra 	$L__BB4_169;

	add.u64 	%rd111, %SP, 0;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd223;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd868, [retval0+0];
	} // callseq 57
	ld.local.u32 	%r313, [%rd1];

$L__BB4_169:
	add.s32 	%r314, %r313, 1;

$L__BB4_171:
	mov.u64 	%rd120, __cudart_sin_cos_coeffs;
	and.b32  	%r270, %r314, 1;
	shl.b32 	%r271, %r314, 3;
	and.b32  	%r272, %r271, 8;
	setp.eq.s32 	%p188, %r270, 0;
	selp.f64 	%fd726, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p188;
	mul.wide.s32 	%rd93, %r272, 8;
	add.s64 	%rd95, %rd120, %rd93;
	ld.global.nc.f64 	%fd727, [%rd95+8];
	mul.rn.f64 	%fd229, %fd868, %fd868;
	fma.rn.f64 	%fd728, %fd726, %fd229, %fd727;
	ld.global.nc.f64 	%fd729, [%rd95+16];
	fma.rn.f64 	%fd730, %fd728, %fd229, %fd729;
	ld.global.nc.f64 	%fd731, [%rd95+24];
	fma.rn.f64 	%fd732, %fd730, %fd229, %fd731;
	ld.global.nc.f64 	%fd733, [%rd95+32];
	fma.rn.f64 	%fd734, %fd732, %fd229, %fd733;
	ld.global.nc.f64 	%fd735, [%rd95+40];
	fma.rn.f64 	%fd736, %fd734, %fd229, %fd735;
	ld.global.nc.f64 	%fd737, [%rd95+48];
	fma.rn.f64 	%fd230, %fd736, %fd229, %fd737;
	fma.rn.f64 	%fd870, %fd230, %fd868, %fd868;
	@%p188 bra 	$L__BB4_173;

	mov.f64 	%fd738, 0d3FF0000000000000;
	fma.rn.f64 	%fd870, %fd230, %fd229, %fd738;

$L__BB4_173:
	and.b32  	%r273, %r314, 2;
	setp.eq.s32 	%p189, %r273, 0;
	@%p189 bra 	$L__BB4_175;

	mov.f64 	%fd739, 0d0000000000000000;
	mov.f64 	%fd740, 0dBFF0000000000000;
	fma.rn.f64 	%fd870, %fd870, %fd740, %fd739;

$L__BB4_175:
	mul.rn.f64 	%fd741, %fd870, 0d3EC92A737110E454;
	add.rn.f64 	%fd236, %fd866, %fd741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd236;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd236;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p190, %r276, 2146435072;
	setp.eq.s32 	%p191, %r274, 0;
	and.pred  	%p6, %p191, %p190;
	@%p6 bra 	$L__BB4_179;
	bra.uni 	$L__BB4_176;

$L__BB4_179:
	mov.f64 	%fd751, 0d0000000000000000;
	mul.rn.f64 	%fd872, %fd236, %fd751;
	mov.u32 	%r316, 1;
	bra.uni 	$L__BB4_180;

$L__BB4_176:
	mul.rn.f64 	%fd742, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r315, %fd742;
	st.local.u32 	[%rd1], %r315;
	cvt.rn.f64.s32 	%fd743, %r315;
	neg.f64 	%fd744, %fd743;
	mov.f64 	%fd745, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd746, %fd744, %fd745, %fd236;
	mov.f64 	%fd747, 0d3C91A62633145C00;
	fma.rn.f64 	%fd748, %fd744, %fd747, %fd746;
	mov.f64 	%fd749, 0d397B839A252049C0;
	fma.rn.f64 	%fd872, %fd744, %fd749, %fd748;
	abs.f64 	%fd750, %fd236;
	setp.ltu.f64 	%p192, %fd750, 0d41E0000000000000;
	@%p192 bra 	$L__BB4_178;

	add.u64 	%rd112, %SP, 0;
	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd112;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd872, [retval0+0];
	} // callseq 58
	ld.local.u32 	%r315, [%rd1];

$L__BB4_178:
	add.s32 	%r316, %r315, 1;

$L__BB4_180:
	mov.u64 	%rd121, __cudart_sin_cos_coeffs;
	and.b32  	%r278, %r316, 1;
	shl.b32 	%r279, %r316, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p193, %r278, 0;
	selp.f64 	%fd752, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p193;
	mul.wide.s32 	%rd97, %r280, 8;
	add.s64 	%rd99, %rd121, %rd97;
	ld.global.nc.f64 	%fd753, [%rd99+8];
	mul.rn.f64 	%fd242, %fd872, %fd872;
	fma.rn.f64 	%fd754, %fd752, %fd242, %fd753;
	ld.global.nc.f64 	%fd755, [%rd99+16];
	fma.rn.f64 	%fd756, %fd754, %fd242, %fd755;
	ld.global.nc.f64 	%fd757, [%rd99+24];
	fma.rn.f64 	%fd758, %fd756, %fd242, %fd757;
	ld.global.nc.f64 	%fd759, [%rd99+32];
	fma.rn.f64 	%fd760, %fd758, %fd242, %fd759;
	ld.global.nc.f64 	%fd761, [%rd99+40];
	fma.rn.f64 	%fd762, %fd760, %fd242, %fd761;
	ld.global.nc.f64 	%fd763, [%rd99+48];
	fma.rn.f64 	%fd243, %fd762, %fd242, %fd763;
	fma.rn.f64 	%fd874, %fd243, %fd872, %fd872;
	@%p193 bra 	$L__BB4_182;

	mov.f64 	%fd764, 0d3FF0000000000000;
	fma.rn.f64 	%fd874, %fd243, %fd242, %fd764;

$L__BB4_182:
	and.b32  	%r281, %r316, 2;
	setp.eq.s32 	%p194, %r281, 0;
	@%p194 bra 	$L__BB4_184;

	mov.f64 	%fd765, 0d0000000000000000;
	mov.f64 	%fd766, 0dBFF0000000000000;
	fma.rn.f64 	%fd874, %fd874, %fd766, %fd765;

$L__BB4_184:
	ld.param.u64 	%rd126, [wgs84_to_bd09_cuda_param_0];
	mov.u32 	%r290, %tid.x;
	mov.u32 	%r289, %ntid.x;
	mov.u32 	%r288, %ctaid.x;
	mad.lo.s32 	%r287, %r288, %r289, %r290;
	mul.wide.s32 	%rd125, %r287, 8;
	cvta.to.global.u64 	%rd124, %rd126;
	add.s64 	%rd123, %rd124, %rd125;
	mul.rn.f64 	%fd767, %fd218, %fd874;
	add.rn.f64 	%fd768, %fd767, 0d3F7A9FBE76C8B439;
	st.global.f64 	[%rd123], %fd768;
	@%p6 bra 	$L__BB4_187;
	bra.uni 	$L__BB4_185;

$L__BB4_187:
	mov.f64 	%fd778, 0d0000000000000000;
	mul.rn.f64 	%fd875, %fd236, %fd778;
	mov.u32 	%r317, 0;
	bra.uni 	$L__BB4_188;

$L__BB4_185:
	mul.rn.f64 	%fd769, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r317, %fd769;
	st.local.u32 	[%rd1], %r317;
	cvt.rn.f64.s32 	%fd770, %r317;
	neg.f64 	%fd771, %fd770;
	mov.f64 	%fd772, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd773, %fd771, %fd772, %fd236;
	mov.f64 	%fd774, 0d3C91A62633145C00;
	fma.rn.f64 	%fd775, %fd771, %fd774, %fd773;
	mov.f64 	%fd776, 0d397B839A252049C0;
	fma.rn.f64 	%fd875, %fd771, %fd776, %fd775;
	abs.f64 	%fd777, %fd236;
	setp.ltu.f64 	%p195, %fd777, 0d41E0000000000000;
	@%p195 bra 	$L__BB4_188;

	add.u64 	%rd113, %SP, 0;
	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd113;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd875, [retval0+0];
	} // callseq 59
	ld.local.u32 	%r317, [%rd1];

$L__BB4_188:
	mov.u64 	%rd122, __cudart_sin_cos_coeffs;
	and.b32  	%r283, %r317, 1;
	shl.b32 	%r284, %r317, 3;
	and.b32  	%r285, %r284, 8;
	setp.eq.s32 	%p196, %r283, 0;
	selp.f64 	%fd779, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd101, %r285, 8;
	add.s64 	%rd103, %rd122, %rd101;
	ld.global.nc.f64 	%fd780, [%rd103+8];
	mul.rn.f64 	%fd253, %fd875, %fd875;
	fma.rn.f64 	%fd781, %fd779, %fd253, %fd780;
	ld.global.nc.f64 	%fd782, [%rd103+16];
	fma.rn.f64 	%fd783, %fd781, %fd253, %fd782;
	ld.global.nc.f64 	%fd784, [%rd103+24];
	fma.rn.f64 	%fd785, %fd783, %fd253, %fd784;
	ld.global.nc.f64 	%fd786, [%rd103+32];
	fma.rn.f64 	%fd787, %fd785, %fd253, %fd786;
	ld.global.nc.f64 	%fd788, [%rd103+40];
	fma.rn.f64 	%fd789, %fd787, %fd253, %fd788;
	ld.global.nc.f64 	%fd790, [%rd103+48];
	fma.rn.f64 	%fd254, %fd789, %fd253, %fd790;
	fma.rn.f64 	%fd877, %fd254, %fd875, %fd875;
	@%p196 bra 	$L__BB4_190;

	mov.f64 	%fd791, 0d3FF0000000000000;
	fma.rn.f64 	%fd877, %fd254, %fd253, %fd791;

$L__BB4_190:
	and.b32  	%r286, %r317, 2;
	setp.eq.s32 	%p197, %r286, 0;
	@%p197 bra 	$L__BB4_192;

	mov.f64 	%fd792, 0d0000000000000000;
	mov.f64 	%fd793, 0dBFF0000000000000;
	fma.rn.f64 	%fd877, %fd877, %fd793, %fd792;

$L__BB4_192:
	ld.param.u64 	%rd130, [wgs84_to_bd09_cuda_param_1];
	mov.u32 	%r294, %tid.x;
	mov.u32 	%r293, %ntid.x;
	mov.u32 	%r292, %ctaid.x;
	mad.lo.s32 	%r291, %r292, %r293, %r294;
	mul.wide.s32 	%rd129, %r291, 8;
	cvta.to.global.u64 	%rd128, %rd130;
	add.s64 	%rd127, %rd128, %rd129;
	mul.rn.f64 	%fd794, %fd218, %fd877;
	add.rn.f64 	%fd795, %fd794, 0d3F789374BC6A7EFA;
	st.global.f64 	[%rd127], %fd795;
	ret;

}
	// .globl	bd09_to_wgs84_cuda
.visible .entry bd09_to_wgs84_cuda(
	.param .u64 bd09_to_wgs84_cuda_param_0,
	.param .u64 bd09_to_wgs84_cuda_param_1
)
{
	.local .align 4 .b8 	__local_depot5[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<198>;
	.reg .b32 	%r<306>;
	.reg .f64 	%fd<861>;
	.reg .b64 	%rd<104>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [bd09_to_wgs84_cuda_param_0];
	ld.param.u64 	%rd20, [bd09_to_wgs84_cuda_param_1];
	cvta.to.global.u64 	%rd21, %rd20;
	add.u64 	%rd22, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd38, %rd19;
	mul.wide.s32 	%rd39, %r68, 8;
	add.s64 	%rd17, %rd38, %rd39;
	add.s64 	%rd18, %rd21, %rd39;
	ld.global.f64 	%fd260, [%rd17];
	add.rn.f64 	%fd1, %fd260, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd261, [%rd18];
	add.rn.f64 	%fd2, %fd261, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd262, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd262;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p7, %r3, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd799, [retval0+0];
	} // callseq 60
	setp.lt.s32 	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	not.pred 	%p9, %p1;
	@%p9 bra 	$L__BB5_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd799;
	}
	xor.b32  	%r70, %r69, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd799;
	}
	mov.b64 	%fd799, {%r71, %r70};

$L__BB5_2:
	setp.eq.f64 	%p10, %fd1, 0d0000000000000000;
	@%p10 bra 	$L__BB5_6;
	bra.uni 	$L__BB5_3;

$L__BB5_6:
	selp.b32 	%r72, %r1, 0, %p7;
	mov.u32 	%r73, 0;
	or.b32  	%r74, %r72, 2146435072;
	setp.lt.s32 	%p14, %r2, 0;
	selp.b32 	%r75, %r74, %r72, %p14;
	mov.b64 	%fd799, {%r73, %r75};
	bra.uni 	$L__BB5_7;

$L__BB5_3:
	setp.gt.s32 	%p11, %r1, -1;
	@%p11 bra 	$L__BB5_7;

	mov.f64 	%fd263, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd264, %fd263;
	setp.eq.f64 	%p12, %fd264, 0d4000000000000000;
	@%p12 bra 	$L__BB5_7;

	mov.f64 	%fd799, 0dFFF8000000000000;

$L__BB5_7:
	add.rn.f64 	%fd266, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd266;
	}
	and.b32  	%r77, %r76, 2146435072;
	setp.ne.s32 	%p15, %r77, 2146435072;
	@%p15 bra 	$L__BB5_14;

	setp.gtu.f64 	%p16, %fd3, 0d7FF0000000000000;
	@%p16 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_9;

$L__BB5_13:
	mov.f64 	%fd268, 0d4000000000000000;
	add.rn.f64 	%fd799, %fd1, %fd268;
	bra.uni 	$L__BB5_14;

$L__BB5_9:
	mov.f64 	%fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd267;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p17, %r4, 2146435072;
	setp.eq.s32 	%p18, %r78, 0;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB5_12;
	bra.uni 	$L__BB5_10;

$L__BB5_12:
	setp.gt.f64 	%p26, %fd3, 0d3FF0000000000000;
	selp.b32 	%r85, 2146435072, 0, %p26;
	mov.u32 	%r86, 0;
	xor.b32  	%r87, %r85, 2146435072;
	setp.lt.s32 	%p27, %r2, 0;
	selp.b32 	%r88, %r87, %r85, %p27;
	setp.eq.f64 	%p28, %fd1, 0dBFF0000000000000;
	selp.b32 	%r89, 1072693248, %r88, %p28;
	mov.b64 	%fd799, {%r86, %r89};
	bra.uni 	$L__BB5_14;

$L__BB5_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd1;
	}
	and.b32  	%r80, %r1, 2147483647;
	setp.ne.s32 	%p20, %r80, 2146435072;
	setp.ne.s32 	%p21, %r79, 0;
	or.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB5_14;

	setp.gt.s32 	%p23, %r2, -1;
	selp.b32 	%r81, 2146435072, 0, %p23;
	mov.u32 	%r82, 0;
	setp.ne.s32 	%p24, %r4, 1071644672;
	and.pred  	%p25, %p24, %p1;
	or.b32  	%r83, %r81, -2147483648;
	selp.b32 	%r84, %r83, %r81, %p25;
	mov.b64 	%fd799, {%r82, %r84};

$L__BB5_14:
	abs.f64 	%fd13, %fd2;
	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd802, [retval0+0];
	} // callseq 61
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd2;
	}
	setp.lt.s32 	%p29, %r5, 0;
	and.pred  	%p2, %p29, %p7;
	not.pred 	%p31, %p2;
	@%p31 bra 	$L__BB5_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd802;
	}
	xor.b32  	%r91, %r90, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r92, %temp}, %fd802;
	}
	mov.b64 	%fd802, {%r92, %r91};

$L__BB5_16:
	setp.eq.f64 	%p32, %fd2, 0d0000000000000000;
	@%p32 bra 	$L__BB5_20;
	bra.uni 	$L__BB5_17;

$L__BB5_20:
	selp.b32 	%r93, %r5, 0, %p7;
	mov.u32 	%r94, 0;
	or.b32  	%r95, %r93, 2146435072;
	setp.lt.s32 	%p36, %r2, 0;
	selp.b32 	%r96, %r95, %r93, %p36;
	mov.b64 	%fd802, {%r94, %r96};
	bra.uni 	$L__BB5_21;

$L__BB5_17:
	setp.gt.s32 	%p33, %r5, -1;
	@%p33 bra 	$L__BB5_21;

	mov.f64 	%fd269, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd270, %fd269;
	setp.eq.f64 	%p34, %fd270, 0d4000000000000000;
	@%p34 bra 	$L__BB5_21;

	mov.f64 	%fd802, 0dFFF8000000000000;

$L__BB5_21:
	add.rn.f64 	%fd272, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd272;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32 	%p37, %r98, 2146435072;
	@%p37 bra 	$L__BB5_28;

	setp.gtu.f64 	%p38, %fd13, 0d7FF0000000000000;
	@%p38 bra 	$L__BB5_27;
	bra.uni 	$L__BB5_23;

$L__BB5_27:
	mov.f64 	%fd274, 0d4000000000000000;
	add.rn.f64 	%fd802, %fd2, %fd274;
	bra.uni 	$L__BB5_28;

$L__BB5_23:
	mov.f64 	%fd273, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd273;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p39, %r6, 2146435072;
	setp.eq.s32 	%p40, %r99, 0;
	and.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB5_26;
	bra.uni 	$L__BB5_24;

$L__BB5_26:
	setp.gt.f64 	%p48, %fd13, 0d3FF0000000000000;
	selp.b32 	%r106, 2146435072, 0, %p48;
	mov.u32 	%r107, 0;
	xor.b32  	%r108, %r106, 2146435072;
	setp.lt.s32 	%p49, %r2, 0;
	selp.b32 	%r109, %r108, %r106, %p49;
	setp.eq.f64 	%p50, %fd2, 0dBFF0000000000000;
	selp.b32 	%r110, 1072693248, %r109, %p50;
	mov.b64 	%fd802, {%r107, %r110};
	bra.uni 	$L__BB5_28;

$L__BB5_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd2;
	}
	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32 	%p42, %r101, 2146435072;
	setp.ne.s32 	%p43, %r100, 0;
	or.pred  	%p44, %p42, %p43;
	@%p44 bra 	$L__BB5_28;

	setp.gt.s32 	%p45, %r2, -1;
	selp.b32 	%r102, 2146435072, 0, %p45;
	mov.u32 	%r103, 0;
	setp.ne.s32 	%p46, %r6, 1071644672;
	and.pred  	%p47, %p46, %p2;
	or.b32  	%r104, %r102, -2147483648;
	selp.b32 	%r105, %r104, %r102, %p47;
	mov.b64 	%fd802, {%r103, %r105};

$L__BB5_28:
	setp.eq.f64 	%p51, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd275, 0d3FF0000000000000, %fd802, %p51;
	setp.eq.f64 	%p52, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd276, 0d3FF0000000000000, %fd799, %p52;
	add.rn.f64 	%fd23, %fd276, %fd275;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd24;
	}
	and.b32  	%r113, %r112, 2147483647;
	setp.eq.s32 	%p53, %r113, 2146435072;
	setp.eq.s32 	%p54, %r111, 0;
	and.pred  	%p55, %p54, %p53;
	@%p55 bra 	$L__BB5_31;
	bra.uni 	$L__BB5_29;

$L__BB5_31:
	mov.f64 	%fd286, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd24, %fd286;
	mov.u32 	%r287, 0;
	bra.uni 	$L__BB5_32;

$L__BB5_29:
	mul.rn.f64 	%fd277, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r287, %fd277;
	st.local.u32 	[%rd1], %r287;
	cvt.rn.f64.s32 	%fd278, %r287;
	neg.f64 	%fd279, %fd278;
	mov.f64 	%fd280, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd281, %fd279, %fd280, %fd24;
	mov.f64 	%fd282, 0d3C91A62633145C00;
	fma.rn.f64 	%fd283, %fd279, %fd282, %fd281;
	mov.f64 	%fd284, 0d397B839A252049C0;
	fma.rn.f64 	%fd803, %fd279, %fd284, %fd283;
	abs.f64 	%fd285, %fd24;
	setp.ltu.f64 	%p56, %fd285, 0d41E0000000000000;
	@%p56 bra 	$L__BB5_32;

	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd803, [retval0+0];
	} // callseq 62
	ld.local.u32 	%r287, [%rd1];

$L__BB5_32:
	and.b32  	%r115, %r287, 1;
	shl.b32 	%r116, %r287, 3;
	and.b32  	%r117, %r116, 8;
	setp.eq.s32 	%p57, %r115, 0;
	selp.f64 	%fd287, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p57;
	mul.wide.s32 	%rd41, %r117, 8;
	mov.u64 	%rd42, __cudart_sin_cos_coeffs;
	add.s64 	%rd43, %rd42, %rd41;
	ld.global.nc.f64 	%fd288, [%rd43+8];
	mul.rn.f64 	%fd29, %fd803, %fd803;
	fma.rn.f64 	%fd289, %fd287, %fd29, %fd288;
	ld.global.nc.f64 	%fd290, [%rd43+16];
	fma.rn.f64 	%fd291, %fd289, %fd29, %fd290;
	ld.global.nc.f64 	%fd292, [%rd43+24];
	fma.rn.f64 	%fd293, %fd291, %fd29, %fd292;
	ld.global.nc.f64 	%fd294, [%rd43+32];
	fma.rn.f64 	%fd295, %fd293, %fd29, %fd294;
	ld.global.nc.f64 	%fd296, [%rd43+40];
	fma.rn.f64 	%fd297, %fd295, %fd29, %fd296;
	ld.global.nc.f64 	%fd298, [%rd43+48];
	fma.rn.f64 	%fd30, %fd297, %fd29, %fd298;
	fma.rn.f64 	%fd805, %fd30, %fd803, %fd803;
	@%p57 bra 	$L__BB5_34;

	mov.f64 	%fd299, 0d3FF0000000000000;
	fma.rn.f64 	%fd805, %fd30, %fd29, %fd299;

$L__BB5_34:
	and.b32  	%r118, %r287, 2;
	setp.eq.s32 	%p58, %r118, 0;
	@%p58 bra 	$L__BB5_36;

	mov.f64 	%fd300, 0d0000000000000000;
	mov.f64 	%fd301, 0dBFF0000000000000;
	fma.rn.f64 	%fd805, %fd805, %fd301, %fd300;

$L__BB5_36:
	mul.rn.f64 	%fd302, %fd805, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd303, %fd23;
	add.rn.f64 	%fd36, %fd303, %fd302;
	setp.eq.f64 	%p59, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p60, %fd3, 0d0000000000000000;
	and.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB5_40;
	bra.uni 	$L__BB5_37;

$L__BB5_40:
	selp.f64 	%fd356, 0d400921FB54442D18, 0d0000000000000000, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd356;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd356;
	}
	and.b32  	%r129, %r5, -2147483648;
	or.b32  	%r130, %r128, %r129;
	mov.b64 	%fd806, {%r127, %r130};
	bra.uni 	$L__BB5_41;

$L__BB5_37:
	setp.eq.f64 	%p62, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p63, %fd13, 0d7FF0000000000000;
	and.pred  	%p64, %p62, %p63;
	@%p64 bra 	$L__BB5_39;
	bra.uni 	$L__BB5_38;

$L__BB5_39:
	selp.f64 	%fd355, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd355;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r124}, %fd355;
	}
	and.b32  	%r125, %r5, -2147483648;
	or.b32  	%r126, %r124, %r125;
	mov.b64 	%fd806, {%r123, %r126};
	bra.uni 	$L__BB5_41;

$L__BB5_38:
	min.f64 	%fd304, %fd13, %fd3;
	max.f64 	%fd305, %fd13, %fd3;
	div.rn.f64 	%fd306, %fd304, %fd305;
	mul.rn.f64 	%fd307, %fd306, %fd306;
	mov.f64 	%fd308, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd309, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd310, %fd309, %fd307, %fd308;
	mov.f64 	%fd311, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd312, %fd310, %fd307, %fd311;
	mov.f64 	%fd313, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd314, %fd312, %fd307, %fd313;
	mov.f64 	%fd315, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd316, %fd314, %fd307, %fd315;
	mov.f64 	%fd317, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd318, %fd316, %fd307, %fd317;
	mov.f64 	%fd319, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd320, %fd318, %fd307, %fd319;
	mov.f64 	%fd321, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd322, %fd320, %fd307, %fd321;
	mov.f64 	%fd323, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd324, %fd322, %fd307, %fd323;
	mov.f64 	%fd325, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd326, %fd324, %fd307, %fd325;
	mov.f64 	%fd327, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd328, %fd326, %fd307, %fd327;
	mov.f64 	%fd329, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd330, %fd328, %fd307, %fd329;
	mov.f64 	%fd331, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd332, %fd330, %fd307, %fd331;
	mov.f64 	%fd333, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd334, %fd332, %fd307, %fd333;
	mov.f64 	%fd335, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd336, %fd334, %fd307, %fd335;
	mov.f64 	%fd337, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd338, %fd336, %fd307, %fd337;
	mov.f64 	%fd339, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd340, %fd338, %fd307, %fd339;
	mov.f64 	%fd341, 0d3FC99999999840D2;
	fma.rn.f64 	%fd342, %fd340, %fd307, %fd341;
	mov.f64 	%fd343, 0dBFD555555555544C;
	fma.rn.f64 	%fd344, %fd342, %fd307, %fd343;
	mul.rn.f64 	%fd345, %fd307, %fd344;
	fma.rn.f64 	%fd346, %fd345, %fd306, %fd306;
	mov.f64 	%fd347, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd348, %fd347, %fd346;
	setp.gt.f64 	%p66, %fd13, %fd3;
	selp.f64 	%fd349, %fd348, %fd346, %p66;
	mov.f64 	%fd350, 0d400921FB54442D18;
	sub.rn.f64 	%fd351, %fd350, %fd349;
	selp.f64 	%fd352, %fd351, %fd349, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd352;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd352;
	}
	and.b32  	%r121, %r5, -2147483648;
	or.b32  	%r122, %r120, %r121;
	mov.b64 	%fd353, {%r119, %r122};
	add.rn.f64 	%fd354, %fd3, %fd13;
	setp.le.f64 	%p67, %fd354, 0d7FF0000000000000;
	selp.f64 	%fd806, %fd353, %fd354, %p67;

$L__BB5_41:
	add.rn.f64 	%fd796, %fd260, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd796, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd41;
	}
	and.b32  	%r133, %r132, 2147483647;
	setp.eq.s32 	%p70, %r133, 2146435072;
	setp.eq.s32 	%p71, %r131, 0;
	and.pred  	%p72, %p71, %p70;
	@%p72 bra 	$L__BB5_45;
	bra.uni 	$L__BB5_42;

$L__BB5_45:
	mov.f64 	%fd366, 0d0000000000000000;
	mul.rn.f64 	%fd808, %fd41, %fd366;
	mov.u32 	%r289, 1;
	bra.uni 	$L__BB5_46;

$L__BB5_42:
	mul.rn.f64 	%fd357, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r288, %fd357;
	st.local.u32 	[%rd1], %r288;
	cvt.rn.f64.s32 	%fd358, %r288;
	neg.f64 	%fd359, %fd358;
	mov.f64 	%fd360, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd361, %fd359, %fd360, %fd41;
	mov.f64 	%fd362, 0d3C91A62633145C00;
	fma.rn.f64 	%fd363, %fd359, %fd362, %fd361;
	mov.f64 	%fd364, 0d397B839A252049C0;
	fma.rn.f64 	%fd808, %fd359, %fd364, %fd363;
	abs.f64 	%fd365, %fd41;
	setp.ltu.f64 	%p73, %fd365, 0d41E0000000000000;
	@%p73 bra 	$L__BB5_44;

	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 63
	ld.local.u32 	%r288, [%rd1];

$L__BB5_44:
	add.s32 	%r289, %r288, 1;

$L__BB5_46:
	and.b32  	%r135, %r289, 1;
	shl.b32 	%r136, %r289, 3;
	and.b32  	%r137, %r136, 8;
	setp.eq.s32 	%p74, %r135, 0;
	selp.f64 	%fd367, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p74;
	mul.wide.s32 	%rd45, %r137, 8;
	add.s64 	%rd47, %rd42, %rd45;
	ld.global.nc.f64 	%fd368, [%rd47+8];
	mul.rn.f64 	%fd47, %fd808, %fd808;
	fma.rn.f64 	%fd369, %fd367, %fd47, %fd368;
	ld.global.nc.f64 	%fd370, [%rd47+16];
	fma.rn.f64 	%fd371, %fd369, %fd47, %fd370;
	ld.global.nc.f64 	%fd372, [%rd47+24];
	fma.rn.f64 	%fd373, %fd371, %fd47, %fd372;
	ld.global.nc.f64 	%fd374, [%rd47+32];
	fma.rn.f64 	%fd375, %fd373, %fd47, %fd374;
	ld.global.nc.f64 	%fd376, [%rd47+40];
	fma.rn.f64 	%fd377, %fd375, %fd47, %fd376;
	ld.global.nc.f64 	%fd378, [%rd47+48];
	fma.rn.f64 	%fd48, %fd377, %fd47, %fd378;
	fma.rn.f64 	%fd810, %fd48, %fd808, %fd808;
	@%p74 bra 	$L__BB5_48;

	mov.f64 	%fd379, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd48, %fd47, %fd379;

$L__BB5_48:
	and.b32  	%r138, %r289, 2;
	setp.eq.s32 	%p75, %r138, 0;
	@%p75 bra 	$L__BB5_50;

	mov.f64 	%fd380, 0d0000000000000000;
	mov.f64 	%fd381, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd381, %fd380;

$L__BB5_50:
	mul.rn.f64 	%fd382, %fd810, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd806, %fd382;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd54;
	}
	and.b32  	%r141, %r140, 2147483647;
	setp.eq.s32 	%p76, %r141, 2146435072;
	setp.eq.s32 	%p77, %r139, 0;
	and.pred  	%p3, %p77, %p76;
	@%p3 bra 	$L__BB5_54;
	bra.uni 	$L__BB5_51;

$L__BB5_54:
	mov.f64 	%fd392, 0d0000000000000000;
	mul.rn.f64 	%fd812, %fd54, %fd392;
	mov.u32 	%r291, 1;
	bra.uni 	$L__BB5_55;

$L__BB5_51:
	mul.rn.f64 	%fd383, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r290, %fd383;
	st.local.u32 	[%rd1], %r290;
	cvt.rn.f64.s32 	%fd384, %r290;
	neg.f64 	%fd385, %fd384;
	mov.f64 	%fd386, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd387, %fd385, %fd386, %fd54;
	mov.f64 	%fd388, 0d3C91A62633145C00;
	fma.rn.f64 	%fd389, %fd385, %fd388, %fd387;
	mov.f64 	%fd390, 0d397B839A252049C0;
	fma.rn.f64 	%fd812, %fd385, %fd390, %fd389;
	abs.f64 	%fd391, %fd54;
	setp.ltu.f64 	%p78, %fd391, 0d41E0000000000000;
	@%p78 bra 	$L__BB5_53;

	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 64
	ld.local.u32 	%r290, [%rd1];

$L__BB5_53:
	add.s32 	%r291, %r290, 1;

$L__BB5_55:
	and.b32  	%r143, %r291, 1;
	shl.b32 	%r144, %r291, 3;
	and.b32  	%r145, %r144, 8;
	setp.eq.s32 	%p79, %r143, 0;
	selp.f64 	%fd393, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd49, %r145, 8;
	add.s64 	%rd51, %rd42, %rd49;
	ld.global.nc.f64 	%fd394, [%rd51+8];
	mul.rn.f64 	%fd60, %fd812, %fd812;
	fma.rn.f64 	%fd395, %fd393, %fd60, %fd394;
	ld.global.nc.f64 	%fd396, [%rd51+16];
	fma.rn.f64 	%fd397, %fd395, %fd60, %fd396;
	ld.global.nc.f64 	%fd398, [%rd51+24];
	fma.rn.f64 	%fd399, %fd397, %fd60, %fd398;
	ld.global.nc.f64 	%fd400, [%rd51+32];
	fma.rn.f64 	%fd401, %fd399, %fd60, %fd400;
	ld.global.nc.f64 	%fd402, [%rd51+40];
	fma.rn.f64 	%fd403, %fd401, %fd60, %fd402;
	ld.global.nc.f64 	%fd404, [%rd51+48];
	fma.rn.f64 	%fd61, %fd403, %fd60, %fd404;
	fma.rn.f64 	%fd814, %fd61, %fd812, %fd812;
	@%p79 bra 	$L__BB5_57;

	mov.f64 	%fd405, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd61, %fd60, %fd405;

$L__BB5_57:
	and.b32  	%r146, %r291, 2;
	setp.eq.s32 	%p80, %r146, 0;
	@%p80 bra 	$L__BB5_59;

	mov.f64 	%fd406, 0d0000000000000000;
	mov.f64 	%fd407, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd407, %fd406;

$L__BB5_59:
	mul.rn.f64 	%fd408, %fd36, %fd814;
	st.global.f64 	[%rd17], %fd408;
	@%p3 bra 	$L__BB5_62;
	bra.uni 	$L__BB5_60;

$L__BB5_62:
	mov.f64 	%fd418, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd54, %fd418;
	mov.u32 	%r292, 0;
	bra.uni 	$L__BB5_63;

$L__BB5_60:
	mul.rn.f64 	%fd409, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r292, %fd409;
	st.local.u32 	[%rd1], %r292;
	cvt.rn.f64.s32 	%fd410, %r292;
	neg.f64 	%fd411, %fd410;
	mov.f64 	%fd412, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd413, %fd411, %fd412, %fd54;
	mov.f64 	%fd414, 0d3C91A62633145C00;
	fma.rn.f64 	%fd415, %fd411, %fd414, %fd413;
	mov.f64 	%fd416, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd411, %fd416, %fd415;
	abs.f64 	%fd417, %fd54;
	setp.ltu.f64 	%p81, %fd417, 0d41E0000000000000;
	@%p81 bra 	$L__BB5_63;

	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 65
	ld.local.u32 	%r292, [%rd1];

$L__BB5_63:
	and.b32  	%r148, %r292, 1;
	shl.b32 	%r149, %r292, 3;
	and.b32  	%r150, %r149, 8;
	setp.eq.s32 	%p82, %r148, 0;
	selp.f64 	%fd419, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p82;
	mul.wide.s32 	%rd53, %r150, 8;
	add.s64 	%rd55, %rd42, %rd53;
	ld.global.nc.f64 	%fd420, [%rd55+8];
	mul.rn.f64 	%fd71, %fd815, %fd815;
	fma.rn.f64 	%fd421, %fd419, %fd71, %fd420;
	ld.global.nc.f64 	%fd422, [%rd55+16];
	fma.rn.f64 	%fd423, %fd421, %fd71, %fd422;
	ld.global.nc.f64 	%fd424, [%rd55+24];
	fma.rn.f64 	%fd425, %fd423, %fd71, %fd424;
	ld.global.nc.f64 	%fd426, [%rd55+32];
	fma.rn.f64 	%fd427, %fd425, %fd71, %fd426;
	ld.global.nc.f64 	%fd428, [%rd55+40];
	fma.rn.f64 	%fd429, %fd427, %fd71, %fd428;
	ld.global.nc.f64 	%fd430, [%rd55+48];
	fma.rn.f64 	%fd72, %fd429, %fd71, %fd430;
	fma.rn.f64 	%fd817, %fd72, %fd815, %fd815;
	@%p82 bra 	$L__BB5_65;

	mov.f64 	%fd431, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd72, %fd71, %fd431;

$L__BB5_65:
	and.b32  	%r151, %r292, 2;
	setp.eq.s32 	%p83, %r151, 0;
	@%p83 bra 	$L__BB5_67;

	mov.f64 	%fd432, 0d0000000000000000;
	mov.f64 	%fd433, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd433, %fd432;

$L__BB5_67:
	mul.rn.f64 	%fd78, %fd36, %fd817;
	st.global.f64 	[%rd18], %fd78;
	ld.global.f64 	%fd79, [%rd17];
	add.rn.f64 	%fd80, %fd79, 0dC05A400000000000;
	add.rn.f64 	%fd81, %fd78, 0dC041800000000000;
	abs.f64 	%fd82, %fd80;
	sqrt.rn.f64 	%fd83, %fd82;
	mul.rn.f64 	%fd84, %fd80, 0d400921FB54442D18;
	mul.rn.f64 	%fd85, %fd81, 0d400921FB54442D18;
	mul.rn.f64 	%fd86, %fd84, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd86;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd86;
	}
	and.b32  	%r154, %r153, 2147483647;
	setp.eq.s32 	%p84, %r154, 2146435072;
	setp.eq.s32 	%p85, %r152, 0;
	and.pred  	%p86, %p85, %p84;
	@%p86 bra 	$L__BB5_70;
	bra.uni 	$L__BB5_68;

$L__BB5_70:
	mov.f64 	%fd443, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd86, %fd443;
	mov.u32 	%r293, 0;
	bra.uni 	$L__BB5_71;

$L__BB5_68:
	mul.rn.f64 	%fd434, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r293, %fd434;
	st.local.u32 	[%rd1], %r293;
	cvt.rn.f64.s32 	%fd435, %r293;
	neg.f64 	%fd436, %fd435;
	mov.f64 	%fd437, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd438, %fd436, %fd437, %fd86;
	mov.f64 	%fd439, 0d3C91A62633145C00;
	fma.rn.f64 	%fd440, %fd436, %fd439, %fd438;
	mov.f64 	%fd441, 0d397B839A252049C0;
	fma.rn.f64 	%fd818, %fd436, %fd441, %fd440;
	abs.f64 	%fd442, %fd86;
	setp.ltu.f64 	%p87, %fd442, 0d41E0000000000000;
	@%p87 bra 	$L__BB5_71;

	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd818, [retval0+0];
	} // callseq 66
	ld.local.u32 	%r293, [%rd1];

$L__BB5_71:
	and.b32  	%r156, %r293, 1;
	shl.b32 	%r157, %r293, 3;
	and.b32  	%r158, %r157, 8;
	setp.eq.s32 	%p88, %r156, 0;
	selp.f64 	%fd444, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p88;
	mul.wide.s32 	%rd57, %r158, 8;
	add.s64 	%rd59, %rd42, %rd57;
	ld.global.nc.f64 	%fd445, [%rd59+8];
	mul.rn.f64 	%fd91, %fd818, %fd818;
	fma.rn.f64 	%fd446, %fd444, %fd91, %fd445;
	ld.global.nc.f64 	%fd447, [%rd59+16];
	fma.rn.f64 	%fd448, %fd446, %fd91, %fd447;
	ld.global.nc.f64 	%fd449, [%rd59+24];
	fma.rn.f64 	%fd450, %fd448, %fd91, %fd449;
	ld.global.nc.f64 	%fd451, [%rd59+32];
	fma.rn.f64 	%fd452, %fd450, %fd91, %fd451;
	ld.global.nc.f64 	%fd453, [%rd59+40];
	fma.rn.f64 	%fd454, %fd452, %fd91, %fd453;
	ld.global.nc.f64 	%fd455, [%rd59+48];
	fma.rn.f64 	%fd92, %fd454, %fd91, %fd455;
	fma.rn.f64 	%fd820, %fd92, %fd818, %fd818;
	@%p88 bra 	$L__BB5_73;

	mov.f64 	%fd456, 0d3FF0000000000000;
	fma.rn.f64 	%fd820, %fd92, %fd91, %fd456;

$L__BB5_73:
	and.b32  	%r159, %r293, 2;
	setp.eq.s32 	%p89, %r159, 0;
	@%p89 bra 	$L__BB5_75;

	mov.f64 	%fd457, 0d0000000000000000;
	mov.f64 	%fd458, 0dBFF0000000000000;
	fma.rn.f64 	%fd820, %fd820, %fd458, %fd457;

$L__BB5_75:
	add.rn.f64 	%fd98, %fd84, %fd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd98;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd98;
	}
	and.b32  	%r162, %r161, 2147483647;
	setp.eq.s32 	%p90, %r162, 2146435072;
	setp.eq.s32 	%p91, %r160, 0;
	and.pred  	%p92, %p91, %p90;
	@%p92 bra 	$L__BB5_78;
	bra.uni 	$L__BB5_76;

$L__BB5_78:
	mov.f64 	%fd468, 0d0000000000000000;
	mul.rn.f64 	%fd821, %fd98, %fd468;
	mov.u32 	%r294, 0;
	bra.uni 	$L__BB5_79;

$L__BB5_76:
	mul.rn.f64 	%fd459, %fd98, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r294, %fd459;
	st.local.u32 	[%rd1], %r294;
	cvt.rn.f64.s32 	%fd460, %r294;
	neg.f64 	%fd461, %fd460;
	mov.f64 	%fd462, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd463, %fd461, %fd462, %fd98;
	mov.f64 	%fd464, 0d3C91A62633145C00;
	fma.rn.f64 	%fd465, %fd461, %fd464, %fd463;
	mov.f64 	%fd466, 0d397B839A252049C0;
	fma.rn.f64 	%fd821, %fd461, %fd466, %fd465;
	abs.f64 	%fd467, %fd98;
	setp.ltu.f64 	%p93, %fd467, 0d41E0000000000000;
	@%p93 bra 	$L__BB5_79;

	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd98;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd821, [retval0+0];
	} // callseq 67
	ld.local.u32 	%r294, [%rd1];

$L__BB5_79:
	and.b32  	%r164, %r294, 1;
	shl.b32 	%r165, %r294, 3;
	and.b32  	%r166, %r165, 8;
	setp.eq.s32 	%p94, %r164, 0;
	selp.f64 	%fd469, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p94;
	mul.wide.s32 	%rd61, %r166, 8;
	add.s64 	%rd63, %rd42, %rd61;
	ld.global.nc.f64 	%fd470, [%rd63+8];
	mul.rn.f64 	%fd103, %fd821, %fd821;
	fma.rn.f64 	%fd471, %fd469, %fd103, %fd470;
	ld.global.nc.f64 	%fd472, [%rd63+16];
	fma.rn.f64 	%fd473, %fd471, %fd103, %fd472;
	ld.global.nc.f64 	%fd474, [%rd63+24];
	fma.rn.f64 	%fd475, %fd473, %fd103, %fd474;
	ld.global.nc.f64 	%fd476, [%rd63+32];
	fma.rn.f64 	%fd477, %fd475, %fd103, %fd476;
	ld.global.nc.f64 	%fd478, [%rd63+40];
	fma.rn.f64 	%fd479, %fd477, %fd103, %fd478;
	ld.global.nc.f64 	%fd480, [%rd63+48];
	fma.rn.f64 	%fd104, %fd479, %fd103, %fd480;
	fma.rn.f64 	%fd823, %fd104, %fd821, %fd821;
	@%p94 bra 	$L__BB5_81;

	mov.f64 	%fd481, 0d3FF0000000000000;
	fma.rn.f64 	%fd823, %fd104, %fd103, %fd481;

$L__BB5_81:
	and.b32  	%r167, %r294, 2;
	setp.eq.s32 	%p95, %r167, 0;
	@%p95 bra 	$L__BB5_83;

	mov.f64 	%fd482, 0d0000000000000000;
	mov.f64 	%fd483, 0dBFF0000000000000;
	fma.rn.f64 	%fd823, %fd823, %fd483, %fd482;

$L__BB5_83:
	mul.rn.f64 	%fd484, %fd823, 0d4034000000000000;
	mul.rn.f64 	%fd485, %fd820, 0d4034000000000000;
	add.rn.f64 	%fd110, %fd485, %fd484;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r168}, %fd85;
	}
	and.b32  	%r169, %r168, 2147483647;
	setp.eq.s32 	%p96, %r169, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r170, %temp}, %fd85;
	}
	setp.eq.s32 	%p97, %r170, 0;
	and.pred  	%p98, %p97, %p96;
	@%p98 bra 	$L__BB5_86;
	bra.uni 	$L__BB5_84;

$L__BB5_86:
	mov.f64 	%fd495, 0d0000000000000000;
	mul.rn.f64 	%fd824, %fd85, %fd495;
	mov.u32 	%r295, 0;
	bra.uni 	$L__BB5_87;

$L__BB5_84:
	mul.rn.f64 	%fd486, %fd85, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r295, %fd486;
	st.local.u32 	[%rd1], %r295;
	cvt.rn.f64.s32 	%fd487, %r295;
	neg.f64 	%fd488, %fd487;
	mov.f64 	%fd489, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd490, %fd488, %fd489, %fd85;
	mov.f64 	%fd491, 0d3C91A62633145C00;
	fma.rn.f64 	%fd492, %fd488, %fd491, %fd490;
	mov.f64 	%fd493, 0d397B839A252049C0;
	fma.rn.f64 	%fd824, %fd488, %fd493, %fd492;
	abs.f64 	%fd494, %fd85;
	setp.ltu.f64 	%p99, %fd494, 0d41E0000000000000;
	@%p99 bra 	$L__BB5_87;

	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd824, [retval0+0];
	} // callseq 68
	ld.local.u32 	%r295, [%rd1];

$L__BB5_87:
	and.b32  	%r172, %r295, 1;
	shl.b32 	%r173, %r295, 3;
	and.b32  	%r174, %r173, 8;
	setp.eq.s32 	%p100, %r172, 0;
	selp.f64 	%fd496, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p100;
	mul.wide.s32 	%rd65, %r174, 8;
	add.s64 	%rd67, %rd42, %rd65;
	ld.global.nc.f64 	%fd497, [%rd67+8];
	mul.rn.f64 	%fd115, %fd824, %fd824;
	fma.rn.f64 	%fd498, %fd496, %fd115, %fd497;
	ld.global.nc.f64 	%fd499, [%rd67+16];
	fma.rn.f64 	%fd500, %fd498, %fd115, %fd499;
	ld.global.nc.f64 	%fd501, [%rd67+24];
	fma.rn.f64 	%fd502, %fd500, %fd115, %fd501;
	ld.global.nc.f64 	%fd503, [%rd67+32];
	fma.rn.f64 	%fd504, %fd502, %fd115, %fd503;
	ld.global.nc.f64 	%fd505, [%rd67+40];
	fma.rn.f64 	%fd506, %fd504, %fd115, %fd505;
	ld.global.nc.f64 	%fd507, [%rd67+48];
	fma.rn.f64 	%fd116, %fd506, %fd115, %fd507;
	fma.rn.f64 	%fd826, %fd116, %fd824, %fd824;
	@%p100 bra 	$L__BB5_89;

	mov.f64 	%fd508, 0d3FF0000000000000;
	fma.rn.f64 	%fd826, %fd116, %fd115, %fd508;

$L__BB5_89:
	and.b32  	%r175, %r295, 2;
	setp.eq.s32 	%p101, %r175, 0;
	@%p101 bra 	$L__BB5_91;

	mov.f64 	%fd509, 0d0000000000000000;
	mov.f64 	%fd510, 0dBFF0000000000000;
	fma.rn.f64 	%fd826, %fd826, %fd510, %fd509;

$L__BB5_91:
	div.rn.f64 	%fd122, %fd85, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r176, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd122;
	}
	and.b32  	%r178, %r177, 2147483647;
	setp.eq.s32 	%p102, %r178, 2146435072;
	setp.eq.s32 	%p103, %r176, 0;
	and.pred  	%p104, %p103, %p102;
	@%p104 bra 	$L__BB5_94;
	bra.uni 	$L__BB5_92;

$L__BB5_94:
	mov.f64 	%fd520, 0d0000000000000000;
	mul.rn.f64 	%fd827, %fd122, %fd520;
	mov.u32 	%r296, 0;
	bra.uni 	$L__BB5_95;

$L__BB5_92:
	mul.rn.f64 	%fd511, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r296, %fd511;
	st.local.u32 	[%rd1], %r296;
	cvt.rn.f64.s32 	%fd512, %r296;
	neg.f64 	%fd513, %fd512;
	mov.f64 	%fd514, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd515, %fd513, %fd514, %fd122;
	mov.f64 	%fd516, 0d3C91A62633145C00;
	fma.rn.f64 	%fd517, %fd513, %fd516, %fd515;
	mov.f64 	%fd518, 0d397B839A252049C0;
	fma.rn.f64 	%fd827, %fd513, %fd518, %fd517;
	abs.f64 	%fd519, %fd122;
	setp.ltu.f64 	%p105, %fd519, 0d41E0000000000000;
	@%p105 bra 	$L__BB5_95;

	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd827, [retval0+0];
	} // callseq 69
	ld.local.u32 	%r296, [%rd1];

$L__BB5_95:
	and.b32  	%r180, %r296, 1;
	shl.b32 	%r181, %r296, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p106, %r180, 0;
	selp.f64 	%fd521, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p106;
	mul.wide.s32 	%rd69, %r182, 8;
	add.s64 	%rd71, %rd42, %rd69;
	ld.global.nc.f64 	%fd522, [%rd71+8];
	mul.rn.f64 	%fd127, %fd827, %fd827;
	fma.rn.f64 	%fd523, %fd521, %fd127, %fd522;
	ld.global.nc.f64 	%fd524, [%rd71+16];
	fma.rn.f64 	%fd525, %fd523, %fd127, %fd524;
	ld.global.nc.f64 	%fd526, [%rd71+24];
	fma.rn.f64 	%fd527, %fd525, %fd127, %fd526;
	ld.global.nc.f64 	%fd528, [%rd71+32];
	fma.rn.f64 	%fd529, %fd527, %fd127, %fd528;
	ld.global.nc.f64 	%fd530, [%rd71+40];
	fma.rn.f64 	%fd531, %fd529, %fd127, %fd530;
	ld.global.nc.f64 	%fd532, [%rd71+48];
	fma.rn.f64 	%fd128, %fd531, %fd127, %fd532;
	fma.rn.f64 	%fd829, %fd128, %fd827, %fd827;
	@%p106 bra 	$L__BB5_97;

	mov.f64 	%fd533, 0d3FF0000000000000;
	fma.rn.f64 	%fd829, %fd128, %fd127, %fd533;

$L__BB5_97:
	and.b32  	%r183, %r296, 2;
	setp.eq.s32 	%p107, %r183, 0;
	@%p107 bra 	$L__BB5_99;

	mov.f64 	%fd534, 0d0000000000000000;
	mov.f64 	%fd535, 0dBFF0000000000000;
	fma.rn.f64 	%fd829, %fd829, %fd535, %fd534;

$L__BB5_99:
	mul.rn.f64 	%fd536, %fd829, 0d4044000000000000;
	mul.rn.f64 	%fd537, %fd826, 0d4034000000000000;
	add.rn.f64 	%fd134, %fd537, %fd536;
	div.rn.f64 	%fd135, %fd85, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r184, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r185}, %fd135;
	}
	and.b32  	%r186, %r185, 2147483647;
	setp.eq.s32 	%p108, %r186, 2146435072;
	setp.eq.s32 	%p109, %r184, 0;
	and.pred  	%p110, %p109, %p108;
	@%p110 bra 	$L__BB5_102;
	bra.uni 	$L__BB5_100;

$L__BB5_102:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd830, %fd135, %fd547;
	mov.u32 	%r297, 0;
	bra.uni 	$L__BB5_103;

$L__BB5_100:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r297, %fd538;
	st.local.u32 	[%rd1], %r297;
	cvt.rn.f64.s32 	%fd539, %r297;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd830, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p111, %fd546, 0d41E0000000000000;
	@%p111 bra 	$L__BB5_103;

	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd830, [retval0+0];
	} // callseq 70
	ld.local.u32 	%r297, [%rd1];

$L__BB5_103:
	and.b32  	%r188, %r297, 1;
	shl.b32 	%r189, %r297, 3;
	and.b32  	%r190, %r189, 8;
	setp.eq.s32 	%p112, %r188, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p112;
	mul.wide.s32 	%rd73, %r190, 8;
	add.s64 	%rd75, %rd42, %rd73;
	ld.global.nc.f64 	%fd549, [%rd75+8];
	mul.rn.f64 	%fd140, %fd830, %fd830;
	fma.rn.f64 	%fd550, %fd548, %fd140, %fd549;
	ld.global.nc.f64 	%fd551, [%rd75+16];
	fma.rn.f64 	%fd552, %fd550, %fd140, %fd551;
	ld.global.nc.f64 	%fd553, [%rd75+24];
	fma.rn.f64 	%fd554, %fd552, %fd140, %fd553;
	ld.global.nc.f64 	%fd555, [%rd75+32];
	fma.rn.f64 	%fd556, %fd554, %fd140, %fd555;
	ld.global.nc.f64 	%fd557, [%rd75+40];
	fma.rn.f64 	%fd558, %fd556, %fd140, %fd557;
	ld.global.nc.f64 	%fd559, [%rd75+48];
	fma.rn.f64 	%fd141, %fd558, %fd140, %fd559;
	fma.rn.f64 	%fd832, %fd141, %fd830, %fd830;
	@%p112 bra 	$L__BB5_105;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd832, %fd141, %fd140, %fd560;

$L__BB5_105:
	and.b32  	%r191, %r297, 2;
	setp.eq.s32 	%p113, %r191, 0;
	@%p113 bra 	$L__BB5_107;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd832, %fd832, %fd562, %fd561;

$L__BB5_107:
	mul.rn.f64 	%fd563, %fd832, 0d4064000000000000;
	add.rn.f64 	%fd147, %fd134, %fd563;
	div.rn.f64 	%fd148, %fd85, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r192, %temp}, %fd148;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd148;
	}
	and.b32  	%r194, %r193, 2147483647;
	setp.eq.s32 	%p114, %r194, 2146435072;
	setp.eq.s32 	%p115, %r192, 0;
	and.pred  	%p116, %p115, %p114;
	@%p116 bra 	$L__BB5_110;
	bra.uni 	$L__BB5_108;

$L__BB5_110:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd833, %fd148, %fd573;
	mov.u32 	%r298, 0;
	bra.uni 	$L__BB5_111;

$L__BB5_108:
	mul.rn.f64 	%fd564, %fd148, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r298, %fd564;
	st.local.u32 	[%rd1], %r298;
	cvt.rn.f64.s32 	%fd565, %r298;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd148;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd833, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd148;
	setp.ltu.f64 	%p117, %fd572, 0d41E0000000000000;
	@%p117 bra 	$L__BB5_111;

	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd833, [retval0+0];
	} // callseq 71
	ld.local.u32 	%r298, [%rd1];

$L__BB5_111:
	and.b32  	%r196, %r298, 1;
	shl.b32 	%r197, %r298, 3;
	and.b32  	%r198, %r197, 8;
	setp.eq.s32 	%p118, %r196, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd77, %r198, 8;
	add.s64 	%rd79, %rd42, %rd77;
	ld.global.nc.f64 	%fd575, [%rd79+8];
	mul.rn.f64 	%fd153, %fd833, %fd833;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd79+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd79+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd79+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd79+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd79+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd835, %fd154, %fd833, %fd833;
	@%p118 bra 	$L__BB5_113;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd835, %fd154, %fd153, %fd586;

$L__BB5_113:
	and.b32  	%r199, %r298, 2;
	setp.eq.s32 	%p119, %r199, 0;
	@%p119 bra 	$L__BB5_115;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd835, %fd835, %fd588, %fd587;

$L__BB5_115:
	mul.rn.f64 	%fd589, %fd835, 0d4074000000000000;
	add.rn.f64 	%fd160, %fd147, %fd589;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd84;
	}
	and.b32  	%r201, %r200, 2147483647;
	setp.eq.s32 	%p120, %r201, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r202, %temp}, %fd84;
	}
	setp.eq.s32 	%p121, %r202, 0;
	and.pred  	%p122, %p121, %p120;
	@%p122 bra 	$L__BB5_118;
	bra.uni 	$L__BB5_116;

$L__BB5_118:
	mov.f64 	%fd599, 0d0000000000000000;
	mul.rn.f64 	%fd836, %fd84, %fd599;
	mov.u32 	%r299, 0;
	bra.uni 	$L__BB5_119;

$L__BB5_116:
	mul.rn.f64 	%fd590, %fd84, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd590;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd591, %r299;
	neg.f64 	%fd592, %fd591;
	mov.f64 	%fd593, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd594, %fd592, %fd593, %fd84;
	mov.f64 	%fd595, 0d3C91A62633145C00;
	fma.rn.f64 	%fd596, %fd592, %fd595, %fd594;
	mov.f64 	%fd597, 0d397B839A252049C0;
	fma.rn.f64 	%fd836, %fd592, %fd597, %fd596;
	abs.f64 	%fd598, %fd84;
	setp.ltu.f64 	%p123, %fd598, 0d41E0000000000000;
	@%p123 bra 	$L__BB5_119;

	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd836, [retval0+0];
	} // callseq 72
	ld.local.u32 	%r299, [%rd1];

$L__BB5_119:
	and.b32  	%r204, %r299, 1;
	shl.b32 	%r205, %r299, 3;
	and.b32  	%r206, %r205, 8;
	setp.eq.s32 	%p124, %r204, 0;
	selp.f64 	%fd600, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p124;
	mul.wide.s32 	%rd81, %r206, 8;
	add.s64 	%rd83, %rd42, %rd81;
	ld.global.nc.f64 	%fd601, [%rd83+8];
	mul.rn.f64 	%fd165, %fd836, %fd836;
	fma.rn.f64 	%fd602, %fd600, %fd165, %fd601;
	ld.global.nc.f64 	%fd603, [%rd83+16];
	fma.rn.f64 	%fd604, %fd602, %fd165, %fd603;
	ld.global.nc.f64 	%fd605, [%rd83+24];
	fma.rn.f64 	%fd606, %fd604, %fd165, %fd605;
	ld.global.nc.f64 	%fd607, [%rd83+32];
	fma.rn.f64 	%fd608, %fd606, %fd165, %fd607;
	ld.global.nc.f64 	%fd609, [%rd83+40];
	fma.rn.f64 	%fd610, %fd608, %fd165, %fd609;
	ld.global.nc.f64 	%fd611, [%rd83+48];
	fma.rn.f64 	%fd166, %fd610, %fd165, %fd611;
	fma.rn.f64 	%fd838, %fd166, %fd836, %fd836;
	@%p124 bra 	$L__BB5_121;

	mov.f64 	%fd612, 0d3FF0000000000000;
	fma.rn.f64 	%fd838, %fd166, %fd165, %fd612;

$L__BB5_121:
	and.b32  	%r207, %r299, 2;
	setp.eq.s32 	%p125, %r207, 0;
	@%p125 bra 	$L__BB5_123;

	mov.f64 	%fd613, 0d0000000000000000;
	mov.f64 	%fd614, 0dBFF0000000000000;
	fma.rn.f64 	%fd838, %fd838, %fd614, %fd613;

$L__BB5_123:
	div.rn.f64 	%fd172, %fd84, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd172;
	}
	and.b32  	%r210, %r209, 2147483647;
	setp.eq.s32 	%p126, %r210, 2146435072;
	setp.eq.s32 	%p127, %r208, 0;
	and.pred  	%p128, %p127, %p126;
	@%p128 bra 	$L__BB5_126;
	bra.uni 	$L__BB5_124;

$L__BB5_126:
	mov.f64 	%fd624, 0d0000000000000000;
	mul.rn.f64 	%fd839, %fd172, %fd624;
	mov.u32 	%r300, 0;
	bra.uni 	$L__BB5_127;

$L__BB5_124:
	mul.rn.f64 	%fd615, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r300, %fd615;
	st.local.u32 	[%rd1], %r300;
	cvt.rn.f64.s32 	%fd616, %r300;
	neg.f64 	%fd617, %fd616;
	mov.f64 	%fd618, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd619, %fd617, %fd618, %fd172;
	mov.f64 	%fd620, 0d3C91A62633145C00;
	fma.rn.f64 	%fd621, %fd617, %fd620, %fd619;
	mov.f64 	%fd622, 0d397B839A252049C0;
	fma.rn.f64 	%fd839, %fd617, %fd622, %fd621;
	abs.f64 	%fd623, %fd172;
	setp.ltu.f64 	%p129, %fd623, 0d41E0000000000000;
	@%p129 bra 	$L__BB5_127;

	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd839, [retval0+0];
	} // callseq 73
	ld.local.u32 	%r300, [%rd1];

$L__BB5_127:
	and.b32  	%r212, %r300, 1;
	shl.b32 	%r213, %r300, 3;
	and.b32  	%r214, %r213, 8;
	setp.eq.s32 	%p130, %r212, 0;
	selp.f64 	%fd625, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p130;
	mul.wide.s32 	%rd85, %r214, 8;
	add.s64 	%rd87, %rd42, %rd85;
	ld.global.nc.f64 	%fd626, [%rd87+8];
	mul.rn.f64 	%fd177, %fd839, %fd839;
	fma.rn.f64 	%fd627, %fd625, %fd177, %fd626;
	ld.global.nc.f64 	%fd628, [%rd87+16];
	fma.rn.f64 	%fd629, %fd627, %fd177, %fd628;
	ld.global.nc.f64 	%fd630, [%rd87+24];
	fma.rn.f64 	%fd631, %fd629, %fd177, %fd630;
	ld.global.nc.f64 	%fd632, [%rd87+32];
	fma.rn.f64 	%fd633, %fd631, %fd177, %fd632;
	ld.global.nc.f64 	%fd634, [%rd87+40];
	fma.rn.f64 	%fd635, %fd633, %fd177, %fd634;
	ld.global.nc.f64 	%fd636, [%rd87+48];
	fma.rn.f64 	%fd178, %fd635, %fd177, %fd636;
	fma.rn.f64 	%fd841, %fd178, %fd839, %fd839;
	@%p130 bra 	$L__BB5_129;

	mov.f64 	%fd637, 0d3FF0000000000000;
	fma.rn.f64 	%fd841, %fd178, %fd177, %fd637;

$L__BB5_129:
	and.b32  	%r215, %r300, 2;
	setp.eq.s32 	%p131, %r215, 0;
	@%p131 bra 	$L__BB5_131;

	mov.f64 	%fd638, 0d0000000000000000;
	mov.f64 	%fd639, 0dBFF0000000000000;
	fma.rn.f64 	%fd841, %fd841, %fd639, %fd638;

$L__BB5_131:
	mul.rn.f64 	%fd640, %fd841, 0d4044000000000000;
	mul.rn.f64 	%fd641, %fd838, 0d4034000000000000;
	add.rn.f64 	%fd184, %fd641, %fd640;
	div.rn.f64 	%fd185, %fd84, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd185;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd185;
	}
	and.b32  	%r218, %r217, 2147483647;
	setp.eq.s32 	%p132, %r218, 2146435072;
	setp.eq.s32 	%p133, %r216, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB5_134;
	bra.uni 	$L__BB5_132;

$L__BB5_134:
	mov.f64 	%fd651, 0d0000000000000000;
	mul.rn.f64 	%fd842, %fd185, %fd651;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB5_135;

$L__BB5_132:
	mul.rn.f64 	%fd642, %fd185, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd642;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd643, %r301;
	neg.f64 	%fd644, %fd643;
	mov.f64 	%fd645, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd646, %fd644, %fd645, %fd185;
	mov.f64 	%fd647, 0d3C91A62633145C00;
	fma.rn.f64 	%fd648, %fd644, %fd647, %fd646;
	mov.f64 	%fd649, 0d397B839A252049C0;
	fma.rn.f64 	%fd842, %fd644, %fd649, %fd648;
	abs.f64 	%fd650, %fd185;
	setp.ltu.f64 	%p135, %fd650, 0d41E0000000000000;
	@%p135 bra 	$L__BB5_135;

	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd185;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd842, [retval0+0];
	} // callseq 74
	ld.local.u32 	%r301, [%rd1];

$L__BB5_135:
	and.b32  	%r220, %r301, 1;
	shl.b32 	%r221, %r301, 3;
	and.b32  	%r222, %r221, 8;
	setp.eq.s32 	%p136, %r220, 0;
	selp.f64 	%fd652, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd89, %r222, 8;
	add.s64 	%rd91, %rd42, %rd89;
	ld.global.nc.f64 	%fd653, [%rd91+8];
	mul.rn.f64 	%fd190, %fd842, %fd842;
	fma.rn.f64 	%fd654, %fd652, %fd190, %fd653;
	ld.global.nc.f64 	%fd655, [%rd91+16];
	fma.rn.f64 	%fd656, %fd654, %fd190, %fd655;
	ld.global.nc.f64 	%fd657, [%rd91+24];
	fma.rn.f64 	%fd658, %fd656, %fd190, %fd657;
	ld.global.nc.f64 	%fd659, [%rd91+32];
	fma.rn.f64 	%fd660, %fd658, %fd190, %fd659;
	ld.global.nc.f64 	%fd661, [%rd91+40];
	fma.rn.f64 	%fd662, %fd660, %fd190, %fd661;
	ld.global.nc.f64 	%fd663, [%rd91+48];
	fma.rn.f64 	%fd191, %fd662, %fd190, %fd663;
	fma.rn.f64 	%fd844, %fd191, %fd842, %fd842;
	@%p136 bra 	$L__BB5_137;

	mov.f64 	%fd664, 0d3FF0000000000000;
	fma.rn.f64 	%fd844, %fd191, %fd190, %fd664;

$L__BB5_137:
	and.b32  	%r223, %r301, 2;
	setp.eq.s32 	%p137, %r223, 0;
	@%p137 bra 	$L__BB5_139;

	mov.f64 	%fd665, 0d0000000000000000;
	mov.f64 	%fd666, 0dBFF0000000000000;
	fma.rn.f64 	%fd844, %fd844, %fd666, %fd665;

$L__BB5_139:
	mul.rn.f64 	%fd667, %fd844, 0d4062C00000000000;
	add.rn.f64 	%fd197, %fd184, %fd667;
	div.rn.f64 	%fd198, %fd84, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd198;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd198;
	}
	and.b32  	%r226, %r225, 2147483647;
	setp.eq.s32 	%p138, %r226, 2146435072;
	setp.eq.s32 	%p139, %r224, 0;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB5_142;
	bra.uni 	$L__BB5_140;

$L__BB5_142:
	mov.f64 	%fd677, 0d0000000000000000;
	mul.rn.f64 	%fd845, %fd198, %fd677;
	mov.u32 	%r302, 0;
	bra.uni 	$L__BB5_143;

$L__BB5_140:
	mul.rn.f64 	%fd668, %fd198, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd668;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd669, %r302;
	neg.f64 	%fd670, %fd669;
	mov.f64 	%fd671, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd672, %fd670, %fd671, %fd198;
	mov.f64 	%fd673, 0d3C91A62633145C00;
	fma.rn.f64 	%fd674, %fd670, %fd673, %fd672;
	mov.f64 	%fd675, 0d397B839A252049C0;
	fma.rn.f64 	%fd845, %fd670, %fd675, %fd674;
	abs.f64 	%fd676, %fd198;
	setp.ltu.f64 	%p141, %fd676, 0d41E0000000000000;
	@%p141 bra 	$L__BB5_143;

	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd198;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd845, [retval0+0];
	} // callseq 75
	ld.local.u32 	%r302, [%rd1];

$L__BB5_143:
	and.b32  	%r228, %r302, 1;
	shl.b32 	%r229, %r302, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p142, %r228, 0;
	selp.f64 	%fd678, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd93, %r230, 8;
	add.s64 	%rd95, %rd42, %rd93;
	ld.global.nc.f64 	%fd679, [%rd95+8];
	mul.rn.f64 	%fd203, %fd845, %fd845;
	fma.rn.f64 	%fd680, %fd678, %fd203, %fd679;
	ld.global.nc.f64 	%fd681, [%rd95+16];
	fma.rn.f64 	%fd682, %fd680, %fd203, %fd681;
	ld.global.nc.f64 	%fd683, [%rd95+24];
	fma.rn.f64 	%fd684, %fd682, %fd203, %fd683;
	ld.global.nc.f64 	%fd685, [%rd95+32];
	fma.rn.f64 	%fd686, %fd684, %fd203, %fd685;
	ld.global.nc.f64 	%fd687, [%rd95+40];
	fma.rn.f64 	%fd688, %fd686, %fd203, %fd687;
	ld.global.nc.f64 	%fd689, [%rd95+48];
	fma.rn.f64 	%fd204, %fd688, %fd203, %fd689;
	fma.rn.f64 	%fd847, %fd204, %fd845, %fd845;
	@%p142 bra 	$L__BB5_145;

	mov.f64 	%fd690, 0d3FF0000000000000;
	fma.rn.f64 	%fd847, %fd204, %fd203, %fd690;

$L__BB5_145:
	and.b32  	%r231, %r302, 2;
	setp.eq.s32 	%p143, %r231, 0;
	@%p143 bra 	$L__BB5_147;

	mov.f64 	%fd691, 0d0000000000000000;
	mov.f64 	%fd692, 0dBFF0000000000000;
	fma.rn.f64 	%fd847, %fd847, %fd692, %fd691;

$L__BB5_147:
	mul.rn.f64 	%fd693, %fd847, 0d4072C00000000000;
	add.rn.f64 	%fd694, %fd197, %fd693;
	add.rn.f64 	%fd210, %fd110, %fd694;
	add.rn.f64 	%fd211, %fd110, %fd160;
	add.rn.f64 	%fd695, %fd80, %fd80;
	add.rn.f64 	%fd696, %fd695, 0dC059000000000000;
	mul.rn.f64 	%fd697, %fd81, 0d4008000000000000;
	add.rn.f64 	%fd212, %fd697, %fd696;
	abs.f64 	%fd213, %fd81;
	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd213;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 76
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd81;
	}
	setp.lt.s32 	%p144, %r53, 0;
	and.pred  	%p4, %p144, %p7;
	not.pred 	%p146, %p4;
	@%p146 bra 	$L__BB5_149;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd850;
	}
	xor.b32  	%r233, %r232, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd850;
	}
	mov.b64 	%fd850, {%r234, %r233};

$L__BB5_149:
	setp.eq.f64 	%p147, %fd81, 0d0000000000000000;
	@%p147 bra 	$L__BB5_153;
	bra.uni 	$L__BB5_150;

$L__BB5_153:
	selp.b32 	%r235, %r53, 0, %p7;
	mov.u32 	%r236, 0;
	or.b32  	%r237, %r235, 2146435072;
	setp.lt.s32 	%p151, %r2, 0;
	selp.b32 	%r238, %r237, %r235, %p151;
	mov.b64 	%fd850, {%r236, %r238};
	bra.uni 	$L__BB5_154;

$L__BB5_150:
	setp.gt.s32 	%p148, %r53, -1;
	@%p148 bra 	$L__BB5_154;

	mov.f64 	%fd698, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd699, %fd698;
	setp.eq.f64 	%p149, %fd699, 0d4000000000000000;
	@%p149 bra 	$L__BB5_154;

	mov.f64 	%fd850, 0dFFF8000000000000;

$L__BB5_154:
	add.rn.f64 	%fd701, %fd81, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r239}, %fd701;
	}
	and.b32  	%r240, %r239, 2146435072;
	setp.ne.s32 	%p152, %r240, 2146435072;
	@%p152 bra 	$L__BB5_161;

	setp.gtu.f64 	%p153, %fd213, 0d7FF0000000000000;
	@%p153 bra 	$L__BB5_160;
	bra.uni 	$L__BB5_156;

$L__BB5_160:
	mov.f64 	%fd703, 0d4000000000000000;
	add.rn.f64 	%fd850, %fd81, %fd703;
	bra.uni 	$L__BB5_161;

$L__BB5_156:
	mov.f64 	%fd702, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd702;
	}
	and.b32  	%r54, %r2, 2147483647;
	setp.eq.s32 	%p154, %r54, 2146435072;
	setp.eq.s32 	%p155, %r241, 0;
	and.pred  	%p156, %p154, %p155;
	@%p156 bra 	$L__BB5_159;
	bra.uni 	$L__BB5_157;

$L__BB5_159:
	setp.gt.f64 	%p163, %fd213, 0d3FF0000000000000;
	selp.b32 	%r248, 2146435072, 0, %p163;
	mov.u32 	%r249, 0;
	xor.b32  	%r250, %r248, 2146435072;
	setp.lt.s32 	%p164, %r2, 0;
	selp.b32 	%r251, %r250, %r248, %p164;
	setp.eq.f64 	%p165, %fd81, 0dBFF0000000000000;
	selp.b32 	%r252, 1072693248, %r251, %p165;
	mov.b64 	%fd850, {%r249, %r252};
	bra.uni 	$L__BB5_161;

$L__BB5_157:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd81;
	}
	and.b32  	%r243, %r53, 2147483647;
	setp.ne.s32 	%p157, %r243, 2146435072;
	setp.ne.s32 	%p158, %r242, 0;
	or.pred  	%p159, %p157, %p158;
	@%p159 bra 	$L__BB5_161;

	setp.gt.s32 	%p160, %r2, -1;
	selp.b32 	%r244, 2146435072, 0, %p160;
	mov.u32 	%r245, 0;
	setp.ne.s32 	%p161, %r54, 1071644672;
	and.pred  	%p162, %p161, %p4;
	or.b32  	%r246, %r244, -2147483648;
	selp.b32 	%r247, %r246, %r244, %p162;
	mov.b64 	%fd850, {%r245, %r247};

$L__BB5_161:
	mul.rn.f64 	%fd704, %fd850, 0d3FC999999999999A;
	setp.eq.f64 	%p166, %fd81, 0d3FF0000000000000;
	selp.f64 	%fd705, 0d3FC999999999999A, %fd704, %p166;
	add.rn.f64 	%fd706, %fd212, %fd705;
	mul.rn.f64 	%fd707, %fd81, %fd80;
	mul.rn.f64 	%fd223, %fd707, 0d3FB999999999999A;
	add.rn.f64 	%fd708, %fd223, %fd706;
	mul.rn.f64 	%fd709, %fd83, 0d3FC999999999999A;
	add.rn.f64 	%fd710, %fd709, %fd708;
	mul.rn.f64 	%fd711, %fd211, 0d3FE5555555555555;
	add.rn.f64 	%fd224, %fd711, %fd710;
	add.rn.f64 	%fd712, %fd81, %fd81;
	add.rn.f64 	%fd713, %fd80, 0d4072C00000000000;
	add.rn.f64 	%fd225, %fd712, %fd713;
	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd853, [retval0+0];
	} // callseq 77
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd80;
	}
	setp.lt.s32 	%p167, %r55, 0;
	and.pred  	%p5, %p167, %p7;
	not.pred 	%p169, %p5;
	@%p169 bra 	$L__BB5_163;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r253}, %fd853;
	}
	xor.b32  	%r254, %r253, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %fd853;
	}
	mov.b64 	%fd853, {%r255, %r254};

$L__BB5_163:
	setp.eq.f64 	%p170, %fd80, 0d0000000000000000;
	@%p170 bra 	$L__BB5_167;
	bra.uni 	$L__BB5_164;

$L__BB5_167:
	selp.b32 	%r256, %r55, 0, %p7;
	mov.u32 	%r257, 0;
	or.b32  	%r258, %r256, 2146435072;
	setp.lt.s32 	%p174, %r2, 0;
	selp.b32 	%r259, %r258, %r256, %p174;
	mov.b64 	%fd853, {%r257, %r259};
	bra.uni 	$L__BB5_168;

$L__BB5_164:
	setp.gt.s32 	%p171, %r55, -1;
	@%p171 bra 	$L__BB5_168;

	mov.f64 	%fd714, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd715, %fd714;
	setp.eq.f64 	%p172, %fd715, 0d4000000000000000;
	@%p172 bra 	$L__BB5_168;

	mov.f64 	%fd853, 0dFFF8000000000000;

$L__BB5_168:
	add.rn.f64 	%fd717, %fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd717;
	}
	and.b32  	%r261, %r260, 2146435072;
	setp.ne.s32 	%p175, %r261, 2146435072;
	@%p175 bra 	$L__BB5_175;

	setp.gtu.f64 	%p176, %fd82, 0d7FF0000000000000;
	@%p176 bra 	$L__BB5_174;
	bra.uni 	$L__BB5_170;

$L__BB5_174:
	mov.f64 	%fd719, 0d4000000000000000;
	add.rn.f64 	%fd853, %fd80, %fd719;
	bra.uni 	$L__BB5_175;

$L__BB5_170:
	mov.f64 	%fd718, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd718;
	}
	and.b32  	%r56, %r2, 2147483647;
	setp.eq.s32 	%p177, %r56, 2146435072;
	setp.eq.s32 	%p178, %r262, 0;
	and.pred  	%p179, %p177, %p178;
	@%p179 bra 	$L__BB5_173;
	bra.uni 	$L__BB5_171;

$L__BB5_173:
	setp.gt.f64 	%p186, %fd82, 0d3FF0000000000000;
	selp.b32 	%r269, 2146435072, 0, %p186;
	mov.u32 	%r270, 0;
	xor.b32  	%r271, %r269, 2146435072;
	setp.lt.s32 	%p187, %r2, 0;
	selp.b32 	%r272, %r271, %r269, %p187;
	setp.eq.f64 	%p188, %fd80, 0dBFF0000000000000;
	selp.b32 	%r273, 1072693248, %r272, %p188;
	mov.b64 	%fd853, {%r270, %r273};
	bra.uni 	$L__BB5_175;

$L__BB5_171:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd80;
	}
	and.b32  	%r264, %r55, 2147483647;
	setp.ne.s32 	%p180, %r264, 2146435072;
	setp.ne.s32 	%p181, %r263, 0;
	or.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB5_175;

	setp.gt.s32 	%p183, %r2, -1;
	selp.b32 	%r265, 2146435072, 0, %p183;
	mov.u32 	%r266, 0;
	setp.ne.s32 	%p184, %r56, 1071644672;
	and.pred  	%p185, %p184, %p5;
	or.b32  	%r267, %r265, -2147483648;
	selp.b32 	%r268, %r267, %r265, %p185;
	mov.b64 	%fd853, {%r266, %r268};

$L__BB5_175:
	mul.rn.f64 	%fd720, %fd853, 0d3FB999999999999A;
	setp.eq.f64 	%p189, %fd80, 0d3FF0000000000000;
	selp.f64 	%fd721, 0d3FB999999999999A, %fd720, %p189;
	add.rn.f64 	%fd722, %fd225, %fd721;
	add.rn.f64 	%fd723, %fd223, %fd722;
	mul.rn.f64 	%fd724, %fd83, 0d3FB999999999999A;
	add.rn.f64 	%fd725, %fd724, %fd723;
	mul.rn.f64 	%fd726, %fd210, 0d3FE5555555555555;
	add.rn.f64 	%fd235, %fd726, %fd725;
	div.rn.f64 	%fd727, %fd78, 0d4066800000000000;
	mul.rn.f64 	%fd236, %fd727, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd236;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd236;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p190, %r276, 2146435072;
	setp.eq.s32 	%p191, %r274, 0;
	and.pred  	%p6, %p191, %p190;
	@%p6 bra 	$L__BB5_178;
	bra.uni 	$L__BB5_176;

$L__BB5_178:
	mov.f64 	%fd737, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd236, %fd737;
	mov.u32 	%r303, 0;
	bra.uni 	$L__BB5_179;

$L__BB5_176:
	mul.rn.f64 	%fd728, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r303, %fd728;
	st.local.u32 	[%rd1], %r303;
	cvt.rn.f64.s32 	%fd729, %r303;
	neg.f64 	%fd730, %fd729;
	mov.f64 	%fd731, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd732, %fd730, %fd731, %fd236;
	mov.f64 	%fd733, 0d3C91A62633145C00;
	fma.rn.f64 	%fd734, %fd730, %fd733, %fd732;
	mov.f64 	%fd735, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd730, %fd735, %fd734;
	abs.f64 	%fd736, %fd236;
	setp.ltu.f64 	%p192, %fd736, 0d41E0000000000000;
	@%p192 bra 	$L__BB5_179;

	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 78
	ld.local.u32 	%r303, [%rd1];

$L__BB5_179:
	and.b32  	%r278, %r303, 1;
	shl.b32 	%r279, %r303, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p193, %r278, 0;
	selp.f64 	%fd738, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p193;
	mul.wide.s32 	%rd97, %r280, 8;
	add.s64 	%rd99, %rd42, %rd97;
	ld.global.nc.f64 	%fd739, [%rd99+8];
	mul.rn.f64 	%fd241, %fd854, %fd854;
	fma.rn.f64 	%fd740, %fd738, %fd241, %fd739;
	ld.global.nc.f64 	%fd741, [%rd99+16];
	fma.rn.f64 	%fd742, %fd740, %fd241, %fd741;
	ld.global.nc.f64 	%fd743, [%rd99+24];
	fma.rn.f64 	%fd744, %fd742, %fd241, %fd743;
	ld.global.nc.f64 	%fd745, [%rd99+32];
	fma.rn.f64 	%fd746, %fd744, %fd241, %fd745;
	ld.global.nc.f64 	%fd747, [%rd99+40];
	fma.rn.f64 	%fd748, %fd746, %fd241, %fd747;
	ld.global.nc.f64 	%fd749, [%rd99+48];
	fma.rn.f64 	%fd242, %fd748, %fd241, %fd749;
	fma.rn.f64 	%fd856, %fd242, %fd854, %fd854;
	@%p193 bra 	$L__BB5_181;

	mov.f64 	%fd750, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd242, %fd241, %fd750;

$L__BB5_181:
	and.b32  	%r281, %r303, 2;
	setp.eq.s32 	%p194, %r281, 0;
	@%p194 bra 	$L__BB5_183;

	mov.f64 	%fd751, 0d0000000000000000;
	mov.f64 	%fd752, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd752, %fd751;

$L__BB5_183:
	@%p6 bra 	$L__BB5_187;
	bra.uni 	$L__BB5_184;

$L__BB5_187:
	mov.f64 	%fd762, 0d0000000000000000;
	mul.rn.f64 	%fd858, %fd236, %fd762;
	mov.u32 	%r305, 1;
	bra.uni 	$L__BB5_188;

$L__BB5_184:
	mul.rn.f64 	%fd753, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd753;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd754, %r304;
	neg.f64 	%fd755, %fd754;
	mov.f64 	%fd756, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd757, %fd755, %fd756, %fd236;
	mov.f64 	%fd758, 0d3C91A62633145C00;
	fma.rn.f64 	%fd759, %fd755, %fd758, %fd757;
	mov.f64 	%fd760, 0d397B839A252049C0;
	fma.rn.f64 	%fd858, %fd755, %fd760, %fd759;
	abs.f64 	%fd761, %fd236;
	setp.ltu.f64 	%p195, %fd761, 0d41E0000000000000;
	@%p195 bra 	$L__BB5_186;

	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd858, [retval0+0];
	} // callseq 79
	ld.local.u32 	%r304, [%rd1];

$L__BB5_186:
	add.s32 	%r305, %r304, 1;

$L__BB5_188:
	and.b32  	%r283, %r305, 1;
	shl.b32 	%r284, %r305, 3;
	and.b32  	%r285, %r284, 8;
	setp.eq.s32 	%p196, %r283, 0;
	selp.f64 	%fd763, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd101, %r285, 8;
	add.s64 	%rd103, %rd42, %rd101;
	ld.global.nc.f64 	%fd764, [%rd103+8];
	mul.rn.f64 	%fd253, %fd858, %fd858;
	fma.rn.f64 	%fd765, %fd763, %fd253, %fd764;
	ld.global.nc.f64 	%fd766, [%rd103+16];
	fma.rn.f64 	%fd767, %fd765, %fd253, %fd766;
	ld.global.nc.f64 	%fd768, [%rd103+24];
	fma.rn.f64 	%fd769, %fd767, %fd253, %fd768;
	ld.global.nc.f64 	%fd770, [%rd103+32];
	fma.rn.f64 	%fd771, %fd769, %fd253, %fd770;
	ld.global.nc.f64 	%fd772, [%rd103+40];
	fma.rn.f64 	%fd773, %fd771, %fd253, %fd772;
	ld.global.nc.f64 	%fd774, [%rd103+48];
	fma.rn.f64 	%fd254, %fd773, %fd253, %fd774;
	fma.rn.f64 	%fd860, %fd254, %fd858, %fd858;
	@%p196 bra 	$L__BB5_190;

	mov.f64 	%fd775, 0d3FF0000000000000;
	fma.rn.f64 	%fd860, %fd254, %fd253, %fd775;

$L__BB5_190:
	and.b32  	%r286, %r305, 2;
	setp.eq.s32 	%p197, %r286, 0;
	@%p197 bra 	$L__BB5_192;

	mov.f64 	%fd776, 0d0000000000000000;
	mov.f64 	%fd777, 0dBFF0000000000000;
	fma.rn.f64 	%fd860, %fd860, %fd777, %fd776;

$L__BB5_192:
	mul.rn.f64 	%fd778, %fd856, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd779, %fd856, %fd778;
	add.rn.f64 	%fd780, %fd779, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd781, %fd780;
	mov.f64 	%fd782, 0dC15854C140000000;
	div.rn.f64 	%fd783, %fd782, %fd781;
	mul.rn.f64 	%fd784, %fd783, %fd860;
	mul.rn.f64 	%fd785, %fd784, 0d400921FB54442D18;
	mul.rn.f64 	%fd786, %fd235, 0d4066800000000000;
	div.rn.f64 	%fd787, %fd786, %fd785;
	add.rn.f64 	%fd788, %fd79, %fd787;
	st.global.f64 	[%rd17], %fd788;
	mul.rn.f64 	%fd789, %fd224, 0d4066800000000000;
	mul.rn.f64 	%fd790, %fd781, %fd780;
	mov.f64 	%fd791, 0dC1582B102DE355C1;
	div.rn.f64 	%fd792, %fd791, %fd790;
	mul.rn.f64 	%fd793, %fd792, 0d400921FB54442D18;
	div.rn.f64 	%fd794, %fd789, %fd793;
	add.rn.f64 	%fd795, %fd78, %fd794;
	st.global.f64 	[%rd18], %fd795;
	ret;

}
	// .globl	gcj02_to_wgs84_exact_cuda
.visible .entry gcj02_to_wgs84_exact_cuda(
	.param .u64 gcj02_to_wgs84_exact_cuda_param_0,
	.param .u64 gcj02_to_wgs84_exact_cuda_param_1,
	.param .f64 gcj02_to_wgs84_exact_cuda_param_2,
	.param .u8 gcj02_to_wgs84_exact_cuda_param_3,
	.param .u32 gcj02_to_wgs84_exact_cuda_param_4
)
{
	.local .align 4 .b8 	__local_depot6[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<321>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<511>;
	.reg .f64 	%fd<1482>;
	.reg .b64 	%rd<184>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd31, [gcj02_to_wgs84_exact_cuda_param_0];
	ld.param.u64 	%rd32, [gcj02_to_wgs84_exact_cuda_param_1];
	ld.param.f64 	%fd453, [gcj02_to_wgs84_exact_cuda_param_2];
	cvta.to.global.u64 	%rd33, %rd32;
	add.u64 	%rd34, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r109, %ntid.x;
	mov.u32 	%r110, %ctaid.x;
	mov.u32 	%r111, %tid.x;
	mad.lo.s32 	%r112, %r110, %r109, %r111;
	cvta.to.global.u64 	%rd62, %rd31;
	mul.wide.s32 	%rd63, %r112, 8;
	add.s64 	%rd29, %rd62, %rd63;
	add.s64 	%rd30, %rd33, %rd63;
	ld.global.f64 	%fd1, [%rd29];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd30];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd9;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p9, %r115, 2146435072;
	setp.eq.s32 	%p10, %r113, 0;
	and.pred  	%p11, %p10, %p9;
	@%p11 bra 	$L__BB6_3;
	bra.uni 	$L__BB6_1;

$L__BB6_3:
	mov.f64 	%fd463, 0d0000000000000000;
	mul.rn.f64 	%fd1371, %fd9, %fd463;
	mov.u32 	%r478, 0;
	bra.uni 	$L__BB6_4;

$L__BB6_1:
	mul.rn.f64 	%fd454, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r478, %fd454;
	st.local.u32 	[%rd1], %r478;
	cvt.rn.f64.s32 	%fd455, %r478;
	neg.f64 	%fd456, %fd455;
	mov.f64 	%fd457, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd458, %fd456, %fd457, %fd9;
	mov.f64 	%fd459, 0d3C91A62633145C00;
	fma.rn.f64 	%fd460, %fd456, %fd459, %fd458;
	mov.f64 	%fd461, 0d397B839A252049C0;
	fma.rn.f64 	%fd1371, %fd456, %fd461, %fd460;
	abs.f64 	%fd462, %fd9;
	setp.ltu.f64 	%p12, %fd462, 0d41E0000000000000;
	@%p12 bra 	$L__BB6_4;

	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1371, [retval0+0];
	} // callseq 80
	ld.local.u32 	%r478, [%rd1];

$L__BB6_4:
	and.b32  	%r117, %r478, 1;
	shl.b32 	%r118, %r478, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p13, %r117, 0;
	selp.f64 	%fd464, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	mul.wide.s32 	%rd65, %r119, 8;
	mov.u64 	%rd66, __cudart_sin_cos_coeffs;
	add.s64 	%rd67, %rd66, %rd65;
	ld.global.nc.f64 	%fd465, [%rd67+8];
	mul.rn.f64 	%fd14, %fd1371, %fd1371;
	fma.rn.f64 	%fd466, %fd464, %fd14, %fd465;
	ld.global.nc.f64 	%fd467, [%rd67+16];
	fma.rn.f64 	%fd468, %fd466, %fd14, %fd467;
	ld.global.nc.f64 	%fd469, [%rd67+24];
	fma.rn.f64 	%fd470, %fd468, %fd14, %fd469;
	ld.global.nc.f64 	%fd471, [%rd67+32];
	fma.rn.f64 	%fd472, %fd470, %fd14, %fd471;
	ld.global.nc.f64 	%fd473, [%rd67+40];
	fma.rn.f64 	%fd474, %fd472, %fd14, %fd473;
	ld.global.nc.f64 	%fd475, [%rd67+48];
	fma.rn.f64 	%fd15, %fd474, %fd14, %fd475;
	fma.rn.f64 	%fd1373, %fd15, %fd1371, %fd1371;
	@%p13 bra 	$L__BB6_6;

	mov.f64 	%fd476, 0d3FF0000000000000;
	fma.rn.f64 	%fd1373, %fd15, %fd14, %fd476;

$L__BB6_6:
	and.b32  	%r120, %r478, 2;
	setp.eq.s32 	%p14, %r120, 0;
	@%p14 bra 	$L__BB6_8;

	mov.f64 	%fd477, 0d0000000000000000;
	mov.f64 	%fd478, 0dBFF0000000000000;
	fma.rn.f64 	%fd1373, %fd1373, %fd478, %fd477;

$L__BB6_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd21;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p15, %r123, 2146435072;
	setp.eq.s32 	%p16, %r121, 0;
	and.pred  	%p17, %p16, %p15;
	@%p17 bra 	$L__BB6_11;
	bra.uni 	$L__BB6_9;

$L__BB6_11:
	mov.f64 	%fd488, 0d0000000000000000;
	mul.rn.f64 	%fd1374, %fd21, %fd488;
	mov.u32 	%r479, 0;
	bra.uni 	$L__BB6_12;

$L__BB6_9:
	mul.rn.f64 	%fd479, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r479, %fd479;
	st.local.u32 	[%rd1], %r479;
	cvt.rn.f64.s32 	%fd480, %r479;
	neg.f64 	%fd481, %fd480;
	mov.f64 	%fd482, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd483, %fd481, %fd482, %fd21;
	mov.f64 	%fd484, 0d3C91A62633145C00;
	fma.rn.f64 	%fd485, %fd481, %fd484, %fd483;
	mov.f64 	%fd486, 0d397B839A252049C0;
	fma.rn.f64 	%fd1374, %fd481, %fd486, %fd485;
	abs.f64 	%fd487, %fd21;
	setp.ltu.f64 	%p18, %fd487, 0d41E0000000000000;
	@%p18 bra 	$L__BB6_12;

	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1374, [retval0+0];
	} // callseq 81
	ld.local.u32 	%r479, [%rd1];

$L__BB6_12:
	and.b32  	%r125, %r479, 1;
	shl.b32 	%r126, %r479, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p19, %r125, 0;
	selp.f64 	%fd489, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd66, %rd69;
	ld.global.nc.f64 	%fd490, [%rd71+8];
	mul.rn.f64 	%fd26, %fd1374, %fd1374;
	fma.rn.f64 	%fd491, %fd489, %fd26, %fd490;
	ld.global.nc.f64 	%fd492, [%rd71+16];
	fma.rn.f64 	%fd493, %fd491, %fd26, %fd492;
	ld.global.nc.f64 	%fd494, [%rd71+24];
	fma.rn.f64 	%fd495, %fd493, %fd26, %fd494;
	ld.global.nc.f64 	%fd496, [%rd71+32];
	fma.rn.f64 	%fd497, %fd495, %fd26, %fd496;
	ld.global.nc.f64 	%fd498, [%rd71+40];
	fma.rn.f64 	%fd499, %fd497, %fd26, %fd498;
	ld.global.nc.f64 	%fd500, [%rd71+48];
	fma.rn.f64 	%fd27, %fd499, %fd26, %fd500;
	fma.rn.f64 	%fd1376, %fd27, %fd1374, %fd1374;
	@%p19 bra 	$L__BB6_14;

	mov.f64 	%fd501, 0d3FF0000000000000;
	fma.rn.f64 	%fd1376, %fd27, %fd26, %fd501;

$L__BB6_14:
	and.b32  	%r128, %r479, 2;
	setp.eq.s32 	%p20, %r128, 0;
	@%p20 bra 	$L__BB6_16;

	mov.f64 	%fd502, 0d0000000000000000;
	mov.f64 	%fd503, 0dBFF0000000000000;
	fma.rn.f64 	%fd1376, %fd1376, %fd503, %fd502;

$L__BB6_16:
	mul.rn.f64 	%fd504, %fd1376, 0d4034000000000000;
	mul.rn.f64 	%fd505, %fd1373, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd505, %fd504;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd8;
	}
	and.b32  	%r130, %r129, 2147483647;
	setp.eq.s32 	%p21, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd8;
	}
	setp.eq.s32 	%p22, %r131, 0;
	and.pred  	%p23, %p22, %p21;
	@%p23 bra 	$L__BB6_19;
	bra.uni 	$L__BB6_17;

$L__BB6_19:
	mov.f64 	%fd515, 0d0000000000000000;
	mul.rn.f64 	%fd1377, %fd8, %fd515;
	mov.u32 	%r480, 0;
	bra.uni 	$L__BB6_20;

$L__BB6_17:
	mul.rn.f64 	%fd506, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r480, %fd506;
	st.local.u32 	[%rd1], %r480;
	cvt.rn.f64.s32 	%fd507, %r480;
	neg.f64 	%fd508, %fd507;
	mov.f64 	%fd509, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd510, %fd508, %fd509, %fd8;
	mov.f64 	%fd511, 0d3C91A62633145C00;
	fma.rn.f64 	%fd512, %fd508, %fd511, %fd510;
	mov.f64 	%fd513, 0d397B839A252049C0;
	fma.rn.f64 	%fd1377, %fd508, %fd513, %fd512;
	abs.f64 	%fd514, %fd8;
	setp.ltu.f64 	%p24, %fd514, 0d41E0000000000000;
	@%p24 bra 	$L__BB6_20;

	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1377, [retval0+0];
	} // callseq 82
	ld.local.u32 	%r480, [%rd1];

$L__BB6_20:
	and.b32  	%r133, %r480, 1;
	shl.b32 	%r134, %r480, 3;
	and.b32  	%r135, %r134, 8;
	setp.eq.s32 	%p25, %r133, 0;
	selp.f64 	%fd516, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p25;
	mul.wide.s32 	%rd73, %r135, 8;
	add.s64 	%rd75, %rd66, %rd73;
	ld.global.nc.f64 	%fd517, [%rd75+8];
	mul.rn.f64 	%fd38, %fd1377, %fd1377;
	fma.rn.f64 	%fd518, %fd516, %fd38, %fd517;
	ld.global.nc.f64 	%fd519, [%rd75+16];
	fma.rn.f64 	%fd520, %fd518, %fd38, %fd519;
	ld.global.nc.f64 	%fd521, [%rd75+24];
	fma.rn.f64 	%fd522, %fd520, %fd38, %fd521;
	ld.global.nc.f64 	%fd523, [%rd75+32];
	fma.rn.f64 	%fd524, %fd522, %fd38, %fd523;
	ld.global.nc.f64 	%fd525, [%rd75+40];
	fma.rn.f64 	%fd526, %fd524, %fd38, %fd525;
	ld.global.nc.f64 	%fd527, [%rd75+48];
	fma.rn.f64 	%fd39, %fd526, %fd38, %fd527;
	fma.rn.f64 	%fd1379, %fd39, %fd1377, %fd1377;
	@%p25 bra 	$L__BB6_22;

	mov.f64 	%fd528, 0d3FF0000000000000;
	fma.rn.f64 	%fd1379, %fd39, %fd38, %fd528;

$L__BB6_22:
	and.b32  	%r136, %r480, 2;
	setp.eq.s32 	%p26, %r136, 0;
	@%p26 bra 	$L__BB6_24;

	mov.f64 	%fd529, 0d0000000000000000;
	mov.f64 	%fd530, 0dBFF0000000000000;
	fma.rn.f64 	%fd1379, %fd1379, %fd530, %fd529;

$L__BB6_24:
	add.rn.f64 	%fd1370, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1369, %fd1370, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd1369, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r137, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r138}, %fd45;
	}
	and.b32  	%r139, %r138, 2147483647;
	setp.eq.s32 	%p27, %r139, 2146435072;
	setp.eq.s32 	%p28, %r137, 0;
	and.pred  	%p29, %p28, %p27;
	@%p29 bra 	$L__BB6_27;
	bra.uni 	$L__BB6_25;

$L__BB6_27:
	mov.f64 	%fd540, 0d0000000000000000;
	mul.rn.f64 	%fd1380, %fd45, %fd540;
	mov.u32 	%r481, 0;
	bra.uni 	$L__BB6_28;

$L__BB6_25:
	mul.rn.f64 	%fd531, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r481, %fd531;
	st.local.u32 	[%rd1], %r481;
	cvt.rn.f64.s32 	%fd532, %r481;
	neg.f64 	%fd533, %fd532;
	mov.f64 	%fd534, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd535, %fd533, %fd534, %fd45;
	mov.f64 	%fd536, 0d3C91A62633145C00;
	fma.rn.f64 	%fd537, %fd533, %fd536, %fd535;
	mov.f64 	%fd538, 0d397B839A252049C0;
	fma.rn.f64 	%fd1380, %fd533, %fd538, %fd537;
	abs.f64 	%fd539, %fd45;
	setp.ltu.f64 	%p30, %fd539, 0d41E0000000000000;
	@%p30 bra 	$L__BB6_28;

	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1380, [retval0+0];
	} // callseq 83
	ld.local.u32 	%r481, [%rd1];

$L__BB6_28:
	and.b32  	%r141, %r481, 1;
	shl.b32 	%r142, %r481, 3;
	and.b32  	%r143, %r142, 8;
	setp.eq.s32 	%p31, %r141, 0;
	selp.f64 	%fd541, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p31;
	mul.wide.s32 	%rd77, %r143, 8;
	add.s64 	%rd79, %rd66, %rd77;
	ld.global.nc.f64 	%fd542, [%rd79+8];
	mul.rn.f64 	%fd50, %fd1380, %fd1380;
	fma.rn.f64 	%fd543, %fd541, %fd50, %fd542;
	ld.global.nc.f64 	%fd544, [%rd79+16];
	fma.rn.f64 	%fd545, %fd543, %fd50, %fd544;
	ld.global.nc.f64 	%fd546, [%rd79+24];
	fma.rn.f64 	%fd547, %fd545, %fd50, %fd546;
	ld.global.nc.f64 	%fd548, [%rd79+32];
	fma.rn.f64 	%fd549, %fd547, %fd50, %fd548;
	ld.global.nc.f64 	%fd550, [%rd79+40];
	fma.rn.f64 	%fd551, %fd549, %fd50, %fd550;
	ld.global.nc.f64 	%fd552, [%rd79+48];
	fma.rn.f64 	%fd51, %fd551, %fd50, %fd552;
	fma.rn.f64 	%fd1382, %fd51, %fd1380, %fd1380;
	@%p31 bra 	$L__BB6_30;

	mov.f64 	%fd553, 0d3FF0000000000000;
	fma.rn.f64 	%fd1382, %fd51, %fd50, %fd553;

$L__BB6_30:
	and.b32  	%r144, %r481, 2;
	setp.eq.s32 	%p32, %r144, 0;
	@%p32 bra 	$L__BB6_32;

	mov.f64 	%fd554, 0d0000000000000000;
	mov.f64 	%fd555, 0dBFF0000000000000;
	fma.rn.f64 	%fd1382, %fd1382, %fd555, %fd554;

$L__BB6_32:
	add.rn.f64 	%fd1366, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1365, %fd1366, 0d400921FB54442D18;
	mul.rn.f64 	%fd556, %fd1382, 0d4044000000000000;
	mul.rn.f64 	%fd557, %fd1379, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd557, %fd556;
	div.rn.f64 	%fd58, %fd1365, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r145, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd58;
	}
	and.b32  	%r147, %r146, 2147483647;
	setp.eq.s32 	%p33, %r147, 2146435072;
	setp.eq.s32 	%p34, %r145, 0;
	and.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB6_35;
	bra.uni 	$L__BB6_33;

$L__BB6_35:
	mov.f64 	%fd567, 0d0000000000000000;
	mul.rn.f64 	%fd1383, %fd58, %fd567;
	mov.u32 	%r482, 0;
	bra.uni 	$L__BB6_36;

$L__BB6_33:
	mul.rn.f64 	%fd558, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r482, %fd558;
	st.local.u32 	[%rd1], %r482;
	cvt.rn.f64.s32 	%fd559, %r482;
	neg.f64 	%fd560, %fd559;
	mov.f64 	%fd561, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd562, %fd560, %fd561, %fd58;
	mov.f64 	%fd563, 0d3C91A62633145C00;
	fma.rn.f64 	%fd564, %fd560, %fd563, %fd562;
	mov.f64 	%fd565, 0d397B839A252049C0;
	fma.rn.f64 	%fd1383, %fd560, %fd565, %fd564;
	abs.f64 	%fd566, %fd58;
	setp.ltu.f64 	%p36, %fd566, 0d41E0000000000000;
	@%p36 bra 	$L__BB6_36;

	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1383, [retval0+0];
	} // callseq 84
	ld.local.u32 	%r482, [%rd1];

$L__BB6_36:
	and.b32  	%r149, %r482, 1;
	shl.b32 	%r150, %r482, 3;
	and.b32  	%r151, %r150, 8;
	setp.eq.s32 	%p37, %r149, 0;
	selp.f64 	%fd568, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	mul.wide.s32 	%rd81, %r151, 8;
	add.s64 	%rd83, %rd66, %rd81;
	ld.global.nc.f64 	%fd569, [%rd83+8];
	mul.rn.f64 	%fd63, %fd1383, %fd1383;
	fma.rn.f64 	%fd570, %fd568, %fd63, %fd569;
	ld.global.nc.f64 	%fd571, [%rd83+16];
	fma.rn.f64 	%fd572, %fd570, %fd63, %fd571;
	ld.global.nc.f64 	%fd573, [%rd83+24];
	fma.rn.f64 	%fd574, %fd572, %fd63, %fd573;
	ld.global.nc.f64 	%fd575, [%rd83+32];
	fma.rn.f64 	%fd576, %fd574, %fd63, %fd575;
	ld.global.nc.f64 	%fd577, [%rd83+40];
	fma.rn.f64 	%fd578, %fd576, %fd63, %fd577;
	ld.global.nc.f64 	%fd579, [%rd83+48];
	fma.rn.f64 	%fd64, %fd578, %fd63, %fd579;
	fma.rn.f64 	%fd1385, %fd64, %fd1383, %fd1383;
	@%p37 bra 	$L__BB6_38;

	mov.f64 	%fd580, 0d3FF0000000000000;
	fma.rn.f64 	%fd1385, %fd64, %fd63, %fd580;

$L__BB6_38:
	and.b32  	%r152, %r482, 2;
	setp.eq.s32 	%p38, %r152, 0;
	@%p38 bra 	$L__BB6_40;

	mov.f64 	%fd581, 0d0000000000000000;
	mov.f64 	%fd582, 0dBFF0000000000000;
	fma.rn.f64 	%fd1385, %fd1385, %fd582, %fd581;

$L__BB6_40:
	add.rn.f64 	%fd1368, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1367, %fd1368, 0d400921FB54442D18;
	mul.rn.f64 	%fd583, %fd1385, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd583;
	div.rn.f64 	%fd71, %fd1367, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd71;
	}
	and.b32  	%r155, %r154, 2147483647;
	setp.eq.s32 	%p39, %r155, 2146435072;
	setp.eq.s32 	%p40, %r153, 0;
	and.pred  	%p41, %p40, %p39;
	@%p41 bra 	$L__BB6_43;
	bra.uni 	$L__BB6_41;

$L__BB6_43:
	mov.f64 	%fd593, 0d0000000000000000;
	mul.rn.f64 	%fd1386, %fd71, %fd593;
	mov.u32 	%r483, 0;
	bra.uni 	$L__BB6_44;

$L__BB6_41:
	mul.rn.f64 	%fd584, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r483, %fd584;
	st.local.u32 	[%rd1], %r483;
	cvt.rn.f64.s32 	%fd585, %r483;
	neg.f64 	%fd586, %fd585;
	mov.f64 	%fd587, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd588, %fd586, %fd587, %fd71;
	mov.f64 	%fd589, 0d3C91A62633145C00;
	fma.rn.f64 	%fd590, %fd586, %fd589, %fd588;
	mov.f64 	%fd591, 0d397B839A252049C0;
	fma.rn.f64 	%fd1386, %fd586, %fd591, %fd590;
	abs.f64 	%fd592, %fd71;
	setp.ltu.f64 	%p42, %fd592, 0d41E0000000000000;
	@%p42 bra 	$L__BB6_44;

	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1386, [retval0+0];
	} // callseq 85
	ld.local.u32 	%r483, [%rd1];

$L__BB6_44:
	and.b32  	%r157, %r483, 1;
	shl.b32 	%r158, %r483, 3;
	and.b32  	%r159, %r158, 8;
	setp.eq.s32 	%p43, %r157, 0;
	selp.f64 	%fd594, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p43;
	mul.wide.s32 	%rd85, %r159, 8;
	add.s64 	%rd87, %rd66, %rd85;
	ld.global.nc.f64 	%fd595, [%rd87+8];
	mul.rn.f64 	%fd76, %fd1386, %fd1386;
	fma.rn.f64 	%fd596, %fd594, %fd76, %fd595;
	ld.global.nc.f64 	%fd597, [%rd87+16];
	fma.rn.f64 	%fd598, %fd596, %fd76, %fd597;
	ld.global.nc.f64 	%fd599, [%rd87+24];
	fma.rn.f64 	%fd600, %fd598, %fd76, %fd599;
	ld.global.nc.f64 	%fd601, [%rd87+32];
	fma.rn.f64 	%fd602, %fd600, %fd76, %fd601;
	ld.global.nc.f64 	%fd603, [%rd87+40];
	fma.rn.f64 	%fd604, %fd602, %fd76, %fd603;
	ld.global.nc.f64 	%fd605, [%rd87+48];
	fma.rn.f64 	%fd77, %fd604, %fd76, %fd605;
	fma.rn.f64 	%fd1388, %fd77, %fd1386, %fd1386;
	@%p43 bra 	$L__BB6_46;

	mov.f64 	%fd606, 0d3FF0000000000000;
	fma.rn.f64 	%fd1388, %fd77, %fd76, %fd606;

$L__BB6_46:
	and.b32  	%r160, %r483, 2;
	setp.eq.s32 	%p44, %r160, 0;
	@%p44 bra 	$L__BB6_48;

	mov.f64 	%fd607, 0d0000000000000000;
	mov.f64 	%fd608, 0dBFF0000000000000;
	fma.rn.f64 	%fd1388, %fd1388, %fd608, %fd607;

$L__BB6_48:
	mul.rn.f64 	%fd609, %fd1388, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd609;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd7;
	}
	and.b32  	%r162, %r161, 2147483647;
	setp.eq.s32 	%p45, %r162, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r163, %temp}, %fd7;
	}
	setp.eq.s32 	%p46, %r163, 0;
	and.pred  	%p47, %p46, %p45;
	@%p47 bra 	$L__BB6_51;
	bra.uni 	$L__BB6_49;

$L__BB6_51:
	mov.f64 	%fd619, 0d0000000000000000;
	mul.rn.f64 	%fd1389, %fd7, %fd619;
	mov.u32 	%r484, 0;
	bra.uni 	$L__BB6_52;

$L__BB6_49:
	mul.rn.f64 	%fd610, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r484, %fd610;
	st.local.u32 	[%rd1], %r484;
	cvt.rn.f64.s32 	%fd611, %r484;
	neg.f64 	%fd612, %fd611;
	mov.f64 	%fd613, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd614, %fd612, %fd613, %fd7;
	mov.f64 	%fd615, 0d3C91A62633145C00;
	fma.rn.f64 	%fd616, %fd612, %fd615, %fd614;
	mov.f64 	%fd617, 0d397B839A252049C0;
	fma.rn.f64 	%fd1389, %fd612, %fd617, %fd616;
	abs.f64 	%fd618, %fd7;
	setp.ltu.f64 	%p48, %fd618, 0d41E0000000000000;
	@%p48 bra 	$L__BB6_52;

	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1389, [retval0+0];
	} // callseq 86
	ld.local.u32 	%r484, [%rd1];

$L__BB6_52:
	and.b32  	%r165, %r484, 1;
	shl.b32 	%r166, %r484, 3;
	and.b32  	%r167, %r166, 8;
	setp.eq.s32 	%p49, %r165, 0;
	selp.f64 	%fd620, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p49;
	mul.wide.s32 	%rd89, %r167, 8;
	add.s64 	%rd91, %rd66, %rd89;
	ld.global.nc.f64 	%fd621, [%rd91+8];
	mul.rn.f64 	%fd88, %fd1389, %fd1389;
	fma.rn.f64 	%fd622, %fd620, %fd88, %fd621;
	ld.global.nc.f64 	%fd623, [%rd91+16];
	fma.rn.f64 	%fd624, %fd622, %fd88, %fd623;
	ld.global.nc.f64 	%fd625, [%rd91+24];
	fma.rn.f64 	%fd626, %fd624, %fd88, %fd625;
	ld.global.nc.f64 	%fd627, [%rd91+32];
	fma.rn.f64 	%fd628, %fd626, %fd88, %fd627;
	ld.global.nc.f64 	%fd629, [%rd91+40];
	fma.rn.f64 	%fd630, %fd628, %fd88, %fd629;
	ld.global.nc.f64 	%fd631, [%rd91+48];
	fma.rn.f64 	%fd89, %fd630, %fd88, %fd631;
	fma.rn.f64 	%fd1391, %fd89, %fd1389, %fd1389;
	@%p49 bra 	$L__BB6_54;

	mov.f64 	%fd632, 0d3FF0000000000000;
	fma.rn.f64 	%fd1391, %fd89, %fd88, %fd632;

$L__BB6_54:
	and.b32  	%r168, %r484, 2;
	setp.eq.s32 	%p50, %r168, 0;
	@%p50 bra 	$L__BB6_56;

	mov.f64 	%fd633, 0d0000000000000000;
	mov.f64 	%fd634, 0dBFF0000000000000;
	fma.rn.f64 	%fd1391, %fd1391, %fd634, %fd633;

$L__BB6_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd95;
	}
	and.b32  	%r171, %r170, 2147483647;
	setp.eq.s32 	%p51, %r171, 2146435072;
	setp.eq.s32 	%p52, %r169, 0;
	and.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB6_59;
	bra.uni 	$L__BB6_57;

$L__BB6_59:
	mov.f64 	%fd644, 0d0000000000000000;
	mul.rn.f64 	%fd1392, %fd95, %fd644;
	mov.u32 	%r485, 0;
	bra.uni 	$L__BB6_60;

$L__BB6_57:
	mul.rn.f64 	%fd635, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r485, %fd635;
	st.local.u32 	[%rd1], %r485;
	cvt.rn.f64.s32 	%fd636, %r485;
	neg.f64 	%fd637, %fd636;
	mov.f64 	%fd638, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd639, %fd637, %fd638, %fd95;
	mov.f64 	%fd640, 0d3C91A62633145C00;
	fma.rn.f64 	%fd641, %fd637, %fd640, %fd639;
	mov.f64 	%fd642, 0d397B839A252049C0;
	fma.rn.f64 	%fd1392, %fd637, %fd642, %fd641;
	abs.f64 	%fd643, %fd95;
	setp.ltu.f64 	%p54, %fd643, 0d41E0000000000000;
	@%p54 bra 	$L__BB6_60;

	{ // callseq 87, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1392, [retval0+0];
	} // callseq 87
	ld.local.u32 	%r485, [%rd1];

$L__BB6_60:
	and.b32  	%r173, %r485, 1;
	shl.b32 	%r174, %r485, 3;
	and.b32  	%r175, %r174, 8;
	setp.eq.s32 	%p55, %r173, 0;
	selp.f64 	%fd645, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p55;
	mul.wide.s32 	%rd93, %r175, 8;
	add.s64 	%rd95, %rd66, %rd93;
	ld.global.nc.f64 	%fd646, [%rd95+8];
	mul.rn.f64 	%fd100, %fd1392, %fd1392;
	fma.rn.f64 	%fd647, %fd645, %fd100, %fd646;
	ld.global.nc.f64 	%fd648, [%rd95+16];
	fma.rn.f64 	%fd649, %fd647, %fd100, %fd648;
	ld.global.nc.f64 	%fd650, [%rd95+24];
	fma.rn.f64 	%fd651, %fd649, %fd100, %fd650;
	ld.global.nc.f64 	%fd652, [%rd95+32];
	fma.rn.f64 	%fd653, %fd651, %fd100, %fd652;
	ld.global.nc.f64 	%fd654, [%rd95+40];
	fma.rn.f64 	%fd655, %fd653, %fd100, %fd654;
	ld.global.nc.f64 	%fd656, [%rd95+48];
	fma.rn.f64 	%fd101, %fd655, %fd100, %fd656;
	fma.rn.f64 	%fd1394, %fd101, %fd1392, %fd1392;
	@%p55 bra 	$L__BB6_62;

	mov.f64 	%fd657, 0d3FF0000000000000;
	fma.rn.f64 	%fd1394, %fd101, %fd100, %fd657;

$L__BB6_62:
	and.b32  	%r176, %r485, 2;
	setp.eq.s32 	%p56, %r176, 0;
	@%p56 bra 	$L__BB6_64;

	mov.f64 	%fd658, 0d0000000000000000;
	mov.f64 	%fd659, 0dBFF0000000000000;
	fma.rn.f64 	%fd1394, %fd1394, %fd659, %fd658;

$L__BB6_64:
	mul.rn.f64 	%fd660, %fd1394, 0d4044000000000000;
	mul.rn.f64 	%fd661, %fd1391, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd661, %fd660;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r177, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %fd108;
	}
	and.b32  	%r179, %r178, 2147483647;
	setp.eq.s32 	%p57, %r179, 2146435072;
	setp.eq.s32 	%p58, %r177, 0;
	and.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB6_67;
	bra.uni 	$L__BB6_65;

$L__BB6_67:
	mov.f64 	%fd671, 0d0000000000000000;
	mul.rn.f64 	%fd1395, %fd108, %fd671;
	mov.u32 	%r486, 0;
	bra.uni 	$L__BB6_68;

$L__BB6_65:
	mul.rn.f64 	%fd662, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r486, %fd662;
	st.local.u32 	[%rd1], %r486;
	cvt.rn.f64.s32 	%fd663, %r486;
	neg.f64 	%fd664, %fd663;
	mov.f64 	%fd665, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd666, %fd664, %fd665, %fd108;
	mov.f64 	%fd667, 0d3C91A62633145C00;
	fma.rn.f64 	%fd668, %fd664, %fd667, %fd666;
	mov.f64 	%fd669, 0d397B839A252049C0;
	fma.rn.f64 	%fd1395, %fd664, %fd669, %fd668;
	abs.f64 	%fd670, %fd108;
	setp.ltu.f64 	%p60, %fd670, 0d41E0000000000000;
	@%p60 bra 	$L__BB6_68;

	{ // callseq 88, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1395, [retval0+0];
	} // callseq 88
	ld.local.u32 	%r486, [%rd1];

$L__BB6_68:
	and.b32  	%r181, %r486, 1;
	shl.b32 	%r182, %r486, 3;
	and.b32  	%r183, %r182, 8;
	setp.eq.s32 	%p61, %r181, 0;
	selp.f64 	%fd672, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p61;
	mul.wide.s32 	%rd97, %r183, 8;
	add.s64 	%rd99, %rd66, %rd97;
	ld.global.nc.f64 	%fd673, [%rd99+8];
	mul.rn.f64 	%fd113, %fd1395, %fd1395;
	fma.rn.f64 	%fd674, %fd672, %fd113, %fd673;
	ld.global.nc.f64 	%fd675, [%rd99+16];
	fma.rn.f64 	%fd676, %fd674, %fd113, %fd675;
	ld.global.nc.f64 	%fd677, [%rd99+24];
	fma.rn.f64 	%fd678, %fd676, %fd113, %fd677;
	ld.global.nc.f64 	%fd679, [%rd99+32];
	fma.rn.f64 	%fd680, %fd678, %fd113, %fd679;
	ld.global.nc.f64 	%fd681, [%rd99+40];
	fma.rn.f64 	%fd682, %fd680, %fd113, %fd681;
	ld.global.nc.f64 	%fd683, [%rd99+48];
	fma.rn.f64 	%fd114, %fd682, %fd113, %fd683;
	fma.rn.f64 	%fd1397, %fd114, %fd1395, %fd1395;
	@%p61 bra 	$L__BB6_70;

	mov.f64 	%fd684, 0d3FF0000000000000;
	fma.rn.f64 	%fd1397, %fd114, %fd113, %fd684;

$L__BB6_70:
	and.b32  	%r184, %r486, 2;
	setp.eq.s32 	%p62, %r184, 0;
	@%p62 bra 	$L__BB6_72;

	mov.f64 	%fd685, 0d0000000000000000;
	mov.f64 	%fd686, 0dBFF0000000000000;
	fma.rn.f64 	%fd1397, %fd1397, %fd686, %fd685;

$L__BB6_72:
	mul.rn.f64 	%fd687, %fd1397, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd687;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r185, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %fd121;
	}
	and.b32  	%r187, %r186, 2147483647;
	setp.eq.s32 	%p63, %r187, 2146435072;
	setp.eq.s32 	%p64, %r185, 0;
	and.pred  	%p65, %p64, %p63;
	@%p65 bra 	$L__BB6_75;
	bra.uni 	$L__BB6_73;

$L__BB6_75:
	mov.f64 	%fd697, 0d0000000000000000;
	mul.rn.f64 	%fd1398, %fd121, %fd697;
	mov.u32 	%r487, 0;
	bra.uni 	$L__BB6_76;

$L__BB6_73:
	mul.rn.f64 	%fd688, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r487, %fd688;
	st.local.u32 	[%rd1], %r487;
	cvt.rn.f64.s32 	%fd689, %r487;
	neg.f64 	%fd690, %fd689;
	mov.f64 	%fd691, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd692, %fd690, %fd691, %fd121;
	mov.f64 	%fd693, 0d3C91A62633145C00;
	fma.rn.f64 	%fd694, %fd690, %fd693, %fd692;
	mov.f64 	%fd695, 0d397B839A252049C0;
	fma.rn.f64 	%fd1398, %fd690, %fd695, %fd694;
	abs.f64 	%fd696, %fd121;
	setp.ltu.f64 	%p66, %fd696, 0d41E0000000000000;
	@%p66 bra 	$L__BB6_76;

	{ // callseq 89, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1398, [retval0+0];
	} // callseq 89
	ld.local.u32 	%r487, [%rd1];

$L__BB6_76:
	and.b32  	%r189, %r487, 1;
	shl.b32 	%r190, %r487, 3;
	and.b32  	%r191, %r190, 8;
	setp.eq.s32 	%p67, %r189, 0;
	selp.f64 	%fd698, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p67;
	mul.wide.s32 	%rd101, %r191, 8;
	add.s64 	%rd103, %rd66, %rd101;
	ld.global.nc.f64 	%fd699, [%rd103+8];
	mul.rn.f64 	%fd126, %fd1398, %fd1398;
	fma.rn.f64 	%fd700, %fd698, %fd126, %fd699;
	ld.global.nc.f64 	%fd701, [%rd103+16];
	fma.rn.f64 	%fd702, %fd700, %fd126, %fd701;
	ld.global.nc.f64 	%fd703, [%rd103+24];
	fma.rn.f64 	%fd704, %fd702, %fd126, %fd703;
	ld.global.nc.f64 	%fd705, [%rd103+32];
	fma.rn.f64 	%fd706, %fd704, %fd126, %fd705;
	ld.global.nc.f64 	%fd707, [%rd103+40];
	fma.rn.f64 	%fd708, %fd706, %fd126, %fd707;
	ld.global.nc.f64 	%fd709, [%rd103+48];
	fma.rn.f64 	%fd127, %fd708, %fd126, %fd709;
	fma.rn.f64 	%fd1400, %fd127, %fd1398, %fd1398;
	@%p67 bra 	$L__BB6_78;

	mov.f64 	%fd710, 0d3FF0000000000000;
	fma.rn.f64 	%fd1400, %fd127, %fd126, %fd710;

$L__BB6_78:
	and.b32  	%r192, %r487, 2;
	setp.eq.s32 	%p68, %r192, 0;
	@%p68 bra 	$L__BB6_80;

	mov.f64 	%fd711, 0d0000000000000000;
	mov.f64 	%fd712, 0dBFF0000000000000;
	fma.rn.f64 	%fd1400, %fd1400, %fd712, %fd711;

$L__BB6_80:
	mul.rn.f64 	%fd713, %fd1400, 0d4072C00000000000;
	add.rn.f64 	%fd714, %fd120, %fd713;
	add.rn.f64 	%fd133, %fd33, %fd714;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd715, %fd2, %fd2;
	mov.f64 	%fd716, 0d4000000000000000;
	add.rn.f64 	%fd717, %fd715, 0dC059000000000000;
	mul.rn.f64 	%fd718, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd717, %fd718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd716;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p69, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 90, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1403, [retval0+0];
	} // callseq 90
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p70, %r33, 0;
	and.pred  	%p1, %p70, %p69;
	not.pred 	%p71, %p1;
	@%p71 bra 	$L__BB6_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd1403;
	}
	xor.b32  	%r194, %r193, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r195, %temp}, %fd1403;
	}
	mov.b64 	%fd1403, {%r195, %r194};

$L__BB6_82:
	setp.eq.f64 	%p72, %fd4, 0d0000000000000000;
	@%p72 bra 	$L__BB6_86;
	bra.uni 	$L__BB6_83;

$L__BB6_86:
	selp.b32 	%r196, %r33, 0, %p69;
	mov.u32 	%r197, 0;
	or.b32  	%r198, %r196, 2146435072;
	setp.lt.s32 	%p76, %r31, 0;
	selp.b32 	%r199, %r198, %r196, %p76;
	mov.b64 	%fd1403, {%r197, %r199};
	bra.uni 	$L__BB6_87;

$L__BB6_83:
	setp.gt.s32 	%p73, %r33, -1;
	@%p73 bra 	$L__BB6_87;

	mov.f64 	%fd719, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd720, %fd719;
	setp.eq.f64 	%p74, %fd720, 0d4000000000000000;
	@%p74 bra 	$L__BB6_87;

	mov.f64 	%fd1403, 0dFFF8000000000000;

$L__BB6_87:
	add.rn.f64 	%fd722, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd722;
	}
	and.b32  	%r201, %r200, 2146435072;
	setp.ne.s32 	%p77, %r201, 2146435072;
	@%p77 bra 	$L__BB6_94;

	setp.gtu.f64 	%p78, %fd136, 0d7FF0000000000000;
	@%p78 bra 	$L__BB6_93;
	bra.uni 	$L__BB6_89;

$L__BB6_93:
	mov.f64 	%fd724, 0d4000000000000000;
	add.rn.f64 	%fd1403, %fd4, %fd724;
	bra.uni 	$L__BB6_94;

$L__BB6_89:
	mov.f64 	%fd723, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r202, %temp}, %fd723;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p79, %r34, 2146435072;
	setp.eq.s32 	%p80, %r202, 0;
	and.pred  	%p81, %p79, %p80;
	@%p81 bra 	$L__BB6_92;
	bra.uni 	$L__BB6_90;

$L__BB6_92:
	setp.gt.f64 	%p88, %fd136, 0d3FF0000000000000;
	selp.b32 	%r209, 2146435072, 0, %p88;
	mov.u32 	%r210, 0;
	xor.b32  	%r211, %r209, 2146435072;
	setp.lt.s32 	%p89, %r31, 0;
	selp.b32 	%r212, %r211, %r209, %p89;
	setp.eq.f64 	%p90, %fd4, 0dBFF0000000000000;
	selp.b32 	%r213, 1072693248, %r212, %p90;
	mov.b64 	%fd1403, {%r210, %r213};
	bra.uni 	$L__BB6_94;

$L__BB6_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd4;
	}
	and.b32  	%r204, %r33, 2147483647;
	setp.ne.s32 	%p82, %r204, 2146435072;
	setp.ne.s32 	%p83, %r203, 0;
	or.pred  	%p84, %p82, %p83;
	@%p84 bra 	$L__BB6_94;

	setp.gt.s32 	%p85, %r31, -1;
	selp.b32 	%r205, 2146435072, 0, %p85;
	mov.u32 	%r206, 0;
	setp.ne.s32 	%p86, %r34, 1071644672;
	and.pred  	%p87, %p86, %p1;
	or.b32  	%r207, %r205, -2147483648;
	selp.b32 	%r208, %r207, %r205, %p87;
	mov.b64 	%fd1403, {%r206, %r208};

$L__BB6_94:
	add.rn.f64 	%fd1360, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1359, %fd1360;
	mul.rn.f64 	%fd725, %fd1403, 0d3FC999999999999A;
	setp.eq.f64 	%p91, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd726, 0d3FC999999999999A, %fd725, %p91;
	add.rn.f64 	%fd727, %fd135, %fd726;
	mul.rn.f64 	%fd728, %fd1360, %fd4;
	mul.rn.f64 	%fd146, %fd728, 0d3FB999999999999A;
	add.rn.f64 	%fd729, %fd146, %fd727;
	mul.rn.f64 	%fd730, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd731, %fd730, %fd729;
	mul.rn.f64 	%fd732, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd732, %fd731;
	add.rn.f64 	%fd733, %fd4, %fd4;
	add.rn.f64 	%fd734, %fd1360, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd734, %fd733;
	{ // callseq 91, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1359;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1406, [retval0+0];
	} // callseq 91
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd1360;
	}
	setp.lt.s32 	%p92, %r35, 0;
	and.pred  	%p2, %p92, %p69;
	not.pred 	%p94, %p2;
	@%p94 bra 	$L__BB6_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd1406;
	}
	xor.b32  	%r215, %r214, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd1406;
	}
	mov.b64 	%fd1406, {%r216, %r215};

$L__BB6_96:
	setp.eq.f64 	%p95, %fd2, 0d0000000000000000;
	@%p95 bra 	$L__BB6_100;
	bra.uni 	$L__BB6_97;

$L__BB6_100:
	selp.b32 	%r217, %r35, 0, %p69;
	mov.u32 	%r218, 0;
	or.b32  	%r219, %r217, 2146435072;
	setp.lt.s32 	%p99, %r31, 0;
	selp.b32 	%r220, %r219, %r217, %p99;
	mov.b64 	%fd1406, {%r218, %r220};
	bra.uni 	$L__BB6_101;

$L__BB6_97:
	setp.gt.s32 	%p96, %r35, -1;
	@%p96 bra 	$L__BB6_101;

	mov.f64 	%fd735, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd736, %fd735;
	setp.eq.f64 	%p97, %fd736, 0d4000000000000000;
	@%p97 bra 	$L__BB6_101;

	mov.f64 	%fd1406, 0dFFF8000000000000;

$L__BB6_101:
	add.rn.f64 	%fd738, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r221}, %fd738;
	}
	and.b32  	%r222, %r221, 2146435072;
	setp.ne.s32 	%p100, %r222, 2146435072;
	@%p100 bra 	$L__BB6_108;

	add.rn.f64 	%fd1362, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1361, %fd1362;
	setp.gtu.f64 	%p101, %fd1361, 0d7FF0000000000000;
	@%p101 bra 	$L__BB6_107;
	bra.uni 	$L__BB6_103;

$L__BB6_107:
	mov.f64 	%fd740, 0d4000000000000000;
	add.rn.f64 	%fd1406, %fd2, %fd740;
	bra.uni 	$L__BB6_108;

$L__BB6_103:
	mov.f64 	%fd739, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r223, %temp}, %fd739;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p102, %r36, 2146435072;
	setp.eq.s32 	%p103, %r223, 0;
	and.pred  	%p104, %p102, %p103;
	@%p104 bra 	$L__BB6_106;
	bra.uni 	$L__BB6_104;

$L__BB6_106:
	add.rn.f64 	%fd1364, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1363, %fd1364;
	setp.gt.f64 	%p111, %fd1363, 0d3FF0000000000000;
	selp.b32 	%r230, 2146435072, 0, %p111;
	mov.u32 	%r231, 0;
	xor.b32  	%r232, %r230, 2146435072;
	setp.lt.s32 	%p112, %r31, 0;
	selp.b32 	%r233, %r232, %r230, %p112;
	setp.eq.f64 	%p113, %fd1364, 0dBFF0000000000000;
	selp.b32 	%r234, 1072693248, %r233, %p113;
	mov.b64 	%fd1406, {%r231, %r234};
	bra.uni 	$L__BB6_108;

$L__BB6_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd2;
	}
	and.b32  	%r225, %r35, 2147483647;
	setp.ne.s32 	%p105, %r225, 2146435072;
	setp.ne.s32 	%p106, %r224, 0;
	or.pred  	%p107, %p105, %p106;
	@%p107 bra 	$L__BB6_108;

	setp.gt.s32 	%p108, %r31, -1;
	selp.b32 	%r226, 2146435072, 0, %p108;
	mov.u32 	%r227, 0;
	setp.ne.s32 	%p109, %r36, 1071644672;
	and.pred  	%p110, %p109, %p2;
	or.b32  	%r228, %r226, -2147483648;
	selp.b32 	%r229, %r228, %r226, %p110;
	mov.b64 	%fd1406, {%r227, %r229};

$L__BB6_108:
	mul.rn.f64 	%fd741, %fd1406, 0d3FB999999999999A;
	setp.eq.f64 	%p114, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd742, 0d3FB999999999999A, %fd741, %p114;
	add.rn.f64 	%fd743, %fd148, %fd742;
	add.rn.f64 	%fd744, %fd146, %fd743;
	mul.rn.f64 	%fd745, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd746, %fd745, %fd744;
	mul.rn.f64 	%fd747, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd747, %fd746;
	div.rn.f64 	%fd748, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd748, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r236}, %fd159;
	}
	and.b32  	%r237, %r236, 2147483647;
	setp.eq.s32 	%p115, %r237, 2146435072;
	setp.eq.s32 	%p116, %r235, 0;
	and.pred  	%p3, %p116, %p115;
	@%p3 bra 	$L__BB6_111;
	bra.uni 	$L__BB6_109;

$L__BB6_111:
	mov.f64 	%fd758, 0d0000000000000000;
	mul.rn.f64 	%fd1407, %fd159, %fd758;
	mov.u32 	%r488, 0;
	bra.uni 	$L__BB6_112;

$L__BB6_109:
	mul.rn.f64 	%fd749, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r488, %fd749;
	st.local.u32 	[%rd1], %r488;
	cvt.rn.f64.s32 	%fd750, %r488;
	neg.f64 	%fd751, %fd750;
	mov.f64 	%fd752, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd753, %fd751, %fd752, %fd159;
	mov.f64 	%fd754, 0d3C91A62633145C00;
	fma.rn.f64 	%fd755, %fd751, %fd754, %fd753;
	mov.f64 	%fd756, 0d397B839A252049C0;
	fma.rn.f64 	%fd1407, %fd751, %fd756, %fd755;
	abs.f64 	%fd757, %fd159;
	setp.ltu.f64 	%p117, %fd757, 0d41E0000000000000;
	@%p117 bra 	$L__BB6_112;

	{ // callseq 92, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1407, [retval0+0];
	} // callseq 92
	ld.local.u32 	%r488, [%rd1];

$L__BB6_112:
	and.b32  	%r239, %r488, 1;
	shl.b32 	%r240, %r488, 3;
	and.b32  	%r241, %r240, 8;
	setp.eq.s32 	%p118, %r239, 0;
	selp.f64 	%fd759, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd105, %r241, 8;
	add.s64 	%rd107, %rd66, %rd105;
	ld.global.nc.f64 	%fd760, [%rd107+8];
	mul.rn.f64 	%fd164, %fd1407, %fd1407;
	fma.rn.f64 	%fd761, %fd759, %fd164, %fd760;
	ld.global.nc.f64 	%fd762, [%rd107+16];
	fma.rn.f64 	%fd763, %fd761, %fd164, %fd762;
	ld.global.nc.f64 	%fd764, [%rd107+24];
	fma.rn.f64 	%fd765, %fd763, %fd164, %fd764;
	ld.global.nc.f64 	%fd766, [%rd107+32];
	fma.rn.f64 	%fd767, %fd765, %fd164, %fd766;
	ld.global.nc.f64 	%fd768, [%rd107+40];
	fma.rn.f64 	%fd769, %fd767, %fd164, %fd768;
	ld.global.nc.f64 	%fd770, [%rd107+48];
	fma.rn.f64 	%fd165, %fd769, %fd164, %fd770;
	fma.rn.f64 	%fd1409, %fd165, %fd1407, %fd1407;
	@%p118 bra 	$L__BB6_114;

	mov.f64 	%fd771, 0d3FF0000000000000;
	fma.rn.f64 	%fd1409, %fd165, %fd164, %fd771;

$L__BB6_114:
	and.b32  	%r242, %r488, 2;
	setp.eq.s32 	%p119, %r242, 0;
	@%p119 bra 	$L__BB6_116;

	mov.f64 	%fd772, 0d0000000000000000;
	mov.f64 	%fd773, 0dBFF0000000000000;
	fma.rn.f64 	%fd1409, %fd1409, %fd773, %fd772;

$L__BB6_116:
	@%p3 bra 	$L__BB6_120;
	bra.uni 	$L__BB6_117;

$L__BB6_120:
	mov.f64 	%fd783, 0d0000000000000000;
	mul.rn.f64 	%fd1411, %fd159, %fd783;
	mov.u32 	%r490, 1;
	bra.uni 	$L__BB6_121;

$L__BB6_117:
	mul.rn.f64 	%fd774, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r489, %fd774;
	st.local.u32 	[%rd1], %r489;
	cvt.rn.f64.s32 	%fd775, %r489;
	neg.f64 	%fd776, %fd775;
	mov.f64 	%fd777, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd778, %fd776, %fd777, %fd159;
	mov.f64 	%fd779, 0d3C91A62633145C00;
	fma.rn.f64 	%fd780, %fd776, %fd779, %fd778;
	mov.f64 	%fd781, 0d397B839A252049C0;
	fma.rn.f64 	%fd1411, %fd776, %fd781, %fd780;
	abs.f64 	%fd782, %fd159;
	setp.ltu.f64 	%p120, %fd782, 0d41E0000000000000;
	@%p120 bra 	$L__BB6_119;

	{ // callseq 93, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1411, [retval0+0];
	} // callseq 93
	ld.local.u32 	%r489, [%rd1];

$L__BB6_119:
	add.s32 	%r490, %r489, 1;

$L__BB6_121:
	and.b32  	%r244, %r490, 1;
	shl.b32 	%r245, %r490, 3;
	and.b32  	%r246, %r245, 8;
	setp.eq.s32 	%p121, %r244, 0;
	selp.f64 	%fd784, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p121;
	mul.wide.s32 	%rd109, %r246, 8;
	add.s64 	%rd111, %rd66, %rd109;
	ld.global.nc.f64 	%fd785, [%rd111+8];
	mul.rn.f64 	%fd176, %fd1411, %fd1411;
	fma.rn.f64 	%fd786, %fd784, %fd176, %fd785;
	ld.global.nc.f64 	%fd787, [%rd111+16];
	fma.rn.f64 	%fd788, %fd786, %fd176, %fd787;
	ld.global.nc.f64 	%fd789, [%rd111+24];
	fma.rn.f64 	%fd790, %fd788, %fd176, %fd789;
	ld.global.nc.f64 	%fd791, [%rd111+32];
	fma.rn.f64 	%fd792, %fd790, %fd176, %fd791;
	ld.global.nc.f64 	%fd793, [%rd111+40];
	fma.rn.f64 	%fd794, %fd792, %fd176, %fd793;
	ld.global.nc.f64 	%fd795, [%rd111+48];
	fma.rn.f64 	%fd177, %fd794, %fd176, %fd795;
	fma.rn.f64 	%fd1413, %fd177, %fd1411, %fd1411;
	@%p121 bra 	$L__BB6_123;

	mov.f64 	%fd796, 0d3FF0000000000000;
	fma.rn.f64 	%fd1413, %fd177, %fd176, %fd796;

$L__BB6_123:
	and.b32  	%r247, %r490, 2;
	setp.eq.s32 	%p122, %r247, 0;
	@%p122 bra 	$L__BB6_125;

	mov.f64 	%fd797, 0d0000000000000000;
	mov.f64 	%fd798, 0dBFF0000000000000;
	fma.rn.f64 	%fd1413, %fd1413, %fd798, %fd797;

$L__BB6_125:
	ld.param.u32 	%r473, [gcj02_to_wgs84_exact_cuda_param_4];
	mul.rn.f64 	%fd799, %fd1409, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd800, %fd1409, %fd799;
	add.rn.f64 	%fd801, %fd800, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd802, %fd801;
	mov.f64 	%fd803, 0dC15854C140000000;
	div.rn.f64 	%fd804, %fd803, %fd802;
	mul.rn.f64 	%fd805, %fd804, %fd1413;
	mul.rn.f64 	%fd806, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd807, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd808, %fd807, %fd806;
	add.rn.f64 	%fd1480, %fd1, %fd808;
	mul.rn.f64 	%fd809, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd810, %fd802, %fd801;
	mov.f64 	%fd811, 0dC1582B102DE355C1;
	div.rn.f64 	%fd812, %fd811, %fd810;
	mul.rn.f64 	%fd813, %fd812, 0d400921FB54442D18;
	div.rn.f64 	%fd814, %fd809, %fd813;
	add.rn.f64 	%fd1481, %fd3, %fd814;
	setp.lt.s32 	%p123, %r473, 1;
	@%p123 bra 	$L__BB6_324;

	and.b32  	%r45, %r31, 2147483647;
	setp.gt.s32 	%p124, %r31, -1;
	selp.b32 	%r46, 2146435072, 0, %p124;
	mov.u32 	%r491, 0;
	or.b32  	%r47, %r46, -2147483648;
	mov.f64 	%fd1414, %fd1481;
	mov.f64 	%fd1415, %fd1480;

$L__BB6_127:
	mov.f64 	%fd1480, %fd1415;
	mov.f64 	%fd1481, %fd1414;
	add.rn.f64 	%fd187, %fd1481, 0dC041800000000000;
	add.rn.f64 	%fd188, %fd1480, 0dC05A400000000000;
	abs.f64 	%fd189, %fd188;
	sqrt.rn.f64 	%fd190, %fd189;
	mul.rn.f64 	%fd191, %fd188, 0d400921FB54442D18;
	mul.rn.f64 	%fd192, %fd187, 0d400921FB54442D18;
	mul.rn.f64 	%fd193, %fd191, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r249, %temp}, %fd193;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd193;
	}
	and.b32  	%r251, %r250, 2147483647;
	setp.eq.s32 	%p125, %r251, 2146435072;
	setp.eq.s32 	%p126, %r249, 0;
	and.pred  	%p127, %p126, %p125;
	@%p127 bra 	$L__BB6_130;
	bra.uni 	$L__BB6_128;

$L__BB6_130:
	mov.f64 	%fd824, 0d0000000000000000;
	mul.rn.f64 	%fd1416, %fd193, %fd824;
	mov.u32 	%r492, 0;
	bra.uni 	$L__BB6_131;

$L__BB6_128:
	mul.rn.f64 	%fd815, %fd193, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r492, %fd815;
	st.local.u32 	[%rd1], %r492;
	cvt.rn.f64.s32 	%fd816, %r492;
	neg.f64 	%fd817, %fd816;
	mov.f64 	%fd818, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd819, %fd817, %fd818, %fd193;
	mov.f64 	%fd820, 0d3C91A62633145C00;
	fma.rn.f64 	%fd821, %fd817, %fd820, %fd819;
	mov.f64 	%fd822, 0d397B839A252049C0;
	fma.rn.f64 	%fd1416, %fd817, %fd822, %fd821;
	abs.f64 	%fd823, %fd193;
	setp.ltu.f64 	%p128, %fd823, 0d41E0000000000000;
	@%p128 bra 	$L__BB6_131;

	{ // callseq 94, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd193;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1416, [retval0+0];
	} // callseq 94
	ld.local.u32 	%r492, [%rd1];

$L__BB6_131:
	and.b32  	%r253, %r492, 1;
	shl.b32 	%r254, %r492, 3;
	and.b32  	%r255, %r254, 8;
	setp.eq.s32 	%p129, %r253, 0;
	selp.f64 	%fd825, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p129;
	mul.wide.s32 	%rd113, %r255, 8;
	add.s64 	%rd115, %rd66, %rd113;
	ld.global.nc.f64 	%fd826, [%rd115+8];
	mul.rn.f64 	%fd198, %fd1416, %fd1416;
	fma.rn.f64 	%fd827, %fd825, %fd198, %fd826;
	ld.global.nc.f64 	%fd828, [%rd115+16];
	fma.rn.f64 	%fd829, %fd827, %fd198, %fd828;
	ld.global.nc.f64 	%fd830, [%rd115+24];
	fma.rn.f64 	%fd831, %fd829, %fd198, %fd830;
	ld.global.nc.f64 	%fd832, [%rd115+32];
	fma.rn.f64 	%fd833, %fd831, %fd198, %fd832;
	ld.global.nc.f64 	%fd834, [%rd115+40];
	fma.rn.f64 	%fd835, %fd833, %fd198, %fd834;
	ld.global.nc.f64 	%fd836, [%rd115+48];
	fma.rn.f64 	%fd199, %fd835, %fd198, %fd836;
	fma.rn.f64 	%fd1418, %fd199, %fd1416, %fd1416;
	@%p129 bra 	$L__BB6_133;

	mov.f64 	%fd837, 0d3FF0000000000000;
	fma.rn.f64 	%fd1418, %fd199, %fd198, %fd837;

$L__BB6_133:
	and.b32  	%r256, %r492, 2;
	setp.eq.s32 	%p130, %r256, 0;
	@%p130 bra 	$L__BB6_135;

	mov.f64 	%fd838, 0d0000000000000000;
	mov.f64 	%fd839, 0dBFF0000000000000;
	fma.rn.f64 	%fd1418, %fd1418, %fd839, %fd838;

$L__BB6_135:
	add.rn.f64 	%fd205, %fd191, %fd191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r257, %temp}, %fd205;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r258}, %fd205;
	}
	and.b32  	%r259, %r258, 2147483647;
	setp.eq.s32 	%p131, %r259, 2146435072;
	setp.eq.s32 	%p132, %r257, 0;
	and.pred  	%p133, %p132, %p131;
	@%p133 bra 	$L__BB6_138;
	bra.uni 	$L__BB6_136;

$L__BB6_138:
	mov.f64 	%fd849, 0d0000000000000000;
	mul.rn.f64 	%fd1419, %fd205, %fd849;
	mov.u32 	%r493, 0;
	bra.uni 	$L__BB6_139;

$L__BB6_136:
	mul.rn.f64 	%fd840, %fd205, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r493, %fd840;
	st.local.u32 	[%rd1], %r493;
	cvt.rn.f64.s32 	%fd841, %r493;
	neg.f64 	%fd842, %fd841;
	mov.f64 	%fd843, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd844, %fd842, %fd843, %fd205;
	mov.f64 	%fd845, 0d3C91A62633145C00;
	fma.rn.f64 	%fd846, %fd842, %fd845, %fd844;
	mov.f64 	%fd847, 0d397B839A252049C0;
	fma.rn.f64 	%fd1419, %fd842, %fd847, %fd846;
	abs.f64 	%fd848, %fd205;
	setp.ltu.f64 	%p134, %fd848, 0d41E0000000000000;
	@%p134 bra 	$L__BB6_139;

	{ // callseq 95, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd205;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1419, [retval0+0];
	} // callseq 95
	ld.local.u32 	%r493, [%rd1];

$L__BB6_139:
	and.b32  	%r261, %r493, 1;
	shl.b32 	%r262, %r493, 3;
	and.b32  	%r263, %r262, 8;
	setp.eq.s32 	%p135, %r261, 0;
	selp.f64 	%fd850, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p135;
	mul.wide.s32 	%rd117, %r263, 8;
	add.s64 	%rd119, %rd66, %rd117;
	ld.global.nc.f64 	%fd851, [%rd119+8];
	mul.rn.f64 	%fd210, %fd1419, %fd1419;
	fma.rn.f64 	%fd852, %fd850, %fd210, %fd851;
	ld.global.nc.f64 	%fd853, [%rd119+16];
	fma.rn.f64 	%fd854, %fd852, %fd210, %fd853;
	ld.global.nc.f64 	%fd855, [%rd119+24];
	fma.rn.f64 	%fd856, %fd854, %fd210, %fd855;
	ld.global.nc.f64 	%fd857, [%rd119+32];
	fma.rn.f64 	%fd858, %fd856, %fd210, %fd857;
	ld.global.nc.f64 	%fd859, [%rd119+40];
	fma.rn.f64 	%fd860, %fd858, %fd210, %fd859;
	ld.global.nc.f64 	%fd861, [%rd119+48];
	fma.rn.f64 	%fd211, %fd860, %fd210, %fd861;
	fma.rn.f64 	%fd1421, %fd211, %fd1419, %fd1419;
	@%p135 bra 	$L__BB6_141;

	mov.f64 	%fd862, 0d3FF0000000000000;
	fma.rn.f64 	%fd1421, %fd211, %fd210, %fd862;

$L__BB6_141:
	and.b32  	%r264, %r493, 2;
	setp.eq.s32 	%p136, %r264, 0;
	@%p136 bra 	$L__BB6_143;

	mov.f64 	%fd863, 0d0000000000000000;
	mov.f64 	%fd864, 0dBFF0000000000000;
	fma.rn.f64 	%fd1421, %fd1421, %fd864, %fd863;

$L__BB6_143:
	mul.rn.f64 	%fd865, %fd1421, 0d4034000000000000;
	mul.rn.f64 	%fd866, %fd1418, 0d4034000000000000;
	add.rn.f64 	%fd217, %fd866, %fd865;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r265}, %fd192;
	}
	and.b32  	%r266, %r265, 2147483647;
	setp.eq.s32 	%p137, %r266, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r267, %temp}, %fd192;
	}
	setp.eq.s32 	%p138, %r267, 0;
	and.pred  	%p139, %p138, %p137;
	@%p139 bra 	$L__BB6_146;
	bra.uni 	$L__BB6_144;

$L__BB6_146:
	mov.f64 	%fd876, 0d0000000000000000;
	mul.rn.f64 	%fd1422, %fd192, %fd876;
	mov.u32 	%r494, 0;
	bra.uni 	$L__BB6_147;

$L__BB6_144:
	mul.rn.f64 	%fd867, %fd192, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r494, %fd867;
	st.local.u32 	[%rd1], %r494;
	cvt.rn.f64.s32 	%fd868, %r494;
	neg.f64 	%fd869, %fd868;
	mov.f64 	%fd870, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd871, %fd869, %fd870, %fd192;
	mov.f64 	%fd872, 0d3C91A62633145C00;
	fma.rn.f64 	%fd873, %fd869, %fd872, %fd871;
	mov.f64 	%fd874, 0d397B839A252049C0;
	fma.rn.f64 	%fd1422, %fd869, %fd874, %fd873;
	abs.f64 	%fd875, %fd192;
	setp.ltu.f64 	%p140, %fd875, 0d41E0000000000000;
	@%p140 bra 	$L__BB6_147;

	{ // callseq 96, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd192;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1422, [retval0+0];
	} // callseq 96
	ld.local.u32 	%r494, [%rd1];

$L__BB6_147:
	and.b32  	%r269, %r494, 1;
	shl.b32 	%r270, %r494, 3;
	and.b32  	%r271, %r270, 8;
	setp.eq.s32 	%p141, %r269, 0;
	selp.f64 	%fd877, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p141;
	mul.wide.s32 	%rd121, %r271, 8;
	add.s64 	%rd123, %rd66, %rd121;
	ld.global.nc.f64 	%fd878, [%rd123+8];
	mul.rn.f64 	%fd222, %fd1422, %fd1422;
	fma.rn.f64 	%fd879, %fd877, %fd222, %fd878;
	ld.global.nc.f64 	%fd880, [%rd123+16];
	fma.rn.f64 	%fd881, %fd879, %fd222, %fd880;
	ld.global.nc.f64 	%fd882, [%rd123+24];
	fma.rn.f64 	%fd883, %fd881, %fd222, %fd882;
	ld.global.nc.f64 	%fd884, [%rd123+32];
	fma.rn.f64 	%fd885, %fd883, %fd222, %fd884;
	ld.global.nc.f64 	%fd886, [%rd123+40];
	fma.rn.f64 	%fd887, %fd885, %fd222, %fd886;
	ld.global.nc.f64 	%fd888, [%rd123+48];
	fma.rn.f64 	%fd223, %fd887, %fd222, %fd888;
	fma.rn.f64 	%fd1424, %fd223, %fd1422, %fd1422;
	@%p141 bra 	$L__BB6_149;

	mov.f64 	%fd889, 0d3FF0000000000000;
	fma.rn.f64 	%fd1424, %fd223, %fd222, %fd889;

$L__BB6_149:
	and.b32  	%r272, %r494, 2;
	setp.eq.s32 	%p142, %r272, 0;
	@%p142 bra 	$L__BB6_151;

	mov.f64 	%fd890, 0d0000000000000000;
	mov.f64 	%fd891, 0dBFF0000000000000;
	fma.rn.f64 	%fd1424, %fd1424, %fd891, %fd890;

$L__BB6_151:
	div.rn.f64 	%fd229, %fd192, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r273, %temp}, %fd229;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r274}, %fd229;
	}
	and.b32  	%r275, %r274, 2147483647;
	setp.eq.s32 	%p143, %r275, 2146435072;
	setp.eq.s32 	%p144, %r273, 0;
	and.pred  	%p145, %p144, %p143;
	@%p145 bra 	$L__BB6_154;
	bra.uni 	$L__BB6_152;

$L__BB6_154:
	mov.f64 	%fd901, 0d0000000000000000;
	mul.rn.f64 	%fd1425, %fd229, %fd901;
	mov.u32 	%r495, 0;
	bra.uni 	$L__BB6_155;

$L__BB6_152:
	mul.rn.f64 	%fd892, %fd229, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r495, %fd892;
	st.local.u32 	[%rd1], %r495;
	cvt.rn.f64.s32 	%fd893, %r495;
	neg.f64 	%fd894, %fd893;
	mov.f64 	%fd895, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd896, %fd894, %fd895, %fd229;
	mov.f64 	%fd897, 0d3C91A62633145C00;
	fma.rn.f64 	%fd898, %fd894, %fd897, %fd896;
	mov.f64 	%fd899, 0d397B839A252049C0;
	fma.rn.f64 	%fd1425, %fd894, %fd899, %fd898;
	abs.f64 	%fd900, %fd229;
	setp.ltu.f64 	%p146, %fd900, 0d41E0000000000000;
	@%p146 bra 	$L__BB6_155;

	{ // callseq 97, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd229;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1425, [retval0+0];
	} // callseq 97
	ld.local.u32 	%r495, [%rd1];

$L__BB6_155:
	and.b32  	%r277, %r495, 1;
	shl.b32 	%r278, %r495, 3;
	and.b32  	%r279, %r278, 8;
	setp.eq.s32 	%p147, %r277, 0;
	selp.f64 	%fd902, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p147;
	mul.wide.s32 	%rd125, %r279, 8;
	add.s64 	%rd127, %rd66, %rd125;
	ld.global.nc.f64 	%fd903, [%rd127+8];
	mul.rn.f64 	%fd234, %fd1425, %fd1425;
	fma.rn.f64 	%fd904, %fd902, %fd234, %fd903;
	ld.global.nc.f64 	%fd905, [%rd127+16];
	fma.rn.f64 	%fd906, %fd904, %fd234, %fd905;
	ld.global.nc.f64 	%fd907, [%rd127+24];
	fma.rn.f64 	%fd908, %fd906, %fd234, %fd907;
	ld.global.nc.f64 	%fd909, [%rd127+32];
	fma.rn.f64 	%fd910, %fd908, %fd234, %fd909;
	ld.global.nc.f64 	%fd911, [%rd127+40];
	fma.rn.f64 	%fd912, %fd910, %fd234, %fd911;
	ld.global.nc.f64 	%fd913, [%rd127+48];
	fma.rn.f64 	%fd235, %fd912, %fd234, %fd913;
	fma.rn.f64 	%fd1427, %fd235, %fd1425, %fd1425;
	@%p147 bra 	$L__BB6_157;

	mov.f64 	%fd914, 0d3FF0000000000000;
	fma.rn.f64 	%fd1427, %fd235, %fd234, %fd914;

$L__BB6_157:
	and.b32  	%r280, %r495, 2;
	setp.eq.s32 	%p148, %r280, 0;
	@%p148 bra 	$L__BB6_159;

	mov.f64 	%fd915, 0d0000000000000000;
	mov.f64 	%fd916, 0dBFF0000000000000;
	fma.rn.f64 	%fd1427, %fd1427, %fd916, %fd915;

$L__BB6_159:
	mul.rn.f64 	%fd917, %fd1427, 0d4044000000000000;
	mul.rn.f64 	%fd918, %fd1424, 0d4034000000000000;
	add.rn.f64 	%fd241, %fd918, %fd917;
	div.rn.f64 	%fd242, %fd192, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r281, %temp}, %fd242;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r282}, %fd242;
	}
	and.b32  	%r283, %r282, 2147483647;
	setp.eq.s32 	%p149, %r283, 2146435072;
	setp.eq.s32 	%p150, %r281, 0;
	and.pred  	%p151, %p150, %p149;
	@%p151 bra 	$L__BB6_162;
	bra.uni 	$L__BB6_160;

$L__BB6_162:
	mov.f64 	%fd928, 0d0000000000000000;
	mul.rn.f64 	%fd1428, %fd242, %fd928;
	mov.u32 	%r496, 0;
	bra.uni 	$L__BB6_163;

$L__BB6_160:
	mul.rn.f64 	%fd919, %fd242, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r496, %fd919;
	st.local.u32 	[%rd1], %r496;
	cvt.rn.f64.s32 	%fd920, %r496;
	neg.f64 	%fd921, %fd920;
	mov.f64 	%fd922, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd923, %fd921, %fd922, %fd242;
	mov.f64 	%fd924, 0d3C91A62633145C00;
	fma.rn.f64 	%fd925, %fd921, %fd924, %fd923;
	mov.f64 	%fd926, 0d397B839A252049C0;
	fma.rn.f64 	%fd1428, %fd921, %fd926, %fd925;
	abs.f64 	%fd927, %fd242;
	setp.ltu.f64 	%p152, %fd927, 0d41E0000000000000;
	@%p152 bra 	$L__BB6_163;

	{ // callseq 98, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd242;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1428, [retval0+0];
	} // callseq 98
	ld.local.u32 	%r496, [%rd1];

$L__BB6_163:
	and.b32  	%r285, %r496, 1;
	shl.b32 	%r286, %r496, 3;
	and.b32  	%r287, %r286, 8;
	setp.eq.s32 	%p153, %r285, 0;
	selp.f64 	%fd929, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p153;
	mul.wide.s32 	%rd129, %r287, 8;
	add.s64 	%rd131, %rd66, %rd129;
	ld.global.nc.f64 	%fd930, [%rd131+8];
	mul.rn.f64 	%fd247, %fd1428, %fd1428;
	fma.rn.f64 	%fd931, %fd929, %fd247, %fd930;
	ld.global.nc.f64 	%fd932, [%rd131+16];
	fma.rn.f64 	%fd933, %fd931, %fd247, %fd932;
	ld.global.nc.f64 	%fd934, [%rd131+24];
	fma.rn.f64 	%fd935, %fd933, %fd247, %fd934;
	ld.global.nc.f64 	%fd936, [%rd131+32];
	fma.rn.f64 	%fd937, %fd935, %fd247, %fd936;
	ld.global.nc.f64 	%fd938, [%rd131+40];
	fma.rn.f64 	%fd939, %fd937, %fd247, %fd938;
	ld.global.nc.f64 	%fd940, [%rd131+48];
	fma.rn.f64 	%fd248, %fd939, %fd247, %fd940;
	fma.rn.f64 	%fd1430, %fd248, %fd1428, %fd1428;
	@%p153 bra 	$L__BB6_165;

	mov.f64 	%fd941, 0d3FF0000000000000;
	fma.rn.f64 	%fd1430, %fd248, %fd247, %fd941;

$L__BB6_165:
	and.b32  	%r288, %r496, 2;
	setp.eq.s32 	%p154, %r288, 0;
	@%p154 bra 	$L__BB6_167;

	mov.f64 	%fd942, 0d0000000000000000;
	mov.f64 	%fd943, 0dBFF0000000000000;
	fma.rn.f64 	%fd1430, %fd1430, %fd943, %fd942;

$L__BB6_167:
	mul.rn.f64 	%fd944, %fd1430, 0d4064000000000000;
	add.rn.f64 	%fd254, %fd241, %fd944;
	div.rn.f64 	%fd255, %fd192, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r289, %temp}, %fd255;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %fd255;
	}
	and.b32  	%r291, %r290, 2147483647;
	setp.eq.s32 	%p155, %r291, 2146435072;
	setp.eq.s32 	%p156, %r289, 0;
	and.pred  	%p157, %p156, %p155;
	@%p157 bra 	$L__BB6_170;
	bra.uni 	$L__BB6_168;

$L__BB6_170:
	mov.f64 	%fd954, 0d0000000000000000;
	mul.rn.f64 	%fd1431, %fd255, %fd954;
	mov.u32 	%r497, 0;
	bra.uni 	$L__BB6_171;

$L__BB6_168:
	mul.rn.f64 	%fd945, %fd255, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r497, %fd945;
	st.local.u32 	[%rd1], %r497;
	cvt.rn.f64.s32 	%fd946, %r497;
	neg.f64 	%fd947, %fd946;
	mov.f64 	%fd948, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd949, %fd947, %fd948, %fd255;
	mov.f64 	%fd950, 0d3C91A62633145C00;
	fma.rn.f64 	%fd951, %fd947, %fd950, %fd949;
	mov.f64 	%fd952, 0d397B839A252049C0;
	fma.rn.f64 	%fd1431, %fd947, %fd952, %fd951;
	abs.f64 	%fd953, %fd255;
	setp.ltu.f64 	%p158, %fd953, 0d41E0000000000000;
	@%p158 bra 	$L__BB6_171;

	{ // callseq 99, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd255;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1431, [retval0+0];
	} // callseq 99
	ld.local.u32 	%r497, [%rd1];

$L__BB6_171:
	and.b32  	%r293, %r497, 1;
	shl.b32 	%r294, %r497, 3;
	and.b32  	%r295, %r294, 8;
	setp.eq.s32 	%p159, %r293, 0;
	selp.f64 	%fd955, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p159;
	mul.wide.s32 	%rd133, %r295, 8;
	add.s64 	%rd135, %rd66, %rd133;
	ld.global.nc.f64 	%fd956, [%rd135+8];
	mul.rn.f64 	%fd260, %fd1431, %fd1431;
	fma.rn.f64 	%fd957, %fd955, %fd260, %fd956;
	ld.global.nc.f64 	%fd958, [%rd135+16];
	fma.rn.f64 	%fd959, %fd957, %fd260, %fd958;
	ld.global.nc.f64 	%fd960, [%rd135+24];
	fma.rn.f64 	%fd961, %fd959, %fd260, %fd960;
	ld.global.nc.f64 	%fd962, [%rd135+32];
	fma.rn.f64 	%fd963, %fd961, %fd260, %fd962;
	ld.global.nc.f64 	%fd964, [%rd135+40];
	fma.rn.f64 	%fd965, %fd963, %fd260, %fd964;
	ld.global.nc.f64 	%fd966, [%rd135+48];
	fma.rn.f64 	%fd261, %fd965, %fd260, %fd966;
	fma.rn.f64 	%fd1433, %fd261, %fd1431, %fd1431;
	@%p159 bra 	$L__BB6_173;

	mov.f64 	%fd967, 0d3FF0000000000000;
	fma.rn.f64 	%fd1433, %fd261, %fd260, %fd967;

$L__BB6_173:
	and.b32  	%r296, %r497, 2;
	setp.eq.s32 	%p160, %r296, 0;
	@%p160 bra 	$L__BB6_175;

	mov.f64 	%fd968, 0d0000000000000000;
	mov.f64 	%fd969, 0dBFF0000000000000;
	fma.rn.f64 	%fd1433, %fd1433, %fd969, %fd968;

$L__BB6_175:
	mul.rn.f64 	%fd970, %fd1433, 0d4074000000000000;
	add.rn.f64 	%fd267, %fd254, %fd970;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r297}, %fd191;
	}
	and.b32  	%r298, %r297, 2147483647;
	setp.eq.s32 	%p161, %r298, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r299, %temp}, %fd191;
	}
	setp.eq.s32 	%p162, %r299, 0;
	and.pred  	%p163, %p162, %p161;
	@%p163 bra 	$L__BB6_178;
	bra.uni 	$L__BB6_176;

$L__BB6_178:
	mov.f64 	%fd980, 0d0000000000000000;
	mul.rn.f64 	%fd1434, %fd191, %fd980;
	mov.u32 	%r498, 0;
	bra.uni 	$L__BB6_179;

$L__BB6_176:
	mul.rn.f64 	%fd971, %fd191, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r498, %fd971;
	st.local.u32 	[%rd1], %r498;
	cvt.rn.f64.s32 	%fd972, %r498;
	neg.f64 	%fd973, %fd972;
	mov.f64 	%fd974, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd975, %fd973, %fd974, %fd191;
	mov.f64 	%fd976, 0d3C91A62633145C00;
	fma.rn.f64 	%fd977, %fd973, %fd976, %fd975;
	mov.f64 	%fd978, 0d397B839A252049C0;
	fma.rn.f64 	%fd1434, %fd973, %fd978, %fd977;
	abs.f64 	%fd979, %fd191;
	setp.ltu.f64 	%p164, %fd979, 0d41E0000000000000;
	@%p164 bra 	$L__BB6_179;

	{ // callseq 100, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1434, [retval0+0];
	} // callseq 100
	ld.local.u32 	%r498, [%rd1];

$L__BB6_179:
	and.b32  	%r301, %r498, 1;
	shl.b32 	%r302, %r498, 3;
	and.b32  	%r303, %r302, 8;
	setp.eq.s32 	%p165, %r301, 0;
	selp.f64 	%fd981, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p165;
	mul.wide.s32 	%rd137, %r303, 8;
	add.s64 	%rd139, %rd66, %rd137;
	ld.global.nc.f64 	%fd982, [%rd139+8];
	mul.rn.f64 	%fd272, %fd1434, %fd1434;
	fma.rn.f64 	%fd983, %fd981, %fd272, %fd982;
	ld.global.nc.f64 	%fd984, [%rd139+16];
	fma.rn.f64 	%fd985, %fd983, %fd272, %fd984;
	ld.global.nc.f64 	%fd986, [%rd139+24];
	fma.rn.f64 	%fd987, %fd985, %fd272, %fd986;
	ld.global.nc.f64 	%fd988, [%rd139+32];
	fma.rn.f64 	%fd989, %fd987, %fd272, %fd988;
	ld.global.nc.f64 	%fd990, [%rd139+40];
	fma.rn.f64 	%fd991, %fd989, %fd272, %fd990;
	ld.global.nc.f64 	%fd992, [%rd139+48];
	fma.rn.f64 	%fd273, %fd991, %fd272, %fd992;
	fma.rn.f64 	%fd1436, %fd273, %fd1434, %fd1434;
	@%p165 bra 	$L__BB6_181;

	mov.f64 	%fd993, 0d3FF0000000000000;
	fma.rn.f64 	%fd1436, %fd273, %fd272, %fd993;

$L__BB6_181:
	and.b32  	%r304, %r498, 2;
	setp.eq.s32 	%p166, %r304, 0;
	@%p166 bra 	$L__BB6_183;

	mov.f64 	%fd994, 0d0000000000000000;
	mov.f64 	%fd995, 0dBFF0000000000000;
	fma.rn.f64 	%fd1436, %fd1436, %fd995, %fd994;

$L__BB6_183:
	div.rn.f64 	%fd279, %fd191, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd279;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r306}, %fd279;
	}
	and.b32  	%r307, %r306, 2147483647;
	setp.eq.s32 	%p167, %r307, 2146435072;
	setp.eq.s32 	%p168, %r305, 0;
	and.pred  	%p169, %p168, %p167;
	@%p169 bra 	$L__BB6_186;
	bra.uni 	$L__BB6_184;

$L__BB6_186:
	mov.f64 	%fd1005, 0d0000000000000000;
	mul.rn.f64 	%fd1437, %fd279, %fd1005;
	mov.u32 	%r499, 0;
	bra.uni 	$L__BB6_187;

$L__BB6_184:
	mul.rn.f64 	%fd996, %fd279, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r499, %fd996;
	st.local.u32 	[%rd1], %r499;
	cvt.rn.f64.s32 	%fd997, %r499;
	neg.f64 	%fd998, %fd997;
	mov.f64 	%fd999, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1000, %fd998, %fd999, %fd279;
	mov.f64 	%fd1001, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1002, %fd998, %fd1001, %fd1000;
	mov.f64 	%fd1003, 0d397B839A252049C0;
	fma.rn.f64 	%fd1437, %fd998, %fd1003, %fd1002;
	abs.f64 	%fd1004, %fd279;
	setp.ltu.f64 	%p170, %fd1004, 0d41E0000000000000;
	@%p170 bra 	$L__BB6_187;

	{ // callseq 101, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd279;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1437, [retval0+0];
	} // callseq 101
	ld.local.u32 	%r499, [%rd1];

$L__BB6_187:
	and.b32  	%r309, %r499, 1;
	shl.b32 	%r310, %r499, 3;
	and.b32  	%r311, %r310, 8;
	setp.eq.s32 	%p171, %r309, 0;
	selp.f64 	%fd1006, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p171;
	mul.wide.s32 	%rd141, %r311, 8;
	add.s64 	%rd143, %rd66, %rd141;
	ld.global.nc.f64 	%fd1007, [%rd143+8];
	mul.rn.f64 	%fd284, %fd1437, %fd1437;
	fma.rn.f64 	%fd1008, %fd1006, %fd284, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd143+16];
	fma.rn.f64 	%fd1010, %fd1008, %fd284, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd143+24];
	fma.rn.f64 	%fd1012, %fd1010, %fd284, %fd1011;
	ld.global.nc.f64 	%fd1013, [%rd143+32];
	fma.rn.f64 	%fd1014, %fd1012, %fd284, %fd1013;
	ld.global.nc.f64 	%fd1015, [%rd143+40];
	fma.rn.f64 	%fd1016, %fd1014, %fd284, %fd1015;
	ld.global.nc.f64 	%fd1017, [%rd143+48];
	fma.rn.f64 	%fd285, %fd1016, %fd284, %fd1017;
	fma.rn.f64 	%fd1439, %fd285, %fd1437, %fd1437;
	@%p171 bra 	$L__BB6_189;

	mov.f64 	%fd1018, 0d3FF0000000000000;
	fma.rn.f64 	%fd1439, %fd285, %fd284, %fd1018;

$L__BB6_189:
	and.b32  	%r312, %r499, 2;
	setp.eq.s32 	%p172, %r312, 0;
	@%p172 bra 	$L__BB6_191;

	mov.f64 	%fd1019, 0d0000000000000000;
	mov.f64 	%fd1020, 0dBFF0000000000000;
	fma.rn.f64 	%fd1439, %fd1439, %fd1020, %fd1019;

$L__BB6_191:
	mul.rn.f64 	%fd1021, %fd1439, 0d4044000000000000;
	mul.rn.f64 	%fd1022, %fd1436, 0d4034000000000000;
	add.rn.f64 	%fd291, %fd1022, %fd1021;
	div.rn.f64 	%fd292, %fd191, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r313, %temp}, %fd292;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd292;
	}
	and.b32  	%r315, %r314, 2147483647;
	setp.eq.s32 	%p173, %r315, 2146435072;
	setp.eq.s32 	%p174, %r313, 0;
	and.pred  	%p175, %p174, %p173;
	@%p175 bra 	$L__BB6_194;
	bra.uni 	$L__BB6_192;

$L__BB6_194:
	mov.f64 	%fd1032, 0d0000000000000000;
	mul.rn.f64 	%fd1440, %fd292, %fd1032;
	mov.u32 	%r500, 0;
	bra.uni 	$L__BB6_195;

$L__BB6_192:
	mul.rn.f64 	%fd1023, %fd292, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r500, %fd1023;
	st.local.u32 	[%rd1], %r500;
	cvt.rn.f64.s32 	%fd1024, %r500;
	neg.f64 	%fd1025, %fd1024;
	mov.f64 	%fd1026, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1027, %fd1025, %fd1026, %fd292;
	mov.f64 	%fd1028, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1029, %fd1025, %fd1028, %fd1027;
	mov.f64 	%fd1030, 0d397B839A252049C0;
	fma.rn.f64 	%fd1440, %fd1025, %fd1030, %fd1029;
	abs.f64 	%fd1031, %fd292;
	setp.ltu.f64 	%p176, %fd1031, 0d41E0000000000000;
	@%p176 bra 	$L__BB6_195;

	{ // callseq 102, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd292;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1440, [retval0+0];
	} // callseq 102
	ld.local.u32 	%r500, [%rd1];

$L__BB6_195:
	and.b32  	%r317, %r500, 1;
	shl.b32 	%r318, %r500, 3;
	and.b32  	%r319, %r318, 8;
	setp.eq.s32 	%p177, %r317, 0;
	selp.f64 	%fd1033, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p177;
	mul.wide.s32 	%rd145, %r319, 8;
	add.s64 	%rd147, %rd66, %rd145;
	ld.global.nc.f64 	%fd1034, [%rd147+8];
	mul.rn.f64 	%fd297, %fd1440, %fd1440;
	fma.rn.f64 	%fd1035, %fd1033, %fd297, %fd1034;
	ld.global.nc.f64 	%fd1036, [%rd147+16];
	fma.rn.f64 	%fd1037, %fd1035, %fd297, %fd1036;
	ld.global.nc.f64 	%fd1038, [%rd147+24];
	fma.rn.f64 	%fd1039, %fd1037, %fd297, %fd1038;
	ld.global.nc.f64 	%fd1040, [%rd147+32];
	fma.rn.f64 	%fd1041, %fd1039, %fd297, %fd1040;
	ld.global.nc.f64 	%fd1042, [%rd147+40];
	fma.rn.f64 	%fd1043, %fd1041, %fd297, %fd1042;
	ld.global.nc.f64 	%fd1044, [%rd147+48];
	fma.rn.f64 	%fd298, %fd1043, %fd297, %fd1044;
	fma.rn.f64 	%fd1442, %fd298, %fd1440, %fd1440;
	@%p177 bra 	$L__BB6_197;

	mov.f64 	%fd1045, 0d3FF0000000000000;
	fma.rn.f64 	%fd1442, %fd298, %fd297, %fd1045;

$L__BB6_197:
	and.b32  	%r320, %r500, 2;
	setp.eq.s32 	%p178, %r320, 0;
	@%p178 bra 	$L__BB6_199;

	mov.f64 	%fd1046, 0d0000000000000000;
	mov.f64 	%fd1047, 0dBFF0000000000000;
	fma.rn.f64 	%fd1442, %fd1442, %fd1047, %fd1046;

$L__BB6_199:
	mul.rn.f64 	%fd1048, %fd1442, 0d4062C00000000000;
	add.rn.f64 	%fd304, %fd291, %fd1048;
	div.rn.f64 	%fd305, %fd191, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r321, %temp}, %fd305;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r322}, %fd305;
	}
	and.b32  	%r323, %r322, 2147483647;
	setp.eq.s32 	%p179, %r323, 2146435072;
	setp.eq.s32 	%p180, %r321, 0;
	and.pred  	%p181, %p180, %p179;
	@%p181 bra 	$L__BB6_202;
	bra.uni 	$L__BB6_200;

$L__BB6_202:
	mov.f64 	%fd1058, 0d0000000000000000;
	mul.rn.f64 	%fd1443, %fd305, %fd1058;
	mov.u32 	%r501, 0;
	bra.uni 	$L__BB6_203;

$L__BB6_200:
	mul.rn.f64 	%fd1049, %fd305, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r501, %fd1049;
	st.local.u32 	[%rd1], %r501;
	cvt.rn.f64.s32 	%fd1050, %r501;
	neg.f64 	%fd1051, %fd1050;
	mov.f64 	%fd1052, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1053, %fd1051, %fd1052, %fd305;
	mov.f64 	%fd1054, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1055, %fd1051, %fd1054, %fd1053;
	mov.f64 	%fd1056, 0d397B839A252049C0;
	fma.rn.f64 	%fd1443, %fd1051, %fd1056, %fd1055;
	abs.f64 	%fd1057, %fd305;
	setp.ltu.f64 	%p182, %fd1057, 0d41E0000000000000;
	@%p182 bra 	$L__BB6_203;

	{ // callseq 103, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd305;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1443, [retval0+0];
	} // callseq 103
	ld.local.u32 	%r501, [%rd1];

$L__BB6_203:
	and.b32  	%r325, %r501, 1;
	shl.b32 	%r326, %r501, 3;
	and.b32  	%r327, %r326, 8;
	setp.eq.s32 	%p183, %r325, 0;
	selp.f64 	%fd1059, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p183;
	mul.wide.s32 	%rd149, %r327, 8;
	add.s64 	%rd151, %rd66, %rd149;
	ld.global.nc.f64 	%fd1060, [%rd151+8];
	mul.rn.f64 	%fd310, %fd1443, %fd1443;
	fma.rn.f64 	%fd1061, %fd1059, %fd310, %fd1060;
	ld.global.nc.f64 	%fd1062, [%rd151+16];
	fma.rn.f64 	%fd1063, %fd1061, %fd310, %fd1062;
	ld.global.nc.f64 	%fd1064, [%rd151+24];
	fma.rn.f64 	%fd1065, %fd1063, %fd310, %fd1064;
	ld.global.nc.f64 	%fd1066, [%rd151+32];
	fma.rn.f64 	%fd1067, %fd1065, %fd310, %fd1066;
	ld.global.nc.f64 	%fd1068, [%rd151+40];
	fma.rn.f64 	%fd1069, %fd1067, %fd310, %fd1068;
	ld.global.nc.f64 	%fd1070, [%rd151+48];
	fma.rn.f64 	%fd311, %fd1069, %fd310, %fd1070;
	fma.rn.f64 	%fd1445, %fd311, %fd1443, %fd1443;
	@%p183 bra 	$L__BB6_205;

	mov.f64 	%fd1071, 0d3FF0000000000000;
	fma.rn.f64 	%fd1445, %fd311, %fd310, %fd1071;

$L__BB6_205:
	and.b32  	%r328, %r501, 2;
	setp.eq.s32 	%p184, %r328, 0;
	@%p184 bra 	$L__BB6_207;

	mov.f64 	%fd1072, 0d0000000000000000;
	mov.f64 	%fd1073, 0dBFF0000000000000;
	fma.rn.f64 	%fd1445, %fd1445, %fd1073, %fd1072;

$L__BB6_207:
	mul.rn.f64 	%fd1074, %fd1445, 0d4072C00000000000;
	add.rn.f64 	%fd1075, %fd304, %fd1074;
	add.rn.f64 	%fd317, %fd217, %fd1075;
	add.rn.f64 	%fd318, %fd217, %fd267;
	add.rn.f64 	%fd1076, %fd188, %fd188;
	add.rn.f64 	%fd1077, %fd1076, 0dC059000000000000;
	mul.rn.f64 	%fd1078, %fd187, 0d4008000000000000;
	add.rn.f64 	%fd319, %fd1077, %fd1078;
	abs.f64 	%fd320, %fd187;
	{ // callseq 104, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd320;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1448, [retval0+0];
	} // callseq 104
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd187;
	}
	setp.lt.s32 	%p185, %r79, 0;
	and.pred  	%p4, %p185, %p69;
	not.pred 	%p187, %p4;
	@%p187 bra 	$L__BB6_209;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r329}, %fd1448;
	}
	xor.b32  	%r330, %r329, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r331, %temp}, %fd1448;
	}
	mov.b64 	%fd1448, {%r331, %r330};

$L__BB6_209:
	setp.eq.f64 	%p188, %fd187, 0d0000000000000000;
	@%p188 bra 	$L__BB6_213;
	bra.uni 	$L__BB6_210;

$L__BB6_213:
	setp.lt.s32 	%p191, %r31, 0;
	mov.u32 	%r332, 0;
	selp.b32 	%r333, %r79, 0, %p69;
	or.b32  	%r334, %r333, 2146435072;
	selp.b32 	%r335, %r334, %r333, %p191;
	mov.b64 	%fd1448, {%r332, %r335};
	bra.uni 	$L__BB6_214;

$L__BB6_210:
	setp.gt.s32 	%p189, %r79, -1;
	@%p189 bra 	$L__BB6_214;

	mov.f64 	%fd1079, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1080, %fd1079;
	setp.eq.f64 	%p190, %fd1080, 0d4000000000000000;
	@%p190 bra 	$L__BB6_214;

	mov.f64 	%fd1448, 0dFFF8000000000000;

$L__BB6_214:
	add.rn.f64 	%fd1082, %fd187, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd1082;
	}
	and.b32  	%r337, %r336, 2146435072;
	setp.ne.s32 	%p193, %r337, 2146435072;
	@%p193 bra 	$L__BB6_221;

	setp.gtu.f64 	%p194, %fd320, 0d7FF0000000000000;
	@%p194 bra 	$L__BB6_220;
	bra.uni 	$L__BB6_216;

$L__BB6_220:
	mov.f64 	%fd1084, 0d4000000000000000;
	add.rn.f64 	%fd1448, %fd187, %fd1084;
	bra.uni 	$L__BB6_221;

$L__BB6_216:
	setp.eq.s32 	%p195, %r45, 2146435072;
	mov.f64 	%fd1083, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd1083;
	}
	setp.eq.s32 	%p196, %r338, 0;
	and.pred  	%p197, %p195, %p196;
	@%p197 bra 	$L__BB6_219;
	bra.uni 	$L__BB6_217;

$L__BB6_219:
	setp.lt.s32 	%p203, %r31, 0;
	mov.u32 	%r343, 0;
	setp.gt.f64 	%p204, %fd320, 0d3FF0000000000000;
	selp.b32 	%r344, 2146435072, 0, %p204;
	xor.b32  	%r345, %r344, 2146435072;
	selp.b32 	%r346, %r345, %r344, %p203;
	setp.eq.f64 	%p205, %fd187, 0dBFF0000000000000;
	selp.b32 	%r347, 1072693248, %r346, %p205;
	mov.b64 	%fd1448, {%r343, %r347};
	bra.uni 	$L__BB6_221;

$L__BB6_217:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd187;
	}
	and.b32  	%r340, %r79, 2147483647;
	setp.ne.s32 	%p198, %r340, 2146435072;
	setp.ne.s32 	%p199, %r339, 0;
	or.pred  	%p200, %p198, %p199;
	@%p200 bra 	$L__BB6_221;

	setp.ne.s32 	%p201, %r45, 1071644672;
	and.pred  	%p202, %p201, %p4;
	selp.b32 	%r341, %r47, %r46, %p202;
	mov.u32 	%r342, 0;
	mov.b64 	%fd1448, {%r342, %r341};

$L__BB6_221:
	mul.rn.f64 	%fd1085, %fd1448, 0d3FC999999999999A;
	setp.eq.f64 	%p206, %fd187, 0d3FF0000000000000;
	selp.f64 	%fd1086, 0d3FC999999999999A, %fd1085, %p206;
	add.rn.f64 	%fd1087, %fd319, %fd1086;
	mul.rn.f64 	%fd1088, %fd188, %fd187;
	mul.rn.f64 	%fd330, %fd1088, 0d3FB999999999999A;
	add.rn.f64 	%fd1089, %fd330, %fd1087;
	mul.rn.f64 	%fd1090, %fd190, 0d3FC999999999999A;
	add.rn.f64 	%fd1091, %fd1090, %fd1089;
	mul.rn.f64 	%fd1092, %fd318, 0d3FE5555555555555;
	add.rn.f64 	%fd331, %fd1092, %fd1091;
	add.rn.f64 	%fd1093, %fd187, %fd187;
	add.rn.f64 	%fd1094, %fd188, 0d4072C00000000000;
	add.rn.f64 	%fd332, %fd1094, %fd1093;
	{ // callseq 105, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd189;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1451, [retval0+0];
	} // callseq 105
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd188;
	}
	setp.lt.s32 	%p207, %r80, 0;
	and.pred  	%p5, %p207, %p69;
	not.pred 	%p209, %p5;
	@%p209 bra 	$L__BB6_223;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r348}, %fd1451;
	}
	xor.b32  	%r349, %r348, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r350, %temp}, %fd1451;
	}
	mov.b64 	%fd1451, {%r350, %r349};

$L__BB6_223:
	setp.eq.f64 	%p210, %fd188, 0d0000000000000000;
	@%p210 bra 	$L__BB6_227;
	bra.uni 	$L__BB6_224;

$L__BB6_227:
	setp.lt.s32 	%p213, %r31, 0;
	mov.u32 	%r351, 0;
	selp.b32 	%r352, %r80, 0, %p69;
	or.b32  	%r353, %r352, 2146435072;
	selp.b32 	%r354, %r353, %r352, %p213;
	mov.b64 	%fd1451, {%r351, %r354};
	bra.uni 	$L__BB6_228;

$L__BB6_224:
	setp.gt.s32 	%p211, %r80, -1;
	@%p211 bra 	$L__BB6_228;

	mov.f64 	%fd1095, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1096, %fd1095;
	setp.eq.f64 	%p212, %fd1096, 0d4000000000000000;
	@%p212 bra 	$L__BB6_228;

	mov.f64 	%fd1451, 0dFFF8000000000000;

$L__BB6_228:
	add.rn.f64 	%fd1098, %fd188, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r355}, %fd1098;
	}
	and.b32  	%r356, %r355, 2146435072;
	setp.ne.s32 	%p215, %r356, 2146435072;
	@%p215 bra 	$L__BB6_235;

	setp.gtu.f64 	%p216, %fd189, 0d7FF0000000000000;
	@%p216 bra 	$L__BB6_234;
	bra.uni 	$L__BB6_230;

$L__BB6_234:
	mov.f64 	%fd1100, 0d4000000000000000;
	add.rn.f64 	%fd1451, %fd188, %fd1100;
	bra.uni 	$L__BB6_235;

$L__BB6_230:
	setp.eq.s32 	%p217, %r45, 2146435072;
	mov.f64 	%fd1099, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r357, %temp}, %fd1099;
	}
	setp.eq.s32 	%p218, %r357, 0;
	and.pred  	%p219, %p217, %p218;
	@%p219 bra 	$L__BB6_233;
	bra.uni 	$L__BB6_231;

$L__BB6_233:
	setp.lt.s32 	%p225, %r31, 0;
	mov.u32 	%r362, 0;
	setp.gt.f64 	%p226, %fd189, 0d3FF0000000000000;
	selp.b32 	%r363, 2146435072, 0, %p226;
	xor.b32  	%r364, %r363, 2146435072;
	selp.b32 	%r365, %r364, %r363, %p225;
	setp.eq.f64 	%p227, %fd188, 0dBFF0000000000000;
	selp.b32 	%r366, 1072693248, %r365, %p227;
	mov.b64 	%fd1451, {%r362, %r366};
	bra.uni 	$L__BB6_235;

$L__BB6_231:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r358, %temp}, %fd188;
	}
	and.b32  	%r359, %r80, 2147483647;
	setp.ne.s32 	%p220, %r359, 2146435072;
	setp.ne.s32 	%p221, %r358, 0;
	or.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB6_235;

	setp.ne.s32 	%p223, %r45, 1071644672;
	and.pred  	%p224, %p223, %p5;
	selp.b32 	%r360, %r47, %r46, %p224;
	mov.u32 	%r361, 0;
	mov.b64 	%fd1451, {%r361, %r360};

$L__BB6_235:
	mul.rn.f64 	%fd1101, %fd1451, 0d3FB999999999999A;
	setp.eq.f64 	%p228, %fd188, 0d3FF0000000000000;
	selp.f64 	%fd1102, 0d3FB999999999999A, %fd1101, %p228;
	add.rn.f64 	%fd1103, %fd332, %fd1102;
	add.rn.f64 	%fd1104, %fd330, %fd1103;
	mul.rn.f64 	%fd1105, %fd190, 0d3FB999999999999A;
	add.rn.f64 	%fd1106, %fd1105, %fd1104;
	mul.rn.f64 	%fd1107, %fd317, 0d3FE5555555555555;
	add.rn.f64 	%fd342, %fd1107, %fd1106;
	div.rn.f64 	%fd1108, %fd1481, 0d4066800000000000;
	mul.rn.f64 	%fd343, %fd1108, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd343;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r368}, %fd343;
	}
	and.b32  	%r369, %r368, 2147483647;
	setp.eq.s32 	%p229, %r369, 2146435072;
	setp.eq.s32 	%p230, %r367, 0;
	and.pred  	%p6, %p230, %p229;
	@%p6 bra 	$L__BB6_238;
	bra.uni 	$L__BB6_236;

$L__BB6_238:
	mov.f64 	%fd1118, 0d0000000000000000;
	mul.rn.f64 	%fd1452, %fd343, %fd1118;
	mov.u32 	%r502, 0;
	bra.uni 	$L__BB6_239;

$L__BB6_236:
	mul.rn.f64 	%fd1109, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r502, %fd1109;
	st.local.u32 	[%rd1], %r502;
	cvt.rn.f64.s32 	%fd1110, %r502;
	neg.f64 	%fd1111, %fd1110;
	mov.f64 	%fd1112, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1113, %fd1111, %fd1112, %fd343;
	mov.f64 	%fd1114, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1115, %fd1111, %fd1114, %fd1113;
	mov.f64 	%fd1116, 0d397B839A252049C0;
	fma.rn.f64 	%fd1452, %fd1111, %fd1116, %fd1115;
	abs.f64 	%fd1117, %fd343;
	setp.ltu.f64 	%p231, %fd1117, 0d41E0000000000000;
	@%p231 bra 	$L__BB6_239;

	{ // callseq 106, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1452, [retval0+0];
	} // callseq 106
	ld.local.u32 	%r502, [%rd1];

$L__BB6_239:
	and.b32  	%r371, %r502, 1;
	shl.b32 	%r372, %r502, 3;
	and.b32  	%r373, %r372, 8;
	setp.eq.s32 	%p232, %r371, 0;
	selp.f64 	%fd1119, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p232;
	mul.wide.s32 	%rd153, %r373, 8;
	add.s64 	%rd155, %rd66, %rd153;
	ld.global.nc.f64 	%fd1120, [%rd155+8];
	mul.rn.f64 	%fd348, %fd1452, %fd1452;
	fma.rn.f64 	%fd1121, %fd1119, %fd348, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd155+16];
	fma.rn.f64 	%fd1123, %fd1121, %fd348, %fd1122;
	ld.global.nc.f64 	%fd1124, [%rd155+24];
	fma.rn.f64 	%fd1125, %fd1123, %fd348, %fd1124;
	ld.global.nc.f64 	%fd1126, [%rd155+32];
	fma.rn.f64 	%fd1127, %fd1125, %fd348, %fd1126;
	ld.global.nc.f64 	%fd1128, [%rd155+40];
	fma.rn.f64 	%fd1129, %fd1127, %fd348, %fd1128;
	ld.global.nc.f64 	%fd1130, [%rd155+48];
	fma.rn.f64 	%fd349, %fd1129, %fd348, %fd1130;
	fma.rn.f64 	%fd1454, %fd349, %fd1452, %fd1452;
	@%p232 bra 	$L__BB6_241;

	mov.f64 	%fd1131, 0d3FF0000000000000;
	fma.rn.f64 	%fd1454, %fd349, %fd348, %fd1131;

$L__BB6_241:
	and.b32  	%r374, %r502, 2;
	setp.eq.s32 	%p233, %r374, 0;
	@%p233 bra 	$L__BB6_243;

	mov.f64 	%fd1132, 0d0000000000000000;
	mov.f64 	%fd1133, 0dBFF0000000000000;
	fma.rn.f64 	%fd1454, %fd1454, %fd1133, %fd1132;

$L__BB6_243:
	@%p6 bra 	$L__BB6_247;
	bra.uni 	$L__BB6_244;

$L__BB6_247:
	mov.f64 	%fd1143, 0d0000000000000000;
	mul.rn.f64 	%fd1456, %fd343, %fd1143;
	mov.u32 	%r504, 1;
	bra.uni 	$L__BB6_248;

$L__BB6_244:
	mul.rn.f64 	%fd1134, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r503, %fd1134;
	st.local.u32 	[%rd1], %r503;
	cvt.rn.f64.s32 	%fd1135, %r503;
	neg.f64 	%fd1136, %fd1135;
	mov.f64 	%fd1137, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1138, %fd1136, %fd1137, %fd343;
	mov.f64 	%fd1139, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1140, %fd1136, %fd1139, %fd1138;
	mov.f64 	%fd1141, 0d397B839A252049C0;
	fma.rn.f64 	%fd1456, %fd1136, %fd1141, %fd1140;
	abs.f64 	%fd1142, %fd343;
	setp.ltu.f64 	%p234, %fd1142, 0d41E0000000000000;
	@%p234 bra 	$L__BB6_246;

	{ // callseq 107, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1456, [retval0+0];
	} // callseq 107
	ld.local.u32 	%r503, [%rd1];

$L__BB6_246:
	add.s32 	%r504, %r503, 1;

$L__BB6_248:
	and.b32  	%r376, %r504, 1;
	shl.b32 	%r377, %r504, 3;
	and.b32  	%r378, %r377, 8;
	setp.eq.s32 	%p235, %r376, 0;
	selp.f64 	%fd1144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p235;
	mul.wide.s32 	%rd157, %r378, 8;
	add.s64 	%rd159, %rd66, %rd157;
	ld.global.nc.f64 	%fd1145, [%rd159+8];
	mul.rn.f64 	%fd360, %fd1456, %fd1456;
	fma.rn.f64 	%fd1146, %fd1144, %fd360, %fd1145;
	ld.global.nc.f64 	%fd1147, [%rd159+16];
	fma.rn.f64 	%fd1148, %fd1146, %fd360, %fd1147;
	ld.global.nc.f64 	%fd1149, [%rd159+24];
	fma.rn.f64 	%fd1150, %fd1148, %fd360, %fd1149;
	ld.global.nc.f64 	%fd1151, [%rd159+32];
	fma.rn.f64 	%fd1152, %fd1150, %fd360, %fd1151;
	ld.global.nc.f64 	%fd1153, [%rd159+40];
	fma.rn.f64 	%fd1154, %fd1152, %fd360, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd159+48];
	fma.rn.f64 	%fd361, %fd1154, %fd360, %fd1155;
	fma.rn.f64 	%fd1458, %fd361, %fd1456, %fd1456;
	@%p235 bra 	$L__BB6_250;

	mov.f64 	%fd1156, 0d3FF0000000000000;
	fma.rn.f64 	%fd1458, %fd361, %fd360, %fd1156;

$L__BB6_250:
	and.b32  	%r379, %r504, 2;
	setp.eq.s32 	%p236, %r379, 0;
	@%p236 bra 	$L__BB6_252;

	mov.f64 	%fd1157, 0d0000000000000000;
	mov.f64 	%fd1158, 0dBFF0000000000000;
	fma.rn.f64 	%fd1458, %fd1458, %fd1158, %fd1157;

$L__BB6_252:
	ld.param.s8 	%rs2, [gcj02_to_wgs84_exact_cuda_param_3];
	mul.rn.f64 	%fd1159, %fd1454, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1160, %fd1454, %fd1159;
	add.rn.f64 	%fd1161, %fd1160, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1162, %fd1161;
	mov.f64 	%fd1163, 0d415854C140000000;
	div.rn.f64 	%fd1164, %fd1163, %fd1162;
	mul.rn.f64 	%fd1165, %fd1164, %fd1458;
	mul.rn.f64 	%fd1166, %fd1165, 0d400921FB54442D18;
	mul.rn.f64 	%fd1167, %fd342, 0d4066800000000000;
	div.rn.f64 	%fd1168, %fd1167, %fd1166;
	add.rn.f64 	%fd1169, %fd1480, %fd1168;
	sub.rn.f64 	%fd367, %fd1, %fd1169;
	mul.rn.f64 	%fd1170, %fd331, 0d4066800000000000;
	mul.rn.f64 	%fd1171, %fd1162, %fd1161;
	mov.f64 	%fd1172, 0d41582B102DE355C1;
	div.rn.f64 	%fd1173, %fd1172, %fd1171;
	mul.rn.f64 	%fd1174, %fd1173, 0d400921FB54442D18;
	div.rn.f64 	%fd1175, %fd1170, %fd1174;
	add.rn.f64 	%fd1176, %fd1481, %fd1175;
	sub.rn.f64 	%fd368, %fd3, %fd1176;
	add.rn.f64 	%fd1415, %fd1480, %fd367;
	add.rn.f64 	%fd1414, %fd1481, %fd368;
	setp.eq.s16 	%p237, %rs2, 0;
	@%p237 bra 	$L__BB6_321;

	mul.rn.f64 	%fd1177, %fd1481, 0d400921FB54442D18;
	div.rn.f64 	%fd371, %fd1177, 0d4066800000000000;
	mul.rn.f64 	%fd1178, %fd1414, 0d400921FB54442D18;
	div.rn.f64 	%fd372, %fd1178, 0d4066800000000000;
	sub.rn.f64 	%fd1179, %fd372, %fd371;
	mul.rn.f64 	%fd373, %fd1179, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r380, %temp}, %fd373;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r381}, %fd373;
	}
	and.b32  	%r382, %r381, 2147483647;
	setp.eq.s32 	%p238, %r382, 2146435072;
	setp.eq.s32 	%p239, %r380, 0;
	and.pred  	%p240, %p239, %p238;
	@%p240 bra 	$L__BB6_256;
	bra.uni 	$L__BB6_254;

$L__BB6_256:
	mov.f64 	%fd1189, 0d0000000000000000;
	mul.rn.f64 	%fd1459, %fd373, %fd1189;
	mov.u32 	%r505, 0;
	bra.uni 	$L__BB6_257;

$L__BB6_321:
	abs.f64 	%fd1357, %fd367;
	setp.geu.f64 	%p318, %fd1357, %fd453;
	@%p318 bra 	$L__BB6_323;

	abs.f64 	%fd1358, %fd368;
	setp.lt.f64 	%p319, %fd1358, %fd453;
	@%p319 bra 	$L__BB6_324;
	bra.uni 	$L__BB6_323;

$L__BB6_254:
	mul.rn.f64 	%fd1180, %fd373, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r505, %fd1180;
	st.local.u32 	[%rd1], %r505;
	cvt.rn.f64.s32 	%fd1181, %r505;
	neg.f64 	%fd1182, %fd1181;
	mov.f64 	%fd1183, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1184, %fd1182, %fd1183, %fd373;
	mov.f64 	%fd1185, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1186, %fd1182, %fd1185, %fd1184;
	mov.f64 	%fd1187, 0d397B839A252049C0;
	fma.rn.f64 	%fd1459, %fd1182, %fd1187, %fd1186;
	abs.f64 	%fd1188, %fd373;
	setp.ltu.f64 	%p241, %fd1188, 0d41E0000000000000;
	@%p241 bra 	$L__BB6_257;

	{ // callseq 108, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd373;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1459, [retval0+0];
	} // callseq 108
	ld.local.u32 	%r505, [%rd1];

$L__BB6_257:
	and.b32  	%r384, %r505, 1;
	shl.b32 	%r385, %r505, 3;
	and.b32  	%r386, %r385, 8;
	setp.eq.s32 	%p242, %r384, 0;
	selp.f64 	%fd1190, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p242;
	mul.wide.s32 	%rd161, %r386, 8;
	add.s64 	%rd163, %rd66, %rd161;
	ld.global.nc.f64 	%fd1191, [%rd163+8];
	mul.rn.f64 	%fd378, %fd1459, %fd1459;
	fma.rn.f64 	%fd1192, %fd1190, %fd378, %fd1191;
	ld.global.nc.f64 	%fd1193, [%rd163+16];
	fma.rn.f64 	%fd1194, %fd1192, %fd378, %fd1193;
	ld.global.nc.f64 	%fd1195, [%rd163+24];
	fma.rn.f64 	%fd1196, %fd1194, %fd378, %fd1195;
	ld.global.nc.f64 	%fd1197, [%rd163+32];
	fma.rn.f64 	%fd1198, %fd1196, %fd378, %fd1197;
	ld.global.nc.f64 	%fd1199, [%rd163+40];
	fma.rn.f64 	%fd1200, %fd1198, %fd378, %fd1199;
	ld.global.nc.f64 	%fd1201, [%rd163+48];
	fma.rn.f64 	%fd379, %fd1200, %fd378, %fd1201;
	fma.rn.f64 	%fd1461, %fd379, %fd1459, %fd1459;
	@%p242 bra 	$L__BB6_259;

	mov.f64 	%fd1202, 0d3FF0000000000000;
	fma.rn.f64 	%fd1461, %fd379, %fd378, %fd1202;

$L__BB6_259:
	and.b32  	%r387, %r505, 2;
	setp.eq.s32 	%p243, %r387, 0;
	@%p243 bra 	$L__BB6_261;

	mov.f64 	%fd1203, 0d0000000000000000;
	mov.f64 	%fd1204, 0dBFF0000000000000;
	fma.rn.f64 	%fd1461, %fd1461, %fd1204, %fd1203;

$L__BB6_261:
	abs.f64 	%fd385, %fd1461;
	{ // callseq 109, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd385;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1464, [retval0+0];
	} // callseq 109
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd1461;
	}
	setp.lt.s32 	%p244, %r92, 0;
	and.pred  	%p7, %p244, %p69;
	not.pred 	%p246, %p7;
	@%p246 bra 	$L__BB6_263;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r388}, %fd1464;
	}
	xor.b32  	%r389, %r388, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r390, %temp}, %fd1464;
	}
	mov.b64 	%fd1464, {%r390, %r389};

$L__BB6_263:
	setp.eq.f64 	%p247, %fd1461, 0d0000000000000000;
	@%p247 bra 	$L__BB6_267;
	bra.uni 	$L__BB6_264;

$L__BB6_267:
	setp.lt.s32 	%p250, %r31, 0;
	mov.u32 	%r391, 0;
	selp.b32 	%r392, %r92, 0, %p69;
	or.b32  	%r393, %r392, 2146435072;
	selp.b32 	%r394, %r393, %r392, %p250;
	mov.b64 	%fd1464, {%r391, %r394};
	bra.uni 	$L__BB6_268;

$L__BB6_264:
	setp.gt.s32 	%p248, %r92, -1;
	@%p248 bra 	$L__BB6_268;

	mov.f64 	%fd1205, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1206, %fd1205;
	setp.eq.f64 	%p249, %fd1206, 0d4000000000000000;
	@%p249 bra 	$L__BB6_268;

	mov.f64 	%fd1464, 0dFFF8000000000000;

$L__BB6_268:
	add.rn.f64 	%fd1208, %fd1461, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r395}, %fd1208;
	}
	and.b32  	%r396, %r395, 2146435072;
	setp.ne.s32 	%p252, %r396, 2146435072;
	@%p252 bra 	$L__BB6_275;

	setp.gtu.f64 	%p253, %fd385, 0d7FF0000000000000;
	@%p253 bra 	$L__BB6_274;
	bra.uni 	$L__BB6_270;

$L__BB6_274:
	mov.f64 	%fd1210, 0d4000000000000000;
	add.rn.f64 	%fd1464, %fd1461, %fd1210;
	bra.uni 	$L__BB6_275;

$L__BB6_270:
	setp.eq.s32 	%p254, %r45, 2146435072;
	mov.f64 	%fd1209, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r397, %temp}, %fd1209;
	}
	setp.eq.s32 	%p255, %r397, 0;
	and.pred  	%p256, %p254, %p255;
	@%p256 bra 	$L__BB6_273;
	bra.uni 	$L__BB6_271;

$L__BB6_273:
	setp.lt.s32 	%p262, %r31, 0;
	mov.u32 	%r402, 0;
	setp.gt.f64 	%p263, %fd385, 0d3FF0000000000000;
	selp.b32 	%r403, 2146435072, 0, %p263;
	xor.b32  	%r404, %r403, 2146435072;
	selp.b32 	%r405, %r404, %r403, %p262;
	setp.eq.f64 	%p264, %fd1461, 0dBFF0000000000000;
	selp.b32 	%r406, 1072693248, %r405, %p264;
	mov.b64 	%fd1464, {%r402, %r406};
	bra.uni 	$L__BB6_275;

$L__BB6_271:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r398, %temp}, %fd1461;
	}
	and.b32  	%r399, %r92, 2147483647;
	setp.ne.s32 	%p257, %r399, 2146435072;
	setp.ne.s32 	%p258, %r398, 0;
	or.pred  	%p259, %p257, %p258;
	@%p259 bra 	$L__BB6_275;

	setp.ne.s32 	%p260, %r45, 1071644672;
	and.pred  	%p261, %p260, %p7;
	selp.b32 	%r400, %r47, %r46, %p261;
	mov.u32 	%r401, 0;
	mov.b64 	%fd1464, {%r401, %r400};

$L__BB6_275:
	setp.eq.f64 	%p265, %fd1461, 0d3FF0000000000000;
	selp.f64 	%fd395, 0d3FF0000000000000, %fd1464, %p265;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r407}, %fd371;
	}
	and.b32  	%r408, %r407, 2147483647;
	setp.eq.s32 	%p266, %r408, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd371;
	}
	setp.eq.s32 	%p267, %r409, 0;
	and.pred  	%p268, %p267, %p266;
	@%p268 bra 	$L__BB6_279;
	bra.uni 	$L__BB6_276;

$L__BB6_279:
	mov.f64 	%fd1220, 0d0000000000000000;
	mul.rn.f64 	%fd1466, %fd371, %fd1220;
	mov.u32 	%r507, 1;
	bra.uni 	$L__BB6_280;

$L__BB6_276:
	mul.rn.f64 	%fd1211, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r506, %fd1211;
	st.local.u32 	[%rd1], %r506;
	cvt.rn.f64.s32 	%fd1212, %r506;
	neg.f64 	%fd1213, %fd1212;
	mov.f64 	%fd1214, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1215, %fd1213, %fd1214, %fd371;
	mov.f64 	%fd1216, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1217, %fd1213, %fd1216, %fd1215;
	mov.f64 	%fd1218, 0d397B839A252049C0;
	fma.rn.f64 	%fd1466, %fd1213, %fd1218, %fd1217;
	abs.f64 	%fd1219, %fd371;
	setp.ltu.f64 	%p269, %fd1219, 0d41E0000000000000;
	@%p269 bra 	$L__BB6_278;

	{ // callseq 110, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1466, [retval0+0];
	} // callseq 110
	ld.local.u32 	%r506, [%rd1];

$L__BB6_278:
	add.s32 	%r507, %r506, 1;

$L__BB6_280:
	and.b32  	%r411, %r507, 1;
	shl.b32 	%r412, %r507, 3;
	and.b32  	%r413, %r412, 8;
	setp.eq.s32 	%p270, %r411, 0;
	selp.f64 	%fd1221, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p270;
	mul.wide.s32 	%rd165, %r413, 8;
	add.s64 	%rd167, %rd66, %rd165;
	ld.global.nc.f64 	%fd1222, [%rd167+8];
	mul.rn.f64 	%fd401, %fd1466, %fd1466;
	fma.rn.f64 	%fd1223, %fd1221, %fd401, %fd1222;
	ld.global.nc.f64 	%fd1224, [%rd167+16];
	fma.rn.f64 	%fd1225, %fd1223, %fd401, %fd1224;
	ld.global.nc.f64 	%fd1226, [%rd167+24];
	fma.rn.f64 	%fd1227, %fd1225, %fd401, %fd1226;
	ld.global.nc.f64 	%fd1228, [%rd167+32];
	fma.rn.f64 	%fd1229, %fd1227, %fd401, %fd1228;
	ld.global.nc.f64 	%fd1230, [%rd167+40];
	fma.rn.f64 	%fd1231, %fd1229, %fd401, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd167+48];
	fma.rn.f64 	%fd402, %fd1231, %fd401, %fd1232;
	fma.rn.f64 	%fd1468, %fd402, %fd1466, %fd1466;
	@%p270 bra 	$L__BB6_282;

	mov.f64 	%fd1233, 0d3FF0000000000000;
	fma.rn.f64 	%fd1468, %fd402, %fd401, %fd1233;

$L__BB6_282:
	and.b32  	%r414, %r507, 2;
	setp.eq.s32 	%p271, %r414, 0;
	@%p271 bra 	$L__BB6_284;

	mov.f64 	%fd1234, 0d0000000000000000;
	mov.f64 	%fd1235, 0dBFF0000000000000;
	fma.rn.f64 	%fd1468, %fd1468, %fd1235, %fd1234;

$L__BB6_284:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r415}, %fd372;
	}
	and.b32  	%r416, %r415, 2147483647;
	setp.eq.s32 	%p272, %r416, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r417, %temp}, %fd372;
	}
	setp.eq.s32 	%p273, %r417, 0;
	and.pred  	%p274, %p273, %p272;
	@%p274 bra 	$L__BB6_288;
	bra.uni 	$L__BB6_285;

$L__BB6_288:
	mov.f64 	%fd1245, 0d0000000000000000;
	mul.rn.f64 	%fd1470, %fd372, %fd1245;
	mov.u32 	%r509, 1;
	bra.uni 	$L__BB6_289;

$L__BB6_285:
	mul.rn.f64 	%fd1236, %fd372, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r508, %fd1236;
	st.local.u32 	[%rd1], %r508;
	cvt.rn.f64.s32 	%fd1237, %r508;
	neg.f64 	%fd1238, %fd1237;
	mov.f64 	%fd1239, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1240, %fd1238, %fd1239, %fd372;
	mov.f64 	%fd1241, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1242, %fd1238, %fd1241, %fd1240;
	mov.f64 	%fd1243, 0d397B839A252049C0;
	fma.rn.f64 	%fd1470, %fd1238, %fd1243, %fd1242;
	abs.f64 	%fd1244, %fd372;
	setp.ltu.f64 	%p275, %fd1244, 0d41E0000000000000;
	@%p275 bra 	$L__BB6_287;

	{ // callseq 111, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd372;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1470, [retval0+0];
	} // callseq 111
	ld.local.u32 	%r508, [%rd1];

$L__BB6_287:
	add.s32 	%r509, %r508, 1;

$L__BB6_289:
	and.b32  	%r419, %r509, 1;
	shl.b32 	%r420, %r509, 3;
	and.b32  	%r421, %r420, 8;
	setp.eq.s32 	%p276, %r419, 0;
	selp.f64 	%fd1246, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p276;
	mul.wide.s32 	%rd169, %r421, 8;
	add.s64 	%rd171, %rd66, %rd169;
	ld.global.nc.f64 	%fd1247, [%rd171+8];
	mul.rn.f64 	%fd413, %fd1470, %fd1470;
	fma.rn.f64 	%fd1248, %fd1246, %fd413, %fd1247;
	ld.global.nc.f64 	%fd1249, [%rd171+16];
	fma.rn.f64 	%fd1250, %fd1248, %fd413, %fd1249;
	ld.global.nc.f64 	%fd1251, [%rd171+24];
	fma.rn.f64 	%fd1252, %fd1250, %fd413, %fd1251;
	ld.global.nc.f64 	%fd1253, [%rd171+32];
	fma.rn.f64 	%fd1254, %fd1252, %fd413, %fd1253;
	ld.global.nc.f64 	%fd1255, [%rd171+40];
	fma.rn.f64 	%fd1256, %fd1254, %fd413, %fd1255;
	ld.global.nc.f64 	%fd1257, [%rd171+48];
	fma.rn.f64 	%fd414, %fd1256, %fd413, %fd1257;
	fma.rn.f64 	%fd1472, %fd414, %fd1470, %fd1470;
	@%p276 bra 	$L__BB6_291;

	mov.f64 	%fd1258, 0d3FF0000000000000;
	fma.rn.f64 	%fd1472, %fd414, %fd413, %fd1258;

$L__BB6_291:
	and.b32  	%r422, %r509, 2;
	setp.eq.s32 	%p277, %r422, 0;
	@%p277 bra 	$L__BB6_293;

	mov.f64 	%fd1259, 0d0000000000000000;
	mov.f64 	%fd1260, 0dBFF0000000000000;
	fma.rn.f64 	%fd1472, %fd1472, %fd1260, %fd1259;

$L__BB6_293:
	mul.rn.f64 	%fd420, %fd1468, %fd1472;
	mul.rn.f64 	%fd1261, %fd1480, 0d400921FB54442D18;
	div.rn.f64 	%fd1262, %fd1261, 0d4066800000000000;
	mul.rn.f64 	%fd1263, %fd1415, 0d400921FB54442D18;
	div.rn.f64 	%fd1264, %fd1263, 0d4066800000000000;
	sub.rn.f64 	%fd1265, %fd1264, %fd1262;
	mul.rn.f64 	%fd421, %fd1265, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r423, %temp}, %fd421;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r424}, %fd421;
	}
	and.b32  	%r425, %r424, 2147483647;
	setp.eq.s32 	%p278, %r425, 2146435072;
	setp.eq.s32 	%p279, %r423, 0;
	and.pred  	%p280, %p279, %p278;
	@%p280 bra 	$L__BB6_296;
	bra.uni 	$L__BB6_294;

$L__BB6_296:
	mov.f64 	%fd1275, 0d0000000000000000;
	mul.rn.f64 	%fd1473, %fd421, %fd1275;
	mov.u32 	%r510, 0;
	bra.uni 	$L__BB6_297;

$L__BB6_294:
	mul.rn.f64 	%fd1266, %fd421, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r510, %fd1266;
	st.local.u32 	[%rd1], %r510;
	cvt.rn.f64.s32 	%fd1267, %r510;
	neg.f64 	%fd1268, %fd1267;
	mov.f64 	%fd1269, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1270, %fd1268, %fd1269, %fd421;
	mov.f64 	%fd1271, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1272, %fd1268, %fd1271, %fd1270;
	mov.f64 	%fd1273, 0d397B839A252049C0;
	fma.rn.f64 	%fd1473, %fd1268, %fd1273, %fd1272;
	abs.f64 	%fd1274, %fd421;
	setp.ltu.f64 	%p281, %fd1274, 0d41E0000000000000;
	@%p281 bra 	$L__BB6_297;

	{ // callseq 112, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd421;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1473, [retval0+0];
	} // callseq 112
	ld.local.u32 	%r510, [%rd1];

$L__BB6_297:
	and.b32  	%r427, %r510, 1;
	shl.b32 	%r428, %r510, 3;
	and.b32  	%r429, %r428, 8;
	setp.eq.s32 	%p282, %r427, 0;
	selp.f64 	%fd1276, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p282;
	mul.wide.s32 	%rd173, %r429, 8;
	add.s64 	%rd175, %rd66, %rd173;
	ld.global.nc.f64 	%fd1277, [%rd175+8];
	mul.rn.f64 	%fd426, %fd1473, %fd1473;
	fma.rn.f64 	%fd1278, %fd1276, %fd426, %fd1277;
	ld.global.nc.f64 	%fd1279, [%rd175+16];
	fma.rn.f64 	%fd1280, %fd1278, %fd426, %fd1279;
	ld.global.nc.f64 	%fd1281, [%rd175+24];
	fma.rn.f64 	%fd1282, %fd1280, %fd426, %fd1281;
	ld.global.nc.f64 	%fd1283, [%rd175+32];
	fma.rn.f64 	%fd1284, %fd1282, %fd426, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd175+40];
	fma.rn.f64 	%fd1286, %fd1284, %fd426, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd175+48];
	fma.rn.f64 	%fd427, %fd1286, %fd426, %fd1287;
	fma.rn.f64 	%fd1475, %fd427, %fd1473, %fd1473;
	@%p282 bra 	$L__BB6_299;

	mov.f64 	%fd1288, 0d3FF0000000000000;
	fma.rn.f64 	%fd1475, %fd427, %fd426, %fd1288;

$L__BB6_299:
	and.b32  	%r430, %r510, 2;
	setp.eq.s32 	%p283, %r430, 0;
	@%p283 bra 	$L__BB6_301;

	mov.f64 	%fd1289, 0d0000000000000000;
	mov.f64 	%fd1290, 0dBFF0000000000000;
	fma.rn.f64 	%fd1475, %fd1475, %fd1290, %fd1289;

$L__BB6_301:
	abs.f64 	%fd433, %fd1475;
	{ // callseq 113, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd433;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1478, [retval0+0];
	} // callseq 113
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd1475;
	}
	setp.lt.s32 	%p284, %r106, 0;
	and.pred  	%p8, %p284, %p69;
	not.pred 	%p286, %p8;
	@%p286 bra 	$L__BB6_303;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd1478;
	}
	xor.b32  	%r432, %r431, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r433, %temp}, %fd1478;
	}
	mov.b64 	%fd1478, {%r433, %r432};

$L__BB6_303:
	setp.eq.f64 	%p287, %fd1475, 0d0000000000000000;
	@%p287 bra 	$L__BB6_307;
	bra.uni 	$L__BB6_304;

$L__BB6_307:
	setp.lt.s32 	%p290, %r31, 0;
	mov.u32 	%r434, 0;
	selp.b32 	%r435, %r106, 0, %p69;
	or.b32  	%r436, %r435, 2146435072;
	selp.b32 	%r437, %r436, %r435, %p290;
	mov.b64 	%fd1478, {%r434, %r437};
	bra.uni 	$L__BB6_308;

$L__BB6_304:
	setp.gt.s32 	%p288, %r106, -1;
	@%p288 bra 	$L__BB6_308;

	mov.f64 	%fd1291, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1292, %fd1291;
	setp.eq.f64 	%p289, %fd1292, 0d4000000000000000;
	@%p289 bra 	$L__BB6_308;

	mov.f64 	%fd1478, 0dFFF8000000000000;

$L__BB6_308:
	add.rn.f64 	%fd1294, %fd1475, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r438}, %fd1294;
	}
	and.b32  	%r439, %r438, 2146435072;
	setp.ne.s32 	%p292, %r439, 2146435072;
	@%p292 bra 	$L__BB6_315;

	setp.gtu.f64 	%p293, %fd433, 0d7FF0000000000000;
	@%p293 bra 	$L__BB6_314;
	bra.uni 	$L__BB6_310;

$L__BB6_314:
	mov.f64 	%fd1296, 0d4000000000000000;
	add.rn.f64 	%fd1478, %fd1475, %fd1296;
	bra.uni 	$L__BB6_315;

$L__BB6_310:
	setp.eq.s32 	%p294, %r45, 2146435072;
	mov.f64 	%fd1295, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r440, %temp}, %fd1295;
	}
	setp.eq.s32 	%p295, %r440, 0;
	and.pred  	%p296, %p294, %p295;
	@%p296 bra 	$L__BB6_313;
	bra.uni 	$L__BB6_311;

$L__BB6_313:
	setp.lt.s32 	%p302, %r31, 0;
	mov.u32 	%r445, 0;
	setp.gt.f64 	%p303, %fd433, 0d3FF0000000000000;
	selp.b32 	%r446, 2146435072, 0, %p303;
	xor.b32  	%r447, %r446, 2146435072;
	selp.b32 	%r448, %r447, %r446, %p302;
	setp.eq.f64 	%p304, %fd1475, 0dBFF0000000000000;
	selp.b32 	%r449, 1072693248, %r448, %p304;
	mov.b64 	%fd1478, {%r445, %r449};
	bra.uni 	$L__BB6_315;

$L__BB6_311:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd1475;
	}
	and.b32  	%r442, %r106, 2147483647;
	setp.ne.s32 	%p297, %r442, 2146435072;
	setp.ne.s32 	%p298, %r441, 0;
	or.pred  	%p299, %p297, %p298;
	@%p299 bra 	$L__BB6_315;

	setp.ne.s32 	%p300, %r45, 1071644672;
	and.pred  	%p301, %p300, %p8;
	selp.b32 	%r443, %r47, %r46, %p301;
	mov.u32 	%r444, 0;
	mov.b64 	%fd1478, {%r444, %r443};

$L__BB6_315:
	setp.eq.f64 	%p305, %fd1475, 0d3FF0000000000000;
	mov.f64 	%fd1297, 0d3FF0000000000000;
	selp.f64 	%fd1298, 0d3FF0000000000000, %fd1478, %p305;
	mul.rn.f64 	%fd1299, %fd420, %fd1298;
	add.rn.f64 	%fd1300, %fd395, %fd1299;
	sqrt.rn.f64 	%fd443, %fd1300;
	sub.rn.f64 	%fd1301, %fd1297, %fd1300;
	sqrt.rn.f64 	%fd444, %fd1301;
	abs.f64 	%fd445, %fd444;
	abs.f64 	%fd446, %fd443;
	setp.eq.f64 	%p306, %fd445, 0d0000000000000000;
	setp.eq.f64 	%p307, %fd446, 0d0000000000000000;
	and.pred  	%p308, %p306, %p307;
	@%p308 bra 	$L__BB6_319;
	bra.uni 	$L__BB6_316;

$L__BB6_319:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r462}, %fd444;
	}
	setp.lt.s32 	%p316, %r462, 0;
	selp.f64 	%fd1354, 0d400921FB54442D18, 0d0000000000000000, %p316;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r463, %temp}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r464}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r465}, %fd443;
	}
	and.b32  	%r466, %r465, -2147483648;
	or.b32  	%r467, %r464, %r466;
	mov.b64 	%fd1479, {%r463, %r467};
	bra.uni 	$L__BB6_320;

$L__BB6_316:
	setp.eq.f64 	%p309, %fd445, 0d7FF0000000000000;
	setp.eq.f64 	%p310, %fd446, 0d7FF0000000000000;
	and.pred  	%p311, %p309, %p310;
	@%p311 bra 	$L__BB6_318;
	bra.uni 	$L__BB6_317;

$L__BB6_318:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r456}, %fd444;
	}
	setp.lt.s32 	%p315, %r456, 0;
	selp.f64 	%fd1353, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p315;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r457, %temp}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r458}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r459}, %fd443;
	}
	and.b32  	%r460, %r459, -2147483648;
	or.b32  	%r461, %r458, %r460;
	mov.b64 	%fd1479, {%r457, %r461};
	bra.uni 	$L__BB6_320;

$L__BB6_317:
	max.f64 	%fd1302, %fd446, %fd445;
	min.f64 	%fd1303, %fd446, %fd445;
	div.rn.f64 	%fd1304, %fd1303, %fd1302;
	mul.rn.f64 	%fd1305, %fd1304, %fd1304;
	mov.f64 	%fd1306, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1307, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1308, %fd1307, %fd1305, %fd1306;
	mov.f64 	%fd1309, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1310, %fd1308, %fd1305, %fd1309;
	mov.f64 	%fd1311, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1312, %fd1310, %fd1305, %fd1311;
	mov.f64 	%fd1313, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1314, %fd1312, %fd1305, %fd1313;
	mov.f64 	%fd1315, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1316, %fd1314, %fd1305, %fd1315;
	mov.f64 	%fd1317, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1318, %fd1316, %fd1305, %fd1317;
	mov.f64 	%fd1319, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1320, %fd1318, %fd1305, %fd1319;
	mov.f64 	%fd1321, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1322, %fd1320, %fd1305, %fd1321;
	mov.f64 	%fd1323, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1324, %fd1322, %fd1305, %fd1323;
	mov.f64 	%fd1325, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1326, %fd1324, %fd1305, %fd1325;
	mov.f64 	%fd1327, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1328, %fd1326, %fd1305, %fd1327;
	mov.f64 	%fd1329, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1330, %fd1328, %fd1305, %fd1329;
	mov.f64 	%fd1331, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1332, %fd1330, %fd1305, %fd1331;
	mov.f64 	%fd1333, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1334, %fd1332, %fd1305, %fd1333;
	mov.f64 	%fd1335, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1336, %fd1334, %fd1305, %fd1335;
	mov.f64 	%fd1337, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1338, %fd1336, %fd1305, %fd1337;
	mov.f64 	%fd1339, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1340, %fd1338, %fd1305, %fd1339;
	mov.f64 	%fd1341, 0dBFD555555555544C;
	fma.rn.f64 	%fd1342, %fd1340, %fd1305, %fd1341;
	mul.rn.f64 	%fd1343, %fd1305, %fd1342;
	fma.rn.f64 	%fd1344, %fd1343, %fd1304, %fd1304;
	mov.f64 	%fd1345, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1346, %fd1345, %fd1344;
	setp.gt.f64 	%p312, %fd446, %fd445;
	selp.f64 	%fd1347, %fd1346, %fd1344, %p312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r450}, %fd444;
	}
	setp.lt.s32 	%p313, %r450, 0;
	mov.f64 	%fd1348, 0d400921FB54442D18;
	sub.rn.f64 	%fd1349, %fd1348, %fd1347;
	selp.f64 	%fd1350, %fd1349, %fd1347, %p313;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r451, %temp}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r452}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r453}, %fd443;
	}
	and.b32  	%r454, %r453, -2147483648;
	or.b32  	%r455, %r452, %r454;
	mov.b64 	%fd1351, {%r451, %r455};
	add.rn.f64 	%fd1352, %fd445, %fd446;
	setp.le.f64 	%p314, %fd1352, 0d7FF0000000000000;
	selp.f64 	%fd1479, %fd1351, %fd1352, %p314;

$L__BB6_320:
	add.rn.f64 	%fd1355, %fd1479, %fd1479;
	mul.rn.f64 	%fd1356, %fd1355, 0d415854A640000000;
	setp.lt.f64 	%p317, %fd1356, %fd453;
	@%p317 bra 	$L__BB6_324;

$L__BB6_323:
	ld.param.u32 	%r468, [gcj02_to_wgs84_exact_cuda_param_4];
	add.s32 	%r491, %r491, 1;
	setp.lt.s32 	%p320, %r491, %r468;
	mov.f64 	%fd1480, %fd1415;
	mov.f64 	%fd1481, %fd1414;
	@%p320 bra 	$L__BB6_127;

$L__BB6_324:
	ld.param.u64 	%rd183, [gcj02_to_wgs84_exact_cuda_param_1];
	mov.u32 	%r477, %tid.x;
	mov.u32 	%r476, %ntid.x;
	mov.u32 	%r475, %ctaid.x;
	mad.lo.s32 	%r474, %r475, %r476, %r477;
	mul.wide.s32 	%rd182, %r474, 8;
	cvta.to.global.u64 	%rd181, %rd183;
	add.s64 	%rd180, %rd181, %rd182;
	ld.param.u64 	%rd179, [gcj02_to_wgs84_exact_cuda_param_0];
	mov.u32 	%r472, %tid.x;
	mov.u32 	%r471, %ntid.x;
	mov.u32 	%r470, %ctaid.x;
	mad.lo.s32 	%r469, %r470, %r471, %r472;
	mul.wide.s32 	%rd178, %r469, 8;
	cvta.to.global.u64 	%rd177, %rd179;
	add.s64 	%rd176, %rd177, %rd178;
	st.global.f64 	[%rd176], %fd1480;
	st.global.f64 	[%rd180], %fd1481;
	ret;

}
	// .globl	bd09_to_wgs84_exact_cuda
.visible .entry bd09_to_wgs84_exact_cuda(
	.param .u64 bd09_to_wgs84_exact_cuda_param_0,
	.param .u64 bd09_to_wgs84_exact_cuda_param_1,
	.param .f64 bd09_to_wgs84_exact_cuda_param_2,
	.param .u8 bd09_to_wgs84_exact_cuda_param_3,
	.param .u32 bd09_to_wgs84_exact_cuda_param_4
)
{
	.local .align 4 .b8 	__local_depot7[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<479>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<721>;
	.reg .f64 	%fd<2011>;
	.reg .b64 	%rd<232>;


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd39, [bd09_to_wgs84_exact_cuda_param_0];
	ld.param.u64 	%rd40, [bd09_to_wgs84_exact_cuda_param_1];
	ld.param.f64 	%fd610, [bd09_to_wgs84_exact_cuda_param_2];
	ld.param.u32 	%r146, [bd09_to_wgs84_exact_cuda_param_4];
	cvta.to.global.u64 	%rd41, %rd40;
	add.u64 	%rd42, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r147, %ntid.x;
	mov.u32 	%r148, %ctaid.x;
	mov.u32 	%r149, %tid.x;
	mad.lo.s32 	%r150, %r148, %r147, %r149;
	cvta.to.global.u64 	%rd78, %rd39;
	mul.wide.s32 	%rd79, %r150, 8;
	add.s64 	%rd37, %rd78, %rd79;
	add.s64 	%rd38, %rd41, %rd79;
	ld.global.f64 	%fd1, [%rd37];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd38];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd611, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd611;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p15, %r3, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 114, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1860, [retval0+0];
	} // callseq 114
	setp.lt.s32 	%p16, %r1, 0;
	and.pred  	%p1, %p16, %p15;
	not.pred 	%p17, %p1;
	@%p17 bra 	$L__BB7_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd1860;
	}
	xor.b32  	%r152, %r151, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd1860;
	}
	mov.b64 	%fd1860, {%r153, %r152};

$L__BB7_2:
	setp.eq.f64 	%p18, %fd2, 0d0000000000000000;
	@%p18 bra 	$L__BB7_6;
	bra.uni 	$L__BB7_3;

$L__BB7_6:
	selp.b32 	%r154, %r1, 0, %p15;
	mov.u32 	%r155, 0;
	or.b32  	%r156, %r154, 2146435072;
	setp.lt.s32 	%p22, %r2, 0;
	selp.b32 	%r157, %r156, %r154, %p22;
	mov.b64 	%fd1860, {%r155, %r157};
	bra.uni 	$L__BB7_7;

$L__BB7_3:
	setp.gt.s32 	%p19, %r1, -1;
	@%p19 bra 	$L__BB7_7;

	mov.f64 	%fd612, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd613, %fd612;
	setp.eq.f64 	%p20, %fd613, 0d4000000000000000;
	@%p20 bra 	$L__BB7_7;

	mov.f64 	%fd1860, 0dFFF8000000000000;

$L__BB7_7:
	add.rn.f64 	%fd615, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %fd615;
	}
	and.b32  	%r159, %r158, 2146435072;
	setp.ne.s32 	%p23, %r159, 2146435072;
	@%p23 bra 	$L__BB7_14;

	setp.gtu.f64 	%p24, %fd5, 0d7FF0000000000000;
	@%p24 bra 	$L__BB7_13;
	bra.uni 	$L__BB7_9;

$L__BB7_13:
	mov.f64 	%fd617, 0d4000000000000000;
	add.rn.f64 	%fd1860, %fd2, %fd617;
	bra.uni 	$L__BB7_14;

$L__BB7_9:
	mov.f64 	%fd616, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd616;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p25, %r4, 2146435072;
	setp.eq.s32 	%p26, %r160, 0;
	and.pred  	%p27, %p25, %p26;
	@%p27 bra 	$L__BB7_12;
	bra.uni 	$L__BB7_10;

$L__BB7_12:
	setp.gt.f64 	%p34, %fd5, 0d3FF0000000000000;
	selp.b32 	%r167, 2146435072, 0, %p34;
	mov.u32 	%r168, 0;
	xor.b32  	%r169, %r167, 2146435072;
	setp.lt.s32 	%p35, %r2, 0;
	selp.b32 	%r170, %r169, %r167, %p35;
	setp.eq.f64 	%p36, %fd2, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p36;
	mov.b64 	%fd1860, {%r168, %r171};
	bra.uni 	$L__BB7_14;

$L__BB7_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd2;
	}
	and.b32  	%r162, %r1, 2147483647;
	setp.ne.s32 	%p28, %r162, 2146435072;
	setp.ne.s32 	%p29, %r161, 0;
	or.pred  	%p30, %p28, %p29;
	@%p30 bra 	$L__BB7_14;

	setp.gt.s32 	%p31, %r2, -1;
	selp.b32 	%r163, 2146435072, 0, %p31;
	mov.u32 	%r164, 0;
	setp.ne.s32 	%p32, %r4, 1071644672;
	and.pred  	%p33, %p32, %p1;
	or.b32  	%r165, %r163, -2147483648;
	selp.b32 	%r166, %r165, %r163, %p33;
	mov.b64 	%fd1860, {%r164, %r166};

$L__BB7_14:
	abs.f64 	%fd15, %fd4;
	{ // callseq 115, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1863, [retval0+0];
	} // callseq 115
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd4;
	}
	setp.lt.s32 	%p37, %r5, 0;
	and.pred  	%p2, %p37, %p15;
	not.pred 	%p39, %p2;
	@%p39 bra 	$L__BB7_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd1863;
	}
	xor.b32  	%r173, %r172, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r174, %temp}, %fd1863;
	}
	mov.b64 	%fd1863, {%r174, %r173};

$L__BB7_16:
	setp.eq.f64 	%p40, %fd4, 0d0000000000000000;
	@%p40 bra 	$L__BB7_20;
	bra.uni 	$L__BB7_17;

$L__BB7_20:
	selp.b32 	%r175, %r5, 0, %p15;
	mov.u32 	%r176, 0;
	or.b32  	%r177, %r175, 2146435072;
	setp.lt.s32 	%p44, %r2, 0;
	selp.b32 	%r178, %r177, %r175, %p44;
	mov.b64 	%fd1863, {%r176, %r178};
	bra.uni 	$L__BB7_21;

$L__BB7_17:
	setp.gt.s32 	%p41, %r5, -1;
	@%p41 bra 	$L__BB7_21;

	mov.f64 	%fd618, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd619, %fd618;
	setp.eq.f64 	%p42, %fd619, 0d4000000000000000;
	@%p42 bra 	$L__BB7_21;

	mov.f64 	%fd1863, 0dFFF8000000000000;

$L__BB7_21:
	add.rn.f64 	%fd621, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd621;
	}
	and.b32  	%r180, %r179, 2146435072;
	setp.ne.s32 	%p45, %r180, 2146435072;
	@%p45 bra 	$L__BB7_28;

	setp.gtu.f64 	%p46, %fd15, 0d7FF0000000000000;
	@%p46 bra 	$L__BB7_27;
	bra.uni 	$L__BB7_23;

$L__BB7_27:
	mov.f64 	%fd623, 0d4000000000000000;
	add.rn.f64 	%fd1863, %fd4, %fd623;
	bra.uni 	$L__BB7_28;

$L__BB7_23:
	mov.f64 	%fd622, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %fd622;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p47, %r6, 2146435072;
	setp.eq.s32 	%p48, %r181, 0;
	and.pred  	%p49, %p47, %p48;
	@%p49 bra 	$L__BB7_26;
	bra.uni 	$L__BB7_24;

$L__BB7_26:
	setp.gt.f64 	%p56, %fd15, 0d3FF0000000000000;
	selp.b32 	%r188, 2146435072, 0, %p56;
	mov.u32 	%r189, 0;
	xor.b32  	%r190, %r188, 2146435072;
	setp.lt.s32 	%p57, %r2, 0;
	selp.b32 	%r191, %r190, %r188, %p57;
	setp.eq.f64 	%p58, %fd4, 0dBFF0000000000000;
	selp.b32 	%r192, 1072693248, %r191, %p58;
	mov.b64 	%fd1863, {%r189, %r192};
	bra.uni 	$L__BB7_28;

$L__BB7_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd4;
	}
	and.b32  	%r183, %r5, 2147483647;
	setp.ne.s32 	%p50, %r183, 2146435072;
	setp.ne.s32 	%p51, %r182, 0;
	or.pred  	%p52, %p50, %p51;
	@%p52 bra 	$L__BB7_28;

	setp.gt.s32 	%p53, %r2, -1;
	selp.b32 	%r184, 2146435072, 0, %p53;
	mov.u32 	%r185, 0;
	setp.ne.s32 	%p54, %r6, 1071644672;
	and.pred  	%p55, %p54, %p2;
	or.b32  	%r186, %r184, -2147483648;
	selp.b32 	%r187, %r186, %r184, %p55;
	mov.b64 	%fd1863, {%r185, %r187};

$L__BB7_28:
	setp.eq.f64 	%p59, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd624, 0d3FF0000000000000, %fd1863, %p59;
	setp.eq.f64 	%p60, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd625, 0d3FF0000000000000, %fd1860, %p60;
	add.rn.f64 	%fd25, %fd625, %fd624;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd26;
	}
	and.b32  	%r195, %r194, 2147483647;
	setp.eq.s32 	%p61, %r195, 2146435072;
	setp.eq.s32 	%p62, %r193, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB7_31;
	bra.uni 	$L__BB7_29;

$L__BB7_31:
	mov.f64 	%fd635, 0d0000000000000000;
	mul.rn.f64 	%fd1864, %fd26, %fd635;
	mov.u32 	%r676, 0;
	bra.uni 	$L__BB7_32;

$L__BB7_29:
	mul.rn.f64 	%fd626, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r676, %fd626;
	st.local.u32 	[%rd1], %r676;
	cvt.rn.f64.s32 	%fd627, %r676;
	neg.f64 	%fd628, %fd627;
	mov.f64 	%fd629, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd630, %fd628, %fd629, %fd26;
	mov.f64 	%fd631, 0d3C91A62633145C00;
	fma.rn.f64 	%fd632, %fd628, %fd631, %fd630;
	mov.f64 	%fd633, 0d397B839A252049C0;
	fma.rn.f64 	%fd1864, %fd628, %fd633, %fd632;
	abs.f64 	%fd634, %fd26;
	setp.ltu.f64 	%p64, %fd634, 0d41E0000000000000;
	@%p64 bra 	$L__BB7_32;

	{ // callseq 116, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1864, [retval0+0];
	} // callseq 116
	ld.local.u32 	%r676, [%rd1];

$L__BB7_32:
	and.b32  	%r197, %r676, 1;
	shl.b32 	%r198, %r676, 3;
	and.b32  	%r199, %r198, 8;
	setp.eq.s32 	%p65, %r197, 0;
	selp.f64 	%fd636, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd81, %r199, 8;
	mov.u64 	%rd82, __cudart_sin_cos_coeffs;
	add.s64 	%rd83, %rd82, %rd81;
	ld.global.nc.f64 	%fd637, [%rd83+8];
	mul.rn.f64 	%fd31, %fd1864, %fd1864;
	fma.rn.f64 	%fd638, %fd636, %fd31, %fd637;
	ld.global.nc.f64 	%fd639, [%rd83+16];
	fma.rn.f64 	%fd640, %fd638, %fd31, %fd639;
	ld.global.nc.f64 	%fd641, [%rd83+24];
	fma.rn.f64 	%fd642, %fd640, %fd31, %fd641;
	ld.global.nc.f64 	%fd643, [%rd83+32];
	fma.rn.f64 	%fd644, %fd642, %fd31, %fd643;
	ld.global.nc.f64 	%fd645, [%rd83+40];
	fma.rn.f64 	%fd646, %fd644, %fd31, %fd645;
	ld.global.nc.f64 	%fd647, [%rd83+48];
	fma.rn.f64 	%fd32, %fd646, %fd31, %fd647;
	fma.rn.f64 	%fd1866, %fd32, %fd1864, %fd1864;
	@%p65 bra 	$L__BB7_34;

	mov.f64 	%fd648, 0d3FF0000000000000;
	fma.rn.f64 	%fd1866, %fd32, %fd31, %fd648;

$L__BB7_34:
	and.b32  	%r200, %r676, 2;
	setp.eq.s32 	%p66, %r200, 0;
	@%p66 bra 	$L__BB7_36;

	mov.f64 	%fd649, 0d0000000000000000;
	mov.f64 	%fd650, 0dBFF0000000000000;
	fma.rn.f64 	%fd1866, %fd1866, %fd650, %fd649;

$L__BB7_36:
	mul.rn.f64 	%fd651, %fd1866, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd652, %fd25;
	add.rn.f64 	%fd38, %fd652, %fd651;
	setp.eq.f64 	%p67, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p68, %fd5, 0d0000000000000000;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB7_40;
	bra.uni 	$L__BB7_37;

$L__BB7_40:
	selp.f64 	%fd705, 0d400921FB54442D18, 0d0000000000000000, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r209, %temp}, %fd705;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd705;
	}
	and.b32  	%r211, %r5, -2147483648;
	or.b32  	%r212, %r210, %r211;
	mov.b64 	%fd1867, {%r209, %r212};
	bra.uni 	$L__BB7_41;

$L__BB7_37:
	setp.eq.f64 	%p70, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p71, %fd15, 0d7FF0000000000000;
	and.pred  	%p72, %p70, %p71;
	@%p72 bra 	$L__BB7_39;
	bra.uni 	$L__BB7_38;

$L__BB7_39:
	selp.f64 	%fd704, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r205, %temp}, %fd704;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd704;
	}
	and.b32  	%r207, %r5, -2147483648;
	or.b32  	%r208, %r206, %r207;
	mov.b64 	%fd1867, {%r205, %r208};
	bra.uni 	$L__BB7_41;

$L__BB7_38:
	min.f64 	%fd653, %fd15, %fd5;
	max.f64 	%fd654, %fd15, %fd5;
	div.rn.f64 	%fd655, %fd653, %fd654;
	mul.rn.f64 	%fd656, %fd655, %fd655;
	mov.f64 	%fd657, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd658, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd659, %fd658, %fd656, %fd657;
	mov.f64 	%fd660, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd661, %fd659, %fd656, %fd660;
	mov.f64 	%fd662, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd663, %fd661, %fd656, %fd662;
	mov.f64 	%fd664, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd665, %fd663, %fd656, %fd664;
	mov.f64 	%fd666, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd667, %fd665, %fd656, %fd666;
	mov.f64 	%fd668, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd669, %fd667, %fd656, %fd668;
	mov.f64 	%fd670, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd671, %fd669, %fd656, %fd670;
	mov.f64 	%fd672, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd673, %fd671, %fd656, %fd672;
	mov.f64 	%fd674, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd675, %fd673, %fd656, %fd674;
	mov.f64 	%fd676, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd677, %fd675, %fd656, %fd676;
	mov.f64 	%fd678, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd679, %fd677, %fd656, %fd678;
	mov.f64 	%fd680, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd681, %fd679, %fd656, %fd680;
	mov.f64 	%fd682, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd683, %fd681, %fd656, %fd682;
	mov.f64 	%fd684, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd685, %fd683, %fd656, %fd684;
	mov.f64 	%fd686, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd687, %fd685, %fd656, %fd686;
	mov.f64 	%fd688, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd689, %fd687, %fd656, %fd688;
	mov.f64 	%fd690, 0d3FC99999999840D2;
	fma.rn.f64 	%fd691, %fd689, %fd656, %fd690;
	mov.f64 	%fd692, 0dBFD555555555544C;
	fma.rn.f64 	%fd693, %fd691, %fd656, %fd692;
	mul.rn.f64 	%fd694, %fd656, %fd693;
	fma.rn.f64 	%fd695, %fd694, %fd655, %fd655;
	mov.f64 	%fd696, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd697, %fd696, %fd695;
	setp.gt.f64 	%p74, %fd15, %fd5;
	selp.f64 	%fd698, %fd697, %fd695, %p74;
	mov.f64 	%fd699, 0d400921FB54442D18;
	sub.rn.f64 	%fd700, %fd699, %fd698;
	selp.f64 	%fd701, %fd700, %fd698, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r201, %temp}, %fd701;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd701;
	}
	and.b32  	%r203, %r5, -2147483648;
	or.b32  	%r204, %r202, %r203;
	mov.b64 	%fd702, {%r201, %r204};
	add.rn.f64 	%fd703, %fd5, %fd15;
	setp.le.f64 	%p75, %fd703, 0d7FF0000000000000;
	selp.f64 	%fd1867, %fd702, %fd703, %p75;

$L__BB7_41:
	add.rn.f64 	%fd1857, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd1857, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd43;
	}
	and.b32  	%r215, %r214, 2147483647;
	setp.eq.s32 	%p78, %r215, 2146435072;
	setp.eq.s32 	%p79, %r213, 0;
	and.pred  	%p80, %p79, %p78;
	@%p80 bra 	$L__BB7_45;
	bra.uni 	$L__BB7_42;

$L__BB7_45:
	mov.f64 	%fd715, 0d0000000000000000;
	mul.rn.f64 	%fd1869, %fd43, %fd715;
	mov.u32 	%r678, 1;
	bra.uni 	$L__BB7_46;

$L__BB7_42:
	mul.rn.f64 	%fd706, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r677, %fd706;
	st.local.u32 	[%rd1], %r677;
	cvt.rn.f64.s32 	%fd707, %r677;
	neg.f64 	%fd708, %fd707;
	mov.f64 	%fd709, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd710, %fd708, %fd709, %fd43;
	mov.f64 	%fd711, 0d3C91A62633145C00;
	fma.rn.f64 	%fd712, %fd708, %fd711, %fd710;
	mov.f64 	%fd713, 0d397B839A252049C0;
	fma.rn.f64 	%fd1869, %fd708, %fd713, %fd712;
	abs.f64 	%fd714, %fd43;
	setp.ltu.f64 	%p81, %fd714, 0d41E0000000000000;
	@%p81 bra 	$L__BB7_44;

	{ // callseq 117, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1869, [retval0+0];
	} // callseq 117
	ld.local.u32 	%r677, [%rd1];

$L__BB7_44:
	add.s32 	%r678, %r677, 1;

$L__BB7_46:
	and.b32  	%r217, %r678, 1;
	shl.b32 	%r218, %r678, 3;
	and.b32  	%r219, %r218, 8;
	setp.eq.s32 	%p82, %r217, 0;
	selp.f64 	%fd716, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p82;
	mul.wide.s32 	%rd85, %r219, 8;
	add.s64 	%rd87, %rd82, %rd85;
	ld.global.nc.f64 	%fd717, [%rd87+8];
	mul.rn.f64 	%fd49, %fd1869, %fd1869;
	fma.rn.f64 	%fd718, %fd716, %fd49, %fd717;
	ld.global.nc.f64 	%fd719, [%rd87+16];
	fma.rn.f64 	%fd720, %fd718, %fd49, %fd719;
	ld.global.nc.f64 	%fd721, [%rd87+24];
	fma.rn.f64 	%fd722, %fd720, %fd49, %fd721;
	ld.global.nc.f64 	%fd723, [%rd87+32];
	fma.rn.f64 	%fd724, %fd722, %fd49, %fd723;
	ld.global.nc.f64 	%fd725, [%rd87+40];
	fma.rn.f64 	%fd726, %fd724, %fd49, %fd725;
	ld.global.nc.f64 	%fd727, [%rd87+48];
	fma.rn.f64 	%fd50, %fd726, %fd49, %fd727;
	fma.rn.f64 	%fd1871, %fd50, %fd1869, %fd1869;
	@%p82 bra 	$L__BB7_48;

	mov.f64 	%fd728, 0d3FF0000000000000;
	fma.rn.f64 	%fd1871, %fd50, %fd49, %fd728;

$L__BB7_48:
	and.b32  	%r220, %r678, 2;
	setp.eq.s32 	%p83, %r220, 0;
	@%p83 bra 	$L__BB7_50;

	mov.f64 	%fd729, 0d0000000000000000;
	mov.f64 	%fd730, 0dBFF0000000000000;
	fma.rn.f64 	%fd1871, %fd1871, %fd730, %fd729;

$L__BB7_50:
	mul.rn.f64 	%fd731, %fd1871, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd1867, %fd731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r221, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r222}, %fd56;
	}
	and.b32  	%r223, %r222, 2147483647;
	setp.eq.s32 	%p84, %r223, 2146435072;
	setp.eq.s32 	%p85, %r221, 0;
	and.pred  	%p3, %p85, %p84;
	@%p3 bra 	$L__BB7_54;
	bra.uni 	$L__BB7_51;

$L__BB7_54:
	mov.f64 	%fd741, 0d0000000000000000;
	mul.rn.f64 	%fd1873, %fd56, %fd741;
	mov.u32 	%r680, 1;
	bra.uni 	$L__BB7_55;

$L__BB7_51:
	mul.rn.f64 	%fd732, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r679, %fd732;
	st.local.u32 	[%rd1], %r679;
	cvt.rn.f64.s32 	%fd733, %r679;
	neg.f64 	%fd734, %fd733;
	mov.f64 	%fd735, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd736, %fd734, %fd735, %fd56;
	mov.f64 	%fd737, 0d3C91A62633145C00;
	fma.rn.f64 	%fd738, %fd734, %fd737, %fd736;
	mov.f64 	%fd739, 0d397B839A252049C0;
	fma.rn.f64 	%fd1873, %fd734, %fd739, %fd738;
	abs.f64 	%fd740, %fd56;
	setp.ltu.f64 	%p86, %fd740, 0d41E0000000000000;
	@%p86 bra 	$L__BB7_53;

	{ // callseq 118, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1873, [retval0+0];
	} // callseq 118
	ld.local.u32 	%r679, [%rd1];

$L__BB7_53:
	add.s32 	%r680, %r679, 1;

$L__BB7_55:
	and.b32  	%r225, %r680, 1;
	shl.b32 	%r226, %r680, 3;
	and.b32  	%r227, %r226, 8;
	setp.eq.s32 	%p87, %r225, 0;
	selp.f64 	%fd742, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p87;
	mul.wide.s32 	%rd89, %r227, 8;
	add.s64 	%rd91, %rd82, %rd89;
	ld.global.nc.f64 	%fd743, [%rd91+8];
	mul.rn.f64 	%fd62, %fd1873, %fd1873;
	fma.rn.f64 	%fd744, %fd742, %fd62, %fd743;
	ld.global.nc.f64 	%fd745, [%rd91+16];
	fma.rn.f64 	%fd746, %fd744, %fd62, %fd745;
	ld.global.nc.f64 	%fd747, [%rd91+24];
	fma.rn.f64 	%fd748, %fd746, %fd62, %fd747;
	ld.global.nc.f64 	%fd749, [%rd91+32];
	fma.rn.f64 	%fd750, %fd748, %fd62, %fd749;
	ld.global.nc.f64 	%fd751, [%rd91+40];
	fma.rn.f64 	%fd752, %fd750, %fd62, %fd751;
	ld.global.nc.f64 	%fd753, [%rd91+48];
	fma.rn.f64 	%fd63, %fd752, %fd62, %fd753;
	fma.rn.f64 	%fd1875, %fd63, %fd1873, %fd1873;
	@%p87 bra 	$L__BB7_57;

	mov.f64 	%fd754, 0d3FF0000000000000;
	fma.rn.f64 	%fd1875, %fd63, %fd62, %fd754;

$L__BB7_57:
	and.b32  	%r228, %r680, 2;
	setp.eq.s32 	%p88, %r228, 0;
	@%p88 bra 	$L__BB7_59;

	mov.f64 	%fd755, 0d0000000000000000;
	mov.f64 	%fd756, 0dBFF0000000000000;
	fma.rn.f64 	%fd1875, %fd1875, %fd756, %fd755;

$L__BB7_59:
	mul.rn.f64 	%fd69, %fd38, %fd1875;
	@%p3 bra 	$L__BB7_62;
	bra.uni 	$L__BB7_60;

$L__BB7_62:
	mov.f64 	%fd766, 0d0000000000000000;
	mul.rn.f64 	%fd1876, %fd56, %fd766;
	mov.u32 	%r681, 0;
	bra.uni 	$L__BB7_63;

$L__BB7_60:
	mul.rn.f64 	%fd757, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r681, %fd757;
	st.local.u32 	[%rd1], %r681;
	cvt.rn.f64.s32 	%fd758, %r681;
	neg.f64 	%fd759, %fd758;
	mov.f64 	%fd760, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd761, %fd759, %fd760, %fd56;
	mov.f64 	%fd762, 0d3C91A62633145C00;
	fma.rn.f64 	%fd763, %fd759, %fd762, %fd761;
	mov.f64 	%fd764, 0d397B839A252049C0;
	fma.rn.f64 	%fd1876, %fd759, %fd764, %fd763;
	abs.f64 	%fd765, %fd56;
	setp.ltu.f64 	%p89, %fd765, 0d41E0000000000000;
	@%p89 bra 	$L__BB7_63;

	{ // callseq 119, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1876, [retval0+0];
	} // callseq 119
	ld.local.u32 	%r681, [%rd1];

$L__BB7_63:
	and.b32  	%r230, %r681, 1;
	shl.b32 	%r231, %r681, 3;
	and.b32  	%r232, %r231, 8;
	setp.eq.s32 	%p90, %r230, 0;
	selp.f64 	%fd767, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p90;
	mul.wide.s32 	%rd93, %r232, 8;
	add.s64 	%rd95, %rd82, %rd93;
	ld.global.nc.f64 	%fd768, [%rd95+8];
	mul.rn.f64 	%fd74, %fd1876, %fd1876;
	fma.rn.f64 	%fd769, %fd767, %fd74, %fd768;
	ld.global.nc.f64 	%fd770, [%rd95+16];
	fma.rn.f64 	%fd771, %fd769, %fd74, %fd770;
	ld.global.nc.f64 	%fd772, [%rd95+24];
	fma.rn.f64 	%fd773, %fd771, %fd74, %fd772;
	ld.global.nc.f64 	%fd774, [%rd95+32];
	fma.rn.f64 	%fd775, %fd773, %fd74, %fd774;
	ld.global.nc.f64 	%fd776, [%rd95+40];
	fma.rn.f64 	%fd777, %fd775, %fd74, %fd776;
	ld.global.nc.f64 	%fd778, [%rd95+48];
	fma.rn.f64 	%fd75, %fd777, %fd74, %fd778;
	fma.rn.f64 	%fd1878, %fd75, %fd1876, %fd1876;
	@%p90 bra 	$L__BB7_65;

	mov.f64 	%fd779, 0d3FF0000000000000;
	fma.rn.f64 	%fd1878, %fd75, %fd74, %fd779;

$L__BB7_65:
	and.b32  	%r233, %r681, 2;
	setp.eq.s32 	%p91, %r233, 0;
	@%p91 bra 	$L__BB7_67;

	mov.f64 	%fd780, 0d0000000000000000;
	mov.f64 	%fd781, 0dBFF0000000000000;
	fma.rn.f64 	%fd1878, %fd1878, %fd781, %fd780;

$L__BB7_67:
	mul.rn.f64 	%fd81, %fd38, %fd1878;
	add.rn.f64 	%fd82, %fd81, 0dC041800000000000;
	add.rn.f64 	%fd83, %fd69, 0dC05A400000000000;
	abs.f64 	%fd84, %fd83;
	sqrt.rn.f64 	%fd85, %fd84;
	mul.rn.f64 	%fd86, %fd83, 0d400921FB54442D18;
	mul.rn.f64 	%fd87, %fd82, 0d400921FB54442D18;
	mul.rn.f64 	%fd88, %fd86, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r235}, %fd88;
	}
	and.b32  	%r236, %r235, 2147483647;
	setp.eq.s32 	%p92, %r236, 2146435072;
	setp.eq.s32 	%p93, %r234, 0;
	and.pred  	%p94, %p93, %p92;
	@%p94 bra 	$L__BB7_70;
	bra.uni 	$L__BB7_68;

$L__BB7_70:
	mov.f64 	%fd791, 0d0000000000000000;
	mul.rn.f64 	%fd1879, %fd88, %fd791;
	mov.u32 	%r682, 0;
	bra.uni 	$L__BB7_71;

$L__BB7_68:
	mul.rn.f64 	%fd782, %fd88, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r682, %fd782;
	st.local.u32 	[%rd1], %r682;
	cvt.rn.f64.s32 	%fd783, %r682;
	neg.f64 	%fd784, %fd783;
	mov.f64 	%fd785, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd786, %fd784, %fd785, %fd88;
	mov.f64 	%fd787, 0d3C91A62633145C00;
	fma.rn.f64 	%fd788, %fd784, %fd787, %fd786;
	mov.f64 	%fd789, 0d397B839A252049C0;
	fma.rn.f64 	%fd1879, %fd784, %fd789, %fd788;
	abs.f64 	%fd790, %fd88;
	setp.ltu.f64 	%p95, %fd790, 0d41E0000000000000;
	@%p95 bra 	$L__BB7_71;

	{ // callseq 120, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd88;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1879, [retval0+0];
	} // callseq 120
	ld.local.u32 	%r682, [%rd1];

$L__BB7_71:
	and.b32  	%r238, %r682, 1;
	shl.b32 	%r239, %r682, 3;
	and.b32  	%r240, %r239, 8;
	setp.eq.s32 	%p96, %r238, 0;
	selp.f64 	%fd792, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p96;
	mul.wide.s32 	%rd97, %r240, 8;
	add.s64 	%rd99, %rd82, %rd97;
	ld.global.nc.f64 	%fd793, [%rd99+8];
	mul.rn.f64 	%fd93, %fd1879, %fd1879;
	fma.rn.f64 	%fd794, %fd792, %fd93, %fd793;
	ld.global.nc.f64 	%fd795, [%rd99+16];
	fma.rn.f64 	%fd796, %fd794, %fd93, %fd795;
	ld.global.nc.f64 	%fd797, [%rd99+24];
	fma.rn.f64 	%fd798, %fd796, %fd93, %fd797;
	ld.global.nc.f64 	%fd799, [%rd99+32];
	fma.rn.f64 	%fd800, %fd798, %fd93, %fd799;
	ld.global.nc.f64 	%fd801, [%rd99+40];
	fma.rn.f64 	%fd802, %fd800, %fd93, %fd801;
	ld.global.nc.f64 	%fd803, [%rd99+48];
	fma.rn.f64 	%fd94, %fd802, %fd93, %fd803;
	fma.rn.f64 	%fd1881, %fd94, %fd1879, %fd1879;
	@%p96 bra 	$L__BB7_73;

	mov.f64 	%fd804, 0d3FF0000000000000;
	fma.rn.f64 	%fd1881, %fd94, %fd93, %fd804;

$L__BB7_73:
	and.b32  	%r241, %r682, 2;
	setp.eq.s32 	%p97, %r241, 0;
	@%p97 bra 	$L__BB7_75;

	mov.f64 	%fd805, 0d0000000000000000;
	mov.f64 	%fd806, 0dBFF0000000000000;
	fma.rn.f64 	%fd1881, %fd1881, %fd806, %fd805;

$L__BB7_75:
	add.rn.f64 	%fd100, %fd86, %fd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd100;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r243}, %fd100;
	}
	and.b32  	%r244, %r243, 2147483647;
	setp.eq.s32 	%p98, %r244, 2146435072;
	setp.eq.s32 	%p99, %r242, 0;
	and.pred  	%p100, %p99, %p98;
	@%p100 bra 	$L__BB7_78;
	bra.uni 	$L__BB7_76;

$L__BB7_78:
	mov.f64 	%fd816, 0d0000000000000000;
	mul.rn.f64 	%fd1882, %fd100, %fd816;
	mov.u32 	%r683, 0;
	bra.uni 	$L__BB7_79;

$L__BB7_76:
	mul.rn.f64 	%fd807, %fd100, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r683, %fd807;
	st.local.u32 	[%rd1], %r683;
	cvt.rn.f64.s32 	%fd808, %r683;
	neg.f64 	%fd809, %fd808;
	mov.f64 	%fd810, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd811, %fd809, %fd810, %fd100;
	mov.f64 	%fd812, 0d3C91A62633145C00;
	fma.rn.f64 	%fd813, %fd809, %fd812, %fd811;
	mov.f64 	%fd814, 0d397B839A252049C0;
	fma.rn.f64 	%fd1882, %fd809, %fd814, %fd813;
	abs.f64 	%fd815, %fd100;
	setp.ltu.f64 	%p101, %fd815, 0d41E0000000000000;
	@%p101 bra 	$L__BB7_79;

	{ // callseq 121, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1882, [retval0+0];
	} // callseq 121
	ld.local.u32 	%r683, [%rd1];

$L__BB7_79:
	and.b32  	%r246, %r683, 1;
	shl.b32 	%r247, %r683, 3;
	and.b32  	%r248, %r247, 8;
	setp.eq.s32 	%p102, %r246, 0;
	selp.f64 	%fd817, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p102;
	mul.wide.s32 	%rd101, %r248, 8;
	add.s64 	%rd103, %rd82, %rd101;
	ld.global.nc.f64 	%fd818, [%rd103+8];
	mul.rn.f64 	%fd105, %fd1882, %fd1882;
	fma.rn.f64 	%fd819, %fd817, %fd105, %fd818;
	ld.global.nc.f64 	%fd820, [%rd103+16];
	fma.rn.f64 	%fd821, %fd819, %fd105, %fd820;
	ld.global.nc.f64 	%fd822, [%rd103+24];
	fma.rn.f64 	%fd823, %fd821, %fd105, %fd822;
	ld.global.nc.f64 	%fd824, [%rd103+32];
	fma.rn.f64 	%fd825, %fd823, %fd105, %fd824;
	ld.global.nc.f64 	%fd826, [%rd103+40];
	fma.rn.f64 	%fd827, %fd825, %fd105, %fd826;
	ld.global.nc.f64 	%fd828, [%rd103+48];
	fma.rn.f64 	%fd106, %fd827, %fd105, %fd828;
	fma.rn.f64 	%fd1884, %fd106, %fd1882, %fd1882;
	@%p102 bra 	$L__BB7_81;

	mov.f64 	%fd829, 0d3FF0000000000000;
	fma.rn.f64 	%fd1884, %fd106, %fd105, %fd829;

$L__BB7_81:
	and.b32  	%r249, %r683, 2;
	setp.eq.s32 	%p103, %r249, 0;
	@%p103 bra 	$L__BB7_83;

	mov.f64 	%fd830, 0d0000000000000000;
	mov.f64 	%fd831, 0dBFF0000000000000;
	fma.rn.f64 	%fd1884, %fd1884, %fd831, %fd830;

$L__BB7_83:
	mul.rn.f64 	%fd832, %fd1884, 0d4034000000000000;
	mul.rn.f64 	%fd833, %fd1881, 0d4034000000000000;
	add.rn.f64 	%fd112, %fd833, %fd832;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd87;
	}
	and.b32  	%r251, %r250, 2147483647;
	setp.eq.s32 	%p104, %r251, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r252, %temp}, %fd87;
	}
	setp.eq.s32 	%p105, %r252, 0;
	and.pred  	%p106, %p105, %p104;
	@%p106 bra 	$L__BB7_86;
	bra.uni 	$L__BB7_84;

$L__BB7_86:
	mov.f64 	%fd843, 0d0000000000000000;
	mul.rn.f64 	%fd1885, %fd87, %fd843;
	mov.u32 	%r684, 0;
	bra.uni 	$L__BB7_87;

$L__BB7_84:
	mul.rn.f64 	%fd834, %fd87, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r684, %fd834;
	st.local.u32 	[%rd1], %r684;
	cvt.rn.f64.s32 	%fd835, %r684;
	neg.f64 	%fd836, %fd835;
	mov.f64 	%fd837, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd838, %fd836, %fd837, %fd87;
	mov.f64 	%fd839, 0d3C91A62633145C00;
	fma.rn.f64 	%fd840, %fd836, %fd839, %fd838;
	mov.f64 	%fd841, 0d397B839A252049C0;
	fma.rn.f64 	%fd1885, %fd836, %fd841, %fd840;
	abs.f64 	%fd842, %fd87;
	setp.ltu.f64 	%p107, %fd842, 0d41E0000000000000;
	@%p107 bra 	$L__BB7_87;

	{ // callseq 122, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1885, [retval0+0];
	} // callseq 122
	ld.local.u32 	%r684, [%rd1];

$L__BB7_87:
	and.b32  	%r254, %r684, 1;
	shl.b32 	%r255, %r684, 3;
	and.b32  	%r256, %r255, 8;
	setp.eq.s32 	%p108, %r254, 0;
	selp.f64 	%fd844, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p108;
	mul.wide.s32 	%rd105, %r256, 8;
	add.s64 	%rd107, %rd82, %rd105;
	ld.global.nc.f64 	%fd845, [%rd107+8];
	mul.rn.f64 	%fd117, %fd1885, %fd1885;
	fma.rn.f64 	%fd846, %fd844, %fd117, %fd845;
	ld.global.nc.f64 	%fd847, [%rd107+16];
	fma.rn.f64 	%fd848, %fd846, %fd117, %fd847;
	ld.global.nc.f64 	%fd849, [%rd107+24];
	fma.rn.f64 	%fd850, %fd848, %fd117, %fd849;
	ld.global.nc.f64 	%fd851, [%rd107+32];
	fma.rn.f64 	%fd852, %fd850, %fd117, %fd851;
	ld.global.nc.f64 	%fd853, [%rd107+40];
	fma.rn.f64 	%fd854, %fd852, %fd117, %fd853;
	ld.global.nc.f64 	%fd855, [%rd107+48];
	fma.rn.f64 	%fd118, %fd854, %fd117, %fd855;
	fma.rn.f64 	%fd1887, %fd118, %fd1885, %fd1885;
	@%p108 bra 	$L__BB7_89;

	mov.f64 	%fd856, 0d3FF0000000000000;
	fma.rn.f64 	%fd1887, %fd118, %fd117, %fd856;

$L__BB7_89:
	and.b32  	%r257, %r684, 2;
	setp.eq.s32 	%p109, %r257, 0;
	@%p109 bra 	$L__BB7_91;

	mov.f64 	%fd857, 0d0000000000000000;
	mov.f64 	%fd858, 0dBFF0000000000000;
	fma.rn.f64 	%fd1887, %fd1887, %fd858, %fd857;

$L__BB7_91:
	div.rn.f64 	%fd124, %fd87, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r258, %temp}, %fd124;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd124;
	}
	and.b32  	%r260, %r259, 2147483647;
	setp.eq.s32 	%p110, %r260, 2146435072;
	setp.eq.s32 	%p111, %r258, 0;
	and.pred  	%p112, %p111, %p110;
	@%p112 bra 	$L__BB7_94;
	bra.uni 	$L__BB7_92;

$L__BB7_94:
	mov.f64 	%fd868, 0d0000000000000000;
	mul.rn.f64 	%fd1888, %fd124, %fd868;
	mov.u32 	%r685, 0;
	bra.uni 	$L__BB7_95;

$L__BB7_92:
	mul.rn.f64 	%fd859, %fd124, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r685, %fd859;
	st.local.u32 	[%rd1], %r685;
	cvt.rn.f64.s32 	%fd860, %r685;
	neg.f64 	%fd861, %fd860;
	mov.f64 	%fd862, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd863, %fd861, %fd862, %fd124;
	mov.f64 	%fd864, 0d3C91A62633145C00;
	fma.rn.f64 	%fd865, %fd861, %fd864, %fd863;
	mov.f64 	%fd866, 0d397B839A252049C0;
	fma.rn.f64 	%fd1888, %fd861, %fd866, %fd865;
	abs.f64 	%fd867, %fd124;
	setp.ltu.f64 	%p113, %fd867, 0d41E0000000000000;
	@%p113 bra 	$L__BB7_95;

	{ // callseq 123, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd124;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1888, [retval0+0];
	} // callseq 123
	ld.local.u32 	%r685, [%rd1];

$L__BB7_95:
	and.b32  	%r262, %r685, 1;
	shl.b32 	%r263, %r685, 3;
	and.b32  	%r264, %r263, 8;
	setp.eq.s32 	%p114, %r262, 0;
	selp.f64 	%fd869, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p114;
	mul.wide.s32 	%rd109, %r264, 8;
	add.s64 	%rd111, %rd82, %rd109;
	ld.global.nc.f64 	%fd870, [%rd111+8];
	mul.rn.f64 	%fd129, %fd1888, %fd1888;
	fma.rn.f64 	%fd871, %fd869, %fd129, %fd870;
	ld.global.nc.f64 	%fd872, [%rd111+16];
	fma.rn.f64 	%fd873, %fd871, %fd129, %fd872;
	ld.global.nc.f64 	%fd874, [%rd111+24];
	fma.rn.f64 	%fd875, %fd873, %fd129, %fd874;
	ld.global.nc.f64 	%fd876, [%rd111+32];
	fma.rn.f64 	%fd877, %fd875, %fd129, %fd876;
	ld.global.nc.f64 	%fd878, [%rd111+40];
	fma.rn.f64 	%fd879, %fd877, %fd129, %fd878;
	ld.global.nc.f64 	%fd880, [%rd111+48];
	fma.rn.f64 	%fd130, %fd879, %fd129, %fd880;
	fma.rn.f64 	%fd1890, %fd130, %fd1888, %fd1888;
	@%p114 bra 	$L__BB7_97;

	mov.f64 	%fd881, 0d3FF0000000000000;
	fma.rn.f64 	%fd1890, %fd130, %fd129, %fd881;

$L__BB7_97:
	and.b32  	%r265, %r685, 2;
	setp.eq.s32 	%p115, %r265, 0;
	@%p115 bra 	$L__BB7_99;

	mov.f64 	%fd882, 0d0000000000000000;
	mov.f64 	%fd883, 0dBFF0000000000000;
	fma.rn.f64 	%fd1890, %fd1890, %fd883, %fd882;

$L__BB7_99:
	mul.rn.f64 	%fd884, %fd1890, 0d4044000000000000;
	mul.rn.f64 	%fd885, %fd1887, 0d4034000000000000;
	add.rn.f64 	%fd136, %fd885, %fd884;
	div.rn.f64 	%fd137, %fd87, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r266, %temp}, %fd137;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd137;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p116, %r268, 2146435072;
	setp.eq.s32 	%p117, %r266, 0;
	and.pred  	%p118, %p117, %p116;
	@%p118 bra 	$L__BB7_102;
	bra.uni 	$L__BB7_100;

$L__BB7_102:
	mov.f64 	%fd895, 0d0000000000000000;
	mul.rn.f64 	%fd1891, %fd137, %fd895;
	mov.u32 	%r686, 0;
	bra.uni 	$L__BB7_103;

$L__BB7_100:
	mul.rn.f64 	%fd886, %fd137, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r686, %fd886;
	st.local.u32 	[%rd1], %r686;
	cvt.rn.f64.s32 	%fd887, %r686;
	neg.f64 	%fd888, %fd887;
	mov.f64 	%fd889, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd890, %fd888, %fd889, %fd137;
	mov.f64 	%fd891, 0d3C91A62633145C00;
	fma.rn.f64 	%fd892, %fd888, %fd891, %fd890;
	mov.f64 	%fd893, 0d397B839A252049C0;
	fma.rn.f64 	%fd1891, %fd888, %fd893, %fd892;
	abs.f64 	%fd894, %fd137;
	setp.ltu.f64 	%p119, %fd894, 0d41E0000000000000;
	@%p119 bra 	$L__BB7_103;

	{ // callseq 124, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd137;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1891, [retval0+0];
	} // callseq 124
	ld.local.u32 	%r686, [%rd1];

$L__BB7_103:
	and.b32  	%r270, %r686, 1;
	shl.b32 	%r271, %r686, 3;
	and.b32  	%r272, %r271, 8;
	setp.eq.s32 	%p120, %r270, 0;
	selp.f64 	%fd896, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p120;
	mul.wide.s32 	%rd113, %r272, 8;
	add.s64 	%rd115, %rd82, %rd113;
	ld.global.nc.f64 	%fd897, [%rd115+8];
	mul.rn.f64 	%fd142, %fd1891, %fd1891;
	fma.rn.f64 	%fd898, %fd896, %fd142, %fd897;
	ld.global.nc.f64 	%fd899, [%rd115+16];
	fma.rn.f64 	%fd900, %fd898, %fd142, %fd899;
	ld.global.nc.f64 	%fd901, [%rd115+24];
	fma.rn.f64 	%fd902, %fd900, %fd142, %fd901;
	ld.global.nc.f64 	%fd903, [%rd115+32];
	fma.rn.f64 	%fd904, %fd902, %fd142, %fd903;
	ld.global.nc.f64 	%fd905, [%rd115+40];
	fma.rn.f64 	%fd906, %fd904, %fd142, %fd905;
	ld.global.nc.f64 	%fd907, [%rd115+48];
	fma.rn.f64 	%fd143, %fd906, %fd142, %fd907;
	fma.rn.f64 	%fd1893, %fd143, %fd1891, %fd1891;
	@%p120 bra 	$L__BB7_105;

	mov.f64 	%fd908, 0d3FF0000000000000;
	fma.rn.f64 	%fd1893, %fd143, %fd142, %fd908;

$L__BB7_105:
	and.b32  	%r273, %r686, 2;
	setp.eq.s32 	%p121, %r273, 0;
	@%p121 bra 	$L__BB7_107;

	mov.f64 	%fd909, 0d0000000000000000;
	mov.f64 	%fd910, 0dBFF0000000000000;
	fma.rn.f64 	%fd1893, %fd1893, %fd910, %fd909;

$L__BB7_107:
	mul.rn.f64 	%fd911, %fd1893, 0d4064000000000000;
	add.rn.f64 	%fd149, %fd136, %fd911;
	div.rn.f64 	%fd150, %fd87, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd150;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd150;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p122, %r276, 2146435072;
	setp.eq.s32 	%p123, %r274, 0;
	and.pred  	%p124, %p123, %p122;
	@%p124 bra 	$L__BB7_110;
	bra.uni 	$L__BB7_108;

$L__BB7_110:
	mov.f64 	%fd921, 0d0000000000000000;
	mul.rn.f64 	%fd1894, %fd150, %fd921;
	mov.u32 	%r687, 0;
	bra.uni 	$L__BB7_111;

$L__BB7_108:
	mul.rn.f64 	%fd912, %fd150, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r687, %fd912;
	st.local.u32 	[%rd1], %r687;
	cvt.rn.f64.s32 	%fd913, %r687;
	neg.f64 	%fd914, %fd913;
	mov.f64 	%fd915, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd916, %fd914, %fd915, %fd150;
	mov.f64 	%fd917, 0d3C91A62633145C00;
	fma.rn.f64 	%fd918, %fd914, %fd917, %fd916;
	mov.f64 	%fd919, 0d397B839A252049C0;
	fma.rn.f64 	%fd1894, %fd914, %fd919, %fd918;
	abs.f64 	%fd920, %fd150;
	setp.ltu.f64 	%p125, %fd920, 0d41E0000000000000;
	@%p125 bra 	$L__BB7_111;

	{ // callseq 125, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd150;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1894, [retval0+0];
	} // callseq 125
	ld.local.u32 	%r687, [%rd1];

$L__BB7_111:
	and.b32  	%r278, %r687, 1;
	shl.b32 	%r279, %r687, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p126, %r278, 0;
	selp.f64 	%fd922, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p126;
	mul.wide.s32 	%rd117, %r280, 8;
	add.s64 	%rd119, %rd82, %rd117;
	ld.global.nc.f64 	%fd923, [%rd119+8];
	mul.rn.f64 	%fd155, %fd1894, %fd1894;
	fma.rn.f64 	%fd924, %fd922, %fd155, %fd923;
	ld.global.nc.f64 	%fd925, [%rd119+16];
	fma.rn.f64 	%fd926, %fd924, %fd155, %fd925;
	ld.global.nc.f64 	%fd927, [%rd119+24];
	fma.rn.f64 	%fd928, %fd926, %fd155, %fd927;
	ld.global.nc.f64 	%fd929, [%rd119+32];
	fma.rn.f64 	%fd930, %fd928, %fd155, %fd929;
	ld.global.nc.f64 	%fd931, [%rd119+40];
	fma.rn.f64 	%fd932, %fd930, %fd155, %fd931;
	ld.global.nc.f64 	%fd933, [%rd119+48];
	fma.rn.f64 	%fd156, %fd932, %fd155, %fd933;
	fma.rn.f64 	%fd1896, %fd156, %fd1894, %fd1894;
	@%p126 bra 	$L__BB7_113;

	mov.f64 	%fd934, 0d3FF0000000000000;
	fma.rn.f64 	%fd1896, %fd156, %fd155, %fd934;

$L__BB7_113:
	and.b32  	%r281, %r687, 2;
	setp.eq.s32 	%p127, %r281, 0;
	@%p127 bra 	$L__BB7_115;

	mov.f64 	%fd935, 0d0000000000000000;
	mov.f64 	%fd936, 0dBFF0000000000000;
	fma.rn.f64 	%fd1896, %fd1896, %fd936, %fd935;

$L__BB7_115:
	mul.rn.f64 	%fd937, %fd1896, 0d4074000000000000;
	add.rn.f64 	%fd162, %fd149, %fd937;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r282}, %fd86;
	}
	and.b32  	%r283, %r282, 2147483647;
	setp.eq.s32 	%p128, %r283, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %fd86;
	}
	setp.eq.s32 	%p129, %r284, 0;
	and.pred  	%p130, %p129, %p128;
	@%p130 bra 	$L__BB7_118;
	bra.uni 	$L__BB7_116;

$L__BB7_118:
	mov.f64 	%fd947, 0d0000000000000000;
	mul.rn.f64 	%fd1897, %fd86, %fd947;
	mov.u32 	%r688, 0;
	bra.uni 	$L__BB7_119;

$L__BB7_116:
	mul.rn.f64 	%fd938, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r688, %fd938;
	st.local.u32 	[%rd1], %r688;
	cvt.rn.f64.s32 	%fd939, %r688;
	neg.f64 	%fd940, %fd939;
	mov.f64 	%fd941, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd942, %fd940, %fd941, %fd86;
	mov.f64 	%fd943, 0d3C91A62633145C00;
	fma.rn.f64 	%fd944, %fd940, %fd943, %fd942;
	mov.f64 	%fd945, 0d397B839A252049C0;
	fma.rn.f64 	%fd1897, %fd940, %fd945, %fd944;
	abs.f64 	%fd946, %fd86;
	setp.ltu.f64 	%p131, %fd946, 0d41E0000000000000;
	@%p131 bra 	$L__BB7_119;

	{ // callseq 126, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1897, [retval0+0];
	} // callseq 126
	ld.local.u32 	%r688, [%rd1];

$L__BB7_119:
	and.b32  	%r286, %r688, 1;
	shl.b32 	%r287, %r688, 3;
	and.b32  	%r288, %r287, 8;
	setp.eq.s32 	%p132, %r286, 0;
	selp.f64 	%fd948, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p132;
	mul.wide.s32 	%rd121, %r288, 8;
	add.s64 	%rd123, %rd82, %rd121;
	ld.global.nc.f64 	%fd949, [%rd123+8];
	mul.rn.f64 	%fd167, %fd1897, %fd1897;
	fma.rn.f64 	%fd950, %fd948, %fd167, %fd949;
	ld.global.nc.f64 	%fd951, [%rd123+16];
	fma.rn.f64 	%fd952, %fd950, %fd167, %fd951;
	ld.global.nc.f64 	%fd953, [%rd123+24];
	fma.rn.f64 	%fd954, %fd952, %fd167, %fd953;
	ld.global.nc.f64 	%fd955, [%rd123+32];
	fma.rn.f64 	%fd956, %fd954, %fd167, %fd955;
	ld.global.nc.f64 	%fd957, [%rd123+40];
	fma.rn.f64 	%fd958, %fd956, %fd167, %fd957;
	ld.global.nc.f64 	%fd959, [%rd123+48];
	fma.rn.f64 	%fd168, %fd958, %fd167, %fd959;
	fma.rn.f64 	%fd1899, %fd168, %fd1897, %fd1897;
	@%p132 bra 	$L__BB7_121;

	mov.f64 	%fd960, 0d3FF0000000000000;
	fma.rn.f64 	%fd1899, %fd168, %fd167, %fd960;

$L__BB7_121:
	and.b32  	%r289, %r688, 2;
	setp.eq.s32 	%p133, %r289, 0;
	@%p133 bra 	$L__BB7_123;

	mov.f64 	%fd961, 0d0000000000000000;
	mov.f64 	%fd962, 0dBFF0000000000000;
	fma.rn.f64 	%fd1899, %fd1899, %fd962, %fd961;

$L__BB7_123:
	div.rn.f64 	%fd174, %fd86, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r290, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd174;
	}
	and.b32  	%r292, %r291, 2147483647;
	setp.eq.s32 	%p134, %r292, 2146435072;
	setp.eq.s32 	%p135, %r290, 0;
	and.pred  	%p136, %p135, %p134;
	@%p136 bra 	$L__BB7_126;
	bra.uni 	$L__BB7_124;

$L__BB7_126:
	mov.f64 	%fd972, 0d0000000000000000;
	mul.rn.f64 	%fd1900, %fd174, %fd972;
	mov.u32 	%r689, 0;
	bra.uni 	$L__BB7_127;

$L__BB7_124:
	mul.rn.f64 	%fd963, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r689, %fd963;
	st.local.u32 	[%rd1], %r689;
	cvt.rn.f64.s32 	%fd964, %r689;
	neg.f64 	%fd965, %fd964;
	mov.f64 	%fd966, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd967, %fd965, %fd966, %fd174;
	mov.f64 	%fd968, 0d3C91A62633145C00;
	fma.rn.f64 	%fd969, %fd965, %fd968, %fd967;
	mov.f64 	%fd970, 0d397B839A252049C0;
	fma.rn.f64 	%fd1900, %fd965, %fd970, %fd969;
	abs.f64 	%fd971, %fd174;
	setp.ltu.f64 	%p137, %fd971, 0d41E0000000000000;
	@%p137 bra 	$L__BB7_127;

	{ // callseq 127, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1900, [retval0+0];
	} // callseq 127
	ld.local.u32 	%r689, [%rd1];

$L__BB7_127:
	and.b32  	%r294, %r689, 1;
	shl.b32 	%r295, %r689, 3;
	and.b32  	%r296, %r295, 8;
	setp.eq.s32 	%p138, %r294, 0;
	selp.f64 	%fd973, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p138;
	mul.wide.s32 	%rd125, %r296, 8;
	add.s64 	%rd127, %rd82, %rd125;
	ld.global.nc.f64 	%fd974, [%rd127+8];
	mul.rn.f64 	%fd179, %fd1900, %fd1900;
	fma.rn.f64 	%fd975, %fd973, %fd179, %fd974;
	ld.global.nc.f64 	%fd976, [%rd127+16];
	fma.rn.f64 	%fd977, %fd975, %fd179, %fd976;
	ld.global.nc.f64 	%fd978, [%rd127+24];
	fma.rn.f64 	%fd979, %fd977, %fd179, %fd978;
	ld.global.nc.f64 	%fd980, [%rd127+32];
	fma.rn.f64 	%fd981, %fd979, %fd179, %fd980;
	ld.global.nc.f64 	%fd982, [%rd127+40];
	fma.rn.f64 	%fd983, %fd981, %fd179, %fd982;
	ld.global.nc.f64 	%fd984, [%rd127+48];
	fma.rn.f64 	%fd180, %fd983, %fd179, %fd984;
	fma.rn.f64 	%fd1902, %fd180, %fd1900, %fd1900;
	@%p138 bra 	$L__BB7_129;

	mov.f64 	%fd985, 0d3FF0000000000000;
	fma.rn.f64 	%fd1902, %fd180, %fd179, %fd985;

$L__BB7_129:
	and.b32  	%r297, %r689, 2;
	setp.eq.s32 	%p139, %r297, 0;
	@%p139 bra 	$L__BB7_131;

	mov.f64 	%fd986, 0d0000000000000000;
	mov.f64 	%fd987, 0dBFF0000000000000;
	fma.rn.f64 	%fd1902, %fd1902, %fd987, %fd986;

$L__BB7_131:
	mul.rn.f64 	%fd988, %fd1902, 0d4044000000000000;
	mul.rn.f64 	%fd989, %fd1899, 0d4034000000000000;
	add.rn.f64 	%fd186, %fd989, %fd988;
	div.rn.f64 	%fd187, %fd86, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r298, %temp}, %fd187;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r299}, %fd187;
	}
	and.b32  	%r300, %r299, 2147483647;
	setp.eq.s32 	%p140, %r300, 2146435072;
	setp.eq.s32 	%p141, %r298, 0;
	and.pred  	%p142, %p141, %p140;
	@%p142 bra 	$L__BB7_134;
	bra.uni 	$L__BB7_132;

$L__BB7_134:
	mov.f64 	%fd999, 0d0000000000000000;
	mul.rn.f64 	%fd1903, %fd187, %fd999;
	mov.u32 	%r690, 0;
	bra.uni 	$L__BB7_135;

$L__BB7_132:
	mul.rn.f64 	%fd990, %fd187, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r690, %fd990;
	st.local.u32 	[%rd1], %r690;
	cvt.rn.f64.s32 	%fd991, %r690;
	neg.f64 	%fd992, %fd991;
	mov.f64 	%fd993, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd994, %fd992, %fd993, %fd187;
	mov.f64 	%fd995, 0d3C91A62633145C00;
	fma.rn.f64 	%fd996, %fd992, %fd995, %fd994;
	mov.f64 	%fd997, 0d397B839A252049C0;
	fma.rn.f64 	%fd1903, %fd992, %fd997, %fd996;
	abs.f64 	%fd998, %fd187;
	setp.ltu.f64 	%p143, %fd998, 0d41E0000000000000;
	@%p143 bra 	$L__BB7_135;

	{ // callseq 128, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd187;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1903, [retval0+0];
	} // callseq 128
	ld.local.u32 	%r690, [%rd1];

$L__BB7_135:
	and.b32  	%r302, %r690, 1;
	shl.b32 	%r303, %r690, 3;
	and.b32  	%r304, %r303, 8;
	setp.eq.s32 	%p144, %r302, 0;
	selp.f64 	%fd1000, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p144;
	mul.wide.s32 	%rd129, %r304, 8;
	add.s64 	%rd131, %rd82, %rd129;
	ld.global.nc.f64 	%fd1001, [%rd131+8];
	mul.rn.f64 	%fd192, %fd1903, %fd1903;
	fma.rn.f64 	%fd1002, %fd1000, %fd192, %fd1001;
	ld.global.nc.f64 	%fd1003, [%rd131+16];
	fma.rn.f64 	%fd1004, %fd1002, %fd192, %fd1003;
	ld.global.nc.f64 	%fd1005, [%rd131+24];
	fma.rn.f64 	%fd1006, %fd1004, %fd192, %fd1005;
	ld.global.nc.f64 	%fd1007, [%rd131+32];
	fma.rn.f64 	%fd1008, %fd1006, %fd192, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd131+40];
	fma.rn.f64 	%fd1010, %fd1008, %fd192, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd131+48];
	fma.rn.f64 	%fd193, %fd1010, %fd192, %fd1011;
	fma.rn.f64 	%fd1905, %fd193, %fd1903, %fd1903;
	@%p144 bra 	$L__BB7_137;

	mov.f64 	%fd1012, 0d3FF0000000000000;
	fma.rn.f64 	%fd1905, %fd193, %fd192, %fd1012;

$L__BB7_137:
	and.b32  	%r305, %r690, 2;
	setp.eq.s32 	%p145, %r305, 0;
	@%p145 bra 	$L__BB7_139;

	mov.f64 	%fd1013, 0d0000000000000000;
	mov.f64 	%fd1014, 0dBFF0000000000000;
	fma.rn.f64 	%fd1905, %fd1905, %fd1014, %fd1013;

$L__BB7_139:
	mul.rn.f64 	%fd1015, %fd1905, 0d4062C00000000000;
	add.rn.f64 	%fd199, %fd186, %fd1015;
	div.rn.f64 	%fd200, %fd86, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r306, %temp}, %fd200;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r307}, %fd200;
	}
	and.b32  	%r308, %r307, 2147483647;
	setp.eq.s32 	%p146, %r308, 2146435072;
	setp.eq.s32 	%p147, %r306, 0;
	and.pred  	%p148, %p147, %p146;
	@%p148 bra 	$L__BB7_142;
	bra.uni 	$L__BB7_140;

$L__BB7_142:
	mov.f64 	%fd1025, 0d0000000000000000;
	mul.rn.f64 	%fd1906, %fd200, %fd1025;
	mov.u32 	%r691, 0;
	bra.uni 	$L__BB7_143;

$L__BB7_140:
	mul.rn.f64 	%fd1016, %fd200, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r691, %fd1016;
	st.local.u32 	[%rd1], %r691;
	cvt.rn.f64.s32 	%fd1017, %r691;
	neg.f64 	%fd1018, %fd1017;
	mov.f64 	%fd1019, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1020, %fd1018, %fd1019, %fd200;
	mov.f64 	%fd1021, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1022, %fd1018, %fd1021, %fd1020;
	mov.f64 	%fd1023, 0d397B839A252049C0;
	fma.rn.f64 	%fd1906, %fd1018, %fd1023, %fd1022;
	abs.f64 	%fd1024, %fd200;
	setp.ltu.f64 	%p149, %fd1024, 0d41E0000000000000;
	@%p149 bra 	$L__BB7_143;

	{ // callseq 129, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd200;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1906, [retval0+0];
	} // callseq 129
	ld.local.u32 	%r691, [%rd1];

$L__BB7_143:
	and.b32  	%r310, %r691, 1;
	shl.b32 	%r311, %r691, 3;
	and.b32  	%r312, %r311, 8;
	setp.eq.s32 	%p150, %r310, 0;
	selp.f64 	%fd1026, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p150;
	mul.wide.s32 	%rd133, %r312, 8;
	add.s64 	%rd135, %rd82, %rd133;
	ld.global.nc.f64 	%fd1027, [%rd135+8];
	mul.rn.f64 	%fd205, %fd1906, %fd1906;
	fma.rn.f64 	%fd1028, %fd1026, %fd205, %fd1027;
	ld.global.nc.f64 	%fd1029, [%rd135+16];
	fma.rn.f64 	%fd1030, %fd1028, %fd205, %fd1029;
	ld.global.nc.f64 	%fd1031, [%rd135+24];
	fma.rn.f64 	%fd1032, %fd1030, %fd205, %fd1031;
	ld.global.nc.f64 	%fd1033, [%rd135+32];
	fma.rn.f64 	%fd1034, %fd1032, %fd205, %fd1033;
	ld.global.nc.f64 	%fd1035, [%rd135+40];
	fma.rn.f64 	%fd1036, %fd1034, %fd205, %fd1035;
	ld.global.nc.f64 	%fd1037, [%rd135+48];
	fma.rn.f64 	%fd206, %fd1036, %fd205, %fd1037;
	fma.rn.f64 	%fd1908, %fd206, %fd1906, %fd1906;
	@%p150 bra 	$L__BB7_145;

	mov.f64 	%fd1038, 0d3FF0000000000000;
	fma.rn.f64 	%fd1908, %fd206, %fd205, %fd1038;

$L__BB7_145:
	and.b32  	%r313, %r691, 2;
	setp.eq.s32 	%p151, %r313, 0;
	@%p151 bra 	$L__BB7_147;

	mov.f64 	%fd1039, 0d0000000000000000;
	mov.f64 	%fd1040, 0dBFF0000000000000;
	fma.rn.f64 	%fd1908, %fd1908, %fd1040, %fd1039;

$L__BB7_147:
	mul.rn.f64 	%fd1041, %fd1908, 0d4072C00000000000;
	add.rn.f64 	%fd1042, %fd199, %fd1041;
	add.rn.f64 	%fd212, %fd112, %fd1042;
	add.rn.f64 	%fd213, %fd112, %fd162;
	add.rn.f64 	%fd1043, %fd83, %fd83;
	add.rn.f64 	%fd1044, %fd1043, 0dC059000000000000;
	mul.rn.f64 	%fd1045, %fd82, 0d4008000000000000;
	add.rn.f64 	%fd214, %fd1044, %fd1045;
	abs.f64 	%fd215, %fd82;
	{ // callseq 130, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1911, [retval0+0];
	} // callseq 130
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd82;
	}
	setp.lt.s32 	%p152, %r53, 0;
	and.pred  	%p4, %p152, %p15;
	not.pred 	%p154, %p4;
	@%p154 bra 	$L__BB7_149;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd1911;
	}
	xor.b32  	%r315, %r314, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r316, %temp}, %fd1911;
	}
	mov.b64 	%fd1911, {%r316, %r315};

$L__BB7_149:
	setp.eq.f64 	%p155, %fd82, 0d0000000000000000;
	@%p155 bra 	$L__BB7_153;
	bra.uni 	$L__BB7_150;

$L__BB7_153:
	selp.b32 	%r317, %r53, 0, %p15;
	mov.u32 	%r318, 0;
	or.b32  	%r319, %r317, 2146435072;
	setp.lt.s32 	%p159, %r2, 0;
	selp.b32 	%r320, %r319, %r317, %p159;
	mov.b64 	%fd1911, {%r318, %r320};
	bra.uni 	$L__BB7_154;

$L__BB7_150:
	setp.gt.s32 	%p156, %r53, -1;
	@%p156 bra 	$L__BB7_154;

	mov.f64 	%fd1046, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1047, %fd1046;
	setp.eq.f64 	%p157, %fd1047, 0d4000000000000000;
	@%p157 bra 	$L__BB7_154;

	mov.f64 	%fd1911, 0dFFF8000000000000;

$L__BB7_154:
	add.rn.f64 	%fd1049, %fd82, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r321}, %fd1049;
	}
	and.b32  	%r322, %r321, 2146435072;
	setp.ne.s32 	%p160, %r322, 2146435072;
	@%p160 bra 	$L__BB7_161;

	setp.gtu.f64 	%p161, %fd215, 0d7FF0000000000000;
	@%p161 bra 	$L__BB7_160;
	bra.uni 	$L__BB7_156;

$L__BB7_160:
	mov.f64 	%fd1051, 0d4000000000000000;
	add.rn.f64 	%fd1911, %fd82, %fd1051;
	bra.uni 	$L__BB7_161;

$L__BB7_156:
	mov.f64 	%fd1050, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r323, %temp}, %fd1050;
	}
	and.b32  	%r54, %r2, 2147483647;
	setp.eq.s32 	%p162, %r54, 2146435072;
	setp.eq.s32 	%p163, %r323, 0;
	and.pred  	%p164, %p162, %p163;
	@%p164 bra 	$L__BB7_159;
	bra.uni 	$L__BB7_157;

$L__BB7_159:
	setp.gt.f64 	%p171, %fd215, 0d3FF0000000000000;
	selp.b32 	%r330, 2146435072, 0, %p171;
	mov.u32 	%r331, 0;
	xor.b32  	%r332, %r330, 2146435072;
	setp.lt.s32 	%p172, %r2, 0;
	selp.b32 	%r333, %r332, %r330, %p172;
	setp.eq.f64 	%p173, %fd82, 0dBFF0000000000000;
	selp.b32 	%r334, 1072693248, %r333, %p173;
	mov.b64 	%fd1911, {%r331, %r334};
	bra.uni 	$L__BB7_161;

$L__BB7_157:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r324, %temp}, %fd82;
	}
	and.b32  	%r325, %r53, 2147483647;
	setp.ne.s32 	%p165, %r325, 2146435072;
	setp.ne.s32 	%p166, %r324, 0;
	or.pred  	%p167, %p165, %p166;
	@%p167 bra 	$L__BB7_161;

	setp.gt.s32 	%p168, %r2, -1;
	selp.b32 	%r326, 2146435072, 0, %p168;
	mov.u32 	%r327, 0;
	setp.ne.s32 	%p169, %r54, 1071644672;
	and.pred  	%p170, %p169, %p4;
	or.b32  	%r328, %r326, -2147483648;
	selp.b32 	%r329, %r328, %r326, %p170;
	mov.b64 	%fd1911, {%r327, %r329};

$L__BB7_161:
	mul.rn.f64 	%fd1052, %fd1911, 0d3FC999999999999A;
	setp.eq.f64 	%p174, %fd82, 0d3FF0000000000000;
	selp.f64 	%fd1053, 0d3FC999999999999A, %fd1052, %p174;
	add.rn.f64 	%fd1054, %fd214, %fd1053;
	mul.rn.f64 	%fd1055, %fd83, %fd82;
	mul.rn.f64 	%fd225, %fd1055, 0d3FB999999999999A;
	add.rn.f64 	%fd1056, %fd225, %fd1054;
	mul.rn.f64 	%fd1057, %fd85, 0d3FC999999999999A;
	add.rn.f64 	%fd1058, %fd1057, %fd1056;
	mul.rn.f64 	%fd1059, %fd213, 0d3FE5555555555555;
	add.rn.f64 	%fd226, %fd1059, %fd1058;
	add.rn.f64 	%fd1060, %fd82, %fd82;
	add.rn.f64 	%fd1061, %fd83, 0d4072C00000000000;
	add.rn.f64 	%fd227, %fd1061, %fd1060;
	{ // callseq 131, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1914, [retval0+0];
	} // callseq 131
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd83;
	}
	setp.lt.s32 	%p175, %r55, 0;
	and.pred  	%p5, %p175, %p15;
	not.pred 	%p177, %p5;
	@%p177 bra 	$L__BB7_163;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r335}, %fd1914;
	}
	xor.b32  	%r336, %r335, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r337, %temp}, %fd1914;
	}
	mov.b64 	%fd1914, {%r337, %r336};

$L__BB7_163:
	setp.eq.f64 	%p178, %fd83, 0d0000000000000000;
	@%p178 bra 	$L__BB7_167;
	bra.uni 	$L__BB7_164;

$L__BB7_167:
	selp.b32 	%r338, %r55, 0, %p15;
	mov.u32 	%r339, 0;
	or.b32  	%r340, %r338, 2146435072;
	setp.lt.s32 	%p182, %r2, 0;
	selp.b32 	%r341, %r340, %r338, %p182;
	mov.b64 	%fd1914, {%r339, %r341};
	bra.uni 	$L__BB7_168;

$L__BB7_164:
	setp.gt.s32 	%p179, %r55, -1;
	@%p179 bra 	$L__BB7_168;

	mov.f64 	%fd1062, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1063, %fd1062;
	setp.eq.f64 	%p180, %fd1063, 0d4000000000000000;
	@%p180 bra 	$L__BB7_168;

	mov.f64 	%fd1914, 0dFFF8000000000000;

$L__BB7_168:
	add.rn.f64 	%fd1065, %fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r342}, %fd1065;
	}
	and.b32  	%r343, %r342, 2146435072;
	setp.ne.s32 	%p183, %r343, 2146435072;
	@%p183 bra 	$L__BB7_175;

	setp.gtu.f64 	%p184, %fd84, 0d7FF0000000000000;
	@%p184 bra 	$L__BB7_174;
	bra.uni 	$L__BB7_170;

$L__BB7_174:
	mov.f64 	%fd1067, 0d4000000000000000;
	add.rn.f64 	%fd1914, %fd83, %fd1067;
	bra.uni 	$L__BB7_175;

$L__BB7_170:
	mov.f64 	%fd1066, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r344, %temp}, %fd1066;
	}
	and.b32  	%r56, %r2, 2147483647;
	setp.eq.s32 	%p185, %r56, 2146435072;
	setp.eq.s32 	%p186, %r344, 0;
	and.pred  	%p187, %p185, %p186;
	@%p187 bra 	$L__BB7_173;
	bra.uni 	$L__BB7_171;

$L__BB7_173:
	setp.gt.f64 	%p194, %fd84, 0d3FF0000000000000;
	selp.b32 	%r351, 2146435072, 0, %p194;
	mov.u32 	%r352, 0;
	xor.b32  	%r353, %r351, 2146435072;
	setp.lt.s32 	%p195, %r2, 0;
	selp.b32 	%r354, %r353, %r351, %p195;
	setp.eq.f64 	%p196, %fd83, 0dBFF0000000000000;
	selp.b32 	%r355, 1072693248, %r354, %p196;
	mov.b64 	%fd1914, {%r352, %r355};
	bra.uni 	$L__BB7_175;

$L__BB7_171:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd83;
	}
	and.b32  	%r346, %r55, 2147483647;
	setp.ne.s32 	%p188, %r346, 2146435072;
	setp.ne.s32 	%p189, %r345, 0;
	or.pred  	%p190, %p188, %p189;
	@%p190 bra 	$L__BB7_175;

	setp.gt.s32 	%p191, %r2, -1;
	selp.b32 	%r347, 2146435072, 0, %p191;
	mov.u32 	%r348, 0;
	setp.ne.s32 	%p192, %r56, 1071644672;
	and.pred  	%p193, %p192, %p5;
	or.b32  	%r349, %r347, -2147483648;
	selp.b32 	%r350, %r349, %r347, %p193;
	mov.b64 	%fd1914, {%r348, %r350};

$L__BB7_175:
	mul.rn.f64 	%fd1068, %fd1914, 0d3FB999999999999A;
	setp.eq.f64 	%p197, %fd83, 0d3FF0000000000000;
	selp.f64 	%fd1069, 0d3FB999999999999A, %fd1068, %p197;
	add.rn.f64 	%fd1070, %fd227, %fd1069;
	add.rn.f64 	%fd1071, %fd225, %fd1070;
	mul.rn.f64 	%fd1072, %fd85, 0d3FB999999999999A;
	add.rn.f64 	%fd1073, %fd1072, %fd1071;
	mul.rn.f64 	%fd1074, %fd212, 0d3FE5555555555555;
	add.rn.f64 	%fd237, %fd1074, %fd1073;
	div.rn.f64 	%fd1075, %fd81, 0d4066800000000000;
	mul.rn.f64 	%fd238, %fd1075, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r356, %temp}, %fd238;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd238;
	}
	and.b32  	%r358, %r357, 2147483647;
	setp.eq.s32 	%p198, %r358, 2146435072;
	setp.eq.s32 	%p199, %r356, 0;
	and.pred  	%p6, %p199, %p198;
	@%p6 bra 	$L__BB7_178;
	bra.uni 	$L__BB7_176;

$L__BB7_178:
	mov.f64 	%fd1085, 0d0000000000000000;
	mul.rn.f64 	%fd1915, %fd238, %fd1085;
	mov.u32 	%r692, 0;
	bra.uni 	$L__BB7_179;

$L__BB7_176:
	mul.rn.f64 	%fd1076, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r692, %fd1076;
	st.local.u32 	[%rd1], %r692;
	cvt.rn.f64.s32 	%fd1077, %r692;
	neg.f64 	%fd1078, %fd1077;
	mov.f64 	%fd1079, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1080, %fd1078, %fd1079, %fd238;
	mov.f64 	%fd1081, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1082, %fd1078, %fd1081, %fd1080;
	mov.f64 	%fd1083, 0d397B839A252049C0;
	fma.rn.f64 	%fd1915, %fd1078, %fd1083, %fd1082;
	abs.f64 	%fd1084, %fd238;
	setp.ltu.f64 	%p200, %fd1084, 0d41E0000000000000;
	@%p200 bra 	$L__BB7_179;

	{ // callseq 132, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1915, [retval0+0];
	} // callseq 132
	ld.local.u32 	%r692, [%rd1];

$L__BB7_179:
	and.b32  	%r360, %r692, 1;
	shl.b32 	%r361, %r692, 3;
	and.b32  	%r362, %r361, 8;
	setp.eq.s32 	%p201, %r360, 0;
	selp.f64 	%fd1086, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p201;
	mul.wide.s32 	%rd137, %r362, 8;
	add.s64 	%rd139, %rd82, %rd137;
	ld.global.nc.f64 	%fd1087, [%rd139+8];
	mul.rn.f64 	%fd243, %fd1915, %fd1915;
	fma.rn.f64 	%fd1088, %fd1086, %fd243, %fd1087;
	ld.global.nc.f64 	%fd1089, [%rd139+16];
	fma.rn.f64 	%fd1090, %fd1088, %fd243, %fd1089;
	ld.global.nc.f64 	%fd1091, [%rd139+24];
	fma.rn.f64 	%fd1092, %fd1090, %fd243, %fd1091;
	ld.global.nc.f64 	%fd1093, [%rd139+32];
	fma.rn.f64 	%fd1094, %fd1092, %fd243, %fd1093;
	ld.global.nc.f64 	%fd1095, [%rd139+40];
	fma.rn.f64 	%fd1096, %fd1094, %fd243, %fd1095;
	ld.global.nc.f64 	%fd1097, [%rd139+48];
	fma.rn.f64 	%fd244, %fd1096, %fd243, %fd1097;
	fma.rn.f64 	%fd1917, %fd244, %fd1915, %fd1915;
	@%p201 bra 	$L__BB7_181;

	mov.f64 	%fd1098, 0d3FF0000000000000;
	fma.rn.f64 	%fd1917, %fd244, %fd243, %fd1098;

$L__BB7_181:
	and.b32  	%r363, %r692, 2;
	setp.eq.s32 	%p202, %r363, 0;
	@%p202 bra 	$L__BB7_183;

	mov.f64 	%fd1099, 0d0000000000000000;
	mov.f64 	%fd1100, 0dBFF0000000000000;
	fma.rn.f64 	%fd1917, %fd1917, %fd1100, %fd1099;

$L__BB7_183:
	@%p6 bra 	$L__BB7_187;
	bra.uni 	$L__BB7_184;

$L__BB7_187:
	mov.f64 	%fd1110, 0d0000000000000000;
	mul.rn.f64 	%fd1919, %fd238, %fd1110;
	mov.u32 	%r694, 1;
	bra.uni 	$L__BB7_188;

$L__BB7_184:
	mul.rn.f64 	%fd1101, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r693, %fd1101;
	st.local.u32 	[%rd1], %r693;
	cvt.rn.f64.s32 	%fd1102, %r693;
	neg.f64 	%fd1103, %fd1102;
	mov.f64 	%fd1104, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1105, %fd1103, %fd1104, %fd238;
	mov.f64 	%fd1106, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1107, %fd1103, %fd1106, %fd1105;
	mov.f64 	%fd1108, 0d397B839A252049C0;
	fma.rn.f64 	%fd1919, %fd1103, %fd1108, %fd1107;
	abs.f64 	%fd1109, %fd238;
	setp.ltu.f64 	%p203, %fd1109, 0d41E0000000000000;
	@%p203 bra 	$L__BB7_186;

	{ // callseq 133, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1919, [retval0+0];
	} // callseq 133
	ld.local.u32 	%r693, [%rd1];

$L__BB7_186:
	add.s32 	%r694, %r693, 1;

$L__BB7_188:
	and.b32  	%r365, %r694, 1;
	shl.b32 	%r366, %r694, 3;
	and.b32  	%r367, %r366, 8;
	setp.eq.s32 	%p204, %r365, 0;
	selp.f64 	%fd1111, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p204;
	mul.wide.s32 	%rd141, %r367, 8;
	add.s64 	%rd143, %rd82, %rd141;
	ld.global.nc.f64 	%fd1112, [%rd143+8];
	mul.rn.f64 	%fd255, %fd1919, %fd1919;
	fma.rn.f64 	%fd1113, %fd1111, %fd255, %fd1112;
	ld.global.nc.f64 	%fd1114, [%rd143+16];
	fma.rn.f64 	%fd1115, %fd1113, %fd255, %fd1114;
	ld.global.nc.f64 	%fd1116, [%rd143+24];
	fma.rn.f64 	%fd1117, %fd1115, %fd255, %fd1116;
	ld.global.nc.f64 	%fd1118, [%rd143+32];
	fma.rn.f64 	%fd1119, %fd1117, %fd255, %fd1118;
	ld.global.nc.f64 	%fd1120, [%rd143+40];
	fma.rn.f64 	%fd1121, %fd1119, %fd255, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd143+48];
	fma.rn.f64 	%fd256, %fd1121, %fd255, %fd1122;
	fma.rn.f64 	%fd1921, %fd256, %fd1919, %fd1919;
	@%p204 bra 	$L__BB7_190;

	mov.f64 	%fd1123, 0d3FF0000000000000;
	fma.rn.f64 	%fd1921, %fd256, %fd255, %fd1123;

$L__BB7_190:
	and.b32  	%r368, %r694, 2;
	setp.eq.s32 	%p205, %r368, 0;
	@%p205 bra 	$L__BB7_192;

	mov.f64 	%fd1124, 0d0000000000000000;
	mov.f64 	%fd1125, 0dBFF0000000000000;
	fma.rn.f64 	%fd1921, %fd1921, %fd1125, %fd1124;

$L__BB7_192:
	mul.rn.f64 	%fd1126, %fd1917, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1127, %fd1917, %fd1126;
	add.rn.f64 	%fd1128, %fd1127, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1129, %fd1128;
	mov.f64 	%fd1130, 0dC15854C140000000;
	div.rn.f64 	%fd1131, %fd1130, %fd1129;
	mul.rn.f64 	%fd1132, %fd1131, %fd1921;
	mul.rn.f64 	%fd1133, %fd1132, 0d400921FB54442D18;
	mul.rn.f64 	%fd1134, %fd237, 0d4066800000000000;
	div.rn.f64 	%fd1135, %fd1134, %fd1133;
	add.rn.f64 	%fd2009, %fd69, %fd1135;
	mul.rn.f64 	%fd1136, %fd226, 0d4066800000000000;
	mul.rn.f64 	%fd1137, %fd1129, %fd1128;
	mov.f64 	%fd1138, 0dC1582B102DE355C1;
	div.rn.f64 	%fd1139, %fd1138, %fd1137;
	mul.rn.f64 	%fd1140, %fd1139, 0d400921FB54442D18;
	div.rn.f64 	%fd1141, %fd1136, %fd1140;
	add.rn.f64 	%fd2010, %fd81, %fd1141;
	setp.lt.s32 	%p206, %r146, 1;
	@%p206 bra 	$L__BB7_458;

	and.b32  	%r65, %r2, 2147483647;
	setp.gt.s32 	%p207, %r2, -1;
	selp.b32 	%r66, 2146435072, 0, %p207;
	mov.u32 	%r695, 0;
	or.b32  	%r67, %r66, -2147483648;
	mov.f64 	%fd1922, %fd2010;
	mov.f64 	%fd1923, %fd2009;

$L__BB7_194:
	mov.f64 	%fd2009, %fd1923;
	mov.f64 	%fd2010, %fd1922;
	add.rn.f64 	%fd266, %fd2010, 0dC041800000000000;
	add.rn.f64 	%fd267, %fd2009, 0dC05A400000000000;
	abs.f64 	%fd268, %fd267;
	sqrt.rn.f64 	%fd269, %fd268;
	mul.rn.f64 	%fd270, %fd267, 0d400921FB54442D18;
	mul.rn.f64 	%fd271, %fd266, 0d400921FB54442D18;
	mul.rn.f64 	%fd272, %fd270, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r370, %temp}, %fd272;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r371}, %fd272;
	}
	and.b32  	%r372, %r371, 2147483647;
	setp.eq.s32 	%p208, %r372, 2146435072;
	setp.eq.s32 	%p209, %r370, 0;
	and.pred  	%p210, %p209, %p208;
	@%p210 bra 	$L__BB7_197;
	bra.uni 	$L__BB7_195;

$L__BB7_197:
	mov.f64 	%fd1151, 0d0000000000000000;
	mul.rn.f64 	%fd1924, %fd272, %fd1151;
	mov.u32 	%r696, 0;
	bra.uni 	$L__BB7_198;

$L__BB7_195:
	mul.rn.f64 	%fd1142, %fd272, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r696, %fd1142;
	st.local.u32 	[%rd1], %r696;
	cvt.rn.f64.s32 	%fd1143, %r696;
	neg.f64 	%fd1144, %fd1143;
	mov.f64 	%fd1145, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1146, %fd1144, %fd1145, %fd272;
	mov.f64 	%fd1147, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1148, %fd1144, %fd1147, %fd1146;
	mov.f64 	%fd1149, 0d397B839A252049C0;
	fma.rn.f64 	%fd1924, %fd1144, %fd1149, %fd1148;
	abs.f64 	%fd1150, %fd272;
	setp.ltu.f64 	%p211, %fd1150, 0d41E0000000000000;
	@%p211 bra 	$L__BB7_198;

	{ // callseq 134, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1924, [retval0+0];
	} // callseq 134
	ld.local.u32 	%r696, [%rd1];

$L__BB7_198:
	and.b32  	%r374, %r696, 1;
	shl.b32 	%r375, %r696, 3;
	and.b32  	%r376, %r375, 8;
	setp.eq.s32 	%p212, %r374, 0;
	selp.f64 	%fd1152, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p212;
	mul.wide.s32 	%rd145, %r376, 8;
	add.s64 	%rd147, %rd82, %rd145;
	ld.global.nc.f64 	%fd1153, [%rd147+8];
	mul.rn.f64 	%fd277, %fd1924, %fd1924;
	fma.rn.f64 	%fd1154, %fd1152, %fd277, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd147+16];
	fma.rn.f64 	%fd1156, %fd1154, %fd277, %fd1155;
	ld.global.nc.f64 	%fd1157, [%rd147+24];
	fma.rn.f64 	%fd1158, %fd1156, %fd277, %fd1157;
	ld.global.nc.f64 	%fd1159, [%rd147+32];
	fma.rn.f64 	%fd1160, %fd1158, %fd277, %fd1159;
	ld.global.nc.f64 	%fd1161, [%rd147+40];
	fma.rn.f64 	%fd1162, %fd1160, %fd277, %fd1161;
	ld.global.nc.f64 	%fd1163, [%rd147+48];
	fma.rn.f64 	%fd278, %fd1162, %fd277, %fd1163;
	fma.rn.f64 	%fd1926, %fd278, %fd1924, %fd1924;
	@%p212 bra 	$L__BB7_200;

	mov.f64 	%fd1164, 0d3FF0000000000000;
	fma.rn.f64 	%fd1926, %fd278, %fd277, %fd1164;

$L__BB7_200:
	and.b32  	%r377, %r696, 2;
	setp.eq.s32 	%p213, %r377, 0;
	@%p213 bra 	$L__BB7_202;

	mov.f64 	%fd1165, 0d0000000000000000;
	mov.f64 	%fd1166, 0dBFF0000000000000;
	fma.rn.f64 	%fd1926, %fd1926, %fd1166, %fd1165;

$L__BB7_202:
	add.rn.f64 	%fd284, %fd270, %fd270;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r378, %temp}, %fd284;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r379}, %fd284;
	}
	and.b32  	%r380, %r379, 2147483647;
	setp.eq.s32 	%p214, %r380, 2146435072;
	setp.eq.s32 	%p215, %r378, 0;
	and.pred  	%p216, %p215, %p214;
	@%p216 bra 	$L__BB7_205;
	bra.uni 	$L__BB7_203;

$L__BB7_205:
	mov.f64 	%fd1176, 0d0000000000000000;
	mul.rn.f64 	%fd1927, %fd284, %fd1176;
	mov.u32 	%r697, 0;
	bra.uni 	$L__BB7_206;

$L__BB7_203:
	mul.rn.f64 	%fd1167, %fd284, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r697, %fd1167;
	st.local.u32 	[%rd1], %r697;
	cvt.rn.f64.s32 	%fd1168, %r697;
	neg.f64 	%fd1169, %fd1168;
	mov.f64 	%fd1170, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1171, %fd1169, %fd1170, %fd284;
	mov.f64 	%fd1172, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1173, %fd1169, %fd1172, %fd1171;
	mov.f64 	%fd1174, 0d397B839A252049C0;
	fma.rn.f64 	%fd1927, %fd1169, %fd1174, %fd1173;
	abs.f64 	%fd1175, %fd284;
	setp.ltu.f64 	%p217, %fd1175, 0d41E0000000000000;
	@%p217 bra 	$L__BB7_206;

	{ // callseq 135, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd284;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1927, [retval0+0];
	} // callseq 135
	ld.local.u32 	%r697, [%rd1];

$L__BB7_206:
	and.b32  	%r382, %r697, 1;
	shl.b32 	%r383, %r697, 3;
	and.b32  	%r384, %r383, 8;
	setp.eq.s32 	%p218, %r382, 0;
	selp.f64 	%fd1177, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p218;
	mul.wide.s32 	%rd149, %r384, 8;
	add.s64 	%rd151, %rd82, %rd149;
	ld.global.nc.f64 	%fd1178, [%rd151+8];
	mul.rn.f64 	%fd289, %fd1927, %fd1927;
	fma.rn.f64 	%fd1179, %fd1177, %fd289, %fd1178;
	ld.global.nc.f64 	%fd1180, [%rd151+16];
	fma.rn.f64 	%fd1181, %fd1179, %fd289, %fd1180;
	ld.global.nc.f64 	%fd1182, [%rd151+24];
	fma.rn.f64 	%fd1183, %fd1181, %fd289, %fd1182;
	ld.global.nc.f64 	%fd1184, [%rd151+32];
	fma.rn.f64 	%fd1185, %fd1183, %fd289, %fd1184;
	ld.global.nc.f64 	%fd1186, [%rd151+40];
	fma.rn.f64 	%fd1187, %fd1185, %fd289, %fd1186;
	ld.global.nc.f64 	%fd1188, [%rd151+48];
	fma.rn.f64 	%fd290, %fd1187, %fd289, %fd1188;
	fma.rn.f64 	%fd1929, %fd290, %fd1927, %fd1927;
	@%p218 bra 	$L__BB7_208;

	mov.f64 	%fd1189, 0d3FF0000000000000;
	fma.rn.f64 	%fd1929, %fd290, %fd289, %fd1189;

$L__BB7_208:
	and.b32  	%r385, %r697, 2;
	setp.eq.s32 	%p219, %r385, 0;
	@%p219 bra 	$L__BB7_210;

	mov.f64 	%fd1190, 0d0000000000000000;
	mov.f64 	%fd1191, 0dBFF0000000000000;
	fma.rn.f64 	%fd1929, %fd1929, %fd1191, %fd1190;

$L__BB7_210:
	mul.rn.f64 	%fd1192, %fd1929, 0d4034000000000000;
	mul.rn.f64 	%fd1193, %fd1926, 0d4034000000000000;
	add.rn.f64 	%fd296, %fd1193, %fd1192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r386}, %fd271;
	}
	and.b32  	%r387, %r386, 2147483647;
	setp.eq.s32 	%p220, %r387, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r388, %temp}, %fd271;
	}
	setp.eq.s32 	%p221, %r388, 0;
	and.pred  	%p222, %p221, %p220;
	@%p222 bra 	$L__BB7_213;
	bra.uni 	$L__BB7_211;

$L__BB7_213:
	mov.f64 	%fd1203, 0d0000000000000000;
	mul.rn.f64 	%fd1930, %fd271, %fd1203;
	mov.u32 	%r698, 0;
	bra.uni 	$L__BB7_214;

$L__BB7_211:
	mul.rn.f64 	%fd1194, %fd271, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r698, %fd1194;
	st.local.u32 	[%rd1], %r698;
	cvt.rn.f64.s32 	%fd1195, %r698;
	neg.f64 	%fd1196, %fd1195;
	mov.f64 	%fd1197, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1198, %fd1196, %fd1197, %fd271;
	mov.f64 	%fd1199, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1200, %fd1196, %fd1199, %fd1198;
	mov.f64 	%fd1201, 0d397B839A252049C0;
	fma.rn.f64 	%fd1930, %fd1196, %fd1201, %fd1200;
	abs.f64 	%fd1202, %fd271;
	setp.ltu.f64 	%p223, %fd1202, 0d41E0000000000000;
	@%p223 bra 	$L__BB7_214;

	{ // callseq 136, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd271;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1930, [retval0+0];
	} // callseq 136
	ld.local.u32 	%r698, [%rd1];

$L__BB7_214:
	and.b32  	%r390, %r698, 1;
	shl.b32 	%r391, %r698, 3;
	and.b32  	%r392, %r391, 8;
	setp.eq.s32 	%p224, %r390, 0;
	selp.f64 	%fd1204, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p224;
	mul.wide.s32 	%rd153, %r392, 8;
	add.s64 	%rd155, %rd82, %rd153;
	ld.global.nc.f64 	%fd1205, [%rd155+8];
	mul.rn.f64 	%fd301, %fd1930, %fd1930;
	fma.rn.f64 	%fd1206, %fd1204, %fd301, %fd1205;
	ld.global.nc.f64 	%fd1207, [%rd155+16];
	fma.rn.f64 	%fd1208, %fd1206, %fd301, %fd1207;
	ld.global.nc.f64 	%fd1209, [%rd155+24];
	fma.rn.f64 	%fd1210, %fd1208, %fd301, %fd1209;
	ld.global.nc.f64 	%fd1211, [%rd155+32];
	fma.rn.f64 	%fd1212, %fd1210, %fd301, %fd1211;
	ld.global.nc.f64 	%fd1213, [%rd155+40];
	fma.rn.f64 	%fd1214, %fd1212, %fd301, %fd1213;
	ld.global.nc.f64 	%fd1215, [%rd155+48];
	fma.rn.f64 	%fd302, %fd1214, %fd301, %fd1215;
	fma.rn.f64 	%fd1932, %fd302, %fd1930, %fd1930;
	@%p224 bra 	$L__BB7_216;

	mov.f64 	%fd1216, 0d3FF0000000000000;
	fma.rn.f64 	%fd1932, %fd302, %fd301, %fd1216;

$L__BB7_216:
	and.b32  	%r393, %r698, 2;
	setp.eq.s32 	%p225, %r393, 0;
	@%p225 bra 	$L__BB7_218;

	mov.f64 	%fd1217, 0d0000000000000000;
	mov.f64 	%fd1218, 0dBFF0000000000000;
	fma.rn.f64 	%fd1932, %fd1932, %fd1218, %fd1217;

$L__BB7_218:
	div.rn.f64 	%fd308, %fd271, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r394, %temp}, %fd308;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r395}, %fd308;
	}
	and.b32  	%r396, %r395, 2147483647;
	setp.eq.s32 	%p226, %r396, 2146435072;
	setp.eq.s32 	%p227, %r394, 0;
	and.pred  	%p228, %p227, %p226;
	@%p228 bra 	$L__BB7_221;
	bra.uni 	$L__BB7_219;

$L__BB7_221:
	mov.f64 	%fd1228, 0d0000000000000000;
	mul.rn.f64 	%fd1933, %fd308, %fd1228;
	mov.u32 	%r699, 0;
	bra.uni 	$L__BB7_222;

$L__BB7_219:
	mul.rn.f64 	%fd1219, %fd308, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r699, %fd1219;
	st.local.u32 	[%rd1], %r699;
	cvt.rn.f64.s32 	%fd1220, %r699;
	neg.f64 	%fd1221, %fd1220;
	mov.f64 	%fd1222, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1223, %fd1221, %fd1222, %fd308;
	mov.f64 	%fd1224, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1225, %fd1221, %fd1224, %fd1223;
	mov.f64 	%fd1226, 0d397B839A252049C0;
	fma.rn.f64 	%fd1933, %fd1221, %fd1226, %fd1225;
	abs.f64 	%fd1227, %fd308;
	setp.ltu.f64 	%p229, %fd1227, 0d41E0000000000000;
	@%p229 bra 	$L__BB7_222;

	{ // callseq 137, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd308;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1933, [retval0+0];
	} // callseq 137
	ld.local.u32 	%r699, [%rd1];

$L__BB7_222:
	and.b32  	%r398, %r699, 1;
	shl.b32 	%r399, %r699, 3;
	and.b32  	%r400, %r399, 8;
	setp.eq.s32 	%p230, %r398, 0;
	selp.f64 	%fd1229, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p230;
	mul.wide.s32 	%rd157, %r400, 8;
	add.s64 	%rd159, %rd82, %rd157;
	ld.global.nc.f64 	%fd1230, [%rd159+8];
	mul.rn.f64 	%fd313, %fd1933, %fd1933;
	fma.rn.f64 	%fd1231, %fd1229, %fd313, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd159+16];
	fma.rn.f64 	%fd1233, %fd1231, %fd313, %fd1232;
	ld.global.nc.f64 	%fd1234, [%rd159+24];
	fma.rn.f64 	%fd1235, %fd1233, %fd313, %fd1234;
	ld.global.nc.f64 	%fd1236, [%rd159+32];
	fma.rn.f64 	%fd1237, %fd1235, %fd313, %fd1236;
	ld.global.nc.f64 	%fd1238, [%rd159+40];
	fma.rn.f64 	%fd1239, %fd1237, %fd313, %fd1238;
	ld.global.nc.f64 	%fd1240, [%rd159+48];
	fma.rn.f64 	%fd314, %fd1239, %fd313, %fd1240;
	fma.rn.f64 	%fd1935, %fd314, %fd1933, %fd1933;
	@%p230 bra 	$L__BB7_224;

	mov.f64 	%fd1241, 0d3FF0000000000000;
	fma.rn.f64 	%fd1935, %fd314, %fd313, %fd1241;

$L__BB7_224:
	and.b32  	%r401, %r699, 2;
	setp.eq.s32 	%p231, %r401, 0;
	@%p231 bra 	$L__BB7_226;

	mov.f64 	%fd1242, 0d0000000000000000;
	mov.f64 	%fd1243, 0dBFF0000000000000;
	fma.rn.f64 	%fd1935, %fd1935, %fd1243, %fd1242;

$L__BB7_226:
	mul.rn.f64 	%fd1244, %fd1935, 0d4044000000000000;
	mul.rn.f64 	%fd1245, %fd1932, 0d4034000000000000;
	add.rn.f64 	%fd320, %fd1245, %fd1244;
	div.rn.f64 	%fd321, %fd271, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd321;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r403}, %fd321;
	}
	and.b32  	%r404, %r403, 2147483647;
	setp.eq.s32 	%p232, %r404, 2146435072;
	setp.eq.s32 	%p233, %r402, 0;
	and.pred  	%p234, %p233, %p232;
	@%p234 bra 	$L__BB7_229;
	bra.uni 	$L__BB7_227;

$L__BB7_229:
	mov.f64 	%fd1255, 0d0000000000000000;
	mul.rn.f64 	%fd1936, %fd321, %fd1255;
	mov.u32 	%r700, 0;
	bra.uni 	$L__BB7_230;

$L__BB7_227:
	mul.rn.f64 	%fd1246, %fd321, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r700, %fd1246;
	st.local.u32 	[%rd1], %r700;
	cvt.rn.f64.s32 	%fd1247, %r700;
	neg.f64 	%fd1248, %fd1247;
	mov.f64 	%fd1249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1250, %fd1248, %fd1249, %fd321;
	mov.f64 	%fd1251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1252, %fd1248, %fd1251, %fd1250;
	mov.f64 	%fd1253, 0d397B839A252049C0;
	fma.rn.f64 	%fd1936, %fd1248, %fd1253, %fd1252;
	abs.f64 	%fd1254, %fd321;
	setp.ltu.f64 	%p235, %fd1254, 0d41E0000000000000;
	@%p235 bra 	$L__BB7_230;

	{ // callseq 138, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd321;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1936, [retval0+0];
	} // callseq 138
	ld.local.u32 	%r700, [%rd1];

$L__BB7_230:
	and.b32  	%r406, %r700, 1;
	shl.b32 	%r407, %r700, 3;
	and.b32  	%r408, %r407, 8;
	setp.eq.s32 	%p236, %r406, 0;
	selp.f64 	%fd1256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p236;
	mul.wide.s32 	%rd161, %r408, 8;
	add.s64 	%rd163, %rd82, %rd161;
	ld.global.nc.f64 	%fd1257, [%rd163+8];
	mul.rn.f64 	%fd326, %fd1936, %fd1936;
	fma.rn.f64 	%fd1258, %fd1256, %fd326, %fd1257;
	ld.global.nc.f64 	%fd1259, [%rd163+16];
	fma.rn.f64 	%fd1260, %fd1258, %fd326, %fd1259;
	ld.global.nc.f64 	%fd1261, [%rd163+24];
	fma.rn.f64 	%fd1262, %fd1260, %fd326, %fd1261;
	ld.global.nc.f64 	%fd1263, [%rd163+32];
	fma.rn.f64 	%fd1264, %fd1262, %fd326, %fd1263;
	ld.global.nc.f64 	%fd1265, [%rd163+40];
	fma.rn.f64 	%fd1266, %fd1264, %fd326, %fd1265;
	ld.global.nc.f64 	%fd1267, [%rd163+48];
	fma.rn.f64 	%fd327, %fd1266, %fd326, %fd1267;
	fma.rn.f64 	%fd1938, %fd327, %fd1936, %fd1936;
	@%p236 bra 	$L__BB7_232;

	mov.f64 	%fd1268, 0d3FF0000000000000;
	fma.rn.f64 	%fd1938, %fd327, %fd326, %fd1268;

$L__BB7_232:
	and.b32  	%r409, %r700, 2;
	setp.eq.s32 	%p237, %r409, 0;
	@%p237 bra 	$L__BB7_234;

	mov.f64 	%fd1269, 0d0000000000000000;
	mov.f64 	%fd1270, 0dBFF0000000000000;
	fma.rn.f64 	%fd1938, %fd1938, %fd1270, %fd1269;

$L__BB7_234:
	mul.rn.f64 	%fd1271, %fd1938, 0d4064000000000000;
	add.rn.f64 	%fd333, %fd320, %fd1271;
	div.rn.f64 	%fd334, %fd271, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r410, %temp}, %fd334;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r411}, %fd334;
	}
	and.b32  	%r412, %r411, 2147483647;
	setp.eq.s32 	%p238, %r412, 2146435072;
	setp.eq.s32 	%p239, %r410, 0;
	and.pred  	%p240, %p239, %p238;
	@%p240 bra 	$L__BB7_237;
	bra.uni 	$L__BB7_235;

$L__BB7_237:
	mov.f64 	%fd1281, 0d0000000000000000;
	mul.rn.f64 	%fd1939, %fd334, %fd1281;
	mov.u32 	%r701, 0;
	bra.uni 	$L__BB7_238;

$L__BB7_235:
	mul.rn.f64 	%fd1272, %fd334, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r701, %fd1272;
	st.local.u32 	[%rd1], %r701;
	cvt.rn.f64.s32 	%fd1273, %r701;
	neg.f64 	%fd1274, %fd1273;
	mov.f64 	%fd1275, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1276, %fd1274, %fd1275, %fd334;
	mov.f64 	%fd1277, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1278, %fd1274, %fd1277, %fd1276;
	mov.f64 	%fd1279, 0d397B839A252049C0;
	fma.rn.f64 	%fd1939, %fd1274, %fd1279, %fd1278;
	abs.f64 	%fd1280, %fd334;
	setp.ltu.f64 	%p241, %fd1280, 0d41E0000000000000;
	@%p241 bra 	$L__BB7_238;

	{ // callseq 139, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd334;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1939, [retval0+0];
	} // callseq 139
	ld.local.u32 	%r701, [%rd1];

$L__BB7_238:
	and.b32  	%r414, %r701, 1;
	shl.b32 	%r415, %r701, 3;
	and.b32  	%r416, %r415, 8;
	setp.eq.s32 	%p242, %r414, 0;
	selp.f64 	%fd1282, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p242;
	mul.wide.s32 	%rd165, %r416, 8;
	add.s64 	%rd167, %rd82, %rd165;
	ld.global.nc.f64 	%fd1283, [%rd167+8];
	mul.rn.f64 	%fd339, %fd1939, %fd1939;
	fma.rn.f64 	%fd1284, %fd1282, %fd339, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd167+16];
	fma.rn.f64 	%fd1286, %fd1284, %fd339, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd167+24];
	fma.rn.f64 	%fd1288, %fd1286, %fd339, %fd1287;
	ld.global.nc.f64 	%fd1289, [%rd167+32];
	fma.rn.f64 	%fd1290, %fd1288, %fd339, %fd1289;
	ld.global.nc.f64 	%fd1291, [%rd167+40];
	fma.rn.f64 	%fd1292, %fd1290, %fd339, %fd1291;
	ld.global.nc.f64 	%fd1293, [%rd167+48];
	fma.rn.f64 	%fd340, %fd1292, %fd339, %fd1293;
	fma.rn.f64 	%fd1941, %fd340, %fd1939, %fd1939;
	@%p242 bra 	$L__BB7_240;

	mov.f64 	%fd1294, 0d3FF0000000000000;
	fma.rn.f64 	%fd1941, %fd340, %fd339, %fd1294;

$L__BB7_240:
	and.b32  	%r417, %r701, 2;
	setp.eq.s32 	%p243, %r417, 0;
	@%p243 bra 	$L__BB7_242;

	mov.f64 	%fd1295, 0d0000000000000000;
	mov.f64 	%fd1296, 0dBFF0000000000000;
	fma.rn.f64 	%fd1941, %fd1941, %fd1296, %fd1295;

$L__BB7_242:
	mul.rn.f64 	%fd1297, %fd1941, 0d4074000000000000;
	add.rn.f64 	%fd346, %fd333, %fd1297;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r418}, %fd270;
	}
	and.b32  	%r419, %r418, 2147483647;
	setp.eq.s32 	%p244, %r419, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r420, %temp}, %fd270;
	}
	setp.eq.s32 	%p245, %r420, 0;
	and.pred  	%p246, %p245, %p244;
	@%p246 bra 	$L__BB7_245;
	bra.uni 	$L__BB7_243;

$L__BB7_245:
	mov.f64 	%fd1307, 0d0000000000000000;
	mul.rn.f64 	%fd1942, %fd270, %fd1307;
	mov.u32 	%r702, 0;
	bra.uni 	$L__BB7_246;

$L__BB7_243:
	mul.rn.f64 	%fd1298, %fd270, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r702, %fd1298;
	st.local.u32 	[%rd1], %r702;
	cvt.rn.f64.s32 	%fd1299, %r702;
	neg.f64 	%fd1300, %fd1299;
	mov.f64 	%fd1301, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1302, %fd1300, %fd1301, %fd270;
	mov.f64 	%fd1303, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1304, %fd1300, %fd1303, %fd1302;
	mov.f64 	%fd1305, 0d397B839A252049C0;
	fma.rn.f64 	%fd1942, %fd1300, %fd1305, %fd1304;
	abs.f64 	%fd1306, %fd270;
	setp.ltu.f64 	%p247, %fd1306, 0d41E0000000000000;
	@%p247 bra 	$L__BB7_246;

	{ // callseq 140, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd270;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1942, [retval0+0];
	} // callseq 140
	ld.local.u32 	%r702, [%rd1];

$L__BB7_246:
	and.b32  	%r422, %r702, 1;
	shl.b32 	%r423, %r702, 3;
	and.b32  	%r424, %r423, 8;
	setp.eq.s32 	%p248, %r422, 0;
	selp.f64 	%fd1308, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p248;
	mul.wide.s32 	%rd169, %r424, 8;
	add.s64 	%rd171, %rd82, %rd169;
	ld.global.nc.f64 	%fd1309, [%rd171+8];
	mul.rn.f64 	%fd351, %fd1942, %fd1942;
	fma.rn.f64 	%fd1310, %fd1308, %fd351, %fd1309;
	ld.global.nc.f64 	%fd1311, [%rd171+16];
	fma.rn.f64 	%fd1312, %fd1310, %fd351, %fd1311;
	ld.global.nc.f64 	%fd1313, [%rd171+24];
	fma.rn.f64 	%fd1314, %fd1312, %fd351, %fd1313;
	ld.global.nc.f64 	%fd1315, [%rd171+32];
	fma.rn.f64 	%fd1316, %fd1314, %fd351, %fd1315;
	ld.global.nc.f64 	%fd1317, [%rd171+40];
	fma.rn.f64 	%fd1318, %fd1316, %fd351, %fd1317;
	ld.global.nc.f64 	%fd1319, [%rd171+48];
	fma.rn.f64 	%fd352, %fd1318, %fd351, %fd1319;
	fma.rn.f64 	%fd1944, %fd352, %fd1942, %fd1942;
	@%p248 bra 	$L__BB7_248;

	mov.f64 	%fd1320, 0d3FF0000000000000;
	fma.rn.f64 	%fd1944, %fd352, %fd351, %fd1320;

$L__BB7_248:
	and.b32  	%r425, %r702, 2;
	setp.eq.s32 	%p249, %r425, 0;
	@%p249 bra 	$L__BB7_250;

	mov.f64 	%fd1321, 0d0000000000000000;
	mov.f64 	%fd1322, 0dBFF0000000000000;
	fma.rn.f64 	%fd1944, %fd1944, %fd1322, %fd1321;

$L__BB7_250:
	div.rn.f64 	%fd358, %fd270, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r426, %temp}, %fd358;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r427}, %fd358;
	}
	and.b32  	%r428, %r427, 2147483647;
	setp.eq.s32 	%p250, %r428, 2146435072;
	setp.eq.s32 	%p251, %r426, 0;
	and.pred  	%p252, %p251, %p250;
	@%p252 bra 	$L__BB7_253;
	bra.uni 	$L__BB7_251;

$L__BB7_253:
	mov.f64 	%fd1332, 0d0000000000000000;
	mul.rn.f64 	%fd1945, %fd358, %fd1332;
	mov.u32 	%r703, 0;
	bra.uni 	$L__BB7_254;

$L__BB7_251:
	mul.rn.f64 	%fd1323, %fd358, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r703, %fd1323;
	st.local.u32 	[%rd1], %r703;
	cvt.rn.f64.s32 	%fd1324, %r703;
	neg.f64 	%fd1325, %fd1324;
	mov.f64 	%fd1326, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1327, %fd1325, %fd1326, %fd358;
	mov.f64 	%fd1328, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1329, %fd1325, %fd1328, %fd1327;
	mov.f64 	%fd1330, 0d397B839A252049C0;
	fma.rn.f64 	%fd1945, %fd1325, %fd1330, %fd1329;
	abs.f64 	%fd1331, %fd358;
	setp.ltu.f64 	%p253, %fd1331, 0d41E0000000000000;
	@%p253 bra 	$L__BB7_254;

	{ // callseq 141, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd358;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1945, [retval0+0];
	} // callseq 141
	ld.local.u32 	%r703, [%rd1];

$L__BB7_254:
	and.b32  	%r430, %r703, 1;
	shl.b32 	%r431, %r703, 3;
	and.b32  	%r432, %r431, 8;
	setp.eq.s32 	%p254, %r430, 0;
	selp.f64 	%fd1333, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p254;
	mul.wide.s32 	%rd173, %r432, 8;
	add.s64 	%rd175, %rd82, %rd173;
	ld.global.nc.f64 	%fd1334, [%rd175+8];
	mul.rn.f64 	%fd363, %fd1945, %fd1945;
	fma.rn.f64 	%fd1335, %fd1333, %fd363, %fd1334;
	ld.global.nc.f64 	%fd1336, [%rd175+16];
	fma.rn.f64 	%fd1337, %fd1335, %fd363, %fd1336;
	ld.global.nc.f64 	%fd1338, [%rd175+24];
	fma.rn.f64 	%fd1339, %fd1337, %fd363, %fd1338;
	ld.global.nc.f64 	%fd1340, [%rd175+32];
	fma.rn.f64 	%fd1341, %fd1339, %fd363, %fd1340;
	ld.global.nc.f64 	%fd1342, [%rd175+40];
	fma.rn.f64 	%fd1343, %fd1341, %fd363, %fd1342;
	ld.global.nc.f64 	%fd1344, [%rd175+48];
	fma.rn.f64 	%fd364, %fd1343, %fd363, %fd1344;
	fma.rn.f64 	%fd1947, %fd364, %fd1945, %fd1945;
	@%p254 bra 	$L__BB7_256;

	mov.f64 	%fd1345, 0d3FF0000000000000;
	fma.rn.f64 	%fd1947, %fd364, %fd363, %fd1345;

$L__BB7_256:
	and.b32  	%r433, %r703, 2;
	setp.eq.s32 	%p255, %r433, 0;
	@%p255 bra 	$L__BB7_258;

	mov.f64 	%fd1346, 0d0000000000000000;
	mov.f64 	%fd1347, 0dBFF0000000000000;
	fma.rn.f64 	%fd1947, %fd1947, %fd1347, %fd1346;

$L__BB7_258:
	mul.rn.f64 	%fd1348, %fd1947, 0d4044000000000000;
	mul.rn.f64 	%fd1349, %fd1944, 0d4034000000000000;
	add.rn.f64 	%fd370, %fd1349, %fd1348;
	div.rn.f64 	%fd371, %fd270, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r434, %temp}, %fd371;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r435}, %fd371;
	}
	and.b32  	%r436, %r435, 2147483647;
	setp.eq.s32 	%p256, %r436, 2146435072;
	setp.eq.s32 	%p257, %r434, 0;
	and.pred  	%p258, %p257, %p256;
	@%p258 bra 	$L__BB7_261;
	bra.uni 	$L__BB7_259;

$L__BB7_261:
	mov.f64 	%fd1359, 0d0000000000000000;
	mul.rn.f64 	%fd1948, %fd371, %fd1359;
	mov.u32 	%r704, 0;
	bra.uni 	$L__BB7_262;

$L__BB7_259:
	mul.rn.f64 	%fd1350, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r704, %fd1350;
	st.local.u32 	[%rd1], %r704;
	cvt.rn.f64.s32 	%fd1351, %r704;
	neg.f64 	%fd1352, %fd1351;
	mov.f64 	%fd1353, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1354, %fd1352, %fd1353, %fd371;
	mov.f64 	%fd1355, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1356, %fd1352, %fd1355, %fd1354;
	mov.f64 	%fd1357, 0d397B839A252049C0;
	fma.rn.f64 	%fd1948, %fd1352, %fd1357, %fd1356;
	abs.f64 	%fd1358, %fd371;
	setp.ltu.f64 	%p259, %fd1358, 0d41E0000000000000;
	@%p259 bra 	$L__BB7_262;

	{ // callseq 142, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1948, [retval0+0];
	} // callseq 142
	ld.local.u32 	%r704, [%rd1];

$L__BB7_262:
	and.b32  	%r438, %r704, 1;
	shl.b32 	%r439, %r704, 3;
	and.b32  	%r440, %r439, 8;
	setp.eq.s32 	%p260, %r438, 0;
	selp.f64 	%fd1360, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p260;
	mul.wide.s32 	%rd177, %r440, 8;
	add.s64 	%rd179, %rd82, %rd177;
	ld.global.nc.f64 	%fd1361, [%rd179+8];
	mul.rn.f64 	%fd376, %fd1948, %fd1948;
	fma.rn.f64 	%fd1362, %fd1360, %fd376, %fd1361;
	ld.global.nc.f64 	%fd1363, [%rd179+16];
	fma.rn.f64 	%fd1364, %fd1362, %fd376, %fd1363;
	ld.global.nc.f64 	%fd1365, [%rd179+24];
	fma.rn.f64 	%fd1366, %fd1364, %fd376, %fd1365;
	ld.global.nc.f64 	%fd1367, [%rd179+32];
	fma.rn.f64 	%fd1368, %fd1366, %fd376, %fd1367;
	ld.global.nc.f64 	%fd1369, [%rd179+40];
	fma.rn.f64 	%fd1370, %fd1368, %fd376, %fd1369;
	ld.global.nc.f64 	%fd1371, [%rd179+48];
	fma.rn.f64 	%fd377, %fd1370, %fd376, %fd1371;
	fma.rn.f64 	%fd1950, %fd377, %fd1948, %fd1948;
	@%p260 bra 	$L__BB7_264;

	mov.f64 	%fd1372, 0d3FF0000000000000;
	fma.rn.f64 	%fd1950, %fd377, %fd376, %fd1372;

$L__BB7_264:
	and.b32  	%r441, %r704, 2;
	setp.eq.s32 	%p261, %r441, 0;
	@%p261 bra 	$L__BB7_266;

	mov.f64 	%fd1373, 0d0000000000000000;
	mov.f64 	%fd1374, 0dBFF0000000000000;
	fma.rn.f64 	%fd1950, %fd1950, %fd1374, %fd1373;

$L__BB7_266:
	mul.rn.f64 	%fd1375, %fd1950, 0d4062C00000000000;
	add.rn.f64 	%fd383, %fd370, %fd1375;
	div.rn.f64 	%fd384, %fd270, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r442, %temp}, %fd384;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r443}, %fd384;
	}
	and.b32  	%r444, %r443, 2147483647;
	setp.eq.s32 	%p262, %r444, 2146435072;
	setp.eq.s32 	%p263, %r442, 0;
	and.pred  	%p264, %p263, %p262;
	@%p264 bra 	$L__BB7_269;
	bra.uni 	$L__BB7_267;

$L__BB7_269:
	mov.f64 	%fd1385, 0d0000000000000000;
	mul.rn.f64 	%fd1951, %fd384, %fd1385;
	mov.u32 	%r705, 0;
	bra.uni 	$L__BB7_270;

$L__BB7_267:
	mul.rn.f64 	%fd1376, %fd384, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r705, %fd1376;
	st.local.u32 	[%rd1], %r705;
	cvt.rn.f64.s32 	%fd1377, %r705;
	neg.f64 	%fd1378, %fd1377;
	mov.f64 	%fd1379, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1380, %fd1378, %fd1379, %fd384;
	mov.f64 	%fd1381, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1382, %fd1378, %fd1381, %fd1380;
	mov.f64 	%fd1383, 0d397B839A252049C0;
	fma.rn.f64 	%fd1951, %fd1378, %fd1383, %fd1382;
	abs.f64 	%fd1384, %fd384;
	setp.ltu.f64 	%p265, %fd1384, 0d41E0000000000000;
	@%p265 bra 	$L__BB7_270;

	{ // callseq 143, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd384;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1951, [retval0+0];
	} // callseq 143
	ld.local.u32 	%r705, [%rd1];

$L__BB7_270:
	and.b32  	%r446, %r705, 1;
	shl.b32 	%r447, %r705, 3;
	and.b32  	%r448, %r447, 8;
	setp.eq.s32 	%p266, %r446, 0;
	selp.f64 	%fd1386, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p266;
	mul.wide.s32 	%rd181, %r448, 8;
	add.s64 	%rd183, %rd82, %rd181;
	ld.global.nc.f64 	%fd1387, [%rd183+8];
	mul.rn.f64 	%fd389, %fd1951, %fd1951;
	fma.rn.f64 	%fd1388, %fd1386, %fd389, %fd1387;
	ld.global.nc.f64 	%fd1389, [%rd183+16];
	fma.rn.f64 	%fd1390, %fd1388, %fd389, %fd1389;
	ld.global.nc.f64 	%fd1391, [%rd183+24];
	fma.rn.f64 	%fd1392, %fd1390, %fd389, %fd1391;
	ld.global.nc.f64 	%fd1393, [%rd183+32];
	fma.rn.f64 	%fd1394, %fd1392, %fd389, %fd1393;
	ld.global.nc.f64 	%fd1395, [%rd183+40];
	fma.rn.f64 	%fd1396, %fd1394, %fd389, %fd1395;
	ld.global.nc.f64 	%fd1397, [%rd183+48];
	fma.rn.f64 	%fd390, %fd1396, %fd389, %fd1397;
	fma.rn.f64 	%fd1953, %fd390, %fd1951, %fd1951;
	@%p266 bra 	$L__BB7_272;

	mov.f64 	%fd1398, 0d3FF0000000000000;
	fma.rn.f64 	%fd1953, %fd390, %fd389, %fd1398;

$L__BB7_272:
	and.b32  	%r449, %r705, 2;
	setp.eq.s32 	%p267, %r449, 0;
	@%p267 bra 	$L__BB7_274;

	mov.f64 	%fd1399, 0d0000000000000000;
	mov.f64 	%fd1400, 0dBFF0000000000000;
	fma.rn.f64 	%fd1953, %fd1953, %fd1400, %fd1399;

$L__BB7_274:
	mul.rn.f64 	%fd1401, %fd1953, 0d4072C00000000000;
	add.rn.f64 	%fd1402, %fd383, %fd1401;
	add.rn.f64 	%fd396, %fd296, %fd1402;
	add.rn.f64 	%fd397, %fd296, %fd346;
	add.rn.f64 	%fd1403, %fd267, %fd267;
	add.rn.f64 	%fd1404, %fd1403, 0dC059000000000000;
	mul.rn.f64 	%fd1405, %fd266, 0d4008000000000000;
	add.rn.f64 	%fd398, %fd1404, %fd1405;
	abs.f64 	%fd399, %fd266;
	{ // callseq 144, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd399;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1956, [retval0+0];
	} // callseq 144
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd266;
	}
	setp.lt.s32 	%p268, %r99, 0;
	and.pred  	%p7, %p268, %p15;
	not.pred 	%p270, %p7;
	@%p270 bra 	$L__BB7_276;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r450}, %fd1956;
	}
	xor.b32  	%r451, %r450, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r452, %temp}, %fd1956;
	}
	mov.b64 	%fd1956, {%r452, %r451};

$L__BB7_276:
	setp.eq.f64 	%p271, %fd266, 0d0000000000000000;
	@%p271 bra 	$L__BB7_280;
	bra.uni 	$L__BB7_277;

$L__BB7_280:
	setp.lt.s32 	%p274, %r2, 0;
	mov.u32 	%r453, 0;
	selp.b32 	%r454, %r99, 0, %p15;
	or.b32  	%r455, %r454, 2146435072;
	selp.b32 	%r456, %r455, %r454, %p274;
	mov.b64 	%fd1956, {%r453, %r456};
	bra.uni 	$L__BB7_281;

$L__BB7_277:
	setp.gt.s32 	%p272, %r99, -1;
	@%p272 bra 	$L__BB7_281;

	mov.f64 	%fd1406, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1407, %fd1406;
	setp.eq.f64 	%p273, %fd1407, 0d4000000000000000;
	@%p273 bra 	$L__BB7_281;

	mov.f64 	%fd1956, 0dFFF8000000000000;

$L__BB7_281:
	add.rn.f64 	%fd1409, %fd266, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r457}, %fd1409;
	}
	and.b32  	%r458, %r457, 2146435072;
	setp.ne.s32 	%p276, %r458, 2146435072;
	@%p276 bra 	$L__BB7_288;

	setp.gtu.f64 	%p277, %fd399, 0d7FF0000000000000;
	@%p277 bra 	$L__BB7_287;
	bra.uni 	$L__BB7_283;

$L__BB7_287:
	mov.f64 	%fd1411, 0d4000000000000000;
	add.rn.f64 	%fd1956, %fd266, %fd1411;
	bra.uni 	$L__BB7_288;

$L__BB7_283:
	setp.eq.s32 	%p278, %r65, 2146435072;
	mov.f64 	%fd1410, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r459, %temp}, %fd1410;
	}
	setp.eq.s32 	%p279, %r459, 0;
	and.pred  	%p280, %p278, %p279;
	@%p280 bra 	$L__BB7_286;
	bra.uni 	$L__BB7_284;

$L__BB7_286:
	setp.lt.s32 	%p286, %r2, 0;
	mov.u32 	%r464, 0;
	setp.gt.f64 	%p287, %fd399, 0d3FF0000000000000;
	selp.b32 	%r465, 2146435072, 0, %p287;
	xor.b32  	%r466, %r465, 2146435072;
	selp.b32 	%r467, %r466, %r465, %p286;
	setp.eq.f64 	%p288, %fd266, 0dBFF0000000000000;
	selp.b32 	%r468, 1072693248, %r467, %p288;
	mov.b64 	%fd1956, {%r464, %r468};
	bra.uni 	$L__BB7_288;

$L__BB7_284:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r460, %temp}, %fd266;
	}
	and.b32  	%r461, %r99, 2147483647;
	setp.ne.s32 	%p281, %r461, 2146435072;
	setp.ne.s32 	%p282, %r460, 0;
	or.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB7_288;

	setp.ne.s32 	%p284, %r65, 1071644672;
	and.pred  	%p285, %p284, %p7;
	selp.b32 	%r462, %r67, %r66, %p285;
	mov.u32 	%r463, 0;
	mov.b64 	%fd1956, {%r463, %r462};

$L__BB7_288:
	mul.rn.f64 	%fd1412, %fd1956, 0d3FC999999999999A;
	setp.eq.f64 	%p289, %fd266, 0d3FF0000000000000;
	selp.f64 	%fd1413, 0d3FC999999999999A, %fd1412, %p289;
	add.rn.f64 	%fd1414, %fd398, %fd1413;
	mul.rn.f64 	%fd1415, %fd267, %fd266;
	mul.rn.f64 	%fd409, %fd1415, 0d3FB999999999999A;
	add.rn.f64 	%fd1416, %fd409, %fd1414;
	mul.rn.f64 	%fd1417, %fd269, 0d3FC999999999999A;
	add.rn.f64 	%fd1418, %fd1417, %fd1416;
	mul.rn.f64 	%fd1419, %fd397, 0d3FE5555555555555;
	add.rn.f64 	%fd410, %fd1419, %fd1418;
	add.rn.f64 	%fd1420, %fd266, %fd266;
	add.rn.f64 	%fd1421, %fd267, 0d4072C00000000000;
	add.rn.f64 	%fd411, %fd1421, %fd1420;
	{ // callseq 145, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd268;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1959, [retval0+0];
	} // callseq 145
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r100}, %fd267;
	}
	setp.lt.s32 	%p290, %r100, 0;
	and.pred  	%p8, %p290, %p15;
	not.pred 	%p292, %p8;
	@%p292 bra 	$L__BB7_290;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r469}, %fd1959;
	}
	xor.b32  	%r470, %r469, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r471, %temp}, %fd1959;
	}
	mov.b64 	%fd1959, {%r471, %r470};

$L__BB7_290:
	setp.eq.f64 	%p293, %fd267, 0d0000000000000000;
	@%p293 bra 	$L__BB7_294;
	bra.uni 	$L__BB7_291;

$L__BB7_294:
	setp.lt.s32 	%p296, %r2, 0;
	mov.u32 	%r472, 0;
	selp.b32 	%r473, %r100, 0, %p15;
	or.b32  	%r474, %r473, 2146435072;
	selp.b32 	%r475, %r474, %r473, %p296;
	mov.b64 	%fd1959, {%r472, %r475};
	bra.uni 	$L__BB7_295;

$L__BB7_291:
	setp.gt.s32 	%p294, %r100, -1;
	@%p294 bra 	$L__BB7_295;

	mov.f64 	%fd1422, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1423, %fd1422;
	setp.eq.f64 	%p295, %fd1423, 0d4000000000000000;
	@%p295 bra 	$L__BB7_295;

	mov.f64 	%fd1959, 0dFFF8000000000000;

$L__BB7_295:
	add.rn.f64 	%fd1425, %fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r476}, %fd1425;
	}
	and.b32  	%r477, %r476, 2146435072;
	setp.ne.s32 	%p298, %r477, 2146435072;
	@%p298 bra 	$L__BB7_302;

	setp.gtu.f64 	%p299, %fd268, 0d7FF0000000000000;
	@%p299 bra 	$L__BB7_301;
	bra.uni 	$L__BB7_297;

$L__BB7_301:
	mov.f64 	%fd1427, 0d4000000000000000;
	add.rn.f64 	%fd1959, %fd267, %fd1427;
	bra.uni 	$L__BB7_302;

$L__BB7_297:
	setp.eq.s32 	%p300, %r65, 2146435072;
	mov.f64 	%fd1426, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r478, %temp}, %fd1426;
	}
	setp.eq.s32 	%p301, %r478, 0;
	and.pred  	%p302, %p300, %p301;
	@%p302 bra 	$L__BB7_300;
	bra.uni 	$L__BB7_298;

$L__BB7_300:
	setp.lt.s32 	%p308, %r2, 0;
	mov.u32 	%r483, 0;
	setp.gt.f64 	%p309, %fd268, 0d3FF0000000000000;
	selp.b32 	%r484, 2146435072, 0, %p309;
	xor.b32  	%r485, %r484, 2146435072;
	selp.b32 	%r486, %r485, %r484, %p308;
	setp.eq.f64 	%p310, %fd267, 0dBFF0000000000000;
	selp.b32 	%r487, 1072693248, %r486, %p310;
	mov.b64 	%fd1959, {%r483, %r487};
	bra.uni 	$L__BB7_302;

$L__BB7_298:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r479, %temp}, %fd267;
	}
	and.b32  	%r480, %r100, 2147483647;
	setp.ne.s32 	%p303, %r480, 2146435072;
	setp.ne.s32 	%p304, %r479, 0;
	or.pred  	%p305, %p303, %p304;
	@%p305 bra 	$L__BB7_302;

	setp.ne.s32 	%p306, %r65, 1071644672;
	and.pred  	%p307, %p306, %p8;
	selp.b32 	%r481, %r67, %r66, %p307;
	mov.u32 	%r482, 0;
	mov.b64 	%fd1959, {%r482, %r481};

$L__BB7_302:
	mul.rn.f64 	%fd1428, %fd1959, 0d3FB999999999999A;
	setp.eq.f64 	%p311, %fd267, 0d3FF0000000000000;
	selp.f64 	%fd1429, 0d3FB999999999999A, %fd1428, %p311;
	add.rn.f64 	%fd1430, %fd411, %fd1429;
	add.rn.f64 	%fd1431, %fd409, %fd1430;
	mul.rn.f64 	%fd1432, %fd269, 0d3FB999999999999A;
	add.rn.f64 	%fd1433, %fd1432, %fd1431;
	mul.rn.f64 	%fd1434, %fd396, 0d3FE5555555555555;
	add.rn.f64 	%fd421, %fd1434, %fd1433;
	div.rn.f64 	%fd1435, %fd2010, 0d4066800000000000;
	mul.rn.f64 	%fd422, %fd1435, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r488, %temp}, %fd422;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd422;
	}
	and.b32  	%r490, %r489, 2147483647;
	setp.eq.s32 	%p312, %r490, 2146435072;
	setp.eq.s32 	%p313, %r488, 0;
	and.pred  	%p9, %p313, %p312;
	@%p9 bra 	$L__BB7_305;
	bra.uni 	$L__BB7_303;

$L__BB7_305:
	mov.f64 	%fd1445, 0d0000000000000000;
	mul.rn.f64 	%fd1960, %fd422, %fd1445;
	mov.u32 	%r706, 0;
	bra.uni 	$L__BB7_306;

$L__BB7_303:
	mul.rn.f64 	%fd1436, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r706, %fd1436;
	st.local.u32 	[%rd1], %r706;
	cvt.rn.f64.s32 	%fd1437, %r706;
	neg.f64 	%fd1438, %fd1437;
	mov.f64 	%fd1439, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1440, %fd1438, %fd1439, %fd422;
	mov.f64 	%fd1441, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1442, %fd1438, %fd1441, %fd1440;
	mov.f64 	%fd1443, 0d397B839A252049C0;
	fma.rn.f64 	%fd1960, %fd1438, %fd1443, %fd1442;
	abs.f64 	%fd1444, %fd422;
	setp.ltu.f64 	%p314, %fd1444, 0d41E0000000000000;
	@%p314 bra 	$L__BB7_306;

	{ // callseq 146, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1960, [retval0+0];
	} // callseq 146
	ld.local.u32 	%r706, [%rd1];

$L__BB7_306:
	and.b32  	%r492, %r706, 1;
	shl.b32 	%r493, %r706, 3;
	and.b32  	%r494, %r493, 8;
	setp.eq.s32 	%p315, %r492, 0;
	selp.f64 	%fd1446, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p315;
	mul.wide.s32 	%rd185, %r494, 8;
	add.s64 	%rd187, %rd82, %rd185;
	ld.global.nc.f64 	%fd1447, [%rd187+8];
	mul.rn.f64 	%fd427, %fd1960, %fd1960;
	fma.rn.f64 	%fd1448, %fd1446, %fd427, %fd1447;
	ld.global.nc.f64 	%fd1449, [%rd187+16];
	fma.rn.f64 	%fd1450, %fd1448, %fd427, %fd1449;
	ld.global.nc.f64 	%fd1451, [%rd187+24];
	fma.rn.f64 	%fd1452, %fd1450, %fd427, %fd1451;
	ld.global.nc.f64 	%fd1453, [%rd187+32];
	fma.rn.f64 	%fd1454, %fd1452, %fd427, %fd1453;
	ld.global.nc.f64 	%fd1455, [%rd187+40];
	fma.rn.f64 	%fd1456, %fd1454, %fd427, %fd1455;
	ld.global.nc.f64 	%fd1457, [%rd187+48];
	fma.rn.f64 	%fd428, %fd1456, %fd427, %fd1457;
	fma.rn.f64 	%fd1962, %fd428, %fd1960, %fd1960;
	@%p315 bra 	$L__BB7_308;

	mov.f64 	%fd1458, 0d3FF0000000000000;
	fma.rn.f64 	%fd1962, %fd428, %fd427, %fd1458;

$L__BB7_308:
	and.b32  	%r495, %r706, 2;
	setp.eq.s32 	%p316, %r495, 0;
	@%p316 bra 	$L__BB7_310;

	mov.f64 	%fd1459, 0d0000000000000000;
	mov.f64 	%fd1460, 0dBFF0000000000000;
	fma.rn.f64 	%fd1962, %fd1962, %fd1460, %fd1459;

$L__BB7_310:
	@%p9 bra 	$L__BB7_314;
	bra.uni 	$L__BB7_311;

$L__BB7_314:
	mov.f64 	%fd1470, 0d0000000000000000;
	mul.rn.f64 	%fd1964, %fd422, %fd1470;
	mov.u32 	%r708, 1;
	bra.uni 	$L__BB7_315;

$L__BB7_311:
	mul.rn.f64 	%fd1461, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r707, %fd1461;
	st.local.u32 	[%rd1], %r707;
	cvt.rn.f64.s32 	%fd1462, %r707;
	neg.f64 	%fd1463, %fd1462;
	mov.f64 	%fd1464, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1465, %fd1463, %fd1464, %fd422;
	mov.f64 	%fd1466, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1467, %fd1463, %fd1466, %fd1465;
	mov.f64 	%fd1468, 0d397B839A252049C0;
	fma.rn.f64 	%fd1964, %fd1463, %fd1468, %fd1467;
	abs.f64 	%fd1469, %fd422;
	setp.ltu.f64 	%p317, %fd1469, 0d41E0000000000000;
	@%p317 bra 	$L__BB7_313;

	{ // callseq 147, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1964, [retval0+0];
	} // callseq 147
	ld.local.u32 	%r707, [%rd1];

$L__BB7_313:
	add.s32 	%r708, %r707, 1;

$L__BB7_315:
	and.b32  	%r497, %r708, 1;
	shl.b32 	%r498, %r708, 3;
	and.b32  	%r499, %r498, 8;
	setp.eq.s32 	%p318, %r497, 0;
	selp.f64 	%fd1471, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p318;
	mul.wide.s32 	%rd189, %r499, 8;
	add.s64 	%rd191, %rd82, %rd189;
	ld.global.nc.f64 	%fd1472, [%rd191+8];
	mul.rn.f64 	%fd439, %fd1964, %fd1964;
	fma.rn.f64 	%fd1473, %fd1471, %fd439, %fd1472;
	ld.global.nc.f64 	%fd1474, [%rd191+16];
	fma.rn.f64 	%fd1475, %fd1473, %fd439, %fd1474;
	ld.global.nc.f64 	%fd1476, [%rd191+24];
	fma.rn.f64 	%fd1477, %fd1475, %fd439, %fd1476;
	ld.global.nc.f64 	%fd1478, [%rd191+32];
	fma.rn.f64 	%fd1479, %fd1477, %fd439, %fd1478;
	ld.global.nc.f64 	%fd1480, [%rd191+40];
	fma.rn.f64 	%fd1481, %fd1479, %fd439, %fd1480;
	ld.global.nc.f64 	%fd1482, [%rd191+48];
	fma.rn.f64 	%fd440, %fd1481, %fd439, %fd1482;
	fma.rn.f64 	%fd1966, %fd440, %fd1964, %fd1964;
	@%p318 bra 	$L__BB7_317;

	mov.f64 	%fd1483, 0d3FF0000000000000;
	fma.rn.f64 	%fd1966, %fd440, %fd439, %fd1483;

$L__BB7_317:
	and.b32  	%r500, %r708, 2;
	setp.eq.s32 	%p319, %r500, 0;
	@%p319 bra 	$L__BB7_319;

	mov.f64 	%fd1484, 0d0000000000000000;
	mov.f64 	%fd1485, 0dBFF0000000000000;
	fma.rn.f64 	%fd1966, %fd1966, %fd1485, %fd1484;

$L__BB7_319:
	mul.rn.f64 	%fd1486, %fd1962, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1487, %fd1962, %fd1486;
	add.rn.f64 	%fd1488, %fd1487, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1489, %fd1488;
	mov.f64 	%fd1490, 0d415854C140000000;
	div.rn.f64 	%fd1491, %fd1490, %fd1489;
	mul.rn.f64 	%fd1492, %fd1491, %fd1966;
	mul.rn.f64 	%fd1493, %fd1492, 0d400921FB54442D18;
	mul.rn.f64 	%fd1494, %fd421, 0d4066800000000000;
	div.rn.f64 	%fd1495, %fd1494, %fd1493;
	add.rn.f64 	%fd446, %fd2009, %fd1495;
	mul.rn.f64 	%fd1496, %fd410, 0d4066800000000000;
	mul.rn.f64 	%fd1497, %fd1489, %fd1488;
	mov.f64 	%fd1498, 0d41582B102DE355C1;
	div.rn.f64 	%fd1499, %fd1498, %fd1497;
	mul.rn.f64 	%fd1500, %fd1499, 0d400921FB54442D18;
	div.rn.f64 	%fd1501, %fd1496, %fd1500;
	add.rn.f64 	%fd447, %fd2010, %fd1501;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd446;
	}
	abs.f64 	%fd448, %fd446;
	{ // callseq 148, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd448;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1969, [retval0+0];
	} // callseq 148
	setp.lt.s32 	%p320, %r109, 0;
	and.pred  	%p10, %p320, %p15;
	not.pred 	%p322, %p10;
	@%p322 bra 	$L__BB7_321;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r501}, %fd1969;
	}
	xor.b32  	%r502, %r501, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r503, %temp}, %fd1969;
	}
	mov.b64 	%fd1969, {%r503, %r502};

$L__BB7_321:
	setp.eq.f64 	%p323, %fd446, 0d0000000000000000;
	@%p323 bra 	$L__BB7_325;
	bra.uni 	$L__BB7_322;

$L__BB7_325:
	setp.lt.s32 	%p326, %r2, 0;
	mov.u32 	%r504, 0;
	selp.b32 	%r505, %r109, 0, %p15;
	or.b32  	%r506, %r505, 2146435072;
	selp.b32 	%r507, %r506, %r505, %p326;
	mov.b64 	%fd1969, {%r504, %r507};
	bra.uni 	$L__BB7_326;

$L__BB7_322:
	setp.gt.s32 	%p324, %r109, -1;
	@%p324 bra 	$L__BB7_326;

	mov.f64 	%fd1502, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1503, %fd1502;
	setp.eq.f64 	%p325, %fd1503, 0d4000000000000000;
	@%p325 bra 	$L__BB7_326;

	mov.f64 	%fd1969, 0dFFF8000000000000;

$L__BB7_326:
	add.rn.f64 	%fd1505, %fd446, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r508}, %fd1505;
	}
	and.b32  	%r509, %r508, 2146435072;
	setp.ne.s32 	%p328, %r509, 2146435072;
	@%p328 bra 	$L__BB7_333;

	setp.gtu.f64 	%p329, %fd448, 0d7FF0000000000000;
	@%p329 bra 	$L__BB7_332;
	bra.uni 	$L__BB7_328;

$L__BB7_332:
	mov.f64 	%fd1507, 0d4000000000000000;
	add.rn.f64 	%fd1969, %fd446, %fd1507;
	bra.uni 	$L__BB7_333;

$L__BB7_328:
	setp.eq.s32 	%p330, %r65, 2146435072;
	mov.f64 	%fd1506, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r510, %temp}, %fd1506;
	}
	setp.eq.s32 	%p331, %r510, 0;
	and.pred  	%p332, %p330, %p331;
	@%p332 bra 	$L__BB7_331;
	bra.uni 	$L__BB7_329;

$L__BB7_331:
	setp.lt.s32 	%p338, %r2, 0;
	mov.u32 	%r515, 0;
	setp.gt.f64 	%p339, %fd448, 0d3FF0000000000000;
	selp.b32 	%r516, 2146435072, 0, %p339;
	xor.b32  	%r517, %r516, 2146435072;
	selp.b32 	%r518, %r517, %r516, %p338;
	setp.eq.f64 	%p340, %fd446, 0dBFF0000000000000;
	selp.b32 	%r519, 1072693248, %r518, %p340;
	mov.b64 	%fd1969, {%r515, %r519};
	bra.uni 	$L__BB7_333;

$L__BB7_329:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r511, %temp}, %fd446;
	}
	and.b32  	%r512, %r109, 2147483647;
	setp.ne.s32 	%p333, %r512, 2146435072;
	setp.ne.s32 	%p334, %r511, 0;
	or.pred  	%p335, %p333, %p334;
	@%p335 bra 	$L__BB7_333;

	setp.ne.s32 	%p336, %r65, 1071644672;
	and.pred  	%p337, %p336, %p10;
	selp.b32 	%r513, %r67, %r66, %p337;
	mov.u32 	%r514, 0;
	mov.b64 	%fd1969, {%r514, %r513};

$L__BB7_333:
	abs.f64 	%fd458, %fd447;
	{ // callseq 149, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd458;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1972, [retval0+0];
	} // callseq 149
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd447;
	}
	setp.lt.s32 	%p341, %r110, 0;
	and.pred  	%p11, %p341, %p15;
	not.pred 	%p343, %p11;
	@%p343 bra 	$L__BB7_335;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r520}, %fd1972;
	}
	xor.b32  	%r521, %r520, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r522, %temp}, %fd1972;
	}
	mov.b64 	%fd1972, {%r522, %r521};

$L__BB7_335:
	setp.eq.f64 	%p344, %fd447, 0d0000000000000000;
	@%p344 bra 	$L__BB7_339;
	bra.uni 	$L__BB7_336;

$L__BB7_339:
	setp.lt.s32 	%p347, %r2, 0;
	mov.u32 	%r523, 0;
	selp.b32 	%r524, %r110, 0, %p15;
	or.b32  	%r525, %r524, 2146435072;
	selp.b32 	%r526, %r525, %r524, %p347;
	mov.b64 	%fd1972, {%r523, %r526};
	bra.uni 	$L__BB7_340;

$L__BB7_336:
	setp.gt.s32 	%p345, %r110, -1;
	@%p345 bra 	$L__BB7_340;

	mov.f64 	%fd1508, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1509, %fd1508;
	setp.eq.f64 	%p346, %fd1509, 0d4000000000000000;
	@%p346 bra 	$L__BB7_340;

	mov.f64 	%fd1972, 0dFFF8000000000000;

$L__BB7_340:
	add.rn.f64 	%fd1511, %fd447, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r527}, %fd1511;
	}
	and.b32  	%r528, %r527, 2146435072;
	setp.ne.s32 	%p349, %r528, 2146435072;
	@%p349 bra 	$L__BB7_347;

	setp.gtu.f64 	%p350, %fd458, 0d7FF0000000000000;
	@%p350 bra 	$L__BB7_346;
	bra.uni 	$L__BB7_342;

$L__BB7_346:
	mov.f64 	%fd1513, 0d4000000000000000;
	add.rn.f64 	%fd1972, %fd447, %fd1513;
	bra.uni 	$L__BB7_347;

$L__BB7_342:
	setp.eq.s32 	%p351, %r65, 2146435072;
	mov.f64 	%fd1512, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r529, %temp}, %fd1512;
	}
	setp.eq.s32 	%p352, %r529, 0;
	and.pred  	%p353, %p351, %p352;
	@%p353 bra 	$L__BB7_345;
	bra.uni 	$L__BB7_343;

$L__BB7_345:
	setp.lt.s32 	%p359, %r2, 0;
	mov.u32 	%r534, 0;
	setp.gt.f64 	%p360, %fd458, 0d3FF0000000000000;
	selp.b32 	%r535, 2146435072, 0, %p360;
	xor.b32  	%r536, %r535, 2146435072;
	selp.b32 	%r537, %r536, %r535, %p359;
	setp.eq.f64 	%p361, %fd447, 0dBFF0000000000000;
	selp.b32 	%r538, 1072693248, %r537, %p361;
	mov.b64 	%fd1972, {%r534, %r538};
	bra.uni 	$L__BB7_347;

$L__BB7_343:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r530, %temp}, %fd447;
	}
	and.b32  	%r531, %r110, 2147483647;
	setp.ne.s32 	%p354, %r531, 2146435072;
	setp.ne.s32 	%p355, %r530, 0;
	or.pred  	%p356, %p354, %p355;
	@%p356 bra 	$L__BB7_347;

	setp.ne.s32 	%p357, %r65, 1071644672;
	and.pred  	%p358, %p357, %p11;
	selp.b32 	%r532, %r67, %r66, %p358;
	mov.u32 	%r533, 0;
	mov.b64 	%fd1972, {%r533, %r532};

$L__BB7_347:
	setp.eq.f64 	%p362, %fd447, 0d3FF0000000000000;
	selp.f64 	%fd1514, 0d3FF0000000000000, %fd1972, %p362;
	setp.eq.f64 	%p363, %fd446, 0d3FF0000000000000;
	selp.f64 	%fd1515, 0d3FF0000000000000, %fd1969, %p363;
	add.rn.f64 	%fd468, %fd1515, %fd1514;
	mul.rn.f64 	%fd469, %fd447, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r539, %temp}, %fd469;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r540}, %fd469;
	}
	and.b32  	%r541, %r540, 2147483647;
	setp.eq.s32 	%p364, %r541, 2146435072;
	setp.eq.s32 	%p365, %r539, 0;
	and.pred  	%p366, %p365, %p364;
	@%p366 bra 	$L__BB7_350;
	bra.uni 	$L__BB7_348;

$L__BB7_350:
	mov.f64 	%fd1525, 0d0000000000000000;
	mul.rn.f64 	%fd1973, %fd469, %fd1525;
	mov.u32 	%r709, 0;
	bra.uni 	$L__BB7_351;

$L__BB7_348:
	mul.rn.f64 	%fd1516, %fd469, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r709, %fd1516;
	st.local.u32 	[%rd1], %r709;
	cvt.rn.f64.s32 	%fd1517, %r709;
	neg.f64 	%fd1518, %fd1517;
	mov.f64 	%fd1519, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1520, %fd1518, %fd1519, %fd469;
	mov.f64 	%fd1521, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1522, %fd1518, %fd1521, %fd1520;
	mov.f64 	%fd1523, 0d397B839A252049C0;
	fma.rn.f64 	%fd1973, %fd1518, %fd1523, %fd1522;
	abs.f64 	%fd1524, %fd469;
	setp.ltu.f64 	%p367, %fd1524, 0d41E0000000000000;
	@%p367 bra 	$L__BB7_351;

	{ // callseq 150, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd469;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1973, [retval0+0];
	} // callseq 150
	ld.local.u32 	%r709, [%rd1];

$L__BB7_351:
	and.b32  	%r543, %r709, 1;
	shl.b32 	%r544, %r709, 3;
	and.b32  	%r545, %r544, 8;
	setp.eq.s32 	%p368, %r543, 0;
	selp.f64 	%fd1526, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p368;
	mul.wide.s32 	%rd193, %r545, 8;
	add.s64 	%rd195, %rd82, %rd193;
	ld.global.nc.f64 	%fd1527, [%rd195+8];
	mul.rn.f64 	%fd474, %fd1973, %fd1973;
	fma.rn.f64 	%fd1528, %fd1526, %fd474, %fd1527;
	ld.global.nc.f64 	%fd1529, [%rd195+16];
	fma.rn.f64 	%fd1530, %fd1528, %fd474, %fd1529;
	ld.global.nc.f64 	%fd1531, [%rd195+24];
	fma.rn.f64 	%fd1532, %fd1530, %fd474, %fd1531;
	ld.global.nc.f64 	%fd1533, [%rd195+32];
	fma.rn.f64 	%fd1534, %fd1532, %fd474, %fd1533;
	ld.global.nc.f64 	%fd1535, [%rd195+40];
	fma.rn.f64 	%fd1536, %fd1534, %fd474, %fd1535;
	ld.global.nc.f64 	%fd1537, [%rd195+48];
	fma.rn.f64 	%fd475, %fd1536, %fd474, %fd1537;
	fma.rn.f64 	%fd1975, %fd475, %fd1973, %fd1973;
	@%p368 bra 	$L__BB7_353;

	mov.f64 	%fd1538, 0d3FF0000000000000;
	fma.rn.f64 	%fd1975, %fd475, %fd474, %fd1538;

$L__BB7_353:
	and.b32  	%r546, %r709, 2;
	setp.eq.s32 	%p369, %r546, 0;
	@%p369 bra 	$L__BB7_355;

	mov.f64 	%fd1539, 0d0000000000000000;
	mov.f64 	%fd1540, 0dBFF0000000000000;
	fma.rn.f64 	%fd1975, %fd1975, %fd1540, %fd1539;

$L__BB7_355:
	mul.rn.f64 	%fd1541, %fd1975, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd1542, %fd468;
	add.rn.f64 	%fd481, %fd1542, %fd1541;
	setp.eq.f64 	%p370, %fd458, 0d0000000000000000;
	setp.eq.f64 	%p371, %fd448, 0d0000000000000000;
	and.pred  	%p372, %p371, %p370;
	@%p372 bra 	$L__BB7_359;
	bra.uni 	$L__BB7_356;

$L__BB7_359:
	selp.f64 	%fd1595, 0d400921FB54442D18, 0d0000000000000000, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r555, %temp}, %fd1595;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r556}, %fd1595;
	}
	and.b32  	%r557, %r110, -2147483648;
	or.b32  	%r558, %r556, %r557;
	mov.b64 	%fd1976, {%r555, %r558};
	bra.uni 	$L__BB7_360;

$L__BB7_356:
	setp.eq.f64 	%p373, %fd448, 0d7FF0000000000000;
	setp.eq.f64 	%p374, %fd458, 0d7FF0000000000000;
	and.pred  	%p375, %p373, %p374;
	@%p375 bra 	$L__BB7_358;
	bra.uni 	$L__BB7_357;

$L__BB7_358:
	selp.f64 	%fd1594, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r551, %temp}, %fd1594;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r552}, %fd1594;
	}
	and.b32  	%r553, %r110, -2147483648;
	or.b32  	%r554, %r552, %r553;
	mov.b64 	%fd1976, {%r551, %r554};
	bra.uni 	$L__BB7_360;

$L__BB7_357:
	min.f64 	%fd1543, %fd458, %fd448;
	max.f64 	%fd1544, %fd458, %fd448;
	div.rn.f64 	%fd1545, %fd1543, %fd1544;
	mul.rn.f64 	%fd1546, %fd1545, %fd1545;
	mov.f64 	%fd1547, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1548, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1549, %fd1548, %fd1546, %fd1547;
	mov.f64 	%fd1550, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1551, %fd1549, %fd1546, %fd1550;
	mov.f64 	%fd1552, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1553, %fd1551, %fd1546, %fd1552;
	mov.f64 	%fd1554, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1555, %fd1553, %fd1546, %fd1554;
	mov.f64 	%fd1556, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1557, %fd1555, %fd1546, %fd1556;
	mov.f64 	%fd1558, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1559, %fd1557, %fd1546, %fd1558;
	mov.f64 	%fd1560, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1561, %fd1559, %fd1546, %fd1560;
	mov.f64 	%fd1562, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1563, %fd1561, %fd1546, %fd1562;
	mov.f64 	%fd1564, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1565, %fd1563, %fd1546, %fd1564;
	mov.f64 	%fd1566, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1567, %fd1565, %fd1546, %fd1566;
	mov.f64 	%fd1568, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1569, %fd1567, %fd1546, %fd1568;
	mov.f64 	%fd1570, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1571, %fd1569, %fd1546, %fd1570;
	mov.f64 	%fd1572, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1573, %fd1571, %fd1546, %fd1572;
	mov.f64 	%fd1574, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1575, %fd1573, %fd1546, %fd1574;
	mov.f64 	%fd1576, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1577, %fd1575, %fd1546, %fd1576;
	mov.f64 	%fd1578, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1579, %fd1577, %fd1546, %fd1578;
	mov.f64 	%fd1580, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1581, %fd1579, %fd1546, %fd1580;
	mov.f64 	%fd1582, 0dBFD555555555544C;
	fma.rn.f64 	%fd1583, %fd1581, %fd1546, %fd1582;
	mul.rn.f64 	%fd1584, %fd1546, %fd1583;
	fma.rn.f64 	%fd1585, %fd1584, %fd1545, %fd1545;
	mov.f64 	%fd1586, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1587, %fd1586, %fd1585;
	setp.gt.f64 	%p377, %fd458, %fd448;
	selp.f64 	%fd1588, %fd1587, %fd1585, %p377;
	mov.f64 	%fd1589, 0d400921FB54442D18;
	sub.rn.f64 	%fd1590, %fd1589, %fd1588;
	selp.f64 	%fd1591, %fd1590, %fd1588, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r547, %temp}, %fd1591;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r548}, %fd1591;
	}
	and.b32  	%r549, %r110, -2147483648;
	or.b32  	%r550, %r548, %r549;
	mov.b64 	%fd1592, {%r547, %r550};
	add.rn.f64 	%fd1593, %fd448, %fd458;
	setp.le.f64 	%p378, %fd1593, 0d7FF0000000000000;
	selp.f64 	%fd1976, %fd1592, %fd1593, %p378;

$L__BB7_360:
	mul.rn.f64 	%fd486, %fd446, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r559, %temp}, %fd486;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r560}, %fd486;
	}
	and.b32  	%r561, %r560, 2147483647;
	setp.eq.s32 	%p381, %r561, 2146435072;
	setp.eq.s32 	%p382, %r559, 0;
	and.pred  	%p383, %p382, %p381;
	@%p383 bra 	$L__BB7_364;
	bra.uni 	$L__BB7_361;

$L__BB7_364:
	mov.f64 	%fd1605, 0d0000000000000000;
	mul.rn.f64 	%fd1978, %fd486, %fd1605;
	mov.u32 	%r711, 1;
	bra.uni 	$L__BB7_365;

$L__BB7_361:
	mul.rn.f64 	%fd1596, %fd486, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r710, %fd1596;
	st.local.u32 	[%rd1], %r710;
	cvt.rn.f64.s32 	%fd1597, %r710;
	neg.f64 	%fd1598, %fd1597;
	mov.f64 	%fd1599, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1600, %fd1598, %fd1599, %fd486;
	mov.f64 	%fd1601, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1602, %fd1598, %fd1601, %fd1600;
	mov.f64 	%fd1603, 0d397B839A252049C0;
	fma.rn.f64 	%fd1978, %fd1598, %fd1603, %fd1602;
	abs.f64 	%fd1604, %fd486;
	setp.ltu.f64 	%p384, %fd1604, 0d41E0000000000000;
	@%p384 bra 	$L__BB7_363;

	{ // callseq 151, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd486;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1978, [retval0+0];
	} // callseq 151
	ld.local.u32 	%r710, [%rd1];

$L__BB7_363:
	add.s32 	%r711, %r710, 1;

$L__BB7_365:
	and.b32  	%r563, %r711, 1;
	shl.b32 	%r564, %r711, 3;
	and.b32  	%r565, %r564, 8;
	setp.eq.s32 	%p385, %r563, 0;
	selp.f64 	%fd1606, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p385;
	mul.wide.s32 	%rd197, %r565, 8;
	add.s64 	%rd199, %rd82, %rd197;
	ld.global.nc.f64 	%fd1607, [%rd199+8];
	mul.rn.f64 	%fd492, %fd1978, %fd1978;
	fma.rn.f64 	%fd1608, %fd1606, %fd492, %fd1607;
	ld.global.nc.f64 	%fd1609, [%rd199+16];
	fma.rn.f64 	%fd1610, %fd1608, %fd492, %fd1609;
	ld.global.nc.f64 	%fd1611, [%rd199+24];
	fma.rn.f64 	%fd1612, %fd1610, %fd492, %fd1611;
	ld.global.nc.f64 	%fd1613, [%rd199+32];
	fma.rn.f64 	%fd1614, %fd1612, %fd492, %fd1613;
	ld.global.nc.f64 	%fd1615, [%rd199+40];
	fma.rn.f64 	%fd1616, %fd1614, %fd492, %fd1615;
	ld.global.nc.f64 	%fd1617, [%rd199+48];
	fma.rn.f64 	%fd493, %fd1616, %fd492, %fd1617;
	fma.rn.f64 	%fd1980, %fd493, %fd1978, %fd1978;
	@%p385 bra 	$L__BB7_367;

	mov.f64 	%fd1618, 0d3FF0000000000000;
	fma.rn.f64 	%fd1980, %fd493, %fd492, %fd1618;

$L__BB7_367:
	and.b32  	%r566, %r711, 2;
	setp.eq.s32 	%p386, %r566, 0;
	@%p386 bra 	$L__BB7_369;

	mov.f64 	%fd1619, 0d0000000000000000;
	mov.f64 	%fd1620, 0dBFF0000000000000;
	fma.rn.f64 	%fd1980, %fd1980, %fd1620, %fd1619;

$L__BB7_369:
	mul.rn.f64 	%fd1621, %fd1980, 0d3EC92A737110E454;
	add.rn.f64 	%fd499, %fd1976, %fd1621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r567, %temp}, %fd499;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r568}, %fd499;
	}
	and.b32  	%r569, %r568, 2147483647;
	setp.eq.s32 	%p387, %r569, 2146435072;
	setp.eq.s32 	%p388, %r567, 0;
	and.pred  	%p12, %p388, %p387;
	@%p12 bra 	$L__BB7_373;
	bra.uni 	$L__BB7_370;

$L__BB7_373:
	mov.f64 	%fd1631, 0d0000000000000000;
	mul.rn.f64 	%fd1982, %fd499, %fd1631;
	mov.u32 	%r713, 1;
	bra.uni 	$L__BB7_374;

$L__BB7_370:
	mul.rn.f64 	%fd1622, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r712, %fd1622;
	st.local.u32 	[%rd1], %r712;
	cvt.rn.f64.s32 	%fd1623, %r712;
	neg.f64 	%fd1624, %fd1623;
	mov.f64 	%fd1625, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1626, %fd1624, %fd1625, %fd499;
	mov.f64 	%fd1627, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1628, %fd1624, %fd1627, %fd1626;
	mov.f64 	%fd1629, 0d397B839A252049C0;
	fma.rn.f64 	%fd1982, %fd1624, %fd1629, %fd1628;
	abs.f64 	%fd1630, %fd499;
	setp.ltu.f64 	%p389, %fd1630, 0d41E0000000000000;
	@%p389 bra 	$L__BB7_372;

	{ // callseq 152, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1982, [retval0+0];
	} // callseq 152
	ld.local.u32 	%r712, [%rd1];

$L__BB7_372:
	add.s32 	%r713, %r712, 1;

$L__BB7_374:
	and.b32  	%r571, %r713, 1;
	shl.b32 	%r572, %r713, 3;
	and.b32  	%r573, %r572, 8;
	setp.eq.s32 	%p390, %r571, 0;
	selp.f64 	%fd1632, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p390;
	mul.wide.s32 	%rd201, %r573, 8;
	add.s64 	%rd203, %rd82, %rd201;
	ld.global.nc.f64 	%fd1633, [%rd203+8];
	mul.rn.f64 	%fd505, %fd1982, %fd1982;
	fma.rn.f64 	%fd1634, %fd1632, %fd505, %fd1633;
	ld.global.nc.f64 	%fd1635, [%rd203+16];
	fma.rn.f64 	%fd1636, %fd1634, %fd505, %fd1635;
	ld.global.nc.f64 	%fd1637, [%rd203+24];
	fma.rn.f64 	%fd1638, %fd1636, %fd505, %fd1637;
	ld.global.nc.f64 	%fd1639, [%rd203+32];
	fma.rn.f64 	%fd1640, %fd1638, %fd505, %fd1639;
	ld.global.nc.f64 	%fd1641, [%rd203+40];
	fma.rn.f64 	%fd1642, %fd1640, %fd505, %fd1641;
	ld.global.nc.f64 	%fd1643, [%rd203+48];
	fma.rn.f64 	%fd506, %fd1642, %fd505, %fd1643;
	fma.rn.f64 	%fd1984, %fd506, %fd1982, %fd1982;
	@%p390 bra 	$L__BB7_376;

	mov.f64 	%fd1644, 0d3FF0000000000000;
	fma.rn.f64 	%fd1984, %fd506, %fd505, %fd1644;

$L__BB7_376:
	and.b32  	%r574, %r713, 2;
	setp.eq.s32 	%p391, %r574, 0;
	@%p391 bra 	$L__BB7_378;

	mov.f64 	%fd1645, 0d0000000000000000;
	mov.f64 	%fd1646, 0dBFF0000000000000;
	fma.rn.f64 	%fd1984, %fd1984, %fd1646, %fd1645;

$L__BB7_378:
	mul.rn.f64 	%fd1647, %fd481, %fd1984;
	add.rn.f64 	%fd512, %fd1647, 0d3F7A9FBE76C8B439;
	@%p12 bra 	$L__BB7_381;
	bra.uni 	$L__BB7_379;

$L__BB7_381:
	mov.f64 	%fd1657, 0d0000000000000000;
	mul.rn.f64 	%fd1985, %fd499, %fd1657;
	mov.u32 	%r714, 0;
	bra.uni 	$L__BB7_382;

$L__BB7_379:
	mul.rn.f64 	%fd1648, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r714, %fd1648;
	st.local.u32 	[%rd1], %r714;
	cvt.rn.f64.s32 	%fd1649, %r714;
	neg.f64 	%fd1650, %fd1649;
	mov.f64 	%fd1651, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1652, %fd1650, %fd1651, %fd499;
	mov.f64 	%fd1653, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1654, %fd1650, %fd1653, %fd1652;
	mov.f64 	%fd1655, 0d397B839A252049C0;
	fma.rn.f64 	%fd1985, %fd1650, %fd1655, %fd1654;
	abs.f64 	%fd1656, %fd499;
	setp.ltu.f64 	%p392, %fd1656, 0d41E0000000000000;
	@%p392 bra 	$L__BB7_382;

	{ // callseq 153, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1985, [retval0+0];
	} // callseq 153
	ld.local.u32 	%r714, [%rd1];

$L__BB7_382:
	and.b32  	%r576, %r714, 1;
	shl.b32 	%r577, %r714, 3;
	and.b32  	%r578, %r577, 8;
	setp.eq.s32 	%p393, %r576, 0;
	selp.f64 	%fd1658, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p393;
	mul.wide.s32 	%rd205, %r578, 8;
	add.s64 	%rd207, %rd82, %rd205;
	ld.global.nc.f64 	%fd1659, [%rd207+8];
	mul.rn.f64 	%fd517, %fd1985, %fd1985;
	fma.rn.f64 	%fd1660, %fd1658, %fd517, %fd1659;
	ld.global.nc.f64 	%fd1661, [%rd207+16];
	fma.rn.f64 	%fd1662, %fd1660, %fd517, %fd1661;
	ld.global.nc.f64 	%fd1663, [%rd207+24];
	fma.rn.f64 	%fd1664, %fd1662, %fd517, %fd1663;
	ld.global.nc.f64 	%fd1665, [%rd207+32];
	fma.rn.f64 	%fd1666, %fd1664, %fd517, %fd1665;
	ld.global.nc.f64 	%fd1667, [%rd207+40];
	fma.rn.f64 	%fd1668, %fd1666, %fd517, %fd1667;
	ld.global.nc.f64 	%fd1669, [%rd207+48];
	fma.rn.f64 	%fd518, %fd1668, %fd517, %fd1669;
	fma.rn.f64 	%fd1987, %fd518, %fd1985, %fd1985;
	@%p393 bra 	$L__BB7_384;

	mov.f64 	%fd1670, 0d3FF0000000000000;
	fma.rn.f64 	%fd1987, %fd518, %fd517, %fd1670;

$L__BB7_384:
	and.b32  	%r579, %r714, 2;
	setp.eq.s32 	%p394, %r579, 0;
	@%p394 bra 	$L__BB7_386;

	mov.f64 	%fd1671, 0d0000000000000000;
	mov.f64 	%fd1672, 0dBFF0000000000000;
	fma.rn.f64 	%fd1987, %fd1987, %fd1672, %fd1671;

$L__BB7_386:
	ld.param.s8 	%rs2, [bd09_to_wgs84_exact_cuda_param_3];
	mul.rn.f64 	%fd1673, %fd481, %fd1987;
	add.rn.f64 	%fd1674, %fd1673, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd524, %fd3, %fd1674;
	sub.rn.f64 	%fd525, %fd1, %fd512;
	add.rn.f64 	%fd1923, %fd2009, %fd525;
	add.rn.f64 	%fd1922, %fd2010, %fd524;
	setp.eq.s16 	%p395, %rs2, 0;
	@%p395 bra 	$L__BB7_455;

	mul.rn.f64 	%fd1675, %fd2010, 0d400921FB54442D18;
	div.rn.f64 	%fd528, %fd1675, 0d4066800000000000;
	mul.rn.f64 	%fd1676, %fd1922, 0d400921FB54442D18;
	div.rn.f64 	%fd529, %fd1676, 0d4066800000000000;
	sub.rn.f64 	%fd1677, %fd529, %fd528;
	mul.rn.f64 	%fd530, %fd1677, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r580, %temp}, %fd530;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r581}, %fd530;
	}
	and.b32  	%r582, %r581, 2147483647;
	setp.eq.s32 	%p396, %r582, 2146435072;
	setp.eq.s32 	%p397, %r580, 0;
	and.pred  	%p398, %p397, %p396;
	@%p398 bra 	$L__BB7_390;
	bra.uni 	$L__BB7_388;

$L__BB7_390:
	mov.f64 	%fd1687, 0d0000000000000000;
	mul.rn.f64 	%fd1988, %fd530, %fd1687;
	mov.u32 	%r715, 0;
	bra.uni 	$L__BB7_391;

$L__BB7_455:
	abs.f64 	%fd1855, %fd525;
	setp.geu.f64 	%p476, %fd1855, %fd610;
	@%p476 bra 	$L__BB7_457;

	abs.f64 	%fd1856, %fd524;
	setp.lt.f64 	%p477, %fd1856, %fd610;
	@%p477 bra 	$L__BB7_458;
	bra.uni 	$L__BB7_457;

$L__BB7_388:
	mul.rn.f64 	%fd1678, %fd530, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r715, %fd1678;
	st.local.u32 	[%rd1], %r715;
	cvt.rn.f64.s32 	%fd1679, %r715;
	neg.f64 	%fd1680, %fd1679;
	mov.f64 	%fd1681, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1682, %fd1680, %fd1681, %fd530;
	mov.f64 	%fd1683, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1684, %fd1680, %fd1683, %fd1682;
	mov.f64 	%fd1685, 0d397B839A252049C0;
	fma.rn.f64 	%fd1988, %fd1680, %fd1685, %fd1684;
	abs.f64 	%fd1686, %fd530;
	setp.ltu.f64 	%p399, %fd1686, 0d41E0000000000000;
	@%p399 bra 	$L__BB7_391;

	{ // callseq 154, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd530;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1988, [retval0+0];
	} // callseq 154
	ld.local.u32 	%r715, [%rd1];

$L__BB7_391:
	and.b32  	%r584, %r715, 1;
	shl.b32 	%r585, %r715, 3;
	and.b32  	%r586, %r585, 8;
	setp.eq.s32 	%p400, %r584, 0;
	selp.f64 	%fd1688, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p400;
	mul.wide.s32 	%rd209, %r586, 8;
	add.s64 	%rd211, %rd82, %rd209;
	ld.global.nc.f64 	%fd1689, [%rd211+8];
	mul.rn.f64 	%fd535, %fd1988, %fd1988;
	fma.rn.f64 	%fd1690, %fd1688, %fd535, %fd1689;
	ld.global.nc.f64 	%fd1691, [%rd211+16];
	fma.rn.f64 	%fd1692, %fd1690, %fd535, %fd1691;
	ld.global.nc.f64 	%fd1693, [%rd211+24];
	fma.rn.f64 	%fd1694, %fd1692, %fd535, %fd1693;
	ld.global.nc.f64 	%fd1695, [%rd211+32];
	fma.rn.f64 	%fd1696, %fd1694, %fd535, %fd1695;
	ld.global.nc.f64 	%fd1697, [%rd211+40];
	fma.rn.f64 	%fd1698, %fd1696, %fd535, %fd1697;
	ld.global.nc.f64 	%fd1699, [%rd211+48];
	fma.rn.f64 	%fd536, %fd1698, %fd535, %fd1699;
	fma.rn.f64 	%fd1990, %fd536, %fd1988, %fd1988;
	@%p400 bra 	$L__BB7_393;

	mov.f64 	%fd1700, 0d3FF0000000000000;
	fma.rn.f64 	%fd1990, %fd536, %fd535, %fd1700;

$L__BB7_393:
	and.b32  	%r587, %r715, 2;
	setp.eq.s32 	%p401, %r587, 0;
	@%p401 bra 	$L__BB7_395;

	mov.f64 	%fd1701, 0d0000000000000000;
	mov.f64 	%fd1702, 0dBFF0000000000000;
	fma.rn.f64 	%fd1990, %fd1990, %fd1702, %fd1701;

$L__BB7_395:
	abs.f64 	%fd542, %fd1990;
	{ // callseq 155, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd542;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1993, [retval0+0];
	} // callseq 155
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd1990;
	}
	setp.lt.s32 	%p402, %r130, 0;
	and.pred  	%p13, %p402, %p15;
	not.pred 	%p404, %p13;
	@%p404 bra 	$L__BB7_397;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r588}, %fd1993;
	}
	xor.b32  	%r589, %r588, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r590, %temp}, %fd1993;
	}
	mov.b64 	%fd1993, {%r590, %r589};

$L__BB7_397:
	setp.eq.f64 	%p405, %fd1990, 0d0000000000000000;
	@%p405 bra 	$L__BB7_401;
	bra.uni 	$L__BB7_398;

$L__BB7_401:
	setp.lt.s32 	%p408, %r2, 0;
	mov.u32 	%r591, 0;
	selp.b32 	%r592, %r130, 0, %p15;
	or.b32  	%r593, %r592, 2146435072;
	selp.b32 	%r594, %r593, %r592, %p408;
	mov.b64 	%fd1993, {%r591, %r594};
	bra.uni 	$L__BB7_402;

$L__BB7_398:
	setp.gt.s32 	%p406, %r130, -1;
	@%p406 bra 	$L__BB7_402;

	mov.f64 	%fd1703, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1704, %fd1703;
	setp.eq.f64 	%p407, %fd1704, 0d4000000000000000;
	@%p407 bra 	$L__BB7_402;

	mov.f64 	%fd1993, 0dFFF8000000000000;

$L__BB7_402:
	add.rn.f64 	%fd1706, %fd1990, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r595}, %fd1706;
	}
	and.b32  	%r596, %r595, 2146435072;
	setp.ne.s32 	%p410, %r596, 2146435072;
	@%p410 bra 	$L__BB7_409;

	setp.gtu.f64 	%p411, %fd542, 0d7FF0000000000000;
	@%p411 bra 	$L__BB7_408;
	bra.uni 	$L__BB7_404;

$L__BB7_408:
	mov.f64 	%fd1708, 0d4000000000000000;
	add.rn.f64 	%fd1993, %fd1990, %fd1708;
	bra.uni 	$L__BB7_409;

$L__BB7_404:
	setp.eq.s32 	%p412, %r65, 2146435072;
	mov.f64 	%fd1707, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r597, %temp}, %fd1707;
	}
	setp.eq.s32 	%p413, %r597, 0;
	and.pred  	%p414, %p412, %p413;
	@%p414 bra 	$L__BB7_407;
	bra.uni 	$L__BB7_405;

$L__BB7_407:
	setp.lt.s32 	%p420, %r2, 0;
	mov.u32 	%r602, 0;
	setp.gt.f64 	%p421, %fd542, 0d3FF0000000000000;
	selp.b32 	%r603, 2146435072, 0, %p421;
	xor.b32  	%r604, %r603, 2146435072;
	selp.b32 	%r605, %r604, %r603, %p420;
	setp.eq.f64 	%p422, %fd1990, 0dBFF0000000000000;
	selp.b32 	%r606, 1072693248, %r605, %p422;
	mov.b64 	%fd1993, {%r602, %r606};
	bra.uni 	$L__BB7_409;

$L__BB7_405:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r598, %temp}, %fd1990;
	}
	and.b32  	%r599, %r130, 2147483647;
	setp.ne.s32 	%p415, %r599, 2146435072;
	setp.ne.s32 	%p416, %r598, 0;
	or.pred  	%p417, %p415, %p416;
	@%p417 bra 	$L__BB7_409;

	setp.ne.s32 	%p418, %r65, 1071644672;
	and.pred  	%p419, %p418, %p13;
	selp.b32 	%r600, %r67, %r66, %p419;
	mov.u32 	%r601, 0;
	mov.b64 	%fd1993, {%r601, %r600};

$L__BB7_409:
	setp.eq.f64 	%p423, %fd1990, 0d3FF0000000000000;
	selp.f64 	%fd552, 0d3FF0000000000000, %fd1993, %p423;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r607}, %fd528;
	}
	and.b32  	%r608, %r607, 2147483647;
	setp.eq.s32 	%p424, %r608, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r609, %temp}, %fd528;
	}
	setp.eq.s32 	%p425, %r609, 0;
	and.pred  	%p426, %p425, %p424;
	@%p426 bra 	$L__BB7_413;
	bra.uni 	$L__BB7_410;

$L__BB7_413:
	mov.f64 	%fd1718, 0d0000000000000000;
	mul.rn.f64 	%fd1995, %fd528, %fd1718;
	mov.u32 	%r717, 1;
	bra.uni 	$L__BB7_414;

$L__BB7_410:
	mul.rn.f64 	%fd1709, %fd528, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r716, %fd1709;
	st.local.u32 	[%rd1], %r716;
	cvt.rn.f64.s32 	%fd1710, %r716;
	neg.f64 	%fd1711, %fd1710;
	mov.f64 	%fd1712, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1713, %fd1711, %fd1712, %fd528;
	mov.f64 	%fd1714, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1715, %fd1711, %fd1714, %fd1713;
	mov.f64 	%fd1716, 0d397B839A252049C0;
	fma.rn.f64 	%fd1995, %fd1711, %fd1716, %fd1715;
	abs.f64 	%fd1717, %fd528;
	setp.ltu.f64 	%p427, %fd1717, 0d41E0000000000000;
	@%p427 bra 	$L__BB7_412;

	{ // callseq 156, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd528;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1995, [retval0+0];
	} // callseq 156
	ld.local.u32 	%r716, [%rd1];

$L__BB7_412:
	add.s32 	%r717, %r716, 1;

$L__BB7_414:
	and.b32  	%r611, %r717, 1;
	shl.b32 	%r612, %r717, 3;
	and.b32  	%r613, %r612, 8;
	setp.eq.s32 	%p428, %r611, 0;
	selp.f64 	%fd1719, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p428;
	mul.wide.s32 	%rd213, %r613, 8;
	add.s64 	%rd215, %rd82, %rd213;
	ld.global.nc.f64 	%fd1720, [%rd215+8];
	mul.rn.f64 	%fd558, %fd1995, %fd1995;
	fma.rn.f64 	%fd1721, %fd1719, %fd558, %fd1720;
	ld.global.nc.f64 	%fd1722, [%rd215+16];
	fma.rn.f64 	%fd1723, %fd1721, %fd558, %fd1722;
	ld.global.nc.f64 	%fd1724, [%rd215+24];
	fma.rn.f64 	%fd1725, %fd1723, %fd558, %fd1724;
	ld.global.nc.f64 	%fd1726, [%rd215+32];
	fma.rn.f64 	%fd1727, %fd1725, %fd558, %fd1726;
	ld.global.nc.f64 	%fd1728, [%rd215+40];
	fma.rn.f64 	%fd1729, %fd1727, %fd558, %fd1728;
	ld.global.nc.f64 	%fd1730, [%rd215+48];
	fma.rn.f64 	%fd559, %fd1729, %fd558, %fd1730;
	fma.rn.f64 	%fd1997, %fd559, %fd1995, %fd1995;
	@%p428 bra 	$L__BB7_416;

	mov.f64 	%fd1731, 0d3FF0000000000000;
	fma.rn.f64 	%fd1997, %fd559, %fd558, %fd1731;

$L__BB7_416:
	and.b32  	%r614, %r717, 2;
	setp.eq.s32 	%p429, %r614, 0;
	@%p429 bra 	$L__BB7_418;

	mov.f64 	%fd1732, 0d0000000000000000;
	mov.f64 	%fd1733, 0dBFF0000000000000;
	fma.rn.f64 	%fd1997, %fd1997, %fd1733, %fd1732;

$L__BB7_418:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r615}, %fd529;
	}
	and.b32  	%r616, %r615, 2147483647;
	setp.eq.s32 	%p430, %r616, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r617, %temp}, %fd529;
	}
	setp.eq.s32 	%p431, %r617, 0;
	and.pred  	%p432, %p431, %p430;
	@%p432 bra 	$L__BB7_422;
	bra.uni 	$L__BB7_419;

$L__BB7_422:
	mov.f64 	%fd1743, 0d0000000000000000;
	mul.rn.f64 	%fd1999, %fd529, %fd1743;
	mov.u32 	%r719, 1;
	bra.uni 	$L__BB7_423;

$L__BB7_419:
	mul.rn.f64 	%fd1734, %fd529, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r718, %fd1734;
	st.local.u32 	[%rd1], %r718;
	cvt.rn.f64.s32 	%fd1735, %r718;
	neg.f64 	%fd1736, %fd1735;
	mov.f64 	%fd1737, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1738, %fd1736, %fd1737, %fd529;
	mov.f64 	%fd1739, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1740, %fd1736, %fd1739, %fd1738;
	mov.f64 	%fd1741, 0d397B839A252049C0;
	fma.rn.f64 	%fd1999, %fd1736, %fd1741, %fd1740;
	abs.f64 	%fd1742, %fd529;
	setp.ltu.f64 	%p433, %fd1742, 0d41E0000000000000;
	@%p433 bra 	$L__BB7_421;

	{ // callseq 157, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd529;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1999, [retval0+0];
	} // callseq 157
	ld.local.u32 	%r718, [%rd1];

$L__BB7_421:
	add.s32 	%r719, %r718, 1;

$L__BB7_423:
	and.b32  	%r619, %r719, 1;
	shl.b32 	%r620, %r719, 3;
	and.b32  	%r621, %r620, 8;
	setp.eq.s32 	%p434, %r619, 0;
	selp.f64 	%fd1744, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p434;
	mul.wide.s32 	%rd217, %r621, 8;
	add.s64 	%rd219, %rd82, %rd217;
	ld.global.nc.f64 	%fd1745, [%rd219+8];
	mul.rn.f64 	%fd570, %fd1999, %fd1999;
	fma.rn.f64 	%fd1746, %fd1744, %fd570, %fd1745;
	ld.global.nc.f64 	%fd1747, [%rd219+16];
	fma.rn.f64 	%fd1748, %fd1746, %fd570, %fd1747;
	ld.global.nc.f64 	%fd1749, [%rd219+24];
	fma.rn.f64 	%fd1750, %fd1748, %fd570, %fd1749;
	ld.global.nc.f64 	%fd1751, [%rd219+32];
	fma.rn.f64 	%fd1752, %fd1750, %fd570, %fd1751;
	ld.global.nc.f64 	%fd1753, [%rd219+40];
	fma.rn.f64 	%fd1754, %fd1752, %fd570, %fd1753;
	ld.global.nc.f64 	%fd1755, [%rd219+48];
	fma.rn.f64 	%fd571, %fd1754, %fd570, %fd1755;
	fma.rn.f64 	%fd2001, %fd571, %fd1999, %fd1999;
	@%p434 bra 	$L__BB7_425;

	mov.f64 	%fd1756, 0d3FF0000000000000;
	fma.rn.f64 	%fd2001, %fd571, %fd570, %fd1756;

$L__BB7_425:
	and.b32  	%r622, %r719, 2;
	setp.eq.s32 	%p435, %r622, 0;
	@%p435 bra 	$L__BB7_427;

	mov.f64 	%fd1757, 0d0000000000000000;
	mov.f64 	%fd1758, 0dBFF0000000000000;
	fma.rn.f64 	%fd2001, %fd2001, %fd1758, %fd1757;

$L__BB7_427:
	mul.rn.f64 	%fd577, %fd1997, %fd2001;
	mul.rn.f64 	%fd1759, %fd2009, 0d400921FB54442D18;
	div.rn.f64 	%fd1760, %fd1759, 0d4066800000000000;
	mul.rn.f64 	%fd1761, %fd1923, 0d400921FB54442D18;
	div.rn.f64 	%fd1762, %fd1761, 0d4066800000000000;
	sub.rn.f64 	%fd1763, %fd1762, %fd1760;
	mul.rn.f64 	%fd578, %fd1763, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r623, %temp}, %fd578;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r624}, %fd578;
	}
	and.b32  	%r625, %r624, 2147483647;
	setp.eq.s32 	%p436, %r625, 2146435072;
	setp.eq.s32 	%p437, %r623, 0;
	and.pred  	%p438, %p437, %p436;
	@%p438 bra 	$L__BB7_430;
	bra.uni 	$L__BB7_428;

$L__BB7_430:
	mov.f64 	%fd1773, 0d0000000000000000;
	mul.rn.f64 	%fd2002, %fd578, %fd1773;
	mov.u32 	%r720, 0;
	bra.uni 	$L__BB7_431;

$L__BB7_428:
	mul.rn.f64 	%fd1764, %fd578, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r720, %fd1764;
	st.local.u32 	[%rd1], %r720;
	cvt.rn.f64.s32 	%fd1765, %r720;
	neg.f64 	%fd1766, %fd1765;
	mov.f64 	%fd1767, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1768, %fd1766, %fd1767, %fd578;
	mov.f64 	%fd1769, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1770, %fd1766, %fd1769, %fd1768;
	mov.f64 	%fd1771, 0d397B839A252049C0;
	fma.rn.f64 	%fd2002, %fd1766, %fd1771, %fd1770;
	abs.f64 	%fd1772, %fd578;
	setp.ltu.f64 	%p439, %fd1772, 0d41E0000000000000;
	@%p439 bra 	$L__BB7_431;

	{ // callseq 158, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd578;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd2002, [retval0+0];
	} // callseq 158
	ld.local.u32 	%r720, [%rd1];

$L__BB7_431:
	and.b32  	%r627, %r720, 1;
	shl.b32 	%r628, %r720, 3;
	and.b32  	%r629, %r628, 8;
	setp.eq.s32 	%p440, %r627, 0;
	selp.f64 	%fd1774, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p440;
	mul.wide.s32 	%rd221, %r629, 8;
	add.s64 	%rd223, %rd82, %rd221;
	ld.global.nc.f64 	%fd1775, [%rd223+8];
	mul.rn.f64 	%fd583, %fd2002, %fd2002;
	fma.rn.f64 	%fd1776, %fd1774, %fd583, %fd1775;
	ld.global.nc.f64 	%fd1777, [%rd223+16];
	fma.rn.f64 	%fd1778, %fd1776, %fd583, %fd1777;
	ld.global.nc.f64 	%fd1779, [%rd223+24];
	fma.rn.f64 	%fd1780, %fd1778, %fd583, %fd1779;
	ld.global.nc.f64 	%fd1781, [%rd223+32];
	fma.rn.f64 	%fd1782, %fd1780, %fd583, %fd1781;
	ld.global.nc.f64 	%fd1783, [%rd223+40];
	fma.rn.f64 	%fd1784, %fd1782, %fd583, %fd1783;
	ld.global.nc.f64 	%fd1785, [%rd223+48];
	fma.rn.f64 	%fd584, %fd1784, %fd583, %fd1785;
	fma.rn.f64 	%fd2004, %fd584, %fd2002, %fd2002;
	@%p440 bra 	$L__BB7_433;

	mov.f64 	%fd1786, 0d3FF0000000000000;
	fma.rn.f64 	%fd2004, %fd584, %fd583, %fd1786;

$L__BB7_433:
	and.b32  	%r630, %r720, 2;
	setp.eq.s32 	%p441, %r630, 0;
	@%p441 bra 	$L__BB7_435;

	mov.f64 	%fd1787, 0d0000000000000000;
	mov.f64 	%fd1788, 0dBFF0000000000000;
	fma.rn.f64 	%fd2004, %fd2004, %fd1788, %fd1787;

$L__BB7_435:
	abs.f64 	%fd590, %fd2004;
	{ // callseq 159, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd590;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd2007, [retval0+0];
	} // callseq 159
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r144}, %fd2004;
	}
	setp.lt.s32 	%p442, %r144, 0;
	and.pred  	%p14, %p442, %p15;
	not.pred 	%p444, %p14;
	@%p444 bra 	$L__BB7_437;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r631}, %fd2007;
	}
	xor.b32  	%r632, %r631, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r633, %temp}, %fd2007;
	}
	mov.b64 	%fd2007, {%r633, %r632};

$L__BB7_437:
	setp.eq.f64 	%p445, %fd2004, 0d0000000000000000;
	@%p445 bra 	$L__BB7_441;
	bra.uni 	$L__BB7_438;

$L__BB7_441:
	setp.lt.s32 	%p448, %r2, 0;
	mov.u32 	%r634, 0;
	selp.b32 	%r635, %r144, 0, %p15;
	or.b32  	%r636, %r635, 2146435072;
	selp.b32 	%r637, %r636, %r635, %p448;
	mov.b64 	%fd2007, {%r634, %r637};
	bra.uni 	$L__BB7_442;

$L__BB7_438:
	setp.gt.s32 	%p446, %r144, -1;
	@%p446 bra 	$L__BB7_442;

	mov.f64 	%fd1789, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1790, %fd1789;
	setp.eq.f64 	%p447, %fd1790, 0d4000000000000000;
	@%p447 bra 	$L__BB7_442;

	mov.f64 	%fd2007, 0dFFF8000000000000;

$L__BB7_442:
	add.rn.f64 	%fd1792, %fd2004, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r638}, %fd1792;
	}
	and.b32  	%r639, %r638, 2146435072;
	setp.ne.s32 	%p450, %r639, 2146435072;
	@%p450 bra 	$L__BB7_449;

	setp.gtu.f64 	%p451, %fd590, 0d7FF0000000000000;
	@%p451 bra 	$L__BB7_448;
	bra.uni 	$L__BB7_444;

$L__BB7_448:
	mov.f64 	%fd1794, 0d4000000000000000;
	add.rn.f64 	%fd2007, %fd2004, %fd1794;
	bra.uni 	$L__BB7_449;

$L__BB7_444:
	setp.eq.s32 	%p452, %r65, 2146435072;
	mov.f64 	%fd1793, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r640, %temp}, %fd1793;
	}
	setp.eq.s32 	%p453, %r640, 0;
	and.pred  	%p454, %p452, %p453;
	@%p454 bra 	$L__BB7_447;
	bra.uni 	$L__BB7_445;

$L__BB7_447:
	setp.lt.s32 	%p460, %r2, 0;
	mov.u32 	%r645, 0;
	setp.gt.f64 	%p461, %fd590, 0d3FF0000000000000;
	selp.b32 	%r646, 2146435072, 0, %p461;
	xor.b32  	%r647, %r646, 2146435072;
	selp.b32 	%r648, %r647, %r646, %p460;
	setp.eq.f64 	%p462, %fd2004, 0dBFF0000000000000;
	selp.b32 	%r649, 1072693248, %r648, %p462;
	mov.b64 	%fd2007, {%r645, %r649};
	bra.uni 	$L__BB7_449;

$L__BB7_445:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r641, %temp}, %fd2004;
	}
	and.b32  	%r642, %r144, 2147483647;
	setp.ne.s32 	%p455, %r642, 2146435072;
	setp.ne.s32 	%p456, %r641, 0;
	or.pred  	%p457, %p455, %p456;
	@%p457 bra 	$L__BB7_449;

	setp.ne.s32 	%p458, %r65, 1071644672;
	and.pred  	%p459, %p458, %p14;
	selp.b32 	%r643, %r67, %r66, %p459;
	mov.u32 	%r644, 0;
	mov.b64 	%fd2007, {%r644, %r643};

$L__BB7_449:
	setp.eq.f64 	%p463, %fd2004, 0d3FF0000000000000;
	mov.f64 	%fd1795, 0d3FF0000000000000;
	selp.f64 	%fd1796, 0d3FF0000000000000, %fd2007, %p463;
	mul.rn.f64 	%fd1797, %fd577, %fd1796;
	add.rn.f64 	%fd1798, %fd552, %fd1797;
	sqrt.rn.f64 	%fd600, %fd1798;
	sub.rn.f64 	%fd1799, %fd1795, %fd1798;
	sqrt.rn.f64 	%fd601, %fd1799;
	abs.f64 	%fd602, %fd601;
	abs.f64 	%fd603, %fd600;
	setp.eq.f64 	%p464, %fd602, 0d0000000000000000;
	setp.eq.f64 	%p465, %fd603, 0d0000000000000000;
	and.pred  	%p466, %p464, %p465;
	@%p466 bra 	$L__BB7_453;
	bra.uni 	$L__BB7_450;

$L__BB7_453:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r662}, %fd601;
	}
	setp.lt.s32 	%p474, %r662, 0;
	selp.f64 	%fd1852, 0d400921FB54442D18, 0d0000000000000000, %p474;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r663, %temp}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r664}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r665}, %fd600;
	}
	and.b32  	%r666, %r665, -2147483648;
	or.b32  	%r667, %r664, %r666;
	mov.b64 	%fd2008, {%r663, %r667};
	bra.uni 	$L__BB7_454;

$L__BB7_450:
	setp.eq.f64 	%p467, %fd602, 0d7FF0000000000000;
	setp.eq.f64 	%p468, %fd603, 0d7FF0000000000000;
	and.pred  	%p469, %p467, %p468;
	@%p469 bra 	$L__BB7_452;
	bra.uni 	$L__BB7_451;

$L__BB7_452:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r656}, %fd601;
	}
	setp.lt.s32 	%p473, %r656, 0;
	selp.f64 	%fd1851, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p473;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r657, %temp}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r658}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r659}, %fd600;
	}
	and.b32  	%r660, %r659, -2147483648;
	or.b32  	%r661, %r658, %r660;
	mov.b64 	%fd2008, {%r657, %r661};
	bra.uni 	$L__BB7_454;

$L__BB7_451:
	max.f64 	%fd1800, %fd603, %fd602;
	min.f64 	%fd1801, %fd603, %fd602;
	div.rn.f64 	%fd1802, %fd1801, %fd1800;
	mul.rn.f64 	%fd1803, %fd1802, %fd1802;
	mov.f64 	%fd1804, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1805, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1806, %fd1805, %fd1803, %fd1804;
	mov.f64 	%fd1807, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1808, %fd1806, %fd1803, %fd1807;
	mov.f64 	%fd1809, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1810, %fd1808, %fd1803, %fd1809;
	mov.f64 	%fd1811, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1812, %fd1810, %fd1803, %fd1811;
	mov.f64 	%fd1813, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1814, %fd1812, %fd1803, %fd1813;
	mov.f64 	%fd1815, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1816, %fd1814, %fd1803, %fd1815;
	mov.f64 	%fd1817, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1818, %fd1816, %fd1803, %fd1817;
	mov.f64 	%fd1819, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1820, %fd1818, %fd1803, %fd1819;
	mov.f64 	%fd1821, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1822, %fd1820, %fd1803, %fd1821;
	mov.f64 	%fd1823, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1824, %fd1822, %fd1803, %fd1823;
	mov.f64 	%fd1825, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1826, %fd1824, %fd1803, %fd1825;
	mov.f64 	%fd1827, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1828, %fd1826, %fd1803, %fd1827;
	mov.f64 	%fd1829, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1830, %fd1828, %fd1803, %fd1829;
	mov.f64 	%fd1831, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1832, %fd1830, %fd1803, %fd1831;
	mov.f64 	%fd1833, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1834, %fd1832, %fd1803, %fd1833;
	mov.f64 	%fd1835, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1836, %fd1834, %fd1803, %fd1835;
	mov.f64 	%fd1837, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1838, %fd1836, %fd1803, %fd1837;
	mov.f64 	%fd1839, 0dBFD555555555544C;
	fma.rn.f64 	%fd1840, %fd1838, %fd1803, %fd1839;
	mul.rn.f64 	%fd1841, %fd1803, %fd1840;
	fma.rn.f64 	%fd1842, %fd1841, %fd1802, %fd1802;
	mov.f64 	%fd1843, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1844, %fd1843, %fd1842;
	setp.gt.f64 	%p470, %fd603, %fd602;
	selp.f64 	%fd1845, %fd1844, %fd1842, %p470;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r650}, %fd601;
	}
	setp.lt.s32 	%p471, %r650, 0;
	mov.f64 	%fd1846, 0d400921FB54442D18;
	sub.rn.f64 	%fd1847, %fd1846, %fd1845;
	selp.f64 	%fd1848, %fd1847, %fd1845, %p471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r651, %temp}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r652}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r653}, %fd600;
	}
	and.b32  	%r654, %r653, -2147483648;
	or.b32  	%r655, %r652, %r654;
	mov.b64 	%fd1849, {%r651, %r655};
	add.rn.f64 	%fd1850, %fd602, %fd603;
	setp.le.f64 	%p472, %fd1850, 0d7FF0000000000000;
	selp.f64 	%fd2008, %fd1849, %fd1850, %p472;

$L__BB7_454:
	add.rn.f64 	%fd1853, %fd2008, %fd2008;
	mul.rn.f64 	%fd1854, %fd1853, 0d415854A640000000;
	setp.lt.f64 	%p475, %fd1854, %fd610;
	@%p475 bra 	$L__BB7_458;

$L__BB7_457:
	add.s32 	%r695, %r695, 1;
	setp.lt.s32 	%p478, %r695, %r146;
	mov.f64 	%fd2009, %fd1923;
	mov.f64 	%fd2010, %fd1922;
	@%p478 bra 	$L__BB7_194;

$L__BB7_458:
	ld.param.u64 	%rd231, [bd09_to_wgs84_exact_cuda_param_1];
	mov.u32 	%r675, %tid.x;
	mov.u32 	%r674, %ntid.x;
	mov.u32 	%r673, %ctaid.x;
	mad.lo.s32 	%r672, %r673, %r674, %r675;
	mul.wide.s32 	%rd230, %r672, 8;
	cvta.to.global.u64 	%rd229, %rd231;
	add.s64 	%rd228, %rd229, %rd230;
	ld.param.u64 	%rd227, [bd09_to_wgs84_exact_cuda_param_0];
	mov.u32 	%r671, %tid.x;
	mov.u32 	%r670, %ntid.x;
	mov.u32 	%r669, %ctaid.x;
	mad.lo.s32 	%r668, %r669, %r670, %r671;
	mul.wide.s32 	%rd226, %r668, 8;
	cvta.to.global.u64 	%rd225, %rd227;
	add.s64 	%rd224, %rd225, %rd226;
	st.global.f64 	[%rd224], %fd2009;
	st.global.f64 	[%rd228], %fd2010;
	ret;

}
	// .globl	bd09_to_gcj02_exact_cuda
.visible .entry bd09_to_gcj02_exact_cuda(
	.param .u64 bd09_to_gcj02_exact_cuda_param_0,
	.param .u64 bd09_to_gcj02_exact_cuda_param_1,
	.param .f64 bd09_to_gcj02_exact_cuda_param_2,
	.param .u8 bd09_to_gcj02_exact_cuda_param_3,
	.param .u32 bd09_to_gcj02_exact_cuda_param_4
)
{
	.local .align 4 .b8 	__local_depot8[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<247>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<349>;
	.reg .f64 	%fd<841>;
	.reg .b64 	%rd<88>;


	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [bd09_to_gcj02_exact_cuda_param_0];
	ld.param.u64 	%rd16, [bd09_to_gcj02_exact_cuda_param_1];
	ld.param.f64 	%fd246, [bd09_to_gcj02_exact_cuda_param_2];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd18, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r68, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd247, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd247;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p9, %r3, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 160, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd776, [retval0+0];
	} // callseq 160
	setp.lt.s32 	%p10, %r1, 0;
	and.pred  	%p1, %p10, %p9;
	not.pred 	%p11, %p1;
	@%p11 bra 	$L__BB8_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd776;
	}
	xor.b32  	%r70, %r69, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd776;
	}
	mov.b64 	%fd776, {%r71, %r70};

$L__BB8_2:
	setp.eq.f64 	%p12, %fd2, 0d0000000000000000;
	@%p12 bra 	$L__BB8_6;
	bra.uni 	$L__BB8_3;

$L__BB8_6:
	selp.b32 	%r72, %r1, 0, %p9;
	mov.u32 	%r73, 0;
	or.b32  	%r74, %r72, 2146435072;
	setp.lt.s32 	%p16, %r2, 0;
	selp.b32 	%r75, %r74, %r72, %p16;
	mov.b64 	%fd776, {%r73, %r75};
	bra.uni 	$L__BB8_7;

$L__BB8_3:
	setp.gt.s32 	%p13, %r1, -1;
	@%p13 bra 	$L__BB8_7;

	mov.f64 	%fd248, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd249, %fd248;
	setp.eq.f64 	%p14, %fd249, 0d4000000000000000;
	@%p14 bra 	$L__BB8_7;

	mov.f64 	%fd776, 0dFFF8000000000000;

$L__BB8_7:
	add.rn.f64 	%fd251, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd251;
	}
	and.b32  	%r77, %r76, 2146435072;
	setp.ne.s32 	%p17, %r77, 2146435072;
	@%p17 bra 	$L__BB8_14;

	setp.gtu.f64 	%p18, %fd5, 0d7FF0000000000000;
	@%p18 bra 	$L__BB8_13;
	bra.uni 	$L__BB8_9;

$L__BB8_13:
	mov.f64 	%fd253, 0d4000000000000000;
	add.rn.f64 	%fd776, %fd2, %fd253;
	bra.uni 	$L__BB8_14;

$L__BB8_9:
	mov.f64 	%fd252, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd252;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p19, %r4, 2146435072;
	setp.eq.s32 	%p20, %r78, 0;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB8_12;
	bra.uni 	$L__BB8_10;

$L__BB8_12:
	setp.gt.f64 	%p28, %fd5, 0d3FF0000000000000;
	selp.b32 	%r85, 2146435072, 0, %p28;
	mov.u32 	%r86, 0;
	xor.b32  	%r87, %r85, 2146435072;
	setp.lt.s32 	%p29, %r2, 0;
	selp.b32 	%r88, %r87, %r85, %p29;
	setp.eq.f64 	%p30, %fd2, 0dBFF0000000000000;
	selp.b32 	%r89, 1072693248, %r88, %p30;
	mov.b64 	%fd776, {%r86, %r89};
	bra.uni 	$L__BB8_14;

$L__BB8_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd2;
	}
	and.b32  	%r80, %r1, 2147483647;
	setp.ne.s32 	%p22, %r80, 2146435072;
	setp.ne.s32 	%p23, %r79, 0;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB8_14;

	setp.gt.s32 	%p25, %r2, -1;
	selp.b32 	%r81, 2146435072, 0, %p25;
	mov.u32 	%r82, 0;
	setp.ne.s32 	%p26, %r4, 1071644672;
	and.pred  	%p27, %p26, %p1;
	or.b32  	%r83, %r81, -2147483648;
	selp.b32 	%r84, %r83, %r81, %p27;
	mov.b64 	%fd776, {%r82, %r84};

$L__BB8_14:
	abs.f64 	%fd15, %fd4;
	{ // callseq 161, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd779, [retval0+0];
	} // callseq 161
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd4;
	}
	setp.lt.s32 	%p31, %r5, 0;
	and.pred  	%p2, %p31, %p9;
	not.pred 	%p33, %p2;
	@%p33 bra 	$L__BB8_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd779;
	}
	xor.b32  	%r91, %r90, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r92, %temp}, %fd779;
	}
	mov.b64 	%fd779, {%r92, %r91};

$L__BB8_16:
	setp.eq.f64 	%p34, %fd4, 0d0000000000000000;
	@%p34 bra 	$L__BB8_20;
	bra.uni 	$L__BB8_17;

$L__BB8_20:
	selp.b32 	%r93, %r5, 0, %p9;
	mov.u32 	%r94, 0;
	or.b32  	%r95, %r93, 2146435072;
	setp.lt.s32 	%p38, %r2, 0;
	selp.b32 	%r96, %r95, %r93, %p38;
	mov.b64 	%fd779, {%r94, %r96};
	bra.uni 	$L__BB8_21;

$L__BB8_17:
	setp.gt.s32 	%p35, %r5, -1;
	@%p35 bra 	$L__BB8_21;

	mov.f64 	%fd254, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd255, %fd254;
	setp.eq.f64 	%p36, %fd255, 0d4000000000000000;
	@%p36 bra 	$L__BB8_21;

	mov.f64 	%fd779, 0dFFF8000000000000;

$L__BB8_21:
	add.rn.f64 	%fd257, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd257;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32 	%p39, %r98, 2146435072;
	@%p39 bra 	$L__BB8_28;

	setp.gtu.f64 	%p40, %fd15, 0d7FF0000000000000;
	@%p40 bra 	$L__BB8_27;
	bra.uni 	$L__BB8_23;

$L__BB8_27:
	mov.f64 	%fd259, 0d4000000000000000;
	add.rn.f64 	%fd779, %fd4, %fd259;
	bra.uni 	$L__BB8_28;

$L__BB8_23:
	mov.f64 	%fd258, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd258;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p41, %r6, 2146435072;
	setp.eq.s32 	%p42, %r99, 0;
	and.pred  	%p43, %p41, %p42;
	@%p43 bra 	$L__BB8_26;
	bra.uni 	$L__BB8_24;

$L__BB8_26:
	setp.gt.f64 	%p50, %fd15, 0d3FF0000000000000;
	selp.b32 	%r106, 2146435072, 0, %p50;
	mov.u32 	%r107, 0;
	xor.b32  	%r108, %r106, 2146435072;
	setp.lt.s32 	%p51, %r2, 0;
	selp.b32 	%r109, %r108, %r106, %p51;
	setp.eq.f64 	%p52, %fd4, 0dBFF0000000000000;
	selp.b32 	%r110, 1072693248, %r109, %p52;
	mov.b64 	%fd779, {%r107, %r110};
	bra.uni 	$L__BB8_28;

$L__BB8_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd4;
	}
	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32 	%p44, %r101, 2146435072;
	setp.ne.s32 	%p45, %r100, 0;
	or.pred  	%p46, %p44, %p45;
	@%p46 bra 	$L__BB8_28;

	setp.gt.s32 	%p47, %r2, -1;
	selp.b32 	%r102, 2146435072, 0, %p47;
	mov.u32 	%r103, 0;
	setp.ne.s32 	%p48, %r6, 1071644672;
	and.pred  	%p49, %p48, %p2;
	or.b32  	%r104, %r102, -2147483648;
	selp.b32 	%r105, %r104, %r102, %p49;
	mov.b64 	%fd779, {%r103, %r105};

$L__BB8_28:
	setp.eq.f64 	%p53, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd260, 0d3FF0000000000000, %fd779, %p53;
	setp.eq.f64 	%p54, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd261, 0d3FF0000000000000, %fd776, %p54;
	add.rn.f64 	%fd25, %fd261, %fd260;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd26;
	}
	and.b32  	%r113, %r112, 2147483647;
	setp.eq.s32 	%p55, %r113, 2146435072;
	setp.eq.s32 	%p56, %r111, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB8_31;
	bra.uni 	$L__BB8_29;

$L__BB8_31:
	mov.f64 	%fd271, 0d0000000000000000;
	mul.rn.f64 	%fd780, %fd26, %fd271;
	mov.u32 	%r330, 0;
	bra.uni 	$L__BB8_32;

$L__BB8_29:
	mul.rn.f64 	%fd262, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r330, %fd262;
	st.local.u32 	[%rd1], %r330;
	cvt.rn.f64.s32 	%fd263, %r330;
	neg.f64 	%fd264, %fd263;
	mov.f64 	%fd265, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd266, %fd264, %fd265, %fd26;
	mov.f64 	%fd267, 0d3C91A62633145C00;
	fma.rn.f64 	%fd268, %fd264, %fd267, %fd266;
	mov.f64 	%fd269, 0d397B839A252049C0;
	fma.rn.f64 	%fd780, %fd264, %fd269, %fd268;
	abs.f64 	%fd270, %fd26;
	setp.ltu.f64 	%p58, %fd270, 0d41E0000000000000;
	@%p58 bra 	$L__BB8_32;

	{ // callseq 162, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd780, [retval0+0];
	} // callseq 162
	ld.local.u32 	%r330, [%rd1];

$L__BB8_32:
	and.b32  	%r115, %r330, 1;
	shl.b32 	%r116, %r330, 3;
	and.b32  	%r117, %r116, 8;
	setp.eq.s32 	%p59, %r115, 0;
	selp.f64 	%fd272, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd33, %r117, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd273, [%rd35+8];
	mul.rn.f64 	%fd31, %fd780, %fd780;
	fma.rn.f64 	%fd274, %fd272, %fd31, %fd273;
	ld.global.nc.f64 	%fd275, [%rd35+16];
	fma.rn.f64 	%fd276, %fd274, %fd31, %fd275;
	ld.global.nc.f64 	%fd277, [%rd35+24];
	fma.rn.f64 	%fd278, %fd276, %fd31, %fd277;
	ld.global.nc.f64 	%fd279, [%rd35+32];
	fma.rn.f64 	%fd280, %fd278, %fd31, %fd279;
	ld.global.nc.f64 	%fd281, [%rd35+40];
	fma.rn.f64 	%fd282, %fd280, %fd31, %fd281;
	ld.global.nc.f64 	%fd283, [%rd35+48];
	fma.rn.f64 	%fd32, %fd282, %fd31, %fd283;
	fma.rn.f64 	%fd782, %fd32, %fd780, %fd780;
	@%p59 bra 	$L__BB8_34;

	mov.f64 	%fd284, 0d3FF0000000000000;
	fma.rn.f64 	%fd782, %fd32, %fd31, %fd284;

$L__BB8_34:
	and.b32  	%r118, %r330, 2;
	setp.eq.s32 	%p60, %r118, 0;
	@%p60 bra 	$L__BB8_36;

	mov.f64 	%fd285, 0d0000000000000000;
	mov.f64 	%fd286, 0dBFF0000000000000;
	fma.rn.f64 	%fd782, %fd782, %fd286, %fd285;

$L__BB8_36:
	mul.rn.f64 	%fd287, %fd782, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd288, %fd25;
	add.rn.f64 	%fd38, %fd288, %fd287;
	setp.eq.f64 	%p61, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p62, %fd5, 0d0000000000000000;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB8_40;
	bra.uni 	$L__BB8_37;

$L__BB8_40:
	selp.f64 	%fd341, 0d400921FB54442D18, 0d0000000000000000, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd341;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd341;
	}
	and.b32  	%r129, %r5, -2147483648;
	or.b32  	%r130, %r128, %r129;
	mov.b64 	%fd783, {%r127, %r130};
	bra.uni 	$L__BB8_41;

$L__BB8_37:
	setp.eq.f64 	%p64, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p65, %fd15, 0d7FF0000000000000;
	and.pred  	%p66, %p64, %p65;
	@%p66 bra 	$L__BB8_39;
	bra.uni 	$L__BB8_38;

$L__BB8_39:
	selp.f64 	%fd340, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd340;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r124}, %fd340;
	}
	and.b32  	%r125, %r5, -2147483648;
	or.b32  	%r126, %r124, %r125;
	mov.b64 	%fd783, {%r123, %r126};
	bra.uni 	$L__BB8_41;

$L__BB8_38:
	min.f64 	%fd289, %fd15, %fd5;
	max.f64 	%fd290, %fd15, %fd5;
	div.rn.f64 	%fd291, %fd289, %fd290;
	mul.rn.f64 	%fd292, %fd291, %fd291;
	mov.f64 	%fd293, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd294, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd295, %fd294, %fd292, %fd293;
	mov.f64 	%fd296, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd297, %fd295, %fd292, %fd296;
	mov.f64 	%fd298, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd299, %fd297, %fd292, %fd298;
	mov.f64 	%fd300, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd301, %fd299, %fd292, %fd300;
	mov.f64 	%fd302, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd303, %fd301, %fd292, %fd302;
	mov.f64 	%fd304, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd305, %fd303, %fd292, %fd304;
	mov.f64 	%fd306, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd307, %fd305, %fd292, %fd306;
	mov.f64 	%fd308, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd309, %fd307, %fd292, %fd308;
	mov.f64 	%fd310, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd311, %fd309, %fd292, %fd310;
	mov.f64 	%fd312, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd313, %fd311, %fd292, %fd312;
	mov.f64 	%fd314, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd315, %fd313, %fd292, %fd314;
	mov.f64 	%fd316, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd317, %fd315, %fd292, %fd316;
	mov.f64 	%fd318, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd319, %fd317, %fd292, %fd318;
	mov.f64 	%fd320, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd321, %fd319, %fd292, %fd320;
	mov.f64 	%fd322, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd323, %fd321, %fd292, %fd322;
	mov.f64 	%fd324, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd325, %fd323, %fd292, %fd324;
	mov.f64 	%fd326, 0d3FC99999999840D2;
	fma.rn.f64 	%fd327, %fd325, %fd292, %fd326;
	mov.f64 	%fd328, 0dBFD555555555544C;
	fma.rn.f64 	%fd329, %fd327, %fd292, %fd328;
	mul.rn.f64 	%fd330, %fd292, %fd329;
	fma.rn.f64 	%fd331, %fd330, %fd291, %fd291;
	mov.f64 	%fd332, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd333, %fd332, %fd331;
	setp.gt.f64 	%p68, %fd15, %fd5;
	selp.f64 	%fd334, %fd333, %fd331, %p68;
	mov.f64 	%fd335, 0d400921FB54442D18;
	sub.rn.f64 	%fd336, %fd335, %fd334;
	selp.f64 	%fd337, %fd336, %fd334, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd337;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd337;
	}
	and.b32  	%r121, %r5, -2147483648;
	or.b32  	%r122, %r120, %r121;
	mov.b64 	%fd338, {%r119, %r122};
	add.rn.f64 	%fd339, %fd5, %fd15;
	setp.le.f64 	%p69, %fd339, 0d7FF0000000000000;
	selp.f64 	%fd783, %fd338, %fd339, %p69;

$L__BB8_41:
	add.rn.f64 	%fd773, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd773, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd43;
	}
	and.b32  	%r133, %r132, 2147483647;
	setp.eq.s32 	%p72, %r133, 2146435072;
	setp.eq.s32 	%p73, %r131, 0;
	and.pred  	%p74, %p73, %p72;
	@%p74 bra 	$L__BB8_45;
	bra.uni 	$L__BB8_42;

$L__BB8_45:
	mov.f64 	%fd351, 0d0000000000000000;
	mul.rn.f64 	%fd785, %fd43, %fd351;
	mov.u32 	%r332, 1;
	bra.uni 	$L__BB8_46;

$L__BB8_42:
	mul.rn.f64 	%fd342, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r331, %fd342;
	st.local.u32 	[%rd1], %r331;
	cvt.rn.f64.s32 	%fd343, %r331;
	neg.f64 	%fd344, %fd343;
	mov.f64 	%fd345, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd346, %fd344, %fd345, %fd43;
	mov.f64 	%fd347, 0d3C91A62633145C00;
	fma.rn.f64 	%fd348, %fd344, %fd347, %fd346;
	mov.f64 	%fd349, 0d397B839A252049C0;
	fma.rn.f64 	%fd785, %fd344, %fd349, %fd348;
	abs.f64 	%fd350, %fd43;
	setp.ltu.f64 	%p75, %fd350, 0d41E0000000000000;
	@%p75 bra 	$L__BB8_44;

	{ // callseq 163, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd785, [retval0+0];
	} // callseq 163
	ld.local.u32 	%r331, [%rd1];

$L__BB8_44:
	add.s32 	%r332, %r331, 1;

$L__BB8_46:
	and.b32  	%r135, %r332, 1;
	shl.b32 	%r136, %r332, 3;
	and.b32  	%r137, %r136, 8;
	setp.eq.s32 	%p76, %r135, 0;
	selp.f64 	%fd352, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd37, %r137, 8;
	add.s64 	%rd39, %rd34, %rd37;
	ld.global.nc.f64 	%fd353, [%rd39+8];
	mul.rn.f64 	%fd49, %fd785, %fd785;
	fma.rn.f64 	%fd354, %fd352, %fd49, %fd353;
	ld.global.nc.f64 	%fd355, [%rd39+16];
	fma.rn.f64 	%fd356, %fd354, %fd49, %fd355;
	ld.global.nc.f64 	%fd357, [%rd39+24];
	fma.rn.f64 	%fd358, %fd356, %fd49, %fd357;
	ld.global.nc.f64 	%fd359, [%rd39+32];
	fma.rn.f64 	%fd360, %fd358, %fd49, %fd359;
	ld.global.nc.f64 	%fd361, [%rd39+40];
	fma.rn.f64 	%fd362, %fd360, %fd49, %fd361;
	ld.global.nc.f64 	%fd363, [%rd39+48];
	fma.rn.f64 	%fd50, %fd362, %fd49, %fd363;
	fma.rn.f64 	%fd787, %fd50, %fd785, %fd785;
	@%p76 bra 	$L__BB8_48;

	mov.f64 	%fd364, 0d3FF0000000000000;
	fma.rn.f64 	%fd787, %fd50, %fd49, %fd364;

$L__BB8_48:
	and.b32  	%r138, %r332, 2;
	setp.eq.s32 	%p77, %r138, 0;
	@%p77 bra 	$L__BB8_50;

	mov.f64 	%fd365, 0d0000000000000000;
	mov.f64 	%fd366, 0dBFF0000000000000;
	fma.rn.f64 	%fd787, %fd787, %fd366, %fd365;

$L__BB8_50:
	mul.rn.f64 	%fd367, %fd787, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd783, %fd367;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd56;
	}
	and.b32  	%r141, %r140, 2147483647;
	setp.eq.s32 	%p78, %r141, 2146435072;
	setp.eq.s32 	%p79, %r139, 0;
	and.pred  	%p3, %p79, %p78;
	@%p3 bra 	$L__BB8_54;
	bra.uni 	$L__BB8_51;

$L__BB8_54:
	mov.f64 	%fd377, 0d0000000000000000;
	mul.rn.f64 	%fd789, %fd56, %fd377;
	mov.u32 	%r334, 1;
	bra.uni 	$L__BB8_55;

$L__BB8_51:
	mul.rn.f64 	%fd368, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r333, %fd368;
	st.local.u32 	[%rd1], %r333;
	cvt.rn.f64.s32 	%fd369, %r333;
	neg.f64 	%fd370, %fd369;
	mov.f64 	%fd371, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd372, %fd370, %fd371, %fd56;
	mov.f64 	%fd373, 0d3C91A62633145C00;
	fma.rn.f64 	%fd374, %fd370, %fd373, %fd372;
	mov.f64 	%fd375, 0d397B839A252049C0;
	fma.rn.f64 	%fd789, %fd370, %fd375, %fd374;
	abs.f64 	%fd376, %fd56;
	setp.ltu.f64 	%p80, %fd376, 0d41E0000000000000;
	@%p80 bra 	$L__BB8_53;

	{ // callseq 164, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd789, [retval0+0];
	} // callseq 164
	ld.local.u32 	%r333, [%rd1];

$L__BB8_53:
	add.s32 	%r334, %r333, 1;

$L__BB8_55:
	and.b32  	%r143, %r334, 1;
	shl.b32 	%r144, %r334, 3;
	and.b32  	%r145, %r144, 8;
	setp.eq.s32 	%p81, %r143, 0;
	selp.f64 	%fd378, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p81;
	mul.wide.s32 	%rd41, %r145, 8;
	add.s64 	%rd43, %rd34, %rd41;
	ld.global.nc.f64 	%fd379, [%rd43+8];
	mul.rn.f64 	%fd62, %fd789, %fd789;
	fma.rn.f64 	%fd380, %fd378, %fd62, %fd379;
	ld.global.nc.f64 	%fd381, [%rd43+16];
	fma.rn.f64 	%fd382, %fd380, %fd62, %fd381;
	ld.global.nc.f64 	%fd383, [%rd43+24];
	fma.rn.f64 	%fd384, %fd382, %fd62, %fd383;
	ld.global.nc.f64 	%fd385, [%rd43+32];
	fma.rn.f64 	%fd386, %fd384, %fd62, %fd385;
	ld.global.nc.f64 	%fd387, [%rd43+40];
	fma.rn.f64 	%fd388, %fd386, %fd62, %fd387;
	ld.global.nc.f64 	%fd389, [%rd43+48];
	fma.rn.f64 	%fd63, %fd388, %fd62, %fd389;
	fma.rn.f64 	%fd791, %fd63, %fd789, %fd789;
	@%p81 bra 	$L__BB8_57;

	mov.f64 	%fd390, 0d3FF0000000000000;
	fma.rn.f64 	%fd791, %fd63, %fd62, %fd390;

$L__BB8_57:
	and.b32  	%r146, %r334, 2;
	setp.eq.s32 	%p82, %r146, 0;
	@%p82 bra 	$L__BB8_59;

	mov.f64 	%fd391, 0d0000000000000000;
	mov.f64 	%fd392, 0dBFF0000000000000;
	fma.rn.f64 	%fd791, %fd791, %fd392, %fd391;

$L__BB8_59:
	mul.rn.f64 	%fd839, %fd38, %fd791;
	@%p3 bra 	$L__BB8_62;
	bra.uni 	$L__BB8_60;

$L__BB8_62:
	mov.f64 	%fd402, 0d0000000000000000;
	mul.rn.f64 	%fd792, %fd56, %fd402;
	mov.u32 	%r335, 0;
	bra.uni 	$L__BB8_63;

$L__BB8_60:
	mul.rn.f64 	%fd393, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r335, %fd393;
	st.local.u32 	[%rd1], %r335;
	cvt.rn.f64.s32 	%fd394, %r335;
	neg.f64 	%fd395, %fd394;
	mov.f64 	%fd396, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd397, %fd395, %fd396, %fd56;
	mov.f64 	%fd398, 0d3C91A62633145C00;
	fma.rn.f64 	%fd399, %fd395, %fd398, %fd397;
	mov.f64 	%fd400, 0d397B839A252049C0;
	fma.rn.f64 	%fd792, %fd395, %fd400, %fd399;
	abs.f64 	%fd401, %fd56;
	setp.ltu.f64 	%p83, %fd401, 0d41E0000000000000;
	@%p83 bra 	$L__BB8_63;

	{ // callseq 165, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd792, [retval0+0];
	} // callseq 165
	ld.local.u32 	%r335, [%rd1];

$L__BB8_63:
	and.b32  	%r148, %r335, 1;
	shl.b32 	%r149, %r335, 3;
	and.b32  	%r150, %r149, 8;
	setp.eq.s32 	%p84, %r148, 0;
	selp.f64 	%fd403, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p84;
	mul.wide.s32 	%rd45, %r150, 8;
	add.s64 	%rd47, %rd34, %rd45;
	ld.global.nc.f64 	%fd404, [%rd47+8];
	mul.rn.f64 	%fd74, %fd792, %fd792;
	fma.rn.f64 	%fd405, %fd403, %fd74, %fd404;
	ld.global.nc.f64 	%fd406, [%rd47+16];
	fma.rn.f64 	%fd407, %fd405, %fd74, %fd406;
	ld.global.nc.f64 	%fd408, [%rd47+24];
	fma.rn.f64 	%fd409, %fd407, %fd74, %fd408;
	ld.global.nc.f64 	%fd410, [%rd47+32];
	fma.rn.f64 	%fd411, %fd409, %fd74, %fd410;
	ld.global.nc.f64 	%fd412, [%rd47+40];
	fma.rn.f64 	%fd413, %fd411, %fd74, %fd412;
	ld.global.nc.f64 	%fd414, [%rd47+48];
	fma.rn.f64 	%fd75, %fd413, %fd74, %fd414;
	fma.rn.f64 	%fd794, %fd75, %fd792, %fd792;
	@%p84 bra 	$L__BB8_65;

	mov.f64 	%fd415, 0d3FF0000000000000;
	fma.rn.f64 	%fd794, %fd75, %fd74, %fd415;

$L__BB8_65:
	and.b32  	%r151, %r335, 2;
	setp.eq.s32 	%p85, %r151, 0;
	@%p85 bra 	$L__BB8_67;

	mov.f64 	%fd416, 0d0000000000000000;
	mov.f64 	%fd417, 0dBFF0000000000000;
	fma.rn.f64 	%fd794, %fd794, %fd417, %fd416;

$L__BB8_67:
	ld.param.u32 	%r329, [bd09_to_gcj02_exact_cuda_param_4];
	mul.rn.f64 	%fd840, %fd38, %fd794;
	setp.lt.s32 	%p86, %r329, 1;
	@%p86 bra 	$L__BB8_208;

	and.b32  	%r23, %r2, 2147483647;
	setp.gt.s32 	%p87, %r2, -1;
	selp.b32 	%r24, 2146435072, 0, %p87;
	mov.u32 	%r336, 0;
	or.b32  	%r25, %r24, -2147483648;
	mov.f64 	%fd795, %fd840;
	mov.f64 	%fd796, %fd839;

$L__BB8_69:
	mov.f64 	%fd839, %fd796;
	mov.f64 	%fd840, %fd795;
	abs.f64 	%fd84, %fd839;
	{ // callseq 166, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd799, [retval0+0];
	} // callseq 166
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd839;
	}
	setp.lt.s32 	%p88, %r27, 0;
	and.pred  	%p4, %p88, %p9;
	not.pred 	%p90, %p4;
	@%p90 bra 	$L__BB8_71;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd799;
	}
	xor.b32  	%r154, %r153, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r155, %temp}, %fd799;
	}
	mov.b64 	%fd799, {%r155, %r154};

$L__BB8_71:
	setp.eq.f64 	%p91, %fd839, 0d0000000000000000;
	@%p91 bra 	$L__BB8_75;
	bra.uni 	$L__BB8_72;

$L__BB8_75:
	setp.lt.s32 	%p94, %r2, 0;
	mov.u32 	%r156, 0;
	selp.b32 	%r157, %r27, 0, %p9;
	or.b32  	%r158, %r157, 2146435072;
	selp.b32 	%r159, %r158, %r157, %p94;
	mov.b64 	%fd799, {%r156, %r159};
	bra.uni 	$L__BB8_76;

$L__BB8_72:
	setp.gt.s32 	%p92, %r27, -1;
	@%p92 bra 	$L__BB8_76;

	mov.f64 	%fd418, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd419, %fd418;
	setp.eq.f64 	%p93, %fd419, 0d4000000000000000;
	@%p93 bra 	$L__BB8_76;

	mov.f64 	%fd799, 0dFFF8000000000000;

$L__BB8_76:
	add.rn.f64 	%fd421, %fd839, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r160}, %fd421;
	}
	and.b32  	%r161, %r160, 2146435072;
	setp.ne.s32 	%p96, %r161, 2146435072;
	@%p96 bra 	$L__BB8_83;

	setp.gtu.f64 	%p97, %fd84, 0d7FF0000000000000;
	@%p97 bra 	$L__BB8_82;
	bra.uni 	$L__BB8_78;

$L__BB8_82:
	mov.f64 	%fd423, 0d4000000000000000;
	add.rn.f64 	%fd799, %fd839, %fd423;
	bra.uni 	$L__BB8_83;

$L__BB8_78:
	setp.eq.s32 	%p98, %r23, 2146435072;
	mov.f64 	%fd422, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r162, %temp}, %fd422;
	}
	setp.eq.s32 	%p99, %r162, 0;
	and.pred  	%p100, %p98, %p99;
	@%p100 bra 	$L__BB8_81;
	bra.uni 	$L__BB8_79;

$L__BB8_81:
	setp.lt.s32 	%p106, %r2, 0;
	mov.u32 	%r167, 0;
	setp.gt.f64 	%p107, %fd84, 0d3FF0000000000000;
	selp.b32 	%r168, 2146435072, 0, %p107;
	xor.b32  	%r169, %r168, 2146435072;
	selp.b32 	%r170, %r169, %r168, %p106;
	setp.eq.f64 	%p108, %fd839, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p108;
	mov.b64 	%fd799, {%r167, %r171};
	bra.uni 	$L__BB8_83;

$L__BB8_79:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r163, %temp}, %fd839;
	}
	and.b32  	%r164, %r27, 2147483647;
	setp.ne.s32 	%p101, %r164, 2146435072;
	setp.ne.s32 	%p102, %r163, 0;
	or.pred  	%p103, %p101, %p102;
	@%p103 bra 	$L__BB8_83;

	setp.ne.s32 	%p104, %r23, 1071644672;
	and.pred  	%p105, %p104, %p4;
	selp.b32 	%r165, %r25, %r24, %p105;
	mov.u32 	%r166, 0;
	mov.b64 	%fd799, {%r166, %r165};

$L__BB8_83:
	abs.f64 	%fd94, %fd840;
	{ // callseq 167, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd802, [retval0+0];
	} // callseq 167
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd840;
	}
	setp.lt.s32 	%p109, %r28, 0;
	and.pred  	%p5, %p109, %p9;
	not.pred 	%p111, %p5;
	@%p111 bra 	$L__BB8_85;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd802;
	}
	xor.b32  	%r173, %r172, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r174, %temp}, %fd802;
	}
	mov.b64 	%fd802, {%r174, %r173};

$L__BB8_85:
	setp.eq.f64 	%p112, %fd840, 0d0000000000000000;
	@%p112 bra 	$L__BB8_89;
	bra.uni 	$L__BB8_86;

$L__BB8_89:
	setp.lt.s32 	%p115, %r2, 0;
	mov.u32 	%r175, 0;
	selp.b32 	%r176, %r28, 0, %p9;
	or.b32  	%r177, %r176, 2146435072;
	selp.b32 	%r178, %r177, %r176, %p115;
	mov.b64 	%fd802, {%r175, %r178};
	bra.uni 	$L__BB8_90;

$L__BB8_86:
	setp.gt.s32 	%p113, %r28, -1;
	@%p113 bra 	$L__BB8_90;

	mov.f64 	%fd424, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd425, %fd424;
	setp.eq.f64 	%p114, %fd425, 0d4000000000000000;
	@%p114 bra 	$L__BB8_90;

	mov.f64 	%fd802, 0dFFF8000000000000;

$L__BB8_90:
	add.rn.f64 	%fd427, %fd840, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd427;
	}
	and.b32  	%r180, %r179, 2146435072;
	setp.ne.s32 	%p117, %r180, 2146435072;
	@%p117 bra 	$L__BB8_97;

	setp.gtu.f64 	%p118, %fd94, 0d7FF0000000000000;
	@%p118 bra 	$L__BB8_96;
	bra.uni 	$L__BB8_92;

$L__BB8_96:
	mov.f64 	%fd429, 0d4000000000000000;
	add.rn.f64 	%fd802, %fd840, %fd429;
	bra.uni 	$L__BB8_97;

$L__BB8_92:
	setp.eq.s32 	%p119, %r23, 2146435072;
	mov.f64 	%fd428, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %fd428;
	}
	setp.eq.s32 	%p120, %r181, 0;
	and.pred  	%p121, %p119, %p120;
	@%p121 bra 	$L__BB8_95;
	bra.uni 	$L__BB8_93;

$L__BB8_95:
	setp.lt.s32 	%p127, %r2, 0;
	mov.u32 	%r186, 0;
	setp.gt.f64 	%p128, %fd94, 0d3FF0000000000000;
	selp.b32 	%r187, 2146435072, 0, %p128;
	xor.b32  	%r188, %r187, 2146435072;
	selp.b32 	%r189, %r188, %r187, %p127;
	setp.eq.f64 	%p129, %fd840, 0dBFF0000000000000;
	selp.b32 	%r190, 1072693248, %r189, %p129;
	mov.b64 	%fd802, {%r186, %r190};
	bra.uni 	$L__BB8_97;

$L__BB8_93:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd840;
	}
	and.b32  	%r183, %r28, 2147483647;
	setp.ne.s32 	%p122, %r183, 2146435072;
	setp.ne.s32 	%p123, %r182, 0;
	or.pred  	%p124, %p122, %p123;
	@%p124 bra 	$L__BB8_97;

	setp.ne.s32 	%p125, %r23, 1071644672;
	and.pred  	%p126, %p125, %p5;
	selp.b32 	%r184, %r25, %r24, %p126;
	mov.u32 	%r185, 0;
	mov.b64 	%fd802, {%r185, %r184};

$L__BB8_97:
	setp.eq.f64 	%p130, %fd840, 0d3FF0000000000000;
	selp.f64 	%fd430, 0d3FF0000000000000, %fd802, %p130;
	setp.eq.f64 	%p131, %fd839, 0d3FF0000000000000;
	selp.f64 	%fd431, 0d3FF0000000000000, %fd799, %p131;
	add.rn.f64 	%fd104, %fd431, %fd430;
	mul.rn.f64 	%fd105, %fd840, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r191, %temp}, %fd105;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd105;
	}
	and.b32  	%r193, %r192, 2147483647;
	setp.eq.s32 	%p132, %r193, 2146435072;
	setp.eq.s32 	%p133, %r191, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB8_100;
	bra.uni 	$L__BB8_98;

$L__BB8_100:
	mov.f64 	%fd441, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd105, %fd441;
	mov.u32 	%r337, 0;
	bra.uni 	$L__BB8_101;

$L__BB8_98:
	mul.rn.f64 	%fd432, %fd105, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r337, %fd432;
	st.local.u32 	[%rd1], %r337;
	cvt.rn.f64.s32 	%fd433, %r337;
	neg.f64 	%fd434, %fd433;
	mov.f64 	%fd435, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd436, %fd434, %fd435, %fd105;
	mov.f64 	%fd437, 0d3C91A62633145C00;
	fma.rn.f64 	%fd438, %fd434, %fd437, %fd436;
	mov.f64 	%fd439, 0d397B839A252049C0;
	fma.rn.f64 	%fd803, %fd434, %fd439, %fd438;
	abs.f64 	%fd440, %fd105;
	setp.ltu.f64 	%p135, %fd440, 0d41E0000000000000;
	@%p135 bra 	$L__BB8_101;

	{ // callseq 168, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd803, [retval0+0];
	} // callseq 168
	ld.local.u32 	%r337, [%rd1];

$L__BB8_101:
	and.b32  	%r195, %r337, 1;
	shl.b32 	%r196, %r337, 3;
	and.b32  	%r197, %r196, 8;
	setp.eq.s32 	%p136, %r195, 0;
	selp.f64 	%fd442, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd49, %r197, 8;
	add.s64 	%rd51, %rd34, %rd49;
	ld.global.nc.f64 	%fd443, [%rd51+8];
	mul.rn.f64 	%fd110, %fd803, %fd803;
	fma.rn.f64 	%fd444, %fd442, %fd110, %fd443;
	ld.global.nc.f64 	%fd445, [%rd51+16];
	fma.rn.f64 	%fd446, %fd444, %fd110, %fd445;
	ld.global.nc.f64 	%fd447, [%rd51+24];
	fma.rn.f64 	%fd448, %fd446, %fd110, %fd447;
	ld.global.nc.f64 	%fd449, [%rd51+32];
	fma.rn.f64 	%fd450, %fd448, %fd110, %fd449;
	ld.global.nc.f64 	%fd451, [%rd51+40];
	fma.rn.f64 	%fd452, %fd450, %fd110, %fd451;
	ld.global.nc.f64 	%fd453, [%rd51+48];
	fma.rn.f64 	%fd111, %fd452, %fd110, %fd453;
	fma.rn.f64 	%fd805, %fd111, %fd803, %fd803;
	@%p136 bra 	$L__BB8_103;

	mov.f64 	%fd454, 0d3FF0000000000000;
	fma.rn.f64 	%fd805, %fd111, %fd110, %fd454;

$L__BB8_103:
	and.b32  	%r198, %r337, 2;
	setp.eq.s32 	%p137, %r198, 0;
	@%p137 bra 	$L__BB8_105;

	mov.f64 	%fd455, 0d0000000000000000;
	mov.f64 	%fd456, 0dBFF0000000000000;
	fma.rn.f64 	%fd805, %fd805, %fd456, %fd455;

$L__BB8_105:
	mul.rn.f64 	%fd457, %fd805, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd458, %fd104;
	add.rn.f64 	%fd117, %fd458, %fd457;
	setp.eq.f64 	%p138, %fd94, 0d0000000000000000;
	setp.eq.f64 	%p139, %fd84, 0d0000000000000000;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB8_109;
	bra.uni 	$L__BB8_106;

$L__BB8_109:
	selp.f64 	%fd511, 0d400921FB54442D18, 0d0000000000000000, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd511;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd511;
	}
	and.b32  	%r209, %r28, -2147483648;
	or.b32  	%r210, %r208, %r209;
	mov.b64 	%fd806, {%r207, %r210};
	bra.uni 	$L__BB8_110;

$L__BB8_106:
	setp.eq.f64 	%p141, %fd84, 0d7FF0000000000000;
	setp.eq.f64 	%p142, %fd94, 0d7FF0000000000000;
	and.pred  	%p143, %p141, %p142;
	@%p143 bra 	$L__BB8_108;
	bra.uni 	$L__BB8_107;

$L__BB8_108:
	selp.f64 	%fd510, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd510;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd510;
	}
	and.b32  	%r205, %r28, -2147483648;
	or.b32  	%r206, %r204, %r205;
	mov.b64 	%fd806, {%r203, %r206};
	bra.uni 	$L__BB8_110;

$L__BB8_107:
	min.f64 	%fd459, %fd94, %fd84;
	max.f64 	%fd460, %fd94, %fd84;
	div.rn.f64 	%fd461, %fd459, %fd460;
	mul.rn.f64 	%fd462, %fd461, %fd461;
	mov.f64 	%fd463, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd464, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd465, %fd464, %fd462, %fd463;
	mov.f64 	%fd466, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd467, %fd465, %fd462, %fd466;
	mov.f64 	%fd468, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd469, %fd467, %fd462, %fd468;
	mov.f64 	%fd470, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd471, %fd469, %fd462, %fd470;
	mov.f64 	%fd472, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd473, %fd471, %fd462, %fd472;
	mov.f64 	%fd474, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd475, %fd473, %fd462, %fd474;
	mov.f64 	%fd476, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd477, %fd475, %fd462, %fd476;
	mov.f64 	%fd478, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd479, %fd477, %fd462, %fd478;
	mov.f64 	%fd480, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd481, %fd479, %fd462, %fd480;
	mov.f64 	%fd482, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd483, %fd481, %fd462, %fd482;
	mov.f64 	%fd484, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd485, %fd483, %fd462, %fd484;
	mov.f64 	%fd486, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd487, %fd485, %fd462, %fd486;
	mov.f64 	%fd488, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd489, %fd487, %fd462, %fd488;
	mov.f64 	%fd490, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd491, %fd489, %fd462, %fd490;
	mov.f64 	%fd492, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd493, %fd491, %fd462, %fd492;
	mov.f64 	%fd494, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd495, %fd493, %fd462, %fd494;
	mov.f64 	%fd496, 0d3FC99999999840D2;
	fma.rn.f64 	%fd497, %fd495, %fd462, %fd496;
	mov.f64 	%fd498, 0dBFD555555555544C;
	fma.rn.f64 	%fd499, %fd497, %fd462, %fd498;
	mul.rn.f64 	%fd500, %fd462, %fd499;
	fma.rn.f64 	%fd501, %fd500, %fd461, %fd461;
	mov.f64 	%fd502, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd503, %fd502, %fd501;
	setp.gt.f64 	%p145, %fd94, %fd84;
	selp.f64 	%fd504, %fd503, %fd501, %p145;
	mov.f64 	%fd505, 0d400921FB54442D18;
	sub.rn.f64 	%fd506, %fd505, %fd504;
	selp.f64 	%fd507, %fd506, %fd504, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r199, %temp}, %fd507;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd507;
	}
	and.b32  	%r201, %r28, -2147483648;
	or.b32  	%r202, %r200, %r201;
	mov.b64 	%fd508, {%r199, %r202};
	add.rn.f64 	%fd509, %fd84, %fd94;
	setp.le.f64 	%p146, %fd509, 0d7FF0000000000000;
	selp.f64 	%fd806, %fd508, %fd509, %p146;

$L__BB8_110:
	mul.rn.f64 	%fd122, %fd839, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r211, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd122;
	}
	and.b32  	%r213, %r212, 2147483647;
	setp.eq.s32 	%p149, %r213, 2146435072;
	setp.eq.s32 	%p150, %r211, 0;
	and.pred  	%p151, %p150, %p149;
	@%p151 bra 	$L__BB8_114;
	bra.uni 	$L__BB8_111;

$L__BB8_114:
	mov.f64 	%fd521, 0d0000000000000000;
	mul.rn.f64 	%fd808, %fd122, %fd521;
	mov.u32 	%r339, 1;
	bra.uni 	$L__BB8_115;

$L__BB8_111:
	mul.rn.f64 	%fd512, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd512;
	st.local.u32 	[%rd1], %r338;
	cvt.rn.f64.s32 	%fd513, %r338;
	neg.f64 	%fd514, %fd513;
	mov.f64 	%fd515, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd516, %fd514, %fd515, %fd122;
	mov.f64 	%fd517, 0d3C91A62633145C00;
	fma.rn.f64 	%fd518, %fd514, %fd517, %fd516;
	mov.f64 	%fd519, 0d397B839A252049C0;
	fma.rn.f64 	%fd808, %fd514, %fd519, %fd518;
	abs.f64 	%fd520, %fd122;
	setp.ltu.f64 	%p152, %fd520, 0d41E0000000000000;
	@%p152 bra 	$L__BB8_113;

	{ // callseq 169, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 169
	ld.local.u32 	%r338, [%rd1];

$L__BB8_113:
	add.s32 	%r339, %r338, 1;

$L__BB8_115:
	and.b32  	%r215, %r339, 1;
	shl.b32 	%r216, %r339, 3;
	and.b32  	%r217, %r216, 8;
	setp.eq.s32 	%p153, %r215, 0;
	selp.f64 	%fd522, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p153;
	mul.wide.s32 	%rd53, %r217, 8;
	add.s64 	%rd55, %rd34, %rd53;
	ld.global.nc.f64 	%fd523, [%rd55+8];
	mul.rn.f64 	%fd128, %fd808, %fd808;
	fma.rn.f64 	%fd524, %fd522, %fd128, %fd523;
	ld.global.nc.f64 	%fd525, [%rd55+16];
	fma.rn.f64 	%fd526, %fd524, %fd128, %fd525;
	ld.global.nc.f64 	%fd527, [%rd55+24];
	fma.rn.f64 	%fd528, %fd526, %fd128, %fd527;
	ld.global.nc.f64 	%fd529, [%rd55+32];
	fma.rn.f64 	%fd530, %fd528, %fd128, %fd529;
	ld.global.nc.f64 	%fd531, [%rd55+40];
	fma.rn.f64 	%fd532, %fd530, %fd128, %fd531;
	ld.global.nc.f64 	%fd533, [%rd55+48];
	fma.rn.f64 	%fd129, %fd532, %fd128, %fd533;
	fma.rn.f64 	%fd810, %fd129, %fd808, %fd808;
	@%p153 bra 	$L__BB8_117;

	mov.f64 	%fd534, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd129, %fd128, %fd534;

$L__BB8_117:
	and.b32  	%r218, %r339, 2;
	setp.eq.s32 	%p154, %r218, 0;
	@%p154 bra 	$L__BB8_119;

	mov.f64 	%fd535, 0d0000000000000000;
	mov.f64 	%fd536, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd536, %fd535;

$L__BB8_119:
	mul.rn.f64 	%fd537, %fd810, 0d3EC92A737110E454;
	add.rn.f64 	%fd135, %fd806, %fd537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r219, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r220}, %fd135;
	}
	and.b32  	%r221, %r220, 2147483647;
	setp.eq.s32 	%p155, %r221, 2146435072;
	setp.eq.s32 	%p156, %r219, 0;
	and.pred  	%p6, %p156, %p155;
	@%p6 bra 	$L__BB8_123;
	bra.uni 	$L__BB8_120;

$L__BB8_123:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd812, %fd135, %fd547;
	mov.u32 	%r341, 1;
	bra.uni 	$L__BB8_124;

$L__BB8_120:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r340, %fd538;
	st.local.u32 	[%rd1], %r340;
	cvt.rn.f64.s32 	%fd539, %r340;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd812, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p157, %fd546, 0d41E0000000000000;
	@%p157 bra 	$L__BB8_122;

	{ // callseq 170, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 170
	ld.local.u32 	%r340, [%rd1];

$L__BB8_122:
	add.s32 	%r341, %r340, 1;

$L__BB8_124:
	and.b32  	%r223, %r341, 1;
	shl.b32 	%r224, %r341, 3;
	and.b32  	%r225, %r224, 8;
	setp.eq.s32 	%p158, %r223, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p158;
	mul.wide.s32 	%rd57, %r225, 8;
	add.s64 	%rd59, %rd34, %rd57;
	ld.global.nc.f64 	%fd549, [%rd59+8];
	mul.rn.f64 	%fd141, %fd812, %fd812;
	fma.rn.f64 	%fd550, %fd548, %fd141, %fd549;
	ld.global.nc.f64 	%fd551, [%rd59+16];
	fma.rn.f64 	%fd552, %fd550, %fd141, %fd551;
	ld.global.nc.f64 	%fd553, [%rd59+24];
	fma.rn.f64 	%fd554, %fd552, %fd141, %fd553;
	ld.global.nc.f64 	%fd555, [%rd59+32];
	fma.rn.f64 	%fd556, %fd554, %fd141, %fd555;
	ld.global.nc.f64 	%fd557, [%rd59+40];
	fma.rn.f64 	%fd558, %fd556, %fd141, %fd557;
	ld.global.nc.f64 	%fd559, [%rd59+48];
	fma.rn.f64 	%fd142, %fd558, %fd141, %fd559;
	fma.rn.f64 	%fd814, %fd142, %fd812, %fd812;
	@%p158 bra 	$L__BB8_126;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd142, %fd141, %fd560;

$L__BB8_126:
	and.b32  	%r226, %r341, 2;
	setp.eq.s32 	%p159, %r226, 0;
	@%p159 bra 	$L__BB8_128;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd562, %fd561;

$L__BB8_128:
	mul.rn.f64 	%fd563, %fd117, %fd814;
	add.rn.f64 	%fd148, %fd563, 0d3F7A9FBE76C8B439;
	@%p6 bra 	$L__BB8_131;
	bra.uni 	$L__BB8_129;

$L__BB8_131:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd135, %fd573;
	mov.u32 	%r342, 0;
	bra.uni 	$L__BB8_132;

$L__BB8_129:
	mul.rn.f64 	%fd564, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r342, %fd564;
	st.local.u32 	[%rd1], %r342;
	cvt.rn.f64.s32 	%fd565, %r342;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd135;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd135;
	setp.ltu.f64 	%p160, %fd572, 0d41E0000000000000;
	@%p160 bra 	$L__BB8_132;

	{ // callseq 171, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 171
	ld.local.u32 	%r342, [%rd1];

$L__BB8_132:
	and.b32  	%r228, %r342, 1;
	shl.b32 	%r229, %r342, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p161, %r228, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p161;
	mul.wide.s32 	%rd61, %r230, 8;
	add.s64 	%rd63, %rd34, %rd61;
	ld.global.nc.f64 	%fd575, [%rd63+8];
	mul.rn.f64 	%fd153, %fd815, %fd815;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd63+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd63+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd63+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd63+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd63+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd817, %fd154, %fd815, %fd815;
	@%p161 bra 	$L__BB8_134;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd154, %fd153, %fd586;

$L__BB8_134:
	and.b32  	%r231, %r342, 2;
	setp.eq.s32 	%p162, %r231, 0;
	@%p162 bra 	$L__BB8_136;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd588, %fd587;

$L__BB8_136:
	ld.param.s8 	%rs2, [bd09_to_gcj02_exact_cuda_param_3];
	mul.rn.f64 	%fd589, %fd117, %fd817;
	add.rn.f64 	%fd590, %fd589, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd160, %fd3, %fd590;
	sub.rn.f64 	%fd161, %fd1, %fd148;
	add.rn.f64 	%fd796, %fd839, %fd161;
	add.rn.f64 	%fd795, %fd840, %fd160;
	setp.eq.s16 	%p163, %rs2, 0;
	@%p163 bra 	$L__BB8_205;

	mul.rn.f64 	%fd591, %fd840, 0d400921FB54442D18;
	div.rn.f64 	%fd164, %fd591, 0d4066800000000000;
	mul.rn.f64 	%fd592, %fd795, 0d400921FB54442D18;
	div.rn.f64 	%fd165, %fd592, 0d4066800000000000;
	sub.rn.f64 	%fd593, %fd165, %fd164;
	mul.rn.f64 	%fd166, %fd593, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r232, %temp}, %fd166;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r233}, %fd166;
	}
	and.b32  	%r234, %r233, 2147483647;
	setp.eq.s32 	%p164, %r234, 2146435072;
	setp.eq.s32 	%p165, %r232, 0;
	and.pred  	%p166, %p165, %p164;
	@%p166 bra 	$L__BB8_140;
	bra.uni 	$L__BB8_138;

$L__BB8_140:
	mov.f64 	%fd603, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd166, %fd603;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB8_141;

$L__BB8_205:
	abs.f64 	%fd771, %fd161;
	setp.geu.f64 	%p244, %fd771, %fd246;
	@%p244 bra 	$L__BB8_207;

	abs.f64 	%fd772, %fd160;
	setp.lt.f64 	%p245, %fd772, %fd246;
	@%p245 bra 	$L__BB8_208;
	bra.uni 	$L__BB8_207;

$L__BB8_138:
	mul.rn.f64 	%fd594, %fd166, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r343, %fd594;
	st.local.u32 	[%rd1], %r343;
	cvt.rn.f64.s32 	%fd595, %r343;
	neg.f64 	%fd596, %fd595;
	mov.f64 	%fd597, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd598, %fd596, %fd597, %fd166;
	mov.f64 	%fd599, 0d3C91A62633145C00;
	fma.rn.f64 	%fd600, %fd596, %fd599, %fd598;
	mov.f64 	%fd601, 0d397B839A252049C0;
	fma.rn.f64 	%fd818, %fd596, %fd601, %fd600;
	abs.f64 	%fd602, %fd166;
	setp.ltu.f64 	%p167, %fd602, 0d41E0000000000000;
	@%p167 bra 	$L__BB8_141;

	{ // callseq 172, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd166;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd818, [retval0+0];
	} // callseq 172
	ld.local.u32 	%r343, [%rd1];

$L__BB8_141:
	and.b32  	%r236, %r343, 1;
	shl.b32 	%r237, %r343, 3;
	and.b32  	%r238, %r237, 8;
	setp.eq.s32 	%p168, %r236, 0;
	selp.f64 	%fd604, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p168;
	mul.wide.s32 	%rd65, %r238, 8;
	add.s64 	%rd67, %rd34, %rd65;
	ld.global.nc.f64 	%fd605, [%rd67+8];
	mul.rn.f64 	%fd171, %fd818, %fd818;
	fma.rn.f64 	%fd606, %fd604, %fd171, %fd605;
	ld.global.nc.f64 	%fd607, [%rd67+16];
	fma.rn.f64 	%fd608, %fd606, %fd171, %fd607;
	ld.global.nc.f64 	%fd609, [%rd67+24];
	fma.rn.f64 	%fd610, %fd608, %fd171, %fd609;
	ld.global.nc.f64 	%fd611, [%rd67+32];
	fma.rn.f64 	%fd612, %fd610, %fd171, %fd611;
	ld.global.nc.f64 	%fd613, [%rd67+40];
	fma.rn.f64 	%fd614, %fd612, %fd171, %fd613;
	ld.global.nc.f64 	%fd615, [%rd67+48];
	fma.rn.f64 	%fd172, %fd614, %fd171, %fd615;
	fma.rn.f64 	%fd820, %fd172, %fd818, %fd818;
	@%p168 bra 	$L__BB8_143;

	mov.f64 	%fd616, 0d3FF0000000000000;
	fma.rn.f64 	%fd820, %fd172, %fd171, %fd616;

$L__BB8_143:
	and.b32  	%r239, %r343, 2;
	setp.eq.s32 	%p169, %r239, 0;
	@%p169 bra 	$L__BB8_145;

	mov.f64 	%fd617, 0d0000000000000000;
	mov.f64 	%fd618, 0dBFF0000000000000;
	fma.rn.f64 	%fd820, %fd820, %fd618, %fd617;

$L__BB8_145:
	abs.f64 	%fd178, %fd820;
	{ // callseq 173, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 173
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd820;
	}
	setp.lt.s32 	%p170, %r48, 0;
	and.pred  	%p7, %p170, %p9;
	not.pred 	%p172, %p7;
	@%p172 bra 	$L__BB8_147;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %fd823;
	}
	xor.b32  	%r241, %r240, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd823;
	}
	mov.b64 	%fd823, {%r242, %r241};

$L__BB8_147:
	setp.eq.f64 	%p173, %fd820, 0d0000000000000000;
	@%p173 bra 	$L__BB8_151;
	bra.uni 	$L__BB8_148;

$L__BB8_151:
	setp.lt.s32 	%p176, %r2, 0;
	mov.u32 	%r243, 0;
	selp.b32 	%r244, %r48, 0, %p9;
	or.b32  	%r245, %r244, 2146435072;
	selp.b32 	%r246, %r245, %r244, %p176;
	mov.b64 	%fd823, {%r243, %r246};
	bra.uni 	$L__BB8_152;

$L__BB8_148:
	setp.gt.s32 	%p174, %r48, -1;
	@%p174 bra 	$L__BB8_152;

	mov.f64 	%fd619, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd620, %fd619;
	setp.eq.f64 	%p175, %fd620, 0d4000000000000000;
	@%p175 bra 	$L__BB8_152;

	mov.f64 	%fd823, 0dFFF8000000000000;

$L__BB8_152:
	add.rn.f64 	%fd622, %fd820, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd622;
	}
	and.b32  	%r248, %r247, 2146435072;
	setp.ne.s32 	%p178, %r248, 2146435072;
	@%p178 bra 	$L__BB8_159;

	setp.gtu.f64 	%p179, %fd178, 0d7FF0000000000000;
	@%p179 bra 	$L__BB8_158;
	bra.uni 	$L__BB8_154;

$L__BB8_158:
	mov.f64 	%fd624, 0d4000000000000000;
	add.rn.f64 	%fd823, %fd820, %fd624;
	bra.uni 	$L__BB8_159;

$L__BB8_154:
	setp.eq.s32 	%p180, %r23, 2146435072;
	mov.f64 	%fd623, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r249, %temp}, %fd623;
	}
	setp.eq.s32 	%p181, %r249, 0;
	and.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB8_157;
	bra.uni 	$L__BB8_155;

$L__BB8_157:
	setp.lt.s32 	%p188, %r2, 0;
	mov.u32 	%r254, 0;
	setp.gt.f64 	%p189, %fd178, 0d3FF0000000000000;
	selp.b32 	%r255, 2146435072, 0, %p189;
	xor.b32  	%r256, %r255, 2146435072;
	selp.b32 	%r257, %r256, %r255, %p188;
	setp.eq.f64 	%p190, %fd820, 0dBFF0000000000000;
	selp.b32 	%r258, 1072693248, %r257, %p190;
	mov.b64 	%fd823, {%r254, %r258};
	bra.uni 	$L__BB8_159;

$L__BB8_155:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r250, %temp}, %fd820;
	}
	and.b32  	%r251, %r48, 2147483647;
	setp.ne.s32 	%p183, %r251, 2146435072;
	setp.ne.s32 	%p184, %r250, 0;
	or.pred  	%p185, %p183, %p184;
	@%p185 bra 	$L__BB8_159;

	setp.ne.s32 	%p186, %r23, 1071644672;
	and.pred  	%p187, %p186, %p7;
	selp.b32 	%r252, %r25, %r24, %p187;
	mov.u32 	%r253, 0;
	mov.b64 	%fd823, {%r253, %r252};

$L__BB8_159:
	setp.eq.f64 	%p191, %fd820, 0d3FF0000000000000;
	selp.f64 	%fd188, 0d3FF0000000000000, %fd823, %p191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd164;
	}
	and.b32  	%r260, %r259, 2147483647;
	setp.eq.s32 	%p192, %r260, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r261, %temp}, %fd164;
	}
	setp.eq.s32 	%p193, %r261, 0;
	and.pred  	%p194, %p193, %p192;
	@%p194 bra 	$L__BB8_163;
	bra.uni 	$L__BB8_160;

$L__BB8_163:
	mov.f64 	%fd634, 0d0000000000000000;
	mul.rn.f64 	%fd825, %fd164, %fd634;
	mov.u32 	%r345, 1;
	bra.uni 	$L__BB8_164;

$L__BB8_160:
	mul.rn.f64 	%fd625, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd625;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd626, %r344;
	neg.f64 	%fd627, %fd626;
	mov.f64 	%fd628, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd629, %fd627, %fd628, %fd164;
	mov.f64 	%fd630, 0d3C91A62633145C00;
	fma.rn.f64 	%fd631, %fd627, %fd630, %fd629;
	mov.f64 	%fd632, 0d397B839A252049C0;
	fma.rn.f64 	%fd825, %fd627, %fd632, %fd631;
	abs.f64 	%fd633, %fd164;
	setp.ltu.f64 	%p195, %fd633, 0d41E0000000000000;
	@%p195 bra 	$L__BB8_162;

	{ // callseq 174, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd825, [retval0+0];
	} // callseq 174
	ld.local.u32 	%r344, [%rd1];

$L__BB8_162:
	add.s32 	%r345, %r344, 1;

$L__BB8_164:
	and.b32  	%r263, %r345, 1;
	shl.b32 	%r264, %r345, 3;
	and.b32  	%r265, %r264, 8;
	setp.eq.s32 	%p196, %r263, 0;
	selp.f64 	%fd635, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd69, %r265, 8;
	add.s64 	%rd71, %rd34, %rd69;
	ld.global.nc.f64 	%fd636, [%rd71+8];
	mul.rn.f64 	%fd194, %fd825, %fd825;
	fma.rn.f64 	%fd637, %fd635, %fd194, %fd636;
	ld.global.nc.f64 	%fd638, [%rd71+16];
	fma.rn.f64 	%fd639, %fd637, %fd194, %fd638;
	ld.global.nc.f64 	%fd640, [%rd71+24];
	fma.rn.f64 	%fd641, %fd639, %fd194, %fd640;
	ld.global.nc.f64 	%fd642, [%rd71+32];
	fma.rn.f64 	%fd643, %fd641, %fd194, %fd642;
	ld.global.nc.f64 	%fd644, [%rd71+40];
	fma.rn.f64 	%fd645, %fd643, %fd194, %fd644;
	ld.global.nc.f64 	%fd646, [%rd71+48];
	fma.rn.f64 	%fd195, %fd645, %fd194, %fd646;
	fma.rn.f64 	%fd827, %fd195, %fd825, %fd825;
	@%p196 bra 	$L__BB8_166;

	mov.f64 	%fd647, 0d3FF0000000000000;
	fma.rn.f64 	%fd827, %fd195, %fd194, %fd647;

$L__BB8_166:
	and.b32  	%r266, %r345, 2;
	setp.eq.s32 	%p197, %r266, 0;
	@%p197 bra 	$L__BB8_168;

	mov.f64 	%fd648, 0d0000000000000000;
	mov.f64 	%fd649, 0dBFF0000000000000;
	fma.rn.f64 	%fd827, %fd827, %fd649, %fd648;

$L__BB8_168:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd165;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p198, %r268, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r269, %temp}, %fd165;
	}
	setp.eq.s32 	%p199, %r269, 0;
	and.pred  	%p200, %p199, %p198;
	@%p200 bra 	$L__BB8_172;
	bra.uni 	$L__BB8_169;

$L__BB8_172:
	mov.f64 	%fd659, 0d0000000000000000;
	mul.rn.f64 	%fd829, %fd165, %fd659;
	mov.u32 	%r347, 1;
	bra.uni 	$L__BB8_173;

$L__BB8_169:
	mul.rn.f64 	%fd650, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r346, %fd650;
	st.local.u32 	[%rd1], %r346;
	cvt.rn.f64.s32 	%fd651, %r346;
	neg.f64 	%fd652, %fd651;
	mov.f64 	%fd653, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd654, %fd652, %fd653, %fd165;
	mov.f64 	%fd655, 0d3C91A62633145C00;
	fma.rn.f64 	%fd656, %fd652, %fd655, %fd654;
	mov.f64 	%fd657, 0d397B839A252049C0;
	fma.rn.f64 	%fd829, %fd652, %fd657, %fd656;
	abs.f64 	%fd658, %fd165;
	setp.ltu.f64 	%p201, %fd658, 0d41E0000000000000;
	@%p201 bra 	$L__BB8_171;

	{ // callseq 175, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd829, [retval0+0];
	} // callseq 175
	ld.local.u32 	%r346, [%rd1];

$L__BB8_171:
	add.s32 	%r347, %r346, 1;

$L__BB8_173:
	and.b32  	%r271, %r347, 1;
	shl.b32 	%r272, %r347, 3;
	and.b32  	%r273, %r272, 8;
	setp.eq.s32 	%p202, %r271, 0;
	selp.f64 	%fd660, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p202;
	mul.wide.s32 	%rd73, %r273, 8;
	add.s64 	%rd75, %rd34, %rd73;
	ld.global.nc.f64 	%fd661, [%rd75+8];
	mul.rn.f64 	%fd206, %fd829, %fd829;
	fma.rn.f64 	%fd662, %fd660, %fd206, %fd661;
	ld.global.nc.f64 	%fd663, [%rd75+16];
	fma.rn.f64 	%fd664, %fd662, %fd206, %fd663;
	ld.global.nc.f64 	%fd665, [%rd75+24];
	fma.rn.f64 	%fd666, %fd664, %fd206, %fd665;
	ld.global.nc.f64 	%fd667, [%rd75+32];
	fma.rn.f64 	%fd668, %fd666, %fd206, %fd667;
	ld.global.nc.f64 	%fd669, [%rd75+40];
	fma.rn.f64 	%fd670, %fd668, %fd206, %fd669;
	ld.global.nc.f64 	%fd671, [%rd75+48];
	fma.rn.f64 	%fd207, %fd670, %fd206, %fd671;
	fma.rn.f64 	%fd831, %fd207, %fd829, %fd829;
	@%p202 bra 	$L__BB8_175;

	mov.f64 	%fd672, 0d3FF0000000000000;
	fma.rn.f64 	%fd831, %fd207, %fd206, %fd672;

$L__BB8_175:
	and.b32  	%r274, %r347, 2;
	setp.eq.s32 	%p203, %r274, 0;
	@%p203 bra 	$L__BB8_177;

	mov.f64 	%fd673, 0d0000000000000000;
	mov.f64 	%fd674, 0dBFF0000000000000;
	fma.rn.f64 	%fd831, %fd831, %fd674, %fd673;

$L__BB8_177:
	mul.rn.f64 	%fd213, %fd827, %fd831;
	mul.rn.f64 	%fd675, %fd839, 0d400921FB54442D18;
	div.rn.f64 	%fd676, %fd675, 0d4066800000000000;
	mul.rn.f64 	%fd677, %fd796, 0d400921FB54442D18;
	div.rn.f64 	%fd678, %fd677, 0d4066800000000000;
	sub.rn.f64 	%fd679, %fd678, %fd676;
	mul.rn.f64 	%fd214, %fd679, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r275, %temp}, %fd214;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd214;
	}
	and.b32  	%r277, %r276, 2147483647;
	setp.eq.s32 	%p204, %r277, 2146435072;
	setp.eq.s32 	%p205, %r275, 0;
	and.pred  	%p206, %p205, %p204;
	@%p206 bra 	$L__BB8_180;
	bra.uni 	$L__BB8_178;

$L__BB8_180:
	mov.f64 	%fd689, 0d0000000000000000;
	mul.rn.f64 	%fd832, %fd214, %fd689;
	mov.u32 	%r348, 0;
	bra.uni 	$L__BB8_181;

$L__BB8_178:
	mul.rn.f64 	%fd680, %fd214, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r348, %fd680;
	st.local.u32 	[%rd1], %r348;
	cvt.rn.f64.s32 	%fd681, %r348;
	neg.f64 	%fd682, %fd681;
	mov.f64 	%fd683, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd684, %fd682, %fd683, %fd214;
	mov.f64 	%fd685, 0d3C91A62633145C00;
	fma.rn.f64 	%fd686, %fd682, %fd685, %fd684;
	mov.f64 	%fd687, 0d397B839A252049C0;
	fma.rn.f64 	%fd832, %fd682, %fd687, %fd686;
	abs.f64 	%fd688, %fd214;
	setp.ltu.f64 	%p207, %fd688, 0d41E0000000000000;
	@%p207 bra 	$L__BB8_181;

	{ // callseq 176, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd214;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 176
	ld.local.u32 	%r348, [%rd1];

$L__BB8_181:
	and.b32  	%r279, %r348, 1;
	shl.b32 	%r280, %r348, 3;
	and.b32  	%r281, %r280, 8;
	setp.eq.s32 	%p208, %r279, 0;
	selp.f64 	%fd690, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p208;
	mul.wide.s32 	%rd77, %r281, 8;
	add.s64 	%rd79, %rd34, %rd77;
	ld.global.nc.f64 	%fd691, [%rd79+8];
	mul.rn.f64 	%fd219, %fd832, %fd832;
	fma.rn.f64 	%fd692, %fd690, %fd219, %fd691;
	ld.global.nc.f64 	%fd693, [%rd79+16];
	fma.rn.f64 	%fd694, %fd692, %fd219, %fd693;
	ld.global.nc.f64 	%fd695, [%rd79+24];
	fma.rn.f64 	%fd696, %fd694, %fd219, %fd695;
	ld.global.nc.f64 	%fd697, [%rd79+32];
	fma.rn.f64 	%fd698, %fd696, %fd219, %fd697;
	ld.global.nc.f64 	%fd699, [%rd79+40];
	fma.rn.f64 	%fd700, %fd698, %fd219, %fd699;
	ld.global.nc.f64 	%fd701, [%rd79+48];
	fma.rn.f64 	%fd220, %fd700, %fd219, %fd701;
	fma.rn.f64 	%fd834, %fd220, %fd832, %fd832;
	@%p208 bra 	$L__BB8_183;

	mov.f64 	%fd702, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd220, %fd219, %fd702;

$L__BB8_183:
	and.b32  	%r282, %r348, 2;
	setp.eq.s32 	%p209, %r282, 0;
	@%p209 bra 	$L__BB8_185;

	mov.f64 	%fd703, 0d0000000000000000;
	mov.f64 	%fd704, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd704, %fd703;

$L__BB8_185:
	abs.f64 	%fd226, %fd834;
	{ // callseq 177, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd226;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd837, [retval0+0];
	} // callseq 177
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd834;
	}
	setp.lt.s32 	%p210, %r62, 0;
	and.pred  	%p8, %p210, %p9;
	not.pred 	%p212, %p8;
	@%p212 bra 	$L__BB8_187;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd837;
	}
	xor.b32  	%r284, %r283, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd837;
	}
	mov.b64 	%fd837, {%r285, %r284};

$L__BB8_187:
	setp.eq.f64 	%p213, %fd834, 0d0000000000000000;
	@%p213 bra 	$L__BB8_191;
	bra.uni 	$L__BB8_188;

$L__BB8_191:
	setp.lt.s32 	%p216, %r2, 0;
	mov.u32 	%r286, 0;
	selp.b32 	%r287, %r62, 0, %p9;
	or.b32  	%r288, %r287, 2146435072;
	selp.b32 	%r289, %r288, %r287, %p216;
	mov.b64 	%fd837, {%r286, %r289};
	bra.uni 	$L__BB8_192;

$L__BB8_188:
	setp.gt.s32 	%p214, %r62, -1;
	@%p214 bra 	$L__BB8_192;

	mov.f64 	%fd705, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd706, %fd705;
	setp.eq.f64 	%p215, %fd706, 0d4000000000000000;
	@%p215 bra 	$L__BB8_192;

	mov.f64 	%fd837, 0dFFF8000000000000;

$L__BB8_192:
	add.rn.f64 	%fd708, %fd834, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %fd708;
	}
	and.b32  	%r291, %r290, 2146435072;
	setp.ne.s32 	%p218, %r291, 2146435072;
	@%p218 bra 	$L__BB8_199;

	setp.gtu.f64 	%p219, %fd226, 0d7FF0000000000000;
	@%p219 bra 	$L__BB8_198;
	bra.uni 	$L__BB8_194;

$L__BB8_198:
	mov.f64 	%fd710, 0d4000000000000000;
	add.rn.f64 	%fd837, %fd834, %fd710;
	bra.uni 	$L__BB8_199;

$L__BB8_194:
	setp.eq.s32 	%p220, %r23, 2146435072;
	mov.f64 	%fd709, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd709;
	}
	setp.eq.s32 	%p221, %r292, 0;
	and.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB8_197;
	bra.uni 	$L__BB8_195;

$L__BB8_197:
	setp.lt.s32 	%p228, %r2, 0;
	mov.u32 	%r297, 0;
	setp.gt.f64 	%p229, %fd226, 0d3FF0000000000000;
	selp.b32 	%r298, 2146435072, 0, %p229;
	xor.b32  	%r299, %r298, 2146435072;
	selp.b32 	%r300, %r299, %r298, %p228;
	setp.eq.f64 	%p230, %fd834, 0dBFF0000000000000;
	selp.b32 	%r301, 1072693248, %r300, %p230;
	mov.b64 	%fd837, {%r297, %r301};
	bra.uni 	$L__BB8_199;

$L__BB8_195:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r293, %temp}, %fd834;
	}
	and.b32  	%r294, %r62, 2147483647;
	setp.ne.s32 	%p223, %r294, 2146435072;
	setp.ne.s32 	%p224, %r293, 0;
	or.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB8_199;

	setp.ne.s32 	%p226, %r23, 1071644672;
	and.pred  	%p227, %p226, %p8;
	selp.b32 	%r295, %r25, %r24, %p227;
	mov.u32 	%r296, 0;
	mov.b64 	%fd837, {%r296, %r295};

$L__BB8_199:
	setp.eq.f64 	%p231, %fd834, 0d3FF0000000000000;
	mov.f64 	%fd711, 0d3FF0000000000000;
	selp.f64 	%fd712, 0d3FF0000000000000, %fd837, %p231;
	mul.rn.f64 	%fd713, %fd213, %fd712;
	add.rn.f64 	%fd714, %fd188, %fd713;
	sqrt.rn.f64 	%fd236, %fd714;
	sub.rn.f64 	%fd715, %fd711, %fd714;
	sqrt.rn.f64 	%fd237, %fd715;
	abs.f64 	%fd238, %fd237;
	abs.f64 	%fd239, %fd236;
	setp.eq.f64 	%p232, %fd238, 0d0000000000000000;
	setp.eq.f64 	%p233, %fd239, 0d0000000000000000;
	and.pred  	%p234, %p232, %p233;
	@%p234 bra 	$L__BB8_203;
	bra.uni 	$L__BB8_200;

$L__BB8_203:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd237;
	}
	setp.lt.s32 	%p242, %r314, 0;
	selp.f64 	%fd768, 0d400921FB54442D18, 0d0000000000000000, %p242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r315, %temp}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r316}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd236;
	}
	and.b32  	%r318, %r317, -2147483648;
	or.b32  	%r319, %r316, %r318;
	mov.b64 	%fd838, {%r315, %r319};
	bra.uni 	$L__BB8_204;

$L__BB8_200:
	setp.eq.f64 	%p235, %fd238, 0d7FF0000000000000;
	setp.eq.f64 	%p236, %fd239, 0d7FF0000000000000;
	and.pred  	%p237, %p235, %p236;
	@%p237 bra 	$L__BB8_202;
	bra.uni 	$L__BB8_201;

$L__BB8_202:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r308}, %fd237;
	}
	setp.lt.s32 	%p241, %r308, 0;
	selp.f64 	%fd767, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p241;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r309, %temp}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r310}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r311}, %fd236;
	}
	and.b32  	%r312, %r311, -2147483648;
	or.b32  	%r313, %r310, %r312;
	mov.b64 	%fd838, {%r309, %r313};
	bra.uni 	$L__BB8_204;

$L__BB8_201:
	max.f64 	%fd716, %fd239, %fd238;
	min.f64 	%fd717, %fd239, %fd238;
	div.rn.f64 	%fd718, %fd717, %fd716;
	mul.rn.f64 	%fd719, %fd718, %fd718;
	mov.f64 	%fd720, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd721, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd722, %fd721, %fd719, %fd720;
	mov.f64 	%fd723, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd724, %fd722, %fd719, %fd723;
	mov.f64 	%fd725, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd726, %fd724, %fd719, %fd725;
	mov.f64 	%fd727, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd728, %fd726, %fd719, %fd727;
	mov.f64 	%fd729, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd730, %fd728, %fd719, %fd729;
	mov.f64 	%fd731, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd732, %fd730, %fd719, %fd731;
	mov.f64 	%fd733, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd734, %fd732, %fd719, %fd733;
	mov.f64 	%fd735, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd736, %fd734, %fd719, %fd735;
	mov.f64 	%fd737, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd738, %fd736, %fd719, %fd737;
	mov.f64 	%fd739, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd740, %fd738, %fd719, %fd739;
	mov.f64 	%fd741, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd742, %fd740, %fd719, %fd741;
	mov.f64 	%fd743, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd744, %fd742, %fd719, %fd743;
	mov.f64 	%fd745, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd746, %fd744, %fd719, %fd745;
	mov.f64 	%fd747, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd748, %fd746, %fd719, %fd747;
	mov.f64 	%fd749, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd750, %fd748, %fd719, %fd749;
	mov.f64 	%fd751, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd752, %fd750, %fd719, %fd751;
	mov.f64 	%fd753, 0d3FC99999999840D2;
	fma.rn.f64 	%fd754, %fd752, %fd719, %fd753;
	mov.f64 	%fd755, 0dBFD555555555544C;
	fma.rn.f64 	%fd756, %fd754, %fd719, %fd755;
	mul.rn.f64 	%fd757, %fd719, %fd756;
	fma.rn.f64 	%fd758, %fd757, %fd718, %fd718;
	mov.f64 	%fd759, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd760, %fd759, %fd758;
	setp.gt.f64 	%p238, %fd239, %fd238;
	selp.f64 	%fd761, %fd760, %fd758, %p238;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r302}, %fd237;
	}
	setp.lt.s32 	%p239, %r302, 0;
	mov.f64 	%fd762, 0d400921FB54442D18;
	sub.rn.f64 	%fd763, %fd762, %fd761;
	selp.f64 	%fd764, %fd763, %fd761, %p239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r303, %temp}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r304}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r305}, %fd236;
	}
	and.b32  	%r306, %r305, -2147483648;
	or.b32  	%r307, %r304, %r306;
	mov.b64 	%fd765, {%r303, %r307};
	add.rn.f64 	%fd766, %fd238, %fd239;
	setp.le.f64 	%p240, %fd766, 0d7FF0000000000000;
	selp.f64 	%fd838, %fd765, %fd766, %p240;

$L__BB8_204:
	add.rn.f64 	%fd769, %fd838, %fd838;
	mul.rn.f64 	%fd770, %fd769, 0d415854A640000000;
	setp.lt.f64 	%p243, %fd770, %fd246;
	@%p243 bra 	$L__BB8_208;

$L__BB8_207:
	ld.param.u32 	%r324, [bd09_to_gcj02_exact_cuda_param_4];
	add.s32 	%r336, %r336, 1;
	setp.lt.s32 	%p246, %r336, %r324;
	mov.f64 	%fd839, %fd796;
	mov.f64 	%fd840, %fd795;
	@%p246 bra 	$L__BB8_69;

$L__BB8_208:
	ld.param.u64 	%rd87, [bd09_to_gcj02_exact_cuda_param_1];
	mov.u32 	%r328, %tid.x;
	mov.u32 	%r327, %ntid.x;
	mov.u32 	%r326, %ctaid.x;
	mad.lo.s32 	%r325, %r326, %r327, %r328;
	mul.wide.s32 	%rd86, %r325, 8;
	cvta.to.global.u64 	%rd85, %rd87;
	add.s64 	%rd84, %rd85, %rd86;
	ld.param.u64 	%rd83, [bd09_to_gcj02_exact_cuda_param_0];
	mov.u32 	%r323, %tid.x;
	mov.u32 	%r322, %ntid.x;
	mov.u32 	%r321, %ctaid.x;
	mad.lo.s32 	%r320, %r321, %r322, %r323;
	mul.wide.s32 	%rd82, %r320, 8;
	cvta.to.global.u64 	%rd81, %rd83;
	add.s64 	%rd80, %rd81, %rd82;
	st.global.f64 	[%rd80], %fd839;
	st.global.f64 	[%rd84], %fd840;
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot9[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot9;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB9_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r12, %r11, %r10;
	mov.u32 	%r13, 15;
	sub.s32 	%r4, %r13, %r10;
	mov.u32 	%r14, 19;
	sub.s32 	%r15, %r14, %r10;
	setp.gt.s32 	%p2, %r12, 14;
	selp.b32 	%r5, 18, %r15, %p2;
	setp.gt.s32 	%p3, %r12, %r5;
	mov.u64 	%rd76, 0;
	mov.u32 	%r31, %r4;
	@%p3 bra 	$L__BB9_4;

	mul.wide.s32 	%rd22, %r4, 8;
	mov.u64 	%rd23, __cudart_i2opi_d;
	add.s64 	%rd74, %rd23, %rd22;
	mov.b64 	%rd24, %fd4;
	shl.b64 	%rd25, %rd24, 11;
	or.b64  	%rd3, %rd25, -9223372036854775808;
	mov.u64 	%rd76, 0;
	mov.u64 	%rd73, %rd1;
	mov.u32 	%r31, %r4;

$L__BB9_3:
	.pragma "nounroll";
	ld.global.nc.u64 	%rd26, [%rd74];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd26;
	mov.b64 	{%blo,%bhi}, %rd3;
	mov.b64 	{%clo,%chi}, %rd76;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd27, {%r0,%r1};
	mov.b64 	%rd76, {%r2,%r3};
	}
	st.local.u64 	[%rd73], %rd27;
	add.s64 	%rd74, %rd74, 8;
	add.s64 	%rd73, %rd73, 8;
	add.s32 	%r31, %r31, 1;
	setp.lt.s32 	%p4, %r31, %r5;
	@%p4 bra 	$L__BB9_3;

$L__BB9_4:
	sub.s32 	%r16, %r31, %r4;
	mul.wide.s32 	%rd28, %r16, 8;
	add.s64 	%rd29, %rd1, %rd28;
	st.local.u64 	[%rd29], %rd76;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB9_6;

	mov.u32 	%r17, 64;
	sub.s32 	%r18, %r17, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r18;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r18;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB9_6:
	and.b32  	%r19, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r20, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r21, %rd39;
	and.b32  	%r22, %r21, 1;
	add.s32 	%r23, %r22, %r20;
	neg.s32 	%r24, %r23;
	setp.eq.s32 	%p6, %r19, 0;
	selp.b32 	%r25, %r23, %r24, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r25;
	setp.eq.s32 	%p7, %r22, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r26, %r19, -2147483648;
	selp.b32 	%r27, %r19, %r26, %p7;
	clz.b64 	%r28, %rd45;
	cvt.u64.u32 	%rd47, %r28;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r28;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r29, %rd50;
	shr.u64 	%rd51, %rd46, %r29;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r27;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB9_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}
.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<139>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32 	%p1, %r51, 0;
	@%p1 bra 	$L__BB10_2;

	mul.rn.f64 	%fd13, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd13;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd13;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

$L__BB10_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd136, {%r49, %r18};
	setp.lt.u32 	%p2, %r18, 1073127583;
	@%p2 bra 	$L__BB10_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd136;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd136;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd136, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

$L__BB10_4:
	add.rn.f64 	%fd14, %fd136, 0d3FF0000000000000;
	mov.f64 	%fd15, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd16, %fd14;
	neg.f64 	%fd17, %fd14;
	fma.rn.f64 	%fd18, %fd17, %fd16, %fd15;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd16, %fd16;
	add.rn.f64 	%fd21, %fd136, 0dBFF0000000000000;
	mul.rn.f64 	%fd22, %fd21, %fd20;
	add.rn.f64 	%fd23, %fd22, %fd22;
	mul.rn.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd26, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F6249249242B910;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F89999999999DFB;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mul.rn.f64 	%fd38, %fd24, %fd37;
	sub.rn.f64 	%fd39, %fd21, %fd23;
	add.rn.f64 	%fd40, %fd39, %fd39;
	mov.f64 	%fd41, 0d4000000000000000;
	neg.f64 	%fd42, %fd23;
	fma.rn.f64 	%fd43, %fd42, %fd21, %fd40;
	mul.rn.f64 	%fd44, %fd20, %fd43;
	add.rn.f64 	%fd45, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd46, 0d3FB5555555555555;
	sub.rn.f64 	%fd47, %fd46, %fd45;
	add.rn.f64 	%fd48, %fd38, %fd47;
	add.rn.f64 	%fd49, %fd48, 0d0000000000000000;
	add.rn.f64 	%fd50, %fd49, 0dBC46A4CB00B9E7B0;
	add.rn.f64 	%fd51, %fd45, %fd50;
	sub.rn.f64 	%fd52, %fd45, %fd51;
	add.rn.f64 	%fd53, %fd50, %fd52;
	mul.rn.f64 	%fd54, %fd23, %fd23;
	neg.f64 	%fd55, %fd54;
	fma.rn.f64 	%fd56, %fd23, %fd23, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd44;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd57, {%r22, %r24};
	fma.rn.f64 	%fd58, %fd23, %fd57, %fd56;
	mul.rn.f64 	%fd59, %fd54, %fd23;
	neg.f64 	%fd60, %fd59;
	fma.rn.f64 	%fd61, %fd54, %fd23, %fd60;
	fma.rn.f64 	%fd62, %fd54, %fd44, %fd61;
	fma.rn.f64 	%fd63, %fd58, %fd23, %fd62;
	mul.rn.f64 	%fd64, %fd51, %fd59;
	neg.f64 	%fd65, %fd64;
	fma.rn.f64 	%fd66, %fd51, %fd59, %fd65;
	fma.rn.f64 	%fd67, %fd51, %fd63, %fd66;
	fma.rn.f64 	%fd68, %fd53, %fd59, %fd67;
	add.rn.f64 	%fd69, %fd64, %fd68;
	sub.rn.f64 	%fd70, %fd64, %fd69;
	add.rn.f64 	%fd71, %fd68, %fd70;
	add.rn.f64 	%fd72, %fd23, %fd69;
	sub.rn.f64 	%fd73, %fd23, %fd72;
	add.rn.f64 	%fd74, %fd69, %fd73;
	add.rn.f64 	%fd75, %fd71, %fd74;
	add.rn.f64 	%fd76, %fd44, %fd75;
	add.rn.f64 	%fd77, %fd72, %fd76;
	sub.rn.f64 	%fd78, %fd72, %fd77;
	add.rn.f64 	%fd79, %fd76, %fd78;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, -2147483648;
	mov.u32 	%r27, 1127219200;
	mov.b64 	%fd80, {%r25, %r27};
	mov.b64 	%fd81, {%r26, %r27};
	sub.rn.f64 	%fd82, %fd80, %fd81;
	mov.f64 	%fd83, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd84, %fd82, %fd83, %fd77;
	neg.f64 	%fd85, %fd82;
	fma.rn.f64 	%fd86, %fd85, %fd83, %fd84;
	sub.rn.f64 	%fd87, %fd86, %fd77;
	sub.rn.f64 	%fd88, %fd79, %fd87;
	mov.f64 	%fd89, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd90, %fd82, %fd89, %fd88;
	add.rn.f64 	%fd91, %fd84, %fd90;
	sub.rn.f64 	%fd92, %fd84, %fd91;
	add.rn.f64 	%fd93, %fd90, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd41;
	}
	shl.b32 	%r29, %r28, 1;
	setp.gt.u32 	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32 	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd41;
	}
	mov.b64 	%fd94, {%r32, %r31};
	mul.rn.f64 	%fd95, %fd91, %fd94;
	neg.f64 	%fd96, %fd95;
	fma.rn.f64 	%fd97, %fd91, %fd94, %fd96;
	fma.rn.f64 	%fd98, %fd93, %fd94, %fd97;
	add.rn.f64 	%fd4, %fd95, %fd98;
	sub.rn.f64 	%fd99, %fd95, %fd4;
	add.rn.f64 	%fd5, %fd98, %fd99;
	mov.f64 	%fd100, 0d4338000000000000;
	mov.f64 	%fd101, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd102, %fd4, %fd101, %fd100;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd102;
	}
	mov.f64 	%fd103, 0dC338000000000000;
	add.rn.f64 	%fd104, %fd102, %fd103;
	mov.f64 	%fd105, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd106, %fd104, %fd105, %fd4;
	mov.f64 	%fd107, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd108, %fd104, %fd107, %fd106;
	mov.f64 	%fd109, 0d3E928AF3FCA213EA;
	mov.f64 	%fd110, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd111, %fd110, %fd108, %fd109;
	mov.f64 	%fd112, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd113, %fd111, %fd108, %fd112;
	mov.f64 	%fd114, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd115, %fd113, %fd108, %fd114;
	mov.f64 	%fd116, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd117, %fd115, %fd108, %fd116;
	mov.f64 	%fd118, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd119, %fd117, %fd108, %fd118;
	mov.f64 	%fd120, 0d3F81111111122322;
	fma.rn.f64 	%fd121, %fd119, %fd108, %fd120;
	mov.f64 	%fd122, 0d3FA55555555502A1;
	fma.rn.f64 	%fd123, %fd121, %fd108, %fd122;
	mov.f64 	%fd124, 0d3FC5555555555511;
	fma.rn.f64 	%fd125, %fd123, %fd108, %fd124;
	mov.f64 	%fd126, 0d3FE000000000000B;
	fma.rn.f64 	%fd127, %fd125, %fd108, %fd126;
	fma.rn.f64 	%fd128, %fd127, %fd108, %fd15;
	fma.rn.f64 	%fd129, %fd128, %fd108, %fd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd129;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd129;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd137, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	%f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p4, %f1, 0f4086232B;
	@%p4 bra 	$L__BB10_7;

	setp.lt.f64 	%p5, %fd4, 0d0000000000000000;
	add.rn.f64 	%fd130, %fd4, 0d7FF0000000000000;
	selp.f64 	%fd137, 0d0000000000000000, %fd130, %p5;
	setp.geu.f32 	%p6, %f1, 0f40874800;
	@%p6 bra 	$L__BB10_7;

	mov.f64 	%fd135, 0d4338000000000000;
	mov.f64 	%fd134, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd133, %fd4, %fd134, %fd135;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd133;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r15, %r39;
	mov.b64 	%fd131, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd132, {%r44, %r43};
	mul.rn.f64 	%fd137, %fd131, %fd132;

$L__BB10_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd137;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.eq.s32 	%p7, %r46, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd137;
	}
	setp.eq.s32 	%p8, %r47, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB10_9;

	fma.rn.f64 	%fd137, %fd137, %fd5, %fd137;

$L__BB10_9:
	st.param.f64 	[func_retval0+0], %fd137;
	ret;

}

