//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35404655
// Cuda compilation tools, release 12.8, V12.8.61
// Based on NVVM 7.0.1
//

.version 8.7
.target sm_52
.address_size 64

	// .globl	bd09_to_gcj02_cuda_float
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.func  (.param .b64 func_retval0) __internal_accurate_pow
(
	.param .b64 __internal_accurate_pow_param_0
)
;
.global .align 4 .b8 __cudart_i2opi_f[24] = {65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.global .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};
.global .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};

.visible .entry bd09_to_gcj02_cuda_float(
	.param .u64 bd09_to_gcj02_cuda_float_param_0,
	.param .u64 bd09_to_gcj02_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot0[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<99>;
	.reg .f32 	%f<179>;
	.reg .b32 	%r<286>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<117>;


	mov.u64 	%SPL, __local_depot0;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd30, [bd09_to_gcj02_cuda_float_param_0];
	ld.param.u64 	%rd31, [bd09_to_gcj02_cuda_float_param_1];
	cvta.to.global.u64 	%rd32, %rd31;
	mov.u32 	%r80, %ntid.x;
	mov.u32 	%r81, %ctaid.x;
	mov.u32 	%r82, %tid.x;
	mad.lo.s32 	%r83, %r81, %r80, %r82;
	cvta.to.global.u64 	%rd33, %rd30;
	mul.wide.s32 	%rd34, %r83, 4;
	add.s64 	%rd35, %rd33, %rd34;
	add.s64 	%rd36, %rd32, %rd34;
	ld.global.f32 	%f59, [%rd35];
	cvt.f64.f32 	%fd24, %f59;
	add.rn.f64 	%fd25, %fd24, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f1, %fd25;
	ld.global.f32 	%f60, [%rd36];
	cvt.f64.f32 	%fd26, %f60;
	add.rn.f64 	%fd27, %fd26, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f2, %fd27;
	cvt.f64.f32 	%fd1, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd28, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd28;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p3, %r3, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 0, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd61, [retval0+0];
	} // callseq 0
	setp.lt.s32 	%p4, %r1, 0;
	and.pred  	%p1, %p4, %p3;
	not.pred 	%p5, %p1;
	@%p5 bra 	$L__BB0_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd61;
	}
	xor.b32  	%r85, %r84, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd61;
	}
	mov.b64 	%fd61, {%r86, %r85};

$L__BB0_2:
	setp.eq.f32 	%p6, %f1, 0f00000000;
	@%p6 bra 	$L__BB0_6;
	bra.uni 	$L__BB0_3;

$L__BB0_6:
	selp.b32 	%r87, %r1, 0, %p3;
	mov.u32 	%r88, 0;
	or.b32  	%r89, %r87, 2146435072;
	setp.lt.s32 	%p10, %r2, 0;
	selp.b32 	%r90, %r89, %r87, %p10;
	mov.b64 	%fd61, {%r88, %r90};
	bra.uni 	$L__BB0_7;

$L__BB0_3:
	setp.gt.s32 	%p7, %r1, -1;
	@%p7 bra 	$L__BB0_7;

	mov.f64 	%fd29, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd30, %fd29;
	setp.eq.f64 	%p8, %fd30, 0d4000000000000000;
	@%p8 bra 	$L__BB0_7;

	mov.f64 	%fd61, 0dFFF8000000000000;

$L__BB0_7:
	add.rn.f64 	%fd32, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd32;
	}
	and.b32  	%r92, %r91, 2146435072;
	setp.ne.s32 	%p11, %r92, 2146435072;
	@%p11 bra 	$L__BB0_14;

	setp.gtu.f64 	%p12, %fd2, 0d7FF0000000000000;
	@%p12 bra 	$L__BB0_13;
	bra.uni 	$L__BB0_9;

$L__BB0_13:
	mov.f64 	%fd34, 0d4000000000000000;
	add.rn.f64 	%fd61, %fd1, %fd34;
	bra.uni 	$L__BB0_14;

$L__BB0_9:
	mov.f64 	%fd33, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd33;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p13, %r4, 2146435072;
	setp.eq.s32 	%p14, %r93, 0;
	and.pred  	%p15, %p13, %p14;
	@%p15 bra 	$L__BB0_12;
	bra.uni 	$L__BB0_10;

$L__BB0_12:
	setp.gt.f64 	%p22, %fd2, 0d3FF0000000000000;
	selp.b32 	%r100, 2146435072, 0, %p22;
	mov.u32 	%r101, 0;
	xor.b32  	%r102, %r100, 2146435072;
	setp.lt.s32 	%p23, %r2, 0;
	selp.b32 	%r103, %r102, %r100, %p23;
	setp.eq.f32 	%p24, %f1, 0fBF800000;
	selp.b32 	%r104, 1072693248, %r103, %p24;
	mov.b64 	%fd61, {%r101, %r104};
	bra.uni 	$L__BB0_14;

$L__BB0_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd1;
	}
	and.b32  	%r95, %r1, 2147483647;
	setp.ne.s32 	%p16, %r95, 2146435072;
	setp.ne.s32 	%p17, %r94, 0;
	or.pred  	%p18, %p16, %p17;
	@%p18 bra 	$L__BB0_14;

	setp.gt.s32 	%p19, %r2, -1;
	selp.b32 	%r96, 2146435072, 0, %p19;
	mov.u32 	%r97, 0;
	setp.ne.s32 	%p20, %r4, 1071644672;
	and.pred  	%p21, %p20, %p1;
	or.b32  	%r98, %r96, -2147483648;
	selp.b32 	%r99, %r98, %r96, %p21;
	mov.b64 	%fd61, {%r97, %r99};

$L__BB0_14:
	cvt.f64.f32 	%fd12, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 1, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 1
	setp.lt.s32 	%p25, %r5, 0;
	and.pred  	%p2, %p25, %p3;
	not.pred 	%p27, %p2;
	@%p27 bra 	$L__BB0_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %fd64;
	}
	xor.b32  	%r106, %r105, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r107, %temp}, %fd64;
	}
	mov.b64 	%fd64, {%r107, %r106};

$L__BB0_16:
	setp.eq.f32 	%p28, %f2, 0f00000000;
	@%p28 bra 	$L__BB0_20;
	bra.uni 	$L__BB0_17;

$L__BB0_20:
	selp.b32 	%r108, %r5, 0, %p3;
	mov.u32 	%r109, 0;
	or.b32  	%r110, %r108, 2146435072;
	setp.lt.s32 	%p32, %r2, 0;
	selp.b32 	%r111, %r110, %r108, %p32;
	mov.b64 	%fd64, {%r109, %r111};
	bra.uni 	$L__BB0_21;

$L__BB0_17:
	setp.gt.s32 	%p29, %r5, -1;
	@%p29 bra 	$L__BB0_21;

	mov.f64 	%fd35, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd36, %fd35;
	setp.eq.f64 	%p30, %fd36, 0d4000000000000000;
	@%p30 bra 	$L__BB0_21;

	mov.f64 	%fd64, 0dFFF8000000000000;

$L__BB0_21:
	add.rn.f64 	%fd38, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd38;
	}
	and.b32  	%r113, %r112, 2146435072;
	setp.ne.s32 	%p33, %r113, 2146435072;
	@%p33 bra 	$L__BB0_28;

	setp.gtu.f64 	%p34, %fd13, 0d7FF0000000000000;
	@%p34 bra 	$L__BB0_27;
	bra.uni 	$L__BB0_23;

$L__BB0_27:
	mov.f64 	%fd40, 0d4000000000000000;
	add.rn.f64 	%fd64, %fd12, %fd40;
	bra.uni 	$L__BB0_28;

$L__BB0_23:
	mov.f64 	%fd39, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd39;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p35, %r6, 2146435072;
	setp.eq.s32 	%p36, %r114, 0;
	and.pred  	%p37, %p35, %p36;
	@%p37 bra 	$L__BB0_26;
	bra.uni 	$L__BB0_24;

$L__BB0_26:
	setp.gt.f64 	%p44, %fd13, 0d3FF0000000000000;
	selp.b32 	%r121, 2146435072, 0, %p44;
	mov.u32 	%r122, 0;
	xor.b32  	%r123, %r121, 2146435072;
	setp.lt.s32 	%p45, %r2, 0;
	selp.b32 	%r124, %r123, %r121, %p45;
	setp.eq.f32 	%p46, %f2, 0fBF800000;
	selp.b32 	%r125, 1072693248, %r124, %p46;
	mov.b64 	%fd64, {%r122, %r125};
	bra.uni 	$L__BB0_28;

$L__BB0_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd12;
	}
	and.b32  	%r116, %r5, 2147483647;
	setp.ne.s32 	%p38, %r116, 2146435072;
	setp.ne.s32 	%p39, %r115, 0;
	or.pred  	%p40, %p38, %p39;
	@%p40 bra 	$L__BB0_28;

	setp.gt.s32 	%p41, %r2, -1;
	selp.b32 	%r117, 2146435072, 0, %p41;
	mov.u32 	%r118, 0;
	setp.ne.s32 	%p42, %r6, 1071644672;
	and.pred  	%p43, %p42, %p2;
	or.b32  	%r119, %r117, -2147483648;
	selp.b32 	%r120, %r119, %r117, %p43;
	mov.b64 	%fd64, {%r118, %r120};

$L__BB0_28:
	setp.eq.f32 	%p47, %f2, 0f3F800000;
	selp.f64 	%fd41, 0d3FF0000000000000, %fd64, %p47;
	setp.eq.f32 	%p48, %f1, 0f3F800000;
	selp.f64 	%fd42, 0d3FF0000000000000, %fd61, %p48;
	add.rn.f64 	%fd23, %fd42, %fd41;
	mul.rn.f32 	%f3, %f2, 0f42517084;
	mul.rn.f32 	%f61, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r273, %f61;
	cvt.rn.f32.s32 	%f62, %r273;
	mov.f32 	%f63, 0fBFC90FDA;
	fma.rn.f32 	%f64, %f62, %f63, %f3;
	mov.f32 	%f65, 0fB3A22168;
	fma.rn.f32 	%f66, %f62, %f65, %f64;
	mov.f32 	%f67, 0fA7C234C5;
	fma.rn.f32 	%f166, %f62, %f67, %f66;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p49, %f5, 0f47CE4780;
	add.u64 	%rd37, %SP, 0;
	add.u64 	%rd114, %SPL, 0;
	add.s64 	%rd1, %rd114, 24;
	@%p49 bra 	$L__BB0_36;

	setp.eq.f32 	%p50, %f5, 0f7F800000;
	@%p50 bra 	$L__BB0_35;
	bra.uni 	$L__BB0_30;

$L__BB0_35:
	mov.f32 	%f70, 0f00000000;
	mul.rn.f32 	%f166, %f3, %f70;
	mov.u32 	%r273, 0;
	bra.uni 	$L__BB0_36;

$L__BB0_30:
	mov.b32 	%r8, %f3;
	bfe.u32 	%r127, %r8, 23, 8;
	add.s32 	%r9, %r127, -128;
	shl.b32 	%r128, %r8, 8;
	or.b32  	%r10, %r128, -2147483648;
	shr.u32 	%r11, %r9, 5;
	cvta.to.local.u64 	%rd105, %rd37;
	mov.u64 	%rd107, 0;
	mov.u32 	%r270, 0;
	mov.u64 	%rd106, __cudart_i2opi_f;

$L__BB0_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r129, [%rd106];
	mad.wide.u32 	%rd42, %r129, %r10, %rd107;
	shr.u64 	%rd107, %rd42, 32;
	st.local.u32 	[%rd105], %rd42;
	add.s64 	%rd106, %rd106, 4;
	add.s64 	%rd105, %rd105, 4;
	add.s32 	%r270, %r270, 1;
	setp.ne.s32 	%p51, %r270, 6;
	@%p51 bra 	$L__BB0_31;

	st.local.u32 	[%rd1], %rd107;
	mov.u32 	%r130, 4;
	sub.s32 	%r14, %r130, %r11;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r11;
	cvta.to.local.u64 	%rd44, %rd37;
	mul.wide.s32 	%rd45, %r132, 4;
	add.s64 	%rd46, %rd44, %rd45;
	ld.local.u32 	%r271, [%rd46];
	ld.local.u32 	%r272, [%rd46+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p52, %r17, 0;
	@%p52 bra 	$L__BB0_34;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r17;
	shr.u32 	%r135, %r272, %r134;
	shl.b32 	%r136, %r271, %r17;
	add.s32 	%r271, %r135, %r136;
	mul.wide.s32 	%rd49, %r14, 4;
	add.s64 	%rd50, %rd44, %rd49;
	ld.local.u32 	%r137, [%rd50];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r272, %r17;
	add.s32 	%r272, %r138, %r139;

$L__BB0_34:
	and.b32  	%r140, %r8, -2147483648;
	shr.u32 	%r141, %r272, 30;
	shl.b32 	%r142, %r271, 2;
	or.b32  	%r143, %r141, %r142;
	shr.u32 	%r144, %r143, 31;
	shr.u32 	%r145, %r271, 30;
	add.s32 	%r146, %r144, %r145;
	neg.s32 	%r147, %r146;
	setp.eq.s32 	%p53, %r140, 0;
	selp.b32 	%r273, %r146, %r147, %p53;
	setp.ne.s32 	%p54, %r144, 0;
	xor.b32  	%r148, %r140, -2147483648;
	selp.b32 	%r149, %r148, %r140, %p54;
	selp.b32 	%r150, -1, 0, %p54;
	xor.b32  	%r151, %r143, %r150;
	shl.b32 	%r152, %r272, 2;
	xor.b32  	%r153, %r152, %r150;
	cvt.u64.u32 	%rd51, %r151;
	cvt.u64.u32 	%rd52, %r153;
	bfi.b64 	%rd53, %rd51, %rd52, 32, 32;
	cvt.rn.f64.s64 	%fd43, %rd53;
	mul.rn.f64 	%fd44, %fd43, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f68, %fd44;
	setp.eq.s32 	%p55, %r149, 0;
	neg.f32 	%f69, %f68;
	selp.f32 	%f166, %f68, %f69, %p55;

$L__BB0_36:
	and.b32  	%r24, %r273, 1;
	setp.eq.s32 	%p56, %r24, 0;
	selp.f32 	%f9, %f166, 0f3F800000, %p56;
	mul.rn.f32 	%f10, %f166, %f166;
	mov.f32 	%f167, 0fB94D4153;
	@%p56 bra 	$L__BB0_38;

	mov.f32 	%f72, 0fBAB607ED;
	mov.f32 	%f73, 0f37CBAC00;
	fma.rn.f32 	%f167, %f73, %f10, %f72;

$L__BB0_38:
	selp.f32 	%f74, 0f3C0885E4, 0f3D2AAABB, %p56;
	fma.rn.f32 	%f75, %f167, %f10, %f74;
	selp.f32 	%f76, 0fBE2AAAA8, 0fBEFFFFFF, %p56;
	fma.rn.f32 	%f77, %f75, %f10, %f76;
	mov.f32 	%f78, 0f00000000;
	fma.rn.f32 	%f79, %f10, %f9, %f78;
	fma.rn.f32 	%f168, %f77, %f79, %f9;
	and.b32  	%r155, %r273, 2;
	setp.eq.s32 	%p58, %r155, 0;
	@%p58 bra 	$L__BB0_40;

	mov.f32 	%f81, 0fBF800000;
	fma.rn.f32 	%f168, %f168, %f81, %f78;

$L__BB0_40:
	cvt.f64.f32 	%fd45, %f168;
	mul.rn.f64 	%fd46, %fd45, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd47, %fd23;
	add.rn.f64 	%fd48, %fd47, %fd46;
	cvt.rn.f32.f64 	%f16, %fd48;
	abs.f32 	%f17, %f1;
	setp.eq.f32 	%p59, %f17, 0f00000000;
	abs.f32 	%f18, %f2;
	setp.eq.f32 	%p60, %f18, 0f00000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB0_44;
	bra.uni 	$L__BB0_41;

$L__BB0_44:
	mov.b32 	%r166, %f1;
	shr.s32 	%r167, %r166, 31;
	and.b32  	%r168, %r167, 1078530011;
	mov.b32 	%r169, %f2;
	and.b32  	%r170, %r169, -2147483648;
	or.b32  	%r171, %r168, %r170;
	mov.b32 	%f169, %r171;
	bra.uni 	$L__BB0_45;

$L__BB0_41:
	setp.eq.f32 	%p62, %f17, 0f7F800000;
	setp.eq.f32 	%p63, %f18, 0f7F800000;
	and.pred  	%p64, %p62, %p63;
	@%p64 bra 	$L__BB0_43;
	bra.uni 	$L__BB0_42;

$L__BB0_43:
	mov.b32 	%r161, %f1;
	setp.lt.s32 	%p68, %r161, 0;
	selp.b32 	%r162, 1075235812, 1061752795, %p68;
	mov.b32 	%r163, %f2;
	and.b32  	%r164, %r163, -2147483648;
	or.b32  	%r165, %r162, %r164;
	mov.b32 	%f169, %r165;
	bra.uni 	$L__BB0_45;

$L__BB0_42:
	max.f32 	%f82, %f18, %f17;
	min.f32 	%f83, %f18, %f17;
	div.rn.f32 	%f84, %f83, %f82;
	mul.rn.f32 	%f85, %f84, %f84;
	mov.f32 	%f86, 0fC0B59883;
	mov.f32 	%f87, 0fBF52C7EA;
	fma.rn.f32 	%f88, %f85, %f87, %f86;
	mov.f32 	%f89, 0fC0D21907;
	fma.rn.f32 	%f90, %f88, %f85, %f89;
	mul.rn.f32 	%f91, %f85, %f90;
	mul.rn.f32 	%f92, %f84, %f91;
	add.rn.f32 	%f93, %f85, 0f41355DC0;
	mov.f32 	%f94, 0f41E6BD60;
	fma.rn.f32 	%f95, %f93, %f85, %f94;
	mov.f32 	%f96, 0f419D92C8;
	fma.rn.f32 	%f97, %f95, %f85, %f96;
	rcp.rn.f32 	%f98, %f97;
	fma.rn.f32 	%f99, %f92, %f98, %f84;
	mov.f32 	%f100, 0f3FC90FDB;
	sub.rn.f32 	%f101, %f100, %f99;
	setp.gt.f32 	%p65, %f18, %f17;
	selp.f32 	%f102, %f101, %f99, %p65;
	mov.b32 	%r156, %f1;
	setp.lt.s32 	%p66, %r156, 0;
	mov.f32 	%f103, 0f40490FDB;
	sub.rn.f32 	%f104, %f103, %f102;
	selp.f32 	%f105, %f104, %f102, %p66;
	mov.b32 	%r157, %f105;
	mov.b32 	%r158, %f2;
	and.b32  	%r159, %r158, -2147483648;
	or.b32  	%r160, %r159, %r157;
	mov.b32 	%f106, %r160;
	add.rn.f32 	%f107, %f17, %f18;
	setp.le.f32 	%p67, %f107, 0f7F800000;
	selp.f32 	%f169, %f106, %f107, %p67;

$L__BB0_45:
	mul.rn.f32 	%f23, %f1, 0f42517084;
	mul.rn.f32 	%f108, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r277, %f108;
	cvt.rn.f32.s32 	%f109, %r277;
	mov.f32 	%f110, 0fBFC90FDA;
	fma.rn.f32 	%f111, %f109, %f110, %f23;
	mov.f32 	%f112, 0fB3A22168;
	fma.rn.f32 	%f113, %f109, %f112, %f111;
	mov.f32 	%f114, 0fA7C234C5;
	fma.rn.f32 	%f170, %f109, %f114, %f113;
	abs.f32 	%f25, %f23;
	setp.ltu.f32 	%p69, %f25, 0f47CE4780;
	@%p69 bra 	$L__BB0_53;

	setp.eq.f32 	%p70, %f25, 0f7F800000;
	@%p70 bra 	$L__BB0_52;
	bra.uni 	$L__BB0_47;

$L__BB0_52:
	mov.f32 	%f117, 0f00000000;
	mul.rn.f32 	%f170, %f23, %f117;
	mov.u32 	%r277, 0;
	bra.uni 	$L__BB0_53;

$L__BB0_47:
	mov.b32 	%r26, %f23;
	bfe.u32 	%r173, %r26, 23, 8;
	add.s32 	%r27, %r173, -128;
	shl.b32 	%r174, %r26, 8;
	or.b32  	%r28, %r174, -2147483648;
	shr.u32 	%r29, %r27, 5;
	cvta.to.local.u64 	%rd108, %rd37;
	mov.u64 	%rd110, 0;
	mov.u32 	%r274, 0;
	mov.u64 	%rd109, __cudart_i2opi_f;

$L__BB0_48:
	.pragma "nounroll";
	ld.global.nc.u32 	%r175, [%rd109];
	mad.wide.u32 	%rd57, %r175, %r28, %rd110;
	shr.u64 	%rd110, %rd57, 32;
	st.local.u32 	[%rd108], %rd57;
	add.s64 	%rd109, %rd109, 4;
	add.s64 	%rd108, %rd108, 4;
	add.s32 	%r274, %r274, 1;
	setp.ne.s32 	%p71, %r274, 6;
	@%p71 bra 	$L__BB0_48;

	st.local.u32 	[%rd1], %rd110;
	mov.u32 	%r176, 4;
	sub.s32 	%r32, %r176, %r29;
	mov.u32 	%r177, 6;
	sub.s32 	%r178, %r177, %r29;
	cvta.to.local.u64 	%rd59, %rd37;
	mul.wide.s32 	%rd60, %r178, 4;
	add.s64 	%rd61, %rd59, %rd60;
	ld.local.u32 	%r275, [%rd61];
	ld.local.u32 	%r276, [%rd61+-4];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p72, %r35, 0;
	@%p72 bra 	$L__BB0_51;

	mov.u32 	%r179, 32;
	sub.s32 	%r180, %r179, %r35;
	shr.u32 	%r181, %r276, %r180;
	shl.b32 	%r182, %r275, %r35;
	add.s32 	%r275, %r181, %r182;
	mul.wide.s32 	%rd64, %r32, 4;
	add.s64 	%rd65, %rd59, %rd64;
	ld.local.u32 	%r183, [%rd65];
	shr.u32 	%r184, %r183, %r180;
	shl.b32 	%r185, %r276, %r35;
	add.s32 	%r276, %r184, %r185;

$L__BB0_51:
	and.b32  	%r186, %r26, -2147483648;
	shr.u32 	%r187, %r276, 30;
	shl.b32 	%r188, %r275, 2;
	or.b32  	%r189, %r187, %r188;
	shr.u32 	%r190, %r189, 31;
	shr.u32 	%r191, %r275, 30;
	add.s32 	%r192, %r190, %r191;
	neg.s32 	%r193, %r192;
	setp.eq.s32 	%p73, %r186, 0;
	selp.b32 	%r277, %r192, %r193, %p73;
	setp.ne.s32 	%p74, %r190, 0;
	xor.b32  	%r194, %r186, -2147483648;
	selp.b32 	%r195, %r194, %r186, %p74;
	selp.b32 	%r196, -1, 0, %p74;
	xor.b32  	%r197, %r189, %r196;
	shl.b32 	%r198, %r276, 2;
	xor.b32  	%r199, %r198, %r196;
	cvt.u64.u32 	%rd66, %r197;
	cvt.u64.u32 	%rd67, %r199;
	bfi.b64 	%rd68, %rd66, %rd67, 32, 32;
	cvt.rn.f64.s64 	%fd49, %rd68;
	mul.rn.f64 	%fd50, %fd49, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f115, %fd50;
	setp.eq.s32 	%p75, %r195, 0;
	neg.f32 	%f116, %f115;
	selp.f32 	%f170, %f115, %f116, %p75;

$L__BB0_53:
	add.s32 	%r42, %r277, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32 	%p76, %r43, 0;
	selp.f32 	%f29, %f170, 0f3F800000, %p76;
	mul.rn.f32 	%f30, %f170, %f170;
	mov.f32 	%f171, 0fB94D4153;
	@%p76 bra 	$L__BB0_55;

	mov.f32 	%f119, 0fBAB607ED;
	mov.f32 	%f120, 0f37CBAC00;
	fma.rn.f32 	%f171, %f120, %f30, %f119;

$L__BB0_55:
	selp.f32 	%f121, 0f3C0885E4, 0f3D2AAABB, %p76;
	fma.rn.f32 	%f122, %f171, %f30, %f121;
	selp.f32 	%f123, 0fBE2AAAA8, 0fBEFFFFFF, %p76;
	fma.rn.f32 	%f124, %f122, %f30, %f123;
	mov.f32 	%f125, 0f00000000;
	fma.rn.f32 	%f126, %f30, %f29, %f125;
	fma.rn.f32 	%f172, %f124, %f126, %f29;
	and.b32  	%r201, %r42, 2;
	setp.eq.s32 	%p78, %r201, 0;
	@%p78 bra 	$L__BB0_57;

	mov.f32 	%f128, 0fBF800000;
	fma.rn.f32 	%f172, %f172, %f128, %f125;

$L__BB0_57:
	cvt.f64.f32 	%fd51, %f172;
	mul.rn.f64 	%fd52, %fd51, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd53, %f169;
	add.rn.f64 	%fd54, %fd53, %fd52;
	cvt.rn.f32.f64 	%f36, %fd54;
	mul.rn.f32 	%f129, %f36, 0f3F22F983;
	cvt.rni.s32.f32 	%r285, %f129;
	cvt.rn.f32.s32 	%f130, %r285;
	mov.f32 	%f131, 0fBFC90FDA;
	fma.rn.f32 	%f132, %f130, %f131, %f36;
	mov.f32 	%f133, 0fB3A22168;
	fma.rn.f32 	%f134, %f130, %f133, %f132;
	mov.f32 	%f135, 0fA7C234C5;
	fma.rn.f32 	%f176, %f130, %f135, %f134;
	abs.f32 	%f38, %f36;
	setp.ltu.f32 	%p79, %f38, 0f47CE4780;
	mov.u32 	%r281, %r285;
	mov.f32 	%f173, %f176;
	@%p79 bra 	$L__BB0_65;

	setp.eq.f32 	%p80, %f38, 0f7F800000;
	@%p80 bra 	$L__BB0_64;
	bra.uni 	$L__BB0_59;

$L__BB0_64:
	mov.f32 	%f138, 0f00000000;
	mul.rn.f32 	%f173, %f36, %f138;
	mov.u32 	%r281, 0;
	bra.uni 	$L__BB0_65;

$L__BB0_59:
	mov.b32 	%r45, %f36;
	bfe.u32 	%r203, %r45, 23, 8;
	add.s32 	%r46, %r203, -128;
	shl.b32 	%r204, %r45, 8;
	or.b32  	%r47, %r204, -2147483648;
	shr.u32 	%r48, %r46, 5;
	cvta.to.local.u64 	%rd111, %rd37;
	mov.u64 	%rd113, 0;
	mov.u32 	%r278, 0;
	mov.u64 	%rd112, __cudart_i2opi_f;

$L__BB0_60:
	.pragma "nounroll";
	ld.global.nc.u32 	%r205, [%rd112];
	mad.wide.u32 	%rd72, %r205, %r47, %rd113;
	shr.u64 	%rd113, %rd72, 32;
	st.local.u32 	[%rd111], %rd72;
	add.s64 	%rd112, %rd112, 4;
	add.s64 	%rd111, %rd111, 4;
	add.s32 	%r278, %r278, 1;
	setp.ne.s32 	%p81, %r278, 6;
	@%p81 bra 	$L__BB0_60;

	st.local.u32 	[%rd1], %rd113;
	mov.u32 	%r206, 4;
	sub.s32 	%r51, %r206, %r48;
	mov.u32 	%r207, 6;
	sub.s32 	%r208, %r207, %r48;
	cvta.to.local.u64 	%rd74, %rd37;
	mul.wide.s32 	%rd75, %r208, 4;
	add.s64 	%rd76, %rd74, %rd75;
	ld.local.u32 	%r279, [%rd76];
	ld.local.u32 	%r280, [%rd76+-4];
	and.b32  	%r54, %r46, 31;
	setp.eq.s32 	%p82, %r54, 0;
	@%p82 bra 	$L__BB0_63;

	mov.u32 	%r209, 32;
	sub.s32 	%r210, %r209, %r54;
	shr.u32 	%r211, %r280, %r210;
	shl.b32 	%r212, %r279, %r54;
	add.s32 	%r279, %r211, %r212;
	mul.wide.s32 	%rd79, %r51, 4;
	add.s64 	%rd80, %rd74, %rd79;
	ld.local.u32 	%r213, [%rd80];
	shr.u32 	%r214, %r213, %r210;
	shl.b32 	%r215, %r280, %r54;
	add.s32 	%r280, %r214, %r215;

$L__BB0_63:
	and.b32  	%r216, %r45, -2147483648;
	shr.u32 	%r217, %r280, 30;
	shl.b32 	%r218, %r279, 2;
	or.b32  	%r219, %r217, %r218;
	shr.u32 	%r220, %r219, 31;
	shr.u32 	%r221, %r279, 30;
	add.s32 	%r222, %r220, %r221;
	neg.s32 	%r223, %r222;
	setp.eq.s32 	%p83, %r216, 0;
	selp.b32 	%r281, %r222, %r223, %p83;
	setp.ne.s32 	%p84, %r220, 0;
	xor.b32  	%r224, %r216, -2147483648;
	selp.b32 	%r225, %r224, %r216, %p84;
	selp.b32 	%r226, -1, 0, %p84;
	xor.b32  	%r227, %r219, %r226;
	shl.b32 	%r228, %r280, 2;
	xor.b32  	%r229, %r228, %r226;
	cvt.u64.u32 	%rd81, %r227;
	cvt.u64.u32 	%rd82, %r229;
	bfi.b64 	%rd83, %rd81, %rd82, 32, 32;
	cvt.rn.f64.s64 	%fd55, %rd83;
	mul.rn.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f136, %fd56;
	setp.eq.s32 	%p85, %r225, 0;
	neg.f32 	%f137, %f136;
	selp.f32 	%f173, %f136, %f137, %p85;

$L__BB0_65:
	add.s32 	%r61, %r281, 1;
	and.b32  	%r62, %r61, 1;
	setp.eq.s32 	%p86, %r62, 0;
	selp.f32 	%f42, %f173, 0f3F800000, %p86;
	mul.rn.f32 	%f43, %f173, %f173;
	mov.f32 	%f174, 0fB94D4153;
	@%p86 bra 	$L__BB0_67;

	mov.f32 	%f140, 0fBAB607ED;
	mov.f32 	%f141, 0f37CBAC00;
	fma.rn.f32 	%f174, %f141, %f43, %f140;

$L__BB0_67:
	selp.f32 	%f142, 0f3C0885E4, 0f3D2AAABB, %p86;
	fma.rn.f32 	%f143, %f174, %f43, %f142;
	selp.f32 	%f144, 0fBE2AAAA8, 0fBEFFFFFF, %p86;
	fma.rn.f32 	%f145, %f143, %f43, %f144;
	mov.f32 	%f146, 0f00000000;
	fma.rn.f32 	%f147, %f43, %f42, %f146;
	fma.rn.f32 	%f175, %f145, %f147, %f42;
	and.b32  	%r231, %r61, 2;
	setp.eq.s32 	%p88, %r231, 0;
	@%p88 bra 	$L__BB0_69;

	mov.f32 	%f149, 0fBF800000;
	fma.rn.f32 	%f175, %f175, %f149, %f146;

$L__BB0_69:
	mul.rn.f32 	%f150, %f175, %f16;
	st.global.f32 	[%rd35], %f150;
	@%p79 bra 	$L__BB0_77;

	setp.eq.f32 	%p90, %f38, 0f7F800000;
	@%p90 bra 	$L__BB0_76;
	bra.uni 	$L__BB0_71;

$L__BB0_76:
	mov.f32 	%f153, 0f00000000;
	mul.rn.f32 	%f176, %f36, %f153;
	mov.u32 	%r285, 0;
	bra.uni 	$L__BB0_77;

$L__BB0_71:
	mov.b32 	%r63, %f36;
	bfe.u32 	%r237, %r63, 23, 8;
	add.s32 	%r64, %r237, -128;
	shl.b32 	%r238, %r63, 8;
	or.b32  	%r65, %r238, -2147483648;
	shr.u32 	%r66, %r64, 5;
	mov.u64 	%rd116, 0;
	mov.u32 	%r282, 0;
	mov.u64 	%rd115, __cudart_i2opi_f;

$L__BB0_72:
	.pragma "nounroll";
	ld.global.nc.u32 	%r239, [%rd115];
	mad.wide.u32 	%rd90, %r239, %r65, %rd116;
	shr.u64 	%rd116, %rd90, 32;
	st.local.u32 	[%rd114], %rd90;
	add.s64 	%rd115, %rd115, 4;
	add.s64 	%rd114, %rd114, 4;
	add.s32 	%r282, %r282, 1;
	setp.ne.s32 	%p91, %r282, 6;
	@%p91 bra 	$L__BB0_72;

	st.local.u32 	[%rd1], %rd116;
	mov.u32 	%r240, 4;
	sub.s32 	%r69, %r240, %r66;
	mov.u32 	%r241, 6;
	sub.s32 	%r242, %r241, %r66;
	cvta.to.local.u64 	%rd92, %rd37;
	mul.wide.s32 	%rd93, %r242, 4;
	add.s64 	%rd94, %rd92, %rd93;
	ld.local.u32 	%r283, [%rd94];
	ld.local.u32 	%r284, [%rd94+-4];
	and.b32  	%r72, %r64, 31;
	setp.eq.s32 	%p92, %r72, 0;
	@%p92 bra 	$L__BB0_75;

	mov.u32 	%r243, 32;
	sub.s32 	%r244, %r243, %r72;
	shr.u32 	%r245, %r284, %r244;
	shl.b32 	%r246, %r283, %r72;
	add.s32 	%r283, %r245, %r246;
	mul.wide.s32 	%rd97, %r69, 4;
	add.s64 	%rd98, %rd92, %rd97;
	ld.local.u32 	%r247, [%rd98];
	shr.u32 	%r248, %r247, %r244;
	shl.b32 	%r249, %r284, %r72;
	add.s32 	%r284, %r248, %r249;

$L__BB0_75:
	and.b32  	%r250, %r63, -2147483648;
	shr.u32 	%r251, %r284, 30;
	shl.b32 	%r252, %r283, 2;
	or.b32  	%r253, %r251, %r252;
	shr.u32 	%r254, %r253, 31;
	shr.u32 	%r255, %r283, 30;
	add.s32 	%r256, %r254, %r255;
	neg.s32 	%r257, %r256;
	setp.eq.s32 	%p93, %r250, 0;
	selp.b32 	%r285, %r256, %r257, %p93;
	setp.ne.s32 	%p94, %r254, 0;
	xor.b32  	%r258, %r250, -2147483648;
	selp.b32 	%r259, %r258, %r250, %p94;
	selp.b32 	%r260, -1, 0, %p94;
	xor.b32  	%r261, %r253, %r260;
	shl.b32 	%r262, %r284, 2;
	xor.b32  	%r263, %r262, %r260;
	cvt.u64.u32 	%rd99, %r261;
	cvt.u64.u32 	%rd100, %r263;
	bfi.b64 	%rd101, %rd99, %rd100, 32, 32;
	cvt.rn.f64.s64 	%fd57, %rd101;
	mul.rn.f64 	%fd58, %fd57, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f151, %fd58;
	setp.eq.s32 	%p95, %r259, 0;
	neg.f32 	%f152, %f151;
	selp.f32 	%f176, %f151, %f152, %p95;

$L__BB0_77:
	and.b32  	%r79, %r285, 1;
	setp.eq.s32 	%p96, %r79, 0;
	selp.f32 	%f52, %f176, 0f3F800000, %p96;
	mul.rn.f32 	%f53, %f176, %f176;
	mov.f32 	%f177, 0fB94D4153;
	@%p96 bra 	$L__BB0_79;

	mov.f32 	%f155, 0fBAB607ED;
	mov.f32 	%f156, 0f37CBAC00;
	fma.rn.f32 	%f177, %f156, %f53, %f155;

$L__BB0_79:
	selp.f32 	%f157, 0f3C0885E4, 0f3D2AAABB, %p96;
	fma.rn.f32 	%f158, %f177, %f53, %f157;
	selp.f32 	%f159, 0fBE2AAAA8, 0fBEFFFFFF, %p96;
	fma.rn.f32 	%f160, %f158, %f53, %f159;
	mov.f32 	%f161, 0f00000000;
	fma.rn.f32 	%f162, %f53, %f52, %f161;
	fma.rn.f32 	%f178, %f160, %f162, %f52;
	and.b32  	%r265, %r285, 2;
	setp.eq.s32 	%p98, %r265, 0;
	@%p98 bra 	$L__BB0_81;

	mov.f32 	%f164, 0fBF800000;
	fma.rn.f32 	%f178, %f178, %f164, %f161;

$L__BB0_81:
	mul.rn.f32 	%f165, %f178, %f16;
	st.global.f32 	[%rd36], %f165;
	ret;

}
	// .globl	gcj02_to_bd09_cuda_float
.visible .entry gcj02_to_bd09_cuda_float(
	.param .u64 gcj02_to_bd09_cuda_float_param_0,
	.param .u64 gcj02_to_bd09_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot1[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<99>;
	.reg .f32 	%f<179>;
	.reg .b32 	%r<286>;
	.reg .f64 	%fd<65>;
	.reg .b64 	%rd<117>;


	mov.u64 	%SPL, __local_depot1;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd30, [gcj02_to_bd09_cuda_float_param_0];
	ld.param.u64 	%rd31, [gcj02_to_bd09_cuda_float_param_1];
	cvta.to.global.u64 	%rd32, %rd31;
	mov.u32 	%r80, %ntid.x;
	mov.u32 	%r81, %ctaid.x;
	mov.u32 	%r82, %tid.x;
	mad.lo.s32 	%r83, %r81, %r80, %r82;
	cvta.to.global.u64 	%rd33, %rd30;
	mul.wide.s32 	%rd34, %r83, 4;
	add.s64 	%rd35, %rd33, %rd34;
	add.s64 	%rd36, %rd32, %rd34;
	ld.global.f32 	%f1, [%rd36];
	ld.global.f32 	%f2, [%rd35];
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd24;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p3, %r3, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 2, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd61, [retval0+0];
	} // callseq 2
	setp.lt.s32 	%p4, %r1, 0;
	and.pred  	%p1, %p4, %p3;
	not.pred 	%p5, %p1;
	@%p5 bra 	$L__BB1_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd61;
	}
	xor.b32  	%r85, %r84, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r86, %temp}, %fd61;
	}
	mov.b64 	%fd61, {%r86, %r85};

$L__BB1_2:
	setp.eq.f32 	%p6, %f2, 0f00000000;
	@%p6 bra 	$L__BB1_6;
	bra.uni 	$L__BB1_3;

$L__BB1_6:
	selp.b32 	%r87, %r1, 0, %p3;
	mov.u32 	%r88, 0;
	or.b32  	%r89, %r87, 2146435072;
	setp.lt.s32 	%p10, %r2, 0;
	selp.b32 	%r90, %r89, %r87, %p10;
	mov.b64 	%fd61, {%r88, %r90};
	bra.uni 	$L__BB1_7;

$L__BB1_3:
	setp.gt.s32 	%p7, %r1, -1;
	@%p7 bra 	$L__BB1_7;

	mov.f64 	%fd25, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd26, %fd25;
	setp.eq.f64 	%p8, %fd26, 0d4000000000000000;
	@%p8 bra 	$L__BB1_7;

	mov.f64 	%fd61, 0dFFF8000000000000;

$L__BB1_7:
	add.rn.f64 	%fd28, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r91}, %fd28;
	}
	and.b32  	%r92, %r91, 2146435072;
	setp.ne.s32 	%p11, %r92, 2146435072;
	@%p11 bra 	$L__BB1_14;

	setp.gtu.f64 	%p12, %fd2, 0d7FF0000000000000;
	@%p12 bra 	$L__BB1_13;
	bra.uni 	$L__BB1_9;

$L__BB1_13:
	mov.f64 	%fd30, 0d4000000000000000;
	add.rn.f64 	%fd61, %fd1, %fd30;
	bra.uni 	$L__BB1_14;

$L__BB1_9:
	mov.f64 	%fd29, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd29;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p13, %r4, 2146435072;
	setp.eq.s32 	%p14, %r93, 0;
	and.pred  	%p15, %p13, %p14;
	@%p15 bra 	$L__BB1_12;
	bra.uni 	$L__BB1_10;

$L__BB1_12:
	setp.gt.f64 	%p22, %fd2, 0d3FF0000000000000;
	selp.b32 	%r100, 2146435072, 0, %p22;
	mov.u32 	%r101, 0;
	xor.b32  	%r102, %r100, 2146435072;
	setp.lt.s32 	%p23, %r2, 0;
	selp.b32 	%r103, %r102, %r100, %p23;
	setp.eq.f32 	%p24, %f2, 0fBF800000;
	selp.b32 	%r104, 1072693248, %r103, %p24;
	mov.b64 	%fd61, {%r101, %r104};
	bra.uni 	$L__BB1_14;

$L__BB1_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r94, %temp}, %fd1;
	}
	and.b32  	%r95, %r1, 2147483647;
	setp.ne.s32 	%p16, %r95, 2146435072;
	setp.ne.s32 	%p17, %r94, 0;
	or.pred  	%p18, %p16, %p17;
	@%p18 bra 	$L__BB1_14;

	setp.gt.s32 	%p19, %r2, -1;
	selp.b32 	%r96, 2146435072, 0, %p19;
	mov.u32 	%r97, 0;
	setp.ne.s32 	%p20, %r4, 1071644672;
	and.pred  	%p21, %p20, %p1;
	or.b32  	%r98, %r96, -2147483648;
	selp.b32 	%r99, %r98, %r96, %p21;
	mov.b64 	%fd61, {%r97, %r99};

$L__BB1_14:
	cvt.f64.f32 	%fd12, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 3, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd64, [retval0+0];
	} // callseq 3
	setp.lt.s32 	%p25, %r5, 0;
	and.pred  	%p2, %p25, %p3;
	not.pred 	%p27, %p2;
	@%p27 bra 	$L__BB1_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %fd64;
	}
	xor.b32  	%r106, %r105, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r107, %temp}, %fd64;
	}
	mov.b64 	%fd64, {%r107, %r106};

$L__BB1_16:
	setp.eq.f32 	%p28, %f1, 0f00000000;
	@%p28 bra 	$L__BB1_20;
	bra.uni 	$L__BB1_17;

$L__BB1_20:
	selp.b32 	%r108, %r5, 0, %p3;
	mov.u32 	%r109, 0;
	or.b32  	%r110, %r108, 2146435072;
	setp.lt.s32 	%p32, %r2, 0;
	selp.b32 	%r111, %r110, %r108, %p32;
	mov.b64 	%fd64, {%r109, %r111};
	bra.uni 	$L__BB1_21;

$L__BB1_17:
	setp.gt.s32 	%p29, %r5, -1;
	@%p29 bra 	$L__BB1_21;

	mov.f64 	%fd31, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd32, %fd31;
	setp.eq.f64 	%p30, %fd32, 0d4000000000000000;
	@%p30 bra 	$L__BB1_21;

	mov.f64 	%fd64, 0dFFF8000000000000;

$L__BB1_21:
	add.rn.f64 	%fd34, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd34;
	}
	and.b32  	%r113, %r112, 2146435072;
	setp.ne.s32 	%p33, %r113, 2146435072;
	@%p33 bra 	$L__BB1_28;

	setp.gtu.f64 	%p34, %fd13, 0d7FF0000000000000;
	@%p34 bra 	$L__BB1_27;
	bra.uni 	$L__BB1_23;

$L__BB1_27:
	mov.f64 	%fd36, 0d4000000000000000;
	add.rn.f64 	%fd64, %fd12, %fd36;
	bra.uni 	$L__BB1_28;

$L__BB1_23:
	mov.f64 	%fd35, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r114, %temp}, %fd35;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p35, %r6, 2146435072;
	setp.eq.s32 	%p36, %r114, 0;
	and.pred  	%p37, %p35, %p36;
	@%p37 bra 	$L__BB1_26;
	bra.uni 	$L__BB1_24;

$L__BB1_26:
	setp.gt.f64 	%p44, %fd13, 0d3FF0000000000000;
	selp.b32 	%r121, 2146435072, 0, %p44;
	mov.u32 	%r122, 0;
	xor.b32  	%r123, %r121, 2146435072;
	setp.lt.s32 	%p45, %r2, 0;
	selp.b32 	%r124, %r123, %r121, %p45;
	setp.eq.f32 	%p46, %f1, 0fBF800000;
	selp.b32 	%r125, 1072693248, %r124, %p46;
	mov.b64 	%fd64, {%r122, %r125};
	bra.uni 	$L__BB1_28;

$L__BB1_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd12;
	}
	and.b32  	%r116, %r5, 2147483647;
	setp.ne.s32 	%p38, %r116, 2146435072;
	setp.ne.s32 	%p39, %r115, 0;
	or.pred  	%p40, %p38, %p39;
	@%p40 bra 	$L__BB1_28;

	setp.gt.s32 	%p41, %r2, -1;
	selp.b32 	%r117, 2146435072, 0, %p41;
	mov.u32 	%r118, 0;
	setp.ne.s32 	%p42, %r6, 1071644672;
	and.pred  	%p43, %p42, %p2;
	or.b32  	%r119, %r117, -2147483648;
	selp.b32 	%r120, %r119, %r117, %p43;
	mov.b64 	%fd64, {%r118, %r120};

$L__BB1_28:
	setp.eq.f32 	%p47, %f1, 0f3F800000;
	selp.f64 	%fd37, 0d3FF0000000000000, %fd64, %p47;
	setp.eq.f32 	%p48, %f2, 0f3F800000;
	selp.f64 	%fd38, 0d3FF0000000000000, %fd61, %p48;
	add.rn.f64 	%fd23, %fd38, %fd37;
	mul.rn.f32 	%f3, %f1, 0f42517084;
	mul.rn.f32 	%f59, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r273, %f59;
	cvt.rn.f32.s32 	%f60, %r273;
	mov.f32 	%f61, 0fBFC90FDA;
	fma.rn.f32 	%f62, %f60, %f61, %f3;
	mov.f32 	%f63, 0fB3A22168;
	fma.rn.f32 	%f64, %f60, %f63, %f62;
	mov.f32 	%f65, 0fA7C234C5;
	fma.rn.f32 	%f166, %f60, %f65, %f64;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p49, %f5, 0f47CE4780;
	add.u64 	%rd37, %SP, 0;
	add.u64 	%rd114, %SPL, 0;
	add.s64 	%rd1, %rd114, 24;
	@%p49 bra 	$L__BB1_36;

	setp.eq.f32 	%p50, %f5, 0f7F800000;
	@%p50 bra 	$L__BB1_35;
	bra.uni 	$L__BB1_30;

$L__BB1_35:
	mov.f32 	%f68, 0f00000000;
	mul.rn.f32 	%f166, %f3, %f68;
	mov.u32 	%r273, 0;
	bra.uni 	$L__BB1_36;

$L__BB1_30:
	mov.b32 	%r8, %f3;
	bfe.u32 	%r127, %r8, 23, 8;
	add.s32 	%r9, %r127, -128;
	shl.b32 	%r128, %r8, 8;
	or.b32  	%r10, %r128, -2147483648;
	shr.u32 	%r11, %r9, 5;
	cvta.to.local.u64 	%rd105, %rd37;
	mov.u64 	%rd107, 0;
	mov.u32 	%r270, 0;
	mov.u64 	%rd106, __cudart_i2opi_f;

$L__BB1_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r129, [%rd106];
	mad.wide.u32 	%rd42, %r129, %r10, %rd107;
	shr.u64 	%rd107, %rd42, 32;
	st.local.u32 	[%rd105], %rd42;
	add.s64 	%rd106, %rd106, 4;
	add.s64 	%rd105, %rd105, 4;
	add.s32 	%r270, %r270, 1;
	setp.ne.s32 	%p51, %r270, 6;
	@%p51 bra 	$L__BB1_31;

	st.local.u32 	[%rd1], %rd107;
	mov.u32 	%r130, 4;
	sub.s32 	%r14, %r130, %r11;
	mov.u32 	%r131, 6;
	sub.s32 	%r132, %r131, %r11;
	cvta.to.local.u64 	%rd44, %rd37;
	mul.wide.s32 	%rd45, %r132, 4;
	add.s64 	%rd46, %rd44, %rd45;
	ld.local.u32 	%r271, [%rd46];
	ld.local.u32 	%r272, [%rd46+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p52, %r17, 0;
	@%p52 bra 	$L__BB1_34;

	mov.u32 	%r133, 32;
	sub.s32 	%r134, %r133, %r17;
	shr.u32 	%r135, %r272, %r134;
	shl.b32 	%r136, %r271, %r17;
	add.s32 	%r271, %r135, %r136;
	mul.wide.s32 	%rd49, %r14, 4;
	add.s64 	%rd50, %rd44, %rd49;
	ld.local.u32 	%r137, [%rd50];
	shr.u32 	%r138, %r137, %r134;
	shl.b32 	%r139, %r272, %r17;
	add.s32 	%r272, %r138, %r139;

$L__BB1_34:
	and.b32  	%r140, %r8, -2147483648;
	shr.u32 	%r141, %r272, 30;
	shl.b32 	%r142, %r271, 2;
	or.b32  	%r143, %r141, %r142;
	shr.u32 	%r144, %r143, 31;
	shr.u32 	%r145, %r271, 30;
	add.s32 	%r146, %r144, %r145;
	neg.s32 	%r147, %r146;
	setp.eq.s32 	%p53, %r140, 0;
	selp.b32 	%r273, %r146, %r147, %p53;
	setp.ne.s32 	%p54, %r144, 0;
	xor.b32  	%r148, %r140, -2147483648;
	selp.b32 	%r149, %r148, %r140, %p54;
	selp.b32 	%r150, -1, 0, %p54;
	xor.b32  	%r151, %r143, %r150;
	shl.b32 	%r152, %r272, 2;
	xor.b32  	%r153, %r152, %r150;
	cvt.u64.u32 	%rd51, %r151;
	cvt.u64.u32 	%rd52, %r153;
	bfi.b64 	%rd53, %rd51, %rd52, 32, 32;
	cvt.rn.f64.s64 	%fd39, %rd53;
	mul.rn.f64 	%fd40, %fd39, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f66, %fd40;
	setp.eq.s32 	%p55, %r149, 0;
	neg.f32 	%f67, %f66;
	selp.f32 	%f166, %f66, %f67, %p55;

$L__BB1_36:
	and.b32  	%r24, %r273, 1;
	setp.eq.s32 	%p56, %r24, 0;
	selp.f32 	%f9, %f166, 0f3F800000, %p56;
	mul.rn.f32 	%f10, %f166, %f166;
	mov.f32 	%f167, 0fB94D4153;
	@%p56 bra 	$L__BB1_38;

	mov.f32 	%f70, 0fBAB607ED;
	mov.f32 	%f71, 0f37CBAC00;
	fma.rn.f32 	%f167, %f71, %f10, %f70;

$L__BB1_38:
	selp.f32 	%f72, 0f3C0885E4, 0f3D2AAABB, %p56;
	fma.rn.f32 	%f73, %f167, %f10, %f72;
	selp.f32 	%f74, 0fBE2AAAA8, 0fBEFFFFFF, %p56;
	fma.rn.f32 	%f75, %f73, %f10, %f74;
	mov.f32 	%f76, 0f00000000;
	fma.rn.f32 	%f77, %f10, %f9, %f76;
	fma.rn.f32 	%f168, %f75, %f77, %f9;
	and.b32  	%r155, %r273, 2;
	setp.eq.s32 	%p58, %r155, 0;
	@%p58 bra 	$L__BB1_40;

	mov.f32 	%f79, 0fBF800000;
	fma.rn.f32 	%f168, %f168, %f79, %f76;

$L__BB1_40:
	cvt.f64.f32 	%fd41, %f168;
	mul.rn.f64 	%fd42, %fd41, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd43, %fd23;
	add.rn.f64 	%fd44, %fd43, %fd42;
	cvt.rn.f32.f64 	%f16, %fd44;
	abs.f32 	%f17, %f2;
	setp.eq.f32 	%p59, %f17, 0f00000000;
	abs.f32 	%f18, %f1;
	setp.eq.f32 	%p60, %f18, 0f00000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB1_44;
	bra.uni 	$L__BB1_41;

$L__BB1_44:
	mov.b32 	%r166, %f2;
	shr.s32 	%r167, %r166, 31;
	and.b32  	%r168, %r167, 1078530011;
	mov.b32 	%r169, %f1;
	and.b32  	%r170, %r169, -2147483648;
	or.b32  	%r171, %r168, %r170;
	mov.b32 	%f169, %r171;
	bra.uni 	$L__BB1_45;

$L__BB1_41:
	setp.eq.f32 	%p62, %f17, 0f7F800000;
	setp.eq.f32 	%p63, %f18, 0f7F800000;
	and.pred  	%p64, %p62, %p63;
	@%p64 bra 	$L__BB1_43;
	bra.uni 	$L__BB1_42;

$L__BB1_43:
	mov.b32 	%r161, %f2;
	setp.lt.s32 	%p68, %r161, 0;
	selp.b32 	%r162, 1075235812, 1061752795, %p68;
	mov.b32 	%r163, %f1;
	and.b32  	%r164, %r163, -2147483648;
	or.b32  	%r165, %r162, %r164;
	mov.b32 	%f169, %r165;
	bra.uni 	$L__BB1_45;

$L__BB1_42:
	max.f32 	%f80, %f18, %f17;
	min.f32 	%f81, %f18, %f17;
	div.rn.f32 	%f82, %f81, %f80;
	mul.rn.f32 	%f83, %f82, %f82;
	mov.f32 	%f84, 0fC0B59883;
	mov.f32 	%f85, 0fBF52C7EA;
	fma.rn.f32 	%f86, %f83, %f85, %f84;
	mov.f32 	%f87, 0fC0D21907;
	fma.rn.f32 	%f88, %f86, %f83, %f87;
	mul.rn.f32 	%f89, %f83, %f88;
	mul.rn.f32 	%f90, %f82, %f89;
	add.rn.f32 	%f91, %f83, 0f41355DC0;
	mov.f32 	%f92, 0f41E6BD60;
	fma.rn.f32 	%f93, %f91, %f83, %f92;
	mov.f32 	%f94, 0f419D92C8;
	fma.rn.f32 	%f95, %f93, %f83, %f94;
	rcp.rn.f32 	%f96, %f95;
	fma.rn.f32 	%f97, %f90, %f96, %f82;
	mov.f32 	%f98, 0f3FC90FDB;
	sub.rn.f32 	%f99, %f98, %f97;
	setp.gt.f32 	%p65, %f18, %f17;
	selp.f32 	%f100, %f99, %f97, %p65;
	mov.b32 	%r156, %f2;
	setp.lt.s32 	%p66, %r156, 0;
	mov.f32 	%f101, 0f40490FDB;
	sub.rn.f32 	%f102, %f101, %f100;
	selp.f32 	%f103, %f102, %f100, %p66;
	mov.b32 	%r157, %f103;
	mov.b32 	%r158, %f1;
	and.b32  	%r159, %r158, -2147483648;
	or.b32  	%r160, %r159, %r157;
	mov.b32 	%f104, %r160;
	add.rn.f32 	%f105, %f17, %f18;
	setp.le.f32 	%p67, %f105, 0f7F800000;
	selp.f32 	%f169, %f104, %f105, %p67;

$L__BB1_45:
	mul.rn.f32 	%f23, %f2, 0f42517084;
	mul.rn.f32 	%f106, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r277, %f106;
	cvt.rn.f32.s32 	%f107, %r277;
	mov.f32 	%f108, 0fBFC90FDA;
	fma.rn.f32 	%f109, %f107, %f108, %f23;
	mov.f32 	%f110, 0fB3A22168;
	fma.rn.f32 	%f111, %f107, %f110, %f109;
	mov.f32 	%f112, 0fA7C234C5;
	fma.rn.f32 	%f170, %f107, %f112, %f111;
	abs.f32 	%f25, %f23;
	setp.ltu.f32 	%p69, %f25, 0f47CE4780;
	@%p69 bra 	$L__BB1_53;

	setp.eq.f32 	%p70, %f25, 0f7F800000;
	@%p70 bra 	$L__BB1_52;
	bra.uni 	$L__BB1_47;

$L__BB1_52:
	mov.f32 	%f115, 0f00000000;
	mul.rn.f32 	%f170, %f23, %f115;
	mov.u32 	%r277, 0;
	bra.uni 	$L__BB1_53;

$L__BB1_47:
	mov.b32 	%r26, %f23;
	bfe.u32 	%r173, %r26, 23, 8;
	add.s32 	%r27, %r173, -128;
	shl.b32 	%r174, %r26, 8;
	or.b32  	%r28, %r174, -2147483648;
	shr.u32 	%r29, %r27, 5;
	cvta.to.local.u64 	%rd108, %rd37;
	mov.u64 	%rd110, 0;
	mov.u32 	%r274, 0;
	mov.u64 	%rd109, __cudart_i2opi_f;

$L__BB1_48:
	.pragma "nounroll";
	ld.global.nc.u32 	%r175, [%rd109];
	mad.wide.u32 	%rd57, %r175, %r28, %rd110;
	shr.u64 	%rd110, %rd57, 32;
	st.local.u32 	[%rd108], %rd57;
	add.s64 	%rd109, %rd109, 4;
	add.s64 	%rd108, %rd108, 4;
	add.s32 	%r274, %r274, 1;
	setp.ne.s32 	%p71, %r274, 6;
	@%p71 bra 	$L__BB1_48;

	st.local.u32 	[%rd1], %rd110;
	mov.u32 	%r176, 4;
	sub.s32 	%r32, %r176, %r29;
	mov.u32 	%r177, 6;
	sub.s32 	%r178, %r177, %r29;
	cvta.to.local.u64 	%rd59, %rd37;
	mul.wide.s32 	%rd60, %r178, 4;
	add.s64 	%rd61, %rd59, %rd60;
	ld.local.u32 	%r275, [%rd61];
	ld.local.u32 	%r276, [%rd61+-4];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p72, %r35, 0;
	@%p72 bra 	$L__BB1_51;

	mov.u32 	%r179, 32;
	sub.s32 	%r180, %r179, %r35;
	shr.u32 	%r181, %r276, %r180;
	shl.b32 	%r182, %r275, %r35;
	add.s32 	%r275, %r181, %r182;
	mul.wide.s32 	%rd64, %r32, 4;
	add.s64 	%rd65, %rd59, %rd64;
	ld.local.u32 	%r183, [%rd65];
	shr.u32 	%r184, %r183, %r180;
	shl.b32 	%r185, %r276, %r35;
	add.s32 	%r276, %r184, %r185;

$L__BB1_51:
	and.b32  	%r186, %r26, -2147483648;
	shr.u32 	%r187, %r276, 30;
	shl.b32 	%r188, %r275, 2;
	or.b32  	%r189, %r187, %r188;
	shr.u32 	%r190, %r189, 31;
	shr.u32 	%r191, %r275, 30;
	add.s32 	%r192, %r190, %r191;
	neg.s32 	%r193, %r192;
	setp.eq.s32 	%p73, %r186, 0;
	selp.b32 	%r277, %r192, %r193, %p73;
	setp.ne.s32 	%p74, %r190, 0;
	xor.b32  	%r194, %r186, -2147483648;
	selp.b32 	%r195, %r194, %r186, %p74;
	selp.b32 	%r196, -1, 0, %p74;
	xor.b32  	%r197, %r189, %r196;
	shl.b32 	%r198, %r276, 2;
	xor.b32  	%r199, %r198, %r196;
	cvt.u64.u32 	%rd66, %r197;
	cvt.u64.u32 	%rd67, %r199;
	bfi.b64 	%rd68, %rd66, %rd67, 32, 32;
	cvt.rn.f64.s64 	%fd45, %rd68;
	mul.rn.f64 	%fd46, %fd45, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f113, %fd46;
	setp.eq.s32 	%p75, %r195, 0;
	neg.f32 	%f114, %f113;
	selp.f32 	%f170, %f113, %f114, %p75;

$L__BB1_53:
	add.s32 	%r42, %r277, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32 	%p76, %r43, 0;
	selp.f32 	%f29, %f170, 0f3F800000, %p76;
	mul.rn.f32 	%f30, %f170, %f170;
	mov.f32 	%f171, 0fB94D4153;
	@%p76 bra 	$L__BB1_55;

	mov.f32 	%f117, 0fBAB607ED;
	mov.f32 	%f118, 0f37CBAC00;
	fma.rn.f32 	%f171, %f118, %f30, %f117;

$L__BB1_55:
	selp.f32 	%f119, 0f3C0885E4, 0f3D2AAABB, %p76;
	fma.rn.f32 	%f120, %f171, %f30, %f119;
	selp.f32 	%f121, 0fBE2AAAA8, 0fBEFFFFFF, %p76;
	fma.rn.f32 	%f122, %f120, %f30, %f121;
	mov.f32 	%f123, 0f00000000;
	fma.rn.f32 	%f124, %f30, %f29, %f123;
	fma.rn.f32 	%f172, %f122, %f124, %f29;
	and.b32  	%r201, %r42, 2;
	setp.eq.s32 	%p78, %r201, 0;
	@%p78 bra 	$L__BB1_57;

	mov.f32 	%f126, 0fBF800000;
	fma.rn.f32 	%f172, %f172, %f126, %f123;

$L__BB1_57:
	cvt.f64.f32 	%fd47, %f172;
	mul.rn.f64 	%fd48, %fd47, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd49, %f169;
	add.rn.f64 	%fd50, %fd48, %fd49;
	cvt.rn.f32.f64 	%f36, %fd50;
	mul.rn.f32 	%f127, %f36, 0f3F22F983;
	cvt.rni.s32.f32 	%r285, %f127;
	cvt.rn.f32.s32 	%f128, %r285;
	mov.f32 	%f129, 0fBFC90FDA;
	fma.rn.f32 	%f130, %f128, %f129, %f36;
	mov.f32 	%f131, 0fB3A22168;
	fma.rn.f32 	%f132, %f128, %f131, %f130;
	mov.f32 	%f133, 0fA7C234C5;
	fma.rn.f32 	%f176, %f128, %f133, %f132;
	abs.f32 	%f38, %f36;
	setp.ltu.f32 	%p79, %f38, 0f47CE4780;
	mov.u32 	%r281, %r285;
	mov.f32 	%f173, %f176;
	@%p79 bra 	$L__BB1_65;

	setp.eq.f32 	%p80, %f38, 0f7F800000;
	@%p80 bra 	$L__BB1_64;
	bra.uni 	$L__BB1_59;

$L__BB1_64:
	mov.f32 	%f136, 0f00000000;
	mul.rn.f32 	%f173, %f36, %f136;
	mov.u32 	%r281, 0;
	bra.uni 	$L__BB1_65;

$L__BB1_59:
	mov.b32 	%r45, %f36;
	bfe.u32 	%r203, %r45, 23, 8;
	add.s32 	%r46, %r203, -128;
	shl.b32 	%r204, %r45, 8;
	or.b32  	%r47, %r204, -2147483648;
	shr.u32 	%r48, %r46, 5;
	cvta.to.local.u64 	%rd111, %rd37;
	mov.u64 	%rd113, 0;
	mov.u32 	%r278, 0;
	mov.u64 	%rd112, __cudart_i2opi_f;

$L__BB1_60:
	.pragma "nounroll";
	ld.global.nc.u32 	%r205, [%rd112];
	mad.wide.u32 	%rd72, %r205, %r47, %rd113;
	shr.u64 	%rd113, %rd72, 32;
	st.local.u32 	[%rd111], %rd72;
	add.s64 	%rd112, %rd112, 4;
	add.s64 	%rd111, %rd111, 4;
	add.s32 	%r278, %r278, 1;
	setp.ne.s32 	%p81, %r278, 6;
	@%p81 bra 	$L__BB1_60;

	st.local.u32 	[%rd1], %rd113;
	mov.u32 	%r206, 4;
	sub.s32 	%r51, %r206, %r48;
	mov.u32 	%r207, 6;
	sub.s32 	%r208, %r207, %r48;
	cvta.to.local.u64 	%rd74, %rd37;
	mul.wide.s32 	%rd75, %r208, 4;
	add.s64 	%rd76, %rd74, %rd75;
	ld.local.u32 	%r279, [%rd76];
	ld.local.u32 	%r280, [%rd76+-4];
	and.b32  	%r54, %r46, 31;
	setp.eq.s32 	%p82, %r54, 0;
	@%p82 bra 	$L__BB1_63;

	mov.u32 	%r209, 32;
	sub.s32 	%r210, %r209, %r54;
	shr.u32 	%r211, %r280, %r210;
	shl.b32 	%r212, %r279, %r54;
	add.s32 	%r279, %r211, %r212;
	mul.wide.s32 	%rd79, %r51, 4;
	add.s64 	%rd80, %rd74, %rd79;
	ld.local.u32 	%r213, [%rd80];
	shr.u32 	%r214, %r213, %r210;
	shl.b32 	%r215, %r280, %r54;
	add.s32 	%r280, %r214, %r215;

$L__BB1_63:
	and.b32  	%r216, %r45, -2147483648;
	shr.u32 	%r217, %r280, 30;
	shl.b32 	%r218, %r279, 2;
	or.b32  	%r219, %r217, %r218;
	shr.u32 	%r220, %r219, 31;
	shr.u32 	%r221, %r279, 30;
	add.s32 	%r222, %r220, %r221;
	neg.s32 	%r223, %r222;
	setp.eq.s32 	%p83, %r216, 0;
	selp.b32 	%r281, %r222, %r223, %p83;
	setp.ne.s32 	%p84, %r220, 0;
	xor.b32  	%r224, %r216, -2147483648;
	selp.b32 	%r225, %r224, %r216, %p84;
	selp.b32 	%r226, -1, 0, %p84;
	xor.b32  	%r227, %r219, %r226;
	shl.b32 	%r228, %r280, 2;
	xor.b32  	%r229, %r228, %r226;
	cvt.u64.u32 	%rd81, %r227;
	cvt.u64.u32 	%rd82, %r229;
	bfi.b64 	%rd83, %rd81, %rd82, 32, 32;
	cvt.rn.f64.s64 	%fd51, %rd83;
	mul.rn.f64 	%fd52, %fd51, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f134, %fd52;
	setp.eq.s32 	%p85, %r225, 0;
	neg.f32 	%f135, %f134;
	selp.f32 	%f173, %f134, %f135, %p85;

$L__BB1_65:
	add.s32 	%r61, %r281, 1;
	and.b32  	%r62, %r61, 1;
	setp.eq.s32 	%p86, %r62, 0;
	selp.f32 	%f42, %f173, 0f3F800000, %p86;
	mul.rn.f32 	%f43, %f173, %f173;
	mov.f32 	%f174, 0fB94D4153;
	@%p86 bra 	$L__BB1_67;

	mov.f32 	%f138, 0fBAB607ED;
	mov.f32 	%f139, 0f37CBAC00;
	fma.rn.f32 	%f174, %f139, %f43, %f138;

$L__BB1_67:
	selp.f32 	%f140, 0f3C0885E4, 0f3D2AAABB, %p86;
	fma.rn.f32 	%f141, %f174, %f43, %f140;
	selp.f32 	%f142, 0fBE2AAAA8, 0fBEFFFFFF, %p86;
	fma.rn.f32 	%f143, %f141, %f43, %f142;
	mov.f32 	%f144, 0f00000000;
	fma.rn.f32 	%f145, %f43, %f42, %f144;
	fma.rn.f32 	%f175, %f143, %f145, %f42;
	and.b32  	%r231, %r61, 2;
	setp.eq.s32 	%p88, %r231, 0;
	@%p88 bra 	$L__BB1_69;

	mov.f32 	%f147, 0fBF800000;
	fma.rn.f32 	%f175, %f175, %f147, %f144;

$L__BB1_69:
	mul.rn.f32 	%f148, %f175, %f16;
	cvt.f64.f32 	%fd53, %f148;
	add.rn.f64 	%fd54, %fd53, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f149, %fd54;
	st.global.f32 	[%rd35], %f149;
	@%p79 bra 	$L__BB1_77;

	setp.eq.f32 	%p90, %f38, 0f7F800000;
	@%p90 bra 	$L__BB1_76;
	bra.uni 	$L__BB1_71;

$L__BB1_76:
	mov.f32 	%f152, 0f00000000;
	mul.rn.f32 	%f176, %f36, %f152;
	mov.u32 	%r285, 0;
	bra.uni 	$L__BB1_77;

$L__BB1_71:
	mov.b32 	%r63, %f36;
	bfe.u32 	%r237, %r63, 23, 8;
	add.s32 	%r64, %r237, -128;
	shl.b32 	%r238, %r63, 8;
	or.b32  	%r65, %r238, -2147483648;
	shr.u32 	%r66, %r64, 5;
	mov.u64 	%rd116, 0;
	mov.u32 	%r282, 0;
	mov.u64 	%rd115, __cudart_i2opi_f;

$L__BB1_72:
	.pragma "nounroll";
	ld.global.nc.u32 	%r239, [%rd115];
	mad.wide.u32 	%rd90, %r239, %r65, %rd116;
	shr.u64 	%rd116, %rd90, 32;
	st.local.u32 	[%rd114], %rd90;
	add.s64 	%rd115, %rd115, 4;
	add.s64 	%rd114, %rd114, 4;
	add.s32 	%r282, %r282, 1;
	setp.ne.s32 	%p91, %r282, 6;
	@%p91 bra 	$L__BB1_72;

	st.local.u32 	[%rd1], %rd116;
	mov.u32 	%r240, 4;
	sub.s32 	%r69, %r240, %r66;
	mov.u32 	%r241, 6;
	sub.s32 	%r242, %r241, %r66;
	cvta.to.local.u64 	%rd92, %rd37;
	mul.wide.s32 	%rd93, %r242, 4;
	add.s64 	%rd94, %rd92, %rd93;
	ld.local.u32 	%r283, [%rd94];
	ld.local.u32 	%r284, [%rd94+-4];
	and.b32  	%r72, %r64, 31;
	setp.eq.s32 	%p92, %r72, 0;
	@%p92 bra 	$L__BB1_75;

	mov.u32 	%r243, 32;
	sub.s32 	%r244, %r243, %r72;
	shr.u32 	%r245, %r284, %r244;
	shl.b32 	%r246, %r283, %r72;
	add.s32 	%r283, %r245, %r246;
	mul.wide.s32 	%rd97, %r69, 4;
	add.s64 	%rd98, %rd92, %rd97;
	ld.local.u32 	%r247, [%rd98];
	shr.u32 	%r248, %r247, %r244;
	shl.b32 	%r249, %r284, %r72;
	add.s32 	%r284, %r248, %r249;

$L__BB1_75:
	and.b32  	%r250, %r63, -2147483648;
	shr.u32 	%r251, %r284, 30;
	shl.b32 	%r252, %r283, 2;
	or.b32  	%r253, %r251, %r252;
	shr.u32 	%r254, %r253, 31;
	shr.u32 	%r255, %r283, 30;
	add.s32 	%r256, %r254, %r255;
	neg.s32 	%r257, %r256;
	setp.eq.s32 	%p93, %r250, 0;
	selp.b32 	%r285, %r256, %r257, %p93;
	setp.ne.s32 	%p94, %r254, 0;
	xor.b32  	%r258, %r250, -2147483648;
	selp.b32 	%r259, %r258, %r250, %p94;
	selp.b32 	%r260, -1, 0, %p94;
	xor.b32  	%r261, %r253, %r260;
	shl.b32 	%r262, %r284, 2;
	xor.b32  	%r263, %r262, %r260;
	cvt.u64.u32 	%rd99, %r261;
	cvt.u64.u32 	%rd100, %r263;
	bfi.b64 	%rd101, %rd99, %rd100, 32, 32;
	cvt.rn.f64.s64 	%fd55, %rd101;
	mul.rn.f64 	%fd56, %fd55, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f150, %fd56;
	setp.eq.s32 	%p95, %r259, 0;
	neg.f32 	%f151, %f150;
	selp.f32 	%f176, %f150, %f151, %p95;

$L__BB1_77:
	and.b32  	%r79, %r285, 1;
	setp.eq.s32 	%p96, %r79, 0;
	selp.f32 	%f52, %f176, 0f3F800000, %p96;
	mul.rn.f32 	%f53, %f176, %f176;
	mov.f32 	%f177, 0fB94D4153;
	@%p96 bra 	$L__BB1_79;

	mov.f32 	%f154, 0fBAB607ED;
	mov.f32 	%f155, 0f37CBAC00;
	fma.rn.f32 	%f177, %f155, %f53, %f154;

$L__BB1_79:
	selp.f32 	%f156, 0f3C0885E4, 0f3D2AAABB, %p96;
	fma.rn.f32 	%f157, %f177, %f53, %f156;
	selp.f32 	%f158, 0fBE2AAAA8, 0fBEFFFFFF, %p96;
	fma.rn.f32 	%f159, %f157, %f53, %f158;
	mov.f32 	%f160, 0f00000000;
	fma.rn.f32 	%f161, %f53, %f52, %f160;
	fma.rn.f32 	%f178, %f159, %f161, %f52;
	and.b32  	%r265, %r285, 2;
	setp.eq.s32 	%p98, %r265, 0;
	@%p98 bra 	$L__BB1_81;

	mov.f32 	%f163, 0fBF800000;
	fma.rn.f32 	%f178, %f178, %f163, %f160;

$L__BB1_81:
	mul.rn.f32 	%f164, %f178, %f16;
	cvt.f64.f32 	%fd57, %f164;
	add.rn.f64 	%fd58, %fd57, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f165, %fd58;
	st.global.f32 	[%rd36], %f165;
	ret;

}
	// .globl	gcj02_to_wgs84_cuda_float
.visible .entry gcj02_to_wgs84_cuda_float(
	.param .u64 gcj02_to_wgs84_cuda_float_param_0,
	.param .u64 gcj02_to_wgs84_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot2[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<137>;
	.reg .f32 	%f<163>;
	.reg .b32 	%r<361>;
	.reg .f64 	%fd<445>;
	.reg .b64 	%rd<152>;


	mov.u64 	%SPL, __local_depot2;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd37, [gcj02_to_wgs84_cuda_float_param_0];
	ld.param.u64 	%rd38, [gcj02_to_wgs84_cuda_float_param_1];
	cvta.to.global.u64 	%rd39, %rd38;
	add.u64 	%rd40, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r103, %ntid.x;
	mov.u32 	%r104, %ctaid.x;
	mov.u32 	%r105, %tid.x;
	mad.lo.s32 	%r106, %r104, %r103, %r105;
	cvta.to.global.u64 	%rd49, %rd37;
	mul.wide.s32 	%rd50, %r106, 4;
	add.s64 	%rd10, %rd49, %rd50;
	add.s64 	%rd11, %rd39, %rd50;
	ld.global.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd11];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd136, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd136;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd137, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd137;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r107, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd4;
	}
	and.b32  	%r109, %r108, 2147483647;
	setp.eq.s32 	%p4, %r109, 2146435072;
	setp.eq.s32 	%p5, %r107, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB2_3;
	bra.uni 	$L__BB2_1;

$L__BB2_3:
	mov.f64 	%fd147, 0d0000000000000000;
	mul.rn.f64 	%fd415, %fd4, %fd147;
	mov.u32 	%r337, 0;
	bra.uni 	$L__BB2_4;

$L__BB2_1:
	mul.rn.f64 	%fd138, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r337, %fd138;
	st.local.u32 	[%rd8], %r337;
	cvt.rn.f64.s32 	%fd139, %r337;
	neg.f64 	%fd140, %fd139;
	mov.f64 	%fd141, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd142, %fd140, %fd141, %fd4;
	mov.f64 	%fd143, 0d3C91A62633145C00;
	fma.rn.f64 	%fd144, %fd140, %fd143, %fd142;
	mov.f64 	%fd145, 0d397B839A252049C0;
	fma.rn.f64 	%fd415, %fd140, %fd145, %fd144;
	abs.f64 	%fd146, %fd4;
	setp.ltu.f64 	%p7, %fd146, 0d41E0000000000000;
	@%p7 bra 	$L__BB2_4;

	{ // callseq 4, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd415, [retval0+0];
	} // callseq 4
	ld.local.u32 	%r337, [%rd8];

$L__BB2_4:
	and.b32  	%r111, %r337, 1;
	shl.b32 	%r112, %r337, 3;
	and.b32  	%r113, %r112, 8;
	setp.eq.s32 	%p8, %r111, 0;
	selp.f64 	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd52, %r113, 8;
	mov.u64 	%rd53, __cudart_sin_cos_coeffs;
	add.s64 	%rd54, %rd53, %rd52;
	ld.global.nc.f64 	%fd149, [%rd54+8];
	mul.rn.f64 	%fd9, %fd415, %fd415;
	fma.rn.f64 	%fd150, %fd148, %fd9, %fd149;
	ld.global.nc.f64 	%fd151, [%rd54+16];
	fma.rn.f64 	%fd152, %fd150, %fd9, %fd151;
	ld.global.nc.f64 	%fd153, [%rd54+24];
	fma.rn.f64 	%fd154, %fd152, %fd9, %fd153;
	ld.global.nc.f64 	%fd155, [%rd54+32];
	fma.rn.f64 	%fd156, %fd154, %fd9, %fd155;
	ld.global.nc.f64 	%fd157, [%rd54+40];
	fma.rn.f64 	%fd158, %fd156, %fd9, %fd157;
	ld.global.nc.f64 	%fd159, [%rd54+48];
	fma.rn.f64 	%fd10, %fd158, %fd9, %fd159;
	fma.rn.f64 	%fd417, %fd10, %fd415, %fd415;
	@%p8 bra 	$L__BB2_6;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd417, %fd10, %fd9, %fd160;

$L__BB2_6:
	and.b32  	%r114, %r337, 2;
	setp.eq.s32 	%p9, %r114, 0;
	@%p9 bra 	$L__BB2_8;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd417, %fd417, %fd162, %fd161;

$L__BB2_8:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r116}, %fd16;
	}
	and.b32  	%r117, %r116, 2147483647;
	setp.eq.s32 	%p10, %r117, 2146435072;
	setp.eq.s32 	%p11, %r115, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB2_11;
	bra.uni 	$L__BB2_9;

$L__BB2_11:
	mov.f64 	%fd172, 0d0000000000000000;
	mul.rn.f64 	%fd418, %fd16, %fd172;
	mov.u32 	%r338, 0;
	bra.uni 	$L__BB2_12;

$L__BB2_9:
	add.u64 	%rd130, %SPL, 0;
	mul.rn.f64 	%fd163, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd163;
	st.local.u32 	[%rd130], %r338;
	cvt.rn.f64.s32 	%fd164, %r338;
	neg.f64 	%fd165, %fd164;
	mov.f64 	%fd166, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd167, %fd165, %fd166, %fd16;
	mov.f64 	%fd168, 0d3C91A62633145C00;
	fma.rn.f64 	%fd169, %fd165, %fd168, %fd167;
	mov.f64 	%fd170, 0d397B839A252049C0;
	fma.rn.f64 	%fd418, %fd165, %fd170, %fd169;
	abs.f64 	%fd171, %fd16;
	setp.ltu.f64 	%p13, %fd171, 0d41E0000000000000;
	@%p13 bra 	$L__BB2_12;

	add.u64 	%rd133, %SP, 0;
	add.u64 	%rd132, %SPL, 0;
	{ // callseq 5, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd133;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd418, [retval0+0];
	} // callseq 5
	ld.local.u32 	%r338, [%rd132];

$L__BB2_12:
	and.b32  	%r119, %r338, 1;
	shl.b32 	%r120, %r338, 3;
	and.b32  	%r121, %r120, 8;
	setp.eq.s32 	%p14, %r119, 0;
	selp.f64 	%fd173, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd56, %r121, 8;
	add.s64 	%rd58, %rd53, %rd56;
	ld.global.nc.f64 	%fd174, [%rd58+8];
	mul.rn.f64 	%fd21, %fd418, %fd418;
	fma.rn.f64 	%fd175, %fd173, %fd21, %fd174;
	ld.global.nc.f64 	%fd176, [%rd58+16];
	fma.rn.f64 	%fd177, %fd175, %fd21, %fd176;
	ld.global.nc.f64 	%fd178, [%rd58+24];
	fma.rn.f64 	%fd179, %fd177, %fd21, %fd178;
	ld.global.nc.f64 	%fd180, [%rd58+32];
	fma.rn.f64 	%fd181, %fd179, %fd21, %fd180;
	ld.global.nc.f64 	%fd182, [%rd58+40];
	fma.rn.f64 	%fd183, %fd181, %fd21, %fd182;
	ld.global.nc.f64 	%fd184, [%rd58+48];
	fma.rn.f64 	%fd22, %fd183, %fd21, %fd184;
	fma.rn.f64 	%fd420, %fd22, %fd418, %fd418;
	@%p14 bra 	$L__BB2_14;

	mov.f64 	%fd185, 0d3FF0000000000000;
	fma.rn.f64 	%fd420, %fd22, %fd21, %fd185;

$L__BB2_14:
	and.b32  	%r122, %r338, 2;
	setp.eq.s32 	%p15, %r122, 0;
	@%p15 bra 	$L__BB2_16;

	mov.f64 	%fd186, 0d0000000000000000;
	mov.f64 	%fd187, 0dBFF0000000000000;
	fma.rn.f64 	%fd420, %fd420, %fd187, %fd186;

$L__BB2_16:
	mul.rn.f64 	%fd188, %fd420, 0d4034000000000000;
	mul.rn.f64 	%fd189, %fd417, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd189, %fd188;
	mul.rn.f32 	%f53, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r342, %f53;
	cvt.rn.f32.s32 	%f54, %r342;
	mov.f32 	%f55, 0fBFC90FDA;
	fma.rn.f32 	%f56, %f54, %f55, %f6;
	mov.f32 	%f57, 0fB3A22168;
	fma.rn.f32 	%f58, %f54, %f57, %f56;
	mov.f32 	%f59, 0fA7C234C5;
	fma.rn.f32 	%f151, %f54, %f59, %f58;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p16, %f8, 0f47CE4780;
	add.s64 	%rd12, %rd1, 24;
	@%p16 bra 	$L__BB2_24;

	setp.eq.f32 	%p17, %f8, 0f7F800000;
	@%p17 bra 	$L__BB2_23;
	bra.uni 	$L__BB2_18;

$L__BB2_23:
	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f151, %f6, %f62;
	mov.u32 	%r342, 0;
	bra.uni 	$L__BB2_24;

$L__BB2_18:
	mov.b32 	%r8, %f6;
	bfe.u32 	%r124, %r8, 23, 8;
	add.s32 	%r9, %r124, -128;
	shl.b32 	%r125, %r8, 8;
	or.b32  	%r10, %r125, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd142, 0;
	mov.u32 	%r339, 0;
	mov.u64 	%rd141, __cudart_i2opi_f;
	mov.u64 	%rd140, %rd1;

$L__BB2_19:
	.pragma "nounroll";
	ld.global.nc.u32 	%r126, [%rd141];
	mad.wide.u32 	%rd61, %r126, %r10, %rd142;
	shr.u64 	%rd142, %rd61, 32;
	st.local.u32 	[%rd140], %rd61;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r339, %r339, 1;
	setp.ne.s32 	%p18, %r339, 6;
	@%p18 bra 	$L__BB2_19;

	st.local.u32 	[%rd12], %rd142;
	mov.u32 	%r127, 4;
	sub.s32 	%r14, %r127, %r11;
	mov.u32 	%r128, 6;
	sub.s32 	%r129, %r128, %r11;
	mul.wide.s32 	%rd62, %r129, 4;
	add.s64 	%rd63, %rd1, %rd62;
	ld.local.u32 	%r340, [%rd63];
	ld.local.u32 	%r341, [%rd63+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p19, %r17, 0;
	@%p19 bra 	$L__BB2_22;

	mov.u32 	%r130, 32;
	sub.s32 	%r131, %r130, %r17;
	shr.u32 	%r132, %r341, %r131;
	shl.b32 	%r133, %r340, %r17;
	add.s32 	%r340, %r132, %r133;
	mul.wide.s32 	%rd64, %r14, 4;
	add.s64 	%rd65, %rd1, %rd64;
	ld.local.u32 	%r134, [%rd65];
	shr.u32 	%r135, %r134, %r131;
	shl.b32 	%r136, %r341, %r17;
	add.s32 	%r341, %r135, %r136;

$L__BB2_22:
	and.b32  	%r137, %r8, -2147483648;
	shr.u32 	%r138, %r341, 30;
	shl.b32 	%r139, %r340, 2;
	or.b32  	%r140, %r138, %r139;
	shr.u32 	%r141, %r140, 31;
	shr.u32 	%r142, %r340, 30;
	add.s32 	%r143, %r141, %r142;
	neg.s32 	%r144, %r143;
	setp.eq.s32 	%p20, %r137, 0;
	selp.b32 	%r342, %r143, %r144, %p20;
	setp.ne.s32 	%p21, %r141, 0;
	xor.b32  	%r145, %r137, -2147483648;
	selp.b32 	%r146, %r145, %r137, %p21;
	selp.b32 	%r147, -1, 0, %p21;
	xor.b32  	%r148, %r140, %r147;
	shl.b32 	%r149, %r341, 2;
	xor.b32  	%r150, %r149, %r147;
	cvt.u64.u32 	%rd66, %r148;
	cvt.u64.u32 	%rd67, %r150;
	bfi.b64 	%rd68, %rd66, %rd67, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd68;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f60, %fd191;
	setp.eq.s32 	%p22, %r146, 0;
	neg.f32 	%f61, %f60;
	selp.f32 	%f151, %f60, %f61, %p22;

$L__BB2_24:
	and.b32  	%r24, %r342, 1;
	setp.eq.s32 	%p23, %r24, 0;
	selp.f32 	%f12, %f151, 0f3F800000, %p23;
	mul.rn.f32 	%f13, %f151, %f151;
	mov.f32 	%f152, 0fB94D4153;
	@%p23 bra 	$L__BB2_26;

	mov.f32 	%f64, 0fBAB607ED;
	mov.f32 	%f65, 0f37CBAC00;
	fma.rn.f32 	%f152, %f65, %f13, %f64;

$L__BB2_26:
	selp.f32 	%f66, 0f3C0885E4, 0f3D2AAABB, %p23;
	fma.rn.f32 	%f67, %f152, %f13, %f66;
	selp.f32 	%f68, 0fBE2AAAA8, 0fBEFFFFFF, %p23;
	fma.rn.f32 	%f69, %f67, %f13, %f68;
	mov.f32 	%f70, 0f00000000;
	fma.rn.f32 	%f71, %f13, %f12, %f70;
	fma.rn.f32 	%f153, %f69, %f71, %f12;
	and.b32  	%r152, %r342, 2;
	setp.eq.s32 	%p25, %r152, 0;
	@%p25 bra 	$L__BB2_28;

	mov.f32 	%f73, 0fBF800000;
	fma.rn.f32 	%f153, %f153, %f73, %f70;

$L__BB2_28:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd30;
	}
	and.b32  	%r155, %r154, 2147483647;
	setp.eq.s32 	%p26, %r155, 2146435072;
	setp.eq.s32 	%p27, %r153, 0;
	and.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB2_31;
	bra.uni 	$L__BB2_29;

$L__BB2_31:
	mov.f64 	%fd201, 0d0000000000000000;
	mul.rn.f64 	%fd421, %fd30, %fd201;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB2_32;

$L__BB2_29:
	mul.rn.f64 	%fd192, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r343, %fd192;
	st.local.u32 	[%rd1], %r343;
	cvt.rn.f64.s32 	%fd193, %r343;
	neg.f64 	%fd194, %fd193;
	mov.f64 	%fd195, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd196, %fd194, %fd195, %fd30;
	mov.f64 	%fd197, 0d3C91A62633145C00;
	fma.rn.f64 	%fd198, %fd194, %fd197, %fd196;
	mov.f64 	%fd199, 0d397B839A252049C0;
	fma.rn.f64 	%fd421, %fd194, %fd199, %fd198;
	abs.f64 	%fd200, %fd30;
	setp.ltu.f64 	%p29, %fd200, 0d41E0000000000000;
	@%p29 bra 	$L__BB2_32;

	add.u64 	%rd134, %SP, 0;
	{ // callseq 6, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd421, [retval0+0];
	} // callseq 6
	ld.local.u32 	%r343, [%rd1];

$L__BB2_32:
	and.b32  	%r157, %r343, 1;
	shl.b32 	%r158, %r343, 3;
	and.b32  	%r159, %r158, 8;
	setp.eq.s32 	%p30, %r157, 0;
	selp.f64 	%fd202, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	mul.wide.s32 	%rd70, %r159, 8;
	add.s64 	%rd72, %rd53, %rd70;
	ld.global.nc.f64 	%fd203, [%rd72+8];
	mul.rn.f64 	%fd35, %fd421, %fd421;
	fma.rn.f64 	%fd204, %fd202, %fd35, %fd203;
	ld.global.nc.f64 	%fd205, [%rd72+16];
	fma.rn.f64 	%fd206, %fd204, %fd35, %fd205;
	ld.global.nc.f64 	%fd207, [%rd72+24];
	fma.rn.f64 	%fd208, %fd206, %fd35, %fd207;
	ld.global.nc.f64 	%fd209, [%rd72+32];
	fma.rn.f64 	%fd210, %fd208, %fd35, %fd209;
	ld.global.nc.f64 	%fd211, [%rd72+40];
	fma.rn.f64 	%fd212, %fd210, %fd35, %fd211;
	ld.global.nc.f64 	%fd213, [%rd72+48];
	fma.rn.f64 	%fd36, %fd212, %fd35, %fd213;
	fma.rn.f64 	%fd423, %fd36, %fd421, %fd421;
	@%p30 bra 	$L__BB2_34;

	mov.f64 	%fd214, 0d3FF0000000000000;
	fma.rn.f64 	%fd423, %fd36, %fd35, %fd214;

$L__BB2_34:
	and.b32  	%r160, %r343, 2;
	setp.eq.s32 	%p31, %r160, 0;
	@%p31 bra 	$L__BB2_36;

	mov.f64 	%fd215, 0d0000000000000000;
	mov.f64 	%fd216, 0dBFF0000000000000;
	fma.rn.f64 	%fd423, %fd423, %fd216, %fd215;

$L__BB2_36:
	mul.rn.f64 	%fd217, %fd423, 0d4044000000000000;
	cvt.f64.f32 	%fd218, %f153;
	mul.rn.f64 	%fd219, %fd218, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd219, %fd217;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd43;
	}
	and.b32  	%r163, %r162, 2147483647;
	setp.eq.s32 	%p32, %r163, 2146435072;
	setp.eq.s32 	%p33, %r161, 0;
	and.pred  	%p34, %p33, %p32;
	@%p34 bra 	$L__BB2_39;
	bra.uni 	$L__BB2_37;

$L__BB2_39:
	mov.f64 	%fd229, 0d0000000000000000;
	mul.rn.f64 	%fd424, %fd43, %fd229;
	mov.u32 	%r344, 0;
	bra.uni 	$L__BB2_40;

$L__BB2_37:
	mul.rn.f64 	%fd220, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd220;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd221, %r344;
	neg.f64 	%fd222, %fd221;
	mov.f64 	%fd223, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd224, %fd222, %fd223, %fd43;
	mov.f64 	%fd225, 0d3C91A62633145C00;
	fma.rn.f64 	%fd226, %fd222, %fd225, %fd224;
	mov.f64 	%fd227, 0d397B839A252049C0;
	fma.rn.f64 	%fd424, %fd222, %fd227, %fd226;
	abs.f64 	%fd228, %fd43;
	setp.ltu.f64 	%p35, %fd228, 0d41E0000000000000;
	@%p35 bra 	$L__BB2_40;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 7, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd424, [retval0+0];
	} // callseq 7
	ld.local.u32 	%r344, [%rd1];

$L__BB2_40:
	and.b32  	%r165, %r344, 1;
	shl.b32 	%r166, %r344, 3;
	and.b32  	%r167, %r166, 8;
	setp.eq.s32 	%p36, %r165, 0;
	selp.f64 	%fd230, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p36;
	mul.wide.s32 	%rd74, %r167, 8;
	add.s64 	%rd76, %rd53, %rd74;
	ld.global.nc.f64 	%fd231, [%rd76+8];
	mul.rn.f64 	%fd48, %fd424, %fd424;
	fma.rn.f64 	%fd232, %fd230, %fd48, %fd231;
	ld.global.nc.f64 	%fd233, [%rd76+16];
	fma.rn.f64 	%fd234, %fd232, %fd48, %fd233;
	ld.global.nc.f64 	%fd235, [%rd76+24];
	fma.rn.f64 	%fd236, %fd234, %fd48, %fd235;
	ld.global.nc.f64 	%fd237, [%rd76+32];
	fma.rn.f64 	%fd238, %fd236, %fd48, %fd237;
	ld.global.nc.f64 	%fd239, [%rd76+40];
	fma.rn.f64 	%fd240, %fd238, %fd48, %fd239;
	ld.global.nc.f64 	%fd241, [%rd76+48];
	fma.rn.f64 	%fd49, %fd240, %fd48, %fd241;
	fma.rn.f64 	%fd426, %fd49, %fd424, %fd424;
	@%p36 bra 	$L__BB2_42;

	mov.f64 	%fd242, 0d3FF0000000000000;
	fma.rn.f64 	%fd426, %fd49, %fd48, %fd242;

$L__BB2_42:
	and.b32  	%r168, %r344, 2;
	setp.eq.s32 	%p37, %r168, 0;
	@%p37 bra 	$L__BB2_44;

	mov.f64 	%fd243, 0d0000000000000000;
	mov.f64 	%fd244, 0dBFF0000000000000;
	fma.rn.f64 	%fd426, %fd426, %fd244, %fd243;

$L__BB2_44:
	mul.rn.f64 	%fd245, %fd426, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd245;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd56;
	}
	and.b32  	%r171, %r170, 2147483647;
	setp.eq.s32 	%p38, %r171, 2146435072;
	setp.eq.s32 	%p39, %r169, 0;
	and.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB2_47;
	bra.uni 	$L__BB2_45;

$L__BB2_47:
	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd427, %fd56, %fd255;
	mov.u32 	%r345, 0;
	bra.uni 	$L__BB2_48;

$L__BB2_45:
	mul.rn.f64 	%fd246, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r345, %fd246;
	st.local.u32 	[%rd1], %r345;
	cvt.rn.f64.s32 	%fd247, %r345;
	neg.f64 	%fd248, %fd247;
	mov.f64 	%fd249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd250, %fd248, %fd249, %fd56;
	mov.f64 	%fd251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd252, %fd248, %fd251, %fd250;
	mov.f64 	%fd253, 0d397B839A252049C0;
	fma.rn.f64 	%fd427, %fd248, %fd253, %fd252;
	abs.f64 	%fd254, %fd56;
	setp.ltu.f64 	%p41, %fd254, 0d41E0000000000000;
	@%p41 bra 	$L__BB2_48;

	add.u64 	%rd136, %SP, 0;
	{ // callseq 8, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd427, [retval0+0];
	} // callseq 8
	ld.local.u32 	%r345, [%rd1];

$L__BB2_48:
	and.b32  	%r173, %r345, 1;
	shl.b32 	%r174, %r345, 3;
	and.b32  	%r175, %r174, 8;
	setp.eq.s32 	%p42, %r173, 0;
	selp.f64 	%fd256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	mul.wide.s32 	%rd78, %r175, 8;
	add.s64 	%rd80, %rd53, %rd78;
	ld.global.nc.f64 	%fd257, [%rd80+8];
	mul.rn.f64 	%fd61, %fd427, %fd427;
	fma.rn.f64 	%fd258, %fd256, %fd61, %fd257;
	ld.global.nc.f64 	%fd259, [%rd80+16];
	fma.rn.f64 	%fd260, %fd258, %fd61, %fd259;
	ld.global.nc.f64 	%fd261, [%rd80+24];
	fma.rn.f64 	%fd262, %fd260, %fd61, %fd261;
	ld.global.nc.f64 	%fd263, [%rd80+32];
	fma.rn.f64 	%fd264, %fd262, %fd61, %fd263;
	ld.global.nc.f64 	%fd265, [%rd80+40];
	fma.rn.f64 	%fd266, %fd264, %fd61, %fd265;
	ld.global.nc.f64 	%fd267, [%rd80+48];
	fma.rn.f64 	%fd62, %fd266, %fd61, %fd267;
	fma.rn.f64 	%fd429, %fd62, %fd427, %fd427;
	@%p42 bra 	$L__BB2_50;

	mov.f64 	%fd268, 0d3FF0000000000000;
	fma.rn.f64 	%fd429, %fd62, %fd61, %fd268;

$L__BB2_50:
	and.b32  	%r176, %r345, 2;
	setp.eq.s32 	%p43, %r176, 0;
	@%p43 bra 	$L__BB2_52;

	mov.f64 	%fd269, 0d0000000000000000;
	mov.f64 	%fd270, 0dBFF0000000000000;
	fma.rn.f64 	%fd429, %fd429, %fd270, %fd269;

$L__BB2_52:
	mul.rn.f64 	%fd271, %fd429, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd271;
	mul.rn.f32 	%f74, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r349, %f74;
	cvt.rn.f32.s32 	%f75, %r349;
	mov.f32 	%f76, 0fBFC90FDA;
	fma.rn.f32 	%f77, %f75, %f76, %f5;
	mov.f32 	%f78, 0fB3A22168;
	fma.rn.f32 	%f79, %f75, %f78, %f77;
	mov.f32 	%f80, 0fA7C234C5;
	fma.rn.f32 	%f154, %f75, %f80, %f79;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p44, %f20, 0f47CE4780;
	@%p44 bra 	$L__BB2_60;

	setp.eq.f32 	%p45, %f20, 0f7F800000;
	@%p45 bra 	$L__BB2_59;
	bra.uni 	$L__BB2_54;

$L__BB2_59:
	mov.f32 	%f83, 0f00000000;
	mul.rn.f32 	%f154, %f5, %f83;
	mov.u32 	%r349, 0;
	bra.uni 	$L__BB2_60;

$L__BB2_54:
	mov.b32 	%r35, %f5;
	bfe.u32 	%r178, %r35, 23, 8;
	add.s32 	%r36, %r178, -128;
	shl.b32 	%r179, %r35, 8;
	or.b32  	%r37, %r179, -2147483648;
	shr.u32 	%r38, %r36, 5;
	mov.u64 	%rd145, 0;
	mov.u32 	%r346, 0;
	mov.u64 	%rd144, __cudart_i2opi_f;
	mov.u64 	%rd143, %rd1;

$L__BB2_55:
	.pragma "nounroll";
	ld.global.nc.u32 	%r180, [%rd144];
	mad.wide.u32 	%rd83, %r180, %r37, %rd145;
	shr.u64 	%rd145, %rd83, 32;
	st.local.u32 	[%rd143], %rd83;
	add.s64 	%rd144, %rd144, 4;
	add.s64 	%rd143, %rd143, 4;
	add.s32 	%r346, %r346, 1;
	setp.ne.s32 	%p46, %r346, 6;
	@%p46 bra 	$L__BB2_55;

	st.local.u32 	[%rd12], %rd145;
	mov.u32 	%r181, 4;
	sub.s32 	%r41, %r181, %r38;
	mov.u32 	%r182, 6;
	sub.s32 	%r183, %r182, %r38;
	mul.wide.s32 	%rd84, %r183, 4;
	add.s64 	%rd85, %rd1, %rd84;
	ld.local.u32 	%r347, [%rd85];
	ld.local.u32 	%r348, [%rd85+-4];
	and.b32  	%r44, %r36, 31;
	setp.eq.s32 	%p47, %r44, 0;
	@%p47 bra 	$L__BB2_58;

	mov.u32 	%r184, 32;
	sub.s32 	%r185, %r184, %r44;
	shr.u32 	%r186, %r348, %r185;
	shl.b32 	%r187, %r347, %r44;
	add.s32 	%r347, %r186, %r187;
	mul.wide.s32 	%rd86, %r41, 4;
	add.s64 	%rd87, %rd1, %rd86;
	ld.local.u32 	%r188, [%rd87];
	shr.u32 	%r189, %r188, %r185;
	shl.b32 	%r190, %r348, %r44;
	add.s32 	%r348, %r189, %r190;

$L__BB2_58:
	and.b32  	%r191, %r35, -2147483648;
	shr.u32 	%r192, %r348, 30;
	shl.b32 	%r193, %r347, 2;
	or.b32  	%r194, %r192, %r193;
	shr.u32 	%r195, %r194, 31;
	shr.u32 	%r196, %r347, 30;
	add.s32 	%r197, %r195, %r196;
	neg.s32 	%r198, %r197;
	setp.eq.s32 	%p48, %r191, 0;
	selp.b32 	%r349, %r197, %r198, %p48;
	setp.ne.s32 	%p49, %r195, 0;
	xor.b32  	%r199, %r191, -2147483648;
	selp.b32 	%r200, %r199, %r191, %p49;
	selp.b32 	%r201, -1, 0, %p49;
	xor.b32  	%r202, %r194, %r201;
	shl.b32 	%r203, %r348, 2;
	xor.b32  	%r204, %r203, %r201;
	cvt.u64.u32 	%rd88, %r202;
	cvt.u64.u32 	%rd89, %r204;
	bfi.b64 	%rd90, %rd88, %rd89, 32, 32;
	cvt.rn.f64.s64 	%fd272, %rd90;
	mul.rn.f64 	%fd273, %fd272, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f81, %fd273;
	setp.eq.s32 	%p50, %r200, 0;
	neg.f32 	%f82, %f81;
	selp.f32 	%f154, %f81, %f82, %p50;

$L__BB2_60:
	cvt.rn.f32.f64 	%f85, %fd28;
	cvt.f64.f32 	%fd69, %f85;
	and.b32  	%r51, %r349, 1;
	setp.eq.s32 	%p51, %r51, 0;
	selp.f32 	%f24, %f154, 0f3F800000, %p51;
	mul.rn.f32 	%f25, %f154, %f154;
	mov.f32 	%f155, 0fB94D4153;
	@%p51 bra 	$L__BB2_62;

	mov.f32 	%f86, 0fBAB607ED;
	mov.f32 	%f87, 0f37CBAC00;
	fma.rn.f32 	%f155, %f87, %f25, %f86;

$L__BB2_62:
	selp.f32 	%f88, 0f3C0885E4, 0f3D2AAABB, %p51;
	fma.rn.f32 	%f89, %f155, %f25, %f88;
	selp.f32 	%f90, 0fBE2AAAA8, 0fBEFFFFFF, %p51;
	fma.rn.f32 	%f91, %f89, %f25, %f90;
	mov.f32 	%f92, 0f00000000;
	fma.rn.f32 	%f93, %f25, %f24, %f92;
	fma.rn.f32 	%f156, %f91, %f93, %f24;
	and.b32  	%r206, %r349, 2;
	setp.eq.s32 	%p53, %r206, 0;
	@%p53 bra 	$L__BB2_64;

	mov.f32 	%f95, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f95, %f92;

$L__BB2_64:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd70;
	}
	and.b32  	%r209, %r208, 2147483647;
	setp.eq.s32 	%p54, %r209, 2146435072;
	setp.eq.s32 	%p55, %r207, 0;
	and.pred  	%p56, %p55, %p54;
	@%p56 bra 	$L__BB2_67;
	bra.uni 	$L__BB2_65;

$L__BB2_67:
	mov.f64 	%fd283, 0d0000000000000000;
	mul.rn.f64 	%fd430, %fd70, %fd283;
	mov.u32 	%r350, 0;
	bra.uni 	$L__BB2_68;

$L__BB2_65:
	mul.rn.f64 	%fd274, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r350, %fd274;
	st.local.u32 	[%rd1], %r350;
	cvt.rn.f64.s32 	%fd275, %r350;
	neg.f64 	%fd276, %fd275;
	mov.f64 	%fd277, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd278, %fd276, %fd277, %fd70;
	mov.f64 	%fd279, 0d3C91A62633145C00;
	fma.rn.f64 	%fd280, %fd276, %fd279, %fd278;
	mov.f64 	%fd281, 0d397B839A252049C0;
	fma.rn.f64 	%fd430, %fd276, %fd281, %fd280;
	abs.f64 	%fd282, %fd70;
	setp.ltu.f64 	%p57, %fd282, 0d41E0000000000000;
	@%p57 bra 	$L__BB2_68;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 9, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd430, [retval0+0];
	} // callseq 9
	ld.local.u32 	%r350, [%rd1];

$L__BB2_68:
	and.b32  	%r211, %r350, 1;
	shl.b32 	%r212, %r350, 3;
	and.b32  	%r213, %r212, 8;
	setp.eq.s32 	%p58, %r211, 0;
	selp.f64 	%fd284, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p58;
	mul.wide.s32 	%rd92, %r213, 8;
	add.s64 	%rd94, %rd53, %rd92;
	ld.global.nc.f64 	%fd285, [%rd94+8];
	mul.rn.f64 	%fd75, %fd430, %fd430;
	fma.rn.f64 	%fd286, %fd284, %fd75, %fd285;
	ld.global.nc.f64 	%fd287, [%rd94+16];
	fma.rn.f64 	%fd288, %fd286, %fd75, %fd287;
	ld.global.nc.f64 	%fd289, [%rd94+24];
	fma.rn.f64 	%fd290, %fd288, %fd75, %fd289;
	ld.global.nc.f64 	%fd291, [%rd94+32];
	fma.rn.f64 	%fd292, %fd290, %fd75, %fd291;
	ld.global.nc.f64 	%fd293, [%rd94+40];
	fma.rn.f64 	%fd294, %fd292, %fd75, %fd293;
	ld.global.nc.f64 	%fd295, [%rd94+48];
	fma.rn.f64 	%fd76, %fd294, %fd75, %fd295;
	fma.rn.f64 	%fd432, %fd76, %fd430, %fd430;
	@%p58 bra 	$L__BB2_70;

	mov.f64 	%fd296, 0d3FF0000000000000;
	fma.rn.f64 	%fd432, %fd76, %fd75, %fd296;

$L__BB2_70:
	and.b32  	%r214, %r350, 2;
	setp.eq.s32 	%p59, %r214, 0;
	@%p59 bra 	$L__BB2_72;

	mov.f64 	%fd297, 0d0000000000000000;
	mov.f64 	%fd298, 0dBFF0000000000000;
	fma.rn.f64 	%fd432, %fd432, %fd298, %fd297;

$L__BB2_72:
	mul.rn.f64 	%fd299, %fd432, 0d4044000000000000;
	cvt.f64.f32 	%fd300, %f156;
	mul.rn.f64 	%fd301, %fd300, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd301, %fd299;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r216}, %fd83;
	}
	and.b32  	%r217, %r216, 2147483647;
	setp.eq.s32 	%p60, %r217, 2146435072;
	setp.eq.s32 	%p61, %r215, 0;
	and.pred  	%p62, %p61, %p60;
	@%p62 bra 	$L__BB2_75;
	bra.uni 	$L__BB2_73;

$L__BB2_75:
	mov.f64 	%fd311, 0d0000000000000000;
	mul.rn.f64 	%fd433, %fd83, %fd311;
	mov.u32 	%r351, 0;
	bra.uni 	$L__BB2_76;

$L__BB2_73:
	mul.rn.f64 	%fd302, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r351, %fd302;
	st.local.u32 	[%rd1], %r351;
	cvt.rn.f64.s32 	%fd303, %r351;
	neg.f64 	%fd304, %fd303;
	mov.f64 	%fd305, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd306, %fd304, %fd305, %fd83;
	mov.f64 	%fd307, 0d3C91A62633145C00;
	fma.rn.f64 	%fd308, %fd304, %fd307, %fd306;
	mov.f64 	%fd309, 0d397B839A252049C0;
	fma.rn.f64 	%fd433, %fd304, %fd309, %fd308;
	abs.f64 	%fd310, %fd83;
	setp.ltu.f64 	%p63, %fd310, 0d41E0000000000000;
	@%p63 bra 	$L__BB2_76;

	add.u64 	%rd138, %SP, 0;
	{ // callseq 10, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd138;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd433, [retval0+0];
	} // callseq 10
	ld.local.u32 	%r351, [%rd1];

$L__BB2_76:
	and.b32  	%r219, %r351, 1;
	shl.b32 	%r220, %r351, 3;
	and.b32  	%r221, %r220, 8;
	setp.eq.s32 	%p64, %r219, 0;
	selp.f64 	%fd312, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p64;
	mul.wide.s32 	%rd96, %r221, 8;
	add.s64 	%rd98, %rd53, %rd96;
	ld.global.nc.f64 	%fd313, [%rd98+8];
	mul.rn.f64 	%fd88, %fd433, %fd433;
	fma.rn.f64 	%fd314, %fd312, %fd88, %fd313;
	ld.global.nc.f64 	%fd315, [%rd98+16];
	fma.rn.f64 	%fd316, %fd314, %fd88, %fd315;
	ld.global.nc.f64 	%fd317, [%rd98+24];
	fma.rn.f64 	%fd318, %fd316, %fd88, %fd317;
	ld.global.nc.f64 	%fd319, [%rd98+32];
	fma.rn.f64 	%fd320, %fd318, %fd88, %fd319;
	ld.global.nc.f64 	%fd321, [%rd98+40];
	fma.rn.f64 	%fd322, %fd320, %fd88, %fd321;
	ld.global.nc.f64 	%fd323, [%rd98+48];
	fma.rn.f64 	%fd89, %fd322, %fd88, %fd323;
	fma.rn.f64 	%fd435, %fd89, %fd433, %fd433;
	@%p64 bra 	$L__BB2_78;

	mov.f64 	%fd324, 0d3FF0000000000000;
	fma.rn.f64 	%fd435, %fd89, %fd88, %fd324;

$L__BB2_78:
	and.b32  	%r222, %r351, 2;
	setp.eq.s32 	%p65, %r222, 0;
	@%p65 bra 	$L__BB2_80;

	mov.f64 	%fd325, 0d0000000000000000;
	mov.f64 	%fd326, 0dBFF0000000000000;
	fma.rn.f64 	%fd435, %fd435, %fd326, %fd325;

$L__BB2_80:
	mul.rn.f64 	%fd327, %fd435, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd327;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r223, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd96;
	}
	and.b32  	%r225, %r224, 2147483647;
	setp.eq.s32 	%p66, %r225, 2146435072;
	setp.eq.s32 	%p67, %r223, 0;
	and.pred  	%p68, %p67, %p66;
	@%p68 bra 	$L__BB2_83;
	bra.uni 	$L__BB2_81;

$L__BB2_83:
	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd436, %fd96, %fd337;
	mov.u32 	%r352, 0;
	bra.uni 	$L__BB2_84;

$L__BB2_81:
	mul.rn.f64 	%fd328, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r352, %fd328;
	st.local.u32 	[%rd1], %r352;
	cvt.rn.f64.s32 	%fd329, %r352;
	neg.f64 	%fd330, %fd329;
	mov.f64 	%fd331, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd332, %fd330, %fd331, %fd96;
	mov.f64 	%fd333, 0d3C91A62633145C00;
	fma.rn.f64 	%fd334, %fd330, %fd333, %fd332;
	mov.f64 	%fd335, 0d397B839A252049C0;
	fma.rn.f64 	%fd436, %fd330, %fd335, %fd334;
	abs.f64 	%fd336, %fd96;
	setp.ltu.f64 	%p69, %fd336, 0d41E0000000000000;
	@%p69 bra 	$L__BB2_84;

	add.u64 	%rd139, %SP, 0;
	{ // callseq 11, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd139;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd436, [retval0+0];
	} // callseq 11
	ld.local.u32 	%r352, [%rd1];

$L__BB2_84:
	and.b32  	%r227, %r352, 1;
	shl.b32 	%r228, %r352, 3;
	and.b32  	%r229, %r228, 8;
	setp.eq.s32 	%p70, %r227, 0;
	selp.f64 	%fd338, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p70;
	mul.wide.s32 	%rd100, %r229, 8;
	add.s64 	%rd102, %rd53, %rd100;
	ld.global.nc.f64 	%fd339, [%rd102+8];
	mul.rn.f64 	%fd101, %fd436, %fd436;
	fma.rn.f64 	%fd340, %fd338, %fd101, %fd339;
	ld.global.nc.f64 	%fd341, [%rd102+16];
	fma.rn.f64 	%fd342, %fd340, %fd101, %fd341;
	ld.global.nc.f64 	%fd343, [%rd102+24];
	fma.rn.f64 	%fd344, %fd342, %fd101, %fd343;
	ld.global.nc.f64 	%fd345, [%rd102+32];
	fma.rn.f64 	%fd346, %fd344, %fd101, %fd345;
	ld.global.nc.f64 	%fd347, [%rd102+40];
	fma.rn.f64 	%fd348, %fd346, %fd101, %fd347;
	ld.global.nc.f64 	%fd349, [%rd102+48];
	fma.rn.f64 	%fd102, %fd348, %fd101, %fd349;
	fma.rn.f64 	%fd438, %fd102, %fd436, %fd436;
	@%p70 bra 	$L__BB2_86;

	mov.f64 	%fd350, 0d3FF0000000000000;
	fma.rn.f64 	%fd438, %fd102, %fd101, %fd350;

$L__BB2_86:
	and.b32  	%r230, %r352, 2;
	setp.eq.s32 	%p71, %r230, 0;
	@%p71 bra 	$L__BB2_88;

	mov.f64 	%fd351, 0d0000000000000000;
	mov.f64 	%fd352, 0dBFF0000000000000;
	fma.rn.f64 	%fd438, %fd438, %fd352, %fd351;

$L__BB2_88:
	mul.rn.f64 	%fd353, %fd438, 0d4072C00000000000;
	add.rn.f64 	%fd354, %fd95, %fd353;
	add.rn.f64 	%fd108, %fd354, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd355, %fd1, %fd1;
	mov.f64 	%fd356, 0d4000000000000000;
	add.rn.f64 	%fd357, %fd355, 0dC059000000000000;
	mul.rn.f64 	%fd358, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd357, %fd358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd356;
	}
	and.b32  	%r62, %r61, 2146435072;
	setp.eq.s32 	%p72, %r62, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 12, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd441, [retval0+0];
	} // callseq 12
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd2;
	}
	setp.lt.s32 	%p73, %r63, 0;
	and.pred  	%p1, %p73, %p72;
	not.pred 	%p74, %p1;
	@%p74 bra 	$L__BB2_90;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r231}, %fd441;
	}
	xor.b32  	%r232, %r231, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd441;
	}
	mov.b64 	%fd441, {%r233, %r232};

$L__BB2_90:
	setp.eq.f32 	%p75, %f4, 0f00000000;
	@%p75 bra 	$L__BB2_94;
	bra.uni 	$L__BB2_91;

$L__BB2_94:
	selp.b32 	%r234, %r63, 0, %p72;
	mov.u32 	%r235, 0;
	or.b32  	%r236, %r234, 2146435072;
	setp.lt.s32 	%p79, %r61, 0;
	selp.b32 	%r237, %r236, %r234, %p79;
	mov.b64 	%fd441, {%r235, %r237};
	bra.uni 	$L__BB2_95;

$L__BB2_91:
	setp.gt.s32 	%p76, %r63, -1;
	@%p76 bra 	$L__BB2_95;

	mov.f64 	%fd359, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd360, %fd359;
	setp.eq.f64 	%p77, %fd360, 0d4000000000000000;
	@%p77 bra 	$L__BB2_95;

	mov.f64 	%fd441, 0dFFF8000000000000;

$L__BB2_95:
	add.rn.f64 	%fd362, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r238}, %fd362;
	}
	and.b32  	%r239, %r238, 2146435072;
	setp.ne.s32 	%p80, %r239, 2146435072;
	@%p80 bra 	$L__BB2_102;

	setp.gtu.f64 	%p81, %fd111, 0d7FF0000000000000;
	@%p81 bra 	$L__BB2_101;
	bra.uni 	$L__BB2_97;

$L__BB2_101:
	mov.f64 	%fd364, 0d4000000000000000;
	add.rn.f64 	%fd441, %fd2, %fd364;
	bra.uni 	$L__BB2_102;

$L__BB2_97:
	mov.f64 	%fd363, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r240, %temp}, %fd363;
	}
	and.b32  	%r64, %r61, 2147483647;
	setp.eq.s32 	%p82, %r64, 2146435072;
	setp.eq.s32 	%p83, %r240, 0;
	and.pred  	%p84, %p82, %p83;
	@%p84 bra 	$L__BB2_100;
	bra.uni 	$L__BB2_98;

$L__BB2_100:
	setp.gt.f64 	%p91, %fd111, 0d3FF0000000000000;
	selp.b32 	%r247, 2146435072, 0, %p91;
	mov.u32 	%r248, 0;
	xor.b32  	%r249, %r247, 2146435072;
	setp.lt.s32 	%p92, %r61, 0;
	selp.b32 	%r250, %r249, %r247, %p92;
	setp.eq.f32 	%p93, %f4, 0fBF800000;
	selp.b32 	%r251, 1072693248, %r250, %p93;
	mov.b64 	%fd441, {%r248, %r251};
	bra.uni 	$L__BB2_102;

$L__BB2_98:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd2;
	}
	and.b32  	%r242, %r63, 2147483647;
	setp.ne.s32 	%p85, %r242, 2146435072;
	setp.ne.s32 	%p86, %r241, 0;
	or.pred  	%p87, %p85, %p86;
	@%p87 bra 	$L__BB2_102;

	setp.gt.s32 	%p88, %r61, -1;
	selp.b32 	%r243, 2146435072, 0, %p88;
	mov.u32 	%r244, 0;
	setp.ne.s32 	%p89, %r64, 1071644672;
	and.pred  	%p90, %p89, %p1;
	or.b32  	%r245, %r243, -2147483648;
	selp.b32 	%r246, %r245, %r243, %p90;
	mov.b64 	%fd441, {%r244, %r246};

$L__BB2_102:
	mul.rn.f64 	%fd365, %fd441, 0d3FC999999999999A;
	setp.eq.f32 	%p94, %f4, 0f3F800000;
	selp.f64 	%fd366, 0d3FC999999999999A, %fd365, %p94;
	add.rn.f64 	%fd367, %fd110, %fd366;
	mul.rn.f32 	%f96, %f2, %f4;
	cvt.f64.f32 	%fd368, %f96;
	mul.rn.f64 	%fd121, %fd368, 0d3FB999999999999A;
	add.rn.f64 	%fd369, %fd121, %fd367;
	abs.f32 	%f97, %f2;
	sqrt.rn.f32 	%f98, %f97;
	cvt.f64.f32 	%fd122, %f98;
	mul.rn.f64 	%fd370, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd371, %fd370, %fd369;
	cvt.rn.f32.f64 	%f99, %fd109;
	cvt.f64.f32 	%fd372, %f99;
	mul.rn.f64 	%fd373, %fd372, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f100, %fd373;
	cvt.f64.f32 	%fd374, %f100;
	add.rn.f64 	%fd123, %fd371, %fd374;
	add.rn.f64 	%fd375, %fd2, %fd2;
	add.rn.f64 	%fd376, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd376, %fd375;
	abs.f64 	%fd125, %fd1;
	{ // callseq 13, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 13
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd1;
	}
	setp.lt.s32 	%p95, %r65, 0;
	and.pred  	%p2, %p95, %p72;
	not.pred 	%p97, %p2;
	@%p97 bra 	$L__BB2_104;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r252}, %fd444;
	}
	xor.b32  	%r253, %r252, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r254, %temp}, %fd444;
	}
	mov.b64 	%fd444, {%r254, %r253};

$L__BB2_104:
	setp.eq.f32 	%p98, %f2, 0f00000000;
	@%p98 bra 	$L__BB2_108;
	bra.uni 	$L__BB2_105;

$L__BB2_108:
	selp.b32 	%r255, %r65, 0, %p72;
	mov.u32 	%r256, 0;
	or.b32  	%r257, %r255, 2146435072;
	setp.lt.s32 	%p102, %r61, 0;
	selp.b32 	%r258, %r257, %r255, %p102;
	mov.b64 	%fd444, {%r256, %r258};
	bra.uni 	$L__BB2_109;

$L__BB2_105:
	setp.gt.s32 	%p99, %r65, -1;
	@%p99 bra 	$L__BB2_109;

	mov.f64 	%fd377, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd378, %fd377;
	setp.eq.f64 	%p100, %fd378, 0d4000000000000000;
	@%p100 bra 	$L__BB2_109;

	mov.f64 	%fd444, 0dFFF8000000000000;

$L__BB2_109:
	add.rn.f64 	%fd380, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd380;
	}
	and.b32  	%r260, %r259, 2146435072;
	setp.ne.s32 	%p103, %r260, 2146435072;
	@%p103 bra 	$L__BB2_116;

	setp.gtu.f64 	%p104, %fd125, 0d7FF0000000000000;
	@%p104 bra 	$L__BB2_115;
	bra.uni 	$L__BB2_111;

$L__BB2_115:
	mov.f64 	%fd382, 0d4000000000000000;
	add.rn.f64 	%fd444, %fd1, %fd382;
	bra.uni 	$L__BB2_116;

$L__BB2_111:
	mov.f64 	%fd381, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r261, %temp}, %fd381;
	}
	and.b32  	%r66, %r61, 2147483647;
	setp.eq.s32 	%p105, %r66, 2146435072;
	setp.eq.s32 	%p106, %r261, 0;
	and.pred  	%p107, %p105, %p106;
	@%p107 bra 	$L__BB2_114;
	bra.uni 	$L__BB2_112;

$L__BB2_114:
	setp.gt.f64 	%p114, %fd125, 0d3FF0000000000000;
	selp.b32 	%r268, 2146435072, 0, %p114;
	mov.u32 	%r269, 0;
	xor.b32  	%r270, %r268, 2146435072;
	setp.lt.s32 	%p115, %r61, 0;
	selp.b32 	%r271, %r270, %r268, %p115;
	setp.eq.f32 	%p116, %f2, 0fBF800000;
	selp.b32 	%r272, 1072693248, %r271, %p116;
	mov.b64 	%fd444, {%r269, %r272};
	bra.uni 	$L__BB2_116;

$L__BB2_112:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd1;
	}
	and.b32  	%r263, %r65, 2147483647;
	setp.ne.s32 	%p108, %r263, 2146435072;
	setp.ne.s32 	%p109, %r262, 0;
	or.pred  	%p110, %p108, %p109;
	@%p110 bra 	$L__BB2_116;

	setp.gt.s32 	%p111, %r61, -1;
	selp.b32 	%r264, 2146435072, 0, %p111;
	mov.u32 	%r265, 0;
	setp.ne.s32 	%p112, %r66, 1071644672;
	and.pred  	%p113, %p112, %p2;
	or.b32  	%r266, %r264, -2147483648;
	selp.b32 	%r267, %r266, %r264, %p113;
	mov.b64 	%fd444, {%r265, %r267};

$L__BB2_116:
	mul.rn.f64 	%fd383, %fd444, 0d3FB999999999999A;
	setp.eq.f32 	%p117, %f2, 0f3F800000;
	selp.f64 	%fd384, 0d3FB999999999999A, %fd383, %p117;
	add.rn.f64 	%fd385, %fd124, %fd384;
	add.rn.f64 	%fd386, %fd121, %fd385;
	mul.rn.f64 	%fd387, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd388, %fd387, %fd386;
	cvt.rn.f32.f64 	%f101, %fd108;
	cvt.f64.f32 	%fd389, %f101;
	mul.rn.f64 	%fd390, %fd389, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f102, %fd390;
	cvt.f64.f32 	%fd391, %f102;
	add.rn.f64 	%fd135, %fd388, %fd391;
	cvt.f64.f32 	%fd392, %f3;
	div.rn.f64 	%fd393, %fd392, 0d4066800000000000;
	mul.rn.f64 	%fd394, %fd393, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd394;
	mul.rn.f32 	%f103, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r360, %f103;
	cvt.rn.f32.s32 	%f104, %r360;
	mov.f32 	%f105, 0fBFC90FDA;
	fma.rn.f32 	%f106, %f104, %f105, %f31;
	mov.f32 	%f107, 0fB3A22168;
	fma.rn.f32 	%f108, %f104, %f107, %f106;
	mov.f32 	%f109, 0fA7C234C5;
	fma.rn.f32 	%f160, %f104, %f109, %f108;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p118, %f33, 0f47CE4780;
	mov.u32 	%r356, %r360;
	mov.f32 	%f157, %f160;
	@%p118 bra 	$L__BB2_124;

	setp.eq.f32 	%p119, %f33, 0f7F800000;
	@%p119 bra 	$L__BB2_123;
	bra.uni 	$L__BB2_118;

$L__BB2_123:
	mov.f32 	%f112, 0f00000000;
	mul.rn.f32 	%f157, %f31, %f112;
	mov.u32 	%r356, 0;
	bra.uni 	$L__BB2_124;

$L__BB2_118:
	mov.b32 	%r68, %f31;
	bfe.u32 	%r274, %r68, 23, 8;
	add.s32 	%r69, %r274, -128;
	shl.b32 	%r275, %r68, 8;
	or.b32  	%r70, %r275, -2147483648;
	shr.u32 	%r71, %r69, 5;
	mov.u64 	%rd148, 0;
	mov.u32 	%r353, 0;
	mov.u64 	%rd147, __cudart_i2opi_f;
	mov.u64 	%rd146, %rd1;

$L__BB2_119:
	.pragma "nounroll";
	ld.global.nc.u32 	%r276, [%rd147];
	mad.wide.u32 	%rd105, %r276, %r70, %rd148;
	shr.u64 	%rd148, %rd105, 32;
	st.local.u32 	[%rd146], %rd105;
	add.s64 	%rd147, %rd147, 4;
	add.s64 	%rd146, %rd146, 4;
	add.s32 	%r353, %r353, 1;
	setp.ne.s32 	%p120, %r353, 6;
	@%p120 bra 	$L__BB2_119;

	st.local.u32 	[%rd12], %rd148;
	mov.u32 	%r277, 4;
	sub.s32 	%r74, %r277, %r71;
	mov.u32 	%r278, 6;
	sub.s32 	%r279, %r278, %r71;
	mul.wide.s32 	%rd106, %r279, 4;
	add.s64 	%rd107, %rd1, %rd106;
	ld.local.u32 	%r354, [%rd107];
	ld.local.u32 	%r355, [%rd107+-4];
	and.b32  	%r77, %r69, 31;
	setp.eq.s32 	%p121, %r77, 0;
	@%p121 bra 	$L__BB2_122;

	mov.u32 	%r280, 32;
	sub.s32 	%r281, %r280, %r77;
	shr.u32 	%r282, %r355, %r281;
	shl.b32 	%r283, %r354, %r77;
	add.s32 	%r354, %r282, %r283;
	mul.wide.s32 	%rd108, %r74, 4;
	add.s64 	%rd109, %rd1, %rd108;
	ld.local.u32 	%r284, [%rd109];
	shr.u32 	%r285, %r284, %r281;
	shl.b32 	%r286, %r355, %r77;
	add.s32 	%r355, %r285, %r286;

$L__BB2_122:
	and.b32  	%r287, %r68, -2147483648;
	shr.u32 	%r288, %r355, 30;
	shl.b32 	%r289, %r354, 2;
	or.b32  	%r290, %r288, %r289;
	shr.u32 	%r291, %r290, 31;
	shr.u32 	%r292, %r354, 30;
	add.s32 	%r293, %r291, %r292;
	neg.s32 	%r294, %r293;
	setp.eq.s32 	%p122, %r287, 0;
	selp.b32 	%r356, %r293, %r294, %p122;
	setp.ne.s32 	%p123, %r291, 0;
	xor.b32  	%r295, %r287, -2147483648;
	selp.b32 	%r296, %r295, %r287, %p123;
	selp.b32 	%r297, -1, 0, %p123;
	xor.b32  	%r298, %r290, %r297;
	shl.b32 	%r299, %r355, 2;
	xor.b32  	%r300, %r299, %r297;
	cvt.u64.u32 	%rd110, %r298;
	cvt.u64.u32 	%rd111, %r300;
	bfi.b64 	%rd112, %rd110, %rd111, 32, 32;
	cvt.rn.f64.s64 	%fd395, %rd112;
	mul.rn.f64 	%fd396, %fd395, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd396;
	setp.eq.s32 	%p124, %r296, 0;
	neg.f32 	%f111, %f110;
	selp.f32 	%f157, %f110, %f111, %p124;

$L__BB2_124:
	and.b32  	%r84, %r356, 1;
	setp.eq.s32 	%p125, %r84, 0;
	selp.f32 	%f37, %f157, 0f3F800000, %p125;
	mul.rn.f32 	%f38, %f157, %f157;
	mov.f32 	%f158, 0fB94D4153;
	@%p125 bra 	$L__BB2_126;

	mov.f32 	%f114, 0fBAB607ED;
	mov.f32 	%f115, 0f37CBAC00;
	fma.rn.f32 	%f158, %f115, %f38, %f114;

$L__BB2_126:
	selp.f32 	%f116, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f117, %f158, %f38, %f116;
	selp.f32 	%f118, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f119, %f117, %f38, %f118;
	mov.f32 	%f120, 0f00000000;
	fma.rn.f32 	%f121, %f38, %f37, %f120;
	fma.rn.f32 	%f159, %f119, %f121, %f37;
	and.b32  	%r302, %r356, 2;
	setp.eq.s32 	%p127, %r302, 0;
	@%p127 bra 	$L__BB2_128;

	mov.f32 	%f123, 0fBF800000;
	fma.rn.f32 	%f159, %f159, %f123, %f120;

$L__BB2_128:
	@%p118 bra 	$L__BB2_136;

	setp.eq.f32 	%p129, %f33, 0f7F800000;
	@%p129 bra 	$L__BB2_135;
	bra.uni 	$L__BB2_130;

$L__BB2_135:
	mov.f32 	%f126, 0f00000000;
	mul.rn.f32 	%f160, %f31, %f126;
	mov.u32 	%r360, 0;
	bra.uni 	$L__BB2_136;

$L__BB2_130:
	mov.b32 	%r85, %f31;
	bfe.u32 	%r304, %r85, 23, 8;
	add.s32 	%r86, %r304, -128;
	shl.b32 	%r305, %r85, 8;
	or.b32  	%r87, %r305, -2147483648;
	shr.u32 	%r88, %r86, 5;
	mov.u64 	%rd151, 0;
	mov.u32 	%r357, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
	mov.u64 	%rd149, %rd1;

$L__BB2_131:
	.pragma "nounroll";
	ld.global.nc.u32 	%r306, [%rd150];
	mad.wide.u32 	%rd115, %r306, %r87, %rd151;
	shr.u64 	%rd151, %rd115, 32;
	st.local.u32 	[%rd149], %rd115;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r357, %r357, 1;
	setp.ne.s32 	%p130, %r357, 6;
	@%p130 bra 	$L__BB2_131;

	st.local.u32 	[%rd12], %rd151;
	mov.u32 	%r307, 4;
	sub.s32 	%r91, %r307, %r88;
	mov.u32 	%r308, 6;
	sub.s32 	%r309, %r308, %r88;
	mul.wide.s32 	%rd116, %r309, 4;
	add.s64 	%rd117, %rd1, %rd116;
	ld.local.u32 	%r358, [%rd117];
	ld.local.u32 	%r359, [%rd117+-4];
	and.b32  	%r94, %r86, 31;
	setp.eq.s32 	%p131, %r94, 0;
	@%p131 bra 	$L__BB2_134;

	mov.u32 	%r310, 32;
	sub.s32 	%r311, %r310, %r94;
	shr.u32 	%r312, %r359, %r311;
	shl.b32 	%r313, %r358, %r94;
	add.s32 	%r358, %r312, %r313;
	mul.wide.s32 	%rd118, %r91, 4;
	add.s64 	%rd119, %rd1, %rd118;
	ld.local.u32 	%r314, [%rd119];
	shr.u32 	%r315, %r314, %r311;
	shl.b32 	%r316, %r359, %r94;
	add.s32 	%r359, %r315, %r316;

$L__BB2_134:
	and.b32  	%r317, %r85, -2147483648;
	shr.u32 	%r318, %r359, 30;
	shl.b32 	%r319, %r358, 2;
	or.b32  	%r320, %r318, %r319;
	shr.u32 	%r321, %r320, 31;
	shr.u32 	%r322, %r358, 30;
	add.s32 	%r323, %r321, %r322;
	neg.s32 	%r324, %r323;
	setp.eq.s32 	%p132, %r317, 0;
	selp.b32 	%r360, %r323, %r324, %p132;
	setp.ne.s32 	%p133, %r321, 0;
	xor.b32  	%r325, %r317, -2147483648;
	selp.b32 	%r326, %r325, %r317, %p133;
	selp.b32 	%r327, -1, 0, %p133;
	xor.b32  	%r328, %r320, %r327;
	shl.b32 	%r329, %r359, 2;
	xor.b32  	%r330, %r329, %r327;
	cvt.u64.u32 	%rd120, %r328;
	cvt.u64.u32 	%rd121, %r330;
	bfi.b64 	%rd122, %rd120, %rd121, 32, 32;
	cvt.rn.f64.s64 	%fd397, %rd122;
	mul.rn.f64 	%fd398, %fd397, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd398;
	setp.eq.s32 	%p134, %r326, 0;
	neg.f32 	%f125, %f124;
	selp.f32 	%f160, %f124, %f125, %p134;

$L__BB2_136:
	add.s32 	%r101, %r360, 1;
	and.b32  	%r102, %r101, 1;
	setp.eq.s32 	%p3, %r102, 0;
	mul.rn.f32 	%f47, %f160, %f160;
	mov.f32 	%f161, 0fB94D4153;
	@%p3 bra 	$L__BB2_138;

	mov.f32 	%f128, 0fBAB607ED;
	mov.f32 	%f129, 0f37CBAC00;
	fma.rn.f32 	%f161, %f129, %f47, %f128;

$L__BB2_138:
	selp.f32 	%f130, %f160, 0f3F800000, %p3;
	selp.f32 	%f131, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f132, %f161, %f47, %f131;
	selp.f32 	%f133, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f134, %f132, %f47, %f133;
	mov.f32 	%f135, 0f00000000;
	fma.rn.f32 	%f136, %f47, %f130, %f135;
	fma.rn.f32 	%f162, %f134, %f136, %f130;
	and.b32  	%r332, %r101, 2;
	setp.eq.s32 	%p136, %r332, 0;
	@%p136 bra 	$L__BB2_140;

	mov.f32 	%f138, 0fBF800000;
	fma.rn.f32 	%f162, %f162, %f138, %f135;

$L__BB2_140:
	mov.u32 	%r336, %tid.x;
	mov.u32 	%r335, %ntid.x;
	mov.u32 	%r334, %ctaid.x;
	mad.lo.s32 	%r333, %r334, %r335, %r336;
	mul.wide.s32 	%rd129, %r333, 4;
	ld.param.u64 	%rd128, [gcj02_to_wgs84_cuda_float_param_1];
	cvta.to.global.u64 	%rd127, %rd128;
	add.s64 	%rd126, %rd127, %rd129;
	ld.param.u64 	%rd125, [gcj02_to_wgs84_cuda_float_param_0];
	cvta.to.global.u64 	%rd124, %rd125;
	add.s64 	%rd123, %rd124, %rd129;
	cvt.f64.f32 	%fd399, %f159;
	mul.rn.f64 	%fd400, %fd399, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd401, %fd400, %fd399;
	add.rn.f64 	%fd402, %fd401, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f139, %fd402;
	sqrt.rn.f32 	%f140, %f139;
	mov.f32 	%f141, 0fCAC2A60A;
	div.rn.f32 	%f142, %f141, %f140;
	mul.rn.f32 	%f143, %f142, %f162;
	cvt.f64.f32 	%fd403, %f143;
	mul.rn.f64 	%fd404, %fd403, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f144, %fd135;
	cvt.f64.f32 	%fd405, %f144;
	mul.rn.f64 	%fd406, %fd405, 0d4066800000000000;
	div.rn.f64 	%fd407, %fd406, %fd404;
	cvt.rn.f32.f64 	%f145, %fd407;
	add.rn.f32 	%f146, %f1, %f145;
	st.global.f32 	[%rd123], %f146;
	mul.rn.f32 	%f147, %f140, %f139;
	cvt.f64.f32 	%fd408, %f147;
	mov.f64 	%fd409, 0dC1582B102DE355C1;
	div.rn.f64 	%fd410, %fd409, %fd408;
	mul.rn.f64 	%fd411, %fd410, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f148, %fd123;
	cvt.f64.f32 	%fd412, %f148;
	mul.rn.f64 	%fd413, %fd412, 0d4066800000000000;
	div.rn.f64 	%fd414, %fd413, %fd411;
	cvt.rn.f32.f64 	%f149, %fd414;
	add.rn.f32 	%f150, %f3, %f149;
	st.global.f32 	[%rd126], %f150;
	ret;

}
	// .globl	wgs84_to_gcj02_cuda_float
.visible .entry wgs84_to_gcj02_cuda_float(
	.param .u64 wgs84_to_gcj02_cuda_float_param_0,
	.param .u64 wgs84_to_gcj02_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot3[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<137>;
	.reg .f32 	%f<163>;
	.reg .b32 	%r<361>;
	.reg .f64 	%fd<445>;
	.reg .b64 	%rd<152>;


	mov.u64 	%SPL, __local_depot3;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd37, [wgs84_to_gcj02_cuda_float_param_0];
	ld.param.u64 	%rd38, [wgs84_to_gcj02_cuda_float_param_1];
	cvta.to.global.u64 	%rd39, %rd38;
	add.u64 	%rd40, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r103, %ntid.x;
	mov.u32 	%r104, %ctaid.x;
	mov.u32 	%r105, %tid.x;
	mad.lo.s32 	%r106, %r104, %r103, %r105;
	cvta.to.global.u64 	%rd49, %rd37;
	mul.wide.s32 	%rd50, %r106, 4;
	add.s64 	%rd10, %rd49, %rd50;
	add.s64 	%rd11, %rd39, %rd50;
	ld.global.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd11];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd136, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd136;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd137, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd137;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r107, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r108}, %fd4;
	}
	and.b32  	%r109, %r108, 2147483647;
	setp.eq.s32 	%p4, %r109, 2146435072;
	setp.eq.s32 	%p5, %r107, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB3_3;
	bra.uni 	$L__BB3_1;

$L__BB3_3:
	mov.f64 	%fd147, 0d0000000000000000;
	mul.rn.f64 	%fd415, %fd4, %fd147;
	mov.u32 	%r337, 0;
	bra.uni 	$L__BB3_4;

$L__BB3_1:
	mul.rn.f64 	%fd138, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r337, %fd138;
	st.local.u32 	[%rd8], %r337;
	cvt.rn.f64.s32 	%fd139, %r337;
	neg.f64 	%fd140, %fd139;
	mov.f64 	%fd141, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd142, %fd140, %fd141, %fd4;
	mov.f64 	%fd143, 0d3C91A62633145C00;
	fma.rn.f64 	%fd144, %fd140, %fd143, %fd142;
	mov.f64 	%fd145, 0d397B839A252049C0;
	fma.rn.f64 	%fd415, %fd140, %fd145, %fd144;
	abs.f64 	%fd146, %fd4;
	setp.ltu.f64 	%p7, %fd146, 0d41E0000000000000;
	@%p7 bra 	$L__BB3_4;

	{ // callseq 14, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd415, [retval0+0];
	} // callseq 14
	ld.local.u32 	%r337, [%rd8];

$L__BB3_4:
	and.b32  	%r111, %r337, 1;
	shl.b32 	%r112, %r337, 3;
	and.b32  	%r113, %r112, 8;
	setp.eq.s32 	%p8, %r111, 0;
	selp.f64 	%fd148, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd52, %r113, 8;
	mov.u64 	%rd53, __cudart_sin_cos_coeffs;
	add.s64 	%rd54, %rd53, %rd52;
	ld.global.nc.f64 	%fd149, [%rd54+8];
	mul.rn.f64 	%fd9, %fd415, %fd415;
	fma.rn.f64 	%fd150, %fd148, %fd9, %fd149;
	ld.global.nc.f64 	%fd151, [%rd54+16];
	fma.rn.f64 	%fd152, %fd150, %fd9, %fd151;
	ld.global.nc.f64 	%fd153, [%rd54+24];
	fma.rn.f64 	%fd154, %fd152, %fd9, %fd153;
	ld.global.nc.f64 	%fd155, [%rd54+32];
	fma.rn.f64 	%fd156, %fd154, %fd9, %fd155;
	ld.global.nc.f64 	%fd157, [%rd54+40];
	fma.rn.f64 	%fd158, %fd156, %fd9, %fd157;
	ld.global.nc.f64 	%fd159, [%rd54+48];
	fma.rn.f64 	%fd10, %fd158, %fd9, %fd159;
	fma.rn.f64 	%fd417, %fd10, %fd415, %fd415;
	@%p8 bra 	$L__BB3_6;

	mov.f64 	%fd160, 0d3FF0000000000000;
	fma.rn.f64 	%fd417, %fd10, %fd9, %fd160;

$L__BB3_6:
	and.b32  	%r114, %r337, 2;
	setp.eq.s32 	%p9, %r114, 0;
	@%p9 bra 	$L__BB3_8;

	mov.f64 	%fd161, 0d0000000000000000;
	mov.f64 	%fd162, 0dBFF0000000000000;
	fma.rn.f64 	%fd417, %fd417, %fd162, %fd161;

$L__BB3_8:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r115, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r116}, %fd16;
	}
	and.b32  	%r117, %r116, 2147483647;
	setp.eq.s32 	%p10, %r117, 2146435072;
	setp.eq.s32 	%p11, %r115, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB3_11;
	bra.uni 	$L__BB3_9;

$L__BB3_11:
	mov.f64 	%fd172, 0d0000000000000000;
	mul.rn.f64 	%fd418, %fd16, %fd172;
	mov.u32 	%r338, 0;
	bra.uni 	$L__BB3_12;

$L__BB3_9:
	add.u64 	%rd130, %SPL, 0;
	mul.rn.f64 	%fd163, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd163;
	st.local.u32 	[%rd130], %r338;
	cvt.rn.f64.s32 	%fd164, %r338;
	neg.f64 	%fd165, %fd164;
	mov.f64 	%fd166, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd167, %fd165, %fd166, %fd16;
	mov.f64 	%fd168, 0d3C91A62633145C00;
	fma.rn.f64 	%fd169, %fd165, %fd168, %fd167;
	mov.f64 	%fd170, 0d397B839A252049C0;
	fma.rn.f64 	%fd418, %fd165, %fd170, %fd169;
	abs.f64 	%fd171, %fd16;
	setp.ltu.f64 	%p13, %fd171, 0d41E0000000000000;
	@%p13 bra 	$L__BB3_12;

	add.u64 	%rd133, %SP, 0;
	add.u64 	%rd132, %SPL, 0;
	{ // callseq 15, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd133;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd418, [retval0+0];
	} // callseq 15
	ld.local.u32 	%r338, [%rd132];

$L__BB3_12:
	and.b32  	%r119, %r338, 1;
	shl.b32 	%r120, %r338, 3;
	and.b32  	%r121, %r120, 8;
	setp.eq.s32 	%p14, %r119, 0;
	selp.f64 	%fd173, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd56, %r121, 8;
	add.s64 	%rd58, %rd53, %rd56;
	ld.global.nc.f64 	%fd174, [%rd58+8];
	mul.rn.f64 	%fd21, %fd418, %fd418;
	fma.rn.f64 	%fd175, %fd173, %fd21, %fd174;
	ld.global.nc.f64 	%fd176, [%rd58+16];
	fma.rn.f64 	%fd177, %fd175, %fd21, %fd176;
	ld.global.nc.f64 	%fd178, [%rd58+24];
	fma.rn.f64 	%fd179, %fd177, %fd21, %fd178;
	ld.global.nc.f64 	%fd180, [%rd58+32];
	fma.rn.f64 	%fd181, %fd179, %fd21, %fd180;
	ld.global.nc.f64 	%fd182, [%rd58+40];
	fma.rn.f64 	%fd183, %fd181, %fd21, %fd182;
	ld.global.nc.f64 	%fd184, [%rd58+48];
	fma.rn.f64 	%fd22, %fd183, %fd21, %fd184;
	fma.rn.f64 	%fd420, %fd22, %fd418, %fd418;
	@%p14 bra 	$L__BB3_14;

	mov.f64 	%fd185, 0d3FF0000000000000;
	fma.rn.f64 	%fd420, %fd22, %fd21, %fd185;

$L__BB3_14:
	and.b32  	%r122, %r338, 2;
	setp.eq.s32 	%p15, %r122, 0;
	@%p15 bra 	$L__BB3_16;

	mov.f64 	%fd186, 0d0000000000000000;
	mov.f64 	%fd187, 0dBFF0000000000000;
	fma.rn.f64 	%fd420, %fd420, %fd187, %fd186;

$L__BB3_16:
	mul.rn.f64 	%fd188, %fd420, 0d4034000000000000;
	mul.rn.f64 	%fd189, %fd417, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd189, %fd188;
	mul.rn.f32 	%f53, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r342, %f53;
	cvt.rn.f32.s32 	%f54, %r342;
	mov.f32 	%f55, 0fBFC90FDA;
	fma.rn.f32 	%f56, %f54, %f55, %f6;
	mov.f32 	%f57, 0fB3A22168;
	fma.rn.f32 	%f58, %f54, %f57, %f56;
	mov.f32 	%f59, 0fA7C234C5;
	fma.rn.f32 	%f151, %f54, %f59, %f58;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p16, %f8, 0f47CE4780;
	add.s64 	%rd12, %rd1, 24;
	@%p16 bra 	$L__BB3_24;

	setp.eq.f32 	%p17, %f8, 0f7F800000;
	@%p17 bra 	$L__BB3_23;
	bra.uni 	$L__BB3_18;

$L__BB3_23:
	mov.f32 	%f62, 0f00000000;
	mul.rn.f32 	%f151, %f6, %f62;
	mov.u32 	%r342, 0;
	bra.uni 	$L__BB3_24;

$L__BB3_18:
	mov.b32 	%r8, %f6;
	bfe.u32 	%r124, %r8, 23, 8;
	add.s32 	%r9, %r124, -128;
	shl.b32 	%r125, %r8, 8;
	or.b32  	%r10, %r125, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd142, 0;
	mov.u32 	%r339, 0;
	mov.u64 	%rd141, __cudart_i2opi_f;
	mov.u64 	%rd140, %rd1;

$L__BB3_19:
	.pragma "nounroll";
	ld.global.nc.u32 	%r126, [%rd141];
	mad.wide.u32 	%rd61, %r126, %r10, %rd142;
	shr.u64 	%rd142, %rd61, 32;
	st.local.u32 	[%rd140], %rd61;
	add.s64 	%rd141, %rd141, 4;
	add.s64 	%rd140, %rd140, 4;
	add.s32 	%r339, %r339, 1;
	setp.ne.s32 	%p18, %r339, 6;
	@%p18 bra 	$L__BB3_19;

	st.local.u32 	[%rd12], %rd142;
	mov.u32 	%r127, 4;
	sub.s32 	%r14, %r127, %r11;
	mov.u32 	%r128, 6;
	sub.s32 	%r129, %r128, %r11;
	mul.wide.s32 	%rd62, %r129, 4;
	add.s64 	%rd63, %rd1, %rd62;
	ld.local.u32 	%r340, [%rd63];
	ld.local.u32 	%r341, [%rd63+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p19, %r17, 0;
	@%p19 bra 	$L__BB3_22;

	mov.u32 	%r130, 32;
	sub.s32 	%r131, %r130, %r17;
	shr.u32 	%r132, %r341, %r131;
	shl.b32 	%r133, %r340, %r17;
	add.s32 	%r340, %r132, %r133;
	mul.wide.s32 	%rd64, %r14, 4;
	add.s64 	%rd65, %rd1, %rd64;
	ld.local.u32 	%r134, [%rd65];
	shr.u32 	%r135, %r134, %r131;
	shl.b32 	%r136, %r341, %r17;
	add.s32 	%r341, %r135, %r136;

$L__BB3_22:
	and.b32  	%r137, %r8, -2147483648;
	shr.u32 	%r138, %r341, 30;
	shl.b32 	%r139, %r340, 2;
	or.b32  	%r140, %r138, %r139;
	shr.u32 	%r141, %r140, 31;
	shr.u32 	%r142, %r340, 30;
	add.s32 	%r143, %r141, %r142;
	neg.s32 	%r144, %r143;
	setp.eq.s32 	%p20, %r137, 0;
	selp.b32 	%r342, %r143, %r144, %p20;
	setp.ne.s32 	%p21, %r141, 0;
	xor.b32  	%r145, %r137, -2147483648;
	selp.b32 	%r146, %r145, %r137, %p21;
	selp.b32 	%r147, -1, 0, %p21;
	xor.b32  	%r148, %r140, %r147;
	shl.b32 	%r149, %r341, 2;
	xor.b32  	%r150, %r149, %r147;
	cvt.u64.u32 	%rd66, %r148;
	cvt.u64.u32 	%rd67, %r150;
	bfi.b64 	%rd68, %rd66, %rd67, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd68;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f60, %fd191;
	setp.eq.s32 	%p22, %r146, 0;
	neg.f32 	%f61, %f60;
	selp.f32 	%f151, %f60, %f61, %p22;

$L__BB3_24:
	and.b32  	%r24, %r342, 1;
	setp.eq.s32 	%p23, %r24, 0;
	selp.f32 	%f12, %f151, 0f3F800000, %p23;
	mul.rn.f32 	%f13, %f151, %f151;
	mov.f32 	%f152, 0fB94D4153;
	@%p23 bra 	$L__BB3_26;

	mov.f32 	%f64, 0fBAB607ED;
	mov.f32 	%f65, 0f37CBAC00;
	fma.rn.f32 	%f152, %f65, %f13, %f64;

$L__BB3_26:
	selp.f32 	%f66, 0f3C0885E4, 0f3D2AAABB, %p23;
	fma.rn.f32 	%f67, %f152, %f13, %f66;
	selp.f32 	%f68, 0fBE2AAAA8, 0fBEFFFFFF, %p23;
	fma.rn.f32 	%f69, %f67, %f13, %f68;
	mov.f32 	%f70, 0f00000000;
	fma.rn.f32 	%f71, %f13, %f12, %f70;
	fma.rn.f32 	%f153, %f69, %f71, %f12;
	and.b32  	%r152, %r342, 2;
	setp.eq.s32 	%p25, %r152, 0;
	@%p25 bra 	$L__BB3_28;

	mov.f32 	%f73, 0fBF800000;
	fma.rn.f32 	%f153, %f153, %f73, %f70;

$L__BB3_28:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd30;
	}
	and.b32  	%r155, %r154, 2147483647;
	setp.eq.s32 	%p26, %r155, 2146435072;
	setp.eq.s32 	%p27, %r153, 0;
	and.pred  	%p28, %p27, %p26;
	@%p28 bra 	$L__BB3_31;
	bra.uni 	$L__BB3_29;

$L__BB3_31:
	mov.f64 	%fd201, 0d0000000000000000;
	mul.rn.f64 	%fd421, %fd30, %fd201;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB3_32;

$L__BB3_29:
	mul.rn.f64 	%fd192, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r343, %fd192;
	st.local.u32 	[%rd1], %r343;
	cvt.rn.f64.s32 	%fd193, %r343;
	neg.f64 	%fd194, %fd193;
	mov.f64 	%fd195, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd196, %fd194, %fd195, %fd30;
	mov.f64 	%fd197, 0d3C91A62633145C00;
	fma.rn.f64 	%fd198, %fd194, %fd197, %fd196;
	mov.f64 	%fd199, 0d397B839A252049C0;
	fma.rn.f64 	%fd421, %fd194, %fd199, %fd198;
	abs.f64 	%fd200, %fd30;
	setp.ltu.f64 	%p29, %fd200, 0d41E0000000000000;
	@%p29 bra 	$L__BB3_32;

	add.u64 	%rd134, %SP, 0;
	{ // callseq 16, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd421, [retval0+0];
	} // callseq 16
	ld.local.u32 	%r343, [%rd1];

$L__BB3_32:
	and.b32  	%r157, %r343, 1;
	shl.b32 	%r158, %r343, 3;
	and.b32  	%r159, %r158, 8;
	setp.eq.s32 	%p30, %r157, 0;
	selp.f64 	%fd202, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p30;
	mul.wide.s32 	%rd70, %r159, 8;
	add.s64 	%rd72, %rd53, %rd70;
	ld.global.nc.f64 	%fd203, [%rd72+8];
	mul.rn.f64 	%fd35, %fd421, %fd421;
	fma.rn.f64 	%fd204, %fd202, %fd35, %fd203;
	ld.global.nc.f64 	%fd205, [%rd72+16];
	fma.rn.f64 	%fd206, %fd204, %fd35, %fd205;
	ld.global.nc.f64 	%fd207, [%rd72+24];
	fma.rn.f64 	%fd208, %fd206, %fd35, %fd207;
	ld.global.nc.f64 	%fd209, [%rd72+32];
	fma.rn.f64 	%fd210, %fd208, %fd35, %fd209;
	ld.global.nc.f64 	%fd211, [%rd72+40];
	fma.rn.f64 	%fd212, %fd210, %fd35, %fd211;
	ld.global.nc.f64 	%fd213, [%rd72+48];
	fma.rn.f64 	%fd36, %fd212, %fd35, %fd213;
	fma.rn.f64 	%fd423, %fd36, %fd421, %fd421;
	@%p30 bra 	$L__BB3_34;

	mov.f64 	%fd214, 0d3FF0000000000000;
	fma.rn.f64 	%fd423, %fd36, %fd35, %fd214;

$L__BB3_34:
	and.b32  	%r160, %r343, 2;
	setp.eq.s32 	%p31, %r160, 0;
	@%p31 bra 	$L__BB3_36;

	mov.f64 	%fd215, 0d0000000000000000;
	mov.f64 	%fd216, 0dBFF0000000000000;
	fma.rn.f64 	%fd423, %fd423, %fd216, %fd215;

$L__BB3_36:
	mul.rn.f64 	%fd217, %fd423, 0d4044000000000000;
	cvt.f64.f32 	%fd218, %f153;
	mul.rn.f64 	%fd219, %fd218, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd219, %fd217;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r162}, %fd43;
	}
	and.b32  	%r163, %r162, 2147483647;
	setp.eq.s32 	%p32, %r163, 2146435072;
	setp.eq.s32 	%p33, %r161, 0;
	and.pred  	%p34, %p33, %p32;
	@%p34 bra 	$L__BB3_39;
	bra.uni 	$L__BB3_37;

$L__BB3_39:
	mov.f64 	%fd229, 0d0000000000000000;
	mul.rn.f64 	%fd424, %fd43, %fd229;
	mov.u32 	%r344, 0;
	bra.uni 	$L__BB3_40;

$L__BB3_37:
	mul.rn.f64 	%fd220, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd220;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd221, %r344;
	neg.f64 	%fd222, %fd221;
	mov.f64 	%fd223, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd224, %fd222, %fd223, %fd43;
	mov.f64 	%fd225, 0d3C91A62633145C00;
	fma.rn.f64 	%fd226, %fd222, %fd225, %fd224;
	mov.f64 	%fd227, 0d397B839A252049C0;
	fma.rn.f64 	%fd424, %fd222, %fd227, %fd226;
	abs.f64 	%fd228, %fd43;
	setp.ltu.f64 	%p35, %fd228, 0d41E0000000000000;
	@%p35 bra 	$L__BB3_40;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 17, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd424, [retval0+0];
	} // callseq 17
	ld.local.u32 	%r344, [%rd1];

$L__BB3_40:
	and.b32  	%r165, %r344, 1;
	shl.b32 	%r166, %r344, 3;
	and.b32  	%r167, %r166, 8;
	setp.eq.s32 	%p36, %r165, 0;
	selp.f64 	%fd230, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p36;
	mul.wide.s32 	%rd74, %r167, 8;
	add.s64 	%rd76, %rd53, %rd74;
	ld.global.nc.f64 	%fd231, [%rd76+8];
	mul.rn.f64 	%fd48, %fd424, %fd424;
	fma.rn.f64 	%fd232, %fd230, %fd48, %fd231;
	ld.global.nc.f64 	%fd233, [%rd76+16];
	fma.rn.f64 	%fd234, %fd232, %fd48, %fd233;
	ld.global.nc.f64 	%fd235, [%rd76+24];
	fma.rn.f64 	%fd236, %fd234, %fd48, %fd235;
	ld.global.nc.f64 	%fd237, [%rd76+32];
	fma.rn.f64 	%fd238, %fd236, %fd48, %fd237;
	ld.global.nc.f64 	%fd239, [%rd76+40];
	fma.rn.f64 	%fd240, %fd238, %fd48, %fd239;
	ld.global.nc.f64 	%fd241, [%rd76+48];
	fma.rn.f64 	%fd49, %fd240, %fd48, %fd241;
	fma.rn.f64 	%fd426, %fd49, %fd424, %fd424;
	@%p36 bra 	$L__BB3_42;

	mov.f64 	%fd242, 0d3FF0000000000000;
	fma.rn.f64 	%fd426, %fd49, %fd48, %fd242;

$L__BB3_42:
	and.b32  	%r168, %r344, 2;
	setp.eq.s32 	%p37, %r168, 0;
	@%p37 bra 	$L__BB3_44;

	mov.f64 	%fd243, 0d0000000000000000;
	mov.f64 	%fd244, 0dBFF0000000000000;
	fma.rn.f64 	%fd426, %fd426, %fd244, %fd243;

$L__BB3_44:
	mul.rn.f64 	%fd245, %fd426, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd245;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd56;
	}
	and.b32  	%r171, %r170, 2147483647;
	setp.eq.s32 	%p38, %r171, 2146435072;
	setp.eq.s32 	%p39, %r169, 0;
	and.pred  	%p40, %p39, %p38;
	@%p40 bra 	$L__BB3_47;
	bra.uni 	$L__BB3_45;

$L__BB3_47:
	mov.f64 	%fd255, 0d0000000000000000;
	mul.rn.f64 	%fd427, %fd56, %fd255;
	mov.u32 	%r345, 0;
	bra.uni 	$L__BB3_48;

$L__BB3_45:
	mul.rn.f64 	%fd246, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r345, %fd246;
	st.local.u32 	[%rd1], %r345;
	cvt.rn.f64.s32 	%fd247, %r345;
	neg.f64 	%fd248, %fd247;
	mov.f64 	%fd249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd250, %fd248, %fd249, %fd56;
	mov.f64 	%fd251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd252, %fd248, %fd251, %fd250;
	mov.f64 	%fd253, 0d397B839A252049C0;
	fma.rn.f64 	%fd427, %fd248, %fd253, %fd252;
	abs.f64 	%fd254, %fd56;
	setp.ltu.f64 	%p41, %fd254, 0d41E0000000000000;
	@%p41 bra 	$L__BB3_48;

	add.u64 	%rd136, %SP, 0;
	{ // callseq 18, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd427, [retval0+0];
	} // callseq 18
	ld.local.u32 	%r345, [%rd1];

$L__BB3_48:
	and.b32  	%r173, %r345, 1;
	shl.b32 	%r174, %r345, 3;
	and.b32  	%r175, %r174, 8;
	setp.eq.s32 	%p42, %r173, 0;
	selp.f64 	%fd256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p42;
	mul.wide.s32 	%rd78, %r175, 8;
	add.s64 	%rd80, %rd53, %rd78;
	ld.global.nc.f64 	%fd257, [%rd80+8];
	mul.rn.f64 	%fd61, %fd427, %fd427;
	fma.rn.f64 	%fd258, %fd256, %fd61, %fd257;
	ld.global.nc.f64 	%fd259, [%rd80+16];
	fma.rn.f64 	%fd260, %fd258, %fd61, %fd259;
	ld.global.nc.f64 	%fd261, [%rd80+24];
	fma.rn.f64 	%fd262, %fd260, %fd61, %fd261;
	ld.global.nc.f64 	%fd263, [%rd80+32];
	fma.rn.f64 	%fd264, %fd262, %fd61, %fd263;
	ld.global.nc.f64 	%fd265, [%rd80+40];
	fma.rn.f64 	%fd266, %fd264, %fd61, %fd265;
	ld.global.nc.f64 	%fd267, [%rd80+48];
	fma.rn.f64 	%fd62, %fd266, %fd61, %fd267;
	fma.rn.f64 	%fd429, %fd62, %fd427, %fd427;
	@%p42 bra 	$L__BB3_50;

	mov.f64 	%fd268, 0d3FF0000000000000;
	fma.rn.f64 	%fd429, %fd62, %fd61, %fd268;

$L__BB3_50:
	and.b32  	%r176, %r345, 2;
	setp.eq.s32 	%p43, %r176, 0;
	@%p43 bra 	$L__BB3_52;

	mov.f64 	%fd269, 0d0000000000000000;
	mov.f64 	%fd270, 0dBFF0000000000000;
	fma.rn.f64 	%fd429, %fd429, %fd270, %fd269;

$L__BB3_52:
	mul.rn.f64 	%fd271, %fd429, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd271;
	mul.rn.f32 	%f74, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r349, %f74;
	cvt.rn.f32.s32 	%f75, %r349;
	mov.f32 	%f76, 0fBFC90FDA;
	fma.rn.f32 	%f77, %f75, %f76, %f5;
	mov.f32 	%f78, 0fB3A22168;
	fma.rn.f32 	%f79, %f75, %f78, %f77;
	mov.f32 	%f80, 0fA7C234C5;
	fma.rn.f32 	%f154, %f75, %f80, %f79;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p44, %f20, 0f47CE4780;
	@%p44 bra 	$L__BB3_60;

	setp.eq.f32 	%p45, %f20, 0f7F800000;
	@%p45 bra 	$L__BB3_59;
	bra.uni 	$L__BB3_54;

$L__BB3_59:
	mov.f32 	%f83, 0f00000000;
	mul.rn.f32 	%f154, %f5, %f83;
	mov.u32 	%r349, 0;
	bra.uni 	$L__BB3_60;

$L__BB3_54:
	mov.b32 	%r35, %f5;
	bfe.u32 	%r178, %r35, 23, 8;
	add.s32 	%r36, %r178, -128;
	shl.b32 	%r179, %r35, 8;
	or.b32  	%r37, %r179, -2147483648;
	shr.u32 	%r38, %r36, 5;
	mov.u64 	%rd145, 0;
	mov.u32 	%r346, 0;
	mov.u64 	%rd144, __cudart_i2opi_f;
	mov.u64 	%rd143, %rd1;

$L__BB3_55:
	.pragma "nounroll";
	ld.global.nc.u32 	%r180, [%rd144];
	mad.wide.u32 	%rd83, %r180, %r37, %rd145;
	shr.u64 	%rd145, %rd83, 32;
	st.local.u32 	[%rd143], %rd83;
	add.s64 	%rd144, %rd144, 4;
	add.s64 	%rd143, %rd143, 4;
	add.s32 	%r346, %r346, 1;
	setp.ne.s32 	%p46, %r346, 6;
	@%p46 bra 	$L__BB3_55;

	st.local.u32 	[%rd12], %rd145;
	mov.u32 	%r181, 4;
	sub.s32 	%r41, %r181, %r38;
	mov.u32 	%r182, 6;
	sub.s32 	%r183, %r182, %r38;
	mul.wide.s32 	%rd84, %r183, 4;
	add.s64 	%rd85, %rd1, %rd84;
	ld.local.u32 	%r347, [%rd85];
	ld.local.u32 	%r348, [%rd85+-4];
	and.b32  	%r44, %r36, 31;
	setp.eq.s32 	%p47, %r44, 0;
	@%p47 bra 	$L__BB3_58;

	mov.u32 	%r184, 32;
	sub.s32 	%r185, %r184, %r44;
	shr.u32 	%r186, %r348, %r185;
	shl.b32 	%r187, %r347, %r44;
	add.s32 	%r347, %r186, %r187;
	mul.wide.s32 	%rd86, %r41, 4;
	add.s64 	%rd87, %rd1, %rd86;
	ld.local.u32 	%r188, [%rd87];
	shr.u32 	%r189, %r188, %r185;
	shl.b32 	%r190, %r348, %r44;
	add.s32 	%r348, %r189, %r190;

$L__BB3_58:
	and.b32  	%r191, %r35, -2147483648;
	shr.u32 	%r192, %r348, 30;
	shl.b32 	%r193, %r347, 2;
	or.b32  	%r194, %r192, %r193;
	shr.u32 	%r195, %r194, 31;
	shr.u32 	%r196, %r347, 30;
	add.s32 	%r197, %r195, %r196;
	neg.s32 	%r198, %r197;
	setp.eq.s32 	%p48, %r191, 0;
	selp.b32 	%r349, %r197, %r198, %p48;
	setp.ne.s32 	%p49, %r195, 0;
	xor.b32  	%r199, %r191, -2147483648;
	selp.b32 	%r200, %r199, %r191, %p49;
	selp.b32 	%r201, -1, 0, %p49;
	xor.b32  	%r202, %r194, %r201;
	shl.b32 	%r203, %r348, 2;
	xor.b32  	%r204, %r203, %r201;
	cvt.u64.u32 	%rd88, %r202;
	cvt.u64.u32 	%rd89, %r204;
	bfi.b64 	%rd90, %rd88, %rd89, 32, 32;
	cvt.rn.f64.s64 	%fd272, %rd90;
	mul.rn.f64 	%fd273, %fd272, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f81, %fd273;
	setp.eq.s32 	%p50, %r200, 0;
	neg.f32 	%f82, %f81;
	selp.f32 	%f154, %f81, %f82, %p50;

$L__BB3_60:
	cvt.rn.f32.f64 	%f85, %fd28;
	cvt.f64.f32 	%fd69, %f85;
	and.b32  	%r51, %r349, 1;
	setp.eq.s32 	%p51, %r51, 0;
	selp.f32 	%f24, %f154, 0f3F800000, %p51;
	mul.rn.f32 	%f25, %f154, %f154;
	mov.f32 	%f155, 0fB94D4153;
	@%p51 bra 	$L__BB3_62;

	mov.f32 	%f86, 0fBAB607ED;
	mov.f32 	%f87, 0f37CBAC00;
	fma.rn.f32 	%f155, %f87, %f25, %f86;

$L__BB3_62:
	selp.f32 	%f88, 0f3C0885E4, 0f3D2AAABB, %p51;
	fma.rn.f32 	%f89, %f155, %f25, %f88;
	selp.f32 	%f90, 0fBE2AAAA8, 0fBEFFFFFF, %p51;
	fma.rn.f32 	%f91, %f89, %f25, %f90;
	mov.f32 	%f92, 0f00000000;
	fma.rn.f32 	%f93, %f25, %f24, %f92;
	fma.rn.f32 	%f156, %f91, %f93, %f24;
	and.b32  	%r206, %r349, 2;
	setp.eq.s32 	%p53, %r206, 0;
	@%p53 bra 	$L__BB3_64;

	mov.f32 	%f95, 0fBF800000;
	fma.rn.f32 	%f156, %f156, %f95, %f92;

$L__BB3_64:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd70;
	}
	and.b32  	%r209, %r208, 2147483647;
	setp.eq.s32 	%p54, %r209, 2146435072;
	setp.eq.s32 	%p55, %r207, 0;
	and.pred  	%p56, %p55, %p54;
	@%p56 bra 	$L__BB3_67;
	bra.uni 	$L__BB3_65;

$L__BB3_67:
	mov.f64 	%fd283, 0d0000000000000000;
	mul.rn.f64 	%fd430, %fd70, %fd283;
	mov.u32 	%r350, 0;
	bra.uni 	$L__BB3_68;

$L__BB3_65:
	mul.rn.f64 	%fd274, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r350, %fd274;
	st.local.u32 	[%rd1], %r350;
	cvt.rn.f64.s32 	%fd275, %r350;
	neg.f64 	%fd276, %fd275;
	mov.f64 	%fd277, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd278, %fd276, %fd277, %fd70;
	mov.f64 	%fd279, 0d3C91A62633145C00;
	fma.rn.f64 	%fd280, %fd276, %fd279, %fd278;
	mov.f64 	%fd281, 0d397B839A252049C0;
	fma.rn.f64 	%fd430, %fd276, %fd281, %fd280;
	abs.f64 	%fd282, %fd70;
	setp.ltu.f64 	%p57, %fd282, 0d41E0000000000000;
	@%p57 bra 	$L__BB3_68;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 19, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd430, [retval0+0];
	} // callseq 19
	ld.local.u32 	%r350, [%rd1];

$L__BB3_68:
	and.b32  	%r211, %r350, 1;
	shl.b32 	%r212, %r350, 3;
	and.b32  	%r213, %r212, 8;
	setp.eq.s32 	%p58, %r211, 0;
	selp.f64 	%fd284, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p58;
	mul.wide.s32 	%rd92, %r213, 8;
	add.s64 	%rd94, %rd53, %rd92;
	ld.global.nc.f64 	%fd285, [%rd94+8];
	mul.rn.f64 	%fd75, %fd430, %fd430;
	fma.rn.f64 	%fd286, %fd284, %fd75, %fd285;
	ld.global.nc.f64 	%fd287, [%rd94+16];
	fma.rn.f64 	%fd288, %fd286, %fd75, %fd287;
	ld.global.nc.f64 	%fd289, [%rd94+24];
	fma.rn.f64 	%fd290, %fd288, %fd75, %fd289;
	ld.global.nc.f64 	%fd291, [%rd94+32];
	fma.rn.f64 	%fd292, %fd290, %fd75, %fd291;
	ld.global.nc.f64 	%fd293, [%rd94+40];
	fma.rn.f64 	%fd294, %fd292, %fd75, %fd293;
	ld.global.nc.f64 	%fd295, [%rd94+48];
	fma.rn.f64 	%fd76, %fd294, %fd75, %fd295;
	fma.rn.f64 	%fd432, %fd76, %fd430, %fd430;
	@%p58 bra 	$L__BB3_70;

	mov.f64 	%fd296, 0d3FF0000000000000;
	fma.rn.f64 	%fd432, %fd76, %fd75, %fd296;

$L__BB3_70:
	and.b32  	%r214, %r350, 2;
	setp.eq.s32 	%p59, %r214, 0;
	@%p59 bra 	$L__BB3_72;

	mov.f64 	%fd297, 0d0000000000000000;
	mov.f64 	%fd298, 0dBFF0000000000000;
	fma.rn.f64 	%fd432, %fd432, %fd298, %fd297;

$L__BB3_72:
	mul.rn.f64 	%fd299, %fd432, 0d4044000000000000;
	cvt.f64.f32 	%fd300, %f156;
	mul.rn.f64 	%fd301, %fd300, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd301, %fd299;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r216}, %fd83;
	}
	and.b32  	%r217, %r216, 2147483647;
	setp.eq.s32 	%p60, %r217, 2146435072;
	setp.eq.s32 	%p61, %r215, 0;
	and.pred  	%p62, %p61, %p60;
	@%p62 bra 	$L__BB3_75;
	bra.uni 	$L__BB3_73;

$L__BB3_75:
	mov.f64 	%fd311, 0d0000000000000000;
	mul.rn.f64 	%fd433, %fd83, %fd311;
	mov.u32 	%r351, 0;
	bra.uni 	$L__BB3_76;

$L__BB3_73:
	mul.rn.f64 	%fd302, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r351, %fd302;
	st.local.u32 	[%rd1], %r351;
	cvt.rn.f64.s32 	%fd303, %r351;
	neg.f64 	%fd304, %fd303;
	mov.f64 	%fd305, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd306, %fd304, %fd305, %fd83;
	mov.f64 	%fd307, 0d3C91A62633145C00;
	fma.rn.f64 	%fd308, %fd304, %fd307, %fd306;
	mov.f64 	%fd309, 0d397B839A252049C0;
	fma.rn.f64 	%fd433, %fd304, %fd309, %fd308;
	abs.f64 	%fd310, %fd83;
	setp.ltu.f64 	%p63, %fd310, 0d41E0000000000000;
	@%p63 bra 	$L__BB3_76;

	add.u64 	%rd138, %SP, 0;
	{ // callseq 20, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd138;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd433, [retval0+0];
	} // callseq 20
	ld.local.u32 	%r351, [%rd1];

$L__BB3_76:
	and.b32  	%r219, %r351, 1;
	shl.b32 	%r220, %r351, 3;
	and.b32  	%r221, %r220, 8;
	setp.eq.s32 	%p64, %r219, 0;
	selp.f64 	%fd312, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p64;
	mul.wide.s32 	%rd96, %r221, 8;
	add.s64 	%rd98, %rd53, %rd96;
	ld.global.nc.f64 	%fd313, [%rd98+8];
	mul.rn.f64 	%fd88, %fd433, %fd433;
	fma.rn.f64 	%fd314, %fd312, %fd88, %fd313;
	ld.global.nc.f64 	%fd315, [%rd98+16];
	fma.rn.f64 	%fd316, %fd314, %fd88, %fd315;
	ld.global.nc.f64 	%fd317, [%rd98+24];
	fma.rn.f64 	%fd318, %fd316, %fd88, %fd317;
	ld.global.nc.f64 	%fd319, [%rd98+32];
	fma.rn.f64 	%fd320, %fd318, %fd88, %fd319;
	ld.global.nc.f64 	%fd321, [%rd98+40];
	fma.rn.f64 	%fd322, %fd320, %fd88, %fd321;
	ld.global.nc.f64 	%fd323, [%rd98+48];
	fma.rn.f64 	%fd89, %fd322, %fd88, %fd323;
	fma.rn.f64 	%fd435, %fd89, %fd433, %fd433;
	@%p64 bra 	$L__BB3_78;

	mov.f64 	%fd324, 0d3FF0000000000000;
	fma.rn.f64 	%fd435, %fd89, %fd88, %fd324;

$L__BB3_78:
	and.b32  	%r222, %r351, 2;
	setp.eq.s32 	%p65, %r222, 0;
	@%p65 bra 	$L__BB3_80;

	mov.f64 	%fd325, 0d0000000000000000;
	mov.f64 	%fd326, 0dBFF0000000000000;
	fma.rn.f64 	%fd435, %fd435, %fd326, %fd325;

$L__BB3_80:
	mul.rn.f64 	%fd327, %fd435, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd327;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r223, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r224}, %fd96;
	}
	and.b32  	%r225, %r224, 2147483647;
	setp.eq.s32 	%p66, %r225, 2146435072;
	setp.eq.s32 	%p67, %r223, 0;
	and.pred  	%p68, %p67, %p66;
	@%p68 bra 	$L__BB3_83;
	bra.uni 	$L__BB3_81;

$L__BB3_83:
	mov.f64 	%fd337, 0d0000000000000000;
	mul.rn.f64 	%fd436, %fd96, %fd337;
	mov.u32 	%r352, 0;
	bra.uni 	$L__BB3_84;

$L__BB3_81:
	mul.rn.f64 	%fd328, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r352, %fd328;
	st.local.u32 	[%rd1], %r352;
	cvt.rn.f64.s32 	%fd329, %r352;
	neg.f64 	%fd330, %fd329;
	mov.f64 	%fd331, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd332, %fd330, %fd331, %fd96;
	mov.f64 	%fd333, 0d3C91A62633145C00;
	fma.rn.f64 	%fd334, %fd330, %fd333, %fd332;
	mov.f64 	%fd335, 0d397B839A252049C0;
	fma.rn.f64 	%fd436, %fd330, %fd335, %fd334;
	abs.f64 	%fd336, %fd96;
	setp.ltu.f64 	%p69, %fd336, 0d41E0000000000000;
	@%p69 bra 	$L__BB3_84;

	add.u64 	%rd139, %SP, 0;
	{ // callseq 21, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd139;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd436, [retval0+0];
	} // callseq 21
	ld.local.u32 	%r352, [%rd1];

$L__BB3_84:
	and.b32  	%r227, %r352, 1;
	shl.b32 	%r228, %r352, 3;
	and.b32  	%r229, %r228, 8;
	setp.eq.s32 	%p70, %r227, 0;
	selp.f64 	%fd338, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p70;
	mul.wide.s32 	%rd100, %r229, 8;
	add.s64 	%rd102, %rd53, %rd100;
	ld.global.nc.f64 	%fd339, [%rd102+8];
	mul.rn.f64 	%fd101, %fd436, %fd436;
	fma.rn.f64 	%fd340, %fd338, %fd101, %fd339;
	ld.global.nc.f64 	%fd341, [%rd102+16];
	fma.rn.f64 	%fd342, %fd340, %fd101, %fd341;
	ld.global.nc.f64 	%fd343, [%rd102+24];
	fma.rn.f64 	%fd344, %fd342, %fd101, %fd343;
	ld.global.nc.f64 	%fd345, [%rd102+32];
	fma.rn.f64 	%fd346, %fd344, %fd101, %fd345;
	ld.global.nc.f64 	%fd347, [%rd102+40];
	fma.rn.f64 	%fd348, %fd346, %fd101, %fd347;
	ld.global.nc.f64 	%fd349, [%rd102+48];
	fma.rn.f64 	%fd102, %fd348, %fd101, %fd349;
	fma.rn.f64 	%fd438, %fd102, %fd436, %fd436;
	@%p70 bra 	$L__BB3_86;

	mov.f64 	%fd350, 0d3FF0000000000000;
	fma.rn.f64 	%fd438, %fd102, %fd101, %fd350;

$L__BB3_86:
	and.b32  	%r230, %r352, 2;
	setp.eq.s32 	%p71, %r230, 0;
	@%p71 bra 	$L__BB3_88;

	mov.f64 	%fd351, 0d0000000000000000;
	mov.f64 	%fd352, 0dBFF0000000000000;
	fma.rn.f64 	%fd438, %fd438, %fd352, %fd351;

$L__BB3_88:
	mul.rn.f64 	%fd353, %fd438, 0d4072C00000000000;
	add.rn.f64 	%fd354, %fd95, %fd353;
	add.rn.f64 	%fd108, %fd354, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd355, %fd1, %fd1;
	mov.f64 	%fd356, 0d4000000000000000;
	add.rn.f64 	%fd357, %fd355, 0dC059000000000000;
	mul.rn.f64 	%fd358, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd357, %fd358;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd356;
	}
	and.b32  	%r62, %r61, 2146435072;
	setp.eq.s32 	%p72, %r62, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 22, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd441, [retval0+0];
	} // callseq 22
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd2;
	}
	setp.lt.s32 	%p73, %r63, 0;
	and.pred  	%p1, %p73, %p72;
	not.pred 	%p74, %p1;
	@%p74 bra 	$L__BB3_90;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r231}, %fd441;
	}
	xor.b32  	%r232, %r231, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r233, %temp}, %fd441;
	}
	mov.b64 	%fd441, {%r233, %r232};

$L__BB3_90:
	setp.eq.f32 	%p75, %f4, 0f00000000;
	@%p75 bra 	$L__BB3_94;
	bra.uni 	$L__BB3_91;

$L__BB3_94:
	selp.b32 	%r234, %r63, 0, %p72;
	mov.u32 	%r235, 0;
	or.b32  	%r236, %r234, 2146435072;
	setp.lt.s32 	%p79, %r61, 0;
	selp.b32 	%r237, %r236, %r234, %p79;
	mov.b64 	%fd441, {%r235, %r237};
	bra.uni 	$L__BB3_95;

$L__BB3_91:
	setp.gt.s32 	%p76, %r63, -1;
	@%p76 bra 	$L__BB3_95;

	mov.f64 	%fd359, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd360, %fd359;
	setp.eq.f64 	%p77, %fd360, 0d4000000000000000;
	@%p77 bra 	$L__BB3_95;

	mov.f64 	%fd441, 0dFFF8000000000000;

$L__BB3_95:
	add.rn.f64 	%fd362, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r238}, %fd362;
	}
	and.b32  	%r239, %r238, 2146435072;
	setp.ne.s32 	%p80, %r239, 2146435072;
	@%p80 bra 	$L__BB3_102;

	setp.gtu.f64 	%p81, %fd111, 0d7FF0000000000000;
	@%p81 bra 	$L__BB3_101;
	bra.uni 	$L__BB3_97;

$L__BB3_101:
	mov.f64 	%fd364, 0d4000000000000000;
	add.rn.f64 	%fd441, %fd2, %fd364;
	bra.uni 	$L__BB3_102;

$L__BB3_97:
	mov.f64 	%fd363, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r240, %temp}, %fd363;
	}
	and.b32  	%r64, %r61, 2147483647;
	setp.eq.s32 	%p82, %r64, 2146435072;
	setp.eq.s32 	%p83, %r240, 0;
	and.pred  	%p84, %p82, %p83;
	@%p84 bra 	$L__BB3_100;
	bra.uni 	$L__BB3_98;

$L__BB3_100:
	setp.gt.f64 	%p91, %fd111, 0d3FF0000000000000;
	selp.b32 	%r247, 2146435072, 0, %p91;
	mov.u32 	%r248, 0;
	xor.b32  	%r249, %r247, 2146435072;
	setp.lt.s32 	%p92, %r61, 0;
	selp.b32 	%r250, %r249, %r247, %p92;
	setp.eq.f32 	%p93, %f4, 0fBF800000;
	selp.b32 	%r251, 1072693248, %r250, %p93;
	mov.b64 	%fd441, {%r248, %r251};
	bra.uni 	$L__BB3_102;

$L__BB3_98:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd2;
	}
	and.b32  	%r242, %r63, 2147483647;
	setp.ne.s32 	%p85, %r242, 2146435072;
	setp.ne.s32 	%p86, %r241, 0;
	or.pred  	%p87, %p85, %p86;
	@%p87 bra 	$L__BB3_102;

	setp.gt.s32 	%p88, %r61, -1;
	selp.b32 	%r243, 2146435072, 0, %p88;
	mov.u32 	%r244, 0;
	setp.ne.s32 	%p89, %r64, 1071644672;
	and.pred  	%p90, %p89, %p1;
	or.b32  	%r245, %r243, -2147483648;
	selp.b32 	%r246, %r245, %r243, %p90;
	mov.b64 	%fd441, {%r244, %r246};

$L__BB3_102:
	mul.rn.f64 	%fd365, %fd441, 0d3FC999999999999A;
	setp.eq.f32 	%p94, %f4, 0f3F800000;
	selp.f64 	%fd366, 0d3FC999999999999A, %fd365, %p94;
	add.rn.f64 	%fd367, %fd110, %fd366;
	mul.rn.f32 	%f96, %f2, %f4;
	cvt.f64.f32 	%fd368, %f96;
	mul.rn.f64 	%fd121, %fd368, 0d3FB999999999999A;
	add.rn.f64 	%fd369, %fd121, %fd367;
	abs.f32 	%f97, %f2;
	sqrt.rn.f32 	%f98, %f97;
	cvt.f64.f32 	%fd122, %f98;
	mul.rn.f64 	%fd370, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd371, %fd370, %fd369;
	cvt.rn.f32.f64 	%f99, %fd109;
	cvt.f64.f32 	%fd372, %f99;
	mul.rn.f64 	%fd373, %fd372, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f100, %fd373;
	cvt.f64.f32 	%fd374, %f100;
	add.rn.f64 	%fd123, %fd371, %fd374;
	add.rn.f64 	%fd375, %fd2, %fd2;
	add.rn.f64 	%fd376, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd376, %fd375;
	abs.f64 	%fd125, %fd1;
	{ // callseq 23, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd444, [retval0+0];
	} // callseq 23
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd1;
	}
	setp.lt.s32 	%p95, %r65, 0;
	and.pred  	%p2, %p95, %p72;
	not.pred 	%p97, %p2;
	@%p97 bra 	$L__BB3_104;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r252}, %fd444;
	}
	xor.b32  	%r253, %r252, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r254, %temp}, %fd444;
	}
	mov.b64 	%fd444, {%r254, %r253};

$L__BB3_104:
	setp.eq.f32 	%p98, %f2, 0f00000000;
	@%p98 bra 	$L__BB3_108;
	bra.uni 	$L__BB3_105;

$L__BB3_108:
	selp.b32 	%r255, %r65, 0, %p72;
	mov.u32 	%r256, 0;
	or.b32  	%r257, %r255, 2146435072;
	setp.lt.s32 	%p102, %r61, 0;
	selp.b32 	%r258, %r257, %r255, %p102;
	mov.b64 	%fd444, {%r256, %r258};
	bra.uni 	$L__BB3_109;

$L__BB3_105:
	setp.gt.s32 	%p99, %r65, -1;
	@%p99 bra 	$L__BB3_109;

	mov.f64 	%fd377, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd378, %fd377;
	setp.eq.f64 	%p100, %fd378, 0d4000000000000000;
	@%p100 bra 	$L__BB3_109;

	mov.f64 	%fd444, 0dFFF8000000000000;

$L__BB3_109:
	add.rn.f64 	%fd380, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd380;
	}
	and.b32  	%r260, %r259, 2146435072;
	setp.ne.s32 	%p103, %r260, 2146435072;
	@%p103 bra 	$L__BB3_116;

	setp.gtu.f64 	%p104, %fd125, 0d7FF0000000000000;
	@%p104 bra 	$L__BB3_115;
	bra.uni 	$L__BB3_111;

$L__BB3_115:
	mov.f64 	%fd382, 0d4000000000000000;
	add.rn.f64 	%fd444, %fd1, %fd382;
	bra.uni 	$L__BB3_116;

$L__BB3_111:
	mov.f64 	%fd381, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r261, %temp}, %fd381;
	}
	and.b32  	%r66, %r61, 2147483647;
	setp.eq.s32 	%p105, %r66, 2146435072;
	setp.eq.s32 	%p106, %r261, 0;
	and.pred  	%p107, %p105, %p106;
	@%p107 bra 	$L__BB3_114;
	bra.uni 	$L__BB3_112;

$L__BB3_114:
	setp.gt.f64 	%p114, %fd125, 0d3FF0000000000000;
	selp.b32 	%r268, 2146435072, 0, %p114;
	mov.u32 	%r269, 0;
	xor.b32  	%r270, %r268, 2146435072;
	setp.lt.s32 	%p115, %r61, 0;
	selp.b32 	%r271, %r270, %r268, %p115;
	setp.eq.f32 	%p116, %f2, 0fBF800000;
	selp.b32 	%r272, 1072693248, %r271, %p116;
	mov.b64 	%fd444, {%r269, %r272};
	bra.uni 	$L__BB3_116;

$L__BB3_112:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd1;
	}
	and.b32  	%r263, %r65, 2147483647;
	setp.ne.s32 	%p108, %r263, 2146435072;
	setp.ne.s32 	%p109, %r262, 0;
	or.pred  	%p110, %p108, %p109;
	@%p110 bra 	$L__BB3_116;

	setp.gt.s32 	%p111, %r61, -1;
	selp.b32 	%r264, 2146435072, 0, %p111;
	mov.u32 	%r265, 0;
	setp.ne.s32 	%p112, %r66, 1071644672;
	and.pred  	%p113, %p112, %p2;
	or.b32  	%r266, %r264, -2147483648;
	selp.b32 	%r267, %r266, %r264, %p113;
	mov.b64 	%fd444, {%r265, %r267};

$L__BB3_116:
	mul.rn.f64 	%fd383, %fd444, 0d3FB999999999999A;
	setp.eq.f32 	%p117, %f2, 0f3F800000;
	selp.f64 	%fd384, 0d3FB999999999999A, %fd383, %p117;
	add.rn.f64 	%fd385, %fd124, %fd384;
	add.rn.f64 	%fd386, %fd121, %fd385;
	mul.rn.f64 	%fd387, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd388, %fd387, %fd386;
	cvt.rn.f32.f64 	%f101, %fd108;
	cvt.f64.f32 	%fd389, %f101;
	mul.rn.f64 	%fd390, %fd389, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f102, %fd390;
	cvt.f64.f32 	%fd391, %f102;
	add.rn.f64 	%fd135, %fd388, %fd391;
	cvt.f64.f32 	%fd392, %f3;
	div.rn.f64 	%fd393, %fd392, 0d4066800000000000;
	mul.rn.f64 	%fd394, %fd393, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd394;
	mul.rn.f32 	%f103, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r360, %f103;
	cvt.rn.f32.s32 	%f104, %r360;
	mov.f32 	%f105, 0fBFC90FDA;
	fma.rn.f32 	%f106, %f104, %f105, %f31;
	mov.f32 	%f107, 0fB3A22168;
	fma.rn.f32 	%f108, %f104, %f107, %f106;
	mov.f32 	%f109, 0fA7C234C5;
	fma.rn.f32 	%f160, %f104, %f109, %f108;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p118, %f33, 0f47CE4780;
	mov.u32 	%r356, %r360;
	mov.f32 	%f157, %f160;
	@%p118 bra 	$L__BB3_124;

	setp.eq.f32 	%p119, %f33, 0f7F800000;
	@%p119 bra 	$L__BB3_123;
	bra.uni 	$L__BB3_118;

$L__BB3_123:
	mov.f32 	%f112, 0f00000000;
	mul.rn.f32 	%f157, %f31, %f112;
	mov.u32 	%r356, 0;
	bra.uni 	$L__BB3_124;

$L__BB3_118:
	mov.b32 	%r68, %f31;
	bfe.u32 	%r274, %r68, 23, 8;
	add.s32 	%r69, %r274, -128;
	shl.b32 	%r275, %r68, 8;
	or.b32  	%r70, %r275, -2147483648;
	shr.u32 	%r71, %r69, 5;
	mov.u64 	%rd148, 0;
	mov.u32 	%r353, 0;
	mov.u64 	%rd147, __cudart_i2opi_f;
	mov.u64 	%rd146, %rd1;

$L__BB3_119:
	.pragma "nounroll";
	ld.global.nc.u32 	%r276, [%rd147];
	mad.wide.u32 	%rd105, %r276, %r70, %rd148;
	shr.u64 	%rd148, %rd105, 32;
	st.local.u32 	[%rd146], %rd105;
	add.s64 	%rd147, %rd147, 4;
	add.s64 	%rd146, %rd146, 4;
	add.s32 	%r353, %r353, 1;
	setp.ne.s32 	%p120, %r353, 6;
	@%p120 bra 	$L__BB3_119;

	st.local.u32 	[%rd12], %rd148;
	mov.u32 	%r277, 4;
	sub.s32 	%r74, %r277, %r71;
	mov.u32 	%r278, 6;
	sub.s32 	%r279, %r278, %r71;
	mul.wide.s32 	%rd106, %r279, 4;
	add.s64 	%rd107, %rd1, %rd106;
	ld.local.u32 	%r354, [%rd107];
	ld.local.u32 	%r355, [%rd107+-4];
	and.b32  	%r77, %r69, 31;
	setp.eq.s32 	%p121, %r77, 0;
	@%p121 bra 	$L__BB3_122;

	mov.u32 	%r280, 32;
	sub.s32 	%r281, %r280, %r77;
	shr.u32 	%r282, %r355, %r281;
	shl.b32 	%r283, %r354, %r77;
	add.s32 	%r354, %r282, %r283;
	mul.wide.s32 	%rd108, %r74, 4;
	add.s64 	%rd109, %rd1, %rd108;
	ld.local.u32 	%r284, [%rd109];
	shr.u32 	%r285, %r284, %r281;
	shl.b32 	%r286, %r355, %r77;
	add.s32 	%r355, %r285, %r286;

$L__BB3_122:
	and.b32  	%r287, %r68, -2147483648;
	shr.u32 	%r288, %r355, 30;
	shl.b32 	%r289, %r354, 2;
	or.b32  	%r290, %r288, %r289;
	shr.u32 	%r291, %r290, 31;
	shr.u32 	%r292, %r354, 30;
	add.s32 	%r293, %r291, %r292;
	neg.s32 	%r294, %r293;
	setp.eq.s32 	%p122, %r287, 0;
	selp.b32 	%r356, %r293, %r294, %p122;
	setp.ne.s32 	%p123, %r291, 0;
	xor.b32  	%r295, %r287, -2147483648;
	selp.b32 	%r296, %r295, %r287, %p123;
	selp.b32 	%r297, -1, 0, %p123;
	xor.b32  	%r298, %r290, %r297;
	shl.b32 	%r299, %r355, 2;
	xor.b32  	%r300, %r299, %r297;
	cvt.u64.u32 	%rd110, %r298;
	cvt.u64.u32 	%rd111, %r300;
	bfi.b64 	%rd112, %rd110, %rd111, 32, 32;
	cvt.rn.f64.s64 	%fd395, %rd112;
	mul.rn.f64 	%fd396, %fd395, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f110, %fd396;
	setp.eq.s32 	%p124, %r296, 0;
	neg.f32 	%f111, %f110;
	selp.f32 	%f157, %f110, %f111, %p124;

$L__BB3_124:
	and.b32  	%r84, %r356, 1;
	setp.eq.s32 	%p125, %r84, 0;
	selp.f32 	%f37, %f157, 0f3F800000, %p125;
	mul.rn.f32 	%f38, %f157, %f157;
	mov.f32 	%f158, 0fB94D4153;
	@%p125 bra 	$L__BB3_126;

	mov.f32 	%f114, 0fBAB607ED;
	mov.f32 	%f115, 0f37CBAC00;
	fma.rn.f32 	%f158, %f115, %f38, %f114;

$L__BB3_126:
	selp.f32 	%f116, 0f3C0885E4, 0f3D2AAABB, %p125;
	fma.rn.f32 	%f117, %f158, %f38, %f116;
	selp.f32 	%f118, 0fBE2AAAA8, 0fBEFFFFFF, %p125;
	fma.rn.f32 	%f119, %f117, %f38, %f118;
	mov.f32 	%f120, 0f00000000;
	fma.rn.f32 	%f121, %f38, %f37, %f120;
	fma.rn.f32 	%f159, %f119, %f121, %f37;
	and.b32  	%r302, %r356, 2;
	setp.eq.s32 	%p127, %r302, 0;
	@%p127 bra 	$L__BB3_128;

	mov.f32 	%f123, 0fBF800000;
	fma.rn.f32 	%f159, %f159, %f123, %f120;

$L__BB3_128:
	@%p118 bra 	$L__BB3_136;

	setp.eq.f32 	%p129, %f33, 0f7F800000;
	@%p129 bra 	$L__BB3_135;
	bra.uni 	$L__BB3_130;

$L__BB3_135:
	mov.f32 	%f126, 0f00000000;
	mul.rn.f32 	%f160, %f31, %f126;
	mov.u32 	%r360, 0;
	bra.uni 	$L__BB3_136;

$L__BB3_130:
	mov.b32 	%r85, %f31;
	bfe.u32 	%r304, %r85, 23, 8;
	add.s32 	%r86, %r304, -128;
	shl.b32 	%r305, %r85, 8;
	or.b32  	%r87, %r305, -2147483648;
	shr.u32 	%r88, %r86, 5;
	mov.u64 	%rd151, 0;
	mov.u32 	%r357, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
	mov.u64 	%rd149, %rd1;

$L__BB3_131:
	.pragma "nounroll";
	ld.global.nc.u32 	%r306, [%rd150];
	mad.wide.u32 	%rd115, %r306, %r87, %rd151;
	shr.u64 	%rd151, %rd115, 32;
	st.local.u32 	[%rd149], %rd115;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r357, %r357, 1;
	setp.ne.s32 	%p130, %r357, 6;
	@%p130 bra 	$L__BB3_131;

	st.local.u32 	[%rd12], %rd151;
	mov.u32 	%r307, 4;
	sub.s32 	%r91, %r307, %r88;
	mov.u32 	%r308, 6;
	sub.s32 	%r309, %r308, %r88;
	mul.wide.s32 	%rd116, %r309, 4;
	add.s64 	%rd117, %rd1, %rd116;
	ld.local.u32 	%r358, [%rd117];
	ld.local.u32 	%r359, [%rd117+-4];
	and.b32  	%r94, %r86, 31;
	setp.eq.s32 	%p131, %r94, 0;
	@%p131 bra 	$L__BB3_134;

	mov.u32 	%r310, 32;
	sub.s32 	%r311, %r310, %r94;
	shr.u32 	%r312, %r359, %r311;
	shl.b32 	%r313, %r358, %r94;
	add.s32 	%r358, %r312, %r313;
	mul.wide.s32 	%rd118, %r91, 4;
	add.s64 	%rd119, %rd1, %rd118;
	ld.local.u32 	%r314, [%rd119];
	shr.u32 	%r315, %r314, %r311;
	shl.b32 	%r316, %r359, %r94;
	add.s32 	%r359, %r315, %r316;

$L__BB3_134:
	and.b32  	%r317, %r85, -2147483648;
	shr.u32 	%r318, %r359, 30;
	shl.b32 	%r319, %r358, 2;
	or.b32  	%r320, %r318, %r319;
	shr.u32 	%r321, %r320, 31;
	shr.u32 	%r322, %r358, 30;
	add.s32 	%r323, %r321, %r322;
	neg.s32 	%r324, %r323;
	setp.eq.s32 	%p132, %r317, 0;
	selp.b32 	%r360, %r323, %r324, %p132;
	setp.ne.s32 	%p133, %r321, 0;
	xor.b32  	%r325, %r317, -2147483648;
	selp.b32 	%r326, %r325, %r317, %p133;
	selp.b32 	%r327, -1, 0, %p133;
	xor.b32  	%r328, %r320, %r327;
	shl.b32 	%r329, %r359, 2;
	xor.b32  	%r330, %r329, %r327;
	cvt.u64.u32 	%rd120, %r328;
	cvt.u64.u32 	%rd121, %r330;
	bfi.b64 	%rd122, %rd120, %rd121, 32, 32;
	cvt.rn.f64.s64 	%fd397, %rd122;
	mul.rn.f64 	%fd398, %fd397, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f124, %fd398;
	setp.eq.s32 	%p134, %r326, 0;
	neg.f32 	%f125, %f124;
	selp.f32 	%f160, %f124, %f125, %p134;

$L__BB3_136:
	add.s32 	%r101, %r360, 1;
	and.b32  	%r102, %r101, 1;
	setp.eq.s32 	%p3, %r102, 0;
	mul.rn.f32 	%f47, %f160, %f160;
	mov.f32 	%f161, 0fB94D4153;
	@%p3 bra 	$L__BB3_138;

	mov.f32 	%f128, 0fBAB607ED;
	mov.f32 	%f129, 0f37CBAC00;
	fma.rn.f32 	%f161, %f129, %f47, %f128;

$L__BB3_138:
	selp.f32 	%f130, %f160, 0f3F800000, %p3;
	selp.f32 	%f131, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f132, %f161, %f47, %f131;
	selp.f32 	%f133, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f134, %f132, %f47, %f133;
	mov.f32 	%f135, 0f00000000;
	fma.rn.f32 	%f136, %f47, %f130, %f135;
	fma.rn.f32 	%f162, %f134, %f136, %f130;
	and.b32  	%r332, %r101, 2;
	setp.eq.s32 	%p136, %r332, 0;
	@%p136 bra 	$L__BB3_140;

	mov.f32 	%f138, 0fBF800000;
	fma.rn.f32 	%f162, %f162, %f138, %f135;

$L__BB3_140:
	mov.u32 	%r336, %tid.x;
	mov.u32 	%r335, %ntid.x;
	mov.u32 	%r334, %ctaid.x;
	mad.lo.s32 	%r333, %r334, %r335, %r336;
	mul.wide.s32 	%rd129, %r333, 4;
	ld.param.u64 	%rd128, [wgs84_to_gcj02_cuda_float_param_1];
	cvta.to.global.u64 	%rd127, %rd128;
	add.s64 	%rd126, %rd127, %rd129;
	ld.param.u64 	%rd125, [wgs84_to_gcj02_cuda_float_param_0];
	cvta.to.global.u64 	%rd124, %rd125;
	add.s64 	%rd123, %rd124, %rd129;
	cvt.f64.f32 	%fd399, %f159;
	mul.rn.f64 	%fd400, %fd399, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd401, %fd400, %fd399;
	add.rn.f64 	%fd402, %fd401, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f139, %fd402;
	sqrt.rn.f32 	%f140, %f139;
	mov.f32 	%f141, 0f4AC2A60A;
	div.rn.f32 	%f142, %f141, %f140;
	mul.rn.f32 	%f143, %f142, %f162;
	cvt.f64.f32 	%fd403, %f143;
	mul.rn.f64 	%fd404, %fd403, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f144, %fd135;
	cvt.f64.f32 	%fd405, %f144;
	mul.rn.f64 	%fd406, %fd405, 0d4066800000000000;
	div.rn.f64 	%fd407, %fd406, %fd404;
	cvt.rn.f32.f64 	%f145, %fd407;
	add.rn.f32 	%f146, %f1, %f145;
	st.global.f32 	[%rd123], %f146;
	mul.rn.f32 	%f147, %f140, %f139;
	cvt.f64.f32 	%fd408, %f147;
	mov.f64 	%fd409, 0d41582B102DE355C1;
	div.rn.f64 	%fd410, %fd409, %fd408;
	mul.rn.f64 	%fd411, %fd410, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f148, %fd123;
	cvt.f64.f32 	%fd412, %f148;
	mul.rn.f64 	%fd413, %fd412, 0d4066800000000000;
	div.rn.f64 	%fd414, %fd413, %fd411;
	cvt.rn.f32.f64 	%f149, %fd414;
	add.rn.f32 	%f150, %f3, %f149;
	st.global.f32 	[%rd126], %f150;
	ret;

}
	// .globl	wgs84_to_bd09_cuda_float
.visible .entry wgs84_to_bd09_cuda_float(
	.param .u64 wgs84_to_bd09_cuda_float_param_0,
	.param .u64 wgs84_to_bd09_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot4[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<235>;
	.reg .f32 	%f<347>;
	.reg .b32 	%r<628>;
	.reg .f64 	%fd<508>;
	.reg .b64 	%rd<236>;


	mov.u64 	%SPL, __local_depot4;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd61, [wgs84_to_bd09_cuda_float_param_0];
	ld.param.u64 	%rd62, [wgs84_to_bd09_cuda_float_param_1];
	cvta.to.global.u64 	%rd63, %rd62;
	add.u64 	%rd64, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r180, %ntid.x;
	mov.u32 	%r181, %ctaid.x;
	mov.u32 	%r182, %tid.x;
	mad.lo.s32 	%r183, %r181, %r180, %r182;
	cvta.to.global.u64 	%rd73, %rd61;
	mul.wide.s32 	%rd74, %r183, 4;
	add.s64 	%rd10, %rd73, %rd74;
	add.s64 	%rd11, %rd63, %rd74;
	ld.global.f32 	%f1, [%rd10];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd11];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd159, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd159;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd160, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd160;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r184, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r185}, %fd4;
	}
	and.b32  	%r186, %r185, 2147483647;
	setp.eq.s32 	%p6, %r186, 2146435072;
	setp.eq.s32 	%p7, %r184, 0;
	and.pred  	%p8, %p7, %p6;
	@%p8 bra 	$L__BB4_3;
	bra.uni 	$L__BB4_1;

$L__BB4_3:
	mov.f64 	%fd170, 0d0000000000000000;
	mul.rn.f64 	%fd472, %fd4, %fd170;
	mov.u32 	%r588, 0;
	bra.uni 	$L__BB4_4;

$L__BB4_1:
	mul.rn.f64 	%fd161, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r588, %fd161;
	st.local.u32 	[%rd8], %r588;
	cvt.rn.f64.s32 	%fd162, %r588;
	neg.f64 	%fd163, %fd162;
	mov.f64 	%fd164, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd165, %fd163, %fd164, %fd4;
	mov.f64 	%fd166, 0d3C91A62633145C00;
	fma.rn.f64 	%fd167, %fd163, %fd166, %fd165;
	mov.f64 	%fd168, 0d397B839A252049C0;
	fma.rn.f64 	%fd472, %fd163, %fd168, %fd167;
	abs.f64 	%fd169, %fd4;
	setp.ltu.f64 	%p9, %fd169, 0d41E0000000000000;
	@%p9 bra 	$L__BB4_4;

	{ // callseq 24, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd64;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd472, [retval0+0];
	} // callseq 24
	ld.local.u32 	%r588, [%rd8];

$L__BB4_4:
	and.b32  	%r188, %r588, 1;
	shl.b32 	%r189, %r588, 3;
	and.b32  	%r190, %r189, 8;
	setp.eq.s32 	%p10, %r188, 0;
	selp.f64 	%fd171, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p10;
	mul.wide.s32 	%rd76, %r190, 8;
	mov.u64 	%rd77, __cudart_sin_cos_coeffs;
	add.s64 	%rd78, %rd77, %rd76;
	ld.global.nc.f64 	%fd172, [%rd78+8];
	mul.rn.f64 	%fd9, %fd472, %fd472;
	fma.rn.f64 	%fd173, %fd171, %fd9, %fd172;
	ld.global.nc.f64 	%fd174, [%rd78+16];
	fma.rn.f64 	%fd175, %fd173, %fd9, %fd174;
	ld.global.nc.f64 	%fd176, [%rd78+24];
	fma.rn.f64 	%fd177, %fd175, %fd9, %fd176;
	ld.global.nc.f64 	%fd178, [%rd78+32];
	fma.rn.f64 	%fd179, %fd177, %fd9, %fd178;
	ld.global.nc.f64 	%fd180, [%rd78+40];
	fma.rn.f64 	%fd181, %fd179, %fd9, %fd180;
	ld.global.nc.f64 	%fd182, [%rd78+48];
	fma.rn.f64 	%fd10, %fd181, %fd9, %fd182;
	fma.rn.f64 	%fd474, %fd10, %fd472, %fd472;
	@%p10 bra 	$L__BB4_6;

	mov.f64 	%fd183, 0d3FF0000000000000;
	fma.rn.f64 	%fd474, %fd10, %fd9, %fd183;

$L__BB4_6:
	and.b32  	%r191, %r588, 2;
	setp.eq.s32 	%p11, %r191, 0;
	@%p11 bra 	$L__BB4_8;

	mov.f64 	%fd184, 0d0000000000000000;
	mov.f64 	%fd185, 0dBFF0000000000000;
	fma.rn.f64 	%fd474, %fd474, %fd185, %fd184;

$L__BB4_8:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r192, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd16;
	}
	and.b32  	%r194, %r193, 2147483647;
	setp.eq.s32 	%p12, %r194, 2146435072;
	setp.eq.s32 	%p13, %r192, 0;
	and.pred  	%p14, %p13, %p12;
	@%p14 bra 	$L__BB4_11;
	bra.uni 	$L__BB4_9;

$L__BB4_11:
	mov.f64 	%fd195, 0d0000000000000000;
	mul.rn.f64 	%fd475, %fd16, %fd195;
	mov.u32 	%r589, 0;
	bra.uni 	$L__BB4_12;

$L__BB4_9:
	add.u64 	%rd204, %SPL, 0;
	mul.rn.f64 	%fd186, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r589, %fd186;
	st.local.u32 	[%rd204], %r589;
	cvt.rn.f64.s32 	%fd187, %r589;
	neg.f64 	%fd188, %fd187;
	mov.f64 	%fd189, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd190, %fd188, %fd189, %fd16;
	mov.f64 	%fd191, 0d3C91A62633145C00;
	fma.rn.f64 	%fd192, %fd188, %fd191, %fd190;
	mov.f64 	%fd193, 0d397B839A252049C0;
	fma.rn.f64 	%fd475, %fd188, %fd193, %fd192;
	abs.f64 	%fd194, %fd16;
	setp.ltu.f64 	%p15, %fd194, 0d41E0000000000000;
	@%p15 bra 	$L__BB4_12;

	add.u64 	%rd208, %SP, 0;
	add.u64 	%rd207, %SP, 0;
	add.u64 	%rd206, %SPL, 0;
	{ // callseq 25, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd207;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd475, [retval0+0];
	} // callseq 25
	ld.local.u32 	%r589, [%rd206];

$L__BB4_12:
	mov.u64 	%rd209, __cudart_sin_cos_coeffs;
	and.b32  	%r196, %r589, 1;
	shl.b32 	%r197, %r589, 3;
	and.b32  	%r198, %r197, 8;
	setp.eq.s32 	%p16, %r196, 0;
	selp.f64 	%fd196, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p16;
	mul.wide.s32 	%rd80, %r198, 8;
	add.s64 	%rd82, %rd209, %rd80;
	ld.global.nc.f64 	%fd197, [%rd82+8];
	mul.rn.f64 	%fd21, %fd475, %fd475;
	fma.rn.f64 	%fd198, %fd196, %fd21, %fd197;
	ld.global.nc.f64 	%fd199, [%rd82+16];
	fma.rn.f64 	%fd200, %fd198, %fd21, %fd199;
	ld.global.nc.f64 	%fd201, [%rd82+24];
	fma.rn.f64 	%fd202, %fd200, %fd21, %fd201;
	ld.global.nc.f64 	%fd203, [%rd82+32];
	fma.rn.f64 	%fd204, %fd202, %fd21, %fd203;
	ld.global.nc.f64 	%fd205, [%rd82+40];
	fma.rn.f64 	%fd206, %fd204, %fd21, %fd205;
	ld.global.nc.f64 	%fd207, [%rd82+48];
	fma.rn.f64 	%fd22, %fd206, %fd21, %fd207;
	fma.rn.f64 	%fd477, %fd22, %fd475, %fd475;
	@%p16 bra 	$L__BB4_14;

	mov.f64 	%fd208, 0d3FF0000000000000;
	fma.rn.f64 	%fd477, %fd22, %fd21, %fd208;

$L__BB4_14:
	and.b32  	%r199, %r589, 2;
	setp.eq.s32 	%p17, %r199, 0;
	@%p17 bra 	$L__BB4_16;

	mov.f64 	%fd209, 0d0000000000000000;
	mov.f64 	%fd210, 0dBFF0000000000000;
	fma.rn.f64 	%fd477, %fd477, %fd210, %fd209;

$L__BB4_16:
	mul.rn.f64 	%fd211, %fd477, 0d4034000000000000;
	mul.rn.f64 	%fd212, %fd474, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd212, %fd211;
	mul.rn.f32 	%f111, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r593, %f111;
	cvt.rn.f32.s32 	%f112, %r593;
	mov.f32 	%f113, 0fBFC90FDA;
	fma.rn.f32 	%f114, %f112, %f113, %f6;
	mov.f32 	%f115, 0fB3A22168;
	fma.rn.f32 	%f116, %f112, %f115, %f114;
	mov.f32 	%f117, 0fA7C234C5;
	fma.rn.f32 	%f322, %f112, %f117, %f116;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p18, %f8, 0f47CE4780;
	add.s64 	%rd12, %rd1, 24;
	@%p18 bra 	$L__BB4_24;

	setp.eq.f32 	%p19, %f8, 0f7F800000;
	@%p19 bra 	$L__BB4_23;
	bra.uni 	$L__BB4_18;

$L__BB4_23:
	mov.f32 	%f120, 0f00000000;
	mul.rn.f32 	%f322, %f6, %f120;
	mov.u32 	%r593, 0;
	bra.uni 	$L__BB4_24;

$L__BB4_18:
	mov.b32 	%r8, %f6;
	bfe.u32 	%r201, %r8, 23, 8;
	add.s32 	%r9, %r201, -128;
	shl.b32 	%r202, %r8, 8;
	or.b32  	%r10, %r202, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd214, 0;
	mov.u32 	%r590, 0;
	mov.u64 	%rd213, __cudart_i2opi_f;
	mov.u64 	%rd212, %rd1;

$L__BB4_19:
	.pragma "nounroll";
	ld.global.nc.u32 	%r203, [%rd213];
	mad.wide.u32 	%rd85, %r203, %r10, %rd214;
	shr.u64 	%rd214, %rd85, 32;
	st.local.u32 	[%rd212], %rd85;
	add.s64 	%rd213, %rd213, 4;
	add.s64 	%rd212, %rd212, 4;
	add.s32 	%r590, %r590, 1;
	setp.ne.s32 	%p20, %r590, 6;
	@%p20 bra 	$L__BB4_19;

	st.local.u32 	[%rd12], %rd214;
	mov.u32 	%r204, 4;
	sub.s32 	%r14, %r204, %r11;
	mov.u32 	%r205, 6;
	sub.s32 	%r206, %r205, %r11;
	mul.wide.s32 	%rd86, %r206, 4;
	add.s64 	%rd87, %rd1, %rd86;
	ld.local.u32 	%r591, [%rd87];
	ld.local.u32 	%r592, [%rd87+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p21, %r17, 0;
	@%p21 bra 	$L__BB4_22;

	mov.u32 	%r207, 32;
	sub.s32 	%r208, %r207, %r17;
	shr.u32 	%r209, %r592, %r208;
	shl.b32 	%r210, %r591, %r17;
	add.s32 	%r591, %r209, %r210;
	mul.wide.s32 	%rd88, %r14, 4;
	add.s64 	%rd89, %rd1, %rd88;
	ld.local.u32 	%r211, [%rd89];
	shr.u32 	%r212, %r211, %r208;
	shl.b32 	%r213, %r592, %r17;
	add.s32 	%r592, %r212, %r213;

$L__BB4_22:
	and.b32  	%r214, %r8, -2147483648;
	shr.u32 	%r215, %r592, 30;
	shl.b32 	%r216, %r591, 2;
	or.b32  	%r217, %r215, %r216;
	shr.u32 	%r218, %r217, 31;
	shr.u32 	%r219, %r591, 30;
	add.s32 	%r220, %r218, %r219;
	neg.s32 	%r221, %r220;
	setp.eq.s32 	%p22, %r214, 0;
	selp.b32 	%r593, %r220, %r221, %p22;
	setp.ne.s32 	%p23, %r218, 0;
	xor.b32  	%r222, %r214, -2147483648;
	selp.b32 	%r223, %r222, %r214, %p23;
	selp.b32 	%r224, -1, 0, %p23;
	xor.b32  	%r225, %r217, %r224;
	shl.b32 	%r226, %r592, 2;
	xor.b32  	%r227, %r226, %r224;
	cvt.u64.u32 	%rd90, %r225;
	cvt.u64.u32 	%rd91, %r227;
	bfi.b64 	%rd92, %rd90, %rd91, 32, 32;
	cvt.rn.f64.s64 	%fd213, %rd92;
	mul.rn.f64 	%fd214, %fd213, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f118, %fd214;
	setp.eq.s32 	%p24, %r223, 0;
	neg.f32 	%f119, %f118;
	selp.f32 	%f322, %f118, %f119, %p24;

$L__BB4_24:
	and.b32  	%r24, %r593, 1;
	setp.eq.s32 	%p25, %r24, 0;
	selp.f32 	%f12, %f322, 0f3F800000, %p25;
	mul.rn.f32 	%f13, %f322, %f322;
	mov.f32 	%f323, 0fB94D4153;
	@%p25 bra 	$L__BB4_26;

	mov.f32 	%f122, 0fBAB607ED;
	mov.f32 	%f123, 0f37CBAC00;
	fma.rn.f32 	%f323, %f123, %f13, %f122;

$L__BB4_26:
	selp.f32 	%f124, 0f3C0885E4, 0f3D2AAABB, %p25;
	fma.rn.f32 	%f125, %f323, %f13, %f124;
	selp.f32 	%f126, 0fBE2AAAA8, 0fBEFFFFFF, %p25;
	fma.rn.f32 	%f127, %f125, %f13, %f126;
	mov.f32 	%f128, 0f00000000;
	fma.rn.f32 	%f129, %f13, %f12, %f128;
	fma.rn.f32 	%f324, %f127, %f129, %f12;
	and.b32  	%r229, %r593, 2;
	setp.eq.s32 	%p27, %r229, 0;
	@%p27 bra 	$L__BB4_28;

	mov.f32 	%f131, 0fBF800000;
	fma.rn.f32 	%f324, %f324, %f131, %f128;

$L__BB4_28:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r230, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r231}, %fd30;
	}
	and.b32  	%r232, %r231, 2147483647;
	setp.eq.s32 	%p28, %r232, 2146435072;
	setp.eq.s32 	%p29, %r230, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB4_31;
	bra.uni 	$L__BB4_29;

$L__BB4_31:
	mov.f64 	%fd224, 0d0000000000000000;
	mul.rn.f64 	%fd478, %fd30, %fd224;
	mov.u32 	%r594, 0;
	bra.uni 	$L__BB4_32;

$L__BB4_29:
	mul.rn.f64 	%fd215, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r594, %fd215;
	st.local.u32 	[%rd1], %r594;
	cvt.rn.f64.s32 	%fd216, %r594;
	neg.f64 	%fd217, %fd216;
	mov.f64 	%fd218, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd219, %fd217, %fd218, %fd30;
	mov.f64 	%fd220, 0d3C91A62633145C00;
	fma.rn.f64 	%fd221, %fd217, %fd220, %fd219;
	mov.f64 	%fd222, 0d397B839A252049C0;
	fma.rn.f64 	%fd478, %fd217, %fd222, %fd221;
	abs.f64 	%fd223, %fd30;
	setp.ltu.f64 	%p31, %fd223, 0d41E0000000000000;
	@%p31 bra 	$L__BB4_32;

	add.u64 	%rd210, %SP, 0;
	{ // callseq 26, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd210;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd478, [retval0+0];
	} // callseq 26
	ld.local.u32 	%r594, [%rd1];

$L__BB4_32:
	mov.u64 	%rd211, __cudart_sin_cos_coeffs;
	and.b32  	%r234, %r594, 1;
	shl.b32 	%r235, %r594, 3;
	and.b32  	%r236, %r235, 8;
	setp.eq.s32 	%p32, %r234, 0;
	selp.f64 	%fd225, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd94, %r236, 8;
	add.s64 	%rd96, %rd211, %rd94;
	ld.global.nc.f64 	%fd226, [%rd96+8];
	mul.rn.f64 	%fd35, %fd478, %fd478;
	fma.rn.f64 	%fd227, %fd225, %fd35, %fd226;
	ld.global.nc.f64 	%fd228, [%rd96+16];
	fma.rn.f64 	%fd229, %fd227, %fd35, %fd228;
	ld.global.nc.f64 	%fd230, [%rd96+24];
	fma.rn.f64 	%fd231, %fd229, %fd35, %fd230;
	ld.global.nc.f64 	%fd232, [%rd96+32];
	fma.rn.f64 	%fd233, %fd231, %fd35, %fd232;
	ld.global.nc.f64 	%fd234, [%rd96+40];
	fma.rn.f64 	%fd235, %fd233, %fd35, %fd234;
	ld.global.nc.f64 	%fd236, [%rd96+48];
	fma.rn.f64 	%fd36, %fd235, %fd35, %fd236;
	fma.rn.f64 	%fd480, %fd36, %fd478, %fd478;
	@%p32 bra 	$L__BB4_34;

	mov.f64 	%fd237, 0d3FF0000000000000;
	fma.rn.f64 	%fd480, %fd36, %fd35, %fd237;

$L__BB4_34:
	and.b32  	%r237, %r594, 2;
	setp.eq.s32 	%p33, %r237, 0;
	@%p33 bra 	$L__BB4_36;

	mov.f64 	%fd238, 0d0000000000000000;
	mov.f64 	%fd239, 0dBFF0000000000000;
	fma.rn.f64 	%fd480, %fd480, %fd239, %fd238;

$L__BB4_36:
	mul.rn.f64 	%fd240, %fd480, 0d4044000000000000;
	cvt.f64.f32 	%fd241, %f324;
	mul.rn.f64 	%fd242, %fd241, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd242, %fd240;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r238, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r239}, %fd43;
	}
	and.b32  	%r240, %r239, 2147483647;
	setp.eq.s32 	%p34, %r240, 2146435072;
	setp.eq.s32 	%p35, %r238, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB4_39;
	bra.uni 	$L__BB4_37;

$L__BB4_39:
	mov.f64 	%fd252, 0d0000000000000000;
	mul.rn.f64 	%fd481, %fd43, %fd252;
	mov.u32 	%r595, 0;
	bra.uni 	$L__BB4_40;

$L__BB4_37:
	mul.rn.f64 	%fd243, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r595, %fd243;
	st.local.u32 	[%rd1], %r595;
	cvt.rn.f64.s32 	%fd244, %r595;
	neg.f64 	%fd245, %fd244;
	mov.f64 	%fd246, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd247, %fd245, %fd246, %fd43;
	mov.f64 	%fd248, 0d3C91A62633145C00;
	fma.rn.f64 	%fd249, %fd245, %fd248, %fd247;
	mov.f64 	%fd250, 0d397B839A252049C0;
	fma.rn.f64 	%fd481, %fd245, %fd250, %fd249;
	abs.f64 	%fd251, %fd43;
	setp.ltu.f64 	%p37, %fd251, 0d41E0000000000000;
	@%p37 bra 	$L__BB4_40;

	add.u64 	%rd187, %SP, 0;
	{ // callseq 27, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd187;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd481, [retval0+0];
	} // callseq 27
	ld.local.u32 	%r595, [%rd1];

$L__BB4_40:
	mov.u64 	%rd188, __cudart_sin_cos_coeffs;
	and.b32  	%r242, %r595, 1;
	shl.b32 	%r243, %r595, 3;
	and.b32  	%r244, %r243, 8;
	setp.eq.s32 	%p38, %r242, 0;
	selp.f64 	%fd253, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd98, %r244, 8;
	add.s64 	%rd100, %rd188, %rd98;
	ld.global.nc.f64 	%fd254, [%rd100+8];
	mul.rn.f64 	%fd48, %fd481, %fd481;
	fma.rn.f64 	%fd255, %fd253, %fd48, %fd254;
	ld.global.nc.f64 	%fd256, [%rd100+16];
	fma.rn.f64 	%fd257, %fd255, %fd48, %fd256;
	ld.global.nc.f64 	%fd258, [%rd100+24];
	fma.rn.f64 	%fd259, %fd257, %fd48, %fd258;
	ld.global.nc.f64 	%fd260, [%rd100+32];
	fma.rn.f64 	%fd261, %fd259, %fd48, %fd260;
	ld.global.nc.f64 	%fd262, [%rd100+40];
	fma.rn.f64 	%fd263, %fd261, %fd48, %fd262;
	ld.global.nc.f64 	%fd264, [%rd100+48];
	fma.rn.f64 	%fd49, %fd263, %fd48, %fd264;
	fma.rn.f64 	%fd483, %fd49, %fd481, %fd481;
	@%p38 bra 	$L__BB4_42;

	mov.f64 	%fd265, 0d3FF0000000000000;
	fma.rn.f64 	%fd483, %fd49, %fd48, %fd265;

$L__BB4_42:
	and.b32  	%r245, %r595, 2;
	setp.eq.s32 	%p39, %r245, 0;
	@%p39 bra 	$L__BB4_44;

	mov.f64 	%fd266, 0d0000000000000000;
	mov.f64 	%fd267, 0dBFF0000000000000;
	fma.rn.f64 	%fd483, %fd483, %fd267, %fd266;

$L__BB4_44:
	mul.rn.f64 	%fd268, %fd483, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd268;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r246, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd56;
	}
	and.b32  	%r248, %r247, 2147483647;
	setp.eq.s32 	%p40, %r248, 2146435072;
	setp.eq.s32 	%p41, %r246, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB4_47;
	bra.uni 	$L__BB4_45;

$L__BB4_47:
	mov.f64 	%fd278, 0d0000000000000000;
	mul.rn.f64 	%fd484, %fd56, %fd278;
	mov.u32 	%r596, 0;
	bra.uni 	$L__BB4_48;

$L__BB4_45:
	mul.rn.f64 	%fd269, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r596, %fd269;
	st.local.u32 	[%rd1], %r596;
	cvt.rn.f64.s32 	%fd270, %r596;
	neg.f64 	%fd271, %fd270;
	mov.f64 	%fd272, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd273, %fd271, %fd272, %fd56;
	mov.f64 	%fd274, 0d3C91A62633145C00;
	fma.rn.f64 	%fd275, %fd271, %fd274, %fd273;
	mov.f64 	%fd276, 0d397B839A252049C0;
	fma.rn.f64 	%fd484, %fd271, %fd276, %fd275;
	abs.f64 	%fd277, %fd56;
	setp.ltu.f64 	%p43, %fd277, 0d41E0000000000000;
	@%p43 bra 	$L__BB4_48;

	add.u64 	%rd189, %SP, 0;
	{ // callseq 28, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd189;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd484, [retval0+0];
	} // callseq 28
	ld.local.u32 	%r596, [%rd1];

$L__BB4_48:
	mov.u64 	%rd190, __cudart_sin_cos_coeffs;
	and.b32  	%r250, %r596, 1;
	shl.b32 	%r251, %r596, 3;
	and.b32  	%r252, %r251, 8;
	setp.eq.s32 	%p44, %r250, 0;
	selp.f64 	%fd279, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd102, %r252, 8;
	add.s64 	%rd104, %rd190, %rd102;
	ld.global.nc.f64 	%fd280, [%rd104+8];
	mul.rn.f64 	%fd61, %fd484, %fd484;
	fma.rn.f64 	%fd281, %fd279, %fd61, %fd280;
	ld.global.nc.f64 	%fd282, [%rd104+16];
	fma.rn.f64 	%fd283, %fd281, %fd61, %fd282;
	ld.global.nc.f64 	%fd284, [%rd104+24];
	fma.rn.f64 	%fd285, %fd283, %fd61, %fd284;
	ld.global.nc.f64 	%fd286, [%rd104+32];
	fma.rn.f64 	%fd287, %fd285, %fd61, %fd286;
	ld.global.nc.f64 	%fd288, [%rd104+40];
	fma.rn.f64 	%fd289, %fd287, %fd61, %fd288;
	ld.global.nc.f64 	%fd290, [%rd104+48];
	fma.rn.f64 	%fd62, %fd289, %fd61, %fd290;
	fma.rn.f64 	%fd486, %fd62, %fd484, %fd484;
	@%p44 bra 	$L__BB4_50;

	mov.f64 	%fd291, 0d3FF0000000000000;
	fma.rn.f64 	%fd486, %fd62, %fd61, %fd291;

$L__BB4_50:
	and.b32  	%r253, %r596, 2;
	setp.eq.s32 	%p45, %r253, 0;
	@%p45 bra 	$L__BB4_52;

	mov.f64 	%fd292, 0d0000000000000000;
	mov.f64 	%fd293, 0dBFF0000000000000;
	fma.rn.f64 	%fd486, %fd486, %fd293, %fd292;

$L__BB4_52:
	mul.rn.f64 	%fd294, %fd486, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd294;
	mul.rn.f32 	%f132, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r600, %f132;
	cvt.rn.f32.s32 	%f133, %r600;
	mov.f32 	%f134, 0fBFC90FDA;
	fma.rn.f32 	%f135, %f133, %f134, %f5;
	mov.f32 	%f136, 0fB3A22168;
	fma.rn.f32 	%f137, %f133, %f136, %f135;
	mov.f32 	%f138, 0fA7C234C5;
	fma.rn.f32 	%f325, %f133, %f138, %f137;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p46, %f20, 0f47CE4780;
	@%p46 bra 	$L__BB4_60;

	setp.eq.f32 	%p47, %f20, 0f7F800000;
	@%p47 bra 	$L__BB4_59;
	bra.uni 	$L__BB4_54;

$L__BB4_59:
	mov.f32 	%f141, 0f00000000;
	mul.rn.f32 	%f325, %f5, %f141;
	mov.u32 	%r600, 0;
	bra.uni 	$L__BB4_60;

$L__BB4_54:
	mov.b32 	%r35, %f5;
	bfe.u32 	%r255, %r35, 23, 8;
	add.s32 	%r36, %r255, -128;
	shl.b32 	%r256, %r35, 8;
	or.b32  	%r37, %r256, -2147483648;
	shr.u32 	%r38, %r36, 5;
	mov.u64 	%rd217, 0;
	mov.u32 	%r597, 0;
	mov.u64 	%rd216, __cudart_i2opi_f;
	mov.u64 	%rd215, %rd1;

$L__BB4_55:
	.pragma "nounroll";
	ld.global.nc.u32 	%r257, [%rd216];
	mad.wide.u32 	%rd107, %r257, %r37, %rd217;
	shr.u64 	%rd217, %rd107, 32;
	st.local.u32 	[%rd215], %rd107;
	add.s64 	%rd216, %rd216, 4;
	add.s64 	%rd215, %rd215, 4;
	add.s32 	%r597, %r597, 1;
	setp.ne.s32 	%p48, %r597, 6;
	@%p48 bra 	$L__BB4_55;

	add.s64 	%rd191, %rd1, 24;
	st.local.u32 	[%rd191], %rd217;
	mov.u32 	%r258, 4;
	sub.s32 	%r41, %r258, %r38;
	mov.u32 	%r259, 6;
	sub.s32 	%r260, %r259, %r38;
	mul.wide.s32 	%rd108, %r260, 4;
	add.s64 	%rd109, %rd1, %rd108;
	ld.local.u32 	%r598, [%rd109];
	ld.local.u32 	%r599, [%rd109+-4];
	and.b32  	%r44, %r36, 31;
	setp.eq.s32 	%p49, %r44, 0;
	@%p49 bra 	$L__BB4_58;

	mov.u32 	%r261, 32;
	sub.s32 	%r262, %r261, %r44;
	shr.u32 	%r263, %r599, %r262;
	shl.b32 	%r264, %r598, %r44;
	add.s32 	%r598, %r263, %r264;
	mul.wide.s32 	%rd110, %r41, 4;
	add.s64 	%rd111, %rd1, %rd110;
	ld.local.u32 	%r265, [%rd111];
	shr.u32 	%r266, %r265, %r262;
	shl.b32 	%r267, %r599, %r44;
	add.s32 	%r599, %r266, %r267;

$L__BB4_58:
	and.b32  	%r268, %r35, -2147483648;
	shr.u32 	%r269, %r599, 30;
	shl.b32 	%r270, %r598, 2;
	or.b32  	%r271, %r269, %r270;
	shr.u32 	%r272, %r271, 31;
	shr.u32 	%r273, %r598, 30;
	add.s32 	%r274, %r272, %r273;
	neg.s32 	%r275, %r274;
	setp.eq.s32 	%p50, %r268, 0;
	selp.b32 	%r600, %r274, %r275, %p50;
	setp.ne.s32 	%p51, %r272, 0;
	xor.b32  	%r276, %r268, -2147483648;
	selp.b32 	%r277, %r276, %r268, %p51;
	selp.b32 	%r278, -1, 0, %p51;
	xor.b32  	%r279, %r271, %r278;
	shl.b32 	%r280, %r599, 2;
	xor.b32  	%r281, %r280, %r278;
	cvt.u64.u32 	%rd112, %r279;
	cvt.u64.u32 	%rd113, %r281;
	bfi.b64 	%rd114, %rd112, %rd113, 32, 32;
	cvt.rn.f64.s64 	%fd295, %rd114;
	mul.rn.f64 	%fd296, %fd295, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f139, %fd296;
	setp.eq.s32 	%p52, %r277, 0;
	neg.f32 	%f140, %f139;
	selp.f32 	%f325, %f139, %f140, %p52;

$L__BB4_60:
	cvt.rn.f32.f64 	%f143, %fd28;
	cvt.f64.f32 	%fd69, %f143;
	and.b32  	%r51, %r600, 1;
	setp.eq.s32 	%p53, %r51, 0;
	selp.f32 	%f24, %f325, 0f3F800000, %p53;
	mul.rn.f32 	%f25, %f325, %f325;
	mov.f32 	%f326, 0fB94D4153;
	@%p53 bra 	$L__BB4_62;

	mov.f32 	%f144, 0fBAB607ED;
	mov.f32 	%f145, 0f37CBAC00;
	fma.rn.f32 	%f326, %f145, %f25, %f144;

$L__BB4_62:
	selp.f32 	%f146, 0f3C0885E4, 0f3D2AAABB, %p53;
	fma.rn.f32 	%f147, %f326, %f25, %f146;
	selp.f32 	%f148, 0fBE2AAAA8, 0fBEFFFFFF, %p53;
	fma.rn.f32 	%f149, %f147, %f25, %f148;
	mov.f32 	%f150, 0f00000000;
	fma.rn.f32 	%f151, %f25, %f24, %f150;
	fma.rn.f32 	%f327, %f149, %f151, %f24;
	and.b32  	%r283, %r600, 2;
	setp.eq.s32 	%p55, %r283, 0;
	@%p55 bra 	$L__BB4_64;

	mov.f32 	%f153, 0fBF800000;
	fma.rn.f32 	%f327, %f327, %f153, %f150;

$L__BB4_64:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r285}, %fd70;
	}
	and.b32  	%r286, %r285, 2147483647;
	setp.eq.s32 	%p56, %r286, 2146435072;
	setp.eq.s32 	%p57, %r284, 0;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB4_67;
	bra.uni 	$L__BB4_65;

$L__BB4_67:
	mov.f64 	%fd306, 0d0000000000000000;
	mul.rn.f64 	%fd487, %fd70, %fd306;
	mov.u32 	%r601, 0;
	bra.uni 	$L__BB4_68;

$L__BB4_65:
	mul.rn.f64 	%fd297, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r601, %fd297;
	st.local.u32 	[%rd1], %r601;
	cvt.rn.f64.s32 	%fd298, %r601;
	neg.f64 	%fd299, %fd298;
	mov.f64 	%fd300, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd301, %fd299, %fd300, %fd70;
	mov.f64 	%fd302, 0d3C91A62633145C00;
	fma.rn.f64 	%fd303, %fd299, %fd302, %fd301;
	mov.f64 	%fd304, 0d397B839A252049C0;
	fma.rn.f64 	%fd487, %fd299, %fd304, %fd303;
	abs.f64 	%fd305, %fd70;
	setp.ltu.f64 	%p59, %fd305, 0d41E0000000000000;
	@%p59 bra 	$L__BB4_68;

	add.u64 	%rd192, %SP, 0;
	{ // callseq 29, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd192;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd487, [retval0+0];
	} // callseq 29
	ld.local.u32 	%r601, [%rd1];

$L__BB4_68:
	mov.u64 	%rd193, __cudart_sin_cos_coeffs;
	and.b32  	%r288, %r601, 1;
	shl.b32 	%r289, %r601, 3;
	and.b32  	%r290, %r289, 8;
	setp.eq.s32 	%p60, %r288, 0;
	selp.f64 	%fd307, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p60;
	mul.wide.s32 	%rd116, %r290, 8;
	add.s64 	%rd118, %rd193, %rd116;
	ld.global.nc.f64 	%fd308, [%rd118+8];
	mul.rn.f64 	%fd75, %fd487, %fd487;
	fma.rn.f64 	%fd309, %fd307, %fd75, %fd308;
	ld.global.nc.f64 	%fd310, [%rd118+16];
	fma.rn.f64 	%fd311, %fd309, %fd75, %fd310;
	ld.global.nc.f64 	%fd312, [%rd118+24];
	fma.rn.f64 	%fd313, %fd311, %fd75, %fd312;
	ld.global.nc.f64 	%fd314, [%rd118+32];
	fma.rn.f64 	%fd315, %fd313, %fd75, %fd314;
	ld.global.nc.f64 	%fd316, [%rd118+40];
	fma.rn.f64 	%fd317, %fd315, %fd75, %fd316;
	ld.global.nc.f64 	%fd318, [%rd118+48];
	fma.rn.f64 	%fd76, %fd317, %fd75, %fd318;
	fma.rn.f64 	%fd489, %fd76, %fd487, %fd487;
	@%p60 bra 	$L__BB4_70;

	mov.f64 	%fd319, 0d3FF0000000000000;
	fma.rn.f64 	%fd489, %fd76, %fd75, %fd319;

$L__BB4_70:
	and.b32  	%r291, %r601, 2;
	setp.eq.s32 	%p61, %r291, 0;
	@%p61 bra 	$L__BB4_72;

	mov.f64 	%fd320, 0d0000000000000000;
	mov.f64 	%fd321, 0dBFF0000000000000;
	fma.rn.f64 	%fd489, %fd489, %fd321, %fd320;

$L__BB4_72:
	mul.rn.f64 	%fd322, %fd489, 0d4044000000000000;
	cvt.f64.f32 	%fd323, %f327;
	mul.rn.f64 	%fd324, %fd323, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd324, %fd322;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r293}, %fd83;
	}
	and.b32  	%r294, %r293, 2147483647;
	setp.eq.s32 	%p62, %r294, 2146435072;
	setp.eq.s32 	%p63, %r292, 0;
	and.pred  	%p64, %p63, %p62;
	@%p64 bra 	$L__BB4_75;
	bra.uni 	$L__BB4_73;

$L__BB4_75:
	mov.f64 	%fd334, 0d0000000000000000;
	mul.rn.f64 	%fd490, %fd83, %fd334;
	mov.u32 	%r602, 0;
	bra.uni 	$L__BB4_76;

$L__BB4_73:
	mul.rn.f64 	%fd325, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r602, %fd325;
	st.local.u32 	[%rd1], %r602;
	cvt.rn.f64.s32 	%fd326, %r602;
	neg.f64 	%fd327, %fd326;
	mov.f64 	%fd328, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd329, %fd327, %fd328, %fd83;
	mov.f64 	%fd330, 0d3C91A62633145C00;
	fma.rn.f64 	%fd331, %fd327, %fd330, %fd329;
	mov.f64 	%fd332, 0d397B839A252049C0;
	fma.rn.f64 	%fd490, %fd327, %fd332, %fd331;
	abs.f64 	%fd333, %fd83;
	setp.ltu.f64 	%p65, %fd333, 0d41E0000000000000;
	@%p65 bra 	$L__BB4_76;

	add.u64 	%rd194, %SP, 0;
	{ // callseq 30, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd194;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd490, [retval0+0];
	} // callseq 30
	ld.local.u32 	%r602, [%rd1];

$L__BB4_76:
	mov.u64 	%rd195, __cudart_sin_cos_coeffs;
	and.b32  	%r296, %r602, 1;
	shl.b32 	%r297, %r602, 3;
	and.b32  	%r298, %r297, 8;
	setp.eq.s32 	%p66, %r296, 0;
	selp.f64 	%fd335, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p66;
	mul.wide.s32 	%rd120, %r298, 8;
	add.s64 	%rd122, %rd195, %rd120;
	ld.global.nc.f64 	%fd336, [%rd122+8];
	mul.rn.f64 	%fd88, %fd490, %fd490;
	fma.rn.f64 	%fd337, %fd335, %fd88, %fd336;
	ld.global.nc.f64 	%fd338, [%rd122+16];
	fma.rn.f64 	%fd339, %fd337, %fd88, %fd338;
	ld.global.nc.f64 	%fd340, [%rd122+24];
	fma.rn.f64 	%fd341, %fd339, %fd88, %fd340;
	ld.global.nc.f64 	%fd342, [%rd122+32];
	fma.rn.f64 	%fd343, %fd341, %fd88, %fd342;
	ld.global.nc.f64 	%fd344, [%rd122+40];
	fma.rn.f64 	%fd345, %fd343, %fd88, %fd344;
	ld.global.nc.f64 	%fd346, [%rd122+48];
	fma.rn.f64 	%fd89, %fd345, %fd88, %fd346;
	fma.rn.f64 	%fd492, %fd89, %fd490, %fd490;
	@%p66 bra 	$L__BB4_78;

	mov.f64 	%fd347, 0d3FF0000000000000;
	fma.rn.f64 	%fd492, %fd89, %fd88, %fd347;

$L__BB4_78:
	and.b32  	%r299, %r602, 2;
	setp.eq.s32 	%p67, %r299, 0;
	@%p67 bra 	$L__BB4_80;

	mov.f64 	%fd348, 0d0000000000000000;
	mov.f64 	%fd349, 0dBFF0000000000000;
	fma.rn.f64 	%fd492, %fd492, %fd349, %fd348;

$L__BB4_80:
	mul.rn.f64 	%fd350, %fd492, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd350;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r300, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r301}, %fd96;
	}
	and.b32  	%r302, %r301, 2147483647;
	setp.eq.s32 	%p68, %r302, 2146435072;
	setp.eq.s32 	%p69, %r300, 0;
	and.pred  	%p70, %p69, %p68;
	@%p70 bra 	$L__BB4_83;
	bra.uni 	$L__BB4_81;

$L__BB4_83:
	mov.f64 	%fd360, 0d0000000000000000;
	mul.rn.f64 	%fd493, %fd96, %fd360;
	mov.u32 	%r603, 0;
	bra.uni 	$L__BB4_84;

$L__BB4_81:
	mul.rn.f64 	%fd351, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r603, %fd351;
	st.local.u32 	[%rd1], %r603;
	cvt.rn.f64.s32 	%fd352, %r603;
	neg.f64 	%fd353, %fd352;
	mov.f64 	%fd354, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd355, %fd353, %fd354, %fd96;
	mov.f64 	%fd356, 0d3C91A62633145C00;
	fma.rn.f64 	%fd357, %fd353, %fd356, %fd355;
	mov.f64 	%fd358, 0d397B839A252049C0;
	fma.rn.f64 	%fd493, %fd353, %fd358, %fd357;
	abs.f64 	%fd359, %fd96;
	setp.ltu.f64 	%p71, %fd359, 0d41E0000000000000;
	@%p71 bra 	$L__BB4_84;

	add.u64 	%rd196, %SP, 0;
	{ // callseq 31, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd196;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd493, [retval0+0];
	} // callseq 31
	ld.local.u32 	%r603, [%rd1];

$L__BB4_84:
	mov.u64 	%rd197, __cudart_sin_cos_coeffs;
	and.b32  	%r304, %r603, 1;
	shl.b32 	%r305, %r603, 3;
	and.b32  	%r306, %r305, 8;
	setp.eq.s32 	%p72, %r304, 0;
	selp.f64 	%fd361, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p72;
	mul.wide.s32 	%rd124, %r306, 8;
	add.s64 	%rd126, %rd197, %rd124;
	ld.global.nc.f64 	%fd362, [%rd126+8];
	mul.rn.f64 	%fd101, %fd493, %fd493;
	fma.rn.f64 	%fd363, %fd361, %fd101, %fd362;
	ld.global.nc.f64 	%fd364, [%rd126+16];
	fma.rn.f64 	%fd365, %fd363, %fd101, %fd364;
	ld.global.nc.f64 	%fd366, [%rd126+24];
	fma.rn.f64 	%fd367, %fd365, %fd101, %fd366;
	ld.global.nc.f64 	%fd368, [%rd126+32];
	fma.rn.f64 	%fd369, %fd367, %fd101, %fd368;
	ld.global.nc.f64 	%fd370, [%rd126+40];
	fma.rn.f64 	%fd371, %fd369, %fd101, %fd370;
	ld.global.nc.f64 	%fd372, [%rd126+48];
	fma.rn.f64 	%fd102, %fd371, %fd101, %fd372;
	fma.rn.f64 	%fd495, %fd102, %fd493, %fd493;
	@%p72 bra 	$L__BB4_86;

	mov.f64 	%fd373, 0d3FF0000000000000;
	fma.rn.f64 	%fd495, %fd102, %fd101, %fd373;

$L__BB4_86:
	and.b32  	%r307, %r603, 2;
	setp.eq.s32 	%p73, %r307, 0;
	@%p73 bra 	$L__BB4_88;

	mov.f64 	%fd374, 0d0000000000000000;
	mov.f64 	%fd375, 0dBFF0000000000000;
	fma.rn.f64 	%fd495, %fd495, %fd375, %fd374;

$L__BB4_88:
	mul.rn.f64 	%fd376, %fd495, 0d4072C00000000000;
	add.rn.f64 	%fd377, %fd95, %fd376;
	add.rn.f64 	%fd108, %fd377, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd378, %fd1, %fd1;
	mov.f64 	%fd379, 0d4000000000000000;
	add.rn.f64 	%fd380, %fd378, 0dC059000000000000;
	mul.rn.f64 	%fd381, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd380, %fd381;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd379;
	}
	and.b32  	%r62, %r61, 2146435072;
	setp.eq.s32 	%p74, %r62, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 32, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd498, [retval0+0];
	} // callseq 32
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd2;
	}
	setp.lt.s32 	%p75, %r63, 0;
	and.pred  	%p1, %p75, %p74;
	not.pred 	%p76, %p1;
	@%p76 bra 	$L__BB4_90;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r308}, %fd498;
	}
	xor.b32  	%r309, %r308, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r310, %temp}, %fd498;
	}
	mov.b64 	%fd498, {%r310, %r309};

$L__BB4_90:
	add.rn.f32 	%f315, %f3, 0fC20C0000;
	setp.eq.f32 	%p77, %f315, 0f00000000;
	@%p77 bra 	$L__BB4_94;
	bra.uni 	$L__BB4_91;

$L__BB4_94:
	selp.b32 	%r311, %r63, 0, %p74;
	mov.u32 	%r312, 0;
	or.b32  	%r313, %r311, 2146435072;
	setp.lt.s32 	%p81, %r61, 0;
	selp.b32 	%r314, %r313, %r311, %p81;
	mov.b64 	%fd498, {%r312, %r314};
	bra.uni 	$L__BB4_95;

$L__BB4_91:
	setp.gt.s32 	%p78, %r63, -1;
	@%p78 bra 	$L__BB4_95;

	mov.f64 	%fd382, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd383, %fd382;
	setp.eq.f64 	%p79, %fd383, 0d4000000000000000;
	@%p79 bra 	$L__BB4_95;

	mov.f64 	%fd498, 0dFFF8000000000000;

$L__BB4_95:
	add.rn.f64 	%fd385, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r315}, %fd385;
	}
	and.b32  	%r316, %r315, 2146435072;
	setp.ne.s32 	%p82, %r316, 2146435072;
	@%p82 bra 	$L__BB4_102;

	setp.gtu.f64 	%p83, %fd111, 0d7FF0000000000000;
	@%p83 bra 	$L__BB4_101;
	bra.uni 	$L__BB4_97;

$L__BB4_101:
	mov.f64 	%fd387, 0d4000000000000000;
	add.rn.f64 	%fd498, %fd2, %fd387;
	bra.uni 	$L__BB4_102;

$L__BB4_97:
	mov.f64 	%fd386, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r317, %temp}, %fd386;
	}
	and.b32  	%r64, %r61, 2147483647;
	setp.eq.s32 	%p84, %r64, 2146435072;
	setp.eq.s32 	%p85, %r317, 0;
	and.pred  	%p86, %p84, %p85;
	@%p86 bra 	$L__BB4_100;
	bra.uni 	$L__BB4_98;

$L__BB4_100:
	add.rn.f32 	%f317, %f3, 0fC20C0000;
	setp.gt.f64 	%p93, %fd111, 0d3FF0000000000000;
	selp.b32 	%r324, 2146435072, 0, %p93;
	mov.u32 	%r325, 0;
	xor.b32  	%r326, %r324, 2146435072;
	setp.lt.s32 	%p94, %r61, 0;
	selp.b32 	%r327, %r326, %r324, %p94;
	setp.eq.f32 	%p95, %f317, 0fBF800000;
	selp.b32 	%r328, 1072693248, %r327, %p95;
	mov.b64 	%fd498, {%r325, %r328};
	bra.uni 	$L__BB4_102;

$L__BB4_98:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r318, %temp}, %fd2;
	}
	and.b32  	%r319, %r63, 2147483647;
	setp.ne.s32 	%p87, %r319, 2146435072;
	setp.ne.s32 	%p88, %r318, 0;
	or.pred  	%p89, %p87, %p88;
	@%p89 bra 	$L__BB4_102;

	setp.gt.s32 	%p90, %r61, -1;
	selp.b32 	%r320, 2146435072, 0, %p90;
	mov.u32 	%r321, 0;
	setp.ne.s32 	%p91, %r64, 1071644672;
	and.pred  	%p92, %p91, %p1;
	or.b32  	%r322, %r320, -2147483648;
	selp.b32 	%r323, %r322, %r320, %p92;
	mov.b64 	%fd498, {%r321, %r323};

$L__BB4_102:
	add.rn.f32 	%f318, %f1, 0fC2D20000;
	add.rn.f32 	%f316, %f3, 0fC20C0000;
	mul.rn.f64 	%fd388, %fd498, 0d3FC999999999999A;
	setp.eq.f32 	%p96, %f316, 0f3F800000;
	selp.f64 	%fd389, 0d3FC999999999999A, %fd388, %p96;
	add.rn.f64 	%fd390, %fd110, %fd389;
	mul.rn.f32 	%f154, %f318, %f316;
	cvt.f64.f32 	%fd391, %f154;
	mul.rn.f64 	%fd121, %fd391, 0d3FB999999999999A;
	add.rn.f64 	%fd392, %fd121, %fd390;
	abs.f32 	%f155, %f318;
	sqrt.rn.f32 	%f156, %f155;
	cvt.f64.f32 	%fd122, %f156;
	mul.rn.f64 	%fd393, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd394, %fd393, %fd392;
	cvt.rn.f32.f64 	%f157, %fd109;
	cvt.f64.f32 	%fd395, %f157;
	mul.rn.f64 	%fd396, %fd395, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f158, %fd396;
	cvt.f64.f32 	%fd397, %f158;
	add.rn.f64 	%fd123, %fd394, %fd397;
	add.rn.f64 	%fd398, %fd2, %fd2;
	add.rn.f64 	%fd399, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd399, %fd398;
	abs.f64 	%fd125, %fd1;
	{ // callseq 33, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd501, [retval0+0];
	} // callseq 33
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd1;
	}
	setp.lt.s32 	%p97, %r65, 0;
	and.pred  	%p2, %p97, %p74;
	not.pred 	%p99, %p2;
	@%p99 bra 	$L__BB4_104;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r329}, %fd501;
	}
	xor.b32  	%r330, %r329, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r331, %temp}, %fd501;
	}
	mov.b64 	%fd501, {%r331, %r330};

$L__BB4_104:
	add.rn.f32 	%f319, %f1, 0fC2D20000;
	setp.eq.f32 	%p100, %f319, 0f00000000;
	@%p100 bra 	$L__BB4_108;
	bra.uni 	$L__BB4_105;

$L__BB4_108:
	selp.b32 	%r332, %r65, 0, %p74;
	mov.u32 	%r333, 0;
	or.b32  	%r334, %r332, 2146435072;
	setp.lt.s32 	%p104, %r61, 0;
	selp.b32 	%r335, %r334, %r332, %p104;
	mov.b64 	%fd501, {%r333, %r335};
	bra.uni 	$L__BB4_109;

$L__BB4_105:
	setp.gt.s32 	%p101, %r65, -1;
	@%p101 bra 	$L__BB4_109;

	mov.f64 	%fd400, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd401, %fd400;
	setp.eq.f64 	%p102, %fd401, 0d4000000000000000;
	@%p102 bra 	$L__BB4_109;

	mov.f64 	%fd501, 0dFFF8000000000000;

$L__BB4_109:
	add.rn.f64 	%fd403, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd403;
	}
	and.b32  	%r337, %r336, 2146435072;
	setp.ne.s32 	%p105, %r337, 2146435072;
	@%p105 bra 	$L__BB4_116;

	setp.gtu.f64 	%p106, %fd125, 0d7FF0000000000000;
	@%p106 bra 	$L__BB4_115;
	bra.uni 	$L__BB4_111;

$L__BB4_115:
	mov.f64 	%fd405, 0d4000000000000000;
	add.rn.f64 	%fd501, %fd1, %fd405;
	bra.uni 	$L__BB4_116;

$L__BB4_111:
	mov.f64 	%fd404, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd404;
	}
	and.b32  	%r66, %r61, 2147483647;
	setp.eq.s32 	%p107, %r66, 2146435072;
	setp.eq.s32 	%p108, %r338, 0;
	and.pred  	%p109, %p107, %p108;
	@%p109 bra 	$L__BB4_114;
	bra.uni 	$L__BB4_112;

$L__BB4_114:
	add.rn.f32 	%f321, %f1, 0fC2D20000;
	setp.gt.f64 	%p116, %fd125, 0d3FF0000000000000;
	selp.b32 	%r345, 2146435072, 0, %p116;
	mov.u32 	%r346, 0;
	xor.b32  	%r347, %r345, 2146435072;
	setp.lt.s32 	%p117, %r61, 0;
	selp.b32 	%r348, %r347, %r345, %p117;
	setp.eq.f32 	%p118, %f321, 0fBF800000;
	selp.b32 	%r349, 1072693248, %r348, %p118;
	mov.b64 	%fd501, {%r346, %r349};
	bra.uni 	$L__BB4_116;

$L__BB4_112:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd1;
	}
	and.b32  	%r340, %r65, 2147483647;
	setp.ne.s32 	%p110, %r340, 2146435072;
	setp.ne.s32 	%p111, %r339, 0;
	or.pred  	%p112, %p110, %p111;
	@%p112 bra 	$L__BB4_116;

	setp.gt.s32 	%p113, %r61, -1;
	selp.b32 	%r341, 2146435072, 0, %p113;
	mov.u32 	%r342, 0;
	setp.ne.s32 	%p114, %r66, 1071644672;
	and.pred  	%p115, %p114, %p2;
	or.b32  	%r343, %r341, -2147483648;
	selp.b32 	%r344, %r343, %r341, %p115;
	mov.b64 	%fd501, {%r342, %r344};

$L__BB4_116:
	add.rn.f32 	%f320, %f1, 0fC2D20000;
	mul.rn.f64 	%fd406, %fd501, 0d3FB999999999999A;
	setp.eq.f32 	%p119, %f320, 0f3F800000;
	selp.f64 	%fd407, 0d3FB999999999999A, %fd406, %p119;
	add.rn.f64 	%fd408, %fd124, %fd407;
	add.rn.f64 	%fd409, %fd121, %fd408;
	mul.rn.f64 	%fd410, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd411, %fd410, %fd409;
	cvt.rn.f32.f64 	%f159, %fd108;
	cvt.f64.f32 	%fd412, %f159;
	mul.rn.f64 	%fd413, %fd412, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f160, %fd413;
	cvt.f64.f32 	%fd414, %f160;
	add.rn.f64 	%fd135, %fd411, %fd414;
	cvt.f64.f32 	%fd415, %f3;
	div.rn.f64 	%fd416, %fd415, 0d4066800000000000;
	mul.rn.f64 	%fd417, %fd416, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd417;
	mul.rn.f32 	%f161, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r611, %f161;
	cvt.rn.f32.s32 	%f162, %r611;
	mov.f32 	%f163, 0fBFC90FDA;
	fma.rn.f32 	%f164, %f162, %f163, %f31;
	mov.f32 	%f165, 0fB3A22168;
	fma.rn.f32 	%f166, %f162, %f165, %f164;
	mov.f32 	%f167, 0fA7C234C5;
	fma.rn.f32 	%f331, %f162, %f167, %f166;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p120, %f33, 0f47CE4780;
	mov.u32 	%r607, %r611;
	mov.f32 	%f328, %f331;
	@%p120 bra 	$L__BB4_124;

	setp.eq.f32 	%p121, %f33, 0f7F800000;
	@%p121 bra 	$L__BB4_123;
	bra.uni 	$L__BB4_118;

$L__BB4_123:
	mov.f32 	%f170, 0f00000000;
	mul.rn.f32 	%f328, %f31, %f170;
	mov.u32 	%r607, 0;
	bra.uni 	$L__BB4_124;

$L__BB4_118:
	mov.b32 	%r68, %f31;
	bfe.u32 	%r351, %r68, 23, 8;
	add.s32 	%r69, %r351, -128;
	shl.b32 	%r352, %r68, 8;
	or.b32  	%r70, %r352, -2147483648;
	shr.u32 	%r71, %r69, 5;
	mov.u64 	%rd220, 0;
	mov.u32 	%r604, 0;
	mov.u64 	%rd219, __cudart_i2opi_f;
	mov.u64 	%rd218, %rd1;

$L__BB4_119:
	.pragma "nounroll";
	ld.global.nc.u32 	%r353, [%rd219];
	mad.wide.u32 	%rd129, %r353, %r70, %rd220;
	shr.u64 	%rd220, %rd129, 32;
	st.local.u32 	[%rd218], %rd129;
	add.s64 	%rd219, %rd219, 4;
	add.s64 	%rd218, %rd218, 4;
	add.s32 	%r604, %r604, 1;
	setp.ne.s32 	%p122, %r604, 6;
	@%p122 bra 	$L__BB4_119;

	add.s64 	%rd198, %rd1, 24;
	st.local.u32 	[%rd198], %rd220;
	mov.u32 	%r354, 4;
	sub.s32 	%r74, %r354, %r71;
	mov.u32 	%r355, 6;
	sub.s32 	%r356, %r355, %r71;
	mul.wide.s32 	%rd130, %r356, 4;
	add.s64 	%rd131, %rd1, %rd130;
	ld.local.u32 	%r605, [%rd131];
	ld.local.u32 	%r606, [%rd131+-4];
	and.b32  	%r77, %r69, 31;
	setp.eq.s32 	%p123, %r77, 0;
	@%p123 bra 	$L__BB4_122;

	mov.u32 	%r357, 32;
	sub.s32 	%r358, %r357, %r77;
	shr.u32 	%r359, %r606, %r358;
	shl.b32 	%r360, %r605, %r77;
	add.s32 	%r605, %r359, %r360;
	mul.wide.s32 	%rd132, %r74, 4;
	add.s64 	%rd133, %rd1, %rd132;
	ld.local.u32 	%r361, [%rd133];
	shr.u32 	%r362, %r361, %r358;
	shl.b32 	%r363, %r606, %r77;
	add.s32 	%r606, %r362, %r363;

$L__BB4_122:
	and.b32  	%r364, %r68, -2147483648;
	shr.u32 	%r365, %r606, 30;
	shl.b32 	%r366, %r605, 2;
	or.b32  	%r367, %r365, %r366;
	shr.u32 	%r368, %r367, 31;
	shr.u32 	%r369, %r605, 30;
	add.s32 	%r370, %r368, %r369;
	neg.s32 	%r371, %r370;
	setp.eq.s32 	%p124, %r364, 0;
	selp.b32 	%r607, %r370, %r371, %p124;
	setp.ne.s32 	%p125, %r368, 0;
	xor.b32  	%r372, %r364, -2147483648;
	selp.b32 	%r373, %r372, %r364, %p125;
	selp.b32 	%r374, -1, 0, %p125;
	xor.b32  	%r375, %r367, %r374;
	shl.b32 	%r376, %r606, 2;
	xor.b32  	%r377, %r376, %r374;
	cvt.u64.u32 	%rd134, %r375;
	cvt.u64.u32 	%rd135, %r377;
	bfi.b64 	%rd136, %rd134, %rd135, 32, 32;
	cvt.rn.f64.s64 	%fd418, %rd136;
	mul.rn.f64 	%fd419, %fd418, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f168, %fd419;
	setp.eq.s32 	%p126, %r373, 0;
	neg.f32 	%f169, %f168;
	selp.f32 	%f328, %f168, %f169, %p126;

$L__BB4_124:
	and.b32  	%r84, %r607, 1;
	setp.eq.s32 	%p127, %r84, 0;
	selp.f32 	%f37, %f328, 0f3F800000, %p127;
	mul.rn.f32 	%f38, %f328, %f328;
	mov.f32 	%f329, 0fB94D4153;
	@%p127 bra 	$L__BB4_126;

	mov.f32 	%f172, 0fBAB607ED;
	mov.f32 	%f173, 0f37CBAC00;
	fma.rn.f32 	%f329, %f173, %f38, %f172;

$L__BB4_126:
	selp.f32 	%f174, 0f3C0885E4, 0f3D2AAABB, %p127;
	fma.rn.f32 	%f175, %f329, %f38, %f174;
	selp.f32 	%f176, 0fBE2AAAA8, 0fBEFFFFFF, %p127;
	fma.rn.f32 	%f177, %f175, %f38, %f176;
	mov.f32 	%f178, 0f00000000;
	fma.rn.f32 	%f179, %f38, %f37, %f178;
	fma.rn.f32 	%f330, %f177, %f179, %f37;
	and.b32  	%r379, %r607, 2;
	setp.eq.s32 	%p129, %r379, 0;
	@%p129 bra 	$L__BB4_128;

	mov.f32 	%f181, 0fBF800000;
	fma.rn.f32 	%f330, %f330, %f181, %f178;

$L__BB4_128:
	@%p120 bra 	$L__BB4_136;

	setp.eq.f32 	%p131, %f33, 0f7F800000;
	@%p131 bra 	$L__BB4_135;
	bra.uni 	$L__BB4_130;

$L__BB4_135:
	mov.f32 	%f184, 0f00000000;
	mul.rn.f32 	%f331, %f31, %f184;
	mov.u32 	%r611, 0;
	bra.uni 	$L__BB4_136;

$L__BB4_130:
	mov.b32 	%r85, %f31;
	bfe.u32 	%r381, %r85, 23, 8;
	add.s32 	%r86, %r381, -128;
	shl.b32 	%r382, %r85, 8;
	or.b32  	%r87, %r382, -2147483648;
	shr.u32 	%r88, %r86, 5;
	mov.u64 	%rd223, 0;
	mov.u32 	%r608, 0;
	mov.u64 	%rd222, __cudart_i2opi_f;
	mov.u64 	%rd221, %rd1;

$L__BB4_131:
	.pragma "nounroll";
	ld.global.nc.u32 	%r383, [%rd222];
	mad.wide.u32 	%rd139, %r383, %r87, %rd223;
	shr.u64 	%rd223, %rd139, 32;
	st.local.u32 	[%rd221], %rd139;
	add.s64 	%rd222, %rd222, 4;
	add.s64 	%rd221, %rd221, 4;
	add.s32 	%r608, %r608, 1;
	setp.ne.s32 	%p132, %r608, 6;
	@%p132 bra 	$L__BB4_131;

	add.s64 	%rd199, %rd1, 24;
	st.local.u32 	[%rd199], %rd223;
	mov.u32 	%r384, 4;
	sub.s32 	%r91, %r384, %r88;
	mov.u32 	%r385, 6;
	sub.s32 	%r386, %r385, %r88;
	mul.wide.s32 	%rd140, %r386, 4;
	add.s64 	%rd141, %rd1, %rd140;
	ld.local.u32 	%r609, [%rd141];
	ld.local.u32 	%r610, [%rd141+-4];
	and.b32  	%r94, %r86, 31;
	setp.eq.s32 	%p133, %r94, 0;
	@%p133 bra 	$L__BB4_134;

	mov.u32 	%r387, 32;
	sub.s32 	%r388, %r387, %r94;
	shr.u32 	%r389, %r610, %r388;
	shl.b32 	%r390, %r609, %r94;
	add.s32 	%r609, %r389, %r390;
	mul.wide.s32 	%rd142, %r91, 4;
	add.s64 	%rd143, %rd1, %rd142;
	ld.local.u32 	%r391, [%rd143];
	shr.u32 	%r392, %r391, %r388;
	shl.b32 	%r393, %r610, %r94;
	add.s32 	%r610, %r392, %r393;

$L__BB4_134:
	and.b32  	%r394, %r85, -2147483648;
	shr.u32 	%r395, %r610, 30;
	shl.b32 	%r396, %r609, 2;
	or.b32  	%r397, %r395, %r396;
	shr.u32 	%r398, %r397, 31;
	shr.u32 	%r399, %r609, 30;
	add.s32 	%r400, %r398, %r399;
	neg.s32 	%r401, %r400;
	setp.eq.s32 	%p134, %r394, 0;
	selp.b32 	%r611, %r400, %r401, %p134;
	setp.ne.s32 	%p135, %r398, 0;
	xor.b32  	%r402, %r394, -2147483648;
	selp.b32 	%r403, %r402, %r394, %p135;
	selp.b32 	%r404, -1, 0, %p135;
	xor.b32  	%r405, %r397, %r404;
	shl.b32 	%r406, %r610, 2;
	xor.b32  	%r407, %r406, %r404;
	cvt.u64.u32 	%rd144, %r405;
	cvt.u64.u32 	%rd145, %r407;
	bfi.b64 	%rd146, %rd144, %rd145, 32, 32;
	cvt.rn.f64.s64 	%fd420, %rd146;
	mul.rn.f64 	%fd421, %fd420, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f182, %fd421;
	setp.eq.s32 	%p136, %r403, 0;
	neg.f32 	%f183, %f182;
	selp.f32 	%f331, %f182, %f183, %p136;

$L__BB4_136:
	add.s32 	%r101, %r611, 1;
	and.b32  	%r102, %r101, 1;
	setp.eq.s32 	%p3, %r102, 0;
	mul.rn.f32 	%f47, %f331, %f331;
	mov.f32 	%f332, 0fB94D4153;
	@%p3 bra 	$L__BB4_138;

	mov.f32 	%f186, 0fBAB607ED;
	mov.f32 	%f187, 0f37CBAC00;
	fma.rn.f32 	%f332, %f187, %f47, %f186;

$L__BB4_138:
	selp.f32 	%f188, %f331, 0f3F800000, %p3;
	selp.f32 	%f189, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f190, %f332, %f47, %f189;
	selp.f32 	%f191, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f192, %f190, %f47, %f191;
	mov.f32 	%f193, 0f00000000;
	fma.rn.f32 	%f194, %f47, %f188, %f193;
	fma.rn.f32 	%f333, %f192, %f194, %f188;
	and.b32  	%r409, %r101, 2;
	setp.eq.s32 	%p138, %r409, 0;
	@%p138 bra 	$L__BB4_140;

	mov.f32 	%f196, 0fBF800000;
	fma.rn.f32 	%f333, %f333, %f196, %f193;

$L__BB4_140:
	cvt.f64.f32 	%fd422, %f330;
	mul.rn.f64 	%fd423, %fd422, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd424, %fd423, %fd422;
	add.rn.f64 	%fd425, %fd424, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f197, %fd425;
	sqrt.rn.f32 	%f198, %f197;
	mov.f32 	%f199, 0f4AC2A60A;
	div.rn.f32 	%f200, %f199, %f198;
	mul.rn.f32 	%f201, %f200, %f333;
	cvt.f64.f32 	%fd426, %f201;
	mul.rn.f64 	%fd427, %fd426, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f202, %fd135;
	cvt.f64.f32 	%fd428, %f202;
	mul.rn.f64 	%fd429, %fd428, 0d4066800000000000;
	div.rn.f64 	%fd430, %fd429, %fd427;
	cvt.rn.f32.f64 	%f203, %fd430;
	add.rn.f32 	%f204, %f1, %f203;
	st.global.f32 	[%rd10], %f204;
	mul.rn.f32 	%f205, %f198, %f197;
	cvt.f64.f32 	%fd431, %f205;
	mov.f64 	%fd432, 0d41582B102DE355C1;
	div.rn.f64 	%fd433, %fd432, %fd431;
	mul.rn.f64 	%fd434, %fd433, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f206, %fd123;
	cvt.f64.f32 	%fd435, %f206;
	mul.rn.f64 	%fd436, %fd435, 0d4066800000000000;
	div.rn.f64 	%fd437, %fd436, %fd434;
	cvt.rn.f32.f64 	%f207, %fd437;
	add.rn.f32 	%f53, %f3, %f207;
	st.global.f32 	[%rd11], %f53;
	ld.global.f32 	%f54, [%rd10];
	cvt.f64.f32 	%fd136, %f54;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r103}, %fd136;
	}
	abs.f64 	%fd137, %fd136;
	{ // callseq 34, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd504, [retval0+0];
	} // callseq 34
	setp.lt.s32 	%p139, %r103, 0;
	and.pred  	%p4, %p139, %p74;
	not.pred 	%p141, %p4;
	@%p141 bra 	$L__BB4_142;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r410}, %fd504;
	}
	xor.b32  	%r411, %r410, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r412, %temp}, %fd504;
	}
	mov.b64 	%fd504, {%r412, %r411};

$L__BB4_142:
	setp.eq.f32 	%p142, %f54, 0f00000000;
	@%p142 bra 	$L__BB4_146;
	bra.uni 	$L__BB4_143;

$L__BB4_146:
	selp.b32 	%r413, %r103, 0, %p74;
	mov.u32 	%r414, 0;
	or.b32  	%r415, %r413, 2146435072;
	setp.lt.s32 	%p146, %r61, 0;
	selp.b32 	%r416, %r415, %r413, %p146;
	mov.b64 	%fd504, {%r414, %r416};
	bra.uni 	$L__BB4_147;

$L__BB4_143:
	setp.gt.s32 	%p143, %r103, -1;
	@%p143 bra 	$L__BB4_147;

	mov.f64 	%fd438, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd439, %fd438;
	setp.eq.f64 	%p144, %fd439, 0d4000000000000000;
	@%p144 bra 	$L__BB4_147;

	mov.f64 	%fd504, 0dFFF8000000000000;

$L__BB4_147:
	add.rn.f64 	%fd441, %fd136, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r417}, %fd441;
	}
	and.b32  	%r418, %r417, 2146435072;
	setp.ne.s32 	%p147, %r418, 2146435072;
	@%p147 bra 	$L__BB4_154;

	setp.gtu.f64 	%p148, %fd137, 0d7FF0000000000000;
	@%p148 bra 	$L__BB4_153;
	bra.uni 	$L__BB4_149;

$L__BB4_153:
	mov.f64 	%fd443, 0d4000000000000000;
	add.rn.f64 	%fd504, %fd136, %fd443;
	bra.uni 	$L__BB4_154;

$L__BB4_149:
	mov.f64 	%fd442, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r419, %temp}, %fd442;
	}
	and.b32  	%r104, %r61, 2147483647;
	setp.eq.s32 	%p149, %r104, 2146435072;
	setp.eq.s32 	%p150, %r419, 0;
	and.pred  	%p151, %p149, %p150;
	@%p151 bra 	$L__BB4_152;
	bra.uni 	$L__BB4_150;

$L__BB4_152:
	setp.gt.f64 	%p158, %fd137, 0d3FF0000000000000;
	selp.b32 	%r426, 2146435072, 0, %p158;
	mov.u32 	%r427, 0;
	xor.b32  	%r428, %r426, 2146435072;
	setp.lt.s32 	%p159, %r61, 0;
	selp.b32 	%r429, %r428, %r426, %p159;
	setp.eq.f32 	%p160, %f54, 0fBF800000;
	selp.b32 	%r430, 1072693248, %r429, %p160;
	mov.b64 	%fd504, {%r427, %r430};
	bra.uni 	$L__BB4_154;

$L__BB4_150:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r420, %temp}, %fd136;
	}
	and.b32  	%r421, %r103, 2147483647;
	setp.ne.s32 	%p152, %r421, 2146435072;
	setp.ne.s32 	%p153, %r420, 0;
	or.pred  	%p154, %p152, %p153;
	@%p154 bra 	$L__BB4_154;

	setp.gt.s32 	%p155, %r61, -1;
	selp.b32 	%r422, 2146435072, 0, %p155;
	mov.u32 	%r423, 0;
	setp.ne.s32 	%p156, %r104, 1071644672;
	and.pred  	%p157, %p156, %p4;
	or.b32  	%r424, %r422, -2147483648;
	selp.b32 	%r425, %r424, %r422, %p157;
	mov.b64 	%fd504, {%r423, %r425};

$L__BB4_154:
	cvt.f64.f32 	%fd147, %f53;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r105}, %fd147;
	}
	abs.f64 	%fd148, %fd147;
	{ // callseq 35, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd507, [retval0+0];
	} // callseq 35
	setp.lt.s32 	%p161, %r105, 0;
	and.pred  	%p5, %p161, %p74;
	not.pred 	%p163, %p5;
	@%p163 bra 	$L__BB4_156;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd507;
	}
	xor.b32  	%r432, %r431, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r433, %temp}, %fd507;
	}
	mov.b64 	%fd507, {%r433, %r432};

$L__BB4_156:
	setp.eq.f32 	%p164, %f53, 0f00000000;
	@%p164 bra 	$L__BB4_160;
	bra.uni 	$L__BB4_157;

$L__BB4_160:
	selp.b32 	%r434, %r105, 0, %p74;
	mov.u32 	%r435, 0;
	or.b32  	%r436, %r434, 2146435072;
	setp.lt.s32 	%p168, %r61, 0;
	selp.b32 	%r437, %r436, %r434, %p168;
	mov.b64 	%fd507, {%r435, %r437};
	bra.uni 	$L__BB4_161;

$L__BB4_157:
	setp.gt.s32 	%p165, %r105, -1;
	@%p165 bra 	$L__BB4_161;

	mov.f64 	%fd444, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd445, %fd444;
	setp.eq.f64 	%p166, %fd445, 0d4000000000000000;
	@%p166 bra 	$L__BB4_161;

	mov.f64 	%fd507, 0dFFF8000000000000;

$L__BB4_161:
	add.rn.f64 	%fd447, %fd147, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r438}, %fd447;
	}
	and.b32  	%r439, %r438, 2146435072;
	setp.ne.s32 	%p169, %r439, 2146435072;
	@%p169 bra 	$L__BB4_168;

	setp.gtu.f64 	%p170, %fd148, 0d7FF0000000000000;
	@%p170 bra 	$L__BB4_167;
	bra.uni 	$L__BB4_163;

$L__BB4_167:
	mov.f64 	%fd449, 0d4000000000000000;
	add.rn.f64 	%fd507, %fd147, %fd449;
	bra.uni 	$L__BB4_168;

$L__BB4_163:
	mov.f64 	%fd448, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r440, %temp}, %fd448;
	}
	and.b32  	%r106, %r61, 2147483647;
	setp.eq.s32 	%p171, %r106, 2146435072;
	setp.eq.s32 	%p172, %r440, 0;
	and.pred  	%p173, %p171, %p172;
	@%p173 bra 	$L__BB4_166;
	bra.uni 	$L__BB4_164;

$L__BB4_166:
	setp.gt.f64 	%p180, %fd148, 0d3FF0000000000000;
	selp.b32 	%r447, 2146435072, 0, %p180;
	mov.u32 	%r448, 0;
	xor.b32  	%r449, %r447, 2146435072;
	setp.lt.s32 	%p181, %r61, 0;
	selp.b32 	%r450, %r449, %r447, %p181;
	setp.eq.f32 	%p182, %f53, 0fBF800000;
	selp.b32 	%r451, 1072693248, %r450, %p182;
	mov.b64 	%fd507, {%r448, %r451};
	bra.uni 	$L__BB4_168;

$L__BB4_164:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd147;
	}
	and.b32  	%r442, %r105, 2147483647;
	setp.ne.s32 	%p174, %r442, 2146435072;
	setp.ne.s32 	%p175, %r441, 0;
	or.pred  	%p176, %p174, %p175;
	@%p176 bra 	$L__BB4_168;

	setp.gt.s32 	%p177, %r61, -1;
	selp.b32 	%r443, 2146435072, 0, %p177;
	mov.u32 	%r444, 0;
	setp.ne.s32 	%p178, %r106, 1071644672;
	and.pred  	%p179, %p178, %p5;
	or.b32  	%r445, %r443, -2147483648;
	selp.b32 	%r446, %r445, %r443, %p179;
	mov.b64 	%fd507, {%r444, %r446};

$L__BB4_168:
	setp.eq.f32 	%p183, %f53, 0f3F800000;
	selp.f64 	%fd450, 0d3FF0000000000000, %fd507, %p183;
	setp.eq.f32 	%p184, %f54, 0f3F800000;
	selp.f64 	%fd451, 0d3FF0000000000000, %fd504, %p184;
	add.rn.f64 	%fd158, %fd451, %fd450;
	mul.rn.f32 	%f55, %f53, 0f42517084;
	mul.rn.f32 	%f208, %f55, 0f3F22F983;
	cvt.rni.s32.f32 	%r615, %f208;
	cvt.rn.f32.s32 	%f209, %r615;
	mov.f32 	%f210, 0fBFC90FDA;
	fma.rn.f32 	%f211, %f209, %f210, %f55;
	mov.f32 	%f212, 0fB3A22168;
	fma.rn.f32 	%f213, %f209, %f212, %f211;
	mov.f32 	%f214, 0fA7C234C5;
	fma.rn.f32 	%f334, %f209, %f214, %f213;
	abs.f32 	%f57, %f55;
	setp.ltu.f32 	%p185, %f57, 0f47CE4780;
	@%p185 bra 	$L__BB4_176;

	setp.eq.f32 	%p186, %f57, 0f7F800000;
	@%p186 bra 	$L__BB4_175;
	bra.uni 	$L__BB4_170;

$L__BB4_175:
	mov.f32 	%f217, 0f00000000;
	mul.rn.f32 	%f334, %f55, %f217;
	mov.u32 	%r615, 0;
	bra.uni 	$L__BB4_176;

$L__BB4_170:
	mov.b32 	%r108, %f55;
	bfe.u32 	%r453, %r108, 23, 8;
	add.s32 	%r109, %r453, -128;
	shl.b32 	%r454, %r108, 8;
	or.b32  	%r110, %r454, -2147483648;
	shr.u32 	%r111, %r109, 5;
	mov.u64 	%rd226, 0;
	mov.u32 	%r612, 0;
	mov.u64 	%rd225, __cudart_i2opi_f;
	mov.u64 	%rd224, %rd1;

$L__BB4_171:
	.pragma "nounroll";
	ld.global.nc.u32 	%r455, [%rd225];
	mad.wide.u32 	%rd149, %r455, %r110, %rd226;
	shr.u64 	%rd226, %rd149, 32;
	st.local.u32 	[%rd224], %rd149;
	add.s64 	%rd225, %rd225, 4;
	add.s64 	%rd224, %rd224, 4;
	add.s32 	%r612, %r612, 1;
	setp.ne.s32 	%p187, %r612, 6;
	@%p187 bra 	$L__BB4_171;

	add.s64 	%rd200, %rd1, 24;
	st.local.u32 	[%rd200], %rd226;
	mov.u32 	%r456, 4;
	sub.s32 	%r114, %r456, %r111;
	mov.u32 	%r457, 6;
	sub.s32 	%r458, %r457, %r111;
	mul.wide.s32 	%rd150, %r458, 4;
	add.s64 	%rd151, %rd1, %rd150;
	ld.local.u32 	%r613, [%rd151];
	ld.local.u32 	%r614, [%rd151+-4];
	and.b32  	%r117, %r109, 31;
	setp.eq.s32 	%p188, %r117, 0;
	@%p188 bra 	$L__BB4_174;

	mov.u32 	%r459, 32;
	sub.s32 	%r460, %r459, %r117;
	shr.u32 	%r461, %r614, %r460;
	shl.b32 	%r462, %r613, %r117;
	add.s32 	%r613, %r461, %r462;
	mul.wide.s32 	%rd152, %r114, 4;
	add.s64 	%rd153, %rd1, %rd152;
	ld.local.u32 	%r463, [%rd153];
	shr.u32 	%r464, %r463, %r460;
	shl.b32 	%r465, %r614, %r117;
	add.s32 	%r614, %r464, %r465;

$L__BB4_174:
	and.b32  	%r466, %r108, -2147483648;
	shr.u32 	%r467, %r614, 30;
	shl.b32 	%r468, %r613, 2;
	or.b32  	%r469, %r467, %r468;
	shr.u32 	%r470, %r469, 31;
	shr.u32 	%r471, %r613, 30;
	add.s32 	%r472, %r470, %r471;
	neg.s32 	%r473, %r472;
	setp.eq.s32 	%p189, %r466, 0;
	selp.b32 	%r615, %r472, %r473, %p189;
	setp.ne.s32 	%p190, %r470, 0;
	xor.b32  	%r474, %r466, -2147483648;
	selp.b32 	%r475, %r474, %r466, %p190;
	selp.b32 	%r476, -1, 0, %p190;
	xor.b32  	%r477, %r469, %r476;
	shl.b32 	%r478, %r614, 2;
	xor.b32  	%r479, %r478, %r476;
	cvt.u64.u32 	%rd154, %r477;
	cvt.u64.u32 	%rd155, %r479;
	bfi.b64 	%rd156, %rd154, %rd155, 32, 32;
	cvt.rn.f64.s64 	%fd452, %rd156;
	mul.rn.f64 	%fd453, %fd452, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f215, %fd453;
	setp.eq.s32 	%p191, %r475, 0;
	neg.f32 	%f216, %f215;
	selp.f32 	%f334, %f215, %f216, %p191;

$L__BB4_176:
	and.b32  	%r124, %r615, 1;
	setp.eq.s32 	%p192, %r124, 0;
	selp.f32 	%f61, %f334, 0f3F800000, %p192;
	mul.rn.f32 	%f62, %f334, %f334;
	mov.f32 	%f335, 0fB94D4153;
	@%p192 bra 	$L__BB4_178;

	mov.f32 	%f219, 0fBAB607ED;
	mov.f32 	%f220, 0f37CBAC00;
	fma.rn.f32 	%f335, %f220, %f62, %f219;

$L__BB4_178:
	selp.f32 	%f221, 0f3C0885E4, 0f3D2AAABB, %p192;
	fma.rn.f32 	%f222, %f335, %f62, %f221;
	selp.f32 	%f223, 0fBE2AAAA8, 0fBEFFFFFF, %p192;
	fma.rn.f32 	%f224, %f222, %f62, %f223;
	mov.f32 	%f225, 0f00000000;
	fma.rn.f32 	%f226, %f62, %f61, %f225;
	fma.rn.f32 	%f336, %f224, %f226, %f61;
	and.b32  	%r481, %r615, 2;
	setp.eq.s32 	%p194, %r481, 0;
	@%p194 bra 	$L__BB4_180;

	mov.f32 	%f228, 0fBF800000;
	fma.rn.f32 	%f336, %f336, %f228, %f225;

$L__BB4_180:
	cvt.f64.f32 	%fd454, %f336;
	mul.rn.f64 	%fd455, %fd454, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd456, %fd158;
	add.rn.f64 	%fd457, %fd456, %fd455;
	cvt.rn.f32.f64 	%f68, %fd457;
	abs.f32 	%f69, %f54;
	setp.eq.f32 	%p195, %f69, 0f00000000;
	abs.f32 	%f70, %f53;
	setp.eq.f32 	%p196, %f70, 0f00000000;
	and.pred  	%p197, %p195, %p196;
	@%p197 bra 	$L__BB4_184;
	bra.uni 	$L__BB4_181;

$L__BB4_184:
	mov.b32 	%r492, %f54;
	shr.s32 	%r493, %r492, 31;
	and.b32  	%r494, %r493, 1078530011;
	mov.b32 	%r495, %f53;
	and.b32  	%r496, %r495, -2147483648;
	or.b32  	%r497, %r494, %r496;
	mov.b32 	%f337, %r497;
	bra.uni 	$L__BB4_185;

$L__BB4_181:
	setp.eq.f32 	%p198, %f69, 0f7F800000;
	setp.eq.f32 	%p199, %f70, 0f7F800000;
	and.pred  	%p200, %p198, %p199;
	@%p200 bra 	$L__BB4_183;
	bra.uni 	$L__BB4_182;

$L__BB4_183:
	mov.b32 	%r487, %f54;
	setp.lt.s32 	%p204, %r487, 0;
	selp.b32 	%r488, 1075235812, 1061752795, %p204;
	mov.b32 	%r489, %f53;
	and.b32  	%r490, %r489, -2147483648;
	or.b32  	%r491, %r488, %r490;
	mov.b32 	%f337, %r491;
	bra.uni 	$L__BB4_185;

$L__BB4_182:
	max.f32 	%f229, %f70, %f69;
	min.f32 	%f230, %f70, %f69;
	div.rn.f32 	%f231, %f230, %f229;
	mul.rn.f32 	%f232, %f231, %f231;
	mov.f32 	%f233, 0fC0B59883;
	mov.f32 	%f234, 0fBF52C7EA;
	fma.rn.f32 	%f235, %f232, %f234, %f233;
	mov.f32 	%f236, 0fC0D21907;
	fma.rn.f32 	%f237, %f235, %f232, %f236;
	mul.rn.f32 	%f238, %f232, %f237;
	mul.rn.f32 	%f239, %f231, %f238;
	add.rn.f32 	%f240, %f232, 0f41355DC0;
	mov.f32 	%f241, 0f41E6BD60;
	fma.rn.f32 	%f242, %f240, %f232, %f241;
	mov.f32 	%f243, 0f419D92C8;
	fma.rn.f32 	%f244, %f242, %f232, %f243;
	rcp.rn.f32 	%f245, %f244;
	fma.rn.f32 	%f246, %f239, %f245, %f231;
	mov.f32 	%f247, 0f3FC90FDB;
	sub.rn.f32 	%f248, %f247, %f246;
	setp.gt.f32 	%p201, %f70, %f69;
	selp.f32 	%f249, %f248, %f246, %p201;
	mov.b32 	%r482, %f54;
	setp.lt.s32 	%p202, %r482, 0;
	mov.f32 	%f250, 0f40490FDB;
	sub.rn.f32 	%f251, %f250, %f249;
	selp.f32 	%f252, %f251, %f249, %p202;
	mov.b32 	%r483, %f252;
	mov.b32 	%r484, %f53;
	and.b32  	%r485, %r484, -2147483648;
	or.b32  	%r486, %r485, %r483;
	mov.b32 	%f253, %r486;
	add.rn.f32 	%f254, %f69, %f70;
	setp.le.f32 	%p203, %f254, 0f7F800000;
	selp.f32 	%f337, %f253, %f254, %p203;

$L__BB4_185:
	mul.rn.f32 	%f75, %f54, 0f42517084;
	mul.rn.f32 	%f255, %f75, 0f3F22F983;
	cvt.rni.s32.f32 	%r619, %f255;
	cvt.rn.f32.s32 	%f256, %r619;
	mov.f32 	%f257, 0fBFC90FDA;
	fma.rn.f32 	%f258, %f256, %f257, %f75;
	mov.f32 	%f259, 0fB3A22168;
	fma.rn.f32 	%f260, %f256, %f259, %f258;
	mov.f32 	%f261, 0fA7C234C5;
	fma.rn.f32 	%f338, %f256, %f261, %f260;
	abs.f32 	%f77, %f75;
	setp.ltu.f32 	%p205, %f77, 0f47CE4780;
	@%p205 bra 	$L__BB4_193;

	setp.eq.f32 	%p206, %f77, 0f7F800000;
	@%p206 bra 	$L__BB4_192;
	bra.uni 	$L__BB4_187;

$L__BB4_192:
	mov.f32 	%f264, 0f00000000;
	mul.rn.f32 	%f338, %f75, %f264;
	mov.u32 	%r619, 0;
	bra.uni 	$L__BB4_193;

$L__BB4_187:
	mov.b32 	%r126, %f75;
	bfe.u32 	%r499, %r126, 23, 8;
	add.s32 	%r127, %r499, -128;
	shl.b32 	%r500, %r126, 8;
	or.b32  	%r128, %r500, -2147483648;
	shr.u32 	%r129, %r127, 5;
	mov.u64 	%rd229, 0;
	mov.u32 	%r616, 0;
	mov.u64 	%rd228, __cudart_i2opi_f;
	mov.u64 	%rd227, %rd1;

$L__BB4_188:
	.pragma "nounroll";
	ld.global.nc.u32 	%r501, [%rd228];
	mad.wide.u32 	%rd159, %r501, %r128, %rd229;
	shr.u64 	%rd229, %rd159, 32;
	st.local.u32 	[%rd227], %rd159;
	add.s64 	%rd228, %rd228, 4;
	add.s64 	%rd227, %rd227, 4;
	add.s32 	%r616, %r616, 1;
	setp.ne.s32 	%p207, %r616, 6;
	@%p207 bra 	$L__BB4_188;

	add.s64 	%rd201, %rd1, 24;
	st.local.u32 	[%rd201], %rd229;
	mov.u32 	%r502, 4;
	sub.s32 	%r132, %r502, %r129;
	mov.u32 	%r503, 6;
	sub.s32 	%r504, %r503, %r129;
	mul.wide.s32 	%rd160, %r504, 4;
	add.s64 	%rd161, %rd1, %rd160;
	ld.local.u32 	%r617, [%rd161];
	ld.local.u32 	%r618, [%rd161+-4];
	and.b32  	%r135, %r127, 31;
	setp.eq.s32 	%p208, %r135, 0;
	@%p208 bra 	$L__BB4_191;

	mov.u32 	%r505, 32;
	sub.s32 	%r506, %r505, %r135;
	shr.u32 	%r507, %r618, %r506;
	shl.b32 	%r508, %r617, %r135;
	add.s32 	%r617, %r507, %r508;
	mul.wide.s32 	%rd162, %r132, 4;
	add.s64 	%rd163, %rd1, %rd162;
	ld.local.u32 	%r509, [%rd163];
	shr.u32 	%r510, %r509, %r506;
	shl.b32 	%r511, %r618, %r135;
	add.s32 	%r618, %r510, %r511;

$L__BB4_191:
	and.b32  	%r512, %r126, -2147483648;
	shr.u32 	%r513, %r618, 30;
	shl.b32 	%r514, %r617, 2;
	or.b32  	%r515, %r513, %r514;
	shr.u32 	%r516, %r515, 31;
	shr.u32 	%r517, %r617, 30;
	add.s32 	%r518, %r516, %r517;
	neg.s32 	%r519, %r518;
	setp.eq.s32 	%p209, %r512, 0;
	selp.b32 	%r619, %r518, %r519, %p209;
	setp.ne.s32 	%p210, %r516, 0;
	xor.b32  	%r520, %r512, -2147483648;
	selp.b32 	%r521, %r520, %r512, %p210;
	selp.b32 	%r522, -1, 0, %p210;
	xor.b32  	%r523, %r515, %r522;
	shl.b32 	%r524, %r618, 2;
	xor.b32  	%r525, %r524, %r522;
	cvt.u64.u32 	%rd164, %r523;
	cvt.u64.u32 	%rd165, %r525;
	bfi.b64 	%rd166, %rd164, %rd165, 32, 32;
	cvt.rn.f64.s64 	%fd458, %rd166;
	mul.rn.f64 	%fd459, %fd458, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f262, %fd459;
	setp.eq.s32 	%p211, %r521, 0;
	neg.f32 	%f263, %f262;
	selp.f32 	%f338, %f262, %f263, %p211;

$L__BB4_193:
	add.s32 	%r142, %r619, 1;
	and.b32  	%r143, %r142, 1;
	setp.eq.s32 	%p212, %r143, 0;
	selp.f32 	%f81, %f338, 0f3F800000, %p212;
	mul.rn.f32 	%f82, %f338, %f338;
	mov.f32 	%f339, 0fB94D4153;
	@%p212 bra 	$L__BB4_195;

	mov.f32 	%f266, 0fBAB607ED;
	mov.f32 	%f267, 0f37CBAC00;
	fma.rn.f32 	%f339, %f267, %f82, %f266;

$L__BB4_195:
	selp.f32 	%f268, 0f3C0885E4, 0f3D2AAABB, %p212;
	fma.rn.f32 	%f269, %f339, %f82, %f268;
	selp.f32 	%f270, 0fBE2AAAA8, 0fBEFFFFFF, %p212;
	fma.rn.f32 	%f271, %f269, %f82, %f270;
	mov.f32 	%f272, 0f00000000;
	fma.rn.f32 	%f273, %f82, %f81, %f272;
	fma.rn.f32 	%f340, %f271, %f273, %f81;
	and.b32  	%r527, %r142, 2;
	setp.eq.s32 	%p214, %r527, 0;
	@%p214 bra 	$L__BB4_197;

	mov.f32 	%f275, 0fBF800000;
	fma.rn.f32 	%f340, %f340, %f275, %f272;

$L__BB4_197:
	cvt.f64.f32 	%fd460, %f340;
	mul.rn.f64 	%fd461, %fd460, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd462, %f337;
	add.rn.f64 	%fd463, %fd461, %fd462;
	cvt.rn.f32.f64 	%f88, %fd463;
	mul.rn.f32 	%f276, %f88, 0f3F22F983;
	cvt.rni.s32.f32 	%r627, %f276;
	cvt.rn.f32.s32 	%f277, %r627;
	mov.f32 	%f278, 0fBFC90FDA;
	fma.rn.f32 	%f279, %f277, %f278, %f88;
	mov.f32 	%f280, 0fB3A22168;
	fma.rn.f32 	%f281, %f277, %f280, %f279;
	mov.f32 	%f282, 0fA7C234C5;
	fma.rn.f32 	%f344, %f277, %f282, %f281;
	abs.f32 	%f90, %f88;
	setp.ltu.f32 	%p215, %f90, 0f47CE4780;
	mov.u32 	%r623, %r627;
	mov.f32 	%f341, %f344;
	@%p215 bra 	$L__BB4_205;

	setp.eq.f32 	%p216, %f90, 0f7F800000;
	@%p216 bra 	$L__BB4_204;
	bra.uni 	$L__BB4_199;

$L__BB4_204:
	mov.f32 	%f285, 0f00000000;
	mul.rn.f32 	%f341, %f88, %f285;
	mov.u32 	%r623, 0;
	bra.uni 	$L__BB4_205;

$L__BB4_199:
	mov.b32 	%r145, %f88;
	bfe.u32 	%r529, %r145, 23, 8;
	add.s32 	%r146, %r529, -128;
	shl.b32 	%r530, %r145, 8;
	or.b32  	%r147, %r530, -2147483648;
	shr.u32 	%r148, %r146, 5;
	mov.u64 	%rd232, 0;
	mov.u32 	%r620, 0;
	mov.u64 	%rd231, __cudart_i2opi_f;
	mov.u64 	%rd230, %rd1;

$L__BB4_200:
	.pragma "nounroll";
	ld.global.nc.u32 	%r531, [%rd231];
	mad.wide.u32 	%rd169, %r531, %r147, %rd232;
	shr.u64 	%rd232, %rd169, 32;
	st.local.u32 	[%rd230], %rd169;
	add.s64 	%rd231, %rd231, 4;
	add.s64 	%rd230, %rd230, 4;
	add.s32 	%r620, %r620, 1;
	setp.ne.s32 	%p217, %r620, 6;
	@%p217 bra 	$L__BB4_200;

	add.s64 	%rd202, %rd1, 24;
	st.local.u32 	[%rd202], %rd232;
	mov.u32 	%r532, 4;
	sub.s32 	%r151, %r532, %r148;
	mov.u32 	%r533, 6;
	sub.s32 	%r534, %r533, %r148;
	mul.wide.s32 	%rd170, %r534, 4;
	add.s64 	%rd171, %rd1, %rd170;
	ld.local.u32 	%r621, [%rd171];
	ld.local.u32 	%r622, [%rd171+-4];
	and.b32  	%r154, %r146, 31;
	setp.eq.s32 	%p218, %r154, 0;
	@%p218 bra 	$L__BB4_203;

	mov.u32 	%r535, 32;
	sub.s32 	%r536, %r535, %r154;
	shr.u32 	%r537, %r622, %r536;
	shl.b32 	%r538, %r621, %r154;
	add.s32 	%r621, %r537, %r538;
	mul.wide.s32 	%rd172, %r151, 4;
	add.s64 	%rd173, %rd1, %rd172;
	ld.local.u32 	%r539, [%rd173];
	shr.u32 	%r540, %r539, %r536;
	shl.b32 	%r541, %r622, %r154;
	add.s32 	%r622, %r540, %r541;

$L__BB4_203:
	and.b32  	%r542, %r145, -2147483648;
	shr.u32 	%r543, %r622, 30;
	shl.b32 	%r544, %r621, 2;
	or.b32  	%r545, %r543, %r544;
	shr.u32 	%r546, %r545, 31;
	shr.u32 	%r547, %r621, 30;
	add.s32 	%r548, %r546, %r547;
	neg.s32 	%r549, %r548;
	setp.eq.s32 	%p219, %r542, 0;
	selp.b32 	%r623, %r548, %r549, %p219;
	setp.ne.s32 	%p220, %r546, 0;
	xor.b32  	%r550, %r542, -2147483648;
	selp.b32 	%r551, %r550, %r542, %p220;
	selp.b32 	%r552, -1, 0, %p220;
	xor.b32  	%r553, %r545, %r552;
	shl.b32 	%r554, %r622, 2;
	xor.b32  	%r555, %r554, %r552;
	cvt.u64.u32 	%rd174, %r553;
	cvt.u64.u32 	%rd175, %r555;
	bfi.b64 	%rd176, %rd174, %rd175, 32, 32;
	cvt.rn.f64.s64 	%fd464, %rd176;
	mul.rn.f64 	%fd465, %fd464, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f283, %fd465;
	setp.eq.s32 	%p221, %r551, 0;
	neg.f32 	%f284, %f283;
	selp.f32 	%f341, %f283, %f284, %p221;

$L__BB4_205:
	add.s32 	%r161, %r623, 1;
	and.b32  	%r162, %r161, 1;
	setp.eq.s32 	%p222, %r162, 0;
	selp.f32 	%f94, %f341, 0f3F800000, %p222;
	mul.rn.f32 	%f95, %f341, %f341;
	mov.f32 	%f342, 0fB94D4153;
	@%p222 bra 	$L__BB4_207;

	mov.f32 	%f287, 0fBAB607ED;
	mov.f32 	%f288, 0f37CBAC00;
	fma.rn.f32 	%f342, %f288, %f95, %f287;

$L__BB4_207:
	selp.f32 	%f289, 0f3C0885E4, 0f3D2AAABB, %p222;
	fma.rn.f32 	%f290, %f342, %f95, %f289;
	selp.f32 	%f291, 0fBE2AAAA8, 0fBEFFFFFF, %p222;
	fma.rn.f32 	%f292, %f290, %f95, %f291;
	mov.f32 	%f293, 0f00000000;
	fma.rn.f32 	%f294, %f95, %f94, %f293;
	fma.rn.f32 	%f343, %f292, %f294, %f94;
	and.b32  	%r557, %r161, 2;
	setp.eq.s32 	%p224, %r557, 0;
	@%p224 bra 	$L__BB4_209;

	mov.f32 	%f296, 0fBF800000;
	fma.rn.f32 	%f343, %f343, %f296, %f293;

$L__BB4_209:
	mul.rn.f32 	%f297, %f343, %f68;
	cvt.f64.f32 	%fd466, %f297;
	add.rn.f64 	%fd467, %fd466, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f298, %fd467;
	st.global.f32 	[%rd10], %f298;
	@%p215 bra 	$L__BB4_217;

	setp.eq.f32 	%p226, %f90, 0f7F800000;
	@%p226 bra 	$L__BB4_216;
	bra.uni 	$L__BB4_211;

$L__BB4_216:
	mov.f32 	%f301, 0f00000000;
	mul.rn.f32 	%f344, %f88, %f301;
	mov.u32 	%r627, 0;
	bra.uni 	$L__BB4_217;

$L__BB4_211:
	mov.b32 	%r163, %f88;
	bfe.u32 	%r559, %r163, 23, 8;
	add.s32 	%r164, %r559, -128;
	shl.b32 	%r560, %r163, 8;
	or.b32  	%r165, %r560, -2147483648;
	shr.u32 	%r166, %r164, 5;
	mov.u64 	%rd235, 0;
	mov.u32 	%r624, 0;
	mov.u64 	%rd234, __cudart_i2opi_f;
	mov.u64 	%rd233, %rd1;

$L__BB4_212:
	.pragma "nounroll";
	ld.global.nc.u32 	%r561, [%rd234];
	mad.wide.u32 	%rd179, %r561, %r165, %rd235;
	shr.u64 	%rd235, %rd179, 32;
	st.local.u32 	[%rd233], %rd179;
	add.s64 	%rd234, %rd234, 4;
	add.s64 	%rd233, %rd233, 4;
	add.s32 	%r624, %r624, 1;
	setp.ne.s32 	%p227, %r624, 6;
	@%p227 bra 	$L__BB4_212;

	add.s64 	%rd203, %rd1, 24;
	st.local.u32 	[%rd203], %rd235;
	mov.u32 	%r562, 4;
	sub.s32 	%r169, %r562, %r166;
	mov.u32 	%r563, 6;
	sub.s32 	%r564, %r563, %r166;
	mul.wide.s32 	%rd180, %r564, 4;
	add.s64 	%rd181, %rd1, %rd180;
	ld.local.u32 	%r625, [%rd181];
	ld.local.u32 	%r626, [%rd181+-4];
	and.b32  	%r172, %r164, 31;
	setp.eq.s32 	%p228, %r172, 0;
	@%p228 bra 	$L__BB4_215;

	mov.u32 	%r565, 32;
	sub.s32 	%r566, %r565, %r172;
	shr.u32 	%r567, %r626, %r566;
	shl.b32 	%r568, %r625, %r172;
	add.s32 	%r625, %r567, %r568;
	mul.wide.s32 	%rd182, %r169, 4;
	add.s64 	%rd183, %rd1, %rd182;
	ld.local.u32 	%r569, [%rd183];
	shr.u32 	%r570, %r569, %r566;
	shl.b32 	%r571, %r626, %r172;
	add.s32 	%r626, %r570, %r571;

$L__BB4_215:
	and.b32  	%r572, %r163, -2147483648;
	shr.u32 	%r573, %r626, 30;
	shl.b32 	%r574, %r625, 2;
	or.b32  	%r575, %r573, %r574;
	shr.u32 	%r576, %r575, 31;
	shr.u32 	%r577, %r625, 30;
	add.s32 	%r578, %r576, %r577;
	neg.s32 	%r579, %r578;
	setp.eq.s32 	%p229, %r572, 0;
	selp.b32 	%r627, %r578, %r579, %p229;
	setp.ne.s32 	%p230, %r576, 0;
	xor.b32  	%r580, %r572, -2147483648;
	selp.b32 	%r581, %r580, %r572, %p230;
	selp.b32 	%r582, -1, 0, %p230;
	xor.b32  	%r583, %r575, %r582;
	shl.b32 	%r584, %r626, 2;
	xor.b32  	%r585, %r584, %r582;
	cvt.u64.u32 	%rd184, %r583;
	cvt.u64.u32 	%rd185, %r585;
	bfi.b64 	%rd186, %rd184, %rd185, 32, 32;
	cvt.rn.f64.s64 	%fd468, %rd186;
	mul.rn.f64 	%fd469, %fd468, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f299, %fd469;
	setp.eq.s32 	%p231, %r581, 0;
	neg.f32 	%f300, %f299;
	selp.f32 	%f344, %f299, %f300, %p231;

$L__BB4_217:
	and.b32  	%r179, %r627, 1;
	setp.eq.s32 	%p232, %r179, 0;
	selp.f32 	%f104, %f344, 0f3F800000, %p232;
	mul.rn.f32 	%f105, %f344, %f344;
	mov.f32 	%f345, 0fB94D4153;
	@%p232 bra 	$L__BB4_219;

	mov.f32 	%f303, 0fBAB607ED;
	mov.f32 	%f304, 0f37CBAC00;
	fma.rn.f32 	%f345, %f304, %f105, %f303;

$L__BB4_219:
	selp.f32 	%f305, 0f3C0885E4, 0f3D2AAABB, %p232;
	fma.rn.f32 	%f306, %f345, %f105, %f305;
	selp.f32 	%f307, 0fBE2AAAA8, 0fBEFFFFFF, %p232;
	fma.rn.f32 	%f308, %f306, %f105, %f307;
	mov.f32 	%f309, 0f00000000;
	fma.rn.f32 	%f310, %f105, %f104, %f309;
	fma.rn.f32 	%f346, %f308, %f310, %f104;
	and.b32  	%r587, %r627, 2;
	setp.eq.s32 	%p234, %r587, 0;
	@%p234 bra 	$L__BB4_221;

	mov.f32 	%f312, 0fBF800000;
	fma.rn.f32 	%f346, %f346, %f312, %f309;

$L__BB4_221:
	mul.rn.f32 	%f313, %f346, %f68;
	cvt.f64.f32 	%fd470, %f313;
	add.rn.f64 	%fd471, %fd470, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f314, %fd471;
	st.global.f32 	[%rd11], %f314;
	ret;

}
	// .globl	bd09_to_wgs84_cuda_float
.visible .entry bd09_to_wgs84_cuda_float(
	.param .u64 bd09_to_wgs84_cuda_float_param_0,
	.param .u64 bd09_to_wgs84_cuda_float_param_1
)
{
	.local .align 4 .b8 	__local_depot5[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<235>;
	.reg .f32 	%f<340>;
	.reg .b32 	%r<632>;
	.reg .f64 	%fd<508>;
	.reg .b64 	%rd<229>;


	mov.u64 	%SPL, __local_depot5;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd61, [bd09_to_wgs84_cuda_float_param_0];
	ld.param.u64 	%rd62, [bd09_to_wgs84_cuda_float_param_1];
	cvta.to.global.u64 	%rd63, %rd62;
	add.u64 	%rd64, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r180, %ntid.x;
	mov.u32 	%r181, %ctaid.x;
	mov.u32 	%r182, %tid.x;
	mad.lo.s32 	%r183, %r181, %r180, %r182;
	cvta.to.global.u64 	%rd73, %rd61;
	mul.wide.s32 	%rd74, %r183, 4;
	add.s64 	%rd10, %rd73, %rd74;
	add.s64 	%rd11, %rd63, %rd74;
	ld.global.f32 	%f111, [%rd10];
	cvt.f64.f32 	%fd159, %f111;
	add.rn.f64 	%fd160, %fd159, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f1, %fd160;
	ld.global.f32 	%f112, [%rd11];
	cvt.f64.f32 	%fd161, %f112;
	add.rn.f64 	%fd162, %fd161, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f2, %fd162;
	cvt.f64.f32 	%fd1, %f1;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd163, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd163;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p6, %r3, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 36, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd474, [retval0+0];
	} // callseq 36
	setp.lt.s32 	%p7, %r1, 0;
	and.pred  	%p1, %p7, %p6;
	not.pred 	%p8, %p1;
	@%p8 bra 	$L__BB5_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r184}, %fd474;
	}
	xor.b32  	%r185, %r184, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r186, %temp}, %fd474;
	}
	mov.b64 	%fd474, {%r186, %r185};

$L__BB5_2:
	setp.eq.f32 	%p9, %f1, 0f00000000;
	@%p9 bra 	$L__BB5_6;
	bra.uni 	$L__BB5_3;

$L__BB5_6:
	selp.b32 	%r187, %r1, 0, %p6;
	mov.u32 	%r188, 0;
	or.b32  	%r189, %r187, 2146435072;
	setp.lt.s32 	%p13, %r2, 0;
	selp.b32 	%r190, %r189, %r187, %p13;
	mov.b64 	%fd474, {%r188, %r190};
	bra.uni 	$L__BB5_7;

$L__BB5_3:
	setp.gt.s32 	%p10, %r1, -1;
	@%p10 bra 	$L__BB5_7;

	mov.f64 	%fd164, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd165, %fd164;
	setp.eq.f64 	%p11, %fd165, 0d4000000000000000;
	@%p11 bra 	$L__BB5_7;

	mov.f64 	%fd474, 0dFFF8000000000000;

$L__BB5_7:
	add.rn.f64 	%fd167, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r191}, %fd167;
	}
	and.b32  	%r192, %r191, 2146435072;
	setp.ne.s32 	%p14, %r192, 2146435072;
	@%p14 bra 	$L__BB5_14;

	setp.gtu.f64 	%p15, %fd2, 0d7FF0000000000000;
	@%p15 bra 	$L__BB5_13;
	bra.uni 	$L__BB5_9;

$L__BB5_13:
	mov.f64 	%fd169, 0d4000000000000000;
	add.rn.f64 	%fd474, %fd1, %fd169;
	bra.uni 	$L__BB5_14;

$L__BB5_9:
	mov.f64 	%fd168, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd168;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p16, %r4, 2146435072;
	setp.eq.s32 	%p17, %r193, 0;
	and.pred  	%p18, %p16, %p17;
	@%p18 bra 	$L__BB5_12;
	bra.uni 	$L__BB5_10;

$L__BB5_12:
	setp.gt.f64 	%p25, %fd2, 0d3FF0000000000000;
	selp.b32 	%r200, 2146435072, 0, %p25;
	mov.u32 	%r201, 0;
	xor.b32  	%r202, %r200, 2146435072;
	setp.lt.s32 	%p26, %r2, 0;
	selp.b32 	%r203, %r202, %r200, %p26;
	setp.eq.f32 	%p27, %f1, 0fBF800000;
	selp.b32 	%r204, 1072693248, %r203, %p27;
	mov.b64 	%fd474, {%r201, %r204};
	bra.uni 	$L__BB5_14;

$L__BB5_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r194, %temp}, %fd1;
	}
	and.b32  	%r195, %r1, 2147483647;
	setp.ne.s32 	%p19, %r195, 2146435072;
	setp.ne.s32 	%p20, %r194, 0;
	or.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB5_14;

	setp.gt.s32 	%p22, %r2, -1;
	selp.b32 	%r196, 2146435072, 0, %p22;
	mov.u32 	%r197, 0;
	setp.ne.s32 	%p23, %r4, 1071644672;
	and.pred  	%p24, %p23, %p1;
	or.b32  	%r198, %r196, -2147483648;
	selp.b32 	%r199, %r198, %r196, %p24;
	mov.b64 	%fd474, {%r197, %r199};

$L__BB5_14:
	cvt.f64.f32 	%fd12, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 37, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd477, [retval0+0];
	} // callseq 37
	setp.lt.s32 	%p28, %r5, 0;
	and.pred  	%p2, %p28, %p6;
	not.pred 	%p30, %p2;
	@%p30 bra 	$L__BB5_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r205}, %fd477;
	}
	xor.b32  	%r206, %r205, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd477;
	}
	mov.b64 	%fd477, {%r207, %r206};

$L__BB5_16:
	setp.eq.f32 	%p31, %f2, 0f00000000;
	@%p31 bra 	$L__BB5_20;
	bra.uni 	$L__BB5_17;

$L__BB5_20:
	selp.b32 	%r208, %r5, 0, %p6;
	mov.u32 	%r209, 0;
	or.b32  	%r210, %r208, 2146435072;
	setp.lt.s32 	%p35, %r2, 0;
	selp.b32 	%r211, %r210, %r208, %p35;
	mov.b64 	%fd477, {%r209, %r211};
	bra.uni 	$L__BB5_21;

$L__BB5_17:
	setp.gt.s32 	%p32, %r5, -1;
	@%p32 bra 	$L__BB5_21;

	mov.f64 	%fd170, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd171, %fd170;
	setp.eq.f64 	%p33, %fd171, 0d4000000000000000;
	@%p33 bra 	$L__BB5_21;

	mov.f64 	%fd477, 0dFFF8000000000000;

$L__BB5_21:
	add.rn.f64 	%fd173, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd173;
	}
	and.b32  	%r213, %r212, 2146435072;
	setp.ne.s32 	%p36, %r213, 2146435072;
	@%p36 bra 	$L__BB5_28;

	setp.gtu.f64 	%p37, %fd13, 0d7FF0000000000000;
	@%p37 bra 	$L__BB5_27;
	bra.uni 	$L__BB5_23;

$L__BB5_27:
	mov.f64 	%fd175, 0d4000000000000000;
	add.rn.f64 	%fd477, %fd12, %fd175;
	bra.uni 	$L__BB5_28;

$L__BB5_23:
	mov.f64 	%fd174, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd174;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p38, %r6, 2146435072;
	setp.eq.s32 	%p39, %r214, 0;
	and.pred  	%p40, %p38, %p39;
	@%p40 bra 	$L__BB5_26;
	bra.uni 	$L__BB5_24;

$L__BB5_26:
	setp.gt.f64 	%p47, %fd13, 0d3FF0000000000000;
	selp.b32 	%r221, 2146435072, 0, %p47;
	mov.u32 	%r222, 0;
	xor.b32  	%r223, %r221, 2146435072;
	setp.lt.s32 	%p48, %r2, 0;
	selp.b32 	%r224, %r223, %r221, %p48;
	setp.eq.f32 	%p49, %f2, 0fBF800000;
	selp.b32 	%r225, 1072693248, %r224, %p49;
	mov.b64 	%fd477, {%r222, %r225};
	bra.uni 	$L__BB5_28;

$L__BB5_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r215, %temp}, %fd12;
	}
	and.b32  	%r216, %r5, 2147483647;
	setp.ne.s32 	%p41, %r216, 2146435072;
	setp.ne.s32 	%p42, %r215, 0;
	or.pred  	%p43, %p41, %p42;
	@%p43 bra 	$L__BB5_28;

	setp.gt.s32 	%p44, %r2, -1;
	selp.b32 	%r217, 2146435072, 0, %p44;
	mov.u32 	%r218, 0;
	setp.ne.s32 	%p45, %r6, 1071644672;
	and.pred  	%p46, %p45, %p2;
	or.b32  	%r219, %r217, -2147483648;
	selp.b32 	%r220, %r219, %r217, %p46;
	mov.b64 	%fd477, {%r218, %r220};

$L__BB5_28:
	setp.eq.f32 	%p50, %f2, 0f3F800000;
	selp.f64 	%fd176, 0d3FF0000000000000, %fd477, %p50;
	setp.eq.f32 	%p51, %f1, 0f3F800000;
	selp.f64 	%fd177, 0d3FF0000000000000, %fd474, %p51;
	add.rn.f64 	%fd23, %fd177, %fd176;
	mul.rn.f32 	%f3, %f2, 0f42517084;
	mul.rn.f32 	%f113, %f3, 0f3F22F983;
	cvt.rni.s32.f32 	%r595, %f113;
	cvt.rn.f32.s32 	%f114, %r595;
	mov.f32 	%f115, 0fBFC90FDA;
	fma.rn.f32 	%f116, %f114, %f115, %f3;
	mov.f32 	%f117, 0fB3A22168;
	fma.rn.f32 	%f118, %f114, %f117, %f116;
	mov.f32 	%f119, 0fA7C234C5;
	fma.rn.f32 	%f315, %f114, %f119, %f118;
	abs.f32 	%f5, %f3;
	setp.ltu.f32 	%p52, %f5, 0f47CE4780;
	add.s64 	%rd12, %rd1, 24;
	@%p52 bra 	$L__BB5_36;

	setp.eq.f32 	%p53, %f5, 0f7F800000;
	@%p53 bra 	$L__BB5_35;
	bra.uni 	$L__BB5_30;

$L__BB5_35:
	mov.f32 	%f122, 0f00000000;
	mul.rn.f32 	%f315, %f3, %f122;
	mov.u32 	%r595, 0;
	bra.uni 	$L__BB5_36;

$L__BB5_30:
	mov.b32 	%r8, %f3;
	bfe.u32 	%r227, %r8, 23, 8;
	add.s32 	%r9, %r227, -128;
	shl.b32 	%r228, %r8, 8;
	or.b32  	%r10, %r228, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd207, 0;
	mov.u32 	%r592, 0;
	mov.u64 	%rd206, __cudart_i2opi_f;
	mov.u64 	%rd205, %rd1;

$L__BB5_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r229, [%rd206];
	mad.wide.u32 	%rd77, %r229, %r10, %rd207;
	shr.u64 	%rd207, %rd77, 32;
	st.local.u32 	[%rd205], %rd77;
	add.s64 	%rd206, %rd206, 4;
	add.s64 	%rd205, %rd205, 4;
	add.s32 	%r592, %r592, 1;
	setp.ne.s32 	%p54, %r592, 6;
	@%p54 bra 	$L__BB5_31;

	st.local.u32 	[%rd12], %rd207;
	mov.u32 	%r230, 4;
	sub.s32 	%r14, %r230, %r11;
	mov.u32 	%r231, 6;
	sub.s32 	%r232, %r231, %r11;
	mul.wide.s32 	%rd78, %r232, 4;
	add.s64 	%rd79, %rd1, %rd78;
	ld.local.u32 	%r593, [%rd79];
	ld.local.u32 	%r594, [%rd79+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p55, %r17, 0;
	@%p55 bra 	$L__BB5_34;

	mov.u32 	%r233, 32;
	sub.s32 	%r234, %r233, %r17;
	shr.u32 	%r235, %r594, %r234;
	shl.b32 	%r236, %r593, %r17;
	add.s32 	%r593, %r235, %r236;
	mul.wide.s32 	%rd80, %r14, 4;
	add.s64 	%rd81, %rd1, %rd80;
	ld.local.u32 	%r237, [%rd81];
	shr.u32 	%r238, %r237, %r234;
	shl.b32 	%r239, %r594, %r17;
	add.s32 	%r594, %r238, %r239;

$L__BB5_34:
	and.b32  	%r240, %r8, -2147483648;
	shr.u32 	%r241, %r594, 30;
	shl.b32 	%r242, %r593, 2;
	or.b32  	%r243, %r241, %r242;
	shr.u32 	%r244, %r243, 31;
	shr.u32 	%r245, %r593, 30;
	add.s32 	%r246, %r244, %r245;
	neg.s32 	%r247, %r246;
	setp.eq.s32 	%p56, %r240, 0;
	selp.b32 	%r595, %r246, %r247, %p56;
	setp.ne.s32 	%p57, %r244, 0;
	xor.b32  	%r248, %r240, -2147483648;
	selp.b32 	%r249, %r248, %r240, %p57;
	selp.b32 	%r250, -1, 0, %p57;
	xor.b32  	%r251, %r243, %r250;
	shl.b32 	%r252, %r594, 2;
	xor.b32  	%r253, %r252, %r250;
	cvt.u64.u32 	%rd82, %r251;
	cvt.u64.u32 	%rd83, %r253;
	bfi.b64 	%rd84, %rd82, %rd83, 32, 32;
	cvt.rn.f64.s64 	%fd178, %rd84;
	mul.rn.f64 	%fd179, %fd178, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f120, %fd179;
	setp.eq.s32 	%p58, %r249, 0;
	neg.f32 	%f121, %f120;
	selp.f32 	%f315, %f120, %f121, %p58;

$L__BB5_36:
	and.b32  	%r24, %r595, 1;
	setp.eq.s32 	%p59, %r24, 0;
	selp.f32 	%f9, %f315, 0f3F800000, %p59;
	mul.rn.f32 	%f10, %f315, %f315;
	mov.f32 	%f316, 0fB94D4153;
	@%p59 bra 	$L__BB5_38;

	mov.f32 	%f124, 0fBAB607ED;
	mov.f32 	%f125, 0f37CBAC00;
	fma.rn.f32 	%f316, %f125, %f10, %f124;

$L__BB5_38:
	selp.f32 	%f126, 0f3C0885E4, 0f3D2AAABB, %p59;
	fma.rn.f32 	%f127, %f316, %f10, %f126;
	selp.f32 	%f128, 0fBE2AAAA8, 0fBEFFFFFF, %p59;
	fma.rn.f32 	%f129, %f127, %f10, %f128;
	mov.f32 	%f130, 0f00000000;
	fma.rn.f32 	%f131, %f10, %f9, %f130;
	fma.rn.f32 	%f317, %f129, %f131, %f9;
	and.b32  	%r255, %r595, 2;
	setp.eq.s32 	%p61, %r255, 0;
	@%p61 bra 	$L__BB5_40;

	mov.f32 	%f133, 0fBF800000;
	fma.rn.f32 	%f317, %f317, %f133, %f130;

$L__BB5_40:
	cvt.f64.f32 	%fd180, %f317;
	mul.rn.f64 	%fd181, %fd180, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd182, %fd23;
	add.rn.f64 	%fd183, %fd182, %fd181;
	cvt.rn.f32.f64 	%f16, %fd183;
	abs.f32 	%f17, %f1;
	setp.eq.f32 	%p62, %f17, 0f00000000;
	abs.f32 	%f18, %f2;
	setp.eq.f32 	%p63, %f18, 0f00000000;
	and.pred  	%p64, %p62, %p63;
	@%p64 bra 	$L__BB5_44;
	bra.uni 	$L__BB5_41;

$L__BB5_44:
	mov.b32 	%r266, %f1;
	shr.s32 	%r267, %r266, 31;
	and.b32  	%r268, %r267, 1078530011;
	mov.b32 	%r269, %f2;
	and.b32  	%r270, %r269, -2147483648;
	or.b32  	%r271, %r268, %r270;
	mov.b32 	%f318, %r271;
	bra.uni 	$L__BB5_45;

$L__BB5_41:
	setp.eq.f32 	%p65, %f17, 0f7F800000;
	setp.eq.f32 	%p66, %f18, 0f7F800000;
	and.pred  	%p67, %p65, %p66;
	@%p67 bra 	$L__BB5_43;
	bra.uni 	$L__BB5_42;

$L__BB5_43:
	mov.b32 	%r261, %f1;
	setp.lt.s32 	%p71, %r261, 0;
	selp.b32 	%r262, 1075235812, 1061752795, %p71;
	mov.b32 	%r263, %f2;
	and.b32  	%r264, %r263, -2147483648;
	or.b32  	%r265, %r262, %r264;
	mov.b32 	%f318, %r265;
	bra.uni 	$L__BB5_45;

$L__BB5_42:
	max.f32 	%f134, %f18, %f17;
	min.f32 	%f135, %f18, %f17;
	div.rn.f32 	%f136, %f135, %f134;
	mul.rn.f32 	%f137, %f136, %f136;
	mov.f32 	%f138, 0fC0B59883;
	mov.f32 	%f139, 0fBF52C7EA;
	fma.rn.f32 	%f140, %f137, %f139, %f138;
	mov.f32 	%f141, 0fC0D21907;
	fma.rn.f32 	%f142, %f140, %f137, %f141;
	mul.rn.f32 	%f143, %f137, %f142;
	mul.rn.f32 	%f144, %f136, %f143;
	add.rn.f32 	%f145, %f137, 0f41355DC0;
	mov.f32 	%f146, 0f41E6BD60;
	fma.rn.f32 	%f147, %f145, %f137, %f146;
	mov.f32 	%f148, 0f419D92C8;
	fma.rn.f32 	%f149, %f147, %f137, %f148;
	rcp.rn.f32 	%f150, %f149;
	fma.rn.f32 	%f151, %f144, %f150, %f136;
	mov.f32 	%f152, 0f3FC90FDB;
	sub.rn.f32 	%f153, %f152, %f151;
	setp.gt.f32 	%p68, %f18, %f17;
	selp.f32 	%f154, %f153, %f151, %p68;
	mov.b32 	%r256, %f1;
	setp.lt.s32 	%p69, %r256, 0;
	mov.f32 	%f155, 0f40490FDB;
	sub.rn.f32 	%f156, %f155, %f154;
	selp.f32 	%f157, %f156, %f154, %p69;
	mov.b32 	%r257, %f157;
	mov.b32 	%r258, %f2;
	and.b32  	%r259, %r258, -2147483648;
	or.b32  	%r260, %r259, %r257;
	mov.b32 	%f158, %r260;
	add.rn.f32 	%f159, %f17, %f18;
	setp.le.f32 	%p70, %f159, 0f7F800000;
	selp.f32 	%f318, %f158, %f159, %p70;

$L__BB5_45:
	mul.rn.f32 	%f23, %f1, 0f42517084;
	mul.rn.f32 	%f160, %f23, 0f3F22F983;
	cvt.rni.s32.f32 	%r599, %f160;
	cvt.rn.f32.s32 	%f161, %r599;
	mov.f32 	%f162, 0fBFC90FDA;
	fma.rn.f32 	%f163, %f161, %f162, %f23;
	mov.f32 	%f164, 0fB3A22168;
	fma.rn.f32 	%f165, %f161, %f164, %f163;
	mov.f32 	%f166, 0fA7C234C5;
	fma.rn.f32 	%f319, %f161, %f166, %f165;
	abs.f32 	%f25, %f23;
	setp.ltu.f32 	%p72, %f25, 0f47CE4780;
	@%p72 bra 	$L__BB5_53;

	setp.eq.f32 	%p73, %f25, 0f7F800000;
	@%p73 bra 	$L__BB5_52;
	bra.uni 	$L__BB5_47;

$L__BB5_52:
	mov.f32 	%f169, 0f00000000;
	mul.rn.f32 	%f319, %f23, %f169;
	mov.u32 	%r599, 0;
	bra.uni 	$L__BB5_53;

$L__BB5_47:
	mov.b32 	%r26, %f23;
	bfe.u32 	%r273, %r26, 23, 8;
	add.s32 	%r27, %r273, -128;
	shl.b32 	%r274, %r26, 8;
	or.b32  	%r28, %r274, -2147483648;
	shr.u32 	%r29, %r27, 5;
	mov.u64 	%rd210, 0;
	mov.u32 	%r596, 0;
	mov.u64 	%rd209, __cudart_i2opi_f;
	mov.u64 	%rd208, %rd1;

$L__BB5_48:
	.pragma "nounroll";
	ld.global.nc.u32 	%r275, [%rd209];
	mad.wide.u32 	%rd87, %r275, %r28, %rd210;
	shr.u64 	%rd210, %rd87, 32;
	st.local.u32 	[%rd208], %rd87;
	add.s64 	%rd209, %rd209, 4;
	add.s64 	%rd208, %rd208, 4;
	add.s32 	%r596, %r596, 1;
	setp.ne.s32 	%p74, %r596, 6;
	@%p74 bra 	$L__BB5_48;

	st.local.u32 	[%rd12], %rd210;
	mov.u32 	%r276, 4;
	sub.s32 	%r32, %r276, %r29;
	mov.u32 	%r277, 6;
	sub.s32 	%r278, %r277, %r29;
	mul.wide.s32 	%rd88, %r278, 4;
	add.s64 	%rd89, %rd1, %rd88;
	ld.local.u32 	%r597, [%rd89];
	ld.local.u32 	%r598, [%rd89+-4];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p75, %r35, 0;
	@%p75 bra 	$L__BB5_51;

	mov.u32 	%r279, 32;
	sub.s32 	%r280, %r279, %r35;
	shr.u32 	%r281, %r598, %r280;
	shl.b32 	%r282, %r597, %r35;
	add.s32 	%r597, %r281, %r282;
	mul.wide.s32 	%rd90, %r32, 4;
	add.s64 	%rd91, %rd1, %rd90;
	ld.local.u32 	%r283, [%rd91];
	shr.u32 	%r284, %r283, %r280;
	shl.b32 	%r285, %r598, %r35;
	add.s32 	%r598, %r284, %r285;

$L__BB5_51:
	and.b32  	%r286, %r26, -2147483648;
	shr.u32 	%r287, %r598, 30;
	shl.b32 	%r288, %r597, 2;
	or.b32  	%r289, %r287, %r288;
	shr.u32 	%r290, %r289, 31;
	shr.u32 	%r291, %r597, 30;
	add.s32 	%r292, %r290, %r291;
	neg.s32 	%r293, %r292;
	setp.eq.s32 	%p76, %r286, 0;
	selp.b32 	%r599, %r292, %r293, %p76;
	setp.ne.s32 	%p77, %r290, 0;
	xor.b32  	%r294, %r286, -2147483648;
	selp.b32 	%r295, %r294, %r286, %p77;
	selp.b32 	%r296, -1, 0, %p77;
	xor.b32  	%r297, %r289, %r296;
	shl.b32 	%r298, %r598, 2;
	xor.b32  	%r299, %r298, %r296;
	cvt.u64.u32 	%rd92, %r297;
	cvt.u64.u32 	%rd93, %r299;
	bfi.b64 	%rd94, %rd92, %rd93, 32, 32;
	cvt.rn.f64.s64 	%fd184, %rd94;
	mul.rn.f64 	%fd185, %fd184, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f167, %fd185;
	setp.eq.s32 	%p78, %r295, 0;
	neg.f32 	%f168, %f167;
	selp.f32 	%f319, %f167, %f168, %p78;

$L__BB5_53:
	add.s32 	%r42, %r599, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32 	%p79, %r43, 0;
	selp.f32 	%f29, %f319, 0f3F800000, %p79;
	mul.rn.f32 	%f30, %f319, %f319;
	mov.f32 	%f320, 0fB94D4153;
	@%p79 bra 	$L__BB5_55;

	mov.f32 	%f171, 0fBAB607ED;
	mov.f32 	%f172, 0f37CBAC00;
	fma.rn.f32 	%f320, %f172, %f30, %f171;

$L__BB5_55:
	selp.f32 	%f173, 0f3C0885E4, 0f3D2AAABB, %p79;
	fma.rn.f32 	%f174, %f320, %f30, %f173;
	selp.f32 	%f175, 0fBE2AAAA8, 0fBEFFFFFF, %p79;
	fma.rn.f32 	%f176, %f174, %f30, %f175;
	mov.f32 	%f177, 0f00000000;
	fma.rn.f32 	%f178, %f30, %f29, %f177;
	fma.rn.f32 	%f321, %f176, %f178, %f29;
	and.b32  	%r301, %r42, 2;
	setp.eq.s32 	%p81, %r301, 0;
	@%p81 bra 	$L__BB5_57;

	mov.f32 	%f180, 0fBF800000;
	fma.rn.f32 	%f321, %f321, %f180, %f177;

$L__BB5_57:
	cvt.f64.f32 	%fd186, %f321;
	mul.rn.f64 	%fd187, %fd186, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd188, %f318;
	add.rn.f64 	%fd189, %fd188, %fd187;
	cvt.rn.f32.f64 	%f36, %fd189;
	mul.rn.f32 	%f181, %f36, 0f3F22F983;
	cvt.rni.s32.f32 	%r607, %f181;
	cvt.rn.f32.s32 	%f182, %r607;
	mov.f32 	%f183, 0fBFC90FDA;
	fma.rn.f32 	%f184, %f182, %f183, %f36;
	mov.f32 	%f185, 0fB3A22168;
	fma.rn.f32 	%f186, %f182, %f185, %f184;
	mov.f32 	%f187, 0fA7C234C5;
	fma.rn.f32 	%f325, %f182, %f187, %f186;
	abs.f32 	%f38, %f36;
	setp.ltu.f32 	%p82, %f38, 0f47CE4780;
	mov.u32 	%r603, %r607;
	mov.f32 	%f322, %f325;
	@%p82 bra 	$L__BB5_65;

	setp.eq.f32 	%p83, %f38, 0f7F800000;
	@%p83 bra 	$L__BB5_64;
	bra.uni 	$L__BB5_59;

$L__BB5_64:
	mov.f32 	%f190, 0f00000000;
	mul.rn.f32 	%f322, %f36, %f190;
	mov.u32 	%r603, 0;
	bra.uni 	$L__BB5_65;

$L__BB5_59:
	mov.b32 	%r45, %f36;
	bfe.u32 	%r303, %r45, 23, 8;
	add.s32 	%r46, %r303, -128;
	shl.b32 	%r304, %r45, 8;
	or.b32  	%r47, %r304, -2147483648;
	shr.u32 	%r48, %r46, 5;
	mov.u64 	%rd213, 0;
	mov.u32 	%r600, 0;
	mov.u64 	%rd212, __cudart_i2opi_f;
	mov.u64 	%rd211, %rd1;

$L__BB5_60:
	.pragma "nounroll";
	ld.global.nc.u32 	%r305, [%rd212];
	mad.wide.u32 	%rd97, %r305, %r47, %rd213;
	shr.u64 	%rd213, %rd97, 32;
	st.local.u32 	[%rd211], %rd97;
	add.s64 	%rd212, %rd212, 4;
	add.s64 	%rd211, %rd211, 4;
	add.s32 	%r600, %r600, 1;
	setp.ne.s32 	%p84, %r600, 6;
	@%p84 bra 	$L__BB5_60;

	st.local.u32 	[%rd12], %rd213;
	mov.u32 	%r306, 4;
	sub.s32 	%r51, %r306, %r48;
	mov.u32 	%r307, 6;
	sub.s32 	%r308, %r307, %r48;
	mul.wide.s32 	%rd98, %r308, 4;
	add.s64 	%rd99, %rd1, %rd98;
	ld.local.u32 	%r601, [%rd99];
	ld.local.u32 	%r602, [%rd99+-4];
	and.b32  	%r54, %r46, 31;
	setp.eq.s32 	%p85, %r54, 0;
	@%p85 bra 	$L__BB5_63;

	mov.u32 	%r309, 32;
	sub.s32 	%r310, %r309, %r54;
	shr.u32 	%r311, %r602, %r310;
	shl.b32 	%r312, %r601, %r54;
	add.s32 	%r601, %r311, %r312;
	mul.wide.s32 	%rd100, %r51, 4;
	add.s64 	%rd101, %rd1, %rd100;
	ld.local.u32 	%r313, [%rd101];
	shr.u32 	%r314, %r313, %r310;
	shl.b32 	%r315, %r602, %r54;
	add.s32 	%r602, %r314, %r315;

$L__BB5_63:
	and.b32  	%r316, %r45, -2147483648;
	shr.u32 	%r317, %r602, 30;
	shl.b32 	%r318, %r601, 2;
	or.b32  	%r319, %r317, %r318;
	shr.u32 	%r320, %r319, 31;
	shr.u32 	%r321, %r601, 30;
	add.s32 	%r322, %r320, %r321;
	neg.s32 	%r323, %r322;
	setp.eq.s32 	%p86, %r316, 0;
	selp.b32 	%r603, %r322, %r323, %p86;
	setp.ne.s32 	%p87, %r320, 0;
	xor.b32  	%r324, %r316, -2147483648;
	selp.b32 	%r325, %r324, %r316, %p87;
	selp.b32 	%r326, -1, 0, %p87;
	xor.b32  	%r327, %r319, %r326;
	shl.b32 	%r328, %r602, 2;
	xor.b32  	%r329, %r328, %r326;
	cvt.u64.u32 	%rd102, %r327;
	cvt.u64.u32 	%rd103, %r329;
	bfi.b64 	%rd104, %rd102, %rd103, 32, 32;
	cvt.rn.f64.s64 	%fd190, %rd104;
	mul.rn.f64 	%fd191, %fd190, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f188, %fd191;
	setp.eq.s32 	%p88, %r325, 0;
	neg.f32 	%f189, %f188;
	selp.f32 	%f322, %f188, %f189, %p88;

$L__BB5_65:
	add.s32 	%r61, %r603, 1;
	and.b32  	%r62, %r61, 1;
	setp.eq.s32 	%p89, %r62, 0;
	selp.f32 	%f42, %f322, 0f3F800000, %p89;
	mul.rn.f32 	%f43, %f322, %f322;
	mov.f32 	%f323, 0fB94D4153;
	@%p89 bra 	$L__BB5_67;

	mov.f32 	%f192, 0fBAB607ED;
	mov.f32 	%f193, 0f37CBAC00;
	fma.rn.f32 	%f323, %f193, %f43, %f192;

$L__BB5_67:
	selp.f32 	%f194, 0f3C0885E4, 0f3D2AAABB, %p89;
	fma.rn.f32 	%f195, %f323, %f43, %f194;
	selp.f32 	%f196, 0fBE2AAAA8, 0fBEFFFFFF, %p89;
	fma.rn.f32 	%f197, %f195, %f43, %f196;
	mov.f32 	%f198, 0f00000000;
	fma.rn.f32 	%f199, %f43, %f42, %f198;
	fma.rn.f32 	%f324, %f197, %f199, %f42;
	and.b32  	%r331, %r61, 2;
	setp.eq.s32 	%p91, %r331, 0;
	@%p91 bra 	$L__BB5_69;

	mov.f32 	%f201, 0fBF800000;
	fma.rn.f32 	%f324, %f324, %f201, %f198;

$L__BB5_69:
	mul.rn.f32 	%f202, %f324, %f16;
	st.global.f32 	[%rd10], %f202;
	@%p82 bra 	$L__BB5_77;

	setp.eq.f32 	%p93, %f38, 0f7F800000;
	@%p93 bra 	$L__BB5_76;
	bra.uni 	$L__BB5_71;

$L__BB5_76:
	mov.f32 	%f205, 0f00000000;
	mul.rn.f32 	%f325, %f36, %f205;
	mov.u32 	%r607, 0;
	bra.uni 	$L__BB5_77;

$L__BB5_71:
	mov.b32 	%r63, %f36;
	bfe.u32 	%r333, %r63, 23, 8;
	add.s32 	%r64, %r333, -128;
	shl.b32 	%r334, %r63, 8;
	or.b32  	%r65, %r334, -2147483648;
	shr.u32 	%r66, %r64, 5;
	mov.u64 	%rd216, 0;
	mov.u32 	%r604, 0;
	mov.u64 	%rd215, __cudart_i2opi_f;
	mov.u64 	%rd214, %rd1;

$L__BB5_72:
	.pragma "nounroll";
	ld.global.nc.u32 	%r335, [%rd215];
	mad.wide.u32 	%rd107, %r335, %r65, %rd216;
	shr.u64 	%rd216, %rd107, 32;
	st.local.u32 	[%rd214], %rd107;
	add.s64 	%rd215, %rd215, 4;
	add.s64 	%rd214, %rd214, 4;
	add.s32 	%r604, %r604, 1;
	setp.ne.s32 	%p94, %r604, 6;
	@%p94 bra 	$L__BB5_72;

	st.local.u32 	[%rd12], %rd216;
	mov.u32 	%r336, 4;
	sub.s32 	%r69, %r336, %r66;
	mov.u32 	%r337, 6;
	sub.s32 	%r338, %r337, %r66;
	mul.wide.s32 	%rd108, %r338, 4;
	add.s64 	%rd109, %rd1, %rd108;
	ld.local.u32 	%r605, [%rd109];
	ld.local.u32 	%r606, [%rd109+-4];
	and.b32  	%r72, %r64, 31;
	setp.eq.s32 	%p95, %r72, 0;
	@%p95 bra 	$L__BB5_75;

	mov.u32 	%r339, 32;
	sub.s32 	%r340, %r339, %r72;
	shr.u32 	%r341, %r606, %r340;
	shl.b32 	%r342, %r605, %r72;
	add.s32 	%r605, %r341, %r342;
	mul.wide.s32 	%rd110, %r69, 4;
	add.s64 	%rd111, %rd1, %rd110;
	ld.local.u32 	%r343, [%rd111];
	shr.u32 	%r344, %r343, %r340;
	shl.b32 	%r345, %r606, %r72;
	add.s32 	%r606, %r344, %r345;

$L__BB5_75:
	and.b32  	%r346, %r63, -2147483648;
	shr.u32 	%r347, %r606, 30;
	shl.b32 	%r348, %r605, 2;
	or.b32  	%r349, %r347, %r348;
	shr.u32 	%r350, %r349, 31;
	shr.u32 	%r351, %r605, 30;
	add.s32 	%r352, %r350, %r351;
	neg.s32 	%r353, %r352;
	setp.eq.s32 	%p96, %r346, 0;
	selp.b32 	%r607, %r352, %r353, %p96;
	setp.ne.s32 	%p97, %r350, 0;
	xor.b32  	%r354, %r346, -2147483648;
	selp.b32 	%r355, %r354, %r346, %p97;
	selp.b32 	%r356, -1, 0, %p97;
	xor.b32  	%r357, %r349, %r356;
	shl.b32 	%r358, %r606, 2;
	xor.b32  	%r359, %r358, %r356;
	cvt.u64.u32 	%rd112, %r357;
	cvt.u64.u32 	%rd113, %r359;
	bfi.b64 	%rd114, %rd112, %rd113, 32, 32;
	cvt.rn.f64.s64 	%fd192, %rd114;
	mul.rn.f64 	%fd193, %fd192, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f203, %fd193;
	setp.eq.s32 	%p98, %r355, 0;
	neg.f32 	%f204, %f203;
	selp.f32 	%f325, %f203, %f204, %p98;

$L__BB5_77:
	and.b32  	%r79, %r607, 1;
	setp.eq.s32 	%p99, %r79, 0;
	selp.f32 	%f52, %f325, 0f3F800000, %p99;
	mul.rn.f32 	%f53, %f325, %f325;
	mov.f32 	%f326, 0fB94D4153;
	@%p99 bra 	$L__BB5_79;

	mov.f32 	%f207, 0fBAB607ED;
	mov.f32 	%f208, 0f37CBAC00;
	fma.rn.f32 	%f326, %f208, %f53, %f207;

$L__BB5_79:
	selp.f32 	%f209, 0f3C0885E4, 0f3D2AAABB, %p99;
	fma.rn.f32 	%f210, %f326, %f53, %f209;
	selp.f32 	%f211, 0fBE2AAAA8, 0fBEFFFFFF, %p99;
	fma.rn.f32 	%f212, %f210, %f53, %f211;
	mov.f32 	%f213, 0f00000000;
	fma.rn.f32 	%f214, %f53, %f52, %f213;
	fma.rn.f32 	%f327, %f212, %f214, %f52;
	and.b32  	%r361, %r607, 2;
	setp.eq.s32 	%p101, %r361, 0;
	@%p101 bra 	$L__BB5_81;

	mov.f32 	%f216, 0fBF800000;
	fma.rn.f32 	%f327, %f327, %f216, %f213;

$L__BB5_81:
	mul.rn.f32 	%f59, %f327, %f16;
	st.global.f32 	[%rd11], %f59;
	ld.global.f32 	%f60, [%rd10];
	add.rn.f32 	%f61, %f60, 0fC2D20000;
	add.rn.f32 	%f62, %f59, 0fC20C0000;
	cvt.f64.f32 	%fd24, %f61;
	mul.rn.f64 	%fd194, %fd24, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f63, %fd194;
	cvt.f64.f32 	%fd25, %f62;
	mul.rn.f64 	%fd195, %fd25, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f64, %fd195;
	cvt.f64.f32 	%fd26, %f63;
	mul.rn.f64 	%fd27, %fd26, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r362, %temp}, %fd27;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r363}, %fd27;
	}
	and.b32  	%r364, %r363, 2147483647;
	setp.eq.s32 	%p102, %r364, 2146435072;
	setp.eq.s32 	%p103, %r362, 0;
	and.pred  	%p104, %p103, %p102;
	@%p104 bra 	$L__BB5_84;
	bra.uni 	$L__BB5_82;

$L__BB5_84:
	mov.f64 	%fd205, 0d0000000000000000;
	mul.rn.f64 	%fd478, %fd27, %fd205;
	mov.u32 	%r608, 0;
	bra.uni 	$L__BB5_85;

$L__BB5_82:
	mul.rn.f64 	%fd196, %fd27, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r608, %fd196;
	st.local.u32 	[%rd1], %r608;
	cvt.rn.f64.s32 	%fd197, %r608;
	neg.f64 	%fd198, %fd197;
	mov.f64 	%fd199, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd200, %fd198, %fd199, %fd27;
	mov.f64 	%fd201, 0d3C91A62633145C00;
	fma.rn.f64 	%fd202, %fd198, %fd201, %fd200;
	mov.f64 	%fd203, 0d397B839A252049C0;
	fma.rn.f64 	%fd478, %fd198, %fd203, %fd202;
	abs.f64 	%fd204, %fd27;
	setp.ltu.f64 	%p105, %fd204, 0d41E0000000000000;
	@%p105 bra 	$L__BB5_85;

	{ // callseq 38, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd64;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd478, [retval0+0];
	} // callseq 38
	ld.local.u32 	%r608, [%rd1];

$L__BB5_85:
	and.b32  	%r366, %r608, 1;
	shl.b32 	%r367, %r608, 3;
	and.b32  	%r368, %r367, 8;
	setp.eq.s32 	%p106, %r366, 0;
	selp.f64 	%fd206, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p106;
	mul.wide.s32 	%rd116, %r368, 8;
	mov.u64 	%rd117, __cudart_sin_cos_coeffs;
	add.s64 	%rd118, %rd117, %rd116;
	ld.global.nc.f64 	%fd207, [%rd118+8];
	mul.rn.f64 	%fd32, %fd478, %fd478;
	fma.rn.f64 	%fd208, %fd206, %fd32, %fd207;
	ld.global.nc.f64 	%fd209, [%rd118+16];
	fma.rn.f64 	%fd210, %fd208, %fd32, %fd209;
	ld.global.nc.f64 	%fd211, [%rd118+24];
	fma.rn.f64 	%fd212, %fd210, %fd32, %fd211;
	ld.global.nc.f64 	%fd213, [%rd118+32];
	fma.rn.f64 	%fd214, %fd212, %fd32, %fd213;
	ld.global.nc.f64 	%fd215, [%rd118+40];
	fma.rn.f64 	%fd216, %fd214, %fd32, %fd215;
	ld.global.nc.f64 	%fd217, [%rd118+48];
	fma.rn.f64 	%fd33, %fd216, %fd32, %fd217;
	fma.rn.f64 	%fd480, %fd33, %fd478, %fd478;
	@%p106 bra 	$L__BB5_87;

	mov.f64 	%fd218, 0d3FF0000000000000;
	fma.rn.f64 	%fd480, %fd33, %fd32, %fd218;

$L__BB5_87:
	and.b32  	%r369, %r608, 2;
	setp.eq.s32 	%p107, %r369, 0;
	@%p107 bra 	$L__BB5_89;

	mov.f64 	%fd219, 0d0000000000000000;
	mov.f64 	%fd220, 0dBFF0000000000000;
	fma.rn.f64 	%fd480, %fd480, %fd220, %fd219;

$L__BB5_89:
	add.rn.f64 	%fd39, %fd26, %fd26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r370, %temp}, %fd39;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r371}, %fd39;
	}
	and.b32  	%r372, %r371, 2147483647;
	setp.eq.s32 	%p108, %r372, 2146435072;
	setp.eq.s32 	%p109, %r370, 0;
	and.pred  	%p110, %p109, %p108;
	@%p110 bra 	$L__BB5_92;
	bra.uni 	$L__BB5_90;

$L__BB5_92:
	mov.f64 	%fd230, 0d0000000000000000;
	mul.rn.f64 	%fd481, %fd39, %fd230;
	mov.u32 	%r609, 0;
	bra.uni 	$L__BB5_93;

$L__BB5_90:
	mul.rn.f64 	%fd221, %fd39, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r609, %fd221;
	st.local.u32 	[%rd1], %r609;
	cvt.rn.f64.s32 	%fd222, %r609;
	neg.f64 	%fd223, %fd222;
	mov.f64 	%fd224, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd225, %fd223, %fd224, %fd39;
	mov.f64 	%fd226, 0d3C91A62633145C00;
	fma.rn.f64 	%fd227, %fd223, %fd226, %fd225;
	mov.f64 	%fd228, 0d397B839A252049C0;
	fma.rn.f64 	%fd481, %fd223, %fd228, %fd227;
	abs.f64 	%fd229, %fd39;
	setp.ltu.f64 	%p111, %fd229, 0d41E0000000000000;
	@%p111 bra 	$L__BB5_93;

	add.u64 	%rd203, %SP, 0;
	{ // callseq 39, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd39;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd203;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd481, [retval0+0];
	} // callseq 39
	ld.local.u32 	%r609, [%rd1];

$L__BB5_93:
	and.b32  	%r374, %r609, 1;
	shl.b32 	%r375, %r609, 3;
	and.b32  	%r376, %r375, 8;
	setp.eq.s32 	%p112, %r374, 0;
	selp.f64 	%fd231, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p112;
	mul.wide.s32 	%rd120, %r376, 8;
	add.s64 	%rd122, %rd117, %rd120;
	ld.global.nc.f64 	%fd232, [%rd122+8];
	mul.rn.f64 	%fd44, %fd481, %fd481;
	fma.rn.f64 	%fd233, %fd231, %fd44, %fd232;
	ld.global.nc.f64 	%fd234, [%rd122+16];
	fma.rn.f64 	%fd235, %fd233, %fd44, %fd234;
	ld.global.nc.f64 	%fd236, [%rd122+24];
	fma.rn.f64 	%fd237, %fd235, %fd44, %fd236;
	ld.global.nc.f64 	%fd238, [%rd122+32];
	fma.rn.f64 	%fd239, %fd237, %fd44, %fd238;
	ld.global.nc.f64 	%fd240, [%rd122+40];
	fma.rn.f64 	%fd241, %fd239, %fd44, %fd240;
	ld.global.nc.f64 	%fd242, [%rd122+48];
	fma.rn.f64 	%fd45, %fd241, %fd44, %fd242;
	fma.rn.f64 	%fd483, %fd45, %fd481, %fd481;
	@%p112 bra 	$L__BB5_95;

	mov.f64 	%fd243, 0d3FF0000000000000;
	fma.rn.f64 	%fd483, %fd45, %fd44, %fd243;

$L__BB5_95:
	and.b32  	%r377, %r609, 2;
	setp.eq.s32 	%p113, %r377, 0;
	@%p113 bra 	$L__BB5_97;

	mov.f64 	%fd244, 0d0000000000000000;
	mov.f64 	%fd245, 0dBFF0000000000000;
	fma.rn.f64 	%fd483, %fd483, %fd245, %fd244;

$L__BB5_97:
	mul.rn.f64 	%fd246, %fd483, 0d4034000000000000;
	mul.rn.f64 	%fd247, %fd480, 0d4034000000000000;
	add.rn.f64 	%fd51, %fd247, %fd246;
	mul.rn.f32 	%f217, %f64, 0f3F22F983;
	cvt.rni.s32.f32 	%r613, %f217;
	cvt.rn.f32.s32 	%f218, %r613;
	mov.f32 	%f219, 0fBFC90FDA;
	fma.rn.f32 	%f220, %f218, %f219, %f64;
	mov.f32 	%f221, 0fB3A22168;
	fma.rn.f32 	%f222, %f218, %f221, %f220;
	mov.f32 	%f223, 0fA7C234C5;
	fma.rn.f32 	%f328, %f218, %f223, %f222;
	abs.f32 	%f66, %f64;
	setp.ltu.f32 	%p114, %f66, 0f47CE4780;
	@%p114 bra 	$L__BB5_105;

	setp.eq.f32 	%p115, %f66, 0f7F800000;
	@%p115 bra 	$L__BB5_104;
	bra.uni 	$L__BB5_99;

$L__BB5_104:
	mov.f32 	%f226, 0f00000000;
	mul.rn.f32 	%f328, %f64, %f226;
	mov.u32 	%r613, 0;
	bra.uni 	$L__BB5_105;

$L__BB5_99:
	mov.b32 	%r87, %f64;
	bfe.u32 	%r379, %r87, 23, 8;
	add.s32 	%r88, %r379, -128;
	shl.b32 	%r380, %r87, 8;
	or.b32  	%r89, %r380, -2147483648;
	shr.u32 	%r90, %r88, 5;
	mov.u64 	%rd219, 0;
	mov.u32 	%r610, 0;
	mov.u64 	%rd218, __cudart_i2opi_f;
	mov.u64 	%rd217, %rd1;

$L__BB5_100:
	.pragma "nounroll";
	ld.global.nc.u32 	%r381, [%rd218];
	mad.wide.u32 	%rd125, %r381, %r89, %rd219;
	shr.u64 	%rd219, %rd125, 32;
	st.local.u32 	[%rd217], %rd125;
	add.s64 	%rd218, %rd218, 4;
	add.s64 	%rd217, %rd217, 4;
	add.s32 	%r610, %r610, 1;
	setp.ne.s32 	%p116, %r610, 6;
	@%p116 bra 	$L__BB5_100;

	add.s64 	%rd187, %rd1, 24;
	st.local.u32 	[%rd187], %rd219;
	mov.u32 	%r382, 4;
	sub.s32 	%r93, %r382, %r90;
	mov.u32 	%r383, 6;
	sub.s32 	%r384, %r383, %r90;
	mul.wide.s32 	%rd126, %r384, 4;
	add.s64 	%rd127, %rd1, %rd126;
	ld.local.u32 	%r611, [%rd127];
	ld.local.u32 	%r612, [%rd127+-4];
	and.b32  	%r96, %r88, 31;
	setp.eq.s32 	%p117, %r96, 0;
	@%p117 bra 	$L__BB5_103;

	mov.u32 	%r385, 32;
	sub.s32 	%r386, %r385, %r96;
	shr.u32 	%r387, %r612, %r386;
	shl.b32 	%r388, %r611, %r96;
	add.s32 	%r611, %r387, %r388;
	mul.wide.s32 	%rd128, %r93, 4;
	add.s64 	%rd129, %rd1, %rd128;
	ld.local.u32 	%r389, [%rd129];
	shr.u32 	%r390, %r389, %r386;
	shl.b32 	%r391, %r612, %r96;
	add.s32 	%r612, %r390, %r391;

$L__BB5_103:
	and.b32  	%r392, %r87, -2147483648;
	shr.u32 	%r393, %r612, 30;
	shl.b32 	%r394, %r611, 2;
	or.b32  	%r395, %r393, %r394;
	shr.u32 	%r396, %r395, 31;
	shr.u32 	%r397, %r611, 30;
	add.s32 	%r398, %r396, %r397;
	neg.s32 	%r399, %r398;
	setp.eq.s32 	%p118, %r392, 0;
	selp.b32 	%r613, %r398, %r399, %p118;
	setp.ne.s32 	%p119, %r396, 0;
	xor.b32  	%r400, %r392, -2147483648;
	selp.b32 	%r401, %r400, %r392, %p119;
	selp.b32 	%r402, -1, 0, %p119;
	xor.b32  	%r403, %r395, %r402;
	shl.b32 	%r404, %r612, 2;
	xor.b32  	%r405, %r404, %r402;
	cvt.u64.u32 	%rd130, %r403;
	cvt.u64.u32 	%rd131, %r405;
	bfi.b64 	%rd132, %rd130, %rd131, 32, 32;
	cvt.rn.f64.s64 	%fd248, %rd132;
	mul.rn.f64 	%fd249, %fd248, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f224, %fd249;
	setp.eq.s32 	%p120, %r401, 0;
	neg.f32 	%f225, %f224;
	selp.f32 	%f328, %f224, %f225, %p120;

$L__BB5_105:
	and.b32  	%r103, %r613, 1;
	setp.eq.s32 	%p121, %r103, 0;
	selp.f32 	%f70, %f328, 0f3F800000, %p121;
	mul.rn.f32 	%f71, %f328, %f328;
	mov.f32 	%f329, 0fB94D4153;
	@%p121 bra 	$L__BB5_107;

	mov.f32 	%f228, 0fBAB607ED;
	mov.f32 	%f229, 0f37CBAC00;
	fma.rn.f32 	%f329, %f229, %f71, %f228;

$L__BB5_107:
	selp.f32 	%f230, 0f3C0885E4, 0f3D2AAABB, %p121;
	fma.rn.f32 	%f231, %f329, %f71, %f230;
	selp.f32 	%f232, 0fBE2AAAA8, 0fBEFFFFFF, %p121;
	fma.rn.f32 	%f233, %f231, %f71, %f232;
	mov.f32 	%f234, 0f00000000;
	fma.rn.f32 	%f235, %f71, %f70, %f234;
	fma.rn.f32 	%f330, %f233, %f235, %f70;
	and.b32  	%r407, %r613, 2;
	setp.eq.s32 	%p123, %r407, 0;
	@%p123 bra 	$L__BB5_109;

	mov.f32 	%f237, 0fBF800000;
	fma.rn.f32 	%f330, %f330, %f237, %f234;

$L__BB5_109:
	cvt.f64.f32 	%fd52, %f64;
	div.rn.f64 	%fd53, %fd52, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r408, %temp}, %fd53;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r409}, %fd53;
	}
	and.b32  	%r410, %r409, 2147483647;
	setp.eq.s32 	%p124, %r410, 2146435072;
	setp.eq.s32 	%p125, %r408, 0;
	and.pred  	%p126, %p125, %p124;
	@%p126 bra 	$L__BB5_112;
	bra.uni 	$L__BB5_110;

$L__BB5_112:
	mov.f64 	%fd259, 0d0000000000000000;
	mul.rn.f64 	%fd484, %fd53, %fd259;
	mov.u32 	%r614, 0;
	bra.uni 	$L__BB5_113;

$L__BB5_110:
	mul.rn.f64 	%fd250, %fd53, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r614, %fd250;
	st.local.u32 	[%rd1], %r614;
	cvt.rn.f64.s32 	%fd251, %r614;
	neg.f64 	%fd252, %fd251;
	mov.f64 	%fd253, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd254, %fd252, %fd253, %fd53;
	mov.f64 	%fd255, 0d3C91A62633145C00;
	fma.rn.f64 	%fd256, %fd252, %fd255, %fd254;
	mov.f64 	%fd257, 0d397B839A252049C0;
	fma.rn.f64 	%fd484, %fd252, %fd257, %fd256;
	abs.f64 	%fd258, %fd53;
	setp.ltu.f64 	%p127, %fd258, 0d41E0000000000000;
	@%p127 bra 	$L__BB5_113;

	add.u64 	%rd204, %SP, 0;
	{ // callseq 40, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd53;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd204;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd484, [retval0+0];
	} // callseq 40
	ld.local.u32 	%r614, [%rd1];

$L__BB5_113:
	and.b32  	%r412, %r614, 1;
	shl.b32 	%r413, %r614, 3;
	and.b32  	%r414, %r413, 8;
	setp.eq.s32 	%p128, %r412, 0;
	selp.f64 	%fd260, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p128;
	mul.wide.s32 	%rd134, %r414, 8;
	add.s64 	%rd136, %rd117, %rd134;
	ld.global.nc.f64 	%fd261, [%rd136+8];
	mul.rn.f64 	%fd58, %fd484, %fd484;
	fma.rn.f64 	%fd262, %fd260, %fd58, %fd261;
	ld.global.nc.f64 	%fd263, [%rd136+16];
	fma.rn.f64 	%fd264, %fd262, %fd58, %fd263;
	ld.global.nc.f64 	%fd265, [%rd136+24];
	fma.rn.f64 	%fd266, %fd264, %fd58, %fd265;
	ld.global.nc.f64 	%fd267, [%rd136+32];
	fma.rn.f64 	%fd268, %fd266, %fd58, %fd267;
	ld.global.nc.f64 	%fd269, [%rd136+40];
	fma.rn.f64 	%fd270, %fd268, %fd58, %fd269;
	ld.global.nc.f64 	%fd271, [%rd136+48];
	fma.rn.f64 	%fd59, %fd270, %fd58, %fd271;
	fma.rn.f64 	%fd486, %fd59, %fd484, %fd484;
	@%p128 bra 	$L__BB5_115;

	mov.f64 	%fd272, 0d3FF0000000000000;
	fma.rn.f64 	%fd486, %fd59, %fd58, %fd272;

$L__BB5_115:
	and.b32  	%r415, %r614, 2;
	setp.eq.s32 	%p129, %r415, 0;
	@%p129 bra 	$L__BB5_117;

	mov.f64 	%fd273, 0d0000000000000000;
	mov.f64 	%fd274, 0dBFF0000000000000;
	fma.rn.f64 	%fd486, %fd486, %fd274, %fd273;

$L__BB5_117:
	mul.rn.f64 	%fd275, %fd486, 0d4044000000000000;
	cvt.f64.f32 	%fd276, %f330;
	mul.rn.f64 	%fd277, %fd276, 0d4034000000000000;
	add.rn.f64 	%fd65, %fd277, %fd275;
	div.rn.f64 	%fd66, %fd52, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r416, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r417}, %fd66;
	}
	and.b32  	%r418, %r417, 2147483647;
	setp.eq.s32 	%p130, %r418, 2146435072;
	setp.eq.s32 	%p131, %r416, 0;
	and.pred  	%p132, %p131, %p130;
	@%p132 bra 	$L__BB5_120;
	bra.uni 	$L__BB5_118;

$L__BB5_120:
	mov.f64 	%fd287, 0d0000000000000000;
	mul.rn.f64 	%fd487, %fd66, %fd287;
	mov.u32 	%r615, 0;
	bra.uni 	$L__BB5_121;

$L__BB5_118:
	mul.rn.f64 	%fd278, %fd66, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r615, %fd278;
	st.local.u32 	[%rd1], %r615;
	cvt.rn.f64.s32 	%fd279, %r615;
	neg.f64 	%fd280, %fd279;
	mov.f64 	%fd281, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd282, %fd280, %fd281, %fd66;
	mov.f64 	%fd283, 0d3C91A62633145C00;
	fma.rn.f64 	%fd284, %fd280, %fd283, %fd282;
	mov.f64 	%fd285, 0d397B839A252049C0;
	fma.rn.f64 	%fd487, %fd280, %fd285, %fd284;
	abs.f64 	%fd286, %fd66;
	setp.ltu.f64 	%p133, %fd286, 0d41E0000000000000;
	@%p133 bra 	$L__BB5_121;

	add.u64 	%rd198, %SP, 0;
	{ // callseq 41, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd66;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd198;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd487, [retval0+0];
	} // callseq 41
	ld.local.u32 	%r615, [%rd1];

$L__BB5_121:
	and.b32  	%r420, %r615, 1;
	shl.b32 	%r421, %r615, 3;
	and.b32  	%r422, %r421, 8;
	setp.eq.s32 	%p134, %r420, 0;
	selp.f64 	%fd288, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p134;
	mul.wide.s32 	%rd138, %r422, 8;
	add.s64 	%rd140, %rd117, %rd138;
	ld.global.nc.f64 	%fd289, [%rd140+8];
	mul.rn.f64 	%fd71, %fd487, %fd487;
	fma.rn.f64 	%fd290, %fd288, %fd71, %fd289;
	ld.global.nc.f64 	%fd291, [%rd140+16];
	fma.rn.f64 	%fd292, %fd290, %fd71, %fd291;
	ld.global.nc.f64 	%fd293, [%rd140+24];
	fma.rn.f64 	%fd294, %fd292, %fd71, %fd293;
	ld.global.nc.f64 	%fd295, [%rd140+32];
	fma.rn.f64 	%fd296, %fd294, %fd71, %fd295;
	ld.global.nc.f64 	%fd297, [%rd140+40];
	fma.rn.f64 	%fd298, %fd296, %fd71, %fd297;
	ld.global.nc.f64 	%fd299, [%rd140+48];
	fma.rn.f64 	%fd72, %fd298, %fd71, %fd299;
	fma.rn.f64 	%fd489, %fd72, %fd487, %fd487;
	@%p134 bra 	$L__BB5_123;

	mov.f64 	%fd300, 0d3FF0000000000000;
	fma.rn.f64 	%fd489, %fd72, %fd71, %fd300;

$L__BB5_123:
	and.b32  	%r423, %r615, 2;
	setp.eq.s32 	%p135, %r423, 0;
	@%p135 bra 	$L__BB5_125;

	mov.f64 	%fd301, 0d0000000000000000;
	mov.f64 	%fd302, 0dBFF0000000000000;
	fma.rn.f64 	%fd489, %fd489, %fd302, %fd301;

$L__BB5_125:
	mul.rn.f64 	%fd303, %fd489, 0d4064000000000000;
	add.rn.f64 	%fd78, %fd65, %fd303;
	div.rn.f64 	%fd79, %fd52, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r424, %temp}, %fd79;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r425}, %fd79;
	}
	and.b32  	%r426, %r425, 2147483647;
	setp.eq.s32 	%p136, %r426, 2146435072;
	setp.eq.s32 	%p137, %r424, 0;
	and.pred  	%p138, %p137, %p136;
	@%p138 bra 	$L__BB5_128;
	bra.uni 	$L__BB5_126;

$L__BB5_128:
	mov.f64 	%fd313, 0d0000000000000000;
	mul.rn.f64 	%fd490, %fd79, %fd313;
	mov.u32 	%r616, 0;
	bra.uni 	$L__BB5_129;

$L__BB5_126:
	mul.rn.f64 	%fd304, %fd79, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r616, %fd304;
	st.local.u32 	[%rd1], %r616;
	cvt.rn.f64.s32 	%fd305, %r616;
	neg.f64 	%fd306, %fd305;
	mov.f64 	%fd307, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd308, %fd306, %fd307, %fd79;
	mov.f64 	%fd309, 0d3C91A62633145C00;
	fma.rn.f64 	%fd310, %fd306, %fd309, %fd308;
	mov.f64 	%fd311, 0d397B839A252049C0;
	fma.rn.f64 	%fd490, %fd306, %fd311, %fd310;
	abs.f64 	%fd312, %fd79;
	setp.ltu.f64 	%p139, %fd312, 0d41E0000000000000;
	@%p139 bra 	$L__BB5_129;

	add.u64 	%rd199, %SP, 0;
	{ // callseq 42, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd199;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd490, [retval0+0];
	} // callseq 42
	ld.local.u32 	%r616, [%rd1];

$L__BB5_129:
	and.b32  	%r428, %r616, 1;
	shl.b32 	%r429, %r616, 3;
	and.b32  	%r430, %r429, 8;
	setp.eq.s32 	%p140, %r428, 0;
	selp.f64 	%fd314, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p140;
	mul.wide.s32 	%rd142, %r430, 8;
	add.s64 	%rd144, %rd117, %rd142;
	ld.global.nc.f64 	%fd315, [%rd144+8];
	mul.rn.f64 	%fd84, %fd490, %fd490;
	fma.rn.f64 	%fd316, %fd314, %fd84, %fd315;
	ld.global.nc.f64 	%fd317, [%rd144+16];
	fma.rn.f64 	%fd318, %fd316, %fd84, %fd317;
	ld.global.nc.f64 	%fd319, [%rd144+24];
	fma.rn.f64 	%fd320, %fd318, %fd84, %fd319;
	ld.global.nc.f64 	%fd321, [%rd144+32];
	fma.rn.f64 	%fd322, %fd320, %fd84, %fd321;
	ld.global.nc.f64 	%fd323, [%rd144+40];
	fma.rn.f64 	%fd324, %fd322, %fd84, %fd323;
	ld.global.nc.f64 	%fd325, [%rd144+48];
	fma.rn.f64 	%fd85, %fd324, %fd84, %fd325;
	fma.rn.f64 	%fd492, %fd85, %fd490, %fd490;
	@%p140 bra 	$L__BB5_131;

	mov.f64 	%fd326, 0d3FF0000000000000;
	fma.rn.f64 	%fd492, %fd85, %fd84, %fd326;

$L__BB5_131:
	and.b32  	%r431, %r616, 2;
	setp.eq.s32 	%p141, %r431, 0;
	@%p141 bra 	$L__BB5_133;

	mov.f64 	%fd327, 0d0000000000000000;
	mov.f64 	%fd328, 0dBFF0000000000000;
	fma.rn.f64 	%fd492, %fd492, %fd328, %fd327;

$L__BB5_133:
	mul.rn.f64 	%fd329, %fd492, 0d4074000000000000;
	add.rn.f64 	%fd91, %fd78, %fd329;
	mul.rn.f32 	%f238, %f63, 0f3F22F983;
	cvt.rni.s32.f32 	%r620, %f238;
	cvt.rn.f32.s32 	%f239, %r620;
	mov.f32 	%f240, 0fBFC90FDA;
	fma.rn.f32 	%f241, %f239, %f240, %f63;
	mov.f32 	%f242, 0fB3A22168;
	fma.rn.f32 	%f243, %f239, %f242, %f241;
	mov.f32 	%f244, 0fA7C234C5;
	fma.rn.f32 	%f331, %f239, %f244, %f243;
	abs.f32 	%f78, %f63;
	setp.ltu.f32 	%p142, %f78, 0f47CE4780;
	@%p142 bra 	$L__BB5_141;

	setp.eq.f32 	%p143, %f78, 0f7F800000;
	@%p143 bra 	$L__BB5_140;
	bra.uni 	$L__BB5_135;

$L__BB5_140:
	mov.f32 	%f247, 0f00000000;
	mul.rn.f32 	%f331, %f63, %f247;
	mov.u32 	%r620, 0;
	bra.uni 	$L__BB5_141;

$L__BB5_135:
	mov.b32 	%r114, %f63;
	bfe.u32 	%r433, %r114, 23, 8;
	add.s32 	%r115, %r433, -128;
	shl.b32 	%r434, %r114, 8;
	or.b32  	%r116, %r434, -2147483648;
	shr.u32 	%r117, %r115, 5;
	mov.u64 	%rd222, 0;
	mov.u32 	%r617, 0;
	mov.u64 	%rd221, __cudart_i2opi_f;
	mov.u64 	%rd220, %rd1;

$L__BB5_136:
	.pragma "nounroll";
	ld.global.nc.u32 	%r435, [%rd221];
	mad.wide.u32 	%rd147, %r435, %r116, %rd222;
	shr.u64 	%rd222, %rd147, 32;
	st.local.u32 	[%rd220], %rd147;
	add.s64 	%rd221, %rd221, 4;
	add.s64 	%rd220, %rd220, 4;
	add.s32 	%r617, %r617, 1;
	setp.ne.s32 	%p144, %r617, 6;
	@%p144 bra 	$L__BB5_136;

	add.s64 	%rd188, %rd1, 24;
	st.local.u32 	[%rd188], %rd222;
	mov.u32 	%r436, 4;
	sub.s32 	%r120, %r436, %r117;
	mov.u32 	%r437, 6;
	sub.s32 	%r438, %r437, %r117;
	mul.wide.s32 	%rd148, %r438, 4;
	add.s64 	%rd149, %rd1, %rd148;
	ld.local.u32 	%r618, [%rd149];
	ld.local.u32 	%r619, [%rd149+-4];
	and.b32  	%r123, %r115, 31;
	setp.eq.s32 	%p145, %r123, 0;
	@%p145 bra 	$L__BB5_139;

	mov.u32 	%r439, 32;
	sub.s32 	%r440, %r439, %r123;
	shr.u32 	%r441, %r619, %r440;
	shl.b32 	%r442, %r618, %r123;
	add.s32 	%r618, %r441, %r442;
	mul.wide.s32 	%rd150, %r120, 4;
	add.s64 	%rd151, %rd1, %rd150;
	ld.local.u32 	%r443, [%rd151];
	shr.u32 	%r444, %r443, %r440;
	shl.b32 	%r445, %r619, %r123;
	add.s32 	%r619, %r444, %r445;

$L__BB5_139:
	and.b32  	%r446, %r114, -2147483648;
	shr.u32 	%r447, %r619, 30;
	shl.b32 	%r448, %r618, 2;
	or.b32  	%r449, %r447, %r448;
	shr.u32 	%r450, %r449, 31;
	shr.u32 	%r451, %r618, 30;
	add.s32 	%r452, %r450, %r451;
	neg.s32 	%r453, %r452;
	setp.eq.s32 	%p146, %r446, 0;
	selp.b32 	%r620, %r452, %r453, %p146;
	setp.ne.s32 	%p147, %r450, 0;
	xor.b32  	%r454, %r446, -2147483648;
	selp.b32 	%r455, %r454, %r446, %p147;
	selp.b32 	%r456, -1, 0, %p147;
	xor.b32  	%r457, %r449, %r456;
	shl.b32 	%r458, %r619, 2;
	xor.b32  	%r459, %r458, %r456;
	cvt.u64.u32 	%rd152, %r457;
	cvt.u64.u32 	%rd153, %r459;
	bfi.b64 	%rd154, %rd152, %rd153, 32, 32;
	cvt.rn.f64.s64 	%fd330, %rd154;
	mul.rn.f64 	%fd331, %fd330, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f245, %fd331;
	setp.eq.s32 	%p148, %r455, 0;
	neg.f32 	%f246, %f245;
	selp.f32 	%f331, %f245, %f246, %p148;

$L__BB5_141:
	cvt.rn.f32.f64 	%f249, %fd51;
	cvt.f64.f32 	%fd92, %f249;
	and.b32  	%r130, %r620, 1;
	setp.eq.s32 	%p149, %r130, 0;
	selp.f32 	%f82, %f331, 0f3F800000, %p149;
	mul.rn.f32 	%f83, %f331, %f331;
	mov.f32 	%f332, 0fB94D4153;
	@%p149 bra 	$L__BB5_143;

	mov.f32 	%f250, 0fBAB607ED;
	mov.f32 	%f251, 0f37CBAC00;
	fma.rn.f32 	%f332, %f251, %f83, %f250;

$L__BB5_143:
	selp.f32 	%f252, 0f3C0885E4, 0f3D2AAABB, %p149;
	fma.rn.f32 	%f253, %f332, %f83, %f252;
	selp.f32 	%f254, 0fBE2AAAA8, 0fBEFFFFFF, %p149;
	fma.rn.f32 	%f255, %f253, %f83, %f254;
	mov.f32 	%f256, 0f00000000;
	fma.rn.f32 	%f257, %f83, %f82, %f256;
	fma.rn.f32 	%f333, %f255, %f257, %f82;
	and.b32  	%r461, %r620, 2;
	setp.eq.s32 	%p151, %r461, 0;
	@%p151 bra 	$L__BB5_145;

	mov.f32 	%f259, 0fBF800000;
	fma.rn.f32 	%f333, %f333, %f259, %f256;

$L__BB5_145:
	div.rn.f64 	%fd93, %fd26, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r462, %temp}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r463}, %fd93;
	}
	and.b32  	%r464, %r463, 2147483647;
	setp.eq.s32 	%p152, %r464, 2146435072;
	setp.eq.s32 	%p153, %r462, 0;
	and.pred  	%p154, %p153, %p152;
	@%p154 bra 	$L__BB5_148;
	bra.uni 	$L__BB5_146;

$L__BB5_148:
	mov.f64 	%fd341, 0d0000000000000000;
	mul.rn.f64 	%fd493, %fd93, %fd341;
	mov.u32 	%r621, 0;
	bra.uni 	$L__BB5_149;

$L__BB5_146:
	mul.rn.f64 	%fd332, %fd93, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r621, %fd332;
	st.local.u32 	[%rd1], %r621;
	cvt.rn.f64.s32 	%fd333, %r621;
	neg.f64 	%fd334, %fd333;
	mov.f64 	%fd335, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd336, %fd334, %fd335, %fd93;
	mov.f64 	%fd337, 0d3C91A62633145C00;
	fma.rn.f64 	%fd338, %fd334, %fd337, %fd336;
	mov.f64 	%fd339, 0d397B839A252049C0;
	fma.rn.f64 	%fd493, %fd334, %fd339, %fd338;
	abs.f64 	%fd340, %fd93;
	setp.ltu.f64 	%p155, %fd340, 0d41E0000000000000;
	@%p155 bra 	$L__BB5_149;

	add.u64 	%rd200, %SP, 0;
	{ // callseq 43, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd93;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd200;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd493, [retval0+0];
	} // callseq 43
	ld.local.u32 	%r621, [%rd1];

$L__BB5_149:
	and.b32  	%r466, %r621, 1;
	shl.b32 	%r467, %r621, 3;
	and.b32  	%r468, %r467, 8;
	setp.eq.s32 	%p156, %r466, 0;
	selp.f64 	%fd342, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p156;
	mul.wide.s32 	%rd156, %r468, 8;
	add.s64 	%rd158, %rd117, %rd156;
	ld.global.nc.f64 	%fd343, [%rd158+8];
	mul.rn.f64 	%fd98, %fd493, %fd493;
	fma.rn.f64 	%fd344, %fd342, %fd98, %fd343;
	ld.global.nc.f64 	%fd345, [%rd158+16];
	fma.rn.f64 	%fd346, %fd344, %fd98, %fd345;
	ld.global.nc.f64 	%fd347, [%rd158+24];
	fma.rn.f64 	%fd348, %fd346, %fd98, %fd347;
	ld.global.nc.f64 	%fd349, [%rd158+32];
	fma.rn.f64 	%fd350, %fd348, %fd98, %fd349;
	ld.global.nc.f64 	%fd351, [%rd158+40];
	fma.rn.f64 	%fd352, %fd350, %fd98, %fd351;
	ld.global.nc.f64 	%fd353, [%rd158+48];
	fma.rn.f64 	%fd99, %fd352, %fd98, %fd353;
	fma.rn.f64 	%fd495, %fd99, %fd493, %fd493;
	@%p156 bra 	$L__BB5_151;

	mov.f64 	%fd354, 0d3FF0000000000000;
	fma.rn.f64 	%fd495, %fd99, %fd98, %fd354;

$L__BB5_151:
	and.b32  	%r469, %r621, 2;
	setp.eq.s32 	%p157, %r469, 0;
	@%p157 bra 	$L__BB5_153;

	mov.f64 	%fd355, 0d0000000000000000;
	mov.f64 	%fd356, 0dBFF0000000000000;
	fma.rn.f64 	%fd495, %fd495, %fd356, %fd355;

$L__BB5_153:
	mul.rn.f64 	%fd357, %fd495, 0d4044000000000000;
	cvt.f64.f32 	%fd358, %f333;
	mul.rn.f64 	%fd359, %fd358, 0d4034000000000000;
	add.rn.f64 	%fd105, %fd359, %fd357;
	div.rn.f64 	%fd106, %fd26, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r470, %temp}, %fd106;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r471}, %fd106;
	}
	and.b32  	%r472, %r471, 2147483647;
	setp.eq.s32 	%p158, %r472, 2146435072;
	setp.eq.s32 	%p159, %r470, 0;
	and.pred  	%p160, %p159, %p158;
	@%p160 bra 	$L__BB5_156;
	bra.uni 	$L__BB5_154;

$L__BB5_156:
	mov.f64 	%fd369, 0d0000000000000000;
	mul.rn.f64 	%fd496, %fd106, %fd369;
	mov.u32 	%r622, 0;
	bra.uni 	$L__BB5_157;

$L__BB5_154:
	mul.rn.f64 	%fd360, %fd106, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r622, %fd360;
	st.local.u32 	[%rd1], %r622;
	cvt.rn.f64.s32 	%fd361, %r622;
	neg.f64 	%fd362, %fd361;
	mov.f64 	%fd363, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd364, %fd362, %fd363, %fd106;
	mov.f64 	%fd365, 0d3C91A62633145C00;
	fma.rn.f64 	%fd366, %fd362, %fd365, %fd364;
	mov.f64 	%fd367, 0d397B839A252049C0;
	fma.rn.f64 	%fd496, %fd362, %fd367, %fd366;
	abs.f64 	%fd368, %fd106;
	setp.ltu.f64 	%p161, %fd368, 0d41E0000000000000;
	@%p161 bra 	$L__BB5_157;

	add.u64 	%rd201, %SP, 0;
	{ // callseq 44, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd201;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd496, [retval0+0];
	} // callseq 44
	ld.local.u32 	%r622, [%rd1];

$L__BB5_157:
	and.b32  	%r474, %r622, 1;
	shl.b32 	%r475, %r622, 3;
	and.b32  	%r476, %r475, 8;
	setp.eq.s32 	%p162, %r474, 0;
	selp.f64 	%fd370, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p162;
	mul.wide.s32 	%rd160, %r476, 8;
	add.s64 	%rd162, %rd117, %rd160;
	ld.global.nc.f64 	%fd371, [%rd162+8];
	mul.rn.f64 	%fd111, %fd496, %fd496;
	fma.rn.f64 	%fd372, %fd370, %fd111, %fd371;
	ld.global.nc.f64 	%fd373, [%rd162+16];
	fma.rn.f64 	%fd374, %fd372, %fd111, %fd373;
	ld.global.nc.f64 	%fd375, [%rd162+24];
	fma.rn.f64 	%fd376, %fd374, %fd111, %fd375;
	ld.global.nc.f64 	%fd377, [%rd162+32];
	fma.rn.f64 	%fd378, %fd376, %fd111, %fd377;
	ld.global.nc.f64 	%fd379, [%rd162+40];
	fma.rn.f64 	%fd380, %fd378, %fd111, %fd379;
	ld.global.nc.f64 	%fd381, [%rd162+48];
	fma.rn.f64 	%fd112, %fd380, %fd111, %fd381;
	fma.rn.f64 	%fd498, %fd112, %fd496, %fd496;
	@%p162 bra 	$L__BB5_159;

	mov.f64 	%fd382, 0d3FF0000000000000;
	fma.rn.f64 	%fd498, %fd112, %fd111, %fd382;

$L__BB5_159:
	and.b32  	%r477, %r622, 2;
	setp.eq.s32 	%p163, %r477, 0;
	@%p163 bra 	$L__BB5_161;

	mov.f64 	%fd383, 0d0000000000000000;
	mov.f64 	%fd384, 0dBFF0000000000000;
	fma.rn.f64 	%fd498, %fd498, %fd384, %fd383;

$L__BB5_161:
	mul.rn.f64 	%fd385, %fd498, 0d4062C00000000000;
	add.rn.f64 	%fd118, %fd105, %fd385;
	div.rn.f64 	%fd119, %fd26, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r478, %temp}, %fd119;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r479}, %fd119;
	}
	and.b32  	%r480, %r479, 2147483647;
	setp.eq.s32 	%p164, %r480, 2146435072;
	setp.eq.s32 	%p165, %r478, 0;
	and.pred  	%p166, %p165, %p164;
	@%p166 bra 	$L__BB5_164;
	bra.uni 	$L__BB5_162;

$L__BB5_164:
	mov.f64 	%fd395, 0d0000000000000000;
	mul.rn.f64 	%fd499, %fd119, %fd395;
	mov.u32 	%r623, 0;
	bra.uni 	$L__BB5_165;

$L__BB5_162:
	mul.rn.f64 	%fd386, %fd119, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r623, %fd386;
	st.local.u32 	[%rd1], %r623;
	cvt.rn.f64.s32 	%fd387, %r623;
	neg.f64 	%fd388, %fd387;
	mov.f64 	%fd389, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd390, %fd388, %fd389, %fd119;
	mov.f64 	%fd391, 0d3C91A62633145C00;
	fma.rn.f64 	%fd392, %fd388, %fd391, %fd390;
	mov.f64 	%fd393, 0d397B839A252049C0;
	fma.rn.f64 	%fd499, %fd388, %fd393, %fd392;
	abs.f64 	%fd394, %fd119;
	setp.ltu.f64 	%p167, %fd394, 0d41E0000000000000;
	@%p167 bra 	$L__BB5_165;

	add.u64 	%rd202, %SP, 0;
	{ // callseq 45, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd202;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd499, [retval0+0];
	} // callseq 45
	ld.local.u32 	%r623, [%rd1];

$L__BB5_165:
	and.b32  	%r482, %r623, 1;
	shl.b32 	%r483, %r623, 3;
	and.b32  	%r484, %r483, 8;
	setp.eq.s32 	%p168, %r482, 0;
	selp.f64 	%fd396, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p168;
	mul.wide.s32 	%rd164, %r484, 8;
	add.s64 	%rd166, %rd117, %rd164;
	ld.global.nc.f64 	%fd397, [%rd166+8];
	mul.rn.f64 	%fd124, %fd499, %fd499;
	fma.rn.f64 	%fd398, %fd396, %fd124, %fd397;
	ld.global.nc.f64 	%fd399, [%rd166+16];
	fma.rn.f64 	%fd400, %fd398, %fd124, %fd399;
	ld.global.nc.f64 	%fd401, [%rd166+24];
	fma.rn.f64 	%fd402, %fd400, %fd124, %fd401;
	ld.global.nc.f64 	%fd403, [%rd166+32];
	fma.rn.f64 	%fd404, %fd402, %fd124, %fd403;
	ld.global.nc.f64 	%fd405, [%rd166+40];
	fma.rn.f64 	%fd406, %fd404, %fd124, %fd405;
	ld.global.nc.f64 	%fd407, [%rd166+48];
	fma.rn.f64 	%fd125, %fd406, %fd124, %fd407;
	fma.rn.f64 	%fd501, %fd125, %fd499, %fd499;
	@%p168 bra 	$L__BB5_167;

	mov.f64 	%fd408, 0d3FF0000000000000;
	fma.rn.f64 	%fd501, %fd125, %fd124, %fd408;

$L__BB5_167:
	and.b32  	%r485, %r623, 2;
	setp.eq.s32 	%p169, %r485, 0;
	@%p169 bra 	$L__BB5_169;

	mov.f64 	%fd409, 0d0000000000000000;
	mov.f64 	%fd410, 0dBFF0000000000000;
	fma.rn.f64 	%fd501, %fd501, %fd410, %fd409;

$L__BB5_169:
	mul.rn.f64 	%fd411, %fd501, 0d4072C00000000000;
	add.rn.f64 	%fd412, %fd118, %fd411;
	add.rn.f64 	%fd131, %fd412, %fd92;
	add.rn.f64 	%fd132, %fd91, %fd92;
	add.rn.f64 	%fd413, %fd24, %fd24;
	add.rn.f64 	%fd414, %fd413, 0dC059000000000000;
	mul.rn.f64 	%fd415, %fd25, 0d4008000000000000;
	add.rn.f64 	%fd133, %fd415, %fd414;
	abs.f64 	%fd134, %fd25;
	{ // callseq 46, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd504, [retval0+0];
	} // callseq 46
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd25;
	}
	setp.lt.s32 	%p170, %r140, 0;
	and.pred  	%p3, %p170, %p6;
	not.pred 	%p172, %p3;
	@%p172 bra 	$L__BB5_171;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r486}, %fd504;
	}
	xor.b32  	%r487, %r486, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r488, %temp}, %fd504;
	}
	mov.b64 	%fd504, {%r488, %r487};

$L__BB5_171:
	setp.eq.f32 	%p173, %f62, 0f00000000;
	@%p173 bra 	$L__BB5_175;
	bra.uni 	$L__BB5_172;

$L__BB5_175:
	selp.b32 	%r489, %r140, 0, %p6;
	mov.u32 	%r490, 0;
	or.b32  	%r491, %r489, 2146435072;
	setp.lt.s32 	%p177, %r2, 0;
	selp.b32 	%r492, %r491, %r489, %p177;
	mov.b64 	%fd504, {%r490, %r492};
	bra.uni 	$L__BB5_176;

$L__BB5_172:
	setp.gt.s32 	%p174, %r140, -1;
	@%p174 bra 	$L__BB5_176;

	mov.f64 	%fd416, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd417, %fd416;
	setp.eq.f64 	%p175, %fd417, 0d4000000000000000;
	@%p175 bra 	$L__BB5_176;

	mov.f64 	%fd504, 0dFFF8000000000000;

$L__BB5_176:
	add.rn.f64 	%fd419, %fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r493}, %fd419;
	}
	and.b32  	%r494, %r493, 2146435072;
	setp.ne.s32 	%p178, %r494, 2146435072;
	@%p178 bra 	$L__BB5_183;

	setp.gtu.f64 	%p179, %fd134, 0d7FF0000000000000;
	@%p179 bra 	$L__BB5_182;
	bra.uni 	$L__BB5_178;

$L__BB5_182:
	mov.f64 	%fd421, 0d4000000000000000;
	add.rn.f64 	%fd504, %fd25, %fd421;
	bra.uni 	$L__BB5_183;

$L__BB5_178:
	mov.f64 	%fd420, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r495, %temp}, %fd420;
	}
	and.b32  	%r141, %r2, 2147483647;
	setp.eq.s32 	%p180, %r141, 2146435072;
	setp.eq.s32 	%p181, %r495, 0;
	and.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB5_181;
	bra.uni 	$L__BB5_179;

$L__BB5_181:
	setp.gt.f64 	%p189, %fd134, 0d3FF0000000000000;
	selp.b32 	%r502, 2146435072, 0, %p189;
	mov.u32 	%r503, 0;
	xor.b32  	%r504, %r502, 2146435072;
	setp.lt.s32 	%p190, %r2, 0;
	selp.b32 	%r505, %r504, %r502, %p190;
	setp.eq.f32 	%p191, %f62, 0fBF800000;
	selp.b32 	%r506, 1072693248, %r505, %p191;
	mov.b64 	%fd504, {%r503, %r506};
	bra.uni 	$L__BB5_183;

$L__BB5_179:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r496, %temp}, %fd25;
	}
	and.b32  	%r497, %r140, 2147483647;
	setp.ne.s32 	%p183, %r497, 2146435072;
	setp.ne.s32 	%p184, %r496, 0;
	or.pred  	%p185, %p183, %p184;
	@%p185 bra 	$L__BB5_183;

	setp.gt.s32 	%p186, %r2, -1;
	selp.b32 	%r498, 2146435072, 0, %p186;
	mov.u32 	%r499, 0;
	setp.ne.s32 	%p187, %r141, 1071644672;
	and.pred  	%p188, %p187, %p3;
	or.b32  	%r500, %r498, -2147483648;
	selp.b32 	%r501, %r500, %r498, %p188;
	mov.b64 	%fd504, {%r499, %r501};

$L__BB5_183:
	mul.rn.f64 	%fd422, %fd504, 0d3FC999999999999A;
	setp.eq.f32 	%p192, %f62, 0f3F800000;
	selp.f64 	%fd423, 0d3FC999999999999A, %fd422, %p192;
	add.rn.f64 	%fd424, %fd133, %fd423;
	mul.rn.f32 	%f260, %f62, %f61;
	cvt.f64.f32 	%fd425, %f260;
	mul.rn.f64 	%fd144, %fd425, 0d3FB999999999999A;
	add.rn.f64 	%fd426, %fd144, %fd424;
	abs.f32 	%f261, %f61;
	sqrt.rn.f32 	%f262, %f261;
	cvt.f64.f32 	%fd145, %f262;
	mul.rn.f64 	%fd427, %fd145, 0d3FC999999999999A;
	add.rn.f64 	%fd428, %fd427, %fd426;
	cvt.rn.f32.f64 	%f263, %fd132;
	cvt.f64.f32 	%fd429, %f263;
	mul.rn.f64 	%fd430, %fd429, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f264, %fd430;
	cvt.f64.f32 	%fd431, %f264;
	add.rn.f64 	%fd146, %fd428, %fd431;
	add.rn.f64 	%fd432, %fd25, %fd25;
	add.rn.f64 	%fd433, %fd24, 0d4072C00000000000;
	add.rn.f64 	%fd147, %fd432, %fd433;
	abs.f64 	%fd148, %fd24;
	{ // callseq 47, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd507, [retval0+0];
	} // callseq 47
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd24;
	}
	setp.lt.s32 	%p193, %r142, 0;
	and.pred  	%p4, %p193, %p6;
	not.pred 	%p195, %p4;
	@%p195 bra 	$L__BB5_185;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r507}, %fd507;
	}
	xor.b32  	%r508, %r507, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r509, %temp}, %fd507;
	}
	mov.b64 	%fd507, {%r509, %r508};

$L__BB5_185:
	setp.eq.f32 	%p196, %f61, 0f00000000;
	@%p196 bra 	$L__BB5_189;
	bra.uni 	$L__BB5_186;

$L__BB5_189:
	selp.b32 	%r510, %r142, 0, %p6;
	mov.u32 	%r511, 0;
	or.b32  	%r512, %r510, 2146435072;
	setp.lt.s32 	%p200, %r2, 0;
	selp.b32 	%r513, %r512, %r510, %p200;
	mov.b64 	%fd507, {%r511, %r513};
	bra.uni 	$L__BB5_190;

$L__BB5_186:
	setp.gt.s32 	%p197, %r142, -1;
	@%p197 bra 	$L__BB5_190;

	mov.f64 	%fd434, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd435, %fd434;
	setp.eq.f64 	%p198, %fd435, 0d4000000000000000;
	@%p198 bra 	$L__BB5_190;

	mov.f64 	%fd507, 0dFFF8000000000000;

$L__BB5_190:
	add.rn.f64 	%fd437, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r514}, %fd437;
	}
	and.b32  	%r515, %r514, 2146435072;
	setp.ne.s32 	%p201, %r515, 2146435072;
	@%p201 bra 	$L__BB5_197;

	setp.gtu.f64 	%p202, %fd148, 0d7FF0000000000000;
	@%p202 bra 	$L__BB5_196;
	bra.uni 	$L__BB5_192;

$L__BB5_196:
	mov.f64 	%fd439, 0d4000000000000000;
	add.rn.f64 	%fd507, %fd24, %fd439;
	bra.uni 	$L__BB5_197;

$L__BB5_192:
	mov.f64 	%fd438, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r516, %temp}, %fd438;
	}
	and.b32  	%r143, %r2, 2147483647;
	setp.eq.s32 	%p203, %r143, 2146435072;
	setp.eq.s32 	%p204, %r516, 0;
	and.pred  	%p205, %p203, %p204;
	@%p205 bra 	$L__BB5_195;
	bra.uni 	$L__BB5_193;

$L__BB5_195:
	setp.gt.f64 	%p212, %fd148, 0d3FF0000000000000;
	selp.b32 	%r523, 2146435072, 0, %p212;
	mov.u32 	%r524, 0;
	xor.b32  	%r525, %r523, 2146435072;
	setp.lt.s32 	%p213, %r2, 0;
	selp.b32 	%r526, %r525, %r523, %p213;
	setp.eq.f32 	%p214, %f61, 0fBF800000;
	selp.b32 	%r527, 1072693248, %r526, %p214;
	mov.b64 	%fd507, {%r524, %r527};
	bra.uni 	$L__BB5_197;

$L__BB5_193:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r517, %temp}, %fd24;
	}
	and.b32  	%r518, %r142, 2147483647;
	setp.ne.s32 	%p206, %r518, 2146435072;
	setp.ne.s32 	%p207, %r517, 0;
	or.pred  	%p208, %p206, %p207;
	@%p208 bra 	$L__BB5_197;

	setp.gt.s32 	%p209, %r2, -1;
	selp.b32 	%r519, 2146435072, 0, %p209;
	mov.u32 	%r520, 0;
	setp.ne.s32 	%p210, %r143, 1071644672;
	and.pred  	%p211, %p210, %p4;
	or.b32  	%r521, %r519, -2147483648;
	selp.b32 	%r522, %r521, %r519, %p211;
	mov.b64 	%fd507, {%r520, %r522};

$L__BB5_197:
	mul.rn.f64 	%fd440, %fd507, 0d3FB999999999999A;
	setp.eq.f32 	%p215, %f61, 0f3F800000;
	selp.f64 	%fd441, 0d3FB999999999999A, %fd440, %p215;
	add.rn.f64 	%fd442, %fd147, %fd441;
	add.rn.f64 	%fd443, %fd144, %fd442;
	mul.rn.f64 	%fd444, %fd145, 0d3FB999999999999A;
	add.rn.f64 	%fd445, %fd444, %fd443;
	cvt.rn.f32.f64 	%f265, %fd131;
	cvt.f64.f32 	%fd446, %f265;
	mul.rn.f64 	%fd447, %fd446, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f266, %fd447;
	cvt.f64.f32 	%fd448, %f266;
	add.rn.f64 	%fd158, %fd445, %fd448;
	cvt.f64.f32 	%fd449, %f59;
	div.rn.f64 	%fd450, %fd449, 0d4066800000000000;
	mul.rn.f64 	%fd451, %fd450, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f89, %fd451;
	mul.rn.f32 	%f267, %f89, 0f3F22F983;
	cvt.rni.s32.f32 	%r631, %f267;
	cvt.rn.f32.s32 	%f268, %r631;
	mov.f32 	%f269, 0fBFC90FDA;
	fma.rn.f32 	%f270, %f268, %f269, %f89;
	mov.f32 	%f271, 0fB3A22168;
	fma.rn.f32 	%f272, %f268, %f271, %f270;
	mov.f32 	%f273, 0fA7C234C5;
	fma.rn.f32 	%f337, %f268, %f273, %f272;
	abs.f32 	%f91, %f89;
	setp.ltu.f32 	%p216, %f91, 0f47CE4780;
	mov.u32 	%r627, %r631;
	mov.f32 	%f334, %f337;
	@%p216 bra 	$L__BB5_205;

	setp.eq.f32 	%p217, %f91, 0f7F800000;
	@%p217 bra 	$L__BB5_204;
	bra.uni 	$L__BB5_199;

$L__BB5_204:
	mov.f32 	%f276, 0f00000000;
	mul.rn.f32 	%f334, %f89, %f276;
	mov.u32 	%r627, 0;
	bra.uni 	$L__BB5_205;

$L__BB5_199:
	mov.b32 	%r145, %f89;
	bfe.u32 	%r529, %r145, 23, 8;
	add.s32 	%r146, %r529, -128;
	shl.b32 	%r530, %r145, 8;
	or.b32  	%r147, %r530, -2147483648;
	shr.u32 	%r148, %r146, 5;
	mov.u64 	%rd225, 0;
	mov.u32 	%r624, 0;
	mov.u64 	%rd224, __cudart_i2opi_f;
	mov.u64 	%rd223, %rd1;

$L__BB5_200:
	.pragma "nounroll";
	ld.global.nc.u32 	%r531, [%rd224];
	mad.wide.u32 	%rd169, %r531, %r147, %rd225;
	shr.u64 	%rd225, %rd169, 32;
	st.local.u32 	[%rd223], %rd169;
	add.s64 	%rd224, %rd224, 4;
	add.s64 	%rd223, %rd223, 4;
	add.s32 	%r624, %r624, 1;
	setp.ne.s32 	%p218, %r624, 6;
	@%p218 bra 	$L__BB5_200;

	add.s64 	%rd189, %rd1, 24;
	st.local.u32 	[%rd189], %rd225;
	mov.u32 	%r532, 4;
	sub.s32 	%r151, %r532, %r148;
	mov.u32 	%r533, 6;
	sub.s32 	%r534, %r533, %r148;
	mul.wide.s32 	%rd170, %r534, 4;
	add.s64 	%rd171, %rd1, %rd170;
	ld.local.u32 	%r625, [%rd171];
	ld.local.u32 	%r626, [%rd171+-4];
	and.b32  	%r154, %r146, 31;
	setp.eq.s32 	%p219, %r154, 0;
	@%p219 bra 	$L__BB5_203;

	mov.u32 	%r535, 32;
	sub.s32 	%r536, %r535, %r154;
	shr.u32 	%r537, %r626, %r536;
	shl.b32 	%r538, %r625, %r154;
	add.s32 	%r625, %r537, %r538;
	mul.wide.s32 	%rd172, %r151, 4;
	add.s64 	%rd173, %rd1, %rd172;
	ld.local.u32 	%r539, [%rd173];
	shr.u32 	%r540, %r539, %r536;
	shl.b32 	%r541, %r626, %r154;
	add.s32 	%r626, %r540, %r541;

$L__BB5_203:
	and.b32  	%r542, %r145, -2147483648;
	shr.u32 	%r543, %r626, 30;
	shl.b32 	%r544, %r625, 2;
	or.b32  	%r545, %r543, %r544;
	shr.u32 	%r546, %r545, 31;
	shr.u32 	%r547, %r625, 30;
	add.s32 	%r548, %r546, %r547;
	neg.s32 	%r549, %r548;
	setp.eq.s32 	%p220, %r542, 0;
	selp.b32 	%r627, %r548, %r549, %p220;
	setp.ne.s32 	%p221, %r546, 0;
	xor.b32  	%r550, %r542, -2147483648;
	selp.b32 	%r551, %r550, %r542, %p221;
	selp.b32 	%r552, -1, 0, %p221;
	xor.b32  	%r553, %r545, %r552;
	shl.b32 	%r554, %r626, 2;
	xor.b32  	%r555, %r554, %r552;
	cvt.u64.u32 	%rd174, %r553;
	cvt.u64.u32 	%rd175, %r555;
	bfi.b64 	%rd176, %rd174, %rd175, 32, 32;
	cvt.rn.f64.s64 	%fd452, %rd176;
	mul.rn.f64 	%fd453, %fd452, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f274, %fd453;
	setp.eq.s32 	%p222, %r551, 0;
	neg.f32 	%f275, %f274;
	selp.f32 	%f334, %f274, %f275, %p222;

$L__BB5_205:
	and.b32  	%r161, %r627, 1;
	setp.eq.s32 	%p223, %r161, 0;
	selp.f32 	%f95, %f334, 0f3F800000, %p223;
	mul.rn.f32 	%f96, %f334, %f334;
	mov.f32 	%f335, 0fB94D4153;
	@%p223 bra 	$L__BB5_207;

	mov.f32 	%f278, 0fBAB607ED;
	mov.f32 	%f279, 0f37CBAC00;
	fma.rn.f32 	%f335, %f279, %f96, %f278;

$L__BB5_207:
	selp.f32 	%f280, 0f3C0885E4, 0f3D2AAABB, %p223;
	fma.rn.f32 	%f281, %f335, %f96, %f280;
	selp.f32 	%f282, 0fBE2AAAA8, 0fBEFFFFFF, %p223;
	fma.rn.f32 	%f283, %f281, %f96, %f282;
	mov.f32 	%f284, 0f00000000;
	fma.rn.f32 	%f285, %f96, %f95, %f284;
	fma.rn.f32 	%f336, %f283, %f285, %f95;
	and.b32  	%r557, %r627, 2;
	setp.eq.s32 	%p225, %r557, 0;
	@%p225 bra 	$L__BB5_209;

	mov.f32 	%f287, 0fBF800000;
	fma.rn.f32 	%f336, %f336, %f287, %f284;

$L__BB5_209:
	@%p216 bra 	$L__BB5_217;

	setp.eq.f32 	%p227, %f91, 0f7F800000;
	@%p227 bra 	$L__BB5_216;
	bra.uni 	$L__BB5_211;

$L__BB5_216:
	mov.f32 	%f290, 0f00000000;
	mul.rn.f32 	%f337, %f89, %f290;
	mov.u32 	%r631, 0;
	bra.uni 	$L__BB5_217;

$L__BB5_211:
	mov.b32 	%r162, %f89;
	bfe.u32 	%r559, %r162, 23, 8;
	add.s32 	%r163, %r559, -128;
	shl.b32 	%r560, %r162, 8;
	or.b32  	%r164, %r560, -2147483648;
	shr.u32 	%r165, %r163, 5;
	mov.u64 	%rd228, 0;
	mov.u32 	%r628, 0;
	mov.u64 	%rd227, __cudart_i2opi_f;
	mov.u64 	%rd226, %rd1;

$L__BB5_212:
	.pragma "nounroll";
	ld.global.nc.u32 	%r561, [%rd227];
	mad.wide.u32 	%rd179, %r561, %r164, %rd228;
	shr.u64 	%rd228, %rd179, 32;
	st.local.u32 	[%rd226], %rd179;
	add.s64 	%rd227, %rd227, 4;
	add.s64 	%rd226, %rd226, 4;
	add.s32 	%r628, %r628, 1;
	setp.ne.s32 	%p228, %r628, 6;
	@%p228 bra 	$L__BB5_212;

	add.s64 	%rd190, %rd1, 24;
	st.local.u32 	[%rd190], %rd228;
	mov.u32 	%r562, 4;
	sub.s32 	%r168, %r562, %r165;
	mov.u32 	%r563, 6;
	sub.s32 	%r564, %r563, %r165;
	mul.wide.s32 	%rd180, %r564, 4;
	add.s64 	%rd181, %rd1, %rd180;
	ld.local.u32 	%r629, [%rd181];
	ld.local.u32 	%r630, [%rd181+-4];
	and.b32  	%r171, %r163, 31;
	setp.eq.s32 	%p229, %r171, 0;
	@%p229 bra 	$L__BB5_215;

	mov.u32 	%r565, 32;
	sub.s32 	%r566, %r565, %r171;
	shr.u32 	%r567, %r630, %r566;
	shl.b32 	%r568, %r629, %r171;
	add.s32 	%r629, %r567, %r568;
	mul.wide.s32 	%rd182, %r168, 4;
	add.s64 	%rd183, %rd1, %rd182;
	ld.local.u32 	%r569, [%rd183];
	shr.u32 	%r570, %r569, %r566;
	shl.b32 	%r571, %r630, %r171;
	add.s32 	%r630, %r570, %r571;

$L__BB5_215:
	and.b32  	%r572, %r162, -2147483648;
	shr.u32 	%r573, %r630, 30;
	shl.b32 	%r574, %r629, 2;
	or.b32  	%r575, %r573, %r574;
	shr.u32 	%r576, %r575, 31;
	shr.u32 	%r577, %r629, 30;
	add.s32 	%r578, %r576, %r577;
	neg.s32 	%r579, %r578;
	setp.eq.s32 	%p230, %r572, 0;
	selp.b32 	%r631, %r578, %r579, %p230;
	setp.ne.s32 	%p231, %r576, 0;
	xor.b32  	%r580, %r572, -2147483648;
	selp.b32 	%r581, %r580, %r572, %p231;
	selp.b32 	%r582, -1, 0, %p231;
	xor.b32  	%r583, %r575, %r582;
	shl.b32 	%r584, %r630, 2;
	xor.b32  	%r585, %r584, %r582;
	cvt.u64.u32 	%rd184, %r583;
	cvt.u64.u32 	%rd185, %r585;
	bfi.b64 	%rd186, %rd184, %rd185, 32, 32;
	cvt.rn.f64.s64 	%fd454, %rd186;
	mul.rn.f64 	%fd455, %fd454, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f288, %fd455;
	setp.eq.s32 	%p232, %r581, 0;
	neg.f32 	%f289, %f288;
	selp.f32 	%f337, %f288, %f289, %p232;

$L__BB5_217:
	add.s32 	%r178, %r631, 1;
	and.b32  	%r179, %r178, 1;
	setp.eq.s32 	%p5, %r179, 0;
	mul.rn.f32 	%f105, %f337, %f337;
	mov.f32 	%f338, 0fB94D4153;
	@%p5 bra 	$L__BB5_219;

	mov.f32 	%f292, 0fBAB607ED;
	mov.f32 	%f293, 0f37CBAC00;
	fma.rn.f32 	%f338, %f293, %f105, %f292;

$L__BB5_219:
	selp.f32 	%f294, %f337, 0f3F800000, %p5;
	selp.f32 	%f295, 0f3C0885E4, 0f3D2AAABB, %p5;
	fma.rn.f32 	%f296, %f338, %f105, %f295;
	selp.f32 	%f297, 0fBE2AAAA8, 0fBEFFFFFF, %p5;
	fma.rn.f32 	%f298, %f296, %f105, %f297;
	mov.f32 	%f299, 0f00000000;
	fma.rn.f32 	%f300, %f105, %f294, %f299;
	fma.rn.f32 	%f339, %f298, %f300, %f294;
	and.b32  	%r587, %r178, 2;
	setp.eq.s32 	%p234, %r587, 0;
	@%p234 bra 	$L__BB5_221;

	mov.f32 	%f302, 0fBF800000;
	fma.rn.f32 	%f339, %f339, %f302, %f299;

$L__BB5_221:
	mov.u32 	%r591, %tid.x;
	mov.u32 	%r590, %ntid.x;
	mov.u32 	%r589, %ctaid.x;
	mad.lo.s32 	%r588, %r589, %r590, %r591;
	mul.wide.s32 	%rd197, %r588, 4;
	ld.param.u64 	%rd196, [bd09_to_wgs84_cuda_float_param_1];
	cvta.to.global.u64 	%rd195, %rd196;
	add.s64 	%rd194, %rd195, %rd197;
	ld.param.u64 	%rd193, [bd09_to_wgs84_cuda_float_param_0];
	cvta.to.global.u64 	%rd192, %rd193;
	add.s64 	%rd191, %rd192, %rd197;
	cvt.f64.f32 	%fd456, %f336;
	mul.rn.f64 	%fd457, %fd456, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd458, %fd457, %fd456;
	add.rn.f64 	%fd459, %fd458, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f303, %fd459;
	sqrt.rn.f32 	%f304, %f303;
	mov.f32 	%f305, 0fCAC2A60A;
	div.rn.f32 	%f306, %f305, %f304;
	mul.rn.f32 	%f307, %f306, %f339;
	cvt.f64.f32 	%fd460, %f307;
	mul.rn.f64 	%fd461, %fd460, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f308, %fd158;
	cvt.f64.f32 	%fd462, %f308;
	mul.rn.f64 	%fd463, %fd462, 0d4066800000000000;
	div.rn.f64 	%fd464, %fd463, %fd461;
	cvt.rn.f32.f64 	%f309, %fd464;
	add.rn.f32 	%f310, %f60, %f309;
	st.global.f32 	[%rd191], %f310;
	mul.rn.f32 	%f311, %f304, %f303;
	cvt.f64.f32 	%fd465, %f311;
	mov.f64 	%fd466, 0dC1582B102DE355C1;
	div.rn.f64 	%fd467, %fd466, %fd465;
	mul.rn.f64 	%fd468, %fd467, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f312, %fd146;
	cvt.f64.f32 	%fd469, %f312;
	mul.rn.f64 	%fd470, %fd469, 0d4066800000000000;
	div.rn.f64 	%fd471, %fd470, %fd468;
	cvt.rn.f32.f64 	%f313, %fd471;
	add.rn.f32 	%f314, %f59, %f313;
	st.global.f32 	[%rd194], %f314;
	ret;

}
	// .globl	gcj02_to_wgs84_exact_cuda_float
.visible .entry gcj02_to_wgs84_exact_cuda_float(
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_0,
	.param .u64 gcj02_to_wgs84_exact_cuda_float_param_1,
	.param .f32 gcj02_to_wgs84_exact_cuda_float_param_2,
	.param .u8 gcj02_to_wgs84_exact_cuda_float_param_3,
	.param .u32 gcj02_to_wgs84_exact_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot6[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<285>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<361>;
	.reg .b32 	%r<717>;
	.reg .f64 	%fd<909>;
	.reg .b64 	%rd<272>;


	mov.u64 	%SPL, __local_depot6;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd61, [gcj02_to_wgs84_exact_cuda_float_param_0];
	ld.param.u64 	%rd62, [gcj02_to_wgs84_exact_cuda_float_param_1];
	add.u64 	%rd63, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r201, %ntid.x;
	mov.u32 	%r202, %ctaid.x;
	mov.u32 	%r203, %tid.x;
	mad.lo.s32 	%r204, %r202, %r201, %r203;
	cvta.to.global.u64 	%rd80, %rd61;
	mul.wide.s32 	%rd81, %r204, 4;
	add.s64 	%rd18, %rd80, %rd81;
	cvta.to.global.u64 	%rd82, %rd62;
	add.s64 	%rd19, %rd82, %rd81;
	ld.global.f32 	%f1, [%rd18];
	add.rn.f32 	%f2, %f1, 0fC2D20000;
	ld.global.f32 	%f3, [%rd19];
	add.rn.f32 	%f4, %f3, 0fC20C0000;
	cvt.f64.f32 	%fd1, %f2;
	mul.rn.f64 	%fd274, %fd1, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f5, %fd274;
	cvt.f64.f32 	%fd2, %f4;
	mul.rn.f64 	%fd275, %fd2, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f6, %fd275;
	cvt.f64.f32 	%fd3, %f5;
	mul.rn.f64 	%fd4, %fd3, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r205, %temp}, %fd4;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd4;
	}
	and.b32  	%r207, %r206, 2147483647;
	setp.eq.s32 	%p7, %r207, 2146435072;
	setp.eq.s32 	%p8, %r205, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB6_3;
	bra.uni 	$L__BB6_1;

$L__BB6_3:
	mov.f64 	%fd285, 0d0000000000000000;
	mul.rn.f64 	%fd849, %fd4, %fd285;
	mov.u32 	%r671, 0;
	bra.uni 	$L__BB6_4;

$L__BB6_1:
	mul.rn.f64 	%fd276, %fd4, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r671, %fd276;
	st.local.u32 	[%rd8], %r671;
	cvt.rn.f64.s32 	%fd277, %r671;
	neg.f64 	%fd278, %fd277;
	mov.f64 	%fd279, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd280, %fd278, %fd279, %fd4;
	mov.f64 	%fd281, 0d3C91A62633145C00;
	fma.rn.f64 	%fd282, %fd278, %fd281, %fd280;
	mov.f64 	%fd283, 0d397B839A252049C0;
	fma.rn.f64 	%fd849, %fd278, %fd283, %fd282;
	abs.f64 	%fd284, %fd4;
	setp.ltu.f64 	%p10, %fd284, 0d41E0000000000000;
	@%p10 bra 	$L__BB6_4;

	{ // callseq 48, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd4;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd849, [retval0+0];
	} // callseq 48
	ld.local.u32 	%r671, [%rd8];

$L__BB6_4:
	and.b32  	%r209, %r671, 1;
	shl.b32 	%r210, %r671, 3;
	and.b32  	%r211, %r210, 8;
	setp.eq.s32 	%p11, %r209, 0;
	selp.f64 	%fd286, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p11;
	mul.wide.s32 	%rd84, %r211, 8;
	mov.u64 	%rd85, __cudart_sin_cos_coeffs;
	add.s64 	%rd86, %rd85, %rd84;
	ld.global.nc.f64 	%fd287, [%rd86+8];
	mul.rn.f64 	%fd9, %fd849, %fd849;
	fma.rn.f64 	%fd288, %fd286, %fd9, %fd287;
	ld.global.nc.f64 	%fd289, [%rd86+16];
	fma.rn.f64 	%fd290, %fd288, %fd9, %fd289;
	ld.global.nc.f64 	%fd291, [%rd86+24];
	fma.rn.f64 	%fd292, %fd290, %fd9, %fd291;
	ld.global.nc.f64 	%fd293, [%rd86+32];
	fma.rn.f64 	%fd294, %fd292, %fd9, %fd293;
	ld.global.nc.f64 	%fd295, [%rd86+40];
	fma.rn.f64 	%fd296, %fd294, %fd9, %fd295;
	ld.global.nc.f64 	%fd297, [%rd86+48];
	fma.rn.f64 	%fd10, %fd296, %fd9, %fd297;
	fma.rn.f64 	%fd851, %fd10, %fd849, %fd849;
	@%p11 bra 	$L__BB6_6;

	mov.f64 	%fd298, 0d3FF0000000000000;
	fma.rn.f64 	%fd851, %fd10, %fd9, %fd298;

$L__BB6_6:
	and.b32  	%r212, %r671, 2;
	setp.eq.s32 	%p12, %r212, 0;
	@%p12 bra 	$L__BB6_8;

	mov.f64 	%fd299, 0d0000000000000000;
	mov.f64 	%fd300, 0dBFF0000000000000;
	fma.rn.f64 	%fd851, %fd851, %fd300, %fd299;

$L__BB6_8:
	add.rn.f64 	%fd16, %fd3, %fd3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd16;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd16;
	}
	and.b32  	%r215, %r214, 2147483647;
	setp.eq.s32 	%p13, %r215, 2146435072;
	setp.eq.s32 	%p14, %r213, 0;
	and.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB6_11;
	bra.uni 	$L__BB6_9;

$L__BB6_11:
	mov.f64 	%fd310, 0d0000000000000000;
	mul.rn.f64 	%fd852, %fd16, %fd310;
	mov.u32 	%r672, 0;
	bra.uni 	$L__BB6_12;

$L__BB6_9:
	mul.rn.f64 	%fd301, %fd16, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r672, %fd301;
	st.local.u32 	[%rd8], %r672;
	cvt.rn.f64.s32 	%fd302, %r672;
	neg.f64 	%fd303, %fd302;
	mov.f64 	%fd304, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd305, %fd303, %fd304, %fd16;
	mov.f64 	%fd306, 0d3C91A62633145C00;
	fma.rn.f64 	%fd307, %fd303, %fd306, %fd305;
	mov.f64 	%fd308, 0d397B839A252049C0;
	fma.rn.f64 	%fd852, %fd303, %fd308, %fd307;
	abs.f64 	%fd309, %fd16;
	setp.ltu.f64 	%p16, %fd309, 0d41E0000000000000;
	@%p16 bra 	$L__BB6_12;

	{ // callseq 49, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd16;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd852, [retval0+0];
	} // callseq 49
	ld.local.u32 	%r672, [%rd8];

$L__BB6_12:
	and.b32  	%r217, %r672, 1;
	shl.b32 	%r218, %r672, 3;
	and.b32  	%r219, %r218, 8;
	setp.eq.s32 	%p17, %r217, 0;
	selp.f64 	%fd311, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	mul.wide.s32 	%rd88, %r219, 8;
	add.s64 	%rd90, %rd85, %rd88;
	ld.global.nc.f64 	%fd312, [%rd90+8];
	mul.rn.f64 	%fd21, %fd852, %fd852;
	fma.rn.f64 	%fd313, %fd311, %fd21, %fd312;
	ld.global.nc.f64 	%fd314, [%rd90+16];
	fma.rn.f64 	%fd315, %fd313, %fd21, %fd314;
	ld.global.nc.f64 	%fd316, [%rd90+24];
	fma.rn.f64 	%fd317, %fd315, %fd21, %fd316;
	ld.global.nc.f64 	%fd318, [%rd90+32];
	fma.rn.f64 	%fd319, %fd317, %fd21, %fd318;
	ld.global.nc.f64 	%fd320, [%rd90+40];
	fma.rn.f64 	%fd321, %fd319, %fd21, %fd320;
	ld.global.nc.f64 	%fd322, [%rd90+48];
	fma.rn.f64 	%fd22, %fd321, %fd21, %fd322;
	fma.rn.f64 	%fd854, %fd22, %fd852, %fd852;
	@%p17 bra 	$L__BB6_14;

	mov.f64 	%fd323, 0d3FF0000000000000;
	fma.rn.f64 	%fd854, %fd22, %fd21, %fd323;

$L__BB6_14:
	and.b32  	%r220, %r672, 2;
	setp.eq.s32 	%p18, %r220, 0;
	@%p18 bra 	$L__BB6_16;

	mov.f64 	%fd324, 0d0000000000000000;
	mov.f64 	%fd325, 0dBFF0000000000000;
	fma.rn.f64 	%fd854, %fd854, %fd325, %fd324;

$L__BB6_16:
	mul.rn.f64 	%fd326, %fd854, 0d4034000000000000;
	mul.rn.f64 	%fd327, %fd851, 0d4034000000000000;
	add.rn.f64 	%fd28, %fd327, %fd326;
	mul.rn.f32 	%f115, %f6, 0f3F22F983;
	cvt.rni.s32.f32 	%r676, %f115;
	cvt.rn.f32.s32 	%f116, %r676;
	mov.f32 	%f117, 0fBFC90FDA;
	fma.rn.f32 	%f118, %f116, %f117, %f6;
	mov.f32 	%f119, 0fB3A22168;
	fma.rn.f32 	%f120, %f116, %f119, %f118;
	mov.f32 	%f121, 0fA7C234C5;
	fma.rn.f32 	%f333, %f116, %f121, %f120;
	abs.f32 	%f8, %f6;
	setp.ltu.f32 	%p19, %f8, 0f47CE4780;
	@%p19 bra 	$L__BB6_24;

	setp.eq.f32 	%p20, %f8, 0f7F800000;
	@%p20 bra 	$L__BB6_23;
	bra.uni 	$L__BB6_18;

$L__BB6_23:
	mov.f32 	%f124, 0f00000000;
	mul.rn.f32 	%f333, %f6, %f124;
	mov.u32 	%r676, 0;
	bra.uni 	$L__BB6_24;

$L__BB6_18:
	mov.b32 	%r8, %f6;
	bfe.u32 	%r222, %r8, 23, 8;
	add.s32 	%r9, %r222, -128;
	shl.b32 	%r223, %r8, 8;
	or.b32  	%r10, %r223, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd254, 0;
	mov.u32 	%r673, 0;
	mov.u64 	%rd253, __cudart_i2opi_f;
	mov.u64 	%rd252, %rd1;

$L__BB6_19:
	.pragma "nounroll";
	ld.global.nc.u32 	%r224, [%rd253];
	mad.wide.u32 	%rd93, %r224, %r10, %rd254;
	shr.u64 	%rd254, %rd93, 32;
	st.local.u32 	[%rd252], %rd93;
	add.s64 	%rd253, %rd253, 4;
	add.s64 	%rd252, %rd252, 4;
	add.s32 	%r673, %r673, 1;
	setp.ne.s32 	%p21, %r673, 6;
	@%p21 bra 	$L__BB6_19;

	st.local.u32 	[%rd1+24], %rd254;
	mov.u32 	%r225, 4;
	sub.s32 	%r14, %r225, %r11;
	mov.u32 	%r226, 6;
	sub.s32 	%r227, %r226, %r11;
	mul.wide.s32 	%rd94, %r227, 4;
	add.s64 	%rd95, %rd1, %rd94;
	ld.local.u32 	%r674, [%rd95];
	ld.local.u32 	%r675, [%rd95+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p22, %r17, 0;
	@%p22 bra 	$L__BB6_22;

	mov.u32 	%r228, 32;
	sub.s32 	%r229, %r228, %r17;
	shr.u32 	%r230, %r675, %r229;
	shl.b32 	%r231, %r674, %r17;
	add.s32 	%r674, %r230, %r231;
	mul.wide.s32 	%rd96, %r14, 4;
	add.s64 	%rd97, %rd1, %rd96;
	ld.local.u32 	%r232, [%rd97];
	shr.u32 	%r233, %r232, %r229;
	shl.b32 	%r234, %r675, %r17;
	add.s32 	%r675, %r233, %r234;

$L__BB6_22:
	and.b32  	%r235, %r8, -2147483648;
	shr.u32 	%r236, %r675, 30;
	shl.b32 	%r237, %r674, 2;
	or.b32  	%r238, %r236, %r237;
	shr.u32 	%r239, %r238, 31;
	shr.u32 	%r240, %r674, 30;
	add.s32 	%r241, %r239, %r240;
	neg.s32 	%r242, %r241;
	setp.eq.s32 	%p23, %r235, 0;
	selp.b32 	%r676, %r241, %r242, %p23;
	setp.ne.s32 	%p24, %r239, 0;
	xor.b32  	%r243, %r235, -2147483648;
	selp.b32 	%r244, %r243, %r235, %p24;
	selp.b32 	%r245, -1, 0, %p24;
	xor.b32  	%r246, %r238, %r245;
	shl.b32 	%r247, %r675, 2;
	xor.b32  	%r248, %r247, %r245;
	cvt.u64.u32 	%rd98, %r246;
	cvt.u64.u32 	%rd99, %r248;
	bfi.b64 	%rd100, %rd98, %rd99, 32, 32;
	cvt.rn.f64.s64 	%fd328, %rd100;
	mul.rn.f64 	%fd329, %fd328, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f122, %fd329;
	setp.eq.s32 	%p25, %r244, 0;
	neg.f32 	%f123, %f122;
	selp.f32 	%f333, %f122, %f123, %p25;

$L__BB6_24:
	and.b32  	%r24, %r676, 1;
	setp.eq.s32 	%p26, %r24, 0;
	selp.f32 	%f12, %f333, 0f3F800000, %p26;
	mul.rn.f32 	%f13, %f333, %f333;
	mov.f32 	%f334, 0fB94D4153;
	@%p26 bra 	$L__BB6_26;

	mov.f32 	%f126, 0fBAB607ED;
	mov.f32 	%f127, 0f37CBAC00;
	fma.rn.f32 	%f334, %f127, %f13, %f126;

$L__BB6_26:
	selp.f32 	%f128, 0f3C0885E4, 0f3D2AAABB, %p26;
	fma.rn.f32 	%f129, %f334, %f13, %f128;
	selp.f32 	%f130, 0fBE2AAAA8, 0fBEFFFFFF, %p26;
	fma.rn.f32 	%f131, %f129, %f13, %f130;
	mov.f32 	%f132, 0f00000000;
	fma.rn.f32 	%f133, %f13, %f12, %f132;
	fma.rn.f32 	%f335, %f131, %f133, %f12;
	and.b32  	%r250, %r676, 2;
	setp.eq.s32 	%p28, %r250, 0;
	@%p28 bra 	$L__BB6_28;

	mov.f32 	%f135, 0fBF800000;
	fma.rn.f32 	%f335, %f335, %f135, %f132;

$L__BB6_28:
	cvt.f64.f32 	%fd29, %f6;
	div.rn.f64 	%fd30, %fd29, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r251, %temp}, %fd30;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r252}, %fd30;
	}
	and.b32  	%r253, %r252, 2147483647;
	setp.eq.s32 	%p29, %r253, 2146435072;
	setp.eq.s32 	%p30, %r251, 0;
	and.pred  	%p31, %p30, %p29;
	@%p31 bra 	$L__BB6_31;
	bra.uni 	$L__BB6_29;

$L__BB6_31:
	mov.f64 	%fd339, 0d0000000000000000;
	mul.rn.f64 	%fd855, %fd30, %fd339;
	mov.u32 	%r677, 0;
	bra.uni 	$L__BB6_32;

$L__BB6_29:
	mul.rn.f64 	%fd330, %fd30, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r677, %fd330;
	st.local.u32 	[%rd8], %r677;
	cvt.rn.f64.s32 	%fd331, %r677;
	neg.f64 	%fd332, %fd331;
	mov.f64 	%fd333, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd334, %fd332, %fd333, %fd30;
	mov.f64 	%fd335, 0d3C91A62633145C00;
	fma.rn.f64 	%fd336, %fd332, %fd335, %fd334;
	mov.f64 	%fd337, 0d397B839A252049C0;
	fma.rn.f64 	%fd855, %fd332, %fd337, %fd336;
	abs.f64 	%fd338, %fd30;
	setp.ltu.f64 	%p32, %fd338, 0d41E0000000000000;
	@%p32 bra 	$L__BB6_32;

	{ // callseq 50, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd30;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd855, [retval0+0];
	} // callseq 50
	ld.local.u32 	%r677, [%rd8];

$L__BB6_32:
	and.b32  	%r255, %r677, 1;
	shl.b32 	%r256, %r677, 3;
	and.b32  	%r257, %r256, 8;
	setp.eq.s32 	%p33, %r255, 0;
	selp.f64 	%fd340, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p33;
	mul.wide.s32 	%rd102, %r257, 8;
	add.s64 	%rd104, %rd85, %rd102;
	ld.global.nc.f64 	%fd341, [%rd104+8];
	mul.rn.f64 	%fd35, %fd855, %fd855;
	fma.rn.f64 	%fd342, %fd340, %fd35, %fd341;
	ld.global.nc.f64 	%fd343, [%rd104+16];
	fma.rn.f64 	%fd344, %fd342, %fd35, %fd343;
	ld.global.nc.f64 	%fd345, [%rd104+24];
	fma.rn.f64 	%fd346, %fd344, %fd35, %fd345;
	ld.global.nc.f64 	%fd347, [%rd104+32];
	fma.rn.f64 	%fd348, %fd346, %fd35, %fd347;
	ld.global.nc.f64 	%fd349, [%rd104+40];
	fma.rn.f64 	%fd350, %fd348, %fd35, %fd349;
	ld.global.nc.f64 	%fd351, [%rd104+48];
	fma.rn.f64 	%fd36, %fd350, %fd35, %fd351;
	fma.rn.f64 	%fd857, %fd36, %fd855, %fd855;
	@%p33 bra 	$L__BB6_34;

	mov.f64 	%fd352, 0d3FF0000000000000;
	fma.rn.f64 	%fd857, %fd36, %fd35, %fd352;

$L__BB6_34:
	and.b32  	%r258, %r677, 2;
	setp.eq.s32 	%p34, %r258, 0;
	@%p34 bra 	$L__BB6_36;

	mov.f64 	%fd353, 0d0000000000000000;
	mov.f64 	%fd354, 0dBFF0000000000000;
	fma.rn.f64 	%fd857, %fd857, %fd354, %fd353;

$L__BB6_36:
	mul.rn.f64 	%fd355, %fd857, 0d4044000000000000;
	cvt.f64.f32 	%fd356, %f335;
	mul.rn.f64 	%fd357, %fd356, 0d4034000000000000;
	add.rn.f64 	%fd42, %fd357, %fd355;
	div.rn.f64 	%fd43, %fd29, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r259, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd43;
	}
	and.b32  	%r261, %r260, 2147483647;
	setp.eq.s32 	%p35, %r261, 2146435072;
	setp.eq.s32 	%p36, %r259, 0;
	and.pred  	%p37, %p36, %p35;
	@%p37 bra 	$L__BB6_39;
	bra.uni 	$L__BB6_37;

$L__BB6_39:
	mov.f64 	%fd367, 0d0000000000000000;
	mul.rn.f64 	%fd858, %fd43, %fd367;
	mov.u32 	%r678, 0;
	bra.uni 	$L__BB6_40;

$L__BB6_37:
	mul.rn.f64 	%fd358, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r678, %fd358;
	st.local.u32 	[%rd8], %r678;
	cvt.rn.f64.s32 	%fd359, %r678;
	neg.f64 	%fd360, %fd359;
	mov.f64 	%fd361, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd362, %fd360, %fd361, %fd43;
	mov.f64 	%fd363, 0d3C91A62633145C00;
	fma.rn.f64 	%fd364, %fd360, %fd363, %fd362;
	mov.f64 	%fd365, 0d397B839A252049C0;
	fma.rn.f64 	%fd858, %fd360, %fd365, %fd364;
	abs.f64 	%fd366, %fd43;
	setp.ltu.f64 	%p38, %fd366, 0d41E0000000000000;
	@%p38 bra 	$L__BB6_40;

	{ // callseq 51, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd858, [retval0+0];
	} // callseq 51
	ld.local.u32 	%r678, [%rd8];

$L__BB6_40:
	and.b32  	%r263, %r678, 1;
	shl.b32 	%r264, %r678, 3;
	and.b32  	%r265, %r264, 8;
	setp.eq.s32 	%p39, %r263, 0;
	selp.f64 	%fd368, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p39;
	mul.wide.s32 	%rd106, %r265, 8;
	add.s64 	%rd108, %rd85, %rd106;
	ld.global.nc.f64 	%fd369, [%rd108+8];
	mul.rn.f64 	%fd48, %fd858, %fd858;
	fma.rn.f64 	%fd370, %fd368, %fd48, %fd369;
	ld.global.nc.f64 	%fd371, [%rd108+16];
	fma.rn.f64 	%fd372, %fd370, %fd48, %fd371;
	ld.global.nc.f64 	%fd373, [%rd108+24];
	fma.rn.f64 	%fd374, %fd372, %fd48, %fd373;
	ld.global.nc.f64 	%fd375, [%rd108+32];
	fma.rn.f64 	%fd376, %fd374, %fd48, %fd375;
	ld.global.nc.f64 	%fd377, [%rd108+40];
	fma.rn.f64 	%fd378, %fd376, %fd48, %fd377;
	ld.global.nc.f64 	%fd379, [%rd108+48];
	fma.rn.f64 	%fd49, %fd378, %fd48, %fd379;
	fma.rn.f64 	%fd860, %fd49, %fd858, %fd858;
	@%p39 bra 	$L__BB6_42;

	mov.f64 	%fd380, 0d3FF0000000000000;
	fma.rn.f64 	%fd860, %fd49, %fd48, %fd380;

$L__BB6_42:
	and.b32  	%r266, %r678, 2;
	setp.eq.s32 	%p40, %r266, 0;
	@%p40 bra 	$L__BB6_44;

	mov.f64 	%fd381, 0d0000000000000000;
	mov.f64 	%fd382, 0dBFF0000000000000;
	fma.rn.f64 	%fd860, %fd860, %fd382, %fd381;

$L__BB6_44:
	mul.rn.f64 	%fd383, %fd860, 0d4064000000000000;
	add.rn.f64 	%fd55, %fd42, %fd383;
	div.rn.f64 	%fd56, %fd29, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r267, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r268}, %fd56;
	}
	and.b32  	%r269, %r268, 2147483647;
	setp.eq.s32 	%p41, %r269, 2146435072;
	setp.eq.s32 	%p42, %r267, 0;
	and.pred  	%p43, %p42, %p41;
	@%p43 bra 	$L__BB6_47;
	bra.uni 	$L__BB6_45;

$L__BB6_47:
	mov.f64 	%fd393, 0d0000000000000000;
	mul.rn.f64 	%fd861, %fd56, %fd393;
	mov.u32 	%r679, 0;
	bra.uni 	$L__BB6_48;

$L__BB6_45:
	mul.rn.f64 	%fd384, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r679, %fd384;
	st.local.u32 	[%rd8], %r679;
	cvt.rn.f64.s32 	%fd385, %r679;
	neg.f64 	%fd386, %fd385;
	mov.f64 	%fd387, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd388, %fd386, %fd387, %fd56;
	mov.f64 	%fd389, 0d3C91A62633145C00;
	fma.rn.f64 	%fd390, %fd386, %fd389, %fd388;
	mov.f64 	%fd391, 0d397B839A252049C0;
	fma.rn.f64 	%fd861, %fd386, %fd391, %fd390;
	abs.f64 	%fd392, %fd56;
	setp.ltu.f64 	%p44, %fd392, 0d41E0000000000000;
	@%p44 bra 	$L__BB6_48;

	{ // callseq 52, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd861, [retval0+0];
	} // callseq 52
	ld.local.u32 	%r679, [%rd8];

$L__BB6_48:
	and.b32  	%r271, %r679, 1;
	shl.b32 	%r272, %r679, 3;
	and.b32  	%r273, %r272, 8;
	setp.eq.s32 	%p45, %r271, 0;
	selp.f64 	%fd394, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p45;
	mul.wide.s32 	%rd110, %r273, 8;
	add.s64 	%rd112, %rd85, %rd110;
	ld.global.nc.f64 	%fd395, [%rd112+8];
	mul.rn.f64 	%fd61, %fd861, %fd861;
	fma.rn.f64 	%fd396, %fd394, %fd61, %fd395;
	ld.global.nc.f64 	%fd397, [%rd112+16];
	fma.rn.f64 	%fd398, %fd396, %fd61, %fd397;
	ld.global.nc.f64 	%fd399, [%rd112+24];
	fma.rn.f64 	%fd400, %fd398, %fd61, %fd399;
	ld.global.nc.f64 	%fd401, [%rd112+32];
	fma.rn.f64 	%fd402, %fd400, %fd61, %fd401;
	ld.global.nc.f64 	%fd403, [%rd112+40];
	fma.rn.f64 	%fd404, %fd402, %fd61, %fd403;
	ld.global.nc.f64 	%fd405, [%rd112+48];
	fma.rn.f64 	%fd62, %fd404, %fd61, %fd405;
	fma.rn.f64 	%fd863, %fd62, %fd861, %fd861;
	@%p45 bra 	$L__BB6_50;

	mov.f64 	%fd406, 0d3FF0000000000000;
	fma.rn.f64 	%fd863, %fd62, %fd61, %fd406;

$L__BB6_50:
	and.b32  	%r274, %r679, 2;
	setp.eq.s32 	%p46, %r274, 0;
	@%p46 bra 	$L__BB6_52;

	mov.f64 	%fd407, 0d0000000000000000;
	mov.f64 	%fd408, 0dBFF0000000000000;
	fma.rn.f64 	%fd863, %fd863, %fd408, %fd407;

$L__BB6_52:
	mul.rn.f64 	%fd409, %fd863, 0d4074000000000000;
	add.rn.f64 	%fd68, %fd55, %fd409;
	mul.rn.f32 	%f136, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r683, %f136;
	cvt.rn.f32.s32 	%f137, %r683;
	mov.f32 	%f138, 0fBFC90FDA;
	fma.rn.f32 	%f139, %f137, %f138, %f5;
	mov.f32 	%f140, 0fB3A22168;
	fma.rn.f32 	%f141, %f137, %f140, %f139;
	mov.f32 	%f142, 0fA7C234C5;
	fma.rn.f32 	%f336, %f137, %f142, %f141;
	abs.f32 	%f20, %f5;
	setp.ltu.f32 	%p47, %f20, 0f47CE4780;
	@%p47 bra 	$L__BB6_60;

	setp.eq.f32 	%p48, %f20, 0f7F800000;
	@%p48 bra 	$L__BB6_59;
	bra.uni 	$L__BB6_54;

$L__BB6_59:
	mov.f32 	%f145, 0f00000000;
	mul.rn.f32 	%f336, %f5, %f145;
	mov.u32 	%r683, 0;
	bra.uni 	$L__BB6_60;

$L__BB6_54:
	mov.b32 	%r35, %f5;
	bfe.u32 	%r276, %r35, 23, 8;
	add.s32 	%r36, %r276, -128;
	shl.b32 	%r277, %r35, 8;
	or.b32  	%r37, %r277, -2147483648;
	shr.u32 	%r38, %r36, 5;
	mov.u64 	%rd257, 0;
	mov.u32 	%r680, 0;
	mov.u64 	%rd256, __cudart_i2opi_f;
	mov.u64 	%rd255, %rd1;

$L__BB6_55:
	.pragma "nounroll";
	ld.global.nc.u32 	%r278, [%rd256];
	mad.wide.u32 	%rd115, %r278, %r37, %rd257;
	shr.u64 	%rd257, %rd115, 32;
	st.local.u32 	[%rd255], %rd115;
	add.s64 	%rd256, %rd256, 4;
	add.s64 	%rd255, %rd255, 4;
	add.s32 	%r680, %r680, 1;
	setp.ne.s32 	%p49, %r680, 6;
	@%p49 bra 	$L__BB6_55;

	st.local.u32 	[%rd1+24], %rd257;
	mov.u32 	%r279, 4;
	sub.s32 	%r41, %r279, %r38;
	mov.u32 	%r280, 6;
	sub.s32 	%r281, %r280, %r38;
	mul.wide.s32 	%rd116, %r281, 4;
	add.s64 	%rd117, %rd1, %rd116;
	ld.local.u32 	%r681, [%rd117];
	ld.local.u32 	%r682, [%rd117+-4];
	and.b32  	%r44, %r36, 31;
	setp.eq.s32 	%p50, %r44, 0;
	@%p50 bra 	$L__BB6_58;

	mov.u32 	%r282, 32;
	sub.s32 	%r283, %r282, %r44;
	shr.u32 	%r284, %r682, %r283;
	shl.b32 	%r285, %r681, %r44;
	add.s32 	%r681, %r284, %r285;
	mul.wide.s32 	%rd118, %r41, 4;
	add.s64 	%rd119, %rd1, %rd118;
	ld.local.u32 	%r286, [%rd119];
	shr.u32 	%r287, %r286, %r283;
	shl.b32 	%r288, %r682, %r44;
	add.s32 	%r682, %r287, %r288;

$L__BB6_58:
	and.b32  	%r289, %r35, -2147483648;
	shr.u32 	%r290, %r682, 30;
	shl.b32 	%r291, %r681, 2;
	or.b32  	%r292, %r290, %r291;
	shr.u32 	%r293, %r292, 31;
	shr.u32 	%r294, %r681, 30;
	add.s32 	%r295, %r293, %r294;
	neg.s32 	%r296, %r295;
	setp.eq.s32 	%p51, %r289, 0;
	selp.b32 	%r683, %r295, %r296, %p51;
	setp.ne.s32 	%p52, %r293, 0;
	xor.b32  	%r297, %r289, -2147483648;
	selp.b32 	%r298, %r297, %r289, %p52;
	selp.b32 	%r299, -1, 0, %p52;
	xor.b32  	%r300, %r292, %r299;
	shl.b32 	%r301, %r682, 2;
	xor.b32  	%r302, %r301, %r299;
	cvt.u64.u32 	%rd120, %r300;
	cvt.u64.u32 	%rd121, %r302;
	bfi.b64 	%rd122, %rd120, %rd121, 32, 32;
	cvt.rn.f64.s64 	%fd410, %rd122;
	mul.rn.f64 	%fd411, %fd410, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f143, %fd411;
	setp.eq.s32 	%p53, %r298, 0;
	neg.f32 	%f144, %f143;
	selp.f32 	%f336, %f143, %f144, %p53;

$L__BB6_60:
	cvt.rn.f32.f64 	%f147, %fd28;
	cvt.f64.f32 	%fd69, %f147;
	and.b32  	%r51, %r683, 1;
	setp.eq.s32 	%p54, %r51, 0;
	selp.f32 	%f24, %f336, 0f3F800000, %p54;
	mul.rn.f32 	%f25, %f336, %f336;
	mov.f32 	%f337, 0fB94D4153;
	@%p54 bra 	$L__BB6_62;

	mov.f32 	%f148, 0fBAB607ED;
	mov.f32 	%f149, 0f37CBAC00;
	fma.rn.f32 	%f337, %f149, %f25, %f148;

$L__BB6_62:
	selp.f32 	%f150, 0f3C0885E4, 0f3D2AAABB, %p54;
	fma.rn.f32 	%f151, %f337, %f25, %f150;
	selp.f32 	%f152, 0fBE2AAAA8, 0fBEFFFFFF, %p54;
	fma.rn.f32 	%f153, %f151, %f25, %f152;
	mov.f32 	%f154, 0f00000000;
	fma.rn.f32 	%f155, %f25, %f24, %f154;
	fma.rn.f32 	%f338, %f153, %f155, %f24;
	and.b32  	%r304, %r683, 2;
	setp.eq.s32 	%p56, %r304, 0;
	@%p56 bra 	$L__BB6_64;

	mov.f32 	%f157, 0fBF800000;
	fma.rn.f32 	%f338, %f338, %f157, %f154;

$L__BB6_64:
	div.rn.f64 	%fd70, %fd3, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd70;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r306}, %fd70;
	}
	and.b32  	%r307, %r306, 2147483647;
	setp.eq.s32 	%p57, %r307, 2146435072;
	setp.eq.s32 	%p58, %r305, 0;
	and.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB6_67;
	bra.uni 	$L__BB6_65;

$L__BB6_67:
	mov.f64 	%fd421, 0d0000000000000000;
	mul.rn.f64 	%fd864, %fd70, %fd421;
	mov.u32 	%r684, 0;
	bra.uni 	$L__BB6_68;

$L__BB6_65:
	mul.rn.f64 	%fd412, %fd70, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r684, %fd412;
	st.local.u32 	[%rd8], %r684;
	cvt.rn.f64.s32 	%fd413, %r684;
	neg.f64 	%fd414, %fd413;
	mov.f64 	%fd415, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd416, %fd414, %fd415, %fd70;
	mov.f64 	%fd417, 0d3C91A62633145C00;
	fma.rn.f64 	%fd418, %fd414, %fd417, %fd416;
	mov.f64 	%fd419, 0d397B839A252049C0;
	fma.rn.f64 	%fd864, %fd414, %fd419, %fd418;
	abs.f64 	%fd420, %fd70;
	setp.ltu.f64 	%p60, %fd420, 0d41E0000000000000;
	@%p60 bra 	$L__BB6_68;

	{ // callseq 53, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd70;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd864, [retval0+0];
	} // callseq 53
	ld.local.u32 	%r684, [%rd8];

$L__BB6_68:
	and.b32  	%r309, %r684, 1;
	shl.b32 	%r310, %r684, 3;
	and.b32  	%r311, %r310, 8;
	setp.eq.s32 	%p61, %r309, 0;
	selp.f64 	%fd422, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p61;
	mul.wide.s32 	%rd124, %r311, 8;
	add.s64 	%rd126, %rd85, %rd124;
	ld.global.nc.f64 	%fd423, [%rd126+8];
	mul.rn.f64 	%fd75, %fd864, %fd864;
	fma.rn.f64 	%fd424, %fd422, %fd75, %fd423;
	ld.global.nc.f64 	%fd425, [%rd126+16];
	fma.rn.f64 	%fd426, %fd424, %fd75, %fd425;
	ld.global.nc.f64 	%fd427, [%rd126+24];
	fma.rn.f64 	%fd428, %fd426, %fd75, %fd427;
	ld.global.nc.f64 	%fd429, [%rd126+32];
	fma.rn.f64 	%fd430, %fd428, %fd75, %fd429;
	ld.global.nc.f64 	%fd431, [%rd126+40];
	fma.rn.f64 	%fd432, %fd430, %fd75, %fd431;
	ld.global.nc.f64 	%fd433, [%rd126+48];
	fma.rn.f64 	%fd76, %fd432, %fd75, %fd433;
	fma.rn.f64 	%fd866, %fd76, %fd864, %fd864;
	@%p61 bra 	$L__BB6_70;

	mov.f64 	%fd434, 0d3FF0000000000000;
	fma.rn.f64 	%fd866, %fd76, %fd75, %fd434;

$L__BB6_70:
	and.b32  	%r312, %r684, 2;
	setp.eq.s32 	%p62, %r312, 0;
	@%p62 bra 	$L__BB6_72;

	mov.f64 	%fd435, 0d0000000000000000;
	mov.f64 	%fd436, 0dBFF0000000000000;
	fma.rn.f64 	%fd866, %fd866, %fd436, %fd435;

$L__BB6_72:
	mul.rn.f64 	%fd437, %fd866, 0d4044000000000000;
	cvt.f64.f32 	%fd438, %f338;
	mul.rn.f64 	%fd439, %fd438, 0d4034000000000000;
	add.rn.f64 	%fd82, %fd439, %fd437;
	div.rn.f64 	%fd83, %fd3, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r313, %temp}, %fd83;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd83;
	}
	and.b32  	%r315, %r314, 2147483647;
	setp.eq.s32 	%p63, %r315, 2146435072;
	setp.eq.s32 	%p64, %r313, 0;
	and.pred  	%p65, %p64, %p63;
	@%p65 bra 	$L__BB6_75;
	bra.uni 	$L__BB6_73;

$L__BB6_75:
	mov.f64 	%fd449, 0d0000000000000000;
	mul.rn.f64 	%fd867, %fd83, %fd449;
	mov.u32 	%r685, 0;
	bra.uni 	$L__BB6_76;

$L__BB6_73:
	mul.rn.f64 	%fd440, %fd83, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r685, %fd440;
	st.local.u32 	[%rd8], %r685;
	cvt.rn.f64.s32 	%fd441, %r685;
	neg.f64 	%fd442, %fd441;
	mov.f64 	%fd443, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd444, %fd442, %fd443, %fd83;
	mov.f64 	%fd445, 0d3C91A62633145C00;
	fma.rn.f64 	%fd446, %fd442, %fd445, %fd444;
	mov.f64 	%fd447, 0d397B839A252049C0;
	fma.rn.f64 	%fd867, %fd442, %fd447, %fd446;
	abs.f64 	%fd448, %fd83;
	setp.ltu.f64 	%p66, %fd448, 0d41E0000000000000;
	@%p66 bra 	$L__BB6_76;

	{ // callseq 54, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd83;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd867, [retval0+0];
	} // callseq 54
	ld.local.u32 	%r685, [%rd8];

$L__BB6_76:
	and.b32  	%r317, %r685, 1;
	shl.b32 	%r318, %r685, 3;
	and.b32  	%r319, %r318, 8;
	setp.eq.s32 	%p67, %r317, 0;
	selp.f64 	%fd450, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p67;
	mul.wide.s32 	%rd128, %r319, 8;
	add.s64 	%rd130, %rd85, %rd128;
	ld.global.nc.f64 	%fd451, [%rd130+8];
	mul.rn.f64 	%fd88, %fd867, %fd867;
	fma.rn.f64 	%fd452, %fd450, %fd88, %fd451;
	ld.global.nc.f64 	%fd453, [%rd130+16];
	fma.rn.f64 	%fd454, %fd452, %fd88, %fd453;
	ld.global.nc.f64 	%fd455, [%rd130+24];
	fma.rn.f64 	%fd456, %fd454, %fd88, %fd455;
	ld.global.nc.f64 	%fd457, [%rd130+32];
	fma.rn.f64 	%fd458, %fd456, %fd88, %fd457;
	ld.global.nc.f64 	%fd459, [%rd130+40];
	fma.rn.f64 	%fd460, %fd458, %fd88, %fd459;
	ld.global.nc.f64 	%fd461, [%rd130+48];
	fma.rn.f64 	%fd89, %fd460, %fd88, %fd461;
	fma.rn.f64 	%fd869, %fd89, %fd867, %fd867;
	@%p67 bra 	$L__BB6_78;

	mov.f64 	%fd462, 0d3FF0000000000000;
	fma.rn.f64 	%fd869, %fd89, %fd88, %fd462;

$L__BB6_78:
	and.b32  	%r320, %r685, 2;
	setp.eq.s32 	%p68, %r320, 0;
	@%p68 bra 	$L__BB6_80;

	mov.f64 	%fd463, 0d0000000000000000;
	mov.f64 	%fd464, 0dBFF0000000000000;
	fma.rn.f64 	%fd869, %fd869, %fd464, %fd463;

$L__BB6_80:
	mul.rn.f64 	%fd465, %fd869, 0d4062C00000000000;
	add.rn.f64 	%fd95, %fd82, %fd465;
	div.rn.f64 	%fd96, %fd3, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r321, %temp}, %fd96;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r322}, %fd96;
	}
	and.b32  	%r323, %r322, 2147483647;
	setp.eq.s32 	%p69, %r323, 2146435072;
	setp.eq.s32 	%p70, %r321, 0;
	and.pred  	%p71, %p70, %p69;
	@%p71 bra 	$L__BB6_83;
	bra.uni 	$L__BB6_81;

$L__BB6_83:
	mov.f64 	%fd475, 0d0000000000000000;
	mul.rn.f64 	%fd870, %fd96, %fd475;
	mov.u32 	%r686, 0;
	bra.uni 	$L__BB6_84;

$L__BB6_81:
	mul.rn.f64 	%fd466, %fd96, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r686, %fd466;
	st.local.u32 	[%rd8], %r686;
	cvt.rn.f64.s32 	%fd467, %r686;
	neg.f64 	%fd468, %fd467;
	mov.f64 	%fd469, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd470, %fd468, %fd469, %fd96;
	mov.f64 	%fd471, 0d3C91A62633145C00;
	fma.rn.f64 	%fd472, %fd468, %fd471, %fd470;
	mov.f64 	%fd473, 0d397B839A252049C0;
	fma.rn.f64 	%fd870, %fd468, %fd473, %fd472;
	abs.f64 	%fd474, %fd96;
	setp.ltu.f64 	%p72, %fd474, 0d41E0000000000000;
	@%p72 bra 	$L__BB6_84;

	{ // callseq 55, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd96;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd870, [retval0+0];
	} // callseq 55
	ld.local.u32 	%r686, [%rd8];

$L__BB6_84:
	and.b32  	%r325, %r686, 1;
	shl.b32 	%r326, %r686, 3;
	and.b32  	%r327, %r326, 8;
	setp.eq.s32 	%p73, %r325, 0;
	selp.f64 	%fd476, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p73;
	mul.wide.s32 	%rd132, %r327, 8;
	add.s64 	%rd134, %rd85, %rd132;
	ld.global.nc.f64 	%fd477, [%rd134+8];
	mul.rn.f64 	%fd101, %fd870, %fd870;
	fma.rn.f64 	%fd478, %fd476, %fd101, %fd477;
	ld.global.nc.f64 	%fd479, [%rd134+16];
	fma.rn.f64 	%fd480, %fd478, %fd101, %fd479;
	ld.global.nc.f64 	%fd481, [%rd134+24];
	fma.rn.f64 	%fd482, %fd480, %fd101, %fd481;
	ld.global.nc.f64 	%fd483, [%rd134+32];
	fma.rn.f64 	%fd484, %fd482, %fd101, %fd483;
	ld.global.nc.f64 	%fd485, [%rd134+40];
	fma.rn.f64 	%fd486, %fd484, %fd101, %fd485;
	ld.global.nc.f64 	%fd487, [%rd134+48];
	fma.rn.f64 	%fd102, %fd486, %fd101, %fd487;
	fma.rn.f64 	%fd872, %fd102, %fd870, %fd870;
	@%p73 bra 	$L__BB6_86;

	mov.f64 	%fd488, 0d3FF0000000000000;
	fma.rn.f64 	%fd872, %fd102, %fd101, %fd488;

$L__BB6_86:
	and.b32  	%r328, %r686, 2;
	setp.eq.s32 	%p74, %r328, 0;
	@%p74 bra 	$L__BB6_88;

	mov.f64 	%fd489, 0d0000000000000000;
	mov.f64 	%fd490, 0dBFF0000000000000;
	fma.rn.f64 	%fd872, %fd872, %fd490, %fd489;

$L__BB6_88:
	mul.rn.f64 	%fd491, %fd872, 0d4072C00000000000;
	add.rn.f64 	%fd492, %fd95, %fd491;
	add.rn.f64 	%fd108, %fd492, %fd69;
	add.rn.f64 	%fd109, %fd68, %fd69;
	add.rn.f64 	%fd493, %fd1, %fd1;
	mov.f64 	%fd494, 0d4000000000000000;
	add.rn.f64 	%fd495, %fd493, 0dC059000000000000;
	mul.rn.f64 	%fd496, %fd2, 0d4008000000000000;
	add.rn.f64 	%fd110, %fd495, %fd496;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r61}, %fd494;
	}
	and.b32  	%r62, %r61, 2146435072;
	setp.eq.s32 	%p75, %r62, 1062207488;
	abs.f64 	%fd111, %fd2;
	{ // callseq 56, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd875, [retval0+0];
	} // callseq 56
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r63}, %fd2;
	}
	setp.lt.s32 	%p76, %r63, 0;
	and.pred  	%p1, %p76, %p75;
	not.pred 	%p77, %p1;
	@%p77 bra 	$L__BB6_90;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r329}, %fd875;
	}
	xor.b32  	%r330, %r329, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r331, %temp}, %fd875;
	}
	mov.b64 	%fd875, {%r331, %r330};

$L__BB6_90:
	add.rn.f32 	%f318, %f3, 0fC20C0000;
	setp.eq.f32 	%p78, %f318, 0f00000000;
	@%p78 bra 	$L__BB6_94;
	bra.uni 	$L__BB6_91;

$L__BB6_94:
	selp.b32 	%r332, %r63, 0, %p75;
	mov.u32 	%r333, 0;
	or.b32  	%r334, %r332, 2146435072;
	setp.lt.s32 	%p82, %r61, 0;
	selp.b32 	%r335, %r334, %r332, %p82;
	mov.b64 	%fd875, {%r333, %r335};
	bra.uni 	$L__BB6_95;

$L__BB6_91:
	setp.gt.s32 	%p79, %r63, -1;
	@%p79 bra 	$L__BB6_95;

	mov.f64 	%fd497, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd498, %fd497;
	setp.eq.f64 	%p80, %fd498, 0d4000000000000000;
	@%p80 bra 	$L__BB6_95;

	mov.f64 	%fd875, 0dFFF8000000000000;

$L__BB6_95:
	add.rn.f64 	%fd500, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd500;
	}
	and.b32  	%r337, %r336, 2146435072;
	setp.ne.s32 	%p83, %r337, 2146435072;
	@%p83 bra 	$L__BB6_102;

	setp.gtu.f64 	%p84, %fd111, 0d7FF0000000000000;
	@%p84 bra 	$L__BB6_101;
	bra.uni 	$L__BB6_97;

$L__BB6_101:
	mov.f64 	%fd502, 0d4000000000000000;
	add.rn.f64 	%fd875, %fd2, %fd502;
	bra.uni 	$L__BB6_102;

$L__BB6_97:
	mov.f64 	%fd501, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd501;
	}
	and.b32  	%r64, %r61, 2147483647;
	setp.eq.s32 	%p85, %r64, 2146435072;
	setp.eq.s32 	%p86, %r338, 0;
	and.pred  	%p87, %p85, %p86;
	@%p87 bra 	$L__BB6_100;
	bra.uni 	$L__BB6_98;

$L__BB6_100:
	add.rn.f32 	%f325, %f3, 0fC20C0000;
	setp.gt.f64 	%p94, %fd111, 0d3FF0000000000000;
	selp.b32 	%r345, 2146435072, 0, %p94;
	mov.u32 	%r346, 0;
	xor.b32  	%r347, %r345, 2146435072;
	setp.lt.s32 	%p95, %r61, 0;
	selp.b32 	%r348, %r347, %r345, %p95;
	setp.eq.f32 	%p96, %f325, 0fBF800000;
	selp.b32 	%r349, 1072693248, %r348, %p96;
	mov.b64 	%fd875, {%r346, %r349};
	bra.uni 	$L__BB6_102;

$L__BB6_98:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd2;
	}
	and.b32  	%r340, %r63, 2147483647;
	setp.ne.s32 	%p88, %r340, 2146435072;
	setp.ne.s32 	%p89, %r339, 0;
	or.pred  	%p90, %p88, %p89;
	@%p90 bra 	$L__BB6_102;

	setp.gt.s32 	%p91, %r61, -1;
	selp.b32 	%r341, 2146435072, 0, %p91;
	mov.u32 	%r342, 0;
	setp.ne.s32 	%p92, %r64, 1071644672;
	and.pred  	%p93, %p92, %p1;
	or.b32  	%r343, %r341, -2147483648;
	selp.b32 	%r344, %r343, %r341, %p93;
	mov.b64 	%fd875, {%r342, %r344};

$L__BB6_102:
	add.rn.f32 	%f320, %f1, 0fC2D20000;
	add.rn.f32 	%f319, %f3, 0fC20C0000;
	mul.rn.f64 	%fd503, %fd875, 0d3FC999999999999A;
	setp.eq.f32 	%p97, %f319, 0f3F800000;
	selp.f64 	%fd504, 0d3FC999999999999A, %fd503, %p97;
	add.rn.f64 	%fd505, %fd110, %fd504;
	mul.rn.f32 	%f158, %f320, %f319;
	cvt.f64.f32 	%fd506, %f158;
	mul.rn.f64 	%fd121, %fd506, 0d3FB999999999999A;
	add.rn.f64 	%fd507, %fd121, %fd505;
	abs.f32 	%f159, %f320;
	sqrt.rn.f32 	%f160, %f159;
	cvt.f64.f32 	%fd122, %f160;
	mul.rn.f64 	%fd508, %fd122, 0d3FC999999999999A;
	add.rn.f64 	%fd509, %fd508, %fd507;
	cvt.rn.f32.f64 	%f161, %fd109;
	cvt.f64.f32 	%fd510, %f161;
	mul.rn.f64 	%fd511, %fd510, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f162, %fd511;
	cvt.f64.f32 	%fd512, %f162;
	add.rn.f64 	%fd123, %fd509, %fd512;
	add.rn.f64 	%fd513, %fd2, %fd2;
	add.rn.f64 	%fd514, %fd1, 0d4072C00000000000;
	add.rn.f64 	%fd124, %fd514, %fd513;
	abs.f64 	%fd125, %fd1;
	{ // callseq 57, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd125;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd878, [retval0+0];
	} // callseq 57
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd1;
	}
	setp.lt.s32 	%p98, %r65, 0;
	and.pred  	%p2, %p98, %p75;
	not.pred 	%p100, %p2;
	@%p100 bra 	$L__BB6_104;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r350}, %fd878;
	}
	xor.b32  	%r351, %r350, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r352, %temp}, %fd878;
	}
	mov.b64 	%fd878, {%r352, %r351};

$L__BB6_104:
	add.rn.f32 	%f321, %f1, 0fC2D20000;
	setp.eq.f32 	%p101, %f321, 0f00000000;
	@%p101 bra 	$L__BB6_108;
	bra.uni 	$L__BB6_105;

$L__BB6_108:
	selp.b32 	%r353, %r65, 0, %p75;
	mov.u32 	%r354, 0;
	or.b32  	%r355, %r353, 2146435072;
	setp.lt.s32 	%p105, %r61, 0;
	selp.b32 	%r356, %r355, %r353, %p105;
	mov.b64 	%fd878, {%r354, %r356};
	bra.uni 	$L__BB6_109;

$L__BB6_105:
	setp.gt.s32 	%p102, %r65, -1;
	@%p102 bra 	$L__BB6_109;

	mov.f64 	%fd515, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd516, %fd515;
	setp.eq.f64 	%p103, %fd516, 0d4000000000000000;
	@%p103 bra 	$L__BB6_109;

	mov.f64 	%fd878, 0dFFF8000000000000;

$L__BB6_109:
	add.rn.f64 	%fd518, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd518;
	}
	and.b32  	%r358, %r357, 2146435072;
	setp.ne.s32 	%p106, %r358, 2146435072;
	@%p106 bra 	$L__BB6_116;

	setp.gtu.f64 	%p107, %fd125, 0d7FF0000000000000;
	@%p107 bra 	$L__BB6_115;
	bra.uni 	$L__BB6_111;

$L__BB6_115:
	mov.f64 	%fd520, 0d4000000000000000;
	add.rn.f64 	%fd878, %fd1, %fd520;
	bra.uni 	$L__BB6_116;

$L__BB6_111:
	mov.f64 	%fd519, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd519;
	}
	and.b32  	%r66, %r61, 2147483647;
	setp.eq.s32 	%p108, %r66, 2146435072;
	setp.eq.s32 	%p109, %r359, 0;
	and.pred  	%p110, %p108, %p109;
	@%p110 bra 	$L__BB6_114;
	bra.uni 	$L__BB6_112;

$L__BB6_114:
	add.rn.f32 	%f324, %f1, 0fC2D20000;
	setp.gt.f64 	%p117, %fd125, 0d3FF0000000000000;
	selp.b32 	%r366, 2146435072, 0, %p117;
	mov.u32 	%r367, 0;
	xor.b32  	%r368, %r366, 2146435072;
	setp.lt.s32 	%p118, %r61, 0;
	selp.b32 	%r369, %r368, %r366, %p118;
	setp.eq.f32 	%p119, %f324, 0fBF800000;
	selp.b32 	%r370, 1072693248, %r369, %p119;
	mov.b64 	%fd878, {%r367, %r370};
	bra.uni 	$L__BB6_116;

$L__BB6_112:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r360, %temp}, %fd1;
	}
	and.b32  	%r361, %r65, 2147483647;
	setp.ne.s32 	%p111, %r361, 2146435072;
	setp.ne.s32 	%p112, %r360, 0;
	or.pred  	%p113, %p111, %p112;
	@%p113 bra 	$L__BB6_116;

	setp.gt.s32 	%p114, %r61, -1;
	selp.b32 	%r362, 2146435072, 0, %p114;
	mov.u32 	%r363, 0;
	setp.ne.s32 	%p115, %r66, 1071644672;
	and.pred  	%p116, %p115, %p2;
	or.b32  	%r364, %r362, -2147483648;
	selp.b32 	%r365, %r364, %r362, %p116;
	mov.b64 	%fd878, {%r363, %r365};

$L__BB6_116:
	add.rn.f32 	%f322, %f1, 0fC2D20000;
	mul.rn.f64 	%fd521, %fd878, 0d3FB999999999999A;
	setp.eq.f32 	%p120, %f322, 0f3F800000;
	selp.f64 	%fd522, 0d3FB999999999999A, %fd521, %p120;
	add.rn.f64 	%fd523, %fd124, %fd522;
	add.rn.f64 	%fd524, %fd121, %fd523;
	mul.rn.f64 	%fd525, %fd122, 0d3FB999999999999A;
	add.rn.f64 	%fd526, %fd525, %fd524;
	cvt.rn.f32.f64 	%f163, %fd108;
	cvt.f64.f32 	%fd527, %f163;
	mul.rn.f64 	%fd528, %fd527, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f164, %fd528;
	cvt.f64.f32 	%fd529, %f164;
	add.rn.f64 	%fd135, %fd526, %fd529;
	cvt.f64.f32 	%fd530, %f3;
	div.rn.f64 	%fd531, %fd530, 0d4066800000000000;
	mul.rn.f64 	%fd532, %fd531, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f31, %fd532;
	mul.rn.f32 	%f165, %f31, 0f3F22F983;
	cvt.rni.s32.f32 	%r694, %f165;
	cvt.rn.f32.s32 	%f166, %r694;
	mov.f32 	%f167, 0fBFC90FDA;
	fma.rn.f32 	%f168, %f166, %f167, %f31;
	mov.f32 	%f169, 0fB3A22168;
	fma.rn.f32 	%f170, %f166, %f169, %f168;
	mov.f32 	%f171, 0fA7C234C5;
	fma.rn.f32 	%f342, %f166, %f171, %f170;
	abs.f32 	%f33, %f31;
	setp.ltu.f32 	%p121, %f33, 0f47CE4780;
	mov.u32 	%r690, %r694;
	mov.f32 	%f339, %f342;
	@%p121 bra 	$L__BB6_124;

	setp.eq.f32 	%p122, %f33, 0f7F800000;
	@%p122 bra 	$L__BB6_123;
	bra.uni 	$L__BB6_118;

$L__BB6_123:
	mov.f32 	%f174, 0f00000000;
	mul.rn.f32 	%f339, %f31, %f174;
	mov.u32 	%r690, 0;
	bra.uni 	$L__BB6_124;

$L__BB6_118:
	mov.b32 	%r68, %f31;
	bfe.u32 	%r372, %r68, 23, 8;
	add.s32 	%r69, %r372, -128;
	shl.b32 	%r373, %r68, 8;
	or.b32  	%r70, %r373, -2147483648;
	shr.u32 	%r71, %r69, 5;
	mov.u64 	%rd260, 0;
	mov.u32 	%r687, 0;
	mov.u64 	%rd259, __cudart_i2opi_f;
	mov.u64 	%rd258, %rd1;

$L__BB6_119:
	.pragma "nounroll";
	ld.global.nc.u32 	%r374, [%rd259];
	mad.wide.u32 	%rd137, %r374, %r70, %rd260;
	shr.u64 	%rd260, %rd137, 32;
	st.local.u32 	[%rd258], %rd137;
	add.s64 	%rd259, %rd259, 4;
	add.s64 	%rd258, %rd258, 4;
	add.s32 	%r687, %r687, 1;
	setp.ne.s32 	%p123, %r687, 6;
	@%p123 bra 	$L__BB6_119;

	st.local.u32 	[%rd1+24], %rd260;
	mov.u32 	%r375, 4;
	sub.s32 	%r74, %r375, %r71;
	mov.u32 	%r376, 6;
	sub.s32 	%r377, %r376, %r71;
	mul.wide.s32 	%rd138, %r377, 4;
	add.s64 	%rd139, %rd1, %rd138;
	ld.local.u32 	%r688, [%rd139];
	ld.local.u32 	%r689, [%rd139+-4];
	and.b32  	%r77, %r69, 31;
	setp.eq.s32 	%p124, %r77, 0;
	@%p124 bra 	$L__BB6_122;

	mov.u32 	%r378, 32;
	sub.s32 	%r379, %r378, %r77;
	shr.u32 	%r380, %r689, %r379;
	shl.b32 	%r381, %r688, %r77;
	add.s32 	%r688, %r380, %r381;
	mul.wide.s32 	%rd140, %r74, 4;
	add.s64 	%rd141, %rd1, %rd140;
	ld.local.u32 	%r382, [%rd141];
	shr.u32 	%r383, %r382, %r379;
	shl.b32 	%r384, %r689, %r77;
	add.s32 	%r689, %r383, %r384;

$L__BB6_122:
	and.b32  	%r385, %r68, -2147483648;
	shr.u32 	%r386, %r689, 30;
	shl.b32 	%r387, %r688, 2;
	or.b32  	%r388, %r386, %r387;
	shr.u32 	%r389, %r388, 31;
	shr.u32 	%r390, %r688, 30;
	add.s32 	%r391, %r389, %r390;
	neg.s32 	%r392, %r391;
	setp.eq.s32 	%p125, %r385, 0;
	selp.b32 	%r690, %r391, %r392, %p125;
	setp.ne.s32 	%p126, %r389, 0;
	xor.b32  	%r393, %r385, -2147483648;
	selp.b32 	%r394, %r393, %r385, %p126;
	selp.b32 	%r395, -1, 0, %p126;
	xor.b32  	%r396, %r388, %r395;
	shl.b32 	%r397, %r689, 2;
	xor.b32  	%r398, %r397, %r395;
	cvt.u64.u32 	%rd142, %r396;
	cvt.u64.u32 	%rd143, %r398;
	bfi.b64 	%rd144, %rd142, %rd143, 32, 32;
	cvt.rn.f64.s64 	%fd533, %rd144;
	mul.rn.f64 	%fd534, %fd533, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f172, %fd534;
	setp.eq.s32 	%p127, %r394, 0;
	neg.f32 	%f173, %f172;
	selp.f32 	%f339, %f172, %f173, %p127;

$L__BB6_124:
	and.b32  	%r84, %r690, 1;
	setp.eq.s32 	%p128, %r84, 0;
	selp.f32 	%f37, %f339, 0f3F800000, %p128;
	mul.rn.f32 	%f38, %f339, %f339;
	mov.f32 	%f340, 0fB94D4153;
	@%p128 bra 	$L__BB6_126;

	mov.f32 	%f176, 0fBAB607ED;
	mov.f32 	%f177, 0f37CBAC00;
	fma.rn.f32 	%f340, %f177, %f38, %f176;

$L__BB6_126:
	selp.f32 	%f178, 0f3C0885E4, 0f3D2AAABB, %p128;
	fma.rn.f32 	%f179, %f340, %f38, %f178;
	selp.f32 	%f180, 0fBE2AAAA8, 0fBEFFFFFF, %p128;
	fma.rn.f32 	%f181, %f179, %f38, %f180;
	mov.f32 	%f182, 0f00000000;
	fma.rn.f32 	%f183, %f38, %f37, %f182;
	fma.rn.f32 	%f341, %f181, %f183, %f37;
	and.b32  	%r400, %r690, 2;
	setp.eq.s32 	%p130, %r400, 0;
	@%p130 bra 	$L__BB6_128;

	mov.f32 	%f185, 0fBF800000;
	fma.rn.f32 	%f341, %f341, %f185, %f182;

$L__BB6_128:
	@%p121 bra 	$L__BB6_136;

	setp.eq.f32 	%p132, %f33, 0f7F800000;
	@%p132 bra 	$L__BB6_135;
	bra.uni 	$L__BB6_130;

$L__BB6_135:
	mov.f32 	%f188, 0f00000000;
	mul.rn.f32 	%f342, %f31, %f188;
	mov.u32 	%r694, 0;
	bra.uni 	$L__BB6_136;

$L__BB6_130:
	mov.b32 	%r85, %f31;
	bfe.u32 	%r402, %r85, 23, 8;
	add.s32 	%r86, %r402, -128;
	shl.b32 	%r403, %r85, 8;
	or.b32  	%r87, %r403, -2147483648;
	shr.u32 	%r88, %r86, 5;
	mov.u64 	%rd261, 0;
	mov.u32 	%r691, 0;
	mov.u64 	%rd148, __cudart_i2opi_f;
	mov.u64 	%rd262, %rd261;

$L__BB6_131:
	.pragma "nounroll";
	shl.b64 	%rd147, %rd261, 2;
	add.s64 	%rd149, %rd148, %rd147;
	ld.global.nc.u32 	%r404, [%rd149];
	mad.wide.u32 	%rd150, %r404, %r87, %rd262;
	shr.u64 	%rd262, %rd150, 32;
	add.s64 	%rd151, %rd1, %rd147;
	st.local.u32 	[%rd151], %rd150;
	add.s32 	%r691, %r691, 1;
	cvt.s64.s32 	%rd261, %r691;
	setp.ne.s32 	%p133, %r691, 6;
	@%p133 bra 	$L__BB6_131;

	st.local.u32 	[%rd1+24], %rd262;
	mov.u32 	%r405, 4;
	sub.s32 	%r91, %r405, %r88;
	mov.u32 	%r406, 6;
	sub.s32 	%r407, %r406, %r88;
	mul.wide.s32 	%rd152, %r407, 4;
	add.s64 	%rd153, %rd1, %rd152;
	ld.local.u32 	%r692, [%rd153];
	ld.local.u32 	%r693, [%rd153+-4];
	and.b32  	%r94, %r86, 31;
	setp.eq.s32 	%p134, %r94, 0;
	@%p134 bra 	$L__BB6_134;

	mov.u32 	%r408, 32;
	sub.s32 	%r409, %r408, %r94;
	shr.u32 	%r410, %r693, %r409;
	shl.b32 	%r411, %r692, %r94;
	add.s32 	%r692, %r410, %r411;
	mul.wide.s32 	%rd154, %r91, 4;
	add.s64 	%rd155, %rd1, %rd154;
	ld.local.u32 	%r412, [%rd155];
	shr.u32 	%r413, %r412, %r409;
	shl.b32 	%r414, %r693, %r94;
	add.s32 	%r693, %r413, %r414;

$L__BB6_134:
	and.b32  	%r415, %r85, -2147483648;
	shr.u32 	%r416, %r693, 30;
	shl.b32 	%r417, %r692, 2;
	or.b32  	%r418, %r416, %r417;
	shr.u32 	%r419, %r418, 31;
	shr.u32 	%r420, %r692, 30;
	add.s32 	%r421, %r419, %r420;
	neg.s32 	%r422, %r421;
	setp.eq.s32 	%p135, %r415, 0;
	selp.b32 	%r694, %r421, %r422, %p135;
	setp.ne.s32 	%p136, %r419, 0;
	xor.b32  	%r423, %r415, -2147483648;
	selp.b32 	%r424, %r423, %r415, %p136;
	selp.b32 	%r425, -1, 0, %p136;
	xor.b32  	%r426, %r418, %r425;
	shl.b32 	%r427, %r693, 2;
	xor.b32  	%r428, %r427, %r425;
	cvt.u64.u32 	%rd156, %r426;
	cvt.u64.u32 	%rd157, %r428;
	bfi.b64 	%rd158, %rd156, %rd157, 32, 32;
	cvt.rn.f64.s64 	%fd535, %rd158;
	mul.rn.f64 	%fd536, %fd535, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f186, %fd536;
	setp.eq.s32 	%p137, %r424, 0;
	neg.f32 	%f187, %f186;
	selp.f32 	%f342, %f186, %f187, %p137;

$L__BB6_136:
	add.s32 	%r101, %r694, 1;
	and.b32  	%r102, %r101, 1;
	setp.eq.s32 	%p3, %r102, 0;
	mul.rn.f32 	%f47, %f342, %f342;
	mov.f32 	%f343, 0fB94D4153;
	@%p3 bra 	$L__BB6_138;

	mov.f32 	%f190, 0fBAB607ED;
	mov.f32 	%f191, 0f37CBAC00;
	fma.rn.f32 	%f343, %f191, %f47, %f190;

$L__BB6_138:
	selp.f32 	%f192, %f342, 0f3F800000, %p3;
	selp.f32 	%f193, 0f3C0885E4, 0f3D2AAABB, %p3;
	fma.rn.f32 	%f194, %f343, %f47, %f193;
	selp.f32 	%f195, 0fBE2AAAA8, 0fBEFFFFFF, %p3;
	fma.rn.f32 	%f196, %f194, %f47, %f195;
	mov.f32 	%f197, 0f00000000;
	fma.rn.f32 	%f198, %f47, %f192, %f197;
	fma.rn.f32 	%f344, %f196, %f198, %f192;
	and.b32  	%r430, %r101, 2;
	setp.eq.s32 	%p139, %r430, 0;
	@%p139 bra 	$L__BB6_140;

	mov.f32 	%f200, 0fBF800000;
	fma.rn.f32 	%f344, %f344, %f200, %f197;

$L__BB6_140:
	ld.param.u32 	%r670, [gcj02_to_wgs84_exact_cuda_float_param_4];
	cvt.f64.f32 	%fd537, %f341;
	mul.rn.f64 	%fd538, %fd537, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd539, %fd538, %fd537;
	add.rn.f64 	%fd540, %fd539, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f201, %fd540;
	sqrt.rn.f32 	%f202, %f201;
	mov.f32 	%f203, 0fCAC2A60A;
	div.rn.f32 	%f204, %f203, %f202;
	mul.rn.f32 	%f205, %f204, %f344;
	cvt.f64.f32 	%fd541, %f205;
	mul.rn.f64 	%fd542, %fd541, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f206, %fd135;
	cvt.f64.f32 	%fd543, %f206;
	mul.rn.f64 	%fd544, %fd543, 0d4066800000000000;
	div.rn.f64 	%fd545, %fd544, %fd542;
	cvt.rn.f32.f64 	%f207, %fd545;
	add.rn.f32 	%f359, %f1, %f207;
	mul.rn.f32 	%f208, %f202, %f201;
	cvt.f64.f32 	%fd546, %f208;
	mov.f64 	%fd547, 0dC1582B102DE355C1;
	div.rn.f64 	%fd548, %fd547, %fd546;
	mul.rn.f64 	%fd549, %fd548, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f209, %fd123;
	cvt.f64.f32 	%fd550, %f209;
	mul.rn.f64 	%fd551, %fd550, 0d4066800000000000;
	div.rn.f64 	%fd552, %fd551, %fd549;
	cvt.rn.f32.f64 	%f210, %fd552;
	add.rn.f32 	%f360, %f3, %f210;
	setp.lt.s32 	%p140, %r670, 1;
	@%p140 bra 	$L__BB6_292;

	and.b32  	%r103, %r61, 2147483647;
	setp.gt.s32 	%p141, %r61, -1;
	selp.b32 	%r104, 2146435072, 0, %p141;
	mov.u32 	%r695, 0;
	or.b32  	%r105, %r104, -2147483648;
	mov.u64 	%rd167, __cudart_i2opi_f;

$L__BB6_142:
	add.rn.f32 	%f57, %f360, 0fC20C0000;
	add.rn.f32 	%f58, %f359, 0fC2D20000;
	cvt.f64.f32 	%fd136, %f58;
	mul.rn.f64 	%fd553, %fd136, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f59, %fd553;
	cvt.f64.f32 	%fd137, %f57;
	mul.rn.f64 	%fd554, %fd137, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f60, %fd554;
	cvt.f64.f32 	%fd138, %f59;
	mul.rn.f64 	%fd139, %fd138, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r432, %temp}, %fd139;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r433}, %fd139;
	}
	and.b32  	%r434, %r433, 2147483647;
	setp.eq.s32 	%p142, %r434, 2146435072;
	setp.eq.s32 	%p143, %r432, 0;
	and.pred  	%p144, %p143, %p142;
	@%p144 bra 	$L__BB6_145;
	bra.uni 	$L__BB6_143;

$L__BB6_145:
	mov.f64 	%fd564, 0d0000000000000000;
	mul.rn.f64 	%fd879, %fd139, %fd564;
	mov.u32 	%r696, 0;
	bra.uni 	$L__BB6_146;

$L__BB6_143:
	mul.rn.f64 	%fd555, %fd139, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r696, %fd555;
	st.local.u32 	[%rd8], %r696;
	cvt.rn.f64.s32 	%fd556, %r696;
	neg.f64 	%fd557, %fd556;
	mov.f64 	%fd558, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd559, %fd557, %fd558, %fd139;
	mov.f64 	%fd560, 0d3C91A62633145C00;
	fma.rn.f64 	%fd561, %fd557, %fd560, %fd559;
	mov.f64 	%fd562, 0d397B839A252049C0;
	fma.rn.f64 	%fd879, %fd557, %fd562, %fd561;
	abs.f64 	%fd563, %fd139;
	setp.ltu.f64 	%p145, %fd563, 0d41E0000000000000;
	@%p145 bra 	$L__BB6_146;

	{ // callseq 58, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd139;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd879, [retval0+0];
	} // callseq 58
	ld.local.u32 	%r696, [%rd8];

$L__BB6_146:
	and.b32  	%r436, %r696, 1;
	shl.b32 	%r437, %r696, 3;
	and.b32  	%r438, %r437, 8;
	setp.eq.s32 	%p146, %r436, 0;
	selp.f64 	%fd565, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p146;
	mul.wide.s32 	%rd160, %r438, 8;
	add.s64 	%rd162, %rd85, %rd160;
	ld.global.nc.f64 	%fd566, [%rd162+8];
	mul.rn.f64 	%fd144, %fd879, %fd879;
	fma.rn.f64 	%fd567, %fd565, %fd144, %fd566;
	ld.global.nc.f64 	%fd568, [%rd162+16];
	fma.rn.f64 	%fd569, %fd567, %fd144, %fd568;
	ld.global.nc.f64 	%fd570, [%rd162+24];
	fma.rn.f64 	%fd571, %fd569, %fd144, %fd570;
	ld.global.nc.f64 	%fd572, [%rd162+32];
	fma.rn.f64 	%fd573, %fd571, %fd144, %fd572;
	ld.global.nc.f64 	%fd574, [%rd162+40];
	fma.rn.f64 	%fd575, %fd573, %fd144, %fd574;
	ld.global.nc.f64 	%fd576, [%rd162+48];
	fma.rn.f64 	%fd145, %fd575, %fd144, %fd576;
	fma.rn.f64 	%fd881, %fd145, %fd879, %fd879;
	@%p146 bra 	$L__BB6_148;

	mov.f64 	%fd577, 0d3FF0000000000000;
	fma.rn.f64 	%fd881, %fd145, %fd144, %fd577;

$L__BB6_148:
	and.b32  	%r439, %r696, 2;
	setp.eq.s32 	%p147, %r439, 0;
	@%p147 bra 	$L__BB6_150;

	mov.f64 	%fd578, 0d0000000000000000;
	mov.f64 	%fd579, 0dBFF0000000000000;
	fma.rn.f64 	%fd881, %fd881, %fd579, %fd578;

$L__BB6_150:
	add.rn.f64 	%fd151, %fd138, %fd138;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r440, %temp}, %fd151;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r441}, %fd151;
	}
	and.b32  	%r442, %r441, 2147483647;
	setp.eq.s32 	%p148, %r442, 2146435072;
	setp.eq.s32 	%p149, %r440, 0;
	and.pred  	%p150, %p149, %p148;
	@%p150 bra 	$L__BB6_153;
	bra.uni 	$L__BB6_151;

$L__BB6_153:
	mov.f64 	%fd589, 0d0000000000000000;
	mul.rn.f64 	%fd882, %fd151, %fd589;
	mov.u32 	%r697, 0;
	bra.uni 	$L__BB6_154;

$L__BB6_151:
	mul.rn.f64 	%fd580, %fd151, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r697, %fd580;
	st.local.u32 	[%rd8], %r697;
	cvt.rn.f64.s32 	%fd581, %r697;
	neg.f64 	%fd582, %fd581;
	mov.f64 	%fd583, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd584, %fd582, %fd583, %fd151;
	mov.f64 	%fd585, 0d3C91A62633145C00;
	fma.rn.f64 	%fd586, %fd582, %fd585, %fd584;
	mov.f64 	%fd587, 0d397B839A252049C0;
	fma.rn.f64 	%fd882, %fd582, %fd587, %fd586;
	abs.f64 	%fd588, %fd151;
	setp.ltu.f64 	%p151, %fd588, 0d41E0000000000000;
	@%p151 bra 	$L__BB6_154;

	{ // callseq 59, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd151;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd882, [retval0+0];
	} // callseq 59
	ld.local.u32 	%r697, [%rd8];

$L__BB6_154:
	and.b32  	%r444, %r697, 1;
	shl.b32 	%r445, %r697, 3;
	and.b32  	%r446, %r445, 8;
	setp.eq.s32 	%p152, %r444, 0;
	selp.f64 	%fd590, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p152;
	mul.wide.s32 	%rd164, %r446, 8;
	add.s64 	%rd166, %rd85, %rd164;
	ld.global.nc.f64 	%fd591, [%rd166+8];
	mul.rn.f64 	%fd156, %fd882, %fd882;
	fma.rn.f64 	%fd592, %fd590, %fd156, %fd591;
	ld.global.nc.f64 	%fd593, [%rd166+16];
	fma.rn.f64 	%fd594, %fd592, %fd156, %fd593;
	ld.global.nc.f64 	%fd595, [%rd166+24];
	fma.rn.f64 	%fd596, %fd594, %fd156, %fd595;
	ld.global.nc.f64 	%fd597, [%rd166+32];
	fma.rn.f64 	%fd598, %fd596, %fd156, %fd597;
	ld.global.nc.f64 	%fd599, [%rd166+40];
	fma.rn.f64 	%fd600, %fd598, %fd156, %fd599;
	ld.global.nc.f64 	%fd601, [%rd166+48];
	fma.rn.f64 	%fd157, %fd600, %fd156, %fd601;
	fma.rn.f64 	%fd884, %fd157, %fd882, %fd882;
	@%p152 bra 	$L__BB6_156;

	mov.f64 	%fd602, 0d3FF0000000000000;
	fma.rn.f64 	%fd884, %fd157, %fd156, %fd602;

$L__BB6_156:
	and.b32  	%r447, %r697, 2;
	setp.eq.s32 	%p153, %r447, 0;
	@%p153 bra 	$L__BB6_158;

	mov.f64 	%fd603, 0d0000000000000000;
	mov.f64 	%fd604, 0dBFF0000000000000;
	fma.rn.f64 	%fd884, %fd884, %fd604, %fd603;

$L__BB6_158:
	mul.rn.f64 	%fd605, %fd884, 0d4034000000000000;
	mul.rn.f64 	%fd606, %fd881, 0d4034000000000000;
	add.rn.f64 	%fd163, %fd606, %fd605;
	mul.rn.f32 	%f211, %f60, 0f3F22F983;
	cvt.rni.s32.f32 	%r701, %f211;
	cvt.rn.f32.s32 	%f212, %r701;
	mov.f32 	%f213, 0fBFC90FDA;
	fma.rn.f32 	%f214, %f212, %f213, %f60;
	mov.f32 	%f215, 0fB3A22168;
	fma.rn.f32 	%f216, %f212, %f215, %f214;
	mov.f32 	%f217, 0fA7C234C5;
	fma.rn.f32 	%f347, %f212, %f217, %f216;
	abs.f32 	%f62, %f60;
	setp.ltu.f32 	%p154, %f62, 0f47CE4780;
	@%p154 bra 	$L__BB6_166;

	setp.eq.f32 	%p155, %f62, 0f7F800000;
	@%p155 bra 	$L__BB6_165;
	bra.uni 	$L__BB6_160;

$L__BB6_165:
	mov.f32 	%f220, 0f00000000;
	mul.rn.f32 	%f347, %f60, %f220;
	mov.u32 	%r701, 0;
	bra.uni 	$L__BB6_166;

$L__BB6_160:
	mov.b32 	%r114, %f60;
	bfe.u32 	%r449, %r114, 23, 8;
	add.s32 	%r115, %r449, -128;
	shl.b32 	%r450, %r114, 8;
	or.b32  	%r116, %r450, -2147483648;
	shr.u32 	%r117, %r115, 5;
	mov.u64 	%rd265, 0;
	mov.u32 	%r698, 0;
	mov.u64 	%rd263, %rd1;
	mov.u64 	%rd264, %rd167;

$L__BB6_161:
	.pragma "nounroll";
	ld.global.nc.u32 	%r451, [%rd264];
	mad.wide.u32 	%rd169, %r451, %r116, %rd265;
	shr.u64 	%rd265, %rd169, 32;
	st.local.u32 	[%rd263], %rd169;
	add.s64 	%rd264, %rd264, 4;
	add.s64 	%rd263, %rd263, 4;
	add.s32 	%r698, %r698, 1;
	setp.ne.s32 	%p156, %r698, 6;
	@%p156 bra 	$L__BB6_161;

	st.local.u32 	[%rd1+24], %rd265;
	mov.u32 	%r452, 4;
	sub.s32 	%r120, %r452, %r117;
	mov.u32 	%r453, 6;
	sub.s32 	%r454, %r453, %r117;
	mul.wide.s32 	%rd170, %r454, 4;
	add.s64 	%rd171, %rd1, %rd170;
	ld.local.u32 	%r699, [%rd171];
	ld.local.u32 	%r700, [%rd171+-4];
	and.b32  	%r123, %r115, 31;
	setp.eq.s32 	%p157, %r123, 0;
	@%p157 bra 	$L__BB6_164;

	mov.u32 	%r455, 32;
	sub.s32 	%r456, %r455, %r123;
	shr.u32 	%r457, %r700, %r456;
	shl.b32 	%r458, %r699, %r123;
	add.s32 	%r699, %r457, %r458;
	mul.wide.s32 	%rd172, %r120, 4;
	add.s64 	%rd173, %rd1, %rd172;
	ld.local.u32 	%r459, [%rd173];
	shr.u32 	%r460, %r459, %r456;
	shl.b32 	%r461, %r700, %r123;
	add.s32 	%r700, %r460, %r461;

$L__BB6_164:
	and.b32  	%r462, %r114, -2147483648;
	shr.u32 	%r463, %r700, 30;
	shl.b32 	%r464, %r699, 2;
	or.b32  	%r465, %r463, %r464;
	shr.u32 	%r466, %r465, 31;
	shr.u32 	%r467, %r699, 30;
	add.s32 	%r468, %r466, %r467;
	neg.s32 	%r469, %r468;
	setp.eq.s32 	%p158, %r462, 0;
	selp.b32 	%r701, %r468, %r469, %p158;
	setp.ne.s32 	%p159, %r466, 0;
	xor.b32  	%r470, %r462, -2147483648;
	selp.b32 	%r471, %r470, %r462, %p159;
	selp.b32 	%r472, -1, 0, %p159;
	xor.b32  	%r473, %r465, %r472;
	shl.b32 	%r474, %r700, 2;
	xor.b32  	%r475, %r474, %r472;
	cvt.u64.u32 	%rd174, %r473;
	cvt.u64.u32 	%rd175, %r475;
	bfi.b64 	%rd176, %rd174, %rd175, 32, 32;
	cvt.rn.f64.s64 	%fd607, %rd176;
	mul.rn.f64 	%fd608, %fd607, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f218, %fd608;
	setp.eq.s32 	%p160, %r471, 0;
	neg.f32 	%f219, %f218;
	selp.f32 	%f347, %f218, %f219, %p160;

$L__BB6_166:
	and.b32  	%r130, %r701, 1;
	setp.eq.s32 	%p161, %r130, 0;
	selp.f32 	%f66, %f347, 0f3F800000, %p161;
	mul.rn.f32 	%f67, %f347, %f347;
	mov.f32 	%f348, 0fB94D4153;
	@%p161 bra 	$L__BB6_168;

	mov.f32 	%f222, 0fBAB607ED;
	mov.f32 	%f223, 0f37CBAC00;
	fma.rn.f32 	%f348, %f223, %f67, %f222;

$L__BB6_168:
	selp.f32 	%f224, 0f3C0885E4, 0f3D2AAABB, %p161;
	fma.rn.f32 	%f225, %f348, %f67, %f224;
	selp.f32 	%f226, 0fBE2AAAA8, 0fBEFFFFFF, %p161;
	fma.rn.f32 	%f227, %f225, %f67, %f226;
	mov.f32 	%f228, 0f00000000;
	fma.rn.f32 	%f229, %f67, %f66, %f228;
	fma.rn.f32 	%f349, %f227, %f229, %f66;
	and.b32  	%r477, %r701, 2;
	setp.eq.s32 	%p163, %r477, 0;
	@%p163 bra 	$L__BB6_170;

	mov.f32 	%f231, 0fBF800000;
	fma.rn.f32 	%f349, %f349, %f231, %f228;

$L__BB6_170:
	cvt.f64.f32 	%fd164, %f60;
	div.rn.f64 	%fd165, %fd164, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r478, %temp}, %fd165;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r479}, %fd165;
	}
	and.b32  	%r480, %r479, 2147483647;
	setp.eq.s32 	%p164, %r480, 2146435072;
	setp.eq.s32 	%p165, %r478, 0;
	and.pred  	%p166, %p165, %p164;
	@%p166 bra 	$L__BB6_173;
	bra.uni 	$L__BB6_171;

$L__BB6_173:
	mov.f64 	%fd618, 0d0000000000000000;
	mul.rn.f64 	%fd885, %fd165, %fd618;
	mov.u32 	%r702, 0;
	bra.uni 	$L__BB6_174;

$L__BB6_171:
	mul.rn.f64 	%fd609, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r702, %fd609;
	st.local.u32 	[%rd1], %r702;
	cvt.rn.f64.s32 	%fd610, %r702;
	neg.f64 	%fd611, %fd610;
	mov.f64 	%fd612, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd613, %fd611, %fd612, %fd165;
	mov.f64 	%fd614, 0d3C91A62633145C00;
	fma.rn.f64 	%fd615, %fd611, %fd614, %fd613;
	mov.f64 	%fd616, 0d397B839A252049C0;
	fma.rn.f64 	%fd885, %fd611, %fd616, %fd615;
	abs.f64 	%fd617, %fd165;
	setp.ltu.f64 	%p167, %fd617, 0d41E0000000000000;
	@%p167 bra 	$L__BB6_174;

	{ // callseq 60, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd885, [retval0+0];
	} // callseq 60
	ld.local.u32 	%r702, [%rd1];

$L__BB6_174:
	and.b32  	%r482, %r702, 1;
	shl.b32 	%r483, %r702, 3;
	and.b32  	%r484, %r483, 8;
	setp.eq.s32 	%p168, %r482, 0;
	selp.f64 	%fd619, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p168;
	mul.wide.s32 	%rd178, %r484, 8;
	add.s64 	%rd180, %rd85, %rd178;
	ld.global.nc.f64 	%fd620, [%rd180+8];
	mul.rn.f64 	%fd170, %fd885, %fd885;
	fma.rn.f64 	%fd621, %fd619, %fd170, %fd620;
	ld.global.nc.f64 	%fd622, [%rd180+16];
	fma.rn.f64 	%fd623, %fd621, %fd170, %fd622;
	ld.global.nc.f64 	%fd624, [%rd180+24];
	fma.rn.f64 	%fd625, %fd623, %fd170, %fd624;
	ld.global.nc.f64 	%fd626, [%rd180+32];
	fma.rn.f64 	%fd627, %fd625, %fd170, %fd626;
	ld.global.nc.f64 	%fd628, [%rd180+40];
	fma.rn.f64 	%fd629, %fd627, %fd170, %fd628;
	ld.global.nc.f64 	%fd630, [%rd180+48];
	fma.rn.f64 	%fd171, %fd629, %fd170, %fd630;
	fma.rn.f64 	%fd887, %fd171, %fd885, %fd885;
	@%p168 bra 	$L__BB6_176;

	mov.f64 	%fd631, 0d3FF0000000000000;
	fma.rn.f64 	%fd887, %fd171, %fd170, %fd631;

$L__BB6_176:
	and.b32  	%r485, %r702, 2;
	setp.eq.s32 	%p169, %r485, 0;
	@%p169 bra 	$L__BB6_178;

	mov.f64 	%fd632, 0d0000000000000000;
	mov.f64 	%fd633, 0dBFF0000000000000;
	fma.rn.f64 	%fd887, %fd887, %fd633, %fd632;

$L__BB6_178:
	mul.rn.f64 	%fd634, %fd887, 0d4044000000000000;
	cvt.f64.f32 	%fd635, %f349;
	mul.rn.f64 	%fd636, %fd635, 0d4034000000000000;
	add.rn.f64 	%fd177, %fd636, %fd634;
	div.rn.f64 	%fd178, %fd164, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r486, %temp}, %fd178;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r487}, %fd178;
	}
	and.b32  	%r488, %r487, 2147483647;
	setp.eq.s32 	%p170, %r488, 2146435072;
	setp.eq.s32 	%p171, %r486, 0;
	and.pred  	%p172, %p171, %p170;
	@%p172 bra 	$L__BB6_181;
	bra.uni 	$L__BB6_179;

$L__BB6_181:
	mov.f64 	%fd646, 0d0000000000000000;
	mul.rn.f64 	%fd888, %fd178, %fd646;
	mov.u32 	%r703, 0;
	bra.uni 	$L__BB6_182;

$L__BB6_179:
	mul.rn.f64 	%fd637, %fd178, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r703, %fd637;
	st.local.u32 	[%rd1], %r703;
	cvt.rn.f64.s32 	%fd638, %r703;
	neg.f64 	%fd639, %fd638;
	mov.f64 	%fd640, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd641, %fd639, %fd640, %fd178;
	mov.f64 	%fd642, 0d3C91A62633145C00;
	fma.rn.f64 	%fd643, %fd639, %fd642, %fd641;
	mov.f64 	%fd644, 0d397B839A252049C0;
	fma.rn.f64 	%fd888, %fd639, %fd644, %fd643;
	abs.f64 	%fd645, %fd178;
	setp.ltu.f64 	%p173, %fd645, 0d41E0000000000000;
	@%p173 bra 	$L__BB6_182;

	{ // callseq 61, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd888, [retval0+0];
	} // callseq 61
	ld.local.u32 	%r703, [%rd1];

$L__BB6_182:
	and.b32  	%r490, %r703, 1;
	shl.b32 	%r491, %r703, 3;
	and.b32  	%r492, %r491, 8;
	setp.eq.s32 	%p174, %r490, 0;
	selp.f64 	%fd647, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p174;
	mul.wide.s32 	%rd182, %r492, 8;
	add.s64 	%rd184, %rd85, %rd182;
	ld.global.nc.f64 	%fd648, [%rd184+8];
	mul.rn.f64 	%fd183, %fd888, %fd888;
	fma.rn.f64 	%fd649, %fd647, %fd183, %fd648;
	ld.global.nc.f64 	%fd650, [%rd184+16];
	fma.rn.f64 	%fd651, %fd649, %fd183, %fd650;
	ld.global.nc.f64 	%fd652, [%rd184+24];
	fma.rn.f64 	%fd653, %fd651, %fd183, %fd652;
	ld.global.nc.f64 	%fd654, [%rd184+32];
	fma.rn.f64 	%fd655, %fd653, %fd183, %fd654;
	ld.global.nc.f64 	%fd656, [%rd184+40];
	fma.rn.f64 	%fd657, %fd655, %fd183, %fd656;
	ld.global.nc.f64 	%fd658, [%rd184+48];
	fma.rn.f64 	%fd184, %fd657, %fd183, %fd658;
	fma.rn.f64 	%fd890, %fd184, %fd888, %fd888;
	@%p174 bra 	$L__BB6_184;

	mov.f64 	%fd659, 0d3FF0000000000000;
	fma.rn.f64 	%fd890, %fd184, %fd183, %fd659;

$L__BB6_184:
	and.b32  	%r493, %r703, 2;
	setp.eq.s32 	%p175, %r493, 0;
	@%p175 bra 	$L__BB6_186;

	mov.f64 	%fd660, 0d0000000000000000;
	mov.f64 	%fd661, 0dBFF0000000000000;
	fma.rn.f64 	%fd890, %fd890, %fd661, %fd660;

$L__BB6_186:
	mul.rn.f64 	%fd662, %fd890, 0d4064000000000000;
	add.rn.f64 	%fd190, %fd177, %fd662;
	div.rn.f64 	%fd191, %fd164, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r494, %temp}, %fd191;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r495}, %fd191;
	}
	and.b32  	%r496, %r495, 2147483647;
	setp.eq.s32 	%p176, %r496, 2146435072;
	setp.eq.s32 	%p177, %r494, 0;
	and.pred  	%p178, %p177, %p176;
	@%p178 bra 	$L__BB6_189;
	bra.uni 	$L__BB6_187;

$L__BB6_189:
	mov.f64 	%fd672, 0d0000000000000000;
	mul.rn.f64 	%fd891, %fd191, %fd672;
	mov.u32 	%r704, 0;
	bra.uni 	$L__BB6_190;

$L__BB6_187:
	mul.rn.f64 	%fd663, %fd191, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r704, %fd663;
	st.local.u32 	[%rd1], %r704;
	cvt.rn.f64.s32 	%fd664, %r704;
	neg.f64 	%fd665, %fd664;
	mov.f64 	%fd666, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd667, %fd665, %fd666, %fd191;
	mov.f64 	%fd668, 0d3C91A62633145C00;
	fma.rn.f64 	%fd669, %fd665, %fd668, %fd667;
	mov.f64 	%fd670, 0d397B839A252049C0;
	fma.rn.f64 	%fd891, %fd665, %fd670, %fd669;
	abs.f64 	%fd671, %fd191;
	setp.ltu.f64 	%p179, %fd671, 0d41E0000000000000;
	@%p179 bra 	$L__BB6_190;

	{ // callseq 62, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd891, [retval0+0];
	} // callseq 62
	ld.local.u32 	%r704, [%rd1];

$L__BB6_190:
	and.b32  	%r498, %r704, 1;
	shl.b32 	%r499, %r704, 3;
	and.b32  	%r500, %r499, 8;
	setp.eq.s32 	%p180, %r498, 0;
	selp.f64 	%fd673, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p180;
	mul.wide.s32 	%rd186, %r500, 8;
	add.s64 	%rd188, %rd85, %rd186;
	ld.global.nc.f64 	%fd674, [%rd188+8];
	mul.rn.f64 	%fd196, %fd891, %fd891;
	fma.rn.f64 	%fd675, %fd673, %fd196, %fd674;
	ld.global.nc.f64 	%fd676, [%rd188+16];
	fma.rn.f64 	%fd677, %fd675, %fd196, %fd676;
	ld.global.nc.f64 	%fd678, [%rd188+24];
	fma.rn.f64 	%fd679, %fd677, %fd196, %fd678;
	ld.global.nc.f64 	%fd680, [%rd188+32];
	fma.rn.f64 	%fd681, %fd679, %fd196, %fd680;
	ld.global.nc.f64 	%fd682, [%rd188+40];
	fma.rn.f64 	%fd683, %fd681, %fd196, %fd682;
	ld.global.nc.f64 	%fd684, [%rd188+48];
	fma.rn.f64 	%fd197, %fd683, %fd196, %fd684;
	fma.rn.f64 	%fd893, %fd197, %fd891, %fd891;
	@%p180 bra 	$L__BB6_192;

	mov.f64 	%fd685, 0d3FF0000000000000;
	fma.rn.f64 	%fd893, %fd197, %fd196, %fd685;

$L__BB6_192:
	and.b32  	%r501, %r704, 2;
	setp.eq.s32 	%p181, %r501, 0;
	@%p181 bra 	$L__BB6_194;

	mov.f64 	%fd686, 0d0000000000000000;
	mov.f64 	%fd687, 0dBFF0000000000000;
	fma.rn.f64 	%fd893, %fd893, %fd687, %fd686;

$L__BB6_194:
	mul.rn.f64 	%fd688, %fd893, 0d4074000000000000;
	add.rn.f64 	%fd203, %fd190, %fd688;
	mul.rn.f32 	%f232, %f59, 0f3F22F983;
	cvt.rni.s32.f32 	%r707, %f232;
	cvt.rn.f32.s32 	%f233, %r707;
	mov.f32 	%f234, 0fBFC90FDA;
	fma.rn.f32 	%f235, %f233, %f234, %f59;
	mov.f32 	%f236, 0fB3A22168;
	fma.rn.f32 	%f237, %f233, %f236, %f235;
	mov.f32 	%f238, 0fA7C234C5;
	fma.rn.f32 	%f350, %f233, %f238, %f237;
	abs.f32 	%f74, %f59;
	setp.ltu.f32 	%p182, %f74, 0f47CE4780;
	@%p182 bra 	$L__BB6_202;

	setp.eq.f32 	%p183, %f74, 0f7F800000;
	@%p183 bra 	$L__BB6_201;
	bra.uni 	$L__BB6_196;

$L__BB6_201:
	mov.f32 	%f241, 0f00000000;
	mul.rn.f32 	%f350, %f59, %f241;
	mov.u32 	%r707, 0;
	bra.uni 	$L__BB6_202;

$L__BB6_196:
	mov.b32 	%r141, %f59;
	bfe.u32 	%r502, %r141, 23, 8;
	add.s32 	%r142, %r502, -128;
	shl.b32 	%r503, %r141, 8;
	or.b32  	%r143, %r503, -2147483648;
	shr.u32 	%r144, %r142, 5;
	mov.u64 	%rd266, 0;
	mov.u64 	%rd267, %rd266;

$L__BB6_197:
	.pragma "nounroll";
	shl.b64 	%rd191, %rd266, 2;
	mov.u64 	%rd192, __cudart_i2opi_f;
	add.s64 	%rd193, %rd192, %rd191;
	ld.global.nc.u32 	%r504, [%rd193];
	mad.wide.u32 	%rd194, %r504, %r143, %rd267;
	shr.u64 	%rd267, %rd194, 32;
	add.s64 	%rd195, %rd1, %rd191;
	st.local.u32 	[%rd195], %rd194;
	cvt.u32.u64 	%r505, %rd266;
	add.s32 	%r506, %r505, 1;
	cvt.s64.s32 	%rd266, %r506;
	setp.ne.s32 	%p184, %r506, 6;
	@%p184 bra 	$L__BB6_197;

	st.local.u32 	[%rd1+24], %rd267;
	mov.u32 	%r507, 4;
	sub.s32 	%r145, %r507, %r144;
	mov.u32 	%r508, 6;
	sub.s32 	%r509, %r508, %r144;
	mul.wide.s32 	%rd196, %r509, 4;
	add.s64 	%rd197, %rd1, %rd196;
	ld.local.u32 	%r705, [%rd197];
	ld.local.u32 	%r706, [%rd197+-4];
	and.b32  	%r148, %r142, 31;
	setp.eq.s32 	%p185, %r148, 0;
	@%p185 bra 	$L__BB6_200;

	mov.u32 	%r510, 32;
	sub.s32 	%r511, %r510, %r148;
	shr.u32 	%r512, %r706, %r511;
	shl.b32 	%r513, %r705, %r148;
	add.s32 	%r705, %r512, %r513;
	mul.wide.s32 	%rd198, %r145, 4;
	add.s64 	%rd199, %rd1, %rd198;
	ld.local.u32 	%r514, [%rd199];
	shr.u32 	%r515, %r514, %r511;
	shl.b32 	%r516, %r706, %r148;
	add.s32 	%r706, %r515, %r516;

$L__BB6_200:
	and.b32  	%r517, %r141, -2147483648;
	shr.u32 	%r518, %r706, 30;
	shl.b32 	%r519, %r705, 2;
	or.b32  	%r520, %r518, %r519;
	shr.u32 	%r521, %r520, 31;
	shr.u32 	%r522, %r705, 30;
	add.s32 	%r523, %r521, %r522;
	neg.s32 	%r524, %r523;
	setp.eq.s32 	%p186, %r517, 0;
	selp.b32 	%r707, %r523, %r524, %p186;
	setp.ne.s32 	%p187, %r521, 0;
	xor.b32  	%r525, %r517, -2147483648;
	selp.b32 	%r526, %r525, %r517, %p187;
	selp.b32 	%r527, -1, 0, %p187;
	xor.b32  	%r528, %r520, %r527;
	shl.b32 	%r529, %r706, 2;
	xor.b32  	%r530, %r529, %r527;
	cvt.u64.u32 	%rd200, %r528;
	cvt.u64.u32 	%rd201, %r530;
	bfi.b64 	%rd202, %rd200, %rd201, 32, 32;
	cvt.rn.f64.s64 	%fd689, %rd202;
	mul.rn.f64 	%fd690, %fd689, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f239, %fd690;
	setp.eq.s32 	%p188, %r526, 0;
	neg.f32 	%f240, %f239;
	selp.f32 	%f350, %f239, %f240, %p188;

$L__BB6_202:
	cvt.rn.f32.f64 	%f243, %fd163;
	cvt.f64.f32 	%fd204, %f243;
	and.b32  	%r155, %r707, 1;
	setp.eq.s32 	%p189, %r155, 0;
	selp.f32 	%f78, %f350, 0f3F800000, %p189;
	mul.rn.f32 	%f79, %f350, %f350;
	mov.f32 	%f351, 0fB94D4153;
	@%p189 bra 	$L__BB6_204;

	mov.f32 	%f244, 0fBAB607ED;
	mov.f32 	%f245, 0f37CBAC00;
	fma.rn.f32 	%f351, %f245, %f79, %f244;

$L__BB6_204:
	selp.f32 	%f246, 0f3C0885E4, 0f3D2AAABB, %p189;
	fma.rn.f32 	%f247, %f351, %f79, %f246;
	selp.f32 	%f248, 0fBE2AAAA8, 0fBEFFFFFF, %p189;
	fma.rn.f32 	%f249, %f247, %f79, %f248;
	mov.f32 	%f250, 0f00000000;
	fma.rn.f32 	%f251, %f79, %f78, %f250;
	fma.rn.f32 	%f352, %f249, %f251, %f78;
	and.b32  	%r532, %r707, 2;
	setp.eq.s32 	%p191, %r532, 0;
	@%p191 bra 	$L__BB6_206;

	mov.f32 	%f253, 0fBF800000;
	fma.rn.f32 	%f352, %f352, %f253, %f250;

$L__BB6_206:
	div.rn.f64 	%fd205, %fd138, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r533, %temp}, %fd205;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r534}, %fd205;
	}
	and.b32  	%r535, %r534, 2147483647;
	setp.eq.s32 	%p192, %r535, 2146435072;
	setp.eq.s32 	%p193, %r533, 0;
	and.pred  	%p194, %p193, %p192;
	@%p194 bra 	$L__BB6_209;
	bra.uni 	$L__BB6_207;

$L__BB6_209:
	mov.f64 	%fd700, 0d0000000000000000;
	mul.rn.f64 	%fd894, %fd205, %fd700;
	mov.u32 	%r708, 0;
	bra.uni 	$L__BB6_210;

$L__BB6_207:
	mul.rn.f64 	%fd691, %fd205, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r708, %fd691;
	st.local.u32 	[%rd1], %r708;
	cvt.rn.f64.s32 	%fd692, %r708;
	neg.f64 	%fd693, %fd692;
	mov.f64 	%fd694, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd695, %fd693, %fd694, %fd205;
	mov.f64 	%fd696, 0d3C91A62633145C00;
	fma.rn.f64 	%fd697, %fd693, %fd696, %fd695;
	mov.f64 	%fd698, 0d397B839A252049C0;
	fma.rn.f64 	%fd894, %fd693, %fd698, %fd697;
	abs.f64 	%fd699, %fd205;
	setp.ltu.f64 	%p195, %fd699, 0d41E0000000000000;
	@%p195 bra 	$L__BB6_210;

	{ // callseq 63, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd205;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd894, [retval0+0];
	} // callseq 63
	ld.local.u32 	%r708, [%rd1];

$L__BB6_210:
	and.b32  	%r537, %r708, 1;
	shl.b32 	%r538, %r708, 3;
	and.b32  	%r539, %r538, 8;
	setp.eq.s32 	%p196, %r537, 0;
	selp.f64 	%fd701, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd204, %r539, 8;
	add.s64 	%rd206, %rd85, %rd204;
	ld.global.nc.f64 	%fd702, [%rd206+8];
	mul.rn.f64 	%fd210, %fd894, %fd894;
	fma.rn.f64 	%fd703, %fd701, %fd210, %fd702;
	ld.global.nc.f64 	%fd704, [%rd206+16];
	fma.rn.f64 	%fd705, %fd703, %fd210, %fd704;
	ld.global.nc.f64 	%fd706, [%rd206+24];
	fma.rn.f64 	%fd707, %fd705, %fd210, %fd706;
	ld.global.nc.f64 	%fd708, [%rd206+32];
	fma.rn.f64 	%fd709, %fd707, %fd210, %fd708;
	ld.global.nc.f64 	%fd710, [%rd206+40];
	fma.rn.f64 	%fd711, %fd709, %fd210, %fd710;
	ld.global.nc.f64 	%fd712, [%rd206+48];
	fma.rn.f64 	%fd211, %fd711, %fd210, %fd712;
	fma.rn.f64 	%fd896, %fd211, %fd894, %fd894;
	@%p196 bra 	$L__BB6_212;

	mov.f64 	%fd713, 0d3FF0000000000000;
	fma.rn.f64 	%fd896, %fd211, %fd210, %fd713;

$L__BB6_212:
	and.b32  	%r540, %r708, 2;
	setp.eq.s32 	%p197, %r540, 0;
	@%p197 bra 	$L__BB6_214;

	mov.f64 	%fd714, 0d0000000000000000;
	mov.f64 	%fd715, 0dBFF0000000000000;
	fma.rn.f64 	%fd896, %fd896, %fd715, %fd714;

$L__BB6_214:
	mul.rn.f64 	%fd716, %fd896, 0d4044000000000000;
	cvt.f64.f32 	%fd717, %f352;
	mul.rn.f64 	%fd718, %fd717, 0d4034000000000000;
	add.rn.f64 	%fd217, %fd718, %fd716;
	div.rn.f64 	%fd218, %fd138, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r541, %temp}, %fd218;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r542}, %fd218;
	}
	and.b32  	%r543, %r542, 2147483647;
	setp.eq.s32 	%p198, %r543, 2146435072;
	setp.eq.s32 	%p199, %r541, 0;
	and.pred  	%p200, %p199, %p198;
	@%p200 bra 	$L__BB6_217;
	bra.uni 	$L__BB6_215;

$L__BB6_217:
	mov.f64 	%fd728, 0d0000000000000000;
	mul.rn.f64 	%fd897, %fd218, %fd728;
	mov.u32 	%r709, 0;
	bra.uni 	$L__BB6_218;

$L__BB6_215:
	mul.rn.f64 	%fd719, %fd218, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r709, %fd719;
	st.local.u32 	[%rd1], %r709;
	cvt.rn.f64.s32 	%fd720, %r709;
	neg.f64 	%fd721, %fd720;
	mov.f64 	%fd722, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd723, %fd721, %fd722, %fd218;
	mov.f64 	%fd724, 0d3C91A62633145C00;
	fma.rn.f64 	%fd725, %fd721, %fd724, %fd723;
	mov.f64 	%fd726, 0d397B839A252049C0;
	fma.rn.f64 	%fd897, %fd721, %fd726, %fd725;
	abs.f64 	%fd727, %fd218;
	setp.ltu.f64 	%p201, %fd727, 0d41E0000000000000;
	@%p201 bra 	$L__BB6_218;

	{ // callseq 64, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd218;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd897, [retval0+0];
	} // callseq 64
	ld.local.u32 	%r709, [%rd1];

$L__BB6_218:
	and.b32  	%r545, %r709, 1;
	shl.b32 	%r546, %r709, 3;
	and.b32  	%r547, %r546, 8;
	setp.eq.s32 	%p202, %r545, 0;
	selp.f64 	%fd729, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p202;
	mul.wide.s32 	%rd208, %r547, 8;
	add.s64 	%rd210, %rd85, %rd208;
	ld.global.nc.f64 	%fd730, [%rd210+8];
	mul.rn.f64 	%fd223, %fd897, %fd897;
	fma.rn.f64 	%fd731, %fd729, %fd223, %fd730;
	ld.global.nc.f64 	%fd732, [%rd210+16];
	fma.rn.f64 	%fd733, %fd731, %fd223, %fd732;
	ld.global.nc.f64 	%fd734, [%rd210+24];
	fma.rn.f64 	%fd735, %fd733, %fd223, %fd734;
	ld.global.nc.f64 	%fd736, [%rd210+32];
	fma.rn.f64 	%fd737, %fd735, %fd223, %fd736;
	ld.global.nc.f64 	%fd738, [%rd210+40];
	fma.rn.f64 	%fd739, %fd737, %fd223, %fd738;
	ld.global.nc.f64 	%fd740, [%rd210+48];
	fma.rn.f64 	%fd224, %fd739, %fd223, %fd740;
	fma.rn.f64 	%fd899, %fd224, %fd897, %fd897;
	@%p202 bra 	$L__BB6_220;

	mov.f64 	%fd741, 0d3FF0000000000000;
	fma.rn.f64 	%fd899, %fd224, %fd223, %fd741;

$L__BB6_220:
	and.b32  	%r548, %r709, 2;
	setp.eq.s32 	%p203, %r548, 0;
	@%p203 bra 	$L__BB6_222;

	mov.f64 	%fd742, 0d0000000000000000;
	mov.f64 	%fd743, 0dBFF0000000000000;
	fma.rn.f64 	%fd899, %fd899, %fd743, %fd742;

$L__BB6_222:
	mul.rn.f64 	%fd744, %fd899, 0d4062C00000000000;
	add.rn.f64 	%fd230, %fd217, %fd744;
	div.rn.f64 	%fd231, %fd138, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r549, %temp}, %fd231;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r550}, %fd231;
	}
	and.b32  	%r551, %r550, 2147483647;
	setp.eq.s32 	%p204, %r551, 2146435072;
	setp.eq.s32 	%p205, %r549, 0;
	and.pred  	%p206, %p205, %p204;
	@%p206 bra 	$L__BB6_225;
	bra.uni 	$L__BB6_223;

$L__BB6_225:
	mov.f64 	%fd754, 0d0000000000000000;
	mul.rn.f64 	%fd900, %fd231, %fd754;
	mov.u32 	%r710, 0;
	bra.uni 	$L__BB6_226;

$L__BB6_223:
	mul.rn.f64 	%fd745, %fd231, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r710, %fd745;
	st.local.u32 	[%rd1], %r710;
	cvt.rn.f64.s32 	%fd746, %r710;
	neg.f64 	%fd747, %fd746;
	mov.f64 	%fd748, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd749, %fd747, %fd748, %fd231;
	mov.f64 	%fd750, 0d3C91A62633145C00;
	fma.rn.f64 	%fd751, %fd747, %fd750, %fd749;
	mov.f64 	%fd752, 0d397B839A252049C0;
	fma.rn.f64 	%fd900, %fd747, %fd752, %fd751;
	abs.f64 	%fd753, %fd231;
	setp.ltu.f64 	%p207, %fd753, 0d41E0000000000000;
	@%p207 bra 	$L__BB6_226;

	{ // callseq 65, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd231;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd900, [retval0+0];
	} // callseq 65
	ld.local.u32 	%r710, [%rd1];

$L__BB6_226:
	and.b32  	%r553, %r710, 1;
	shl.b32 	%r554, %r710, 3;
	and.b32  	%r555, %r554, 8;
	setp.eq.s32 	%p208, %r553, 0;
	selp.f64 	%fd755, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p208;
	mul.wide.s32 	%rd212, %r555, 8;
	add.s64 	%rd214, %rd85, %rd212;
	ld.global.nc.f64 	%fd756, [%rd214+8];
	mul.rn.f64 	%fd236, %fd900, %fd900;
	fma.rn.f64 	%fd757, %fd755, %fd236, %fd756;
	ld.global.nc.f64 	%fd758, [%rd214+16];
	fma.rn.f64 	%fd759, %fd757, %fd236, %fd758;
	ld.global.nc.f64 	%fd760, [%rd214+24];
	fma.rn.f64 	%fd761, %fd759, %fd236, %fd760;
	ld.global.nc.f64 	%fd762, [%rd214+32];
	fma.rn.f64 	%fd763, %fd761, %fd236, %fd762;
	ld.global.nc.f64 	%fd764, [%rd214+40];
	fma.rn.f64 	%fd765, %fd763, %fd236, %fd764;
	ld.global.nc.f64 	%fd766, [%rd214+48];
	fma.rn.f64 	%fd237, %fd765, %fd236, %fd766;
	fma.rn.f64 	%fd902, %fd237, %fd900, %fd900;
	@%p208 bra 	$L__BB6_228;

	mov.f64 	%fd767, 0d3FF0000000000000;
	fma.rn.f64 	%fd902, %fd237, %fd236, %fd767;

$L__BB6_228:
	and.b32  	%r556, %r710, 2;
	setp.eq.s32 	%p209, %r556, 0;
	@%p209 bra 	$L__BB6_230;

	mov.f64 	%fd768, 0d0000000000000000;
	mov.f64 	%fd769, 0dBFF0000000000000;
	fma.rn.f64 	%fd902, %fd902, %fd769, %fd768;

$L__BB6_230:
	mul.rn.f64 	%fd770, %fd902, 0d4072C00000000000;
	add.rn.f64 	%fd771, %fd230, %fd770;
	add.rn.f64 	%fd243, %fd771, %fd204;
	add.rn.f64 	%fd244, %fd203, %fd204;
	add.rn.f64 	%fd772, %fd136, %fd136;
	add.rn.f64 	%fd773, %fd772, 0dC059000000000000;
	mul.rn.f64 	%fd774, %fd137, 0d4008000000000000;
	add.rn.f64 	%fd245, %fd773, %fd774;
	abs.f64 	%fd246, %fd137;
	{ // callseq 66, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd246;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd905, [retval0+0];
	} // callseq 66
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r165}, %fd137;
	}
	setp.lt.s32 	%p210, %r165, 0;
	and.pred  	%p4, %p210, %p75;
	not.pred 	%p212, %p4;
	@%p212 bra 	$L__BB6_232;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r557}, %fd905;
	}
	xor.b32  	%r558, %r557, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r559, %temp}, %fd905;
	}
	mov.b64 	%fd905, {%r559, %r558};

$L__BB6_232:
	add.rn.f32 	%f326, %f360, 0fC20C0000;
	setp.eq.f32 	%p213, %f326, 0f00000000;
	@%p213 bra 	$L__BB6_236;
	bra.uni 	$L__BB6_233;

$L__BB6_236:
	setp.lt.s32 	%p216, %r61, 0;
	mov.u32 	%r560, 0;
	selp.b32 	%r561, %r165, 0, %p75;
	or.b32  	%r562, %r561, 2146435072;
	selp.b32 	%r563, %r562, %r561, %p216;
	mov.b64 	%fd905, {%r560, %r563};
	bra.uni 	$L__BB6_237;

$L__BB6_233:
	setp.gt.s32 	%p214, %r165, -1;
	@%p214 bra 	$L__BB6_237;

	mov.f64 	%fd775, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd776, %fd775;
	setp.eq.f64 	%p215, %fd776, 0d4000000000000000;
	@%p215 bra 	$L__BB6_237;

	mov.f64 	%fd905, 0dFFF8000000000000;

$L__BB6_237:
	add.rn.f64 	%fd778, %fd137, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r564}, %fd778;
	}
	and.b32  	%r565, %r564, 2146435072;
	setp.ne.s32 	%p218, %r565, 2146435072;
	@%p218 bra 	$L__BB6_244;

	setp.gtu.f64 	%p219, %fd246, 0d7FF0000000000000;
	@%p219 bra 	$L__BB6_243;
	bra.uni 	$L__BB6_239;

$L__BB6_243:
	mov.f64 	%fd780, 0d4000000000000000;
	add.rn.f64 	%fd905, %fd137, %fd780;
	bra.uni 	$L__BB6_244;

$L__BB6_239:
	setp.eq.s32 	%p220, %r103, 2146435072;
	mov.f64 	%fd779, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r566, %temp}, %fd779;
	}
	setp.eq.s32 	%p221, %r566, 0;
	and.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB6_242;
	bra.uni 	$L__BB6_240;

$L__BB6_242:
	add.rn.f32 	%f332, %f360, 0fC20C0000;
	setp.lt.s32 	%p228, %r61, 0;
	mov.u32 	%r571, 0;
	setp.gt.f64 	%p229, %fd246, 0d3FF0000000000000;
	selp.b32 	%r572, 2146435072, 0, %p229;
	xor.b32  	%r573, %r572, 2146435072;
	selp.b32 	%r574, %r573, %r572, %p228;
	setp.eq.f32 	%p230, %f332, 0fBF800000;
	selp.b32 	%r575, 1072693248, %r574, %p230;
	mov.b64 	%fd905, {%r571, %r575};
	bra.uni 	$L__BB6_244;

$L__BB6_240:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r567, %temp}, %fd137;
	}
	and.b32  	%r568, %r165, 2147483647;
	setp.ne.s32 	%p223, %r568, 2146435072;
	setp.ne.s32 	%p224, %r567, 0;
	or.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB6_244;

	setp.ne.s32 	%p226, %r103, 1071644672;
	and.pred  	%p227, %p226, %p4;
	selp.b32 	%r569, %r105, %r104, %p227;
	mov.u32 	%r570, 0;
	mov.b64 	%fd905, {%r570, %r569};

$L__BB6_244:
	add.rn.f32 	%f328, %f359, 0fC2D20000;
	add.rn.f32 	%f327, %f360, 0fC20C0000;
	mul.rn.f64 	%fd781, %fd905, 0d3FC999999999999A;
	setp.eq.f32 	%p231, %f327, 0f3F800000;
	selp.f64 	%fd782, 0d3FC999999999999A, %fd781, %p231;
	add.rn.f64 	%fd783, %fd245, %fd782;
	mul.rn.f32 	%f254, %f328, %f327;
	cvt.f64.f32 	%fd784, %f254;
	mul.rn.f64 	%fd256, %fd784, 0d3FB999999999999A;
	add.rn.f64 	%fd785, %fd256, %fd783;
	abs.f32 	%f255, %f328;
	sqrt.rn.f32 	%f256, %f255;
	cvt.f64.f32 	%fd257, %f256;
	mul.rn.f64 	%fd786, %fd257, 0d3FC999999999999A;
	add.rn.f64 	%fd787, %fd786, %fd785;
	cvt.rn.f32.f64 	%f257, %fd244;
	cvt.f64.f32 	%fd788, %f257;
	mul.rn.f64 	%fd789, %fd788, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f258, %fd789;
	cvt.f64.f32 	%fd790, %f258;
	add.rn.f64 	%fd258, %fd787, %fd790;
	add.rn.f64 	%fd791, %fd137, %fd137;
	add.rn.f64 	%fd792, %fd136, 0d4072C00000000000;
	add.rn.f64 	%fd259, %fd792, %fd791;
	abs.f64 	%fd260, %fd136;
	{ // callseq 67, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd260;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd908, [retval0+0];
	} // callseq 67
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd136;
	}
	setp.lt.s32 	%p232, %r166, 0;
	and.pred  	%p5, %p232, %p75;
	not.pred 	%p234, %p5;
	@%p234 bra 	$L__BB6_246;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r576}, %fd908;
	}
	xor.b32  	%r577, %r576, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r578, %temp}, %fd908;
	}
	mov.b64 	%fd908, {%r578, %r577};

$L__BB6_246:
	add.rn.f32 	%f329, %f359, 0fC2D20000;
	setp.eq.f32 	%p235, %f329, 0f00000000;
	@%p235 bra 	$L__BB6_250;
	bra.uni 	$L__BB6_247;

$L__BB6_250:
	setp.lt.s32 	%p238, %r61, 0;
	mov.u32 	%r579, 0;
	selp.b32 	%r580, %r166, 0, %p75;
	or.b32  	%r581, %r580, 2146435072;
	selp.b32 	%r582, %r581, %r580, %p238;
	mov.b64 	%fd908, {%r579, %r582};
	bra.uni 	$L__BB6_251;

$L__BB6_247:
	setp.gt.s32 	%p236, %r166, -1;
	@%p236 bra 	$L__BB6_251;

	mov.f64 	%fd793, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd794, %fd793;
	setp.eq.f64 	%p237, %fd794, 0d4000000000000000;
	@%p237 bra 	$L__BB6_251;

	mov.f64 	%fd908, 0dFFF8000000000000;

$L__BB6_251:
	add.rn.f64 	%fd796, %fd136, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r583}, %fd796;
	}
	and.b32  	%r584, %r583, 2146435072;
	setp.ne.s32 	%p240, %r584, 2146435072;
	@%p240 bra 	$L__BB6_258;

	setp.gtu.f64 	%p241, %fd260, 0d7FF0000000000000;
	@%p241 bra 	$L__BB6_257;
	bra.uni 	$L__BB6_253;

$L__BB6_257:
	mov.f64 	%fd798, 0d4000000000000000;
	add.rn.f64 	%fd908, %fd136, %fd798;
	bra.uni 	$L__BB6_258;

$L__BB6_253:
	setp.eq.s32 	%p242, %r103, 2146435072;
	mov.f64 	%fd797, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r585, %temp}, %fd797;
	}
	setp.eq.s32 	%p243, %r585, 0;
	and.pred  	%p244, %p242, %p243;
	@%p244 bra 	$L__BB6_256;
	bra.uni 	$L__BB6_254;

$L__BB6_256:
	add.rn.f32 	%f331, %f359, 0fC2D20000;
	setp.lt.s32 	%p250, %r61, 0;
	mov.u32 	%r590, 0;
	setp.gt.f64 	%p251, %fd260, 0d3FF0000000000000;
	selp.b32 	%r591, 2146435072, 0, %p251;
	xor.b32  	%r592, %r591, 2146435072;
	selp.b32 	%r593, %r592, %r591, %p250;
	setp.eq.f32 	%p252, %f331, 0fBF800000;
	selp.b32 	%r594, 1072693248, %r593, %p252;
	mov.b64 	%fd908, {%r590, %r594};
	bra.uni 	$L__BB6_258;

$L__BB6_254:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r586, %temp}, %fd136;
	}
	and.b32  	%r587, %r166, 2147483647;
	setp.ne.s32 	%p245, %r587, 2146435072;
	setp.ne.s32 	%p246, %r586, 0;
	or.pred  	%p247, %p245, %p246;
	@%p247 bra 	$L__BB6_258;

	setp.ne.s32 	%p248, %r103, 1071644672;
	and.pred  	%p249, %p248, %p5;
	selp.b32 	%r588, %r105, %r104, %p249;
	mov.u32 	%r589, 0;
	mov.b64 	%fd908, {%r589, %r588};

$L__BB6_258:
	add.rn.f32 	%f330, %f359, 0fC2D20000;
	mul.rn.f64 	%fd799, %fd908, 0d3FB999999999999A;
	setp.eq.f32 	%p253, %f330, 0f3F800000;
	selp.f64 	%fd800, 0d3FB999999999999A, %fd799, %p253;
	add.rn.f64 	%fd801, %fd259, %fd800;
	add.rn.f64 	%fd802, %fd256, %fd801;
	mul.rn.f64 	%fd803, %fd257, 0d3FB999999999999A;
	add.rn.f64 	%fd804, %fd803, %fd802;
	cvt.rn.f32.f64 	%f259, %fd243;
	cvt.f64.f32 	%fd805, %f259;
	mul.rn.f64 	%fd806, %fd805, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f260, %fd806;
	cvt.f64.f32 	%fd807, %f260;
	add.rn.f64 	%fd270, %fd804, %fd807;
	cvt.f64.f32 	%fd271, %f360;
	div.rn.f64 	%fd808, %fd271, 0d4066800000000000;
	mul.rn.f64 	%fd809, %fd808, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f85, %fd809;
	mul.rn.f32 	%f261, %f85, 0f3F22F983;
	cvt.rni.s32.f32 	%r716, %f261;
	cvt.rn.f32.s32 	%f262, %r716;
	mov.f32 	%f263, 0fBFC90FDA;
	fma.rn.f32 	%f264, %f262, %f263, %f85;
	mov.f32 	%f265, 0fB3A22168;
	fma.rn.f32 	%f266, %f262, %f265, %f264;
	mov.f32 	%f267, 0fA7C234C5;
	fma.rn.f32 	%f356, %f262, %f267, %f266;
	abs.f32 	%f87, %f85;
	setp.ltu.f32 	%p254, %f87, 0f47CE4780;
	mov.u32 	%r713, %r716;
	mov.f32 	%f353, %f356;
	@%p254 bra 	$L__BB6_266;

	setp.eq.f32 	%p255, %f87, 0f7F800000;
	@%p255 bra 	$L__BB6_265;
	bra.uni 	$L__BB6_260;

$L__BB6_265:
	mov.f32 	%f270, 0f00000000;
	mul.rn.f32 	%f353, %f85, %f270;
	mov.u32 	%r713, 0;
	bra.uni 	$L__BB6_266;

$L__BB6_260:
	mov.b32 	%r168, %f85;
	bfe.u32 	%r595, %r168, 23, 8;
	add.s32 	%r169, %r595, -128;
	shl.b32 	%r596, %r168, 8;
	or.b32  	%r170, %r596, -2147483648;
	shr.u32 	%r171, %r169, 5;
	mov.u64 	%rd268, 0;
	mov.u64 	%rd269, %rd268;

$L__BB6_261:
	.pragma "nounroll";
	shl.b64 	%rd217, %rd268, 2;
	mov.u64 	%rd218, __cudart_i2opi_f;
	add.s64 	%rd219, %rd218, %rd217;
	ld.global.nc.u32 	%r597, [%rd219];
	mad.wide.u32 	%rd220, %r597, %r170, %rd269;
	shr.u64 	%rd269, %rd220, 32;
	add.s64 	%rd221, %rd1, %rd217;
	st.local.u32 	[%rd221], %rd220;
	cvt.u32.u64 	%r598, %rd268;
	add.s32 	%r599, %r598, 1;
	cvt.s64.s32 	%rd268, %r599;
	setp.ne.s32 	%p256, %r599, 6;
	@%p256 bra 	$L__BB6_261;

	st.local.u32 	[%rd1+24], %rd269;
	mov.u32 	%r600, 4;
	sub.s32 	%r172, %r600, %r171;
	mov.u32 	%r601, 6;
	sub.s32 	%r602, %r601, %r171;
	mul.wide.s32 	%rd222, %r602, 4;
	add.s64 	%rd223, %rd1, %rd222;
	ld.local.u32 	%r711, [%rd223];
	ld.local.u32 	%r712, [%rd223+-4];
	and.b32  	%r175, %r169, 31;
	setp.eq.s32 	%p257, %r175, 0;
	@%p257 bra 	$L__BB6_264;

	mov.u32 	%r603, 32;
	sub.s32 	%r604, %r603, %r175;
	shr.u32 	%r605, %r712, %r604;
	shl.b32 	%r606, %r711, %r175;
	add.s32 	%r711, %r605, %r606;
	mul.wide.s32 	%rd224, %r172, 4;
	add.s64 	%rd225, %rd1, %rd224;
	ld.local.u32 	%r607, [%rd225];
	shr.u32 	%r608, %r607, %r604;
	shl.b32 	%r609, %r712, %r175;
	add.s32 	%r712, %r608, %r609;

$L__BB6_264:
	and.b32  	%r610, %r168, -2147483648;
	shr.u32 	%r611, %r712, 30;
	shl.b32 	%r612, %r711, 2;
	or.b32  	%r613, %r611, %r612;
	shr.u32 	%r614, %r613, 31;
	shr.u32 	%r615, %r711, 30;
	add.s32 	%r616, %r614, %r615;
	neg.s32 	%r617, %r616;
	setp.eq.s32 	%p258, %r610, 0;
	selp.b32 	%r713, %r616, %r617, %p258;
	setp.ne.s32 	%p259, %r614, 0;
	xor.b32  	%r618, %r610, -2147483648;
	selp.b32 	%r619, %r618, %r610, %p259;
	selp.b32 	%r620, -1, 0, %p259;
	xor.b32  	%r621, %r613, %r620;
	shl.b32 	%r622, %r712, 2;
	xor.b32  	%r623, %r622, %r620;
	cvt.u64.u32 	%rd226, %r621;
	cvt.u64.u32 	%rd227, %r623;
	bfi.b64 	%rd228, %rd226, %rd227, 32, 32;
	cvt.rn.f64.s64 	%fd810, %rd228;
	mul.rn.f64 	%fd811, %fd810, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f268, %fd811;
	setp.eq.s32 	%p260, %r619, 0;
	neg.f32 	%f269, %f268;
	selp.f32 	%f353, %f268, %f269, %p260;

$L__BB6_266:
	and.b32  	%r182, %r713, 1;
	setp.eq.s32 	%p261, %r182, 0;
	selp.f32 	%f91, %f353, 0f3F800000, %p261;
	mul.rn.f32 	%f92, %f353, %f353;
	mov.f32 	%f354, 0fB94D4153;
	@%p261 bra 	$L__BB6_268;

	mov.f32 	%f272, 0fBAB607ED;
	mov.f32 	%f273, 0f37CBAC00;
	fma.rn.f32 	%f354, %f273, %f92, %f272;

$L__BB6_268:
	selp.f32 	%f274, 0f3C0885E4, 0f3D2AAABB, %p261;
	fma.rn.f32 	%f275, %f354, %f92, %f274;
	selp.f32 	%f276, 0fBE2AAAA8, 0fBEFFFFFF, %p261;
	fma.rn.f32 	%f277, %f275, %f92, %f276;
	mov.f32 	%f278, 0f00000000;
	fma.rn.f32 	%f279, %f92, %f91, %f278;
	fma.rn.f32 	%f355, %f277, %f279, %f91;
	and.b32  	%r625, %r713, 2;
	setp.eq.s32 	%p263, %r625, 0;
	@%p263 bra 	$L__BB6_270;

	mov.f32 	%f281, 0fBF800000;
	fma.rn.f32 	%f355, %f355, %f281, %f278;

$L__BB6_270:
	@%p254 bra 	$L__BB6_278;

	setp.eq.f32 	%p265, %f87, 0f7F800000;
	@%p265 bra 	$L__BB6_277;
	bra.uni 	$L__BB6_272;

$L__BB6_277:
	mov.f32 	%f284, 0f00000000;
	mul.rn.f32 	%f356, %f85, %f284;
	mov.u32 	%r716, 0;
	bra.uni 	$L__BB6_278;

$L__BB6_272:
	mov.b32 	%r183, %f85;
	bfe.u32 	%r626, %r183, 23, 8;
	add.s32 	%r184, %r626, -128;
	shl.b32 	%r627, %r183, 8;
	or.b32  	%r185, %r627, -2147483648;
	shr.u32 	%r186, %r184, 5;
	mov.u64 	%rd270, 0;
	mov.u64 	%rd271, %rd270;

$L__BB6_273:
	.pragma "nounroll";
	shl.b64 	%rd231, %rd270, 2;
	mov.u64 	%rd232, __cudart_i2opi_f;
	add.s64 	%rd233, %rd232, %rd231;
	ld.global.nc.u32 	%r628, [%rd233];
	mad.wide.u32 	%rd234, %r628, %r185, %rd271;
	shr.u64 	%rd271, %rd234, 32;
	add.s64 	%rd235, %rd1, %rd231;
	st.local.u32 	[%rd235], %rd234;
	cvt.u32.u64 	%r629, %rd270;
	add.s32 	%r630, %r629, 1;
	cvt.s64.s32 	%rd270, %r630;
	setp.ne.s32 	%p266, %r630, 6;
	@%p266 bra 	$L__BB6_273;

	st.local.u32 	[%rd1+24], %rd271;
	mov.u32 	%r631, 4;
	sub.s32 	%r187, %r631, %r186;
	mov.u32 	%r632, 6;
	sub.s32 	%r633, %r632, %r186;
	mul.wide.s32 	%rd236, %r633, 4;
	add.s64 	%rd237, %rd1, %rd236;
	ld.local.u32 	%r714, [%rd237];
	ld.local.u32 	%r715, [%rd237+-4];
	and.b32  	%r190, %r184, 31;
	setp.eq.s32 	%p267, %r190, 0;
	@%p267 bra 	$L__BB6_276;

	mov.u32 	%r634, 32;
	sub.s32 	%r635, %r634, %r190;
	shr.u32 	%r636, %r715, %r635;
	shl.b32 	%r637, %r714, %r190;
	add.s32 	%r714, %r636, %r637;
	mul.wide.s32 	%rd238, %r187, 4;
	add.s64 	%rd239, %rd1, %rd238;
	ld.local.u32 	%r638, [%rd239];
	shr.u32 	%r639, %r638, %r635;
	shl.b32 	%r640, %r715, %r190;
	add.s32 	%r715, %r639, %r640;

$L__BB6_276:
	and.b32  	%r641, %r183, -2147483648;
	shr.u32 	%r642, %r715, 30;
	shl.b32 	%r643, %r714, 2;
	or.b32  	%r644, %r642, %r643;
	shr.u32 	%r645, %r644, 31;
	shr.u32 	%r646, %r714, 30;
	add.s32 	%r647, %r645, %r646;
	neg.s32 	%r648, %r647;
	setp.eq.s32 	%p268, %r641, 0;
	selp.b32 	%r716, %r647, %r648, %p268;
	setp.ne.s32 	%p269, %r645, 0;
	xor.b32  	%r649, %r641, -2147483648;
	selp.b32 	%r650, %r649, %r641, %p269;
	selp.b32 	%r651, -1, 0, %p269;
	xor.b32  	%r652, %r644, %r651;
	shl.b32 	%r653, %r715, 2;
	xor.b32  	%r654, %r653, %r651;
	cvt.u64.u32 	%rd240, %r652;
	cvt.u64.u32 	%rd241, %r654;
	bfi.b64 	%rd242, %rd240, %rd241, 32, 32;
	cvt.rn.f64.s64 	%fd812, %rd242;
	mul.rn.f64 	%fd813, %fd812, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f282, %fd813;
	setp.eq.s32 	%p270, %r650, 0;
	neg.f32 	%f283, %f282;
	selp.f32 	%f356, %f282, %f283, %p270;

$L__BB6_278:
	add.s32 	%r197, %r716, 1;
	and.b32  	%r198, %r197, 1;
	setp.eq.s32 	%p6, %r198, 0;
	mul.rn.f32 	%f101, %f356, %f356;
	mov.f32 	%f357, 0fB94D4153;
	@%p6 bra 	$L__BB6_280;

	mov.f32 	%f286, 0fBAB607ED;
	mov.f32 	%f287, 0f37CBAC00;
	fma.rn.f32 	%f357, %f287, %f101, %f286;

$L__BB6_280:
	selp.f32 	%f288, %f356, 0f3F800000, %p6;
	selp.f32 	%f289, 0f3C0885E4, 0f3D2AAABB, %p6;
	fma.rn.f32 	%f290, %f357, %f101, %f289;
	selp.f32 	%f291, 0fBE2AAAA8, 0fBEFFFFFF, %p6;
	fma.rn.f32 	%f292, %f290, %f101, %f291;
	mov.f32 	%f293, 0f00000000;
	fma.rn.f32 	%f294, %f101, %f288, %f293;
	fma.rn.f32 	%f358, %f292, %f294, %f288;
	and.b32  	%r656, %r197, 2;
	setp.eq.s32 	%p272, %r656, 0;
	@%p272 bra 	$L__BB6_282;

	mov.f32 	%f296, 0fBF800000;
	fma.rn.f32 	%f358, %f358, %f296, %f293;

$L__BB6_282:
	ld.param.s8 	%rs2, [gcj02_to_wgs84_exact_cuda_float_param_3];
	cvt.f64.f32 	%fd814, %f355;
	mul.rn.f64 	%fd815, %fd814, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd816, %fd815, %fd814;
	add.rn.f64 	%fd817, %fd816, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f297, %fd817;
	sqrt.rn.f32 	%f298, %f297;
	mov.f32 	%f299, 0f4AC2A60A;
	div.rn.f32 	%f300, %f299, %f298;
	mul.rn.f32 	%f301, %f300, %f358;
	cvt.f64.f32 	%fd818, %f301;
	mul.rn.f64 	%fd819, %fd818, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f302, %fd270;
	cvt.f64.f32 	%fd820, %f302;
	mul.rn.f64 	%fd821, %fd820, 0d4066800000000000;
	div.rn.f64 	%fd822, %fd821, %fd819;
	cvt.rn.f32.f64 	%f303, %fd822;
	add.rn.f32 	%f304, %f359, %f303;
	sub.rn.f32 	%f107, %f1, %f304;
	mul.rn.f32 	%f305, %f298, %f297;
	cvt.f64.f32 	%fd823, %f305;
	mov.f64 	%fd824, 0d41582B102DE355C1;
	div.rn.f64 	%fd825, %fd824, %fd823;
	mul.rn.f64 	%fd826, %fd825, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f306, %fd258;
	cvt.f64.f32 	%fd827, %f306;
	mul.rn.f64 	%fd828, %fd827, 0d4066800000000000;
	div.rn.f64 	%fd829, %fd828, %fd826;
	cvt.rn.f32.f64 	%f307, %fd829;
	add.rn.f32 	%f308, %f360, %f307;
	sub.rn.f32 	%f108, %f3, %f308;
	add.rn.f32 	%f109, %f359, %f107;
	add.rn.f32 	%f110, %f360, %f108;
	setp.eq.s16 	%p273, %rs2, 0;
	@%p273 bra 	$L__BB6_290;
	bra.uni 	$L__BB6_283;

$L__BB6_290:
	ld.param.f32 	%f323, [gcj02_to_wgs84_exact_cuda_float_param_2];
	abs.f32 	%f314, %f107;
	abs.f32 	%f315, %f108;
	mul.rn.f32 	%f316, %f315, %f323;
	setp.lt.f32 	%p282, %f314, %f316;
	selp.f32 	%f317, 0f3F800000, 0f00000000, %p282;
	setp.lt.f32 	%p283, %f317, %f323;
	add.s32 	%r695, %r695, 1;
	@%p283 bra 	$L__BB6_292;

	ld.param.u32 	%r669, [gcj02_to_wgs84_exact_cuda_float_param_4];
	setp.lt.s32 	%p284, %r695, %r669;
	mov.f32 	%f360, %f110;
	mov.f32 	%f359, %f109;
	@%p284 bra 	$L__BB6_142;

$L__BB6_292:
	mov.u32 	%r668, %tid.x;
	mov.u32 	%r667, %ntid.x;
	mov.u32 	%r666, %ctaid.x;
	mad.lo.s32 	%r665, %r666, %r667, %r668;
	mul.wide.s32 	%rd251, %r665, 4;
	ld.param.u64 	%rd250, [gcj02_to_wgs84_exact_cuda_float_param_1];
	cvta.to.global.u64 	%rd249, %rd250;
	add.s64 	%rd248, %rd249, %rd251;
	ld.param.u64 	%rd247, [gcj02_to_wgs84_exact_cuda_float_param_0];
	cvta.to.global.u64 	%rd246, %rd247;
	add.s64 	%rd245, %rd246, %rd251;
	st.global.f32 	[%rd245], %f359;
	st.global.f32 	[%rd248], %f360;
	ret;

$L__BB6_283:
	mul.rn.f64 	%fd830, %fd271, 0d400921FB54442D18;
	div.rn.f64 	%fd831, %fd830, 0d4066800000000000;
	cvt.rn.f32.f64 	%f309, %fd831;
	cvt.f64.f32 	%fd832, %f359;
	mul.rn.f64 	%fd833, %fd832, 0d400921FB54442D18;
	div.rn.f64 	%fd834, %fd833, 0d4066800000000000;
	cvt.rn.f32.f64 	%f310, %fd834;
	cvt.f64.f32 	%fd835, %f110;
	mul.rn.f64 	%fd836, %fd835, 0d400921FB54442D18;
	div.rn.f64 	%fd837, %fd836, 0d4066800000000000;
	cvt.rn.f32.f64 	%f311, %fd837;
	cvt.f64.f32 	%fd838, %f109;
	mul.rn.f64 	%fd839, %fd838, 0d400921FB54442D18;
	div.rn.f64 	%fd840, %fd839, 0d4066800000000000;
	cvt.rn.f32.f64 	%f312, %fd840;
	sub.rn.f32 	%f313, %f311, %f309;
	sub.rn.f32 	%f111, %f312, %f310;
	cvt.f64.f32 	%fd841, %f313;
	mul.rn.f64 	%fd272, %fd841, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r657, %temp}, %fd272;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r658}, %fd272;
	}
	and.b32  	%r659, %r658, 2147483647;
	setp.eq.s32 	%p274, %r659, 2146435072;
	setp.eq.s32 	%p275, %r657, 0;
	and.pred  	%p276, %p275, %p274;
	@%p276 bra 	$L__BB6_286;

	mul.rn.f64 	%fd842, %fd272, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r660, %fd842;
	st.local.u32 	[%rd1], %r660;
	abs.f64 	%fd843, %fd272;
	setp.ltu.f64 	%p277, %fd843, 0d41E0000000000000;
	@%p277 bra 	$L__BB6_286;

	{ // callseq 68, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd844, [retval0+0];
	} // callseq 68

$L__BB6_286:
	cvt.f64.f32 	%fd845, %f111;
	mul.rn.f64 	%fd273, %fd845, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r661, %temp}, %fd273;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r662}, %fd273;
	}
	and.b32  	%r663, %r662, 2147483647;
	setp.eq.s32 	%p278, %r663, 2146435072;
	setp.eq.s32 	%p279, %r661, 0;
	and.pred  	%p280, %p279, %p278;
	@%p280 bra 	$L__BB6_289;

	mul.rn.f64 	%fd846, %fd273, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r664, %fd846;
	st.local.u32 	[%rd1], %r664;
	abs.f64 	%fd847, %fd273;
	setp.ltu.f64 	%p281, %fd847, 0d41E0000000000000;
	@%p281 bra 	$L__BB6_289;

	{ // callseq 69, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd273;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd63;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd848, [retval0+0];
	} // callseq 69

$L__BB6_289:

}
	// .globl	bd09_to_wgs84_exact_cuda_float
.visible .entry bd09_to_wgs84_exact_cuda_float(
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_0,
	.param .u64 bd09_to_wgs84_exact_cuda_float_param_1,
	.param .f32 bd09_to_wgs84_exact_cuda_float_param_2,
	.param .u8 bd09_to_wgs84_exact_cuda_float_param_3,
	.param .u32 bd09_to_wgs84_exact_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot7[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<479>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<713>;
	.reg .b32 	%r<1245>;
	.reg .f64 	%fd<1035>;
	.reg .b64 	%rd<428>;


	mov.u64 	%SPL, __local_depot7;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd101, [bd09_to_wgs84_exact_cuda_float_param_0];
	ld.param.u64 	%rd102, [bd09_to_wgs84_exact_cuda_float_param_1];
	add.u64 	%rd103, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	add.u64 	%rd8, %SPL, 0;
	mov.u32 	%r345, %ntid.x;
	mov.u32 	%r346, %ctaid.x;
	mov.u32 	%r347, %tid.x;
	mad.lo.s32 	%r348, %r346, %r345, %r347;
	cvta.to.global.u64 	%rd120, %rd101;
	mul.wide.s32 	%rd121, %r348, 4;
	add.s64 	%rd18, %rd120, %rd121;
	cvta.to.global.u64 	%rd122, %rd102;
	add.s64 	%rd19, %rd122, %rd121;
	ld.global.f32 	%f1, [%rd18];
	cvt.f64.f32 	%fd321, %f1;
	add.rn.f64 	%fd322, %fd321, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f2, %fd322;
	ld.global.f32 	%f3, [%rd19];
	cvt.f64.f32 	%fd323, %f3;
	add.rn.f64 	%fd324, %fd323, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f4, %fd324;
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd325, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd325;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p11, %r3, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 70, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd965, [retval0+0];
	} // callseq 70
	setp.lt.s32 	%p12, %r1, 0;
	and.pred  	%p1, %p12, %p11;
	not.pred 	%p13, %p1;
	@%p13 bra 	$L__BB7_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r349}, %fd965;
	}
	xor.b32  	%r350, %r349, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r351, %temp}, %fd965;
	}
	mov.b64 	%fd965, {%r351, %r350};

$L__BB7_2:
	setp.eq.f32 	%p14, %f2, 0f00000000;
	@%p14 bra 	$L__BB7_6;
	bra.uni 	$L__BB7_3;

$L__BB7_6:
	selp.b32 	%r352, %r1, 0, %p11;
	mov.u32 	%r353, 0;
	or.b32  	%r354, %r352, 2146435072;
	setp.lt.s32 	%p18, %r2, 0;
	selp.b32 	%r355, %r354, %r352, %p18;
	mov.b64 	%fd965, {%r353, %r355};
	bra.uni 	$L__BB7_7;

$L__BB7_3:
	setp.gt.s32 	%p15, %r1, -1;
	@%p15 bra 	$L__BB7_7;

	mov.f64 	%fd326, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd327, %fd326;
	setp.eq.f64 	%p16, %fd327, 0d4000000000000000;
	@%p16 bra 	$L__BB7_7;

	mov.f64 	%fd965, 0dFFF8000000000000;

$L__BB7_7:
	add.rn.f64 	%fd329, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r356}, %fd329;
	}
	and.b32  	%r357, %r356, 2146435072;
	setp.ne.s32 	%p19, %r357, 2146435072;
	@%p19 bra 	$L__BB7_14;

	setp.gtu.f64 	%p20, %fd2, 0d7FF0000000000000;
	@%p20 bra 	$L__BB7_13;
	bra.uni 	$L__BB7_9;

$L__BB7_13:
	mov.f64 	%fd331, 0d4000000000000000;
	add.rn.f64 	%fd965, %fd1, %fd331;
	bra.uni 	$L__BB7_14;

$L__BB7_9:
	mov.f64 	%fd330, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r358, %temp}, %fd330;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p21, %r4, 2146435072;
	setp.eq.s32 	%p22, %r358, 0;
	and.pred  	%p23, %p21, %p22;
	@%p23 bra 	$L__BB7_12;
	bra.uni 	$L__BB7_10;

$L__BB7_12:
	setp.gt.f64 	%p30, %fd2, 0d3FF0000000000000;
	selp.b32 	%r365, 2146435072, 0, %p30;
	mov.u32 	%r366, 0;
	xor.b32  	%r367, %r365, 2146435072;
	setp.lt.s32 	%p31, %r2, 0;
	selp.b32 	%r368, %r367, %r365, %p31;
	setp.eq.f32 	%p32, %f2, 0fBF800000;
	selp.b32 	%r369, 1072693248, %r368, %p32;
	mov.b64 	%fd965, {%r366, %r369};
	bra.uni 	$L__BB7_14;

$L__BB7_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd1;
	}
	and.b32  	%r360, %r1, 2147483647;
	setp.ne.s32 	%p24, %r360, 2146435072;
	setp.ne.s32 	%p25, %r359, 0;
	or.pred  	%p26, %p24, %p25;
	@%p26 bra 	$L__BB7_14;

	setp.gt.s32 	%p27, %r2, -1;
	selp.b32 	%r361, 2146435072, 0, %p27;
	mov.u32 	%r362, 0;
	setp.ne.s32 	%p28, %r4, 1071644672;
	and.pred  	%p29, %p28, %p1;
	or.b32  	%r363, %r361, -2147483648;
	selp.b32 	%r364, %r363, %r361, %p29;
	mov.b64 	%fd965, {%r362, %r364};

$L__BB7_14:
	cvt.f64.f32 	%fd12, %f4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 71, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd968, [retval0+0];
	} // callseq 71
	setp.lt.s32 	%p33, %r5, 0;
	and.pred  	%p2, %p33, %p11;
	not.pred 	%p35, %p2;
	@%p35 bra 	$L__BB7_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r370}, %fd968;
	}
	xor.b32  	%r371, %r370, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r372, %temp}, %fd968;
	}
	mov.b64 	%fd968, {%r372, %r371};

$L__BB7_16:
	setp.eq.f32 	%p36, %f4, 0f00000000;
	@%p36 bra 	$L__BB7_20;
	bra.uni 	$L__BB7_17;

$L__BB7_20:
	selp.b32 	%r373, %r5, 0, %p11;
	mov.u32 	%r374, 0;
	or.b32  	%r375, %r373, 2146435072;
	setp.lt.s32 	%p40, %r2, 0;
	selp.b32 	%r376, %r375, %r373, %p40;
	mov.b64 	%fd968, {%r374, %r376};
	bra.uni 	$L__BB7_21;

$L__BB7_17:
	setp.gt.s32 	%p37, %r5, -1;
	@%p37 bra 	$L__BB7_21;

	mov.f64 	%fd332, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd333, %fd332;
	setp.eq.f64 	%p38, %fd333, 0d4000000000000000;
	@%p38 bra 	$L__BB7_21;

	mov.f64 	%fd968, 0dFFF8000000000000;

$L__BB7_21:
	add.rn.f64 	%fd335, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r377}, %fd335;
	}
	and.b32  	%r378, %r377, 2146435072;
	setp.ne.s32 	%p41, %r378, 2146435072;
	@%p41 bra 	$L__BB7_28;

	setp.gtu.f64 	%p42, %fd13, 0d7FF0000000000000;
	@%p42 bra 	$L__BB7_27;
	bra.uni 	$L__BB7_23;

$L__BB7_27:
	mov.f64 	%fd337, 0d4000000000000000;
	add.rn.f64 	%fd968, %fd12, %fd337;
	bra.uni 	$L__BB7_28;

$L__BB7_23:
	mov.f64 	%fd336, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r379, %temp}, %fd336;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p43, %r6, 2146435072;
	setp.eq.s32 	%p44, %r379, 0;
	and.pred  	%p45, %p43, %p44;
	@%p45 bra 	$L__BB7_26;
	bra.uni 	$L__BB7_24;

$L__BB7_26:
	setp.gt.f64 	%p52, %fd13, 0d3FF0000000000000;
	selp.b32 	%r386, 2146435072, 0, %p52;
	mov.u32 	%r387, 0;
	xor.b32  	%r388, %r386, 2146435072;
	setp.lt.s32 	%p53, %r2, 0;
	selp.b32 	%r389, %r388, %r386, %p53;
	setp.eq.f32 	%p54, %f4, 0fBF800000;
	selp.b32 	%r390, 1072693248, %r389, %p54;
	mov.b64 	%fd968, {%r387, %r390};
	bra.uni 	$L__BB7_28;

$L__BB7_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r380, %temp}, %fd12;
	}
	and.b32  	%r381, %r5, 2147483647;
	setp.ne.s32 	%p46, %r381, 2146435072;
	setp.ne.s32 	%p47, %r380, 0;
	or.pred  	%p48, %p46, %p47;
	@%p48 bra 	$L__BB7_28;

	setp.gt.s32 	%p49, %r2, -1;
	selp.b32 	%r382, 2146435072, 0, %p49;
	mov.u32 	%r383, 0;
	setp.ne.s32 	%p50, %r6, 1071644672;
	and.pred  	%p51, %p50, %p2;
	or.b32  	%r384, %r382, -2147483648;
	selp.b32 	%r385, %r384, %r382, %p51;
	mov.b64 	%fd968, {%r383, %r385};

$L__BB7_28:
	setp.eq.f32 	%p55, %f4, 0f3F800000;
	selp.f64 	%fd338, 0d3FF0000000000000, %fd968, %p55;
	setp.eq.f32 	%p56, %f2, 0f3F800000;
	selp.f64 	%fd339, 0d3FF0000000000000, %fd965, %p56;
	add.rn.f64 	%fd23, %fd339, %fd338;
	mul.rn.f32 	%f5, %f4, 0f42517084;
	mul.rn.f32 	%f233, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r1174, %f233;
	cvt.rn.f32.s32 	%f234, %r1174;
	mov.f32 	%f235, 0fBFC90FDA;
	fma.rn.f32 	%f236, %f234, %f235, %f5;
	mov.f32 	%f237, 0fB3A22168;
	fma.rn.f32 	%f238, %f234, %f237, %f236;
	mov.f32 	%f239, 0fA7C234C5;
	fma.rn.f32 	%f659, %f234, %f239, %f238;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p57, %f7, 0f47CE4780;
	@%p57 bra 	$L__BB7_36;

	setp.eq.f32 	%p58, %f7, 0f7F800000;
	@%p58 bra 	$L__BB7_35;
	bra.uni 	$L__BB7_30;

$L__BB7_35:
	mov.f32 	%f242, 0f00000000;
	mul.rn.f32 	%f659, %f5, %f242;
	mov.u32 	%r1174, 0;
	bra.uni 	$L__BB7_36;

$L__BB7_30:
	mov.b32 	%r8, %f5;
	bfe.u32 	%r392, %r8, 23, 8;
	add.s32 	%r9, %r392, -128;
	shl.b32 	%r393, %r8, 8;
	or.b32  	%r10, %r393, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd390, 0;
	mov.u32 	%r1171, 0;
	mov.u64 	%rd389, __cudart_i2opi_f;
	mov.u64 	%rd388, %rd1;

$L__BB7_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r394, [%rd389];
	mad.wide.u32 	%rd125, %r394, %r10, %rd390;
	shr.u64 	%rd390, %rd125, 32;
	st.local.u32 	[%rd388], %rd125;
	add.s64 	%rd389, %rd389, 4;
	add.s64 	%rd388, %rd388, 4;
	add.s32 	%r1171, %r1171, 1;
	setp.ne.s32 	%p59, %r1171, 6;
	@%p59 bra 	$L__BB7_31;

	st.local.u32 	[%rd1+24], %rd390;
	mov.u32 	%r395, 4;
	sub.s32 	%r14, %r395, %r11;
	mov.u32 	%r396, 6;
	sub.s32 	%r397, %r396, %r11;
	mul.wide.s32 	%rd126, %r397, 4;
	add.s64 	%rd127, %rd1, %rd126;
	ld.local.u32 	%r1172, [%rd127];
	ld.local.u32 	%r1173, [%rd127+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p60, %r17, 0;
	@%p60 bra 	$L__BB7_34;

	mov.u32 	%r398, 32;
	sub.s32 	%r399, %r398, %r17;
	shr.u32 	%r400, %r1173, %r399;
	shl.b32 	%r401, %r1172, %r17;
	add.s32 	%r1172, %r400, %r401;
	mul.wide.s32 	%rd128, %r14, 4;
	add.s64 	%rd129, %rd1, %rd128;
	ld.local.u32 	%r402, [%rd129];
	shr.u32 	%r403, %r402, %r399;
	shl.b32 	%r404, %r1173, %r17;
	add.s32 	%r1173, %r403, %r404;

$L__BB7_34:
	and.b32  	%r405, %r8, -2147483648;
	shr.u32 	%r406, %r1173, 30;
	shl.b32 	%r407, %r1172, 2;
	or.b32  	%r408, %r406, %r407;
	shr.u32 	%r409, %r408, 31;
	shr.u32 	%r410, %r1172, 30;
	add.s32 	%r411, %r409, %r410;
	neg.s32 	%r412, %r411;
	setp.eq.s32 	%p61, %r405, 0;
	selp.b32 	%r1174, %r411, %r412, %p61;
	setp.ne.s32 	%p62, %r409, 0;
	xor.b32  	%r413, %r405, -2147483648;
	selp.b32 	%r414, %r413, %r405, %p62;
	selp.b32 	%r415, -1, 0, %p62;
	xor.b32  	%r416, %r408, %r415;
	shl.b32 	%r417, %r1173, 2;
	xor.b32  	%r418, %r417, %r415;
	cvt.u64.u32 	%rd130, %r416;
	cvt.u64.u32 	%rd131, %r418;
	bfi.b64 	%rd132, %rd130, %rd131, 32, 32;
	cvt.rn.f64.s64 	%fd340, %rd132;
	mul.rn.f64 	%fd341, %fd340, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f240, %fd341;
	setp.eq.s32 	%p63, %r414, 0;
	neg.f32 	%f241, %f240;
	selp.f32 	%f659, %f240, %f241, %p63;

$L__BB7_36:
	and.b32  	%r24, %r1174, 1;
	setp.eq.s32 	%p64, %r24, 0;
	selp.f32 	%f11, %f659, 0f3F800000, %p64;
	mul.rn.f32 	%f12, %f659, %f659;
	mov.f32 	%f660, 0fB94D4153;
	@%p64 bra 	$L__BB7_38;

	mov.f32 	%f244, 0fBAB607ED;
	mov.f32 	%f245, 0f37CBAC00;
	fma.rn.f32 	%f660, %f245, %f12, %f244;

$L__BB7_38:
	selp.f32 	%f246, 0f3C0885E4, 0f3D2AAABB, %p64;
	fma.rn.f32 	%f247, %f660, %f12, %f246;
	selp.f32 	%f248, 0fBE2AAAA8, 0fBEFFFFFF, %p64;
	fma.rn.f32 	%f249, %f247, %f12, %f248;
	mov.f32 	%f250, 0f00000000;
	fma.rn.f32 	%f251, %f12, %f11, %f250;
	fma.rn.f32 	%f661, %f249, %f251, %f11;
	and.b32  	%r420, %r1174, 2;
	setp.eq.s32 	%p66, %r420, 0;
	@%p66 bra 	$L__BB7_40;

	mov.f32 	%f253, 0fBF800000;
	fma.rn.f32 	%f661, %f661, %f253, %f250;

$L__BB7_40:
	cvt.f64.f32 	%fd342, %f661;
	mul.rn.f64 	%fd343, %fd342, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd344, %fd23;
	add.rn.f64 	%fd345, %fd344, %fd343;
	cvt.rn.f32.f64 	%f18, %fd345;
	abs.f32 	%f19, %f2;
	setp.eq.f32 	%p67, %f19, 0f00000000;
	abs.f32 	%f20, %f4;
	setp.eq.f32 	%p68, %f20, 0f00000000;
	and.pred  	%p69, %p67, %p68;
	@%p69 bra 	$L__BB7_44;
	bra.uni 	$L__BB7_41;

$L__BB7_44:
	mov.b32 	%r431, %f2;
	shr.s32 	%r432, %r431, 31;
	and.b32  	%r433, %r432, 1078530011;
	mov.b32 	%r434, %f4;
	and.b32  	%r435, %r434, -2147483648;
	or.b32  	%r436, %r433, %r435;
	mov.b32 	%f662, %r436;
	bra.uni 	$L__BB7_45;

$L__BB7_41:
	setp.eq.f32 	%p70, %f19, 0f7F800000;
	setp.eq.f32 	%p71, %f20, 0f7F800000;
	and.pred  	%p72, %p70, %p71;
	@%p72 bra 	$L__BB7_43;
	bra.uni 	$L__BB7_42;

$L__BB7_43:
	mov.b32 	%r426, %f2;
	setp.lt.s32 	%p76, %r426, 0;
	selp.b32 	%r427, 1075235812, 1061752795, %p76;
	mov.b32 	%r428, %f4;
	and.b32  	%r429, %r428, -2147483648;
	or.b32  	%r430, %r427, %r429;
	mov.b32 	%f662, %r430;
	bra.uni 	$L__BB7_45;

$L__BB7_42:
	max.f32 	%f254, %f20, %f19;
	min.f32 	%f255, %f20, %f19;
	div.rn.f32 	%f256, %f255, %f254;
	mul.rn.f32 	%f257, %f256, %f256;
	mov.f32 	%f258, 0fC0B59883;
	mov.f32 	%f259, 0fBF52C7EA;
	fma.rn.f32 	%f260, %f257, %f259, %f258;
	mov.f32 	%f261, 0fC0D21907;
	fma.rn.f32 	%f262, %f260, %f257, %f261;
	mul.rn.f32 	%f263, %f257, %f262;
	mul.rn.f32 	%f264, %f256, %f263;
	add.rn.f32 	%f265, %f257, 0f41355DC0;
	mov.f32 	%f266, 0f41E6BD60;
	fma.rn.f32 	%f267, %f265, %f257, %f266;
	mov.f32 	%f268, 0f419D92C8;
	fma.rn.f32 	%f269, %f267, %f257, %f268;
	rcp.rn.f32 	%f270, %f269;
	fma.rn.f32 	%f271, %f264, %f270, %f256;
	mov.f32 	%f272, 0f3FC90FDB;
	sub.rn.f32 	%f273, %f272, %f271;
	setp.gt.f32 	%p73, %f20, %f19;
	selp.f32 	%f274, %f273, %f271, %p73;
	mov.b32 	%r421, %f2;
	setp.lt.s32 	%p74, %r421, 0;
	mov.f32 	%f275, 0f40490FDB;
	sub.rn.f32 	%f276, %f275, %f274;
	selp.f32 	%f277, %f276, %f274, %p74;
	mov.b32 	%r422, %f277;
	mov.b32 	%r423, %f4;
	and.b32  	%r424, %r423, -2147483648;
	or.b32  	%r425, %r424, %r422;
	mov.b32 	%f278, %r425;
	add.rn.f32 	%f279, %f19, %f20;
	setp.le.f32 	%p75, %f279, 0f7F800000;
	selp.f32 	%f662, %f278, %f279, %p75;

$L__BB7_45:
	mul.rn.f32 	%f25, %f2, 0f42517084;
	mul.rn.f32 	%f280, %f25, 0f3F22F983;
	cvt.rni.s32.f32 	%r1178, %f280;
	cvt.rn.f32.s32 	%f281, %r1178;
	mov.f32 	%f282, 0fBFC90FDA;
	fma.rn.f32 	%f283, %f281, %f282, %f25;
	mov.f32 	%f284, 0fB3A22168;
	fma.rn.f32 	%f285, %f281, %f284, %f283;
	mov.f32 	%f286, 0fA7C234C5;
	fma.rn.f32 	%f663, %f281, %f286, %f285;
	abs.f32 	%f27, %f25;
	setp.ltu.f32 	%p77, %f27, 0f47CE4780;
	@%p77 bra 	$L__BB7_53;

	setp.eq.f32 	%p78, %f27, 0f7F800000;
	@%p78 bra 	$L__BB7_52;
	bra.uni 	$L__BB7_47;

$L__BB7_52:
	mov.f32 	%f289, 0f00000000;
	mul.rn.f32 	%f663, %f25, %f289;
	mov.u32 	%r1178, 0;
	bra.uni 	$L__BB7_53;

$L__BB7_47:
	mov.b32 	%r26, %f25;
	bfe.u32 	%r438, %r26, 23, 8;
	add.s32 	%r27, %r438, -128;
	shl.b32 	%r439, %r26, 8;
	or.b32  	%r28, %r439, -2147483648;
	shr.u32 	%r29, %r27, 5;
	mov.u64 	%rd393, 0;
	mov.u32 	%r1175, 0;
	mov.u64 	%rd392, __cudart_i2opi_f;
	mov.u64 	%rd391, %rd1;

$L__BB7_48:
	.pragma "nounroll";
	ld.global.nc.u32 	%r440, [%rd392];
	mad.wide.u32 	%rd135, %r440, %r28, %rd393;
	shr.u64 	%rd393, %rd135, 32;
	st.local.u32 	[%rd391], %rd135;
	add.s64 	%rd392, %rd392, 4;
	add.s64 	%rd391, %rd391, 4;
	add.s32 	%r1175, %r1175, 1;
	setp.ne.s32 	%p79, %r1175, 6;
	@%p79 bra 	$L__BB7_48;

	st.local.u32 	[%rd1+24], %rd393;
	mov.u32 	%r441, 4;
	sub.s32 	%r32, %r441, %r29;
	mov.u32 	%r442, 6;
	sub.s32 	%r443, %r442, %r29;
	mul.wide.s32 	%rd136, %r443, 4;
	add.s64 	%rd137, %rd1, %rd136;
	ld.local.u32 	%r1176, [%rd137];
	ld.local.u32 	%r1177, [%rd137+-4];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p80, %r35, 0;
	@%p80 bra 	$L__BB7_51;

	mov.u32 	%r444, 32;
	sub.s32 	%r445, %r444, %r35;
	shr.u32 	%r446, %r1177, %r445;
	shl.b32 	%r447, %r1176, %r35;
	add.s32 	%r1176, %r446, %r447;
	mul.wide.s32 	%rd138, %r32, 4;
	add.s64 	%rd139, %rd1, %rd138;
	ld.local.u32 	%r448, [%rd139];
	shr.u32 	%r449, %r448, %r445;
	shl.b32 	%r450, %r1177, %r35;
	add.s32 	%r1177, %r449, %r450;

$L__BB7_51:
	and.b32  	%r451, %r26, -2147483648;
	shr.u32 	%r452, %r1177, 30;
	shl.b32 	%r453, %r1176, 2;
	or.b32  	%r454, %r452, %r453;
	shr.u32 	%r455, %r454, 31;
	shr.u32 	%r456, %r1176, 30;
	add.s32 	%r457, %r455, %r456;
	neg.s32 	%r458, %r457;
	setp.eq.s32 	%p81, %r451, 0;
	selp.b32 	%r1178, %r457, %r458, %p81;
	setp.ne.s32 	%p82, %r455, 0;
	xor.b32  	%r459, %r451, -2147483648;
	selp.b32 	%r460, %r459, %r451, %p82;
	selp.b32 	%r461, -1, 0, %p82;
	xor.b32  	%r462, %r454, %r461;
	shl.b32 	%r463, %r1177, 2;
	xor.b32  	%r464, %r463, %r461;
	cvt.u64.u32 	%rd140, %r462;
	cvt.u64.u32 	%rd141, %r464;
	bfi.b64 	%rd142, %rd140, %rd141, 32, 32;
	cvt.rn.f64.s64 	%fd346, %rd142;
	mul.rn.f64 	%fd347, %fd346, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f287, %fd347;
	setp.eq.s32 	%p83, %r460, 0;
	neg.f32 	%f288, %f287;
	selp.f32 	%f663, %f287, %f288, %p83;

$L__BB7_53:
	add.s32 	%r42, %r1178, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32 	%p84, %r43, 0;
	selp.f32 	%f31, %f663, 0f3F800000, %p84;
	mul.rn.f32 	%f32, %f663, %f663;
	mov.f32 	%f664, 0fB94D4153;
	@%p84 bra 	$L__BB7_55;

	mov.f32 	%f291, 0fBAB607ED;
	mov.f32 	%f292, 0f37CBAC00;
	fma.rn.f32 	%f664, %f292, %f32, %f291;

$L__BB7_55:
	selp.f32 	%f293, 0f3C0885E4, 0f3D2AAABB, %p84;
	fma.rn.f32 	%f294, %f664, %f32, %f293;
	selp.f32 	%f295, 0fBE2AAAA8, 0fBEFFFFFF, %p84;
	fma.rn.f32 	%f296, %f294, %f32, %f295;
	mov.f32 	%f297, 0f00000000;
	fma.rn.f32 	%f298, %f32, %f31, %f297;
	fma.rn.f32 	%f665, %f296, %f298, %f31;
	and.b32  	%r466, %r42, 2;
	setp.eq.s32 	%p86, %r466, 0;
	@%p86 bra 	$L__BB7_57;

	mov.f32 	%f300, 0fBF800000;
	fma.rn.f32 	%f665, %f665, %f300, %f297;

$L__BB7_57:
	cvt.f64.f32 	%fd348, %f665;
	mul.rn.f64 	%fd349, %fd348, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd350, %f662;
	add.rn.f64 	%fd351, %fd350, %fd349;
	cvt.rn.f32.f64 	%f38, %fd351;
	mul.rn.f32 	%f301, %f38, 0f3F22F983;
	cvt.rni.s32.f32 	%r1186, %f301;
	cvt.rn.f32.s32 	%f302, %r1186;
	mov.f32 	%f303, 0fBFC90FDA;
	fma.rn.f32 	%f304, %f302, %f303, %f38;
	mov.f32 	%f305, 0fB3A22168;
	fma.rn.f32 	%f306, %f302, %f305, %f304;
	mov.f32 	%f307, 0fA7C234C5;
	fma.rn.f32 	%f669, %f302, %f307, %f306;
	abs.f32 	%f40, %f38;
	setp.ltu.f32 	%p87, %f40, 0f47CE4780;
	mov.u32 	%r1182, %r1186;
	mov.f32 	%f666, %f669;
	@%p87 bra 	$L__BB7_65;

	setp.eq.f32 	%p88, %f40, 0f7F800000;
	@%p88 bra 	$L__BB7_64;
	bra.uni 	$L__BB7_59;

$L__BB7_64:
	mov.f32 	%f310, 0f00000000;
	mul.rn.f32 	%f666, %f38, %f310;
	mov.u32 	%r1182, 0;
	bra.uni 	$L__BB7_65;

$L__BB7_59:
	mov.b32 	%r45, %f38;
	bfe.u32 	%r468, %r45, 23, 8;
	add.s32 	%r46, %r468, -128;
	shl.b32 	%r469, %r45, 8;
	or.b32  	%r47, %r469, -2147483648;
	shr.u32 	%r48, %r46, 5;
	mov.u64 	%rd396, 0;
	mov.u32 	%r1179, 0;
	mov.u64 	%rd395, __cudart_i2opi_f;
	mov.u64 	%rd394, %rd1;

$L__BB7_60:
	.pragma "nounroll";
	ld.global.nc.u32 	%r470, [%rd395];
	mad.wide.u32 	%rd145, %r470, %r47, %rd396;
	shr.u64 	%rd396, %rd145, 32;
	st.local.u32 	[%rd394], %rd145;
	add.s64 	%rd395, %rd395, 4;
	add.s64 	%rd394, %rd394, 4;
	add.s32 	%r1179, %r1179, 1;
	setp.ne.s32 	%p89, %r1179, 6;
	@%p89 bra 	$L__BB7_60;

	st.local.u32 	[%rd1+24], %rd396;
	mov.u32 	%r471, 4;
	sub.s32 	%r51, %r471, %r48;
	mov.u32 	%r472, 6;
	sub.s32 	%r473, %r472, %r48;
	mul.wide.s32 	%rd146, %r473, 4;
	add.s64 	%rd147, %rd1, %rd146;
	ld.local.u32 	%r1180, [%rd147];
	ld.local.u32 	%r1181, [%rd147+-4];
	and.b32  	%r54, %r46, 31;
	setp.eq.s32 	%p90, %r54, 0;
	@%p90 bra 	$L__BB7_63;

	mov.u32 	%r474, 32;
	sub.s32 	%r475, %r474, %r54;
	shr.u32 	%r476, %r1181, %r475;
	shl.b32 	%r477, %r1180, %r54;
	add.s32 	%r1180, %r476, %r477;
	mul.wide.s32 	%rd148, %r51, 4;
	add.s64 	%rd149, %rd1, %rd148;
	ld.local.u32 	%r478, [%rd149];
	shr.u32 	%r479, %r478, %r475;
	shl.b32 	%r480, %r1181, %r54;
	add.s32 	%r1181, %r479, %r480;

$L__BB7_63:
	and.b32  	%r481, %r45, -2147483648;
	shr.u32 	%r482, %r1181, 30;
	shl.b32 	%r483, %r1180, 2;
	or.b32  	%r484, %r482, %r483;
	shr.u32 	%r485, %r484, 31;
	shr.u32 	%r486, %r1180, 30;
	add.s32 	%r487, %r485, %r486;
	neg.s32 	%r488, %r487;
	setp.eq.s32 	%p91, %r481, 0;
	selp.b32 	%r1182, %r487, %r488, %p91;
	setp.ne.s32 	%p92, %r485, 0;
	xor.b32  	%r489, %r481, -2147483648;
	selp.b32 	%r490, %r489, %r481, %p92;
	selp.b32 	%r491, -1, 0, %p92;
	xor.b32  	%r492, %r484, %r491;
	shl.b32 	%r493, %r1181, 2;
	xor.b32  	%r494, %r493, %r491;
	cvt.u64.u32 	%rd150, %r492;
	cvt.u64.u32 	%rd151, %r494;
	bfi.b64 	%rd152, %rd150, %rd151, 32, 32;
	cvt.rn.f64.s64 	%fd352, %rd152;
	mul.rn.f64 	%fd353, %fd352, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f308, %fd353;
	setp.eq.s32 	%p93, %r490, 0;
	neg.f32 	%f309, %f308;
	selp.f32 	%f666, %f308, %f309, %p93;

$L__BB7_65:
	add.s32 	%r61, %r1182, 1;
	and.b32  	%r62, %r61, 1;
	setp.eq.s32 	%p94, %r62, 0;
	selp.f32 	%f44, %f666, 0f3F800000, %p94;
	mul.rn.f32 	%f45, %f666, %f666;
	mov.f32 	%f667, 0fB94D4153;
	@%p94 bra 	$L__BB7_67;

	mov.f32 	%f312, 0fBAB607ED;
	mov.f32 	%f313, 0f37CBAC00;
	fma.rn.f32 	%f667, %f313, %f45, %f312;

$L__BB7_67:
	selp.f32 	%f314, 0f3C0885E4, 0f3D2AAABB, %p94;
	fma.rn.f32 	%f315, %f667, %f45, %f314;
	selp.f32 	%f316, 0fBE2AAAA8, 0fBEFFFFFF, %p94;
	fma.rn.f32 	%f317, %f315, %f45, %f316;
	mov.f32 	%f318, 0f00000000;
	fma.rn.f32 	%f319, %f45, %f44, %f318;
	fma.rn.f32 	%f668, %f317, %f319, %f44;
	and.b32  	%r496, %r61, 2;
	setp.eq.s32 	%p96, %r496, 0;
	@%p96 bra 	$L__BB7_69;

	mov.f32 	%f321, 0fBF800000;
	fma.rn.f32 	%f668, %f668, %f321, %f318;

$L__BB7_69:
	mul.rn.f32 	%f51, %f668, %f18;
	@%p87 bra 	$L__BB7_77;

	setp.eq.f32 	%p98, %f40, 0f7F800000;
	@%p98 bra 	$L__BB7_76;
	bra.uni 	$L__BB7_71;

$L__BB7_76:
	mov.f32 	%f324, 0f00000000;
	mul.rn.f32 	%f669, %f38, %f324;
	mov.u32 	%r1186, 0;
	bra.uni 	$L__BB7_77;

$L__BB7_71:
	mov.b32 	%r63, %f38;
	bfe.u32 	%r498, %r63, 23, 8;
	add.s32 	%r64, %r498, -128;
	shl.b32 	%r499, %r63, 8;
	or.b32  	%r65, %r499, -2147483648;
	shr.u32 	%r66, %r64, 5;
	mov.u64 	%rd399, 0;
	mov.u32 	%r1183, 0;
	mov.u64 	%rd398, __cudart_i2opi_f;
	mov.u64 	%rd397, %rd1;

$L__BB7_72:
	.pragma "nounroll";
	ld.global.nc.u32 	%r500, [%rd398];
	mad.wide.u32 	%rd155, %r500, %r65, %rd399;
	shr.u64 	%rd399, %rd155, 32;
	st.local.u32 	[%rd397], %rd155;
	add.s64 	%rd398, %rd398, 4;
	add.s64 	%rd397, %rd397, 4;
	add.s32 	%r1183, %r1183, 1;
	setp.ne.s32 	%p99, %r1183, 6;
	@%p99 bra 	$L__BB7_72;

	st.local.u32 	[%rd1+24], %rd399;
	mov.u32 	%r501, 4;
	sub.s32 	%r69, %r501, %r66;
	mov.u32 	%r502, 6;
	sub.s32 	%r503, %r502, %r66;
	mul.wide.s32 	%rd156, %r503, 4;
	add.s64 	%rd157, %rd1, %rd156;
	ld.local.u32 	%r1184, [%rd157];
	ld.local.u32 	%r1185, [%rd157+-4];
	and.b32  	%r72, %r64, 31;
	setp.eq.s32 	%p100, %r72, 0;
	@%p100 bra 	$L__BB7_75;

	mov.u32 	%r504, 32;
	sub.s32 	%r505, %r504, %r72;
	shr.u32 	%r506, %r1185, %r505;
	shl.b32 	%r507, %r1184, %r72;
	add.s32 	%r1184, %r506, %r507;
	mul.wide.s32 	%rd158, %r69, 4;
	add.s64 	%rd159, %rd1, %rd158;
	ld.local.u32 	%r508, [%rd159];
	shr.u32 	%r509, %r508, %r505;
	shl.b32 	%r510, %r1185, %r72;
	add.s32 	%r1185, %r509, %r510;

$L__BB7_75:
	and.b32  	%r511, %r63, -2147483648;
	shr.u32 	%r512, %r1185, 30;
	shl.b32 	%r513, %r1184, 2;
	or.b32  	%r514, %r512, %r513;
	shr.u32 	%r515, %r514, 31;
	shr.u32 	%r516, %r1184, 30;
	add.s32 	%r517, %r515, %r516;
	neg.s32 	%r518, %r517;
	setp.eq.s32 	%p101, %r511, 0;
	selp.b32 	%r1186, %r517, %r518, %p101;
	setp.ne.s32 	%p102, %r515, 0;
	xor.b32  	%r519, %r511, -2147483648;
	selp.b32 	%r520, %r519, %r511, %p102;
	selp.b32 	%r521, -1, 0, %p102;
	xor.b32  	%r522, %r514, %r521;
	shl.b32 	%r523, %r1185, 2;
	xor.b32  	%r524, %r523, %r521;
	cvt.u64.u32 	%rd160, %r522;
	cvt.u64.u32 	%rd161, %r524;
	bfi.b64 	%rd162, %rd160, %rd161, 32, 32;
	cvt.rn.f64.s64 	%fd354, %rd162;
	mul.rn.f64 	%fd355, %fd354, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f322, %fd355;
	setp.eq.s32 	%p103, %r520, 0;
	neg.f32 	%f323, %f322;
	selp.f32 	%f669, %f322, %f323, %p103;

$L__BB7_77:
	and.b32  	%r79, %r1186, 1;
	setp.eq.s32 	%p104, %r79, 0;
	selp.f32 	%f55, %f669, 0f3F800000, %p104;
	mul.rn.f32 	%f56, %f669, %f669;
	mov.f32 	%f670, 0fB94D4153;
	@%p104 bra 	$L__BB7_79;

	mov.f32 	%f326, 0fBAB607ED;
	mov.f32 	%f327, 0f37CBAC00;
	fma.rn.f32 	%f670, %f327, %f56, %f326;

$L__BB7_79:
	selp.f32 	%f328, 0f3C0885E4, 0f3D2AAABB, %p104;
	fma.rn.f32 	%f329, %f670, %f56, %f328;
	selp.f32 	%f330, 0fBE2AAAA8, 0fBEFFFFFF, %p104;
	fma.rn.f32 	%f331, %f329, %f56, %f330;
	mov.f32 	%f332, 0f00000000;
	fma.rn.f32 	%f333, %f56, %f55, %f332;
	fma.rn.f32 	%f671, %f331, %f333, %f55;
	and.b32  	%r526, %r1186, 2;
	setp.eq.s32 	%p106, %r526, 0;
	@%p106 bra 	$L__BB7_81;

	mov.f32 	%f335, 0fBF800000;
	fma.rn.f32 	%f671, %f671, %f335, %f332;

$L__BB7_81:
	mul.rn.f32 	%f62, %f671, %f18;
	add.rn.f32 	%f63, %f62, 0fC20C0000;
	add.rn.f32 	%f64, %f51, 0fC2D20000;
	cvt.f64.f32 	%fd24, %f64;
	mul.rn.f64 	%fd356, %fd24, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f65, %fd356;
	cvt.f64.f32 	%fd25, %f63;
	mul.rn.f64 	%fd357, %fd25, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f66, %fd357;
	cvt.f64.f32 	%fd26, %f65;
	mul.rn.f64 	%fd27, %fd26, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r527, %temp}, %fd27;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r528}, %fd27;
	}
	and.b32  	%r529, %r528, 2147483647;
	setp.eq.s32 	%p107, %r529, 2146435072;
	setp.eq.s32 	%p108, %r527, 0;
	and.pred  	%p109, %p108, %p107;
	@%p109 bra 	$L__BB7_84;
	bra.uni 	$L__BB7_82;

$L__BB7_84:
	mov.f64 	%fd367, 0d0000000000000000;
	mul.rn.f64 	%fd969, %fd27, %fd367;
	mov.u32 	%r1187, 0;
	bra.uni 	$L__BB7_85;

$L__BB7_82:
	mul.rn.f64 	%fd358, %fd27, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1187, %fd358;
	st.local.u32 	[%rd8], %r1187;
	cvt.rn.f64.s32 	%fd359, %r1187;
	neg.f64 	%fd360, %fd359;
	mov.f64 	%fd361, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd362, %fd360, %fd361, %fd27;
	mov.f64 	%fd363, 0d3C91A62633145C00;
	fma.rn.f64 	%fd364, %fd360, %fd363, %fd362;
	mov.f64 	%fd365, 0d397B839A252049C0;
	fma.rn.f64 	%fd969, %fd360, %fd365, %fd364;
	abs.f64 	%fd366, %fd27;
	setp.ltu.f64 	%p110, %fd366, 0d41E0000000000000;
	@%p110 bra 	$L__BB7_85;

	{ // callseq 72, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd27;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd969, [retval0+0];
	} // callseq 72
	ld.local.u32 	%r1187, [%rd8];

$L__BB7_85:
	and.b32  	%r531, %r1187, 1;
	shl.b32 	%r532, %r1187, 3;
	and.b32  	%r533, %r532, 8;
	setp.eq.s32 	%p111, %r531, 0;
	selp.f64 	%fd368, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p111;
	mul.wide.s32 	%rd164, %r533, 8;
	mov.u64 	%rd165, __cudart_sin_cos_coeffs;
	add.s64 	%rd166, %rd165, %rd164;
	ld.global.nc.f64 	%fd369, [%rd166+8];
	mul.rn.f64 	%fd32, %fd969, %fd969;
	fma.rn.f64 	%fd370, %fd368, %fd32, %fd369;
	ld.global.nc.f64 	%fd371, [%rd166+16];
	fma.rn.f64 	%fd372, %fd370, %fd32, %fd371;
	ld.global.nc.f64 	%fd373, [%rd166+24];
	fma.rn.f64 	%fd374, %fd372, %fd32, %fd373;
	ld.global.nc.f64 	%fd375, [%rd166+32];
	fma.rn.f64 	%fd376, %fd374, %fd32, %fd375;
	ld.global.nc.f64 	%fd377, [%rd166+40];
	fma.rn.f64 	%fd378, %fd376, %fd32, %fd377;
	ld.global.nc.f64 	%fd379, [%rd166+48];
	fma.rn.f64 	%fd33, %fd378, %fd32, %fd379;
	fma.rn.f64 	%fd971, %fd33, %fd969, %fd969;
	@%p111 bra 	$L__BB7_87;

	mov.f64 	%fd380, 0d3FF0000000000000;
	fma.rn.f64 	%fd971, %fd33, %fd32, %fd380;

$L__BB7_87:
	and.b32  	%r534, %r1187, 2;
	setp.eq.s32 	%p112, %r534, 0;
	@%p112 bra 	$L__BB7_89;

	mov.f64 	%fd381, 0d0000000000000000;
	mov.f64 	%fd382, 0dBFF0000000000000;
	fma.rn.f64 	%fd971, %fd971, %fd382, %fd381;

$L__BB7_89:
	add.rn.f64 	%fd39, %fd26, %fd26;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r535, %temp}, %fd39;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r536}, %fd39;
	}
	and.b32  	%r537, %r536, 2147483647;
	setp.eq.s32 	%p113, %r537, 2146435072;
	setp.eq.s32 	%p114, %r535, 0;
	and.pred  	%p115, %p114, %p113;
	@%p115 bra 	$L__BB7_92;
	bra.uni 	$L__BB7_90;

$L__BB7_92:
	mov.f64 	%fd392, 0d0000000000000000;
	mul.rn.f64 	%fd972, %fd39, %fd392;
	mov.u32 	%r1188, 0;
	bra.uni 	$L__BB7_93;

$L__BB7_90:
	mul.rn.f64 	%fd383, %fd39, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1188, %fd383;
	st.local.u32 	[%rd8], %r1188;
	cvt.rn.f64.s32 	%fd384, %r1188;
	neg.f64 	%fd385, %fd384;
	mov.f64 	%fd386, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd387, %fd385, %fd386, %fd39;
	mov.f64 	%fd388, 0d3C91A62633145C00;
	fma.rn.f64 	%fd389, %fd385, %fd388, %fd387;
	mov.f64 	%fd390, 0d397B839A252049C0;
	fma.rn.f64 	%fd972, %fd385, %fd390, %fd389;
	abs.f64 	%fd391, %fd39;
	setp.ltu.f64 	%p116, %fd391, 0d41E0000000000000;
	@%p116 bra 	$L__BB7_93;

	{ // callseq 73, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd39;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd972, [retval0+0];
	} // callseq 73
	ld.local.u32 	%r1188, [%rd8];

$L__BB7_93:
	and.b32  	%r539, %r1188, 1;
	shl.b32 	%r540, %r1188, 3;
	and.b32  	%r541, %r540, 8;
	setp.eq.s32 	%p117, %r539, 0;
	selp.f64 	%fd393, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p117;
	mul.wide.s32 	%rd168, %r541, 8;
	add.s64 	%rd170, %rd165, %rd168;
	ld.global.nc.f64 	%fd394, [%rd170+8];
	mul.rn.f64 	%fd44, %fd972, %fd972;
	fma.rn.f64 	%fd395, %fd393, %fd44, %fd394;
	ld.global.nc.f64 	%fd396, [%rd170+16];
	fma.rn.f64 	%fd397, %fd395, %fd44, %fd396;
	ld.global.nc.f64 	%fd398, [%rd170+24];
	fma.rn.f64 	%fd399, %fd397, %fd44, %fd398;
	ld.global.nc.f64 	%fd400, [%rd170+32];
	fma.rn.f64 	%fd401, %fd399, %fd44, %fd400;
	ld.global.nc.f64 	%fd402, [%rd170+40];
	fma.rn.f64 	%fd403, %fd401, %fd44, %fd402;
	ld.global.nc.f64 	%fd404, [%rd170+48];
	fma.rn.f64 	%fd45, %fd403, %fd44, %fd404;
	fma.rn.f64 	%fd974, %fd45, %fd972, %fd972;
	@%p117 bra 	$L__BB7_95;

	mov.f64 	%fd405, 0d3FF0000000000000;
	fma.rn.f64 	%fd974, %fd45, %fd44, %fd405;

$L__BB7_95:
	and.b32  	%r542, %r1188, 2;
	setp.eq.s32 	%p118, %r542, 0;
	@%p118 bra 	$L__BB7_97;

	mov.f64 	%fd406, 0d0000000000000000;
	mov.f64 	%fd407, 0dBFF0000000000000;
	fma.rn.f64 	%fd974, %fd974, %fd407, %fd406;

$L__BB7_97:
	mul.rn.f64 	%fd408, %fd974, 0d4034000000000000;
	mul.rn.f64 	%fd409, %fd971, 0d4034000000000000;
	add.rn.f64 	%fd51, %fd409, %fd408;
	mul.rn.f32 	%f336, %f66, 0f3F22F983;
	cvt.rni.s32.f32 	%r1192, %f336;
	cvt.rn.f32.s32 	%f337, %r1192;
	mov.f32 	%f338, 0fBFC90FDA;
	fma.rn.f32 	%f339, %f337, %f338, %f66;
	mov.f32 	%f340, 0fB3A22168;
	fma.rn.f32 	%f341, %f337, %f340, %f339;
	mov.f32 	%f342, 0fA7C234C5;
	fma.rn.f32 	%f672, %f337, %f342, %f341;
	abs.f32 	%f68, %f66;
	setp.ltu.f32 	%p119, %f68, 0f47CE4780;
	@%p119 bra 	$L__BB7_105;

	setp.eq.f32 	%p120, %f68, 0f7F800000;
	@%p120 bra 	$L__BB7_104;
	bra.uni 	$L__BB7_99;

$L__BB7_104:
	mov.f32 	%f345, 0f00000000;
	mul.rn.f32 	%f672, %f66, %f345;
	mov.u32 	%r1192, 0;
	bra.uni 	$L__BB7_105;

$L__BB7_99:
	mov.b32 	%r87, %f66;
	bfe.u32 	%r544, %r87, 23, 8;
	add.s32 	%r88, %r544, -128;
	shl.b32 	%r545, %r87, 8;
	or.b32  	%r89, %r545, -2147483648;
	shr.u32 	%r90, %r88, 5;
	mov.u64 	%rd402, 0;
	mov.u32 	%r1189, 0;
	mov.u64 	%rd401, __cudart_i2opi_f;
	mov.u64 	%rd400, %rd1;

$L__BB7_100:
	.pragma "nounroll";
	ld.global.nc.u32 	%r546, [%rd401];
	mad.wide.u32 	%rd173, %r546, %r89, %rd402;
	shr.u64 	%rd402, %rd173, 32;
	st.local.u32 	[%rd400], %rd173;
	add.s64 	%rd401, %rd401, 4;
	add.s64 	%rd400, %rd400, 4;
	add.s32 	%r1189, %r1189, 1;
	setp.ne.s32 	%p121, %r1189, 6;
	@%p121 bra 	$L__BB7_100;

	st.local.u32 	[%rd1+24], %rd402;
	mov.u32 	%r547, 4;
	sub.s32 	%r93, %r547, %r90;
	mov.u32 	%r548, 6;
	sub.s32 	%r549, %r548, %r90;
	mul.wide.s32 	%rd174, %r549, 4;
	add.s64 	%rd175, %rd1, %rd174;
	ld.local.u32 	%r1190, [%rd175];
	ld.local.u32 	%r1191, [%rd175+-4];
	and.b32  	%r96, %r88, 31;
	setp.eq.s32 	%p122, %r96, 0;
	@%p122 bra 	$L__BB7_103;

	mov.u32 	%r550, 32;
	sub.s32 	%r551, %r550, %r96;
	shr.u32 	%r552, %r1191, %r551;
	shl.b32 	%r553, %r1190, %r96;
	add.s32 	%r1190, %r552, %r553;
	mul.wide.s32 	%rd176, %r93, 4;
	add.s64 	%rd177, %rd1, %rd176;
	ld.local.u32 	%r554, [%rd177];
	shr.u32 	%r555, %r554, %r551;
	shl.b32 	%r556, %r1191, %r96;
	add.s32 	%r1191, %r555, %r556;

$L__BB7_103:
	and.b32  	%r557, %r87, -2147483648;
	shr.u32 	%r558, %r1191, 30;
	shl.b32 	%r559, %r1190, 2;
	or.b32  	%r560, %r558, %r559;
	shr.u32 	%r561, %r560, 31;
	shr.u32 	%r562, %r1190, 30;
	add.s32 	%r563, %r561, %r562;
	neg.s32 	%r564, %r563;
	setp.eq.s32 	%p123, %r557, 0;
	selp.b32 	%r1192, %r563, %r564, %p123;
	setp.ne.s32 	%p124, %r561, 0;
	xor.b32  	%r565, %r557, -2147483648;
	selp.b32 	%r566, %r565, %r557, %p124;
	selp.b32 	%r567, -1, 0, %p124;
	xor.b32  	%r568, %r560, %r567;
	shl.b32 	%r569, %r1191, 2;
	xor.b32  	%r570, %r569, %r567;
	cvt.u64.u32 	%rd178, %r568;
	cvt.u64.u32 	%rd179, %r570;
	bfi.b64 	%rd180, %rd178, %rd179, 32, 32;
	cvt.rn.f64.s64 	%fd410, %rd180;
	mul.rn.f64 	%fd411, %fd410, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f343, %fd411;
	setp.eq.s32 	%p125, %r566, 0;
	neg.f32 	%f344, %f343;
	selp.f32 	%f672, %f343, %f344, %p125;

$L__BB7_105:
	and.b32  	%r103, %r1192, 1;
	setp.eq.s32 	%p126, %r103, 0;
	selp.f32 	%f72, %f672, 0f3F800000, %p126;
	mul.rn.f32 	%f73, %f672, %f672;
	mov.f32 	%f673, 0fB94D4153;
	@%p126 bra 	$L__BB7_107;

	mov.f32 	%f347, 0fBAB607ED;
	mov.f32 	%f348, 0f37CBAC00;
	fma.rn.f32 	%f673, %f348, %f73, %f347;

$L__BB7_107:
	selp.f32 	%f349, 0f3C0885E4, 0f3D2AAABB, %p126;
	fma.rn.f32 	%f350, %f673, %f73, %f349;
	selp.f32 	%f351, 0fBE2AAAA8, 0fBEFFFFFF, %p126;
	fma.rn.f32 	%f352, %f350, %f73, %f351;
	mov.f32 	%f353, 0f00000000;
	fma.rn.f32 	%f354, %f73, %f72, %f353;
	fma.rn.f32 	%f674, %f352, %f354, %f72;
	and.b32  	%r572, %r1192, 2;
	setp.eq.s32 	%p128, %r572, 0;
	@%p128 bra 	$L__BB7_109;

	mov.f32 	%f356, 0fBF800000;
	fma.rn.f32 	%f674, %f674, %f356, %f353;

$L__BB7_109:
	cvt.f64.f32 	%fd52, %f66;
	div.rn.f64 	%fd53, %fd52, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r573, %temp}, %fd53;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r574}, %fd53;
	}
	and.b32  	%r575, %r574, 2147483647;
	setp.eq.s32 	%p129, %r575, 2146435072;
	setp.eq.s32 	%p130, %r573, 0;
	and.pred  	%p131, %p130, %p129;
	@%p131 bra 	$L__BB7_112;
	bra.uni 	$L__BB7_110;

$L__BB7_112:
	mov.f64 	%fd421, 0d0000000000000000;
	mul.rn.f64 	%fd975, %fd53, %fd421;
	mov.u32 	%r1193, 0;
	bra.uni 	$L__BB7_113;

$L__BB7_110:
	mul.rn.f64 	%fd412, %fd53, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1193, %fd412;
	st.local.u32 	[%rd8], %r1193;
	cvt.rn.f64.s32 	%fd413, %r1193;
	neg.f64 	%fd414, %fd413;
	mov.f64 	%fd415, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd416, %fd414, %fd415, %fd53;
	mov.f64 	%fd417, 0d3C91A62633145C00;
	fma.rn.f64 	%fd418, %fd414, %fd417, %fd416;
	mov.f64 	%fd419, 0d397B839A252049C0;
	fma.rn.f64 	%fd975, %fd414, %fd419, %fd418;
	abs.f64 	%fd420, %fd53;
	setp.ltu.f64 	%p132, %fd420, 0d41E0000000000000;
	@%p132 bra 	$L__BB7_113;

	{ // callseq 74, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd53;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd975, [retval0+0];
	} // callseq 74
	ld.local.u32 	%r1193, [%rd8];

$L__BB7_113:
	and.b32  	%r577, %r1193, 1;
	shl.b32 	%r578, %r1193, 3;
	and.b32  	%r579, %r578, 8;
	setp.eq.s32 	%p133, %r577, 0;
	selp.f64 	%fd422, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p133;
	mul.wide.s32 	%rd182, %r579, 8;
	add.s64 	%rd184, %rd165, %rd182;
	ld.global.nc.f64 	%fd423, [%rd184+8];
	mul.rn.f64 	%fd58, %fd975, %fd975;
	fma.rn.f64 	%fd424, %fd422, %fd58, %fd423;
	ld.global.nc.f64 	%fd425, [%rd184+16];
	fma.rn.f64 	%fd426, %fd424, %fd58, %fd425;
	ld.global.nc.f64 	%fd427, [%rd184+24];
	fma.rn.f64 	%fd428, %fd426, %fd58, %fd427;
	ld.global.nc.f64 	%fd429, [%rd184+32];
	fma.rn.f64 	%fd430, %fd428, %fd58, %fd429;
	ld.global.nc.f64 	%fd431, [%rd184+40];
	fma.rn.f64 	%fd432, %fd430, %fd58, %fd431;
	ld.global.nc.f64 	%fd433, [%rd184+48];
	fma.rn.f64 	%fd59, %fd432, %fd58, %fd433;
	fma.rn.f64 	%fd977, %fd59, %fd975, %fd975;
	@%p133 bra 	$L__BB7_115;

	mov.f64 	%fd434, 0d3FF0000000000000;
	fma.rn.f64 	%fd977, %fd59, %fd58, %fd434;

$L__BB7_115:
	and.b32  	%r580, %r1193, 2;
	setp.eq.s32 	%p134, %r580, 0;
	@%p134 bra 	$L__BB7_117;

	mov.f64 	%fd435, 0d0000000000000000;
	mov.f64 	%fd436, 0dBFF0000000000000;
	fma.rn.f64 	%fd977, %fd977, %fd436, %fd435;

$L__BB7_117:
	mul.rn.f64 	%fd437, %fd977, 0d4044000000000000;
	cvt.f64.f32 	%fd438, %f674;
	mul.rn.f64 	%fd439, %fd438, 0d4034000000000000;
	add.rn.f64 	%fd65, %fd439, %fd437;
	div.rn.f64 	%fd66, %fd52, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r581, %temp}, %fd66;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r582}, %fd66;
	}
	and.b32  	%r583, %r582, 2147483647;
	setp.eq.s32 	%p135, %r583, 2146435072;
	setp.eq.s32 	%p136, %r581, 0;
	and.pred  	%p137, %p136, %p135;
	@%p137 bra 	$L__BB7_120;
	bra.uni 	$L__BB7_118;

$L__BB7_120:
	mov.f64 	%fd449, 0d0000000000000000;
	mul.rn.f64 	%fd978, %fd66, %fd449;
	mov.u32 	%r1194, 0;
	bra.uni 	$L__BB7_121;

$L__BB7_118:
	mul.rn.f64 	%fd440, %fd66, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1194, %fd440;
	st.local.u32 	[%rd8], %r1194;
	cvt.rn.f64.s32 	%fd441, %r1194;
	neg.f64 	%fd442, %fd441;
	mov.f64 	%fd443, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd444, %fd442, %fd443, %fd66;
	mov.f64 	%fd445, 0d3C91A62633145C00;
	fma.rn.f64 	%fd446, %fd442, %fd445, %fd444;
	mov.f64 	%fd447, 0d397B839A252049C0;
	fma.rn.f64 	%fd978, %fd442, %fd447, %fd446;
	abs.f64 	%fd448, %fd66;
	setp.ltu.f64 	%p138, %fd448, 0d41E0000000000000;
	@%p138 bra 	$L__BB7_121;

	{ // callseq 75, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd66;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd978, [retval0+0];
	} // callseq 75
	ld.local.u32 	%r1194, [%rd8];

$L__BB7_121:
	and.b32  	%r585, %r1194, 1;
	shl.b32 	%r586, %r1194, 3;
	and.b32  	%r587, %r586, 8;
	setp.eq.s32 	%p139, %r585, 0;
	selp.f64 	%fd450, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p139;
	mul.wide.s32 	%rd186, %r587, 8;
	add.s64 	%rd188, %rd165, %rd186;
	ld.global.nc.f64 	%fd451, [%rd188+8];
	mul.rn.f64 	%fd71, %fd978, %fd978;
	fma.rn.f64 	%fd452, %fd450, %fd71, %fd451;
	ld.global.nc.f64 	%fd453, [%rd188+16];
	fma.rn.f64 	%fd454, %fd452, %fd71, %fd453;
	ld.global.nc.f64 	%fd455, [%rd188+24];
	fma.rn.f64 	%fd456, %fd454, %fd71, %fd455;
	ld.global.nc.f64 	%fd457, [%rd188+32];
	fma.rn.f64 	%fd458, %fd456, %fd71, %fd457;
	ld.global.nc.f64 	%fd459, [%rd188+40];
	fma.rn.f64 	%fd460, %fd458, %fd71, %fd459;
	ld.global.nc.f64 	%fd461, [%rd188+48];
	fma.rn.f64 	%fd72, %fd460, %fd71, %fd461;
	fma.rn.f64 	%fd980, %fd72, %fd978, %fd978;
	@%p139 bra 	$L__BB7_123;

	mov.f64 	%fd462, 0d3FF0000000000000;
	fma.rn.f64 	%fd980, %fd72, %fd71, %fd462;

$L__BB7_123:
	and.b32  	%r588, %r1194, 2;
	setp.eq.s32 	%p140, %r588, 0;
	@%p140 bra 	$L__BB7_125;

	mov.f64 	%fd463, 0d0000000000000000;
	mov.f64 	%fd464, 0dBFF0000000000000;
	fma.rn.f64 	%fd980, %fd980, %fd464, %fd463;

$L__BB7_125:
	mul.rn.f64 	%fd465, %fd980, 0d4064000000000000;
	add.rn.f64 	%fd78, %fd65, %fd465;
	div.rn.f64 	%fd79, %fd52, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r589, %temp}, %fd79;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r590}, %fd79;
	}
	and.b32  	%r591, %r590, 2147483647;
	setp.eq.s32 	%p141, %r591, 2146435072;
	setp.eq.s32 	%p142, %r589, 0;
	and.pred  	%p143, %p142, %p141;
	@%p143 bra 	$L__BB7_128;
	bra.uni 	$L__BB7_126;

$L__BB7_128:
	mov.f64 	%fd475, 0d0000000000000000;
	mul.rn.f64 	%fd981, %fd79, %fd475;
	mov.u32 	%r1195, 0;
	bra.uni 	$L__BB7_129;

$L__BB7_126:
	mul.rn.f64 	%fd466, %fd79, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1195, %fd466;
	st.local.u32 	[%rd8], %r1195;
	cvt.rn.f64.s32 	%fd467, %r1195;
	neg.f64 	%fd468, %fd467;
	mov.f64 	%fd469, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd470, %fd468, %fd469, %fd79;
	mov.f64 	%fd471, 0d3C91A62633145C00;
	fma.rn.f64 	%fd472, %fd468, %fd471, %fd470;
	mov.f64 	%fd473, 0d397B839A252049C0;
	fma.rn.f64 	%fd981, %fd468, %fd473, %fd472;
	abs.f64 	%fd474, %fd79;
	setp.ltu.f64 	%p144, %fd474, 0d41E0000000000000;
	@%p144 bra 	$L__BB7_129;

	{ // callseq 76, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd79;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd981, [retval0+0];
	} // callseq 76
	ld.local.u32 	%r1195, [%rd8];

$L__BB7_129:
	and.b32  	%r593, %r1195, 1;
	shl.b32 	%r594, %r1195, 3;
	and.b32  	%r595, %r594, 8;
	setp.eq.s32 	%p145, %r593, 0;
	selp.f64 	%fd476, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p145;
	mul.wide.s32 	%rd190, %r595, 8;
	add.s64 	%rd192, %rd165, %rd190;
	ld.global.nc.f64 	%fd477, [%rd192+8];
	mul.rn.f64 	%fd84, %fd981, %fd981;
	fma.rn.f64 	%fd478, %fd476, %fd84, %fd477;
	ld.global.nc.f64 	%fd479, [%rd192+16];
	fma.rn.f64 	%fd480, %fd478, %fd84, %fd479;
	ld.global.nc.f64 	%fd481, [%rd192+24];
	fma.rn.f64 	%fd482, %fd480, %fd84, %fd481;
	ld.global.nc.f64 	%fd483, [%rd192+32];
	fma.rn.f64 	%fd484, %fd482, %fd84, %fd483;
	ld.global.nc.f64 	%fd485, [%rd192+40];
	fma.rn.f64 	%fd486, %fd484, %fd84, %fd485;
	ld.global.nc.f64 	%fd487, [%rd192+48];
	fma.rn.f64 	%fd85, %fd486, %fd84, %fd487;
	fma.rn.f64 	%fd983, %fd85, %fd981, %fd981;
	@%p145 bra 	$L__BB7_131;

	mov.f64 	%fd488, 0d3FF0000000000000;
	fma.rn.f64 	%fd983, %fd85, %fd84, %fd488;

$L__BB7_131:
	and.b32  	%r596, %r1195, 2;
	setp.eq.s32 	%p146, %r596, 0;
	@%p146 bra 	$L__BB7_133;

	mov.f64 	%fd489, 0d0000000000000000;
	mov.f64 	%fd490, 0dBFF0000000000000;
	fma.rn.f64 	%fd983, %fd983, %fd490, %fd489;

$L__BB7_133:
	mul.rn.f64 	%fd491, %fd983, 0d4074000000000000;
	add.rn.f64 	%fd91, %fd78, %fd491;
	mul.rn.f32 	%f357, %f65, 0f3F22F983;
	cvt.rni.s32.f32 	%r1199, %f357;
	cvt.rn.f32.s32 	%f358, %r1199;
	mov.f32 	%f359, 0fBFC90FDA;
	fma.rn.f32 	%f360, %f358, %f359, %f65;
	mov.f32 	%f361, 0fB3A22168;
	fma.rn.f32 	%f362, %f358, %f361, %f360;
	mov.f32 	%f363, 0fA7C234C5;
	fma.rn.f32 	%f675, %f358, %f363, %f362;
	abs.f32 	%f80, %f65;
	setp.ltu.f32 	%p147, %f80, 0f47CE4780;
	@%p147 bra 	$L__BB7_141;

	setp.eq.f32 	%p148, %f80, 0f7F800000;
	@%p148 bra 	$L__BB7_140;
	bra.uni 	$L__BB7_135;

$L__BB7_140:
	mov.f32 	%f366, 0f00000000;
	mul.rn.f32 	%f675, %f65, %f366;
	mov.u32 	%r1199, 0;
	bra.uni 	$L__BB7_141;

$L__BB7_135:
	mov.b32 	%r114, %f65;
	bfe.u32 	%r598, %r114, 23, 8;
	add.s32 	%r115, %r598, -128;
	shl.b32 	%r599, %r114, 8;
	or.b32  	%r116, %r599, -2147483648;
	shr.u32 	%r117, %r115, 5;
	mov.u64 	%rd405, 0;
	mov.u32 	%r1196, 0;
	mov.u64 	%rd404, __cudart_i2opi_f;
	mov.u64 	%rd403, %rd1;

$L__BB7_136:
	.pragma "nounroll";
	ld.global.nc.u32 	%r600, [%rd404];
	mad.wide.u32 	%rd195, %r600, %r116, %rd405;
	shr.u64 	%rd405, %rd195, 32;
	st.local.u32 	[%rd403], %rd195;
	add.s64 	%rd404, %rd404, 4;
	add.s64 	%rd403, %rd403, 4;
	add.s32 	%r1196, %r1196, 1;
	setp.ne.s32 	%p149, %r1196, 6;
	@%p149 bra 	$L__BB7_136;

	st.local.u32 	[%rd1+24], %rd405;
	mov.u32 	%r601, 4;
	sub.s32 	%r120, %r601, %r117;
	mov.u32 	%r602, 6;
	sub.s32 	%r603, %r602, %r117;
	mul.wide.s32 	%rd196, %r603, 4;
	add.s64 	%rd197, %rd1, %rd196;
	ld.local.u32 	%r1197, [%rd197];
	ld.local.u32 	%r1198, [%rd197+-4];
	and.b32  	%r123, %r115, 31;
	setp.eq.s32 	%p150, %r123, 0;
	@%p150 bra 	$L__BB7_139;

	mov.u32 	%r604, 32;
	sub.s32 	%r605, %r604, %r123;
	shr.u32 	%r606, %r1198, %r605;
	shl.b32 	%r607, %r1197, %r123;
	add.s32 	%r1197, %r606, %r607;
	mul.wide.s32 	%rd198, %r120, 4;
	add.s64 	%rd199, %rd1, %rd198;
	ld.local.u32 	%r608, [%rd199];
	shr.u32 	%r609, %r608, %r605;
	shl.b32 	%r610, %r1198, %r123;
	add.s32 	%r1198, %r609, %r610;

$L__BB7_139:
	and.b32  	%r611, %r114, -2147483648;
	shr.u32 	%r612, %r1198, 30;
	shl.b32 	%r613, %r1197, 2;
	or.b32  	%r614, %r612, %r613;
	shr.u32 	%r615, %r614, 31;
	shr.u32 	%r616, %r1197, 30;
	add.s32 	%r617, %r615, %r616;
	neg.s32 	%r618, %r617;
	setp.eq.s32 	%p151, %r611, 0;
	selp.b32 	%r1199, %r617, %r618, %p151;
	setp.ne.s32 	%p152, %r615, 0;
	xor.b32  	%r619, %r611, -2147483648;
	selp.b32 	%r620, %r619, %r611, %p152;
	selp.b32 	%r621, -1, 0, %p152;
	xor.b32  	%r622, %r614, %r621;
	shl.b32 	%r623, %r1198, 2;
	xor.b32  	%r624, %r623, %r621;
	cvt.u64.u32 	%rd200, %r622;
	cvt.u64.u32 	%rd201, %r624;
	bfi.b64 	%rd202, %rd200, %rd201, 32, 32;
	cvt.rn.f64.s64 	%fd492, %rd202;
	mul.rn.f64 	%fd493, %fd492, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f364, %fd493;
	setp.eq.s32 	%p153, %r620, 0;
	neg.f32 	%f365, %f364;
	selp.f32 	%f675, %f364, %f365, %p153;

$L__BB7_141:
	cvt.rn.f32.f64 	%f368, %fd51;
	cvt.f64.f32 	%fd92, %f368;
	and.b32  	%r130, %r1199, 1;
	setp.eq.s32 	%p154, %r130, 0;
	selp.f32 	%f84, %f675, 0f3F800000, %p154;
	mul.rn.f32 	%f85, %f675, %f675;
	mov.f32 	%f676, 0fB94D4153;
	@%p154 bra 	$L__BB7_143;

	mov.f32 	%f369, 0fBAB607ED;
	mov.f32 	%f370, 0f37CBAC00;
	fma.rn.f32 	%f676, %f370, %f85, %f369;

$L__BB7_143:
	selp.f32 	%f371, 0f3C0885E4, 0f3D2AAABB, %p154;
	fma.rn.f32 	%f372, %f676, %f85, %f371;
	selp.f32 	%f373, 0fBE2AAAA8, 0fBEFFFFFF, %p154;
	fma.rn.f32 	%f374, %f372, %f85, %f373;
	mov.f32 	%f375, 0f00000000;
	fma.rn.f32 	%f376, %f85, %f84, %f375;
	fma.rn.f32 	%f677, %f374, %f376, %f84;
	and.b32  	%r626, %r1199, 2;
	setp.eq.s32 	%p156, %r626, 0;
	@%p156 bra 	$L__BB7_145;

	mov.f32 	%f378, 0fBF800000;
	fma.rn.f32 	%f677, %f677, %f378, %f375;

$L__BB7_145:
	div.rn.f64 	%fd93, %fd26, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r627, %temp}, %fd93;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r628}, %fd93;
	}
	and.b32  	%r629, %r628, 2147483647;
	setp.eq.s32 	%p157, %r629, 2146435072;
	setp.eq.s32 	%p158, %r627, 0;
	and.pred  	%p159, %p158, %p157;
	@%p159 bra 	$L__BB7_148;
	bra.uni 	$L__BB7_146;

$L__BB7_148:
	mov.f64 	%fd503, 0d0000000000000000;
	mul.rn.f64 	%fd984, %fd93, %fd503;
	mov.u32 	%r1200, 0;
	bra.uni 	$L__BB7_149;

$L__BB7_146:
	mul.rn.f64 	%fd494, %fd93, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1200, %fd494;
	st.local.u32 	[%rd8], %r1200;
	cvt.rn.f64.s32 	%fd495, %r1200;
	neg.f64 	%fd496, %fd495;
	mov.f64 	%fd497, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd498, %fd496, %fd497, %fd93;
	mov.f64 	%fd499, 0d3C91A62633145C00;
	fma.rn.f64 	%fd500, %fd496, %fd499, %fd498;
	mov.f64 	%fd501, 0d397B839A252049C0;
	fma.rn.f64 	%fd984, %fd496, %fd501, %fd500;
	abs.f64 	%fd502, %fd93;
	setp.ltu.f64 	%p160, %fd502, 0d41E0000000000000;
	@%p160 bra 	$L__BB7_149;

	{ // callseq 77, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd93;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd984, [retval0+0];
	} // callseq 77
	ld.local.u32 	%r1200, [%rd8];

$L__BB7_149:
	and.b32  	%r631, %r1200, 1;
	shl.b32 	%r632, %r1200, 3;
	and.b32  	%r633, %r632, 8;
	setp.eq.s32 	%p161, %r631, 0;
	selp.f64 	%fd504, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p161;
	mul.wide.s32 	%rd204, %r633, 8;
	add.s64 	%rd206, %rd165, %rd204;
	ld.global.nc.f64 	%fd505, [%rd206+8];
	mul.rn.f64 	%fd98, %fd984, %fd984;
	fma.rn.f64 	%fd506, %fd504, %fd98, %fd505;
	ld.global.nc.f64 	%fd507, [%rd206+16];
	fma.rn.f64 	%fd508, %fd506, %fd98, %fd507;
	ld.global.nc.f64 	%fd509, [%rd206+24];
	fma.rn.f64 	%fd510, %fd508, %fd98, %fd509;
	ld.global.nc.f64 	%fd511, [%rd206+32];
	fma.rn.f64 	%fd512, %fd510, %fd98, %fd511;
	ld.global.nc.f64 	%fd513, [%rd206+40];
	fma.rn.f64 	%fd514, %fd512, %fd98, %fd513;
	ld.global.nc.f64 	%fd515, [%rd206+48];
	fma.rn.f64 	%fd99, %fd514, %fd98, %fd515;
	fma.rn.f64 	%fd986, %fd99, %fd984, %fd984;
	@%p161 bra 	$L__BB7_151;

	mov.f64 	%fd516, 0d3FF0000000000000;
	fma.rn.f64 	%fd986, %fd99, %fd98, %fd516;

$L__BB7_151:
	and.b32  	%r634, %r1200, 2;
	setp.eq.s32 	%p162, %r634, 0;
	@%p162 bra 	$L__BB7_153;

	mov.f64 	%fd517, 0d0000000000000000;
	mov.f64 	%fd518, 0dBFF0000000000000;
	fma.rn.f64 	%fd986, %fd986, %fd518, %fd517;

$L__BB7_153:
	mul.rn.f64 	%fd519, %fd986, 0d4044000000000000;
	cvt.f64.f32 	%fd520, %f677;
	mul.rn.f64 	%fd521, %fd520, 0d4034000000000000;
	add.rn.f64 	%fd105, %fd521, %fd519;
	div.rn.f64 	%fd106, %fd26, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r635, %temp}, %fd106;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r636}, %fd106;
	}
	and.b32  	%r637, %r636, 2147483647;
	setp.eq.s32 	%p163, %r637, 2146435072;
	setp.eq.s32 	%p164, %r635, 0;
	and.pred  	%p165, %p164, %p163;
	@%p165 bra 	$L__BB7_156;
	bra.uni 	$L__BB7_154;

$L__BB7_156:
	mov.f64 	%fd531, 0d0000000000000000;
	mul.rn.f64 	%fd987, %fd106, %fd531;
	mov.u32 	%r1201, 0;
	bra.uni 	$L__BB7_157;

$L__BB7_154:
	mul.rn.f64 	%fd522, %fd106, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1201, %fd522;
	st.local.u32 	[%rd8], %r1201;
	cvt.rn.f64.s32 	%fd523, %r1201;
	neg.f64 	%fd524, %fd523;
	mov.f64 	%fd525, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd526, %fd524, %fd525, %fd106;
	mov.f64 	%fd527, 0d3C91A62633145C00;
	fma.rn.f64 	%fd528, %fd524, %fd527, %fd526;
	mov.f64 	%fd529, 0d397B839A252049C0;
	fma.rn.f64 	%fd987, %fd524, %fd529, %fd528;
	abs.f64 	%fd530, %fd106;
	setp.ltu.f64 	%p166, %fd530, 0d41E0000000000000;
	@%p166 bra 	$L__BB7_157;

	{ // callseq 78, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd106;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd987, [retval0+0];
	} // callseq 78
	ld.local.u32 	%r1201, [%rd8];

$L__BB7_157:
	and.b32  	%r639, %r1201, 1;
	shl.b32 	%r640, %r1201, 3;
	and.b32  	%r641, %r640, 8;
	setp.eq.s32 	%p167, %r639, 0;
	selp.f64 	%fd532, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p167;
	mul.wide.s32 	%rd208, %r641, 8;
	add.s64 	%rd210, %rd165, %rd208;
	ld.global.nc.f64 	%fd533, [%rd210+8];
	mul.rn.f64 	%fd111, %fd987, %fd987;
	fma.rn.f64 	%fd534, %fd532, %fd111, %fd533;
	ld.global.nc.f64 	%fd535, [%rd210+16];
	fma.rn.f64 	%fd536, %fd534, %fd111, %fd535;
	ld.global.nc.f64 	%fd537, [%rd210+24];
	fma.rn.f64 	%fd538, %fd536, %fd111, %fd537;
	ld.global.nc.f64 	%fd539, [%rd210+32];
	fma.rn.f64 	%fd540, %fd538, %fd111, %fd539;
	ld.global.nc.f64 	%fd541, [%rd210+40];
	fma.rn.f64 	%fd542, %fd540, %fd111, %fd541;
	ld.global.nc.f64 	%fd543, [%rd210+48];
	fma.rn.f64 	%fd112, %fd542, %fd111, %fd543;
	fma.rn.f64 	%fd989, %fd112, %fd987, %fd987;
	@%p167 bra 	$L__BB7_159;

	mov.f64 	%fd544, 0d3FF0000000000000;
	fma.rn.f64 	%fd989, %fd112, %fd111, %fd544;

$L__BB7_159:
	and.b32  	%r642, %r1201, 2;
	setp.eq.s32 	%p168, %r642, 0;
	@%p168 bra 	$L__BB7_161;

	mov.f64 	%fd545, 0d0000000000000000;
	mov.f64 	%fd546, 0dBFF0000000000000;
	fma.rn.f64 	%fd989, %fd989, %fd546, %fd545;

$L__BB7_161:
	mul.rn.f64 	%fd547, %fd989, 0d4062C00000000000;
	add.rn.f64 	%fd118, %fd105, %fd547;
	div.rn.f64 	%fd119, %fd26, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r643, %temp}, %fd119;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r644}, %fd119;
	}
	and.b32  	%r645, %r644, 2147483647;
	setp.eq.s32 	%p169, %r645, 2146435072;
	setp.eq.s32 	%p170, %r643, 0;
	and.pred  	%p171, %p170, %p169;
	@%p171 bra 	$L__BB7_164;
	bra.uni 	$L__BB7_162;

$L__BB7_164:
	mov.f64 	%fd557, 0d0000000000000000;
	mul.rn.f64 	%fd990, %fd119, %fd557;
	mov.u32 	%r1202, 0;
	bra.uni 	$L__BB7_165;

$L__BB7_162:
	mul.rn.f64 	%fd548, %fd119, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1202, %fd548;
	st.local.u32 	[%rd8], %r1202;
	cvt.rn.f64.s32 	%fd549, %r1202;
	neg.f64 	%fd550, %fd549;
	mov.f64 	%fd551, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd552, %fd550, %fd551, %fd119;
	mov.f64 	%fd553, 0d3C91A62633145C00;
	fma.rn.f64 	%fd554, %fd550, %fd553, %fd552;
	mov.f64 	%fd555, 0d397B839A252049C0;
	fma.rn.f64 	%fd990, %fd550, %fd555, %fd554;
	abs.f64 	%fd556, %fd119;
	setp.ltu.f64 	%p172, %fd556, 0d41E0000000000000;
	@%p172 bra 	$L__BB7_165;

	{ // callseq 79, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd119;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd990, [retval0+0];
	} // callseq 79
	ld.local.u32 	%r1202, [%rd8];

$L__BB7_165:
	and.b32  	%r647, %r1202, 1;
	shl.b32 	%r648, %r1202, 3;
	and.b32  	%r649, %r648, 8;
	setp.eq.s32 	%p173, %r647, 0;
	selp.f64 	%fd558, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p173;
	mul.wide.s32 	%rd212, %r649, 8;
	add.s64 	%rd214, %rd165, %rd212;
	ld.global.nc.f64 	%fd559, [%rd214+8];
	mul.rn.f64 	%fd124, %fd990, %fd990;
	fma.rn.f64 	%fd560, %fd558, %fd124, %fd559;
	ld.global.nc.f64 	%fd561, [%rd214+16];
	fma.rn.f64 	%fd562, %fd560, %fd124, %fd561;
	ld.global.nc.f64 	%fd563, [%rd214+24];
	fma.rn.f64 	%fd564, %fd562, %fd124, %fd563;
	ld.global.nc.f64 	%fd565, [%rd214+32];
	fma.rn.f64 	%fd566, %fd564, %fd124, %fd565;
	ld.global.nc.f64 	%fd567, [%rd214+40];
	fma.rn.f64 	%fd568, %fd566, %fd124, %fd567;
	ld.global.nc.f64 	%fd569, [%rd214+48];
	fma.rn.f64 	%fd125, %fd568, %fd124, %fd569;
	fma.rn.f64 	%fd992, %fd125, %fd990, %fd990;
	@%p173 bra 	$L__BB7_167;

	mov.f64 	%fd570, 0d3FF0000000000000;
	fma.rn.f64 	%fd992, %fd125, %fd124, %fd570;

$L__BB7_167:
	and.b32  	%r650, %r1202, 2;
	setp.eq.s32 	%p174, %r650, 0;
	@%p174 bra 	$L__BB7_169;

	mov.f64 	%fd571, 0d0000000000000000;
	mov.f64 	%fd572, 0dBFF0000000000000;
	fma.rn.f64 	%fd992, %fd992, %fd572, %fd571;

$L__BB7_169:
	mul.rn.f64 	%fd573, %fd992, 0d4072C00000000000;
	add.rn.f64 	%fd574, %fd118, %fd573;
	add.rn.f64 	%fd131, %fd574, %fd92;
	add.rn.f64 	%fd132, %fd91, %fd92;
	add.rn.f64 	%fd575, %fd24, %fd24;
	add.rn.f64 	%fd576, %fd575, 0dC059000000000000;
	mul.rn.f64 	%fd577, %fd25, 0d4008000000000000;
	add.rn.f64 	%fd133, %fd576, %fd577;
	abs.f64 	%fd134, %fd25;
	{ // callseq 80, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd134;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd995, [retval0+0];
	} // callseq 80
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd25;
	}
	setp.lt.s32 	%p175, %r140, 0;
	and.pred  	%p3, %p175, %p11;
	not.pred 	%p177, %p3;
	@%p177 bra 	$L__BB7_171;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r651}, %fd995;
	}
	xor.b32  	%r652, %r651, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r653, %temp}, %fd995;
	}
	mov.b64 	%fd995, {%r653, %r652};

$L__BB7_171:
	add.rn.f32 	%f644, %f62, 0fC20C0000;
	setp.eq.f32 	%p178, %f644, 0f00000000;
	@%p178 bra 	$L__BB7_175;
	bra.uni 	$L__BB7_172;

$L__BB7_175:
	selp.b32 	%r654, %r140, 0, %p11;
	mov.u32 	%r655, 0;
	or.b32  	%r656, %r654, 2146435072;
	setp.lt.s32 	%p182, %r2, 0;
	selp.b32 	%r657, %r656, %r654, %p182;
	mov.b64 	%fd995, {%r655, %r657};
	bra.uni 	$L__BB7_176;

$L__BB7_172:
	setp.gt.s32 	%p179, %r140, -1;
	@%p179 bra 	$L__BB7_176;

	mov.f64 	%fd578, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd579, %fd578;
	setp.eq.f64 	%p180, %fd579, 0d4000000000000000;
	@%p180 bra 	$L__BB7_176;

	mov.f64 	%fd995, 0dFFF8000000000000;

$L__BB7_176:
	add.rn.f64 	%fd581, %fd25, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r658}, %fd581;
	}
	and.b32  	%r659, %r658, 2146435072;
	setp.ne.s32 	%p183, %r659, 2146435072;
	@%p183 bra 	$L__BB7_183;

	setp.gtu.f64 	%p184, %fd134, 0d7FF0000000000000;
	@%p184 bra 	$L__BB7_182;
	bra.uni 	$L__BB7_178;

$L__BB7_182:
	mov.f64 	%fd583, 0d4000000000000000;
	add.rn.f64 	%fd995, %fd25, %fd583;
	bra.uni 	$L__BB7_183;

$L__BB7_178:
	mov.f64 	%fd582, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r660, %temp}, %fd582;
	}
	and.b32  	%r141, %r2, 2147483647;
	setp.eq.s32 	%p185, %r141, 2146435072;
	setp.eq.s32 	%p186, %r660, 0;
	and.pred  	%p187, %p185, %p186;
	@%p187 bra 	$L__BB7_181;
	bra.uni 	$L__BB7_179;

$L__BB7_181:
	add.rn.f32 	%f651, %f62, 0fC20C0000;
	setp.gt.f64 	%p194, %fd134, 0d3FF0000000000000;
	selp.b32 	%r667, 2146435072, 0, %p194;
	mov.u32 	%r668, 0;
	xor.b32  	%r669, %r667, 2146435072;
	setp.lt.s32 	%p195, %r2, 0;
	selp.b32 	%r670, %r669, %r667, %p195;
	setp.eq.f32 	%p196, %f651, 0fBF800000;
	selp.b32 	%r671, 1072693248, %r670, %p196;
	mov.b64 	%fd995, {%r668, %r671};
	bra.uni 	$L__BB7_183;

$L__BB7_179:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r661, %temp}, %fd25;
	}
	and.b32  	%r662, %r140, 2147483647;
	setp.ne.s32 	%p188, %r662, 2146435072;
	setp.ne.s32 	%p189, %r661, 0;
	or.pred  	%p190, %p188, %p189;
	@%p190 bra 	$L__BB7_183;

	setp.gt.s32 	%p191, %r2, -1;
	selp.b32 	%r663, 2146435072, 0, %p191;
	mov.u32 	%r664, 0;
	setp.ne.s32 	%p192, %r141, 1071644672;
	and.pred  	%p193, %p192, %p3;
	or.b32  	%r665, %r663, -2147483648;
	selp.b32 	%r666, %r665, %r663, %p193;
	mov.b64 	%fd995, {%r664, %r666};

$L__BB7_183:
	add.rn.f32 	%f646, %f62, 0fC20C0000;
	add.rn.f32 	%f645, %f51, 0fC2D20000;
	mul.rn.f64 	%fd584, %fd995, 0d3FC999999999999A;
	setp.eq.f32 	%p197, %f646, 0f3F800000;
	selp.f64 	%fd585, 0d3FC999999999999A, %fd584, %p197;
	add.rn.f64 	%fd586, %fd133, %fd585;
	mul.rn.f32 	%f379, %f645, %f646;
	cvt.f64.f32 	%fd587, %f379;
	mul.rn.f64 	%fd144, %fd587, 0d3FB999999999999A;
	add.rn.f64 	%fd588, %fd144, %fd586;
	abs.f32 	%f380, %f645;
	sqrt.rn.f32 	%f381, %f380;
	cvt.f64.f32 	%fd145, %f381;
	mul.rn.f64 	%fd589, %fd145, 0d3FC999999999999A;
	add.rn.f64 	%fd590, %fd589, %fd588;
	cvt.rn.f32.f64 	%f382, %fd132;
	cvt.f64.f32 	%fd591, %f382;
	mul.rn.f64 	%fd592, %fd591, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f383, %fd592;
	cvt.f64.f32 	%fd593, %f383;
	add.rn.f64 	%fd146, %fd590, %fd593;
	add.rn.f64 	%fd594, %fd25, %fd25;
	add.rn.f64 	%fd595, %fd24, 0d4072C00000000000;
	add.rn.f64 	%fd147, %fd595, %fd594;
	abs.f64 	%fd148, %fd24;
	{ // callseq 81, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd998, [retval0+0];
	} // callseq 81
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd24;
	}
	setp.lt.s32 	%p198, %r142, 0;
	and.pred  	%p4, %p198, %p11;
	not.pred 	%p200, %p4;
	@%p200 bra 	$L__BB7_185;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r672}, %fd998;
	}
	xor.b32  	%r673, %r672, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r674, %temp}, %fd998;
	}
	mov.b64 	%fd998, {%r674, %r673};

$L__BB7_185:
	add.rn.f32 	%f647, %f51, 0fC2D20000;
	setp.eq.f32 	%p201, %f647, 0f00000000;
	@%p201 bra 	$L__BB7_189;
	bra.uni 	$L__BB7_186;

$L__BB7_189:
	selp.b32 	%r675, %r142, 0, %p11;
	mov.u32 	%r676, 0;
	or.b32  	%r677, %r675, 2146435072;
	setp.lt.s32 	%p205, %r2, 0;
	selp.b32 	%r678, %r677, %r675, %p205;
	mov.b64 	%fd998, {%r676, %r678};
	bra.uni 	$L__BB7_190;

$L__BB7_186:
	setp.gt.s32 	%p202, %r142, -1;
	@%p202 bra 	$L__BB7_190;

	mov.f64 	%fd596, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd597, %fd596;
	setp.eq.f64 	%p203, %fd597, 0d4000000000000000;
	@%p203 bra 	$L__BB7_190;

	mov.f64 	%fd998, 0dFFF8000000000000;

$L__BB7_190:
	add.rn.f64 	%fd599, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r679}, %fd599;
	}
	and.b32  	%r680, %r679, 2146435072;
	setp.ne.s32 	%p206, %r680, 2146435072;
	@%p206 bra 	$L__BB7_197;

	setp.gtu.f64 	%p207, %fd148, 0d7FF0000000000000;
	@%p207 bra 	$L__BB7_196;
	bra.uni 	$L__BB7_192;

$L__BB7_196:
	mov.f64 	%fd601, 0d4000000000000000;
	add.rn.f64 	%fd998, %fd24, %fd601;
	bra.uni 	$L__BB7_197;

$L__BB7_192:
	mov.f64 	%fd600, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r681, %temp}, %fd600;
	}
	and.b32  	%r143, %r2, 2147483647;
	setp.eq.s32 	%p208, %r143, 2146435072;
	setp.eq.s32 	%p209, %r681, 0;
	and.pred  	%p210, %p208, %p209;
	@%p210 bra 	$L__BB7_195;
	bra.uni 	$L__BB7_193;

$L__BB7_195:
	add.rn.f32 	%f650, %f51, 0fC2D20000;
	setp.gt.f64 	%p217, %fd148, 0d3FF0000000000000;
	selp.b32 	%r688, 2146435072, 0, %p217;
	mov.u32 	%r689, 0;
	xor.b32  	%r690, %r688, 2146435072;
	setp.lt.s32 	%p218, %r2, 0;
	selp.b32 	%r691, %r690, %r688, %p218;
	setp.eq.f32 	%p219, %f650, 0fBF800000;
	selp.b32 	%r692, 1072693248, %r691, %p219;
	mov.b64 	%fd998, {%r689, %r692};
	bra.uni 	$L__BB7_197;

$L__BB7_193:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r682, %temp}, %fd24;
	}
	and.b32  	%r683, %r142, 2147483647;
	setp.ne.s32 	%p211, %r683, 2146435072;
	setp.ne.s32 	%p212, %r682, 0;
	or.pred  	%p213, %p211, %p212;
	@%p213 bra 	$L__BB7_197;

	setp.gt.s32 	%p214, %r2, -1;
	selp.b32 	%r684, 2146435072, 0, %p214;
	mov.u32 	%r685, 0;
	setp.ne.s32 	%p215, %r143, 1071644672;
	and.pred  	%p216, %p215, %p4;
	or.b32  	%r686, %r684, -2147483648;
	selp.b32 	%r687, %r686, %r684, %p216;
	mov.b64 	%fd998, {%r685, %r687};

$L__BB7_197:
	add.rn.f32 	%f648, %f51, 0fC2D20000;
	mul.rn.f64 	%fd602, %fd998, 0d3FB999999999999A;
	setp.eq.f32 	%p220, %f648, 0f3F800000;
	selp.f64 	%fd603, 0d3FB999999999999A, %fd602, %p220;
	add.rn.f64 	%fd604, %fd147, %fd603;
	add.rn.f64 	%fd605, %fd144, %fd604;
	mul.rn.f64 	%fd606, %fd145, 0d3FB999999999999A;
	add.rn.f64 	%fd607, %fd606, %fd605;
	cvt.rn.f32.f64 	%f384, %fd131;
	cvt.f64.f32 	%fd608, %f384;
	mul.rn.f64 	%fd609, %fd608, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f385, %fd609;
	cvt.f64.f32 	%fd610, %f385;
	add.rn.f64 	%fd158, %fd607, %fd610;
	cvt.f64.f32 	%fd611, %f62;
	div.rn.f64 	%fd612, %fd611, 0d4066800000000000;
	mul.rn.f64 	%fd613, %fd612, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f91, %fd613;
	mul.rn.f32 	%f386, %f91, 0f3F22F983;
	cvt.rni.s32.f32 	%r1210, %f386;
	cvt.rn.f32.s32 	%f387, %r1210;
	mov.f32 	%f388, 0fBFC90FDA;
	fma.rn.f32 	%f389, %f387, %f388, %f91;
	mov.f32 	%f390, 0fB3A22168;
	fma.rn.f32 	%f391, %f387, %f390, %f389;
	mov.f32 	%f392, 0fA7C234C5;
	fma.rn.f32 	%f681, %f387, %f392, %f391;
	abs.f32 	%f93, %f91;
	setp.ltu.f32 	%p221, %f93, 0f47CE4780;
	mov.u32 	%r1206, %r1210;
	mov.f32 	%f678, %f681;
	@%p221 bra 	$L__BB7_205;

	setp.eq.f32 	%p222, %f93, 0f7F800000;
	@%p222 bra 	$L__BB7_204;
	bra.uni 	$L__BB7_199;

$L__BB7_204:
	mov.f32 	%f395, 0f00000000;
	mul.rn.f32 	%f678, %f91, %f395;
	mov.u32 	%r1206, 0;
	bra.uni 	$L__BB7_205;

$L__BB7_199:
	mov.b32 	%r145, %f91;
	bfe.u32 	%r694, %r145, 23, 8;
	add.s32 	%r146, %r694, -128;
	shl.b32 	%r695, %r145, 8;
	or.b32  	%r147, %r695, -2147483648;
	shr.u32 	%r148, %r146, 5;
	mov.u64 	%rd408, 0;
	mov.u32 	%r1203, 0;
	mov.u64 	%rd407, __cudart_i2opi_f;
	mov.u64 	%rd406, %rd1;

$L__BB7_200:
	.pragma "nounroll";
	ld.global.nc.u32 	%r696, [%rd407];
	mad.wide.u32 	%rd217, %r696, %r147, %rd408;
	shr.u64 	%rd408, %rd217, 32;
	st.local.u32 	[%rd406], %rd217;
	add.s64 	%rd407, %rd407, 4;
	add.s64 	%rd406, %rd406, 4;
	add.s32 	%r1203, %r1203, 1;
	setp.ne.s32 	%p223, %r1203, 6;
	@%p223 bra 	$L__BB7_200;

	st.local.u32 	[%rd1+24], %rd408;
	mov.u32 	%r697, 4;
	sub.s32 	%r151, %r697, %r148;
	mov.u32 	%r698, 6;
	sub.s32 	%r699, %r698, %r148;
	mul.wide.s32 	%rd218, %r699, 4;
	add.s64 	%rd219, %rd1, %rd218;
	ld.local.u32 	%r1204, [%rd219];
	ld.local.u32 	%r1205, [%rd219+-4];
	and.b32  	%r154, %r146, 31;
	setp.eq.s32 	%p224, %r154, 0;
	@%p224 bra 	$L__BB7_203;

	mov.u32 	%r700, 32;
	sub.s32 	%r701, %r700, %r154;
	shr.u32 	%r702, %r1205, %r701;
	shl.b32 	%r703, %r1204, %r154;
	add.s32 	%r1204, %r702, %r703;
	mul.wide.s32 	%rd220, %r151, 4;
	add.s64 	%rd221, %rd1, %rd220;
	ld.local.u32 	%r704, [%rd221];
	shr.u32 	%r705, %r704, %r701;
	shl.b32 	%r706, %r1205, %r154;
	add.s32 	%r1205, %r705, %r706;

$L__BB7_203:
	and.b32  	%r707, %r145, -2147483648;
	shr.u32 	%r708, %r1205, 30;
	shl.b32 	%r709, %r1204, 2;
	or.b32  	%r710, %r708, %r709;
	shr.u32 	%r711, %r710, 31;
	shr.u32 	%r712, %r1204, 30;
	add.s32 	%r713, %r711, %r712;
	neg.s32 	%r714, %r713;
	setp.eq.s32 	%p225, %r707, 0;
	selp.b32 	%r1206, %r713, %r714, %p225;
	setp.ne.s32 	%p226, %r711, 0;
	xor.b32  	%r715, %r707, -2147483648;
	selp.b32 	%r716, %r715, %r707, %p226;
	selp.b32 	%r717, -1, 0, %p226;
	xor.b32  	%r718, %r710, %r717;
	shl.b32 	%r719, %r1205, 2;
	xor.b32  	%r720, %r719, %r717;
	cvt.u64.u32 	%rd222, %r718;
	cvt.u64.u32 	%rd223, %r720;
	bfi.b64 	%rd224, %rd222, %rd223, 32, 32;
	cvt.rn.f64.s64 	%fd614, %rd224;
	mul.rn.f64 	%fd615, %fd614, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f393, %fd615;
	setp.eq.s32 	%p227, %r716, 0;
	neg.f32 	%f394, %f393;
	selp.f32 	%f678, %f393, %f394, %p227;

$L__BB7_205:
	and.b32  	%r161, %r1206, 1;
	setp.eq.s32 	%p228, %r161, 0;
	selp.f32 	%f97, %f678, 0f3F800000, %p228;
	mul.rn.f32 	%f98, %f678, %f678;
	mov.f32 	%f679, 0fB94D4153;
	@%p228 bra 	$L__BB7_207;

	mov.f32 	%f397, 0fBAB607ED;
	mov.f32 	%f398, 0f37CBAC00;
	fma.rn.f32 	%f679, %f398, %f98, %f397;

$L__BB7_207:
	selp.f32 	%f399, 0f3C0885E4, 0f3D2AAABB, %p228;
	fma.rn.f32 	%f400, %f679, %f98, %f399;
	selp.f32 	%f401, 0fBE2AAAA8, 0fBEFFFFFF, %p228;
	fma.rn.f32 	%f402, %f400, %f98, %f401;
	mov.f32 	%f403, 0f00000000;
	fma.rn.f32 	%f404, %f98, %f97, %f403;
	fma.rn.f32 	%f680, %f402, %f404, %f97;
	and.b32  	%r722, %r1206, 2;
	setp.eq.s32 	%p230, %r722, 0;
	@%p230 bra 	$L__BB7_209;

	mov.f32 	%f406, 0fBF800000;
	fma.rn.f32 	%f680, %f680, %f406, %f403;

$L__BB7_209:
	@%p221 bra 	$L__BB7_217;

	setp.eq.f32 	%p232, %f93, 0f7F800000;
	@%p232 bra 	$L__BB7_216;
	bra.uni 	$L__BB7_211;

$L__BB7_216:
	mov.f32 	%f409, 0f00000000;
	mul.rn.f32 	%f681, %f91, %f409;
	mov.u32 	%r1210, 0;
	bra.uni 	$L__BB7_217;

$L__BB7_211:
	mov.b32 	%r162, %f91;
	bfe.u32 	%r724, %r162, 23, 8;
	add.s32 	%r163, %r724, -128;
	shl.b32 	%r725, %r162, 8;
	or.b32  	%r164, %r725, -2147483648;
	shr.u32 	%r165, %r163, 5;
	mov.u64 	%rd409, 0;
	mov.u32 	%r1207, 0;
	mov.u64 	%rd228, __cudart_i2opi_f;
	mov.u64 	%rd410, %rd409;

$L__BB7_212:
	.pragma "nounroll";
	shl.b64 	%rd227, %rd409, 2;
	add.s64 	%rd229, %rd228, %rd227;
	ld.global.nc.u32 	%r726, [%rd229];
	mad.wide.u32 	%rd230, %r726, %r164, %rd410;
	shr.u64 	%rd410, %rd230, 32;
	add.s64 	%rd231, %rd1, %rd227;
	st.local.u32 	[%rd231], %rd230;
	add.s32 	%r1207, %r1207, 1;
	cvt.s64.s32 	%rd409, %r1207;
	setp.ne.s32 	%p233, %r1207, 6;
	@%p233 bra 	$L__BB7_212;

	st.local.u32 	[%rd1+24], %rd410;
	mov.u32 	%r727, 4;
	sub.s32 	%r168, %r727, %r165;
	mov.u32 	%r728, 6;
	sub.s32 	%r729, %r728, %r165;
	mul.wide.s32 	%rd232, %r729, 4;
	add.s64 	%rd233, %rd1, %rd232;
	ld.local.u32 	%r1208, [%rd233];
	ld.local.u32 	%r1209, [%rd233+-4];
	and.b32  	%r171, %r163, 31;
	setp.eq.s32 	%p234, %r171, 0;
	@%p234 bra 	$L__BB7_215;

	mov.u32 	%r730, 32;
	sub.s32 	%r731, %r730, %r171;
	shr.u32 	%r732, %r1209, %r731;
	shl.b32 	%r733, %r1208, %r171;
	add.s32 	%r1208, %r732, %r733;
	mul.wide.s32 	%rd234, %r168, 4;
	add.s64 	%rd235, %rd1, %rd234;
	ld.local.u32 	%r734, [%rd235];
	shr.u32 	%r735, %r734, %r731;
	shl.b32 	%r736, %r1209, %r171;
	add.s32 	%r1209, %r735, %r736;

$L__BB7_215:
	and.b32  	%r737, %r162, -2147483648;
	shr.u32 	%r738, %r1209, 30;
	shl.b32 	%r739, %r1208, 2;
	or.b32  	%r740, %r738, %r739;
	shr.u32 	%r741, %r740, 31;
	shr.u32 	%r742, %r1208, 30;
	add.s32 	%r743, %r741, %r742;
	neg.s32 	%r744, %r743;
	setp.eq.s32 	%p235, %r737, 0;
	selp.b32 	%r1210, %r743, %r744, %p235;
	setp.ne.s32 	%p236, %r741, 0;
	xor.b32  	%r745, %r737, -2147483648;
	selp.b32 	%r746, %r745, %r737, %p236;
	selp.b32 	%r747, -1, 0, %p236;
	xor.b32  	%r748, %r740, %r747;
	shl.b32 	%r749, %r1209, 2;
	xor.b32  	%r750, %r749, %r747;
	cvt.u64.u32 	%rd236, %r748;
	cvt.u64.u32 	%rd237, %r750;
	bfi.b64 	%rd238, %rd236, %rd237, 32, 32;
	cvt.rn.f64.s64 	%fd616, %rd238;
	mul.rn.f64 	%fd617, %fd616, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f407, %fd617;
	setp.eq.s32 	%p237, %r746, 0;
	neg.f32 	%f408, %f407;
	selp.f32 	%f681, %f407, %f408, %p237;

$L__BB7_217:
	add.s32 	%r178, %r1210, 1;
	and.b32  	%r179, %r178, 1;
	setp.eq.s32 	%p5, %r179, 0;
	mul.rn.f32 	%f107, %f681, %f681;
	mov.f32 	%f682, 0fB94D4153;
	@%p5 bra 	$L__BB7_219;

	mov.f32 	%f411, 0fBAB607ED;
	mov.f32 	%f412, 0f37CBAC00;
	fma.rn.f32 	%f682, %f412, %f107, %f411;

$L__BB7_219:
	selp.f32 	%f413, %f681, 0f3F800000, %p5;
	selp.f32 	%f414, 0f3C0885E4, 0f3D2AAABB, %p5;
	fma.rn.f32 	%f415, %f682, %f107, %f414;
	selp.f32 	%f416, 0fBE2AAAA8, 0fBEFFFFFF, %p5;
	fma.rn.f32 	%f417, %f415, %f107, %f416;
	mov.f32 	%f418, 0f00000000;
	fma.rn.f32 	%f419, %f107, %f413, %f418;
	fma.rn.f32 	%f683, %f417, %f419, %f413;
	and.b32  	%r752, %r178, 2;
	setp.eq.s32 	%p239, %r752, 0;
	@%p239 bra 	$L__BB7_221;

	mov.f32 	%f421, 0fBF800000;
	fma.rn.f32 	%f683, %f683, %f421, %f418;

$L__BB7_221:
	ld.param.u32 	%r1170, [bd09_to_wgs84_exact_cuda_float_param_4];
	cvt.f64.f32 	%fd618, %f680;
	mul.rn.f64 	%fd619, %fd618, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd620, %fd619, %fd618;
	add.rn.f64 	%fd621, %fd620, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f422, %fd621;
	sqrt.rn.f32 	%f423, %f422;
	mov.f32 	%f424, 0fCAC2A60A;
	div.rn.f32 	%f425, %f424, %f423;
	mul.rn.f32 	%f426, %f425, %f683;
	cvt.f64.f32 	%fd622, %f426;
	mul.rn.f64 	%fd623, %fd622, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f427, %fd158;
	cvt.f64.f32 	%fd624, %f427;
	mul.rn.f64 	%fd625, %fd624, 0d4066800000000000;
	div.rn.f64 	%fd626, %fd625, %fd623;
	cvt.rn.f32.f64 	%f428, %fd626;
	add.rn.f32 	%f711, %f51, %f428;
	mul.rn.f32 	%f429, %f423, %f422;
	cvt.f64.f32 	%fd627, %f429;
	mov.f64 	%fd628, 0dC1582B102DE355C1;
	div.rn.f64 	%fd629, %fd628, %fd627;
	mul.rn.f64 	%fd630, %fd629, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f430, %fd146;
	cvt.f64.f32 	%fd631, %f430;
	mul.rn.f64 	%fd632, %fd631, 0d4066800000000000;
	div.rn.f64 	%fd633, %fd632, %fd630;
	cvt.rn.f32.f64 	%f431, %fd633;
	add.rn.f32 	%f712, %f62, %f431;
	setp.lt.s32 	%p240, %r1170, 1;
	@%p240 bra 	$L__BB7_454;

	and.b32  	%r180, %r2, 2147483647;
	setp.gt.s32 	%p241, %r2, -1;
	selp.b32 	%r181, 2146435072, 0, %p241;
	mov.u32 	%r1211, 0;
	or.b32  	%r182, %r181, -2147483648;
	mov.u64 	%rd247, __cudart_i2opi_f;

$L__BB7_223:
	add.rn.f32 	%f117, %f712, 0fC20C0000;
	add.rn.f32 	%f118, %f711, 0fC2D20000;
	cvt.f64.f32 	%fd159, %f118;
	mul.rn.f64 	%fd634, %fd159, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f119, %fd634;
	cvt.f64.f32 	%fd160, %f117;
	mul.rn.f64 	%fd635, %fd160, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f120, %fd635;
	cvt.f64.f32 	%fd161, %f119;
	mul.rn.f64 	%fd162, %fd161, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r754, %temp}, %fd162;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r755}, %fd162;
	}
	and.b32  	%r756, %r755, 2147483647;
	setp.eq.s32 	%p242, %r756, 2146435072;
	setp.eq.s32 	%p243, %r754, 0;
	and.pred  	%p244, %p243, %p242;
	@%p244 bra 	$L__BB7_226;
	bra.uni 	$L__BB7_224;

$L__BB7_226:
	mov.f64 	%fd645, 0d0000000000000000;
	mul.rn.f64 	%fd999, %fd162, %fd645;
	mov.u32 	%r1212, 0;
	bra.uni 	$L__BB7_227;

$L__BB7_224:
	mul.rn.f64 	%fd636, %fd162, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1212, %fd636;
	st.local.u32 	[%rd8], %r1212;
	cvt.rn.f64.s32 	%fd637, %r1212;
	neg.f64 	%fd638, %fd637;
	mov.f64 	%fd639, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd640, %fd638, %fd639, %fd162;
	mov.f64 	%fd641, 0d3C91A62633145C00;
	fma.rn.f64 	%fd642, %fd638, %fd641, %fd640;
	mov.f64 	%fd643, 0d397B839A252049C0;
	fma.rn.f64 	%fd999, %fd638, %fd643, %fd642;
	abs.f64 	%fd644, %fd162;
	setp.ltu.f64 	%p245, %fd644, 0d41E0000000000000;
	@%p245 bra 	$L__BB7_227;

	{ // callseq 82, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd162;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd999, [retval0+0];
	} // callseq 82
	ld.local.u32 	%r1212, [%rd8];

$L__BB7_227:
	and.b32  	%r758, %r1212, 1;
	shl.b32 	%r759, %r1212, 3;
	and.b32  	%r760, %r759, 8;
	setp.eq.s32 	%p246, %r758, 0;
	selp.f64 	%fd646, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p246;
	mul.wide.s32 	%rd240, %r760, 8;
	add.s64 	%rd242, %rd165, %rd240;
	ld.global.nc.f64 	%fd647, [%rd242+8];
	mul.rn.f64 	%fd167, %fd999, %fd999;
	fma.rn.f64 	%fd648, %fd646, %fd167, %fd647;
	ld.global.nc.f64 	%fd649, [%rd242+16];
	fma.rn.f64 	%fd650, %fd648, %fd167, %fd649;
	ld.global.nc.f64 	%fd651, [%rd242+24];
	fma.rn.f64 	%fd652, %fd650, %fd167, %fd651;
	ld.global.nc.f64 	%fd653, [%rd242+32];
	fma.rn.f64 	%fd654, %fd652, %fd167, %fd653;
	ld.global.nc.f64 	%fd655, [%rd242+40];
	fma.rn.f64 	%fd656, %fd654, %fd167, %fd655;
	ld.global.nc.f64 	%fd657, [%rd242+48];
	fma.rn.f64 	%fd168, %fd656, %fd167, %fd657;
	fma.rn.f64 	%fd1001, %fd168, %fd999, %fd999;
	@%p246 bra 	$L__BB7_229;

	mov.f64 	%fd658, 0d3FF0000000000000;
	fma.rn.f64 	%fd1001, %fd168, %fd167, %fd658;

$L__BB7_229:
	and.b32  	%r761, %r1212, 2;
	setp.eq.s32 	%p247, %r761, 0;
	@%p247 bra 	$L__BB7_231;

	mov.f64 	%fd659, 0d0000000000000000;
	mov.f64 	%fd660, 0dBFF0000000000000;
	fma.rn.f64 	%fd1001, %fd1001, %fd660, %fd659;

$L__BB7_231:
	add.rn.f64 	%fd174, %fd161, %fd161;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r762, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r763}, %fd174;
	}
	and.b32  	%r764, %r763, 2147483647;
	setp.eq.s32 	%p248, %r764, 2146435072;
	setp.eq.s32 	%p249, %r762, 0;
	and.pred  	%p250, %p249, %p248;
	@%p250 bra 	$L__BB7_234;
	bra.uni 	$L__BB7_232;

$L__BB7_234:
	mov.f64 	%fd670, 0d0000000000000000;
	mul.rn.f64 	%fd1002, %fd174, %fd670;
	mov.u32 	%r1213, 0;
	bra.uni 	$L__BB7_235;

$L__BB7_232:
	mul.rn.f64 	%fd661, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1213, %fd661;
	st.local.u32 	[%rd8], %r1213;
	cvt.rn.f64.s32 	%fd662, %r1213;
	neg.f64 	%fd663, %fd662;
	mov.f64 	%fd664, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd665, %fd663, %fd664, %fd174;
	mov.f64 	%fd666, 0d3C91A62633145C00;
	fma.rn.f64 	%fd667, %fd663, %fd666, %fd665;
	mov.f64 	%fd668, 0d397B839A252049C0;
	fma.rn.f64 	%fd1002, %fd663, %fd668, %fd667;
	abs.f64 	%fd669, %fd174;
	setp.ltu.f64 	%p251, %fd669, 0d41E0000000000000;
	@%p251 bra 	$L__BB7_235;

	{ // callseq 83, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1002, [retval0+0];
	} // callseq 83
	ld.local.u32 	%r1213, [%rd8];

$L__BB7_235:
	and.b32  	%r766, %r1213, 1;
	shl.b32 	%r767, %r1213, 3;
	and.b32  	%r768, %r767, 8;
	setp.eq.s32 	%p252, %r766, 0;
	selp.f64 	%fd671, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p252;
	mul.wide.s32 	%rd244, %r768, 8;
	add.s64 	%rd246, %rd165, %rd244;
	ld.global.nc.f64 	%fd672, [%rd246+8];
	mul.rn.f64 	%fd179, %fd1002, %fd1002;
	fma.rn.f64 	%fd673, %fd671, %fd179, %fd672;
	ld.global.nc.f64 	%fd674, [%rd246+16];
	fma.rn.f64 	%fd675, %fd673, %fd179, %fd674;
	ld.global.nc.f64 	%fd676, [%rd246+24];
	fma.rn.f64 	%fd677, %fd675, %fd179, %fd676;
	ld.global.nc.f64 	%fd678, [%rd246+32];
	fma.rn.f64 	%fd679, %fd677, %fd179, %fd678;
	ld.global.nc.f64 	%fd680, [%rd246+40];
	fma.rn.f64 	%fd681, %fd679, %fd179, %fd680;
	ld.global.nc.f64 	%fd682, [%rd246+48];
	fma.rn.f64 	%fd180, %fd681, %fd179, %fd682;
	fma.rn.f64 	%fd1004, %fd180, %fd1002, %fd1002;
	@%p252 bra 	$L__BB7_237;

	mov.f64 	%fd683, 0d3FF0000000000000;
	fma.rn.f64 	%fd1004, %fd180, %fd179, %fd683;

$L__BB7_237:
	and.b32  	%r769, %r1213, 2;
	setp.eq.s32 	%p253, %r769, 0;
	@%p253 bra 	$L__BB7_239;

	mov.f64 	%fd684, 0d0000000000000000;
	mov.f64 	%fd685, 0dBFF0000000000000;
	fma.rn.f64 	%fd1004, %fd1004, %fd685, %fd684;

$L__BB7_239:
	mul.rn.f64 	%fd686, %fd1004, 0d4034000000000000;
	mul.rn.f64 	%fd687, %fd1001, 0d4034000000000000;
	add.rn.f64 	%fd186, %fd687, %fd686;
	mul.rn.f32 	%f432, %f120, 0f3F22F983;
	cvt.rni.s32.f32 	%r1217, %f432;
	cvt.rn.f32.s32 	%f433, %r1217;
	mov.f32 	%f434, 0fBFC90FDA;
	fma.rn.f32 	%f435, %f433, %f434, %f120;
	mov.f32 	%f436, 0fB3A22168;
	fma.rn.f32 	%f437, %f433, %f436, %f435;
	mov.f32 	%f438, 0fA7C234C5;
	fma.rn.f32 	%f686, %f433, %f438, %f437;
	abs.f32 	%f122, %f120;
	setp.ltu.f32 	%p254, %f122, 0f47CE4780;
	@%p254 bra 	$L__BB7_247;

	setp.eq.f32 	%p255, %f122, 0f7F800000;
	@%p255 bra 	$L__BB7_246;
	bra.uni 	$L__BB7_241;

$L__BB7_246:
	mov.f32 	%f441, 0f00000000;
	mul.rn.f32 	%f686, %f120, %f441;
	mov.u32 	%r1217, 0;
	bra.uni 	$L__BB7_247;

$L__BB7_241:
	mov.b32 	%r191, %f120;
	bfe.u32 	%r771, %r191, 23, 8;
	add.s32 	%r192, %r771, -128;
	shl.b32 	%r772, %r191, 8;
	or.b32  	%r193, %r772, -2147483648;
	shr.u32 	%r194, %r192, 5;
	mov.u64 	%rd413, 0;
	mov.u32 	%r1214, 0;
	mov.u64 	%rd411, %rd1;
	mov.u64 	%rd412, %rd247;

$L__BB7_242:
	.pragma "nounroll";
	ld.global.nc.u32 	%r773, [%rd412];
	mad.wide.u32 	%rd249, %r773, %r193, %rd413;
	shr.u64 	%rd413, %rd249, 32;
	st.local.u32 	[%rd411], %rd249;
	add.s64 	%rd412, %rd412, 4;
	add.s64 	%rd411, %rd411, 4;
	add.s32 	%r1214, %r1214, 1;
	setp.ne.s32 	%p256, %r1214, 6;
	@%p256 bra 	$L__BB7_242;

	st.local.u32 	[%rd1+24], %rd413;
	mov.u32 	%r774, 4;
	sub.s32 	%r197, %r774, %r194;
	mov.u32 	%r775, 6;
	sub.s32 	%r776, %r775, %r194;
	mul.wide.s32 	%rd250, %r776, 4;
	add.s64 	%rd251, %rd1, %rd250;
	ld.local.u32 	%r1215, [%rd251];
	ld.local.u32 	%r1216, [%rd251+-4];
	and.b32  	%r200, %r192, 31;
	setp.eq.s32 	%p257, %r200, 0;
	@%p257 bra 	$L__BB7_245;

	mov.u32 	%r777, 32;
	sub.s32 	%r778, %r777, %r200;
	shr.u32 	%r779, %r1216, %r778;
	shl.b32 	%r780, %r1215, %r200;
	add.s32 	%r1215, %r779, %r780;
	mul.wide.s32 	%rd252, %r197, 4;
	add.s64 	%rd253, %rd1, %rd252;
	ld.local.u32 	%r781, [%rd253];
	shr.u32 	%r782, %r781, %r778;
	shl.b32 	%r783, %r1216, %r200;
	add.s32 	%r1216, %r782, %r783;

$L__BB7_245:
	and.b32  	%r784, %r191, -2147483648;
	shr.u32 	%r785, %r1216, 30;
	shl.b32 	%r786, %r1215, 2;
	or.b32  	%r787, %r785, %r786;
	shr.u32 	%r788, %r787, 31;
	shr.u32 	%r789, %r1215, 30;
	add.s32 	%r790, %r788, %r789;
	neg.s32 	%r791, %r790;
	setp.eq.s32 	%p258, %r784, 0;
	selp.b32 	%r1217, %r790, %r791, %p258;
	setp.ne.s32 	%p259, %r788, 0;
	xor.b32  	%r792, %r784, -2147483648;
	selp.b32 	%r793, %r792, %r784, %p259;
	selp.b32 	%r794, -1, 0, %p259;
	xor.b32  	%r795, %r787, %r794;
	shl.b32 	%r796, %r1216, 2;
	xor.b32  	%r797, %r796, %r794;
	cvt.u64.u32 	%rd254, %r795;
	cvt.u64.u32 	%rd255, %r797;
	bfi.b64 	%rd256, %rd254, %rd255, 32, 32;
	cvt.rn.f64.s64 	%fd688, %rd256;
	mul.rn.f64 	%fd689, %fd688, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f439, %fd689;
	setp.eq.s32 	%p260, %r793, 0;
	neg.f32 	%f440, %f439;
	selp.f32 	%f686, %f439, %f440, %p260;

$L__BB7_247:
	and.b32  	%r207, %r1217, 1;
	setp.eq.s32 	%p261, %r207, 0;
	selp.f32 	%f126, %f686, 0f3F800000, %p261;
	mul.rn.f32 	%f127, %f686, %f686;
	mov.f32 	%f687, 0fB94D4153;
	@%p261 bra 	$L__BB7_249;

	mov.f32 	%f443, 0fBAB607ED;
	mov.f32 	%f444, 0f37CBAC00;
	fma.rn.f32 	%f687, %f444, %f127, %f443;

$L__BB7_249:
	selp.f32 	%f445, 0f3C0885E4, 0f3D2AAABB, %p261;
	fma.rn.f32 	%f446, %f687, %f127, %f445;
	selp.f32 	%f447, 0fBE2AAAA8, 0fBEFFFFFF, %p261;
	fma.rn.f32 	%f448, %f446, %f127, %f447;
	mov.f32 	%f449, 0f00000000;
	fma.rn.f32 	%f450, %f127, %f126, %f449;
	fma.rn.f32 	%f688, %f448, %f450, %f126;
	and.b32  	%r799, %r1217, 2;
	setp.eq.s32 	%p263, %r799, 0;
	@%p263 bra 	$L__BB7_251;

	mov.f32 	%f452, 0fBF800000;
	fma.rn.f32 	%f688, %f688, %f452, %f449;

$L__BB7_251:
	cvt.f64.f32 	%fd187, %f120;
	div.rn.f64 	%fd188, %fd187, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r800, %temp}, %fd188;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r801}, %fd188;
	}
	and.b32  	%r802, %r801, 2147483647;
	setp.eq.s32 	%p264, %r802, 2146435072;
	setp.eq.s32 	%p265, %r800, 0;
	and.pred  	%p266, %p265, %p264;
	@%p266 bra 	$L__BB7_254;
	bra.uni 	$L__BB7_252;

$L__BB7_254:
	mov.f64 	%fd699, 0d0000000000000000;
	mul.rn.f64 	%fd1005, %fd188, %fd699;
	mov.u32 	%r1218, 0;
	bra.uni 	$L__BB7_255;

$L__BB7_252:
	mul.rn.f64 	%fd690, %fd188, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1218, %fd690;
	st.local.u32 	[%rd1], %r1218;
	cvt.rn.f64.s32 	%fd691, %r1218;
	neg.f64 	%fd692, %fd691;
	mov.f64 	%fd693, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd694, %fd692, %fd693, %fd188;
	mov.f64 	%fd695, 0d3C91A62633145C00;
	fma.rn.f64 	%fd696, %fd692, %fd695, %fd694;
	mov.f64 	%fd697, 0d397B839A252049C0;
	fma.rn.f64 	%fd1005, %fd692, %fd697, %fd696;
	abs.f64 	%fd698, %fd188;
	setp.ltu.f64 	%p267, %fd698, 0d41E0000000000000;
	@%p267 bra 	$L__BB7_255;

	{ // callseq 84, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd188;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1005, [retval0+0];
	} // callseq 84
	ld.local.u32 	%r1218, [%rd1];

$L__BB7_255:
	and.b32  	%r804, %r1218, 1;
	shl.b32 	%r805, %r1218, 3;
	and.b32  	%r806, %r805, 8;
	setp.eq.s32 	%p268, %r804, 0;
	selp.f64 	%fd700, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p268;
	mul.wide.s32 	%rd258, %r806, 8;
	add.s64 	%rd260, %rd165, %rd258;
	ld.global.nc.f64 	%fd701, [%rd260+8];
	mul.rn.f64 	%fd193, %fd1005, %fd1005;
	fma.rn.f64 	%fd702, %fd700, %fd193, %fd701;
	ld.global.nc.f64 	%fd703, [%rd260+16];
	fma.rn.f64 	%fd704, %fd702, %fd193, %fd703;
	ld.global.nc.f64 	%fd705, [%rd260+24];
	fma.rn.f64 	%fd706, %fd704, %fd193, %fd705;
	ld.global.nc.f64 	%fd707, [%rd260+32];
	fma.rn.f64 	%fd708, %fd706, %fd193, %fd707;
	ld.global.nc.f64 	%fd709, [%rd260+40];
	fma.rn.f64 	%fd710, %fd708, %fd193, %fd709;
	ld.global.nc.f64 	%fd711, [%rd260+48];
	fma.rn.f64 	%fd194, %fd710, %fd193, %fd711;
	fma.rn.f64 	%fd1007, %fd194, %fd1005, %fd1005;
	@%p268 bra 	$L__BB7_257;

	mov.f64 	%fd712, 0d3FF0000000000000;
	fma.rn.f64 	%fd1007, %fd194, %fd193, %fd712;

$L__BB7_257:
	and.b32  	%r807, %r1218, 2;
	setp.eq.s32 	%p269, %r807, 0;
	@%p269 bra 	$L__BB7_259;

	mov.f64 	%fd713, 0d0000000000000000;
	mov.f64 	%fd714, 0dBFF0000000000000;
	fma.rn.f64 	%fd1007, %fd1007, %fd714, %fd713;

$L__BB7_259:
	mul.rn.f64 	%fd715, %fd1007, 0d4044000000000000;
	cvt.f64.f32 	%fd716, %f688;
	mul.rn.f64 	%fd717, %fd716, 0d4034000000000000;
	add.rn.f64 	%fd200, %fd717, %fd715;
	div.rn.f64 	%fd201, %fd187, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r808, %temp}, %fd201;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r809}, %fd201;
	}
	and.b32  	%r810, %r809, 2147483647;
	setp.eq.s32 	%p270, %r810, 2146435072;
	setp.eq.s32 	%p271, %r808, 0;
	and.pred  	%p272, %p271, %p270;
	@%p272 bra 	$L__BB7_262;
	bra.uni 	$L__BB7_260;

$L__BB7_262:
	mov.f64 	%fd727, 0d0000000000000000;
	mul.rn.f64 	%fd1008, %fd201, %fd727;
	mov.u32 	%r1219, 0;
	bra.uni 	$L__BB7_263;

$L__BB7_260:
	mul.rn.f64 	%fd718, %fd201, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1219, %fd718;
	st.local.u32 	[%rd1], %r1219;
	cvt.rn.f64.s32 	%fd719, %r1219;
	neg.f64 	%fd720, %fd719;
	mov.f64 	%fd721, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd722, %fd720, %fd721, %fd201;
	mov.f64 	%fd723, 0d3C91A62633145C00;
	fma.rn.f64 	%fd724, %fd720, %fd723, %fd722;
	mov.f64 	%fd725, 0d397B839A252049C0;
	fma.rn.f64 	%fd1008, %fd720, %fd725, %fd724;
	abs.f64 	%fd726, %fd201;
	setp.ltu.f64 	%p273, %fd726, 0d41E0000000000000;
	@%p273 bra 	$L__BB7_263;

	{ // callseq 85, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd201;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1008, [retval0+0];
	} // callseq 85
	ld.local.u32 	%r1219, [%rd1];

$L__BB7_263:
	and.b32  	%r812, %r1219, 1;
	shl.b32 	%r813, %r1219, 3;
	and.b32  	%r814, %r813, 8;
	setp.eq.s32 	%p274, %r812, 0;
	selp.f64 	%fd728, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p274;
	mul.wide.s32 	%rd262, %r814, 8;
	add.s64 	%rd264, %rd165, %rd262;
	ld.global.nc.f64 	%fd729, [%rd264+8];
	mul.rn.f64 	%fd206, %fd1008, %fd1008;
	fma.rn.f64 	%fd730, %fd728, %fd206, %fd729;
	ld.global.nc.f64 	%fd731, [%rd264+16];
	fma.rn.f64 	%fd732, %fd730, %fd206, %fd731;
	ld.global.nc.f64 	%fd733, [%rd264+24];
	fma.rn.f64 	%fd734, %fd732, %fd206, %fd733;
	ld.global.nc.f64 	%fd735, [%rd264+32];
	fma.rn.f64 	%fd736, %fd734, %fd206, %fd735;
	ld.global.nc.f64 	%fd737, [%rd264+40];
	fma.rn.f64 	%fd738, %fd736, %fd206, %fd737;
	ld.global.nc.f64 	%fd739, [%rd264+48];
	fma.rn.f64 	%fd207, %fd738, %fd206, %fd739;
	fma.rn.f64 	%fd1010, %fd207, %fd1008, %fd1008;
	@%p274 bra 	$L__BB7_265;

	mov.f64 	%fd740, 0d3FF0000000000000;
	fma.rn.f64 	%fd1010, %fd207, %fd206, %fd740;

$L__BB7_265:
	and.b32  	%r815, %r1219, 2;
	setp.eq.s32 	%p275, %r815, 0;
	@%p275 bra 	$L__BB7_267;

	mov.f64 	%fd741, 0d0000000000000000;
	mov.f64 	%fd742, 0dBFF0000000000000;
	fma.rn.f64 	%fd1010, %fd1010, %fd742, %fd741;

$L__BB7_267:
	mul.rn.f64 	%fd743, %fd1010, 0d4064000000000000;
	add.rn.f64 	%fd213, %fd200, %fd743;
	div.rn.f64 	%fd214, %fd187, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r816, %temp}, %fd214;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r817}, %fd214;
	}
	and.b32  	%r818, %r817, 2147483647;
	setp.eq.s32 	%p276, %r818, 2146435072;
	setp.eq.s32 	%p277, %r816, 0;
	and.pred  	%p278, %p277, %p276;
	@%p278 bra 	$L__BB7_270;
	bra.uni 	$L__BB7_268;

$L__BB7_270:
	mov.f64 	%fd753, 0d0000000000000000;
	mul.rn.f64 	%fd1011, %fd214, %fd753;
	mov.u32 	%r1220, 0;
	bra.uni 	$L__BB7_271;

$L__BB7_268:
	mul.rn.f64 	%fd744, %fd214, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1220, %fd744;
	st.local.u32 	[%rd1], %r1220;
	cvt.rn.f64.s32 	%fd745, %r1220;
	neg.f64 	%fd746, %fd745;
	mov.f64 	%fd747, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd748, %fd746, %fd747, %fd214;
	mov.f64 	%fd749, 0d3C91A62633145C00;
	fma.rn.f64 	%fd750, %fd746, %fd749, %fd748;
	mov.f64 	%fd751, 0d397B839A252049C0;
	fma.rn.f64 	%fd1011, %fd746, %fd751, %fd750;
	abs.f64 	%fd752, %fd214;
	setp.ltu.f64 	%p279, %fd752, 0d41E0000000000000;
	@%p279 bra 	$L__BB7_271;

	{ // callseq 86, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd214;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1011, [retval0+0];
	} // callseq 86
	ld.local.u32 	%r1220, [%rd1];

$L__BB7_271:
	and.b32  	%r820, %r1220, 1;
	shl.b32 	%r821, %r1220, 3;
	and.b32  	%r822, %r821, 8;
	setp.eq.s32 	%p280, %r820, 0;
	selp.f64 	%fd754, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p280;
	mul.wide.s32 	%rd266, %r822, 8;
	add.s64 	%rd268, %rd165, %rd266;
	ld.global.nc.f64 	%fd755, [%rd268+8];
	mul.rn.f64 	%fd219, %fd1011, %fd1011;
	fma.rn.f64 	%fd756, %fd754, %fd219, %fd755;
	ld.global.nc.f64 	%fd757, [%rd268+16];
	fma.rn.f64 	%fd758, %fd756, %fd219, %fd757;
	ld.global.nc.f64 	%fd759, [%rd268+24];
	fma.rn.f64 	%fd760, %fd758, %fd219, %fd759;
	ld.global.nc.f64 	%fd761, [%rd268+32];
	fma.rn.f64 	%fd762, %fd760, %fd219, %fd761;
	ld.global.nc.f64 	%fd763, [%rd268+40];
	fma.rn.f64 	%fd764, %fd762, %fd219, %fd763;
	ld.global.nc.f64 	%fd765, [%rd268+48];
	fma.rn.f64 	%fd220, %fd764, %fd219, %fd765;
	fma.rn.f64 	%fd1013, %fd220, %fd1011, %fd1011;
	@%p280 bra 	$L__BB7_273;

	mov.f64 	%fd766, 0d3FF0000000000000;
	fma.rn.f64 	%fd1013, %fd220, %fd219, %fd766;

$L__BB7_273:
	and.b32  	%r823, %r1220, 2;
	setp.eq.s32 	%p281, %r823, 0;
	@%p281 bra 	$L__BB7_275;

	mov.f64 	%fd767, 0d0000000000000000;
	mov.f64 	%fd768, 0dBFF0000000000000;
	fma.rn.f64 	%fd1013, %fd1013, %fd768, %fd767;

$L__BB7_275:
	mul.rn.f64 	%fd769, %fd1013, 0d4074000000000000;
	add.rn.f64 	%fd226, %fd213, %fd769;
	mul.rn.f32 	%f453, %f119, 0f3F22F983;
	cvt.rni.s32.f32 	%r1223, %f453;
	cvt.rn.f32.s32 	%f454, %r1223;
	mov.f32 	%f455, 0fBFC90FDA;
	fma.rn.f32 	%f456, %f454, %f455, %f119;
	mov.f32 	%f457, 0fB3A22168;
	fma.rn.f32 	%f458, %f454, %f457, %f456;
	mov.f32 	%f459, 0fA7C234C5;
	fma.rn.f32 	%f689, %f454, %f459, %f458;
	abs.f32 	%f134, %f119;
	setp.ltu.f32 	%p282, %f134, 0f47CE4780;
	@%p282 bra 	$L__BB7_283;

	setp.eq.f32 	%p283, %f134, 0f7F800000;
	@%p283 bra 	$L__BB7_282;
	bra.uni 	$L__BB7_277;

$L__BB7_282:
	mov.f32 	%f462, 0f00000000;
	mul.rn.f32 	%f689, %f119, %f462;
	mov.u32 	%r1223, 0;
	bra.uni 	$L__BB7_283;

$L__BB7_277:
	mov.b32 	%r218, %f119;
	bfe.u32 	%r824, %r218, 23, 8;
	add.s32 	%r219, %r824, -128;
	shl.b32 	%r825, %r218, 8;
	or.b32  	%r220, %r825, -2147483648;
	shr.u32 	%r221, %r219, 5;
	mov.u64 	%rd414, 0;
	mov.u64 	%rd415, %rd414;

$L__BB7_278:
	.pragma "nounroll";
	shl.b64 	%rd271, %rd414, 2;
	mov.u64 	%rd272, __cudart_i2opi_f;
	add.s64 	%rd273, %rd272, %rd271;
	ld.global.nc.u32 	%r826, [%rd273];
	mad.wide.u32 	%rd274, %r826, %r220, %rd415;
	shr.u64 	%rd415, %rd274, 32;
	add.s64 	%rd275, %rd1, %rd271;
	st.local.u32 	[%rd275], %rd274;
	cvt.u32.u64 	%r827, %rd414;
	add.s32 	%r828, %r827, 1;
	cvt.s64.s32 	%rd414, %r828;
	setp.ne.s32 	%p284, %r828, 6;
	@%p284 bra 	$L__BB7_278;

	st.local.u32 	[%rd1+24], %rd415;
	mov.u32 	%r829, 4;
	sub.s32 	%r222, %r829, %r221;
	mov.u32 	%r830, 6;
	sub.s32 	%r831, %r830, %r221;
	mul.wide.s32 	%rd276, %r831, 4;
	add.s64 	%rd277, %rd1, %rd276;
	ld.local.u32 	%r1221, [%rd277];
	ld.local.u32 	%r1222, [%rd277+-4];
	and.b32  	%r225, %r219, 31;
	setp.eq.s32 	%p285, %r225, 0;
	@%p285 bra 	$L__BB7_281;

	mov.u32 	%r832, 32;
	sub.s32 	%r833, %r832, %r225;
	shr.u32 	%r834, %r1222, %r833;
	shl.b32 	%r835, %r1221, %r225;
	add.s32 	%r1221, %r834, %r835;
	mul.wide.s32 	%rd278, %r222, 4;
	add.s64 	%rd279, %rd1, %rd278;
	ld.local.u32 	%r836, [%rd279];
	shr.u32 	%r837, %r836, %r833;
	shl.b32 	%r838, %r1222, %r225;
	add.s32 	%r1222, %r837, %r838;

$L__BB7_281:
	and.b32  	%r839, %r218, -2147483648;
	shr.u32 	%r840, %r1222, 30;
	shl.b32 	%r841, %r1221, 2;
	or.b32  	%r842, %r840, %r841;
	shr.u32 	%r843, %r842, 31;
	shr.u32 	%r844, %r1221, 30;
	add.s32 	%r845, %r843, %r844;
	neg.s32 	%r846, %r845;
	setp.eq.s32 	%p286, %r839, 0;
	selp.b32 	%r1223, %r845, %r846, %p286;
	setp.ne.s32 	%p287, %r843, 0;
	xor.b32  	%r847, %r839, -2147483648;
	selp.b32 	%r848, %r847, %r839, %p287;
	selp.b32 	%r849, -1, 0, %p287;
	xor.b32  	%r850, %r842, %r849;
	shl.b32 	%r851, %r1222, 2;
	xor.b32  	%r852, %r851, %r849;
	cvt.u64.u32 	%rd280, %r850;
	cvt.u64.u32 	%rd281, %r852;
	bfi.b64 	%rd282, %rd280, %rd281, 32, 32;
	cvt.rn.f64.s64 	%fd770, %rd282;
	mul.rn.f64 	%fd771, %fd770, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f460, %fd771;
	setp.eq.s32 	%p288, %r848, 0;
	neg.f32 	%f461, %f460;
	selp.f32 	%f689, %f460, %f461, %p288;

$L__BB7_283:
	cvt.rn.f32.f64 	%f464, %fd186;
	cvt.f64.f32 	%fd227, %f464;
	and.b32  	%r232, %r1223, 1;
	setp.eq.s32 	%p289, %r232, 0;
	selp.f32 	%f138, %f689, 0f3F800000, %p289;
	mul.rn.f32 	%f139, %f689, %f689;
	mov.f32 	%f690, 0fB94D4153;
	@%p289 bra 	$L__BB7_285;

	mov.f32 	%f465, 0fBAB607ED;
	mov.f32 	%f466, 0f37CBAC00;
	fma.rn.f32 	%f690, %f466, %f139, %f465;

$L__BB7_285:
	selp.f32 	%f467, 0f3C0885E4, 0f3D2AAABB, %p289;
	fma.rn.f32 	%f468, %f690, %f139, %f467;
	selp.f32 	%f469, 0fBE2AAAA8, 0fBEFFFFFF, %p289;
	fma.rn.f32 	%f470, %f468, %f139, %f469;
	mov.f32 	%f471, 0f00000000;
	fma.rn.f32 	%f472, %f139, %f138, %f471;
	fma.rn.f32 	%f691, %f470, %f472, %f138;
	and.b32  	%r854, %r1223, 2;
	setp.eq.s32 	%p291, %r854, 0;
	@%p291 bra 	$L__BB7_287;

	mov.f32 	%f474, 0fBF800000;
	fma.rn.f32 	%f691, %f691, %f474, %f471;

$L__BB7_287:
	div.rn.f64 	%fd228, %fd161, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r855, %temp}, %fd228;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r856}, %fd228;
	}
	and.b32  	%r857, %r856, 2147483647;
	setp.eq.s32 	%p292, %r857, 2146435072;
	setp.eq.s32 	%p293, %r855, 0;
	and.pred  	%p294, %p293, %p292;
	@%p294 bra 	$L__BB7_290;
	bra.uni 	$L__BB7_288;

$L__BB7_290:
	mov.f64 	%fd781, 0d0000000000000000;
	mul.rn.f64 	%fd1014, %fd228, %fd781;
	mov.u32 	%r1224, 0;
	bra.uni 	$L__BB7_291;

$L__BB7_288:
	mul.rn.f64 	%fd772, %fd228, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1224, %fd772;
	st.local.u32 	[%rd1], %r1224;
	cvt.rn.f64.s32 	%fd773, %r1224;
	neg.f64 	%fd774, %fd773;
	mov.f64 	%fd775, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd776, %fd774, %fd775, %fd228;
	mov.f64 	%fd777, 0d3C91A62633145C00;
	fma.rn.f64 	%fd778, %fd774, %fd777, %fd776;
	mov.f64 	%fd779, 0d397B839A252049C0;
	fma.rn.f64 	%fd1014, %fd774, %fd779, %fd778;
	abs.f64 	%fd780, %fd228;
	setp.ltu.f64 	%p295, %fd780, 0d41E0000000000000;
	@%p295 bra 	$L__BB7_291;

	{ // callseq 87, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd228;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1014, [retval0+0];
	} // callseq 87
	ld.local.u32 	%r1224, [%rd1];

$L__BB7_291:
	and.b32  	%r859, %r1224, 1;
	shl.b32 	%r860, %r1224, 3;
	and.b32  	%r861, %r860, 8;
	setp.eq.s32 	%p296, %r859, 0;
	selp.f64 	%fd782, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p296;
	mul.wide.s32 	%rd284, %r861, 8;
	add.s64 	%rd286, %rd165, %rd284;
	ld.global.nc.f64 	%fd783, [%rd286+8];
	mul.rn.f64 	%fd233, %fd1014, %fd1014;
	fma.rn.f64 	%fd784, %fd782, %fd233, %fd783;
	ld.global.nc.f64 	%fd785, [%rd286+16];
	fma.rn.f64 	%fd786, %fd784, %fd233, %fd785;
	ld.global.nc.f64 	%fd787, [%rd286+24];
	fma.rn.f64 	%fd788, %fd786, %fd233, %fd787;
	ld.global.nc.f64 	%fd789, [%rd286+32];
	fma.rn.f64 	%fd790, %fd788, %fd233, %fd789;
	ld.global.nc.f64 	%fd791, [%rd286+40];
	fma.rn.f64 	%fd792, %fd790, %fd233, %fd791;
	ld.global.nc.f64 	%fd793, [%rd286+48];
	fma.rn.f64 	%fd234, %fd792, %fd233, %fd793;
	fma.rn.f64 	%fd1016, %fd234, %fd1014, %fd1014;
	@%p296 bra 	$L__BB7_293;

	mov.f64 	%fd794, 0d3FF0000000000000;
	fma.rn.f64 	%fd1016, %fd234, %fd233, %fd794;

$L__BB7_293:
	and.b32  	%r862, %r1224, 2;
	setp.eq.s32 	%p297, %r862, 0;
	@%p297 bra 	$L__BB7_295;

	mov.f64 	%fd795, 0d0000000000000000;
	mov.f64 	%fd796, 0dBFF0000000000000;
	fma.rn.f64 	%fd1016, %fd1016, %fd796, %fd795;

$L__BB7_295:
	mul.rn.f64 	%fd797, %fd1016, 0d4044000000000000;
	cvt.f64.f32 	%fd798, %f691;
	mul.rn.f64 	%fd799, %fd798, 0d4034000000000000;
	add.rn.f64 	%fd240, %fd799, %fd797;
	div.rn.f64 	%fd241, %fd161, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r863, %temp}, %fd241;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r864}, %fd241;
	}
	and.b32  	%r865, %r864, 2147483647;
	setp.eq.s32 	%p298, %r865, 2146435072;
	setp.eq.s32 	%p299, %r863, 0;
	and.pred  	%p300, %p299, %p298;
	@%p300 bra 	$L__BB7_298;
	bra.uni 	$L__BB7_296;

$L__BB7_298:
	mov.f64 	%fd809, 0d0000000000000000;
	mul.rn.f64 	%fd1017, %fd241, %fd809;
	mov.u32 	%r1225, 0;
	bra.uni 	$L__BB7_299;

$L__BB7_296:
	mul.rn.f64 	%fd800, %fd241, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1225, %fd800;
	st.local.u32 	[%rd1], %r1225;
	cvt.rn.f64.s32 	%fd801, %r1225;
	neg.f64 	%fd802, %fd801;
	mov.f64 	%fd803, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd804, %fd802, %fd803, %fd241;
	mov.f64 	%fd805, 0d3C91A62633145C00;
	fma.rn.f64 	%fd806, %fd802, %fd805, %fd804;
	mov.f64 	%fd807, 0d397B839A252049C0;
	fma.rn.f64 	%fd1017, %fd802, %fd807, %fd806;
	abs.f64 	%fd808, %fd241;
	setp.ltu.f64 	%p301, %fd808, 0d41E0000000000000;
	@%p301 bra 	$L__BB7_299;

	{ // callseq 88, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd241;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1017, [retval0+0];
	} // callseq 88
	ld.local.u32 	%r1225, [%rd1];

$L__BB7_299:
	and.b32  	%r867, %r1225, 1;
	shl.b32 	%r868, %r1225, 3;
	and.b32  	%r869, %r868, 8;
	setp.eq.s32 	%p302, %r867, 0;
	selp.f64 	%fd810, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p302;
	mul.wide.s32 	%rd288, %r869, 8;
	add.s64 	%rd290, %rd165, %rd288;
	ld.global.nc.f64 	%fd811, [%rd290+8];
	mul.rn.f64 	%fd246, %fd1017, %fd1017;
	fma.rn.f64 	%fd812, %fd810, %fd246, %fd811;
	ld.global.nc.f64 	%fd813, [%rd290+16];
	fma.rn.f64 	%fd814, %fd812, %fd246, %fd813;
	ld.global.nc.f64 	%fd815, [%rd290+24];
	fma.rn.f64 	%fd816, %fd814, %fd246, %fd815;
	ld.global.nc.f64 	%fd817, [%rd290+32];
	fma.rn.f64 	%fd818, %fd816, %fd246, %fd817;
	ld.global.nc.f64 	%fd819, [%rd290+40];
	fma.rn.f64 	%fd820, %fd818, %fd246, %fd819;
	ld.global.nc.f64 	%fd821, [%rd290+48];
	fma.rn.f64 	%fd247, %fd820, %fd246, %fd821;
	fma.rn.f64 	%fd1019, %fd247, %fd1017, %fd1017;
	@%p302 bra 	$L__BB7_301;

	mov.f64 	%fd822, 0d3FF0000000000000;
	fma.rn.f64 	%fd1019, %fd247, %fd246, %fd822;

$L__BB7_301:
	and.b32  	%r870, %r1225, 2;
	setp.eq.s32 	%p303, %r870, 0;
	@%p303 bra 	$L__BB7_303;

	mov.f64 	%fd823, 0d0000000000000000;
	mov.f64 	%fd824, 0dBFF0000000000000;
	fma.rn.f64 	%fd1019, %fd1019, %fd824, %fd823;

$L__BB7_303:
	mul.rn.f64 	%fd825, %fd1019, 0d4062C00000000000;
	add.rn.f64 	%fd253, %fd240, %fd825;
	div.rn.f64 	%fd254, %fd161, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r871, %temp}, %fd254;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r872}, %fd254;
	}
	and.b32  	%r873, %r872, 2147483647;
	setp.eq.s32 	%p304, %r873, 2146435072;
	setp.eq.s32 	%p305, %r871, 0;
	and.pred  	%p306, %p305, %p304;
	@%p306 bra 	$L__BB7_306;
	bra.uni 	$L__BB7_304;

$L__BB7_306:
	mov.f64 	%fd835, 0d0000000000000000;
	mul.rn.f64 	%fd1020, %fd254, %fd835;
	mov.u32 	%r1226, 0;
	bra.uni 	$L__BB7_307;

$L__BB7_304:
	mul.rn.f64 	%fd826, %fd254, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1226, %fd826;
	st.local.u32 	[%rd1], %r1226;
	cvt.rn.f64.s32 	%fd827, %r1226;
	neg.f64 	%fd828, %fd827;
	mov.f64 	%fd829, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd830, %fd828, %fd829, %fd254;
	mov.f64 	%fd831, 0d3C91A62633145C00;
	fma.rn.f64 	%fd832, %fd828, %fd831, %fd830;
	mov.f64 	%fd833, 0d397B839A252049C0;
	fma.rn.f64 	%fd1020, %fd828, %fd833, %fd832;
	abs.f64 	%fd834, %fd254;
	setp.ltu.f64 	%p307, %fd834, 0d41E0000000000000;
	@%p307 bra 	$L__BB7_307;

	{ // callseq 89, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd254;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1020, [retval0+0];
	} // callseq 89
	ld.local.u32 	%r1226, [%rd1];

$L__BB7_307:
	and.b32  	%r875, %r1226, 1;
	shl.b32 	%r876, %r1226, 3;
	and.b32  	%r877, %r876, 8;
	setp.eq.s32 	%p308, %r875, 0;
	selp.f64 	%fd836, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p308;
	mul.wide.s32 	%rd292, %r877, 8;
	add.s64 	%rd294, %rd165, %rd292;
	ld.global.nc.f64 	%fd837, [%rd294+8];
	mul.rn.f64 	%fd259, %fd1020, %fd1020;
	fma.rn.f64 	%fd838, %fd836, %fd259, %fd837;
	ld.global.nc.f64 	%fd839, [%rd294+16];
	fma.rn.f64 	%fd840, %fd838, %fd259, %fd839;
	ld.global.nc.f64 	%fd841, [%rd294+24];
	fma.rn.f64 	%fd842, %fd840, %fd259, %fd841;
	ld.global.nc.f64 	%fd843, [%rd294+32];
	fma.rn.f64 	%fd844, %fd842, %fd259, %fd843;
	ld.global.nc.f64 	%fd845, [%rd294+40];
	fma.rn.f64 	%fd846, %fd844, %fd259, %fd845;
	ld.global.nc.f64 	%fd847, [%rd294+48];
	fma.rn.f64 	%fd260, %fd846, %fd259, %fd847;
	fma.rn.f64 	%fd1022, %fd260, %fd1020, %fd1020;
	@%p308 bra 	$L__BB7_309;

	mov.f64 	%fd848, 0d3FF0000000000000;
	fma.rn.f64 	%fd1022, %fd260, %fd259, %fd848;

$L__BB7_309:
	and.b32  	%r878, %r1226, 2;
	setp.eq.s32 	%p309, %r878, 0;
	@%p309 bra 	$L__BB7_311;

	mov.f64 	%fd849, 0d0000000000000000;
	mov.f64 	%fd850, 0dBFF0000000000000;
	fma.rn.f64 	%fd1022, %fd1022, %fd850, %fd849;

$L__BB7_311:
	mul.rn.f64 	%fd851, %fd1022, 0d4072C00000000000;
	add.rn.f64 	%fd852, %fd253, %fd851;
	add.rn.f64 	%fd266, %fd852, %fd227;
	add.rn.f64 	%fd267, %fd226, %fd227;
	add.rn.f64 	%fd853, %fd159, %fd159;
	add.rn.f64 	%fd854, %fd853, 0dC059000000000000;
	mul.rn.f64 	%fd855, %fd160, 0d4008000000000000;
	add.rn.f64 	%fd268, %fd854, %fd855;
	abs.f64 	%fd269, %fd160;
	{ // callseq 90, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd269;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1025, [retval0+0];
	} // callseq 90
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r242}, %fd160;
	}
	setp.lt.s32 	%p310, %r242, 0;
	and.pred  	%p6, %p310, %p11;
	not.pred 	%p312, %p6;
	@%p312 bra 	$L__BB7_313;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r879}, %fd1025;
	}
	xor.b32  	%r880, %r879, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r881, %temp}, %fd1025;
	}
	mov.b64 	%fd1025, {%r881, %r880};

$L__BB7_313:
	add.rn.f32 	%f652, %f712, 0fC20C0000;
	setp.eq.f32 	%p313, %f652, 0f00000000;
	@%p313 bra 	$L__BB7_317;
	bra.uni 	$L__BB7_314;

$L__BB7_317:
	setp.lt.s32 	%p316, %r2, 0;
	mov.u32 	%r882, 0;
	selp.b32 	%r883, %r242, 0, %p11;
	or.b32  	%r884, %r883, 2146435072;
	selp.b32 	%r885, %r884, %r883, %p316;
	mov.b64 	%fd1025, {%r882, %r885};
	bra.uni 	$L__BB7_318;

$L__BB7_314:
	setp.gt.s32 	%p314, %r242, -1;
	@%p314 bra 	$L__BB7_318;

	mov.f64 	%fd856, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd857, %fd856;
	setp.eq.f64 	%p315, %fd857, 0d4000000000000000;
	@%p315 bra 	$L__BB7_318;

	mov.f64 	%fd1025, 0dFFF8000000000000;

$L__BB7_318:
	add.rn.f64 	%fd859, %fd160, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r886}, %fd859;
	}
	and.b32  	%r887, %r886, 2146435072;
	setp.ne.s32 	%p318, %r887, 2146435072;
	@%p318 bra 	$L__BB7_325;

	setp.gtu.f64 	%p319, %fd269, 0d7FF0000000000000;
	@%p319 bra 	$L__BB7_324;
	bra.uni 	$L__BB7_320;

$L__BB7_324:
	mov.f64 	%fd861, 0d4000000000000000;
	add.rn.f64 	%fd1025, %fd160, %fd861;
	bra.uni 	$L__BB7_325;

$L__BB7_320:
	setp.eq.s32 	%p320, %r180, 2146435072;
	mov.f64 	%fd860, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r888, %temp}, %fd860;
	}
	setp.eq.s32 	%p321, %r888, 0;
	and.pred  	%p322, %p320, %p321;
	@%p322 bra 	$L__BB7_323;
	bra.uni 	$L__BB7_321;

$L__BB7_323:
	add.rn.f32 	%f658, %f712, 0fC20C0000;
	setp.lt.s32 	%p328, %r2, 0;
	mov.u32 	%r893, 0;
	setp.gt.f64 	%p329, %fd269, 0d3FF0000000000000;
	selp.b32 	%r894, 2146435072, 0, %p329;
	xor.b32  	%r895, %r894, 2146435072;
	selp.b32 	%r896, %r895, %r894, %p328;
	setp.eq.f32 	%p330, %f658, 0fBF800000;
	selp.b32 	%r897, 1072693248, %r896, %p330;
	mov.b64 	%fd1025, {%r893, %r897};
	bra.uni 	$L__BB7_325;

$L__BB7_321:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r889, %temp}, %fd160;
	}
	and.b32  	%r890, %r242, 2147483647;
	setp.ne.s32 	%p323, %r890, 2146435072;
	setp.ne.s32 	%p324, %r889, 0;
	or.pred  	%p325, %p323, %p324;
	@%p325 bra 	$L__BB7_325;

	setp.ne.s32 	%p326, %r180, 1071644672;
	and.pred  	%p327, %p326, %p6;
	selp.b32 	%r891, %r182, %r181, %p327;
	mov.u32 	%r892, 0;
	mov.b64 	%fd1025, {%r892, %r891};

$L__BB7_325:
	add.rn.f32 	%f654, %f711, 0fC2D20000;
	add.rn.f32 	%f653, %f712, 0fC20C0000;
	mul.rn.f64 	%fd862, %fd1025, 0d3FC999999999999A;
	setp.eq.f32 	%p331, %f653, 0f3F800000;
	selp.f64 	%fd863, 0d3FC999999999999A, %fd862, %p331;
	add.rn.f64 	%fd864, %fd268, %fd863;
	mul.rn.f32 	%f475, %f654, %f653;
	cvt.f64.f32 	%fd865, %f475;
	mul.rn.f64 	%fd279, %fd865, 0d3FB999999999999A;
	add.rn.f64 	%fd866, %fd279, %fd864;
	abs.f32 	%f476, %f654;
	sqrt.rn.f32 	%f477, %f476;
	cvt.f64.f32 	%fd280, %f477;
	mul.rn.f64 	%fd867, %fd280, 0d3FC999999999999A;
	add.rn.f64 	%fd868, %fd867, %fd866;
	cvt.rn.f32.f64 	%f478, %fd267;
	cvt.f64.f32 	%fd869, %f478;
	mul.rn.f64 	%fd870, %fd869, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f479, %fd870;
	cvt.f64.f32 	%fd871, %f479;
	add.rn.f64 	%fd281, %fd868, %fd871;
	add.rn.f64 	%fd872, %fd160, %fd160;
	add.rn.f64 	%fd873, %fd159, 0d4072C00000000000;
	add.rn.f64 	%fd282, %fd873, %fd872;
	abs.f64 	%fd283, %fd159;
	{ // callseq 91, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd283;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1028, [retval0+0];
	} // callseq 91
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r243}, %fd159;
	}
	setp.lt.s32 	%p332, %r243, 0;
	and.pred  	%p7, %p332, %p11;
	not.pred 	%p334, %p7;
	@%p334 bra 	$L__BB7_327;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r898}, %fd1028;
	}
	xor.b32  	%r899, %r898, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r900, %temp}, %fd1028;
	}
	mov.b64 	%fd1028, {%r900, %r899};

$L__BB7_327:
	add.rn.f32 	%f655, %f711, 0fC2D20000;
	setp.eq.f32 	%p335, %f655, 0f00000000;
	@%p335 bra 	$L__BB7_331;
	bra.uni 	$L__BB7_328;

$L__BB7_331:
	setp.lt.s32 	%p338, %r2, 0;
	mov.u32 	%r901, 0;
	selp.b32 	%r902, %r243, 0, %p11;
	or.b32  	%r903, %r902, 2146435072;
	selp.b32 	%r904, %r903, %r902, %p338;
	mov.b64 	%fd1028, {%r901, %r904};
	bra.uni 	$L__BB7_332;

$L__BB7_328:
	setp.gt.s32 	%p336, %r243, -1;
	@%p336 bra 	$L__BB7_332;

	mov.f64 	%fd874, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd875, %fd874;
	setp.eq.f64 	%p337, %fd875, 0d4000000000000000;
	@%p337 bra 	$L__BB7_332;

	mov.f64 	%fd1028, 0dFFF8000000000000;

$L__BB7_332:
	add.rn.f64 	%fd877, %fd159, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r905}, %fd877;
	}
	and.b32  	%r906, %r905, 2146435072;
	setp.ne.s32 	%p340, %r906, 2146435072;
	@%p340 bra 	$L__BB7_339;

	setp.gtu.f64 	%p341, %fd283, 0d7FF0000000000000;
	@%p341 bra 	$L__BB7_338;
	bra.uni 	$L__BB7_334;

$L__BB7_338:
	mov.f64 	%fd879, 0d4000000000000000;
	add.rn.f64 	%fd1028, %fd159, %fd879;
	bra.uni 	$L__BB7_339;

$L__BB7_334:
	setp.eq.s32 	%p342, %r180, 2146435072;
	mov.f64 	%fd878, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r907, %temp}, %fd878;
	}
	setp.eq.s32 	%p343, %r907, 0;
	and.pred  	%p344, %p342, %p343;
	@%p344 bra 	$L__BB7_337;
	bra.uni 	$L__BB7_335;

$L__BB7_337:
	add.rn.f32 	%f657, %f711, 0fC2D20000;
	setp.lt.s32 	%p350, %r2, 0;
	mov.u32 	%r912, 0;
	setp.gt.f64 	%p351, %fd283, 0d3FF0000000000000;
	selp.b32 	%r913, 2146435072, 0, %p351;
	xor.b32  	%r914, %r913, 2146435072;
	selp.b32 	%r915, %r914, %r913, %p350;
	setp.eq.f32 	%p352, %f657, 0fBF800000;
	selp.b32 	%r916, 1072693248, %r915, %p352;
	mov.b64 	%fd1028, {%r912, %r916};
	bra.uni 	$L__BB7_339;

$L__BB7_335:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r908, %temp}, %fd159;
	}
	and.b32  	%r909, %r243, 2147483647;
	setp.ne.s32 	%p345, %r909, 2146435072;
	setp.ne.s32 	%p346, %r908, 0;
	or.pred  	%p347, %p345, %p346;
	@%p347 bra 	$L__BB7_339;

	setp.ne.s32 	%p348, %r180, 1071644672;
	and.pred  	%p349, %p348, %p7;
	selp.b32 	%r910, %r182, %r181, %p349;
	mov.u32 	%r911, 0;
	mov.b64 	%fd1028, {%r911, %r910};

$L__BB7_339:
	add.rn.f32 	%f656, %f711, 0fC2D20000;
	mul.rn.f64 	%fd880, %fd1028, 0d3FB999999999999A;
	setp.eq.f32 	%p353, %f656, 0f3F800000;
	selp.f64 	%fd881, 0d3FB999999999999A, %fd880, %p353;
	add.rn.f64 	%fd882, %fd282, %fd881;
	add.rn.f64 	%fd883, %fd279, %fd882;
	mul.rn.f64 	%fd884, %fd280, 0d3FB999999999999A;
	add.rn.f64 	%fd885, %fd884, %fd883;
	cvt.rn.f32.f64 	%f480, %fd266;
	cvt.f64.f32 	%fd886, %f480;
	mul.rn.f64 	%fd887, %fd886, 0d3FE5555555555555;
	cvt.rn.f32.f64 	%f481, %fd887;
	cvt.f64.f32 	%fd888, %f481;
	add.rn.f64 	%fd293, %fd885, %fd888;
	cvt.f64.f32 	%fd294, %f712;
	div.rn.f64 	%fd889, %fd294, 0d4066800000000000;
	mul.rn.f64 	%fd890, %fd889, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f145, %fd890;
	mul.rn.f32 	%f482, %f145, 0f3F22F983;
	cvt.rni.s32.f32 	%r1232, %f482;
	cvt.rn.f32.s32 	%f483, %r1232;
	mov.f32 	%f484, 0fBFC90FDA;
	fma.rn.f32 	%f485, %f483, %f484, %f145;
	mov.f32 	%f486, 0fB3A22168;
	fma.rn.f32 	%f487, %f483, %f486, %f485;
	mov.f32 	%f488, 0fA7C234C5;
	fma.rn.f32 	%f695, %f483, %f488, %f487;
	abs.f32 	%f147, %f145;
	setp.ltu.f32 	%p354, %f147, 0f47CE4780;
	mov.u32 	%r1229, %r1232;
	mov.f32 	%f692, %f695;
	@%p354 bra 	$L__BB7_347;

	setp.eq.f32 	%p355, %f147, 0f7F800000;
	@%p355 bra 	$L__BB7_346;
	bra.uni 	$L__BB7_341;

$L__BB7_346:
	mov.f32 	%f491, 0f00000000;
	mul.rn.f32 	%f692, %f145, %f491;
	mov.u32 	%r1229, 0;
	bra.uni 	$L__BB7_347;

$L__BB7_341:
	mov.b32 	%r245, %f145;
	bfe.u32 	%r917, %r245, 23, 8;
	add.s32 	%r246, %r917, -128;
	shl.b32 	%r918, %r245, 8;
	or.b32  	%r247, %r918, -2147483648;
	shr.u32 	%r248, %r246, 5;
	mov.u64 	%rd416, 0;
	mov.u64 	%rd417, %rd416;

$L__BB7_342:
	.pragma "nounroll";
	shl.b64 	%rd297, %rd416, 2;
	mov.u64 	%rd298, __cudart_i2opi_f;
	add.s64 	%rd299, %rd298, %rd297;
	ld.global.nc.u32 	%r919, [%rd299];
	mad.wide.u32 	%rd300, %r919, %r247, %rd417;
	shr.u64 	%rd417, %rd300, 32;
	add.s64 	%rd301, %rd1, %rd297;
	st.local.u32 	[%rd301], %rd300;
	cvt.u32.u64 	%r920, %rd416;
	add.s32 	%r921, %r920, 1;
	cvt.s64.s32 	%rd416, %r921;
	setp.ne.s32 	%p356, %r921, 6;
	@%p356 bra 	$L__BB7_342;

	st.local.u32 	[%rd1+24], %rd417;
	mov.u32 	%r922, 4;
	sub.s32 	%r249, %r922, %r248;
	mov.u32 	%r923, 6;
	sub.s32 	%r924, %r923, %r248;
	mul.wide.s32 	%rd302, %r924, 4;
	add.s64 	%rd303, %rd1, %rd302;
	ld.local.u32 	%r1227, [%rd303];
	ld.local.u32 	%r1228, [%rd303+-4];
	and.b32  	%r252, %r246, 31;
	setp.eq.s32 	%p357, %r252, 0;
	@%p357 bra 	$L__BB7_345;

	mov.u32 	%r925, 32;
	sub.s32 	%r926, %r925, %r252;
	shr.u32 	%r927, %r1228, %r926;
	shl.b32 	%r928, %r1227, %r252;
	add.s32 	%r1227, %r927, %r928;
	mul.wide.s32 	%rd304, %r249, 4;
	add.s64 	%rd305, %rd1, %rd304;
	ld.local.u32 	%r929, [%rd305];
	shr.u32 	%r930, %r929, %r926;
	shl.b32 	%r931, %r1228, %r252;
	add.s32 	%r1228, %r930, %r931;

$L__BB7_345:
	and.b32  	%r932, %r245, -2147483648;
	shr.u32 	%r933, %r1228, 30;
	shl.b32 	%r934, %r1227, 2;
	or.b32  	%r935, %r933, %r934;
	shr.u32 	%r936, %r935, 31;
	shr.u32 	%r937, %r1227, 30;
	add.s32 	%r938, %r936, %r937;
	neg.s32 	%r939, %r938;
	setp.eq.s32 	%p358, %r932, 0;
	selp.b32 	%r1229, %r938, %r939, %p358;
	setp.ne.s32 	%p359, %r936, 0;
	xor.b32  	%r940, %r932, -2147483648;
	selp.b32 	%r941, %r940, %r932, %p359;
	selp.b32 	%r942, -1, 0, %p359;
	xor.b32  	%r943, %r935, %r942;
	shl.b32 	%r944, %r1228, 2;
	xor.b32  	%r945, %r944, %r942;
	cvt.u64.u32 	%rd306, %r943;
	cvt.u64.u32 	%rd307, %r945;
	bfi.b64 	%rd308, %rd306, %rd307, 32, 32;
	cvt.rn.f64.s64 	%fd891, %rd308;
	mul.rn.f64 	%fd892, %fd891, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f489, %fd892;
	setp.eq.s32 	%p360, %r941, 0;
	neg.f32 	%f490, %f489;
	selp.f32 	%f692, %f489, %f490, %p360;

$L__BB7_347:
	and.b32  	%r259, %r1229, 1;
	setp.eq.s32 	%p361, %r259, 0;
	selp.f32 	%f151, %f692, 0f3F800000, %p361;
	mul.rn.f32 	%f152, %f692, %f692;
	mov.f32 	%f693, 0fB94D4153;
	@%p361 bra 	$L__BB7_349;

	mov.f32 	%f493, 0fBAB607ED;
	mov.f32 	%f494, 0f37CBAC00;
	fma.rn.f32 	%f693, %f494, %f152, %f493;

$L__BB7_349:
	selp.f32 	%f495, 0f3C0885E4, 0f3D2AAABB, %p361;
	fma.rn.f32 	%f496, %f693, %f152, %f495;
	selp.f32 	%f497, 0fBE2AAAA8, 0fBEFFFFFF, %p361;
	fma.rn.f32 	%f498, %f496, %f152, %f497;
	mov.f32 	%f499, 0f00000000;
	fma.rn.f32 	%f500, %f152, %f151, %f499;
	fma.rn.f32 	%f694, %f498, %f500, %f151;
	and.b32  	%r947, %r1229, 2;
	setp.eq.s32 	%p363, %r947, 0;
	@%p363 bra 	$L__BB7_351;

	mov.f32 	%f502, 0fBF800000;
	fma.rn.f32 	%f694, %f694, %f502, %f499;

$L__BB7_351:
	@%p354 bra 	$L__BB7_359;

	setp.eq.f32 	%p365, %f147, 0f7F800000;
	@%p365 bra 	$L__BB7_358;
	bra.uni 	$L__BB7_353;

$L__BB7_358:
	mov.f32 	%f505, 0f00000000;
	mul.rn.f32 	%f695, %f145, %f505;
	mov.u32 	%r1232, 0;
	bra.uni 	$L__BB7_359;

$L__BB7_353:
	mov.b32 	%r260, %f145;
	bfe.u32 	%r948, %r260, 23, 8;
	add.s32 	%r261, %r948, -128;
	shl.b32 	%r949, %r260, 8;
	or.b32  	%r262, %r949, -2147483648;
	shr.u32 	%r263, %r261, 5;
	mov.u64 	%rd418, 0;
	mov.u64 	%rd419, %rd418;

$L__BB7_354:
	.pragma "nounroll";
	shl.b64 	%rd311, %rd418, 2;
	mov.u64 	%rd312, __cudart_i2opi_f;
	add.s64 	%rd313, %rd312, %rd311;
	ld.global.nc.u32 	%r950, [%rd313];
	mad.wide.u32 	%rd314, %r950, %r262, %rd419;
	shr.u64 	%rd419, %rd314, 32;
	add.s64 	%rd315, %rd1, %rd311;
	st.local.u32 	[%rd315], %rd314;
	cvt.u32.u64 	%r951, %rd418;
	add.s32 	%r952, %r951, 1;
	cvt.s64.s32 	%rd418, %r952;
	setp.ne.s32 	%p366, %r952, 6;
	@%p366 bra 	$L__BB7_354;

	st.local.u32 	[%rd1+24], %rd419;
	mov.u32 	%r953, 4;
	sub.s32 	%r264, %r953, %r263;
	mov.u32 	%r954, 6;
	sub.s32 	%r955, %r954, %r263;
	mul.wide.s32 	%rd316, %r955, 4;
	add.s64 	%rd317, %rd1, %rd316;
	ld.local.u32 	%r1230, [%rd317];
	ld.local.u32 	%r1231, [%rd317+-4];
	and.b32  	%r267, %r261, 31;
	setp.eq.s32 	%p367, %r267, 0;
	@%p367 bra 	$L__BB7_357;

	mov.u32 	%r956, 32;
	sub.s32 	%r957, %r956, %r267;
	shr.u32 	%r958, %r1231, %r957;
	shl.b32 	%r959, %r1230, %r267;
	add.s32 	%r1230, %r958, %r959;
	mul.wide.s32 	%rd318, %r264, 4;
	add.s64 	%rd319, %rd1, %rd318;
	ld.local.u32 	%r960, [%rd319];
	shr.u32 	%r961, %r960, %r957;
	shl.b32 	%r962, %r1231, %r267;
	add.s32 	%r1231, %r961, %r962;

$L__BB7_357:
	and.b32  	%r963, %r260, -2147483648;
	shr.u32 	%r964, %r1231, 30;
	shl.b32 	%r965, %r1230, 2;
	or.b32  	%r966, %r964, %r965;
	shr.u32 	%r967, %r966, 31;
	shr.u32 	%r968, %r1230, 30;
	add.s32 	%r969, %r967, %r968;
	neg.s32 	%r970, %r969;
	setp.eq.s32 	%p368, %r963, 0;
	selp.b32 	%r1232, %r969, %r970, %p368;
	setp.ne.s32 	%p369, %r967, 0;
	xor.b32  	%r971, %r963, -2147483648;
	selp.b32 	%r972, %r971, %r963, %p369;
	selp.b32 	%r973, -1, 0, %p369;
	xor.b32  	%r974, %r966, %r973;
	shl.b32 	%r975, %r1231, 2;
	xor.b32  	%r976, %r975, %r973;
	cvt.u64.u32 	%rd320, %r974;
	cvt.u64.u32 	%rd321, %r976;
	bfi.b64 	%rd322, %rd320, %rd321, 32, 32;
	cvt.rn.f64.s64 	%fd893, %rd322;
	mul.rn.f64 	%fd894, %fd893, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f503, %fd894;
	setp.eq.s32 	%p370, %r972, 0;
	neg.f32 	%f504, %f503;
	selp.f32 	%f695, %f503, %f504, %p370;

$L__BB7_359:
	add.s32 	%r274, %r1232, 1;
	and.b32  	%r275, %r274, 1;
	setp.eq.s32 	%p8, %r275, 0;
	mul.rn.f32 	%f161, %f695, %f695;
	mov.f32 	%f696, 0fB94D4153;
	@%p8 bra 	$L__BB7_361;

	mov.f32 	%f507, 0fBAB607ED;
	mov.f32 	%f508, 0f37CBAC00;
	fma.rn.f32 	%f696, %f508, %f161, %f507;

$L__BB7_361:
	selp.f32 	%f509, %f695, 0f3F800000, %p8;
	selp.f32 	%f510, 0f3C0885E4, 0f3D2AAABB, %p8;
	fma.rn.f32 	%f511, %f696, %f161, %f510;
	selp.f32 	%f512, 0fBE2AAAA8, 0fBEFFFFFF, %p8;
	fma.rn.f32 	%f513, %f511, %f161, %f512;
	mov.f32 	%f514, 0f00000000;
	fma.rn.f32 	%f515, %f161, %f509, %f514;
	fma.rn.f32 	%f697, %f513, %f515, %f509;
	and.b32  	%r978, %r274, 2;
	setp.eq.s32 	%p372, %r978, 0;
	@%p372 bra 	$L__BB7_363;

	mov.f32 	%f517, 0fBF800000;
	fma.rn.f32 	%f697, %f697, %f517, %f514;

$L__BB7_363:
	cvt.f64.f32 	%fd895, %f694;
	mul.rn.f64 	%fd896, %fd895, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd897, %fd896, %fd895;
	add.rn.f64 	%fd898, %fd897, 0d3FF0000000000000;
	cvt.rn.f32.f64 	%f518, %fd898;
	sqrt.rn.f32 	%f519, %f518;
	mov.f32 	%f520, 0f4AC2A60A;
	div.rn.f32 	%f521, %f520, %f519;
	mul.rn.f32 	%f522, %f521, %f697;
	cvt.f64.f32 	%fd899, %f522;
	mul.rn.f64 	%fd900, %fd899, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f523, %fd293;
	cvt.f64.f32 	%fd901, %f523;
	mul.rn.f64 	%fd902, %fd901, 0d4066800000000000;
	div.rn.f64 	%fd903, %fd902, %fd900;
	cvt.rn.f32.f64 	%f524, %fd903;
	add.rn.f32 	%f167, %f711, %f524;
	mul.rn.f32 	%f525, %f519, %f518;
	cvt.f64.f32 	%fd904, %f525;
	mov.f64 	%fd905, 0d41582B102DE355C1;
	div.rn.f64 	%fd906, %fd905, %fd904;
	mul.rn.f64 	%fd907, %fd906, 0d400921FB54442D18;
	cvt.rn.f32.f64 	%f526, %fd281;
	cvt.f64.f32 	%fd908, %f526;
	mul.rn.f64 	%fd909, %fd908, 0d4066800000000000;
	div.rn.f64 	%fd910, %fd909, %fd907;
	cvt.rn.f32.f64 	%f527, %fd910;
	add.rn.f32 	%f168, %f712, %f527;
	cvt.f64.f32 	%fd295, %f167;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd295;
	}
	abs.f64 	%fd296, %fd295;
	{ // callseq 92, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd296;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1031, [retval0+0];
	} // callseq 92
	setp.lt.s32 	%p373, %r276, 0;
	and.pred  	%p9, %p373, %p11;
	not.pred 	%p375, %p9;
	@%p375 bra 	$L__BB7_365;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r979}, %fd1031;
	}
	xor.b32  	%r980, %r979, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r981, %temp}, %fd1031;
	}
	mov.b64 	%fd1031, {%r981, %r980};

$L__BB7_365:
	setp.eq.f32 	%p376, %f167, 0f00000000;
	@%p376 bra 	$L__BB7_369;
	bra.uni 	$L__BB7_366;

$L__BB7_369:
	setp.lt.s32 	%p379, %r2, 0;
	mov.u32 	%r982, 0;
	selp.b32 	%r983, %r276, 0, %p11;
	or.b32  	%r984, %r983, 2146435072;
	selp.b32 	%r985, %r984, %r983, %p379;
	mov.b64 	%fd1031, {%r982, %r985};
	bra.uni 	$L__BB7_370;

$L__BB7_366:
	setp.gt.s32 	%p377, %r276, -1;
	@%p377 bra 	$L__BB7_370;

	mov.f64 	%fd911, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd912, %fd911;
	setp.eq.f64 	%p378, %fd912, 0d4000000000000000;
	@%p378 bra 	$L__BB7_370;

	mov.f64 	%fd1031, 0dFFF8000000000000;

$L__BB7_370:
	add.rn.f64 	%fd914, %fd295, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r986}, %fd914;
	}
	and.b32  	%r987, %r986, 2146435072;
	setp.ne.s32 	%p381, %r987, 2146435072;
	@%p381 bra 	$L__BB7_377;

	setp.gtu.f64 	%p382, %fd296, 0d7FF0000000000000;
	@%p382 bra 	$L__BB7_376;
	bra.uni 	$L__BB7_372;

$L__BB7_376:
	mov.f64 	%fd916, 0d4000000000000000;
	add.rn.f64 	%fd1031, %fd295, %fd916;
	bra.uni 	$L__BB7_377;

$L__BB7_372:
	setp.eq.s32 	%p383, %r180, 2146435072;
	mov.f64 	%fd915, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r988, %temp}, %fd915;
	}
	setp.eq.s32 	%p384, %r988, 0;
	and.pred  	%p385, %p383, %p384;
	@%p385 bra 	$L__BB7_375;
	bra.uni 	$L__BB7_373;

$L__BB7_375:
	setp.lt.s32 	%p391, %r2, 0;
	mov.u32 	%r993, 0;
	setp.gt.f64 	%p392, %fd296, 0d3FF0000000000000;
	selp.b32 	%r994, 2146435072, 0, %p392;
	xor.b32  	%r995, %r994, 2146435072;
	selp.b32 	%r996, %r995, %r994, %p391;
	setp.eq.f32 	%p393, %f167, 0fBF800000;
	selp.b32 	%r997, 1072693248, %r996, %p393;
	mov.b64 	%fd1031, {%r993, %r997};
	bra.uni 	$L__BB7_377;

$L__BB7_373:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r989, %temp}, %fd295;
	}
	and.b32  	%r990, %r276, 2147483647;
	setp.ne.s32 	%p386, %r990, 2146435072;
	setp.ne.s32 	%p387, %r989, 0;
	or.pred  	%p388, %p386, %p387;
	@%p388 bra 	$L__BB7_377;

	setp.ne.s32 	%p389, %r180, 1071644672;
	and.pred  	%p390, %p389, %p9;
	selp.b32 	%r991, %r182, %r181, %p390;
	mov.u32 	%r992, 0;
	mov.b64 	%fd1031, {%r992, %r991};

$L__BB7_377:
	cvt.f64.f32 	%fd306, %f168;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r277}, %fd306;
	}
	abs.f64 	%fd307, %fd306;
	{ // callseq 93, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd307;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1034, [retval0+0];
	} // callseq 93
	setp.lt.s32 	%p394, %r277, 0;
	and.pred  	%p10, %p394, %p11;
	not.pred 	%p396, %p10;
	@%p396 bra 	$L__BB7_379;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r998}, %fd1034;
	}
	xor.b32  	%r999, %r998, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1000, %temp}, %fd1034;
	}
	mov.b64 	%fd1034, {%r1000, %r999};

$L__BB7_379:
	setp.eq.f32 	%p397, %f168, 0f00000000;
	@%p397 bra 	$L__BB7_383;
	bra.uni 	$L__BB7_380;

$L__BB7_383:
	setp.lt.s32 	%p400, %r2, 0;
	mov.u32 	%r1001, 0;
	selp.b32 	%r1002, %r277, 0, %p11;
	or.b32  	%r1003, %r1002, 2146435072;
	selp.b32 	%r1004, %r1003, %r1002, %p400;
	mov.b64 	%fd1034, {%r1001, %r1004};
	bra.uni 	$L__BB7_384;

$L__BB7_380:
	setp.gt.s32 	%p398, %r277, -1;
	@%p398 bra 	$L__BB7_384;

	mov.f64 	%fd917, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd918, %fd917;
	setp.eq.f64 	%p399, %fd918, 0d4000000000000000;
	@%p399 bra 	$L__BB7_384;

	mov.f64 	%fd1034, 0dFFF8000000000000;

$L__BB7_384:
	add.rn.f64 	%fd920, %fd306, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1005}, %fd920;
	}
	and.b32  	%r1006, %r1005, 2146435072;
	setp.ne.s32 	%p402, %r1006, 2146435072;
	@%p402 bra 	$L__BB7_391;

	setp.gtu.f64 	%p403, %fd307, 0d7FF0000000000000;
	@%p403 bra 	$L__BB7_390;
	bra.uni 	$L__BB7_386;

$L__BB7_390:
	mov.f64 	%fd922, 0d4000000000000000;
	add.rn.f64 	%fd1034, %fd306, %fd922;
	bra.uni 	$L__BB7_391;

$L__BB7_386:
	setp.eq.s32 	%p404, %r180, 2146435072;
	mov.f64 	%fd921, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1007, %temp}, %fd921;
	}
	setp.eq.s32 	%p405, %r1007, 0;
	and.pred  	%p406, %p404, %p405;
	@%p406 bra 	$L__BB7_389;
	bra.uni 	$L__BB7_387;

$L__BB7_389:
	setp.lt.s32 	%p412, %r2, 0;
	mov.u32 	%r1012, 0;
	setp.gt.f64 	%p413, %fd307, 0d3FF0000000000000;
	selp.b32 	%r1013, 2146435072, 0, %p413;
	xor.b32  	%r1014, %r1013, 2146435072;
	selp.b32 	%r1015, %r1014, %r1013, %p412;
	setp.eq.f32 	%p414, %f168, 0fBF800000;
	selp.b32 	%r1016, 1072693248, %r1015, %p414;
	mov.b64 	%fd1034, {%r1012, %r1016};
	bra.uni 	$L__BB7_391;

$L__BB7_387:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1008, %temp}, %fd306;
	}
	and.b32  	%r1009, %r277, 2147483647;
	setp.ne.s32 	%p407, %r1009, 2146435072;
	setp.ne.s32 	%p408, %r1008, 0;
	or.pred  	%p409, %p407, %p408;
	@%p409 bra 	$L__BB7_391;

	setp.ne.s32 	%p410, %r180, 1071644672;
	and.pred  	%p411, %p410, %p10;
	selp.b32 	%r1010, %r182, %r181, %p411;
	mov.u32 	%r1011, 0;
	mov.b64 	%fd1034, {%r1011, %r1010};

$L__BB7_391:
	setp.eq.f32 	%p415, %f168, 0f3F800000;
	selp.f64 	%fd923, 0d3FF0000000000000, %fd1034, %p415;
	setp.eq.f32 	%p416, %f167, 0f3F800000;
	selp.f64 	%fd924, 0d3FF0000000000000, %fd1031, %p416;
	add.rn.f64 	%fd317, %fd924, %fd923;
	mul.rn.f32 	%f169, %f168, 0f42517084;
	mul.rn.f32 	%f528, %f169, 0f3F22F983;
	cvt.rni.s32.f32 	%r1235, %f528;
	cvt.rn.f32.s32 	%f529, %r1235;
	mov.f32 	%f530, 0fBFC90FDA;
	fma.rn.f32 	%f531, %f529, %f530, %f169;
	mov.f32 	%f532, 0fB3A22168;
	fma.rn.f32 	%f533, %f529, %f532, %f531;
	mov.f32 	%f534, 0fA7C234C5;
	fma.rn.f32 	%f698, %f529, %f534, %f533;
	abs.f32 	%f171, %f169;
	setp.ltu.f32 	%p417, %f171, 0f47CE4780;
	@%p417 bra 	$L__BB7_399;

	setp.eq.f32 	%p418, %f171, 0f7F800000;
	@%p418 bra 	$L__BB7_398;
	bra.uni 	$L__BB7_393;

$L__BB7_398:
	mov.f32 	%f537, 0f00000000;
	mul.rn.f32 	%f698, %f169, %f537;
	mov.u32 	%r1235, 0;
	bra.uni 	$L__BB7_399;

$L__BB7_393:
	mov.b32 	%r279, %f169;
	bfe.u32 	%r1017, %r279, 23, 8;
	add.s32 	%r280, %r1017, -128;
	shl.b32 	%r1018, %r279, 8;
	or.b32  	%r281, %r1018, -2147483648;
	shr.u32 	%r282, %r280, 5;
	mov.u64 	%rd420, 0;
	mov.u64 	%rd421, %rd420;

$L__BB7_394:
	.pragma "nounroll";
	shl.b64 	%rd325, %rd420, 2;
	mov.u64 	%rd326, __cudart_i2opi_f;
	add.s64 	%rd327, %rd326, %rd325;
	ld.global.nc.u32 	%r1019, [%rd327];
	mad.wide.u32 	%rd328, %r1019, %r281, %rd421;
	shr.u64 	%rd421, %rd328, 32;
	add.s64 	%rd329, %rd1, %rd325;
	st.local.u32 	[%rd329], %rd328;
	cvt.u32.u64 	%r1020, %rd420;
	add.s32 	%r1021, %r1020, 1;
	cvt.s64.s32 	%rd420, %r1021;
	setp.ne.s32 	%p419, %r1021, 6;
	@%p419 bra 	$L__BB7_394;

	st.local.u32 	[%rd1+24], %rd421;
	mov.u32 	%r1022, 4;
	sub.s32 	%r283, %r1022, %r282;
	mov.u32 	%r1023, 6;
	sub.s32 	%r1024, %r1023, %r282;
	mul.wide.s32 	%rd330, %r1024, 4;
	add.s64 	%rd331, %rd1, %rd330;
	ld.local.u32 	%r1233, [%rd331];
	ld.local.u32 	%r1234, [%rd331+-4];
	and.b32  	%r286, %r280, 31;
	setp.eq.s32 	%p420, %r286, 0;
	@%p420 bra 	$L__BB7_397;

	mov.u32 	%r1025, 32;
	sub.s32 	%r1026, %r1025, %r286;
	shr.u32 	%r1027, %r1234, %r1026;
	shl.b32 	%r1028, %r1233, %r286;
	add.s32 	%r1233, %r1027, %r1028;
	mul.wide.s32 	%rd332, %r283, 4;
	add.s64 	%rd333, %rd1, %rd332;
	ld.local.u32 	%r1029, [%rd333];
	shr.u32 	%r1030, %r1029, %r1026;
	shl.b32 	%r1031, %r1234, %r286;
	add.s32 	%r1234, %r1030, %r1031;

$L__BB7_397:
	and.b32  	%r1032, %r279, -2147483648;
	shr.u32 	%r1033, %r1234, 30;
	shl.b32 	%r1034, %r1233, 2;
	or.b32  	%r1035, %r1033, %r1034;
	shr.u32 	%r1036, %r1035, 31;
	shr.u32 	%r1037, %r1233, 30;
	add.s32 	%r1038, %r1036, %r1037;
	neg.s32 	%r1039, %r1038;
	setp.eq.s32 	%p421, %r1032, 0;
	selp.b32 	%r1235, %r1038, %r1039, %p421;
	setp.ne.s32 	%p422, %r1036, 0;
	xor.b32  	%r1040, %r1032, -2147483648;
	selp.b32 	%r1041, %r1040, %r1032, %p422;
	selp.b32 	%r1042, -1, 0, %p422;
	xor.b32  	%r1043, %r1035, %r1042;
	shl.b32 	%r1044, %r1234, 2;
	xor.b32  	%r1045, %r1044, %r1042;
	cvt.u64.u32 	%rd334, %r1043;
	cvt.u64.u32 	%rd335, %r1045;
	bfi.b64 	%rd336, %rd334, %rd335, 32, 32;
	cvt.rn.f64.s64 	%fd925, %rd336;
	mul.rn.f64 	%fd926, %fd925, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f535, %fd926;
	setp.eq.s32 	%p423, %r1041, 0;
	neg.f32 	%f536, %f535;
	selp.f32 	%f698, %f535, %f536, %p423;

$L__BB7_399:
	and.b32  	%r293, %r1235, 1;
	setp.eq.s32 	%p424, %r293, 0;
	selp.f32 	%f175, %f698, 0f3F800000, %p424;
	mul.rn.f32 	%f176, %f698, %f698;
	mov.f32 	%f699, 0fB94D4153;
	@%p424 bra 	$L__BB7_401;

	mov.f32 	%f539, 0fBAB607ED;
	mov.f32 	%f540, 0f37CBAC00;
	fma.rn.f32 	%f699, %f540, %f176, %f539;

$L__BB7_401:
	selp.f32 	%f541, 0f3C0885E4, 0f3D2AAABB, %p424;
	fma.rn.f32 	%f542, %f699, %f176, %f541;
	selp.f32 	%f543, 0fBE2AAAA8, 0fBEFFFFFF, %p424;
	fma.rn.f32 	%f544, %f542, %f176, %f543;
	mov.f32 	%f545, 0f00000000;
	fma.rn.f32 	%f546, %f176, %f175, %f545;
	fma.rn.f32 	%f700, %f544, %f546, %f175;
	and.b32  	%r1047, %r1235, 2;
	setp.eq.s32 	%p426, %r1047, 0;
	@%p426 bra 	$L__BB7_403;

	mov.f32 	%f548, 0fBF800000;
	fma.rn.f32 	%f700, %f700, %f548, %f545;

$L__BB7_403:
	cvt.f64.f32 	%fd927, %f700;
	mul.rn.f64 	%fd928, %fd927, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd929, %fd317;
	add.rn.f64 	%fd318, %fd929, %fd928;
	abs.f32 	%f182, %f167;
	setp.eq.f32 	%p427, %f182, 0f00000000;
	abs.f32 	%f183, %f168;
	setp.eq.f32 	%p428, %f183, 0f00000000;
	and.pred  	%p429, %p427, %p428;
	@%p429 bra 	$L__BB7_407;
	bra.uni 	$L__BB7_404;

$L__BB7_407:
	mov.b32 	%r1058, %f167;
	shr.s32 	%r1059, %r1058, 31;
	and.b32  	%r1060, %r1059, 1078530011;
	mov.b32 	%r1061, %f168;
	and.b32  	%r1062, %r1061, -2147483648;
	or.b32  	%r1063, %r1060, %r1062;
	mov.b32 	%f701, %r1063;
	bra.uni 	$L__BB7_408;

$L__BB7_404:
	setp.eq.f32 	%p430, %f182, 0f7F800000;
	setp.eq.f32 	%p431, %f183, 0f7F800000;
	and.pred  	%p432, %p430, %p431;
	@%p432 bra 	$L__BB7_406;
	bra.uni 	$L__BB7_405;

$L__BB7_406:
	mov.b32 	%r1053, %f167;
	setp.lt.s32 	%p436, %r1053, 0;
	selp.b32 	%r1054, 1075235812, 1061752795, %p436;
	mov.b32 	%r1055, %f168;
	and.b32  	%r1056, %r1055, -2147483648;
	or.b32  	%r1057, %r1054, %r1056;
	mov.b32 	%f701, %r1057;
	bra.uni 	$L__BB7_408;

$L__BB7_405:
	max.f32 	%f549, %f183, %f182;
	min.f32 	%f550, %f183, %f182;
	div.rn.f32 	%f551, %f550, %f549;
	mul.rn.f32 	%f552, %f551, %f551;
	mov.f32 	%f553, 0fC0B59883;
	mov.f32 	%f554, 0fBF52C7EA;
	fma.rn.f32 	%f555, %f552, %f554, %f553;
	mov.f32 	%f556, 0fC0D21907;
	fma.rn.f32 	%f557, %f555, %f552, %f556;
	mul.rn.f32 	%f558, %f552, %f557;
	mul.rn.f32 	%f559, %f551, %f558;
	add.rn.f32 	%f560, %f552, 0f41355DC0;
	mov.f32 	%f561, 0f41E6BD60;
	fma.rn.f32 	%f562, %f560, %f552, %f561;
	mov.f32 	%f563, 0f419D92C8;
	fma.rn.f32 	%f564, %f562, %f552, %f563;
	rcp.rn.f32 	%f565, %f564;
	fma.rn.f32 	%f566, %f559, %f565, %f551;
	mov.f32 	%f567, 0f3FC90FDB;
	sub.rn.f32 	%f568, %f567, %f566;
	setp.gt.f32 	%p433, %f183, %f182;
	selp.f32 	%f569, %f568, %f566, %p433;
	mov.b32 	%r1048, %f167;
	setp.lt.s32 	%p434, %r1048, 0;
	mov.f32 	%f570, 0f40490FDB;
	sub.rn.f32 	%f571, %f570, %f569;
	selp.f32 	%f572, %f571, %f569, %p434;
	mov.b32 	%r1049, %f572;
	mov.b32 	%r1050, %f168;
	and.b32  	%r1051, %r1050, -2147483648;
	or.b32  	%r1052, %r1051, %r1049;
	mov.b32 	%f573, %r1052;
	add.rn.f32 	%f574, %f182, %f183;
	setp.le.f32 	%p435, %f574, 0f7F800000;
	selp.f32 	%f701, %f573, %f574, %p435;

$L__BB7_408:
	mul.rn.f32 	%f188, %f167, 0f42517084;
	mul.rn.f32 	%f575, %f188, 0f3F22F983;
	cvt.rni.s32.f32 	%r1238, %f575;
	cvt.rn.f32.s32 	%f576, %r1238;
	mov.f32 	%f577, 0fBFC90FDA;
	fma.rn.f32 	%f578, %f576, %f577, %f188;
	mov.f32 	%f579, 0fB3A22168;
	fma.rn.f32 	%f580, %f576, %f579, %f578;
	mov.f32 	%f581, 0fA7C234C5;
	fma.rn.f32 	%f702, %f576, %f581, %f580;
	abs.f32 	%f190, %f188;
	setp.ltu.f32 	%p437, %f190, 0f47CE4780;
	@%p437 bra 	$L__BB7_416;

	setp.eq.f32 	%p438, %f190, 0f7F800000;
	@%p438 bra 	$L__BB7_415;
	bra.uni 	$L__BB7_410;

$L__BB7_415:
	mov.f32 	%f584, 0f00000000;
	mul.rn.f32 	%f702, %f188, %f584;
	mov.u32 	%r1238, 0;
	bra.uni 	$L__BB7_416;

$L__BB7_410:
	mov.b32 	%r295, %f188;
	bfe.u32 	%r1064, %r295, 23, 8;
	add.s32 	%r296, %r1064, -128;
	shl.b32 	%r1065, %r295, 8;
	or.b32  	%r297, %r1065, -2147483648;
	shr.u32 	%r298, %r296, 5;
	mov.u64 	%rd422, 0;
	mov.u64 	%rd423, %rd422;

$L__BB7_411:
	.pragma "nounroll";
	shl.b64 	%rd339, %rd422, 2;
	mov.u64 	%rd340, __cudart_i2opi_f;
	add.s64 	%rd341, %rd340, %rd339;
	ld.global.nc.u32 	%r1066, [%rd341];
	mad.wide.u32 	%rd342, %r1066, %r297, %rd423;
	shr.u64 	%rd423, %rd342, 32;
	add.s64 	%rd343, %rd1, %rd339;
	st.local.u32 	[%rd343], %rd342;
	cvt.u32.u64 	%r1067, %rd422;
	add.s32 	%r1068, %r1067, 1;
	cvt.s64.s32 	%rd422, %r1068;
	setp.ne.s32 	%p439, %r1068, 6;
	@%p439 bra 	$L__BB7_411;

	st.local.u32 	[%rd1+24], %rd423;
	mov.u32 	%r1069, 4;
	sub.s32 	%r299, %r1069, %r298;
	mov.u32 	%r1070, 6;
	sub.s32 	%r1071, %r1070, %r298;
	mul.wide.s32 	%rd344, %r1071, 4;
	add.s64 	%rd345, %rd1, %rd344;
	ld.local.u32 	%r1236, [%rd345];
	ld.local.u32 	%r1237, [%rd345+-4];
	and.b32  	%r302, %r296, 31;
	setp.eq.s32 	%p440, %r302, 0;
	@%p440 bra 	$L__BB7_414;

	mov.u32 	%r1072, 32;
	sub.s32 	%r1073, %r1072, %r302;
	shr.u32 	%r1074, %r1237, %r1073;
	shl.b32 	%r1075, %r1236, %r302;
	add.s32 	%r1236, %r1074, %r1075;
	mul.wide.s32 	%rd346, %r299, 4;
	add.s64 	%rd347, %rd1, %rd346;
	ld.local.u32 	%r1076, [%rd347];
	shr.u32 	%r1077, %r1076, %r1073;
	shl.b32 	%r1078, %r1237, %r302;
	add.s32 	%r1237, %r1077, %r1078;

$L__BB7_414:
	and.b32  	%r1079, %r295, -2147483648;
	shr.u32 	%r1080, %r1237, 30;
	shl.b32 	%r1081, %r1236, 2;
	or.b32  	%r1082, %r1080, %r1081;
	shr.u32 	%r1083, %r1082, 31;
	shr.u32 	%r1084, %r1236, 30;
	add.s32 	%r1085, %r1083, %r1084;
	neg.s32 	%r1086, %r1085;
	setp.eq.s32 	%p441, %r1079, 0;
	selp.b32 	%r1238, %r1085, %r1086, %p441;
	setp.ne.s32 	%p442, %r1083, 0;
	xor.b32  	%r1087, %r1079, -2147483648;
	selp.b32 	%r1088, %r1087, %r1079, %p442;
	selp.b32 	%r1089, -1, 0, %p442;
	xor.b32  	%r1090, %r1082, %r1089;
	shl.b32 	%r1091, %r1237, 2;
	xor.b32  	%r1092, %r1091, %r1089;
	cvt.u64.u32 	%rd348, %r1090;
	cvt.u64.u32 	%rd349, %r1092;
	bfi.b64 	%rd350, %rd348, %rd349, 32, 32;
	cvt.rn.f64.s64 	%fd930, %rd350;
	mul.rn.f64 	%fd931, %fd930, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f582, %fd931;
	setp.eq.s32 	%p443, %r1088, 0;
	neg.f32 	%f583, %f582;
	selp.f32 	%f702, %f582, %f583, %p443;

$L__BB7_416:
	cvt.rn.f32.f64 	%f194, %fd318;
	add.s32 	%r309, %r1238, 1;
	and.b32  	%r310, %r309, 1;
	setp.eq.s32 	%p444, %r310, 0;
	selp.f32 	%f195, %f702, 0f3F800000, %p444;
	mul.rn.f32 	%f196, %f702, %f702;
	mov.f32 	%f703, 0fB94D4153;
	@%p444 bra 	$L__BB7_418;

	mov.f32 	%f586, 0fBAB607ED;
	mov.f32 	%f587, 0f37CBAC00;
	fma.rn.f32 	%f703, %f587, %f196, %f586;

$L__BB7_418:
	selp.f32 	%f588, 0f3C0885E4, 0f3D2AAABB, %p444;
	fma.rn.f32 	%f589, %f703, %f196, %f588;
	selp.f32 	%f590, 0fBE2AAAA8, 0fBEFFFFFF, %p444;
	fma.rn.f32 	%f591, %f589, %f196, %f590;
	mov.f32 	%f592, 0f00000000;
	fma.rn.f32 	%f593, %f196, %f195, %f592;
	fma.rn.f32 	%f704, %f591, %f593, %f195;
	and.b32  	%r1094, %r309, 2;
	setp.eq.s32 	%p446, %r1094, 0;
	@%p446 bra 	$L__BB7_420;

	mov.f32 	%f595, 0fBF800000;
	fma.rn.f32 	%f704, %f704, %f595, %f592;

$L__BB7_420:
	cvt.f64.f32 	%fd932, %f704;
	mul.rn.f64 	%fd933, %fd932, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd934, %f701;
	add.rn.f64 	%fd935, %fd933, %fd934;
	cvt.rn.f32.f64 	%f202, %fd935;
	mul.rn.f32 	%f596, %f202, 0f3F22F983;
	cvt.rni.s32.f32 	%r1244, %f596;
	cvt.rn.f32.s32 	%f597, %r1244;
	mov.f32 	%f598, 0fBFC90FDA;
	fma.rn.f32 	%f599, %f597, %f598, %f202;
	mov.f32 	%f600, 0fB3A22168;
	fma.rn.f32 	%f601, %f597, %f600, %f599;
	mov.f32 	%f602, 0fA7C234C5;
	fma.rn.f32 	%f708, %f597, %f602, %f601;
	abs.f32 	%f204, %f202;
	setp.ltu.f32 	%p447, %f204, 0f47CE4780;
	mov.u32 	%r1241, %r1244;
	mov.f32 	%f705, %f708;
	@%p447 bra 	$L__BB7_428;

	setp.eq.f32 	%p448, %f204, 0f7F800000;
	@%p448 bra 	$L__BB7_427;
	bra.uni 	$L__BB7_422;

$L__BB7_427:
	mov.f32 	%f605, 0f00000000;
	mul.rn.f32 	%f705, %f202, %f605;
	mov.u32 	%r1241, 0;
	bra.uni 	$L__BB7_428;

$L__BB7_422:
	mov.b32 	%r312, %f202;
	bfe.u32 	%r1095, %r312, 23, 8;
	add.s32 	%r313, %r1095, -128;
	shl.b32 	%r1096, %r312, 8;
	or.b32  	%r314, %r1096, -2147483648;
	shr.u32 	%r315, %r313, 5;
	mov.u64 	%rd424, 0;
	mov.u64 	%rd425, %rd424;

$L__BB7_423:
	.pragma "nounroll";
	shl.b64 	%rd353, %rd424, 2;
	mov.u64 	%rd354, __cudart_i2opi_f;
	add.s64 	%rd355, %rd354, %rd353;
	ld.global.nc.u32 	%r1097, [%rd355];
	mad.wide.u32 	%rd356, %r1097, %r314, %rd425;
	shr.u64 	%rd425, %rd356, 32;
	add.s64 	%rd357, %rd1, %rd353;
	st.local.u32 	[%rd357], %rd356;
	cvt.u32.u64 	%r1098, %rd424;
	add.s32 	%r1099, %r1098, 1;
	cvt.s64.s32 	%rd424, %r1099;
	setp.ne.s32 	%p449, %r1099, 6;
	@%p449 bra 	$L__BB7_423;

	st.local.u32 	[%rd1+24], %rd425;
	mov.u32 	%r1100, 4;
	sub.s32 	%r316, %r1100, %r315;
	mov.u32 	%r1101, 6;
	sub.s32 	%r1102, %r1101, %r315;
	mul.wide.s32 	%rd358, %r1102, 4;
	add.s64 	%rd359, %rd1, %rd358;
	ld.local.u32 	%r1239, [%rd359];
	ld.local.u32 	%r1240, [%rd359+-4];
	and.b32  	%r319, %r313, 31;
	setp.eq.s32 	%p450, %r319, 0;
	@%p450 bra 	$L__BB7_426;

	mov.u32 	%r1103, 32;
	sub.s32 	%r1104, %r1103, %r319;
	shr.u32 	%r1105, %r1240, %r1104;
	shl.b32 	%r1106, %r1239, %r319;
	add.s32 	%r1239, %r1105, %r1106;
	mul.wide.s32 	%rd360, %r316, 4;
	add.s64 	%rd361, %rd1, %rd360;
	ld.local.u32 	%r1107, [%rd361];
	shr.u32 	%r1108, %r1107, %r1104;
	shl.b32 	%r1109, %r1240, %r319;
	add.s32 	%r1240, %r1108, %r1109;

$L__BB7_426:
	and.b32  	%r1110, %r312, -2147483648;
	shr.u32 	%r1111, %r1240, 30;
	shl.b32 	%r1112, %r1239, 2;
	or.b32  	%r1113, %r1111, %r1112;
	shr.u32 	%r1114, %r1113, 31;
	shr.u32 	%r1115, %r1239, 30;
	add.s32 	%r1116, %r1114, %r1115;
	neg.s32 	%r1117, %r1116;
	setp.eq.s32 	%p451, %r1110, 0;
	selp.b32 	%r1241, %r1116, %r1117, %p451;
	setp.ne.s32 	%p452, %r1114, 0;
	xor.b32  	%r1118, %r1110, -2147483648;
	selp.b32 	%r1119, %r1118, %r1110, %p452;
	selp.b32 	%r1120, -1, 0, %p452;
	xor.b32  	%r1121, %r1113, %r1120;
	shl.b32 	%r1122, %r1240, 2;
	xor.b32  	%r1123, %r1122, %r1120;
	cvt.u64.u32 	%rd362, %r1121;
	cvt.u64.u32 	%rd363, %r1123;
	bfi.b64 	%rd364, %rd362, %rd363, 32, 32;
	cvt.rn.f64.s64 	%fd936, %rd364;
	mul.rn.f64 	%fd937, %fd936, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f603, %fd937;
	setp.eq.s32 	%p453, %r1119, 0;
	neg.f32 	%f604, %f603;
	selp.f32 	%f705, %f603, %f604, %p453;

$L__BB7_428:
	add.s32 	%r326, %r1241, 1;
	and.b32  	%r327, %r326, 1;
	setp.eq.s32 	%p454, %r327, 0;
	selp.f32 	%f208, %f705, 0f3F800000, %p454;
	mul.rn.f32 	%f209, %f705, %f705;
	mov.f32 	%f706, 0fB94D4153;
	@%p454 bra 	$L__BB7_430;

	mov.f32 	%f607, 0fBAB607ED;
	mov.f32 	%f608, 0f37CBAC00;
	fma.rn.f32 	%f706, %f608, %f209, %f607;

$L__BB7_430:
	selp.f32 	%f609, 0f3C0885E4, 0f3D2AAABB, %p454;
	fma.rn.f32 	%f610, %f706, %f209, %f609;
	selp.f32 	%f611, 0fBE2AAAA8, 0fBEFFFFFF, %p454;
	fma.rn.f32 	%f612, %f610, %f209, %f611;
	mov.f32 	%f613, 0f00000000;
	fma.rn.f32 	%f614, %f209, %f208, %f613;
	fma.rn.f32 	%f707, %f612, %f614, %f208;
	and.b32  	%r1125, %r326, 2;
	setp.eq.s32 	%p456, %r1125, 0;
	@%p456 bra 	$L__BB7_432;

	mov.f32 	%f616, 0fBF800000;
	fma.rn.f32 	%f707, %f707, %f616, %f613;

$L__BB7_432:
	@%p447 bra 	$L__BB7_440;

	setp.eq.f32 	%p458, %f204, 0f7F800000;
	@%p458 bra 	$L__BB7_439;
	bra.uni 	$L__BB7_434;

$L__BB7_439:
	mov.f32 	%f619, 0f00000000;
	mul.rn.f32 	%f708, %f202, %f619;
	mov.u32 	%r1244, 0;
	bra.uni 	$L__BB7_440;

$L__BB7_434:
	mov.b32 	%r328, %f202;
	bfe.u32 	%r1126, %r328, 23, 8;
	add.s32 	%r329, %r1126, -128;
	shl.b32 	%r1127, %r328, 8;
	or.b32  	%r330, %r1127, -2147483648;
	shr.u32 	%r331, %r329, 5;
	mov.u64 	%rd426, 0;
	mov.u64 	%rd427, %rd426;

$L__BB7_435:
	.pragma "nounroll";
	shl.b64 	%rd367, %rd426, 2;
	mov.u64 	%rd368, __cudart_i2opi_f;
	add.s64 	%rd369, %rd368, %rd367;
	ld.global.nc.u32 	%r1128, [%rd369];
	mad.wide.u32 	%rd370, %r1128, %r330, %rd427;
	shr.u64 	%rd427, %rd370, 32;
	add.s64 	%rd371, %rd1, %rd367;
	st.local.u32 	[%rd371], %rd370;
	cvt.u32.u64 	%r1129, %rd426;
	add.s32 	%r1130, %r1129, 1;
	cvt.s64.s32 	%rd426, %r1130;
	setp.ne.s32 	%p459, %r1130, 6;
	@%p459 bra 	$L__BB7_435;

	st.local.u32 	[%rd1+24], %rd427;
	mov.u32 	%r1131, 4;
	sub.s32 	%r332, %r1131, %r331;
	mov.u32 	%r1132, 6;
	sub.s32 	%r1133, %r1132, %r331;
	mul.wide.s32 	%rd372, %r1133, 4;
	add.s64 	%rd373, %rd1, %rd372;
	ld.local.u32 	%r1242, [%rd373];
	ld.local.u32 	%r1243, [%rd373+-4];
	and.b32  	%r335, %r329, 31;
	setp.eq.s32 	%p460, %r335, 0;
	@%p460 bra 	$L__BB7_438;

	mov.u32 	%r1134, 32;
	sub.s32 	%r1135, %r1134, %r335;
	shr.u32 	%r1136, %r1243, %r1135;
	shl.b32 	%r1137, %r1242, %r335;
	add.s32 	%r1242, %r1136, %r1137;
	mul.wide.s32 	%rd374, %r332, 4;
	add.s64 	%rd375, %rd1, %rd374;
	ld.local.u32 	%r1138, [%rd375];
	shr.u32 	%r1139, %r1138, %r1135;
	shl.b32 	%r1140, %r1243, %r335;
	add.s32 	%r1243, %r1139, %r1140;

$L__BB7_438:
	and.b32  	%r1141, %r328, -2147483648;
	shr.u32 	%r1142, %r1243, 30;
	shl.b32 	%r1143, %r1242, 2;
	or.b32  	%r1144, %r1142, %r1143;
	shr.u32 	%r1145, %r1144, 31;
	shr.u32 	%r1146, %r1242, 30;
	add.s32 	%r1147, %r1145, %r1146;
	neg.s32 	%r1148, %r1147;
	setp.eq.s32 	%p461, %r1141, 0;
	selp.b32 	%r1244, %r1147, %r1148, %p461;
	setp.ne.s32 	%p462, %r1145, 0;
	xor.b32  	%r1149, %r1141, -2147483648;
	selp.b32 	%r1150, %r1149, %r1141, %p462;
	selp.b32 	%r1151, -1, 0, %p462;
	xor.b32  	%r1152, %r1144, %r1151;
	shl.b32 	%r1153, %r1243, 2;
	xor.b32  	%r1154, %r1153, %r1151;
	cvt.u64.u32 	%rd376, %r1152;
	cvt.u64.u32 	%rd377, %r1154;
	bfi.b64 	%rd378, %rd376, %rd377, 32, 32;
	cvt.rn.f64.s64 	%fd938, %rd378;
	mul.rn.f64 	%fd939, %fd938, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f617, %fd939;
	setp.eq.s32 	%p463, %r1150, 0;
	neg.f32 	%f618, %f617;
	selp.f32 	%f708, %f617, %f618, %p463;

$L__BB7_440:
	and.b32  	%r342, %r1244, 1;
	setp.eq.s32 	%p464, %r342, 0;
	selp.f32 	%f218, %f708, 0f3F800000, %p464;
	mul.rn.f32 	%f219, %f708, %f708;
	mov.f32 	%f709, 0fB94D4153;
	@%p464 bra 	$L__BB7_442;

	mov.f32 	%f621, 0fBAB607ED;
	mov.f32 	%f622, 0f37CBAC00;
	fma.rn.f32 	%f709, %f622, %f219, %f621;

$L__BB7_442:
	selp.f32 	%f623, 0f3C0885E4, 0f3D2AAABB, %p464;
	fma.rn.f32 	%f624, %f709, %f219, %f623;
	selp.f32 	%f625, 0fBE2AAAA8, 0fBEFFFFFF, %p464;
	fma.rn.f32 	%f626, %f624, %f219, %f625;
	mov.f32 	%f627, 0f00000000;
	fma.rn.f32 	%f628, %f219, %f218, %f627;
	fma.rn.f32 	%f710, %f626, %f628, %f218;
	and.b32  	%r1156, %r1244, 2;
	setp.eq.s32 	%p466, %r1156, 0;
	@%p466 bra 	$L__BB7_444;

	mov.f32 	%f630, 0fBF800000;
	fma.rn.f32 	%f710, %f710, %f630, %f627;

$L__BB7_444:
	ld.param.s8 	%rs2, [bd09_to_wgs84_exact_cuda_float_param_3];
	mul.rn.f32 	%f631, %f710, %f194;
	cvt.f64.f32 	%fd940, %f631;
	add.rn.f64 	%fd941, %fd940, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f632, %fd941;
	sub.rn.f32 	%f225, %f3, %f632;
	mul.rn.f32 	%f633, %f707, %f194;
	cvt.f64.f32 	%fd942, %f633;
	add.rn.f64 	%fd943, %fd942, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f634, %fd943;
	sub.rn.f32 	%f226, %f1, %f634;
	add.rn.f32 	%f227, %f711, %f226;
	add.rn.f32 	%f228, %f712, %f225;
	setp.eq.s16 	%p467, %rs2, 0;
	@%p467 bra 	$L__BB7_452;
	bra.uni 	$L__BB7_445;

$L__BB7_452:
	ld.param.f32 	%f649, [bd09_to_wgs84_exact_cuda_float_param_2];
	abs.f32 	%f640, %f226;
	abs.f32 	%f641, %f225;
	mul.rn.f32 	%f642, %f641, %f649;
	setp.lt.f32 	%p476, %f640, %f642;
	selp.f32 	%f643, 0f3F800000, 0f00000000, %p476;
	setp.lt.f32 	%p477, %f643, %f649;
	add.s32 	%r1211, %r1211, 1;
	@%p477 bra 	$L__BB7_454;

	ld.param.u32 	%r1169, [bd09_to_wgs84_exact_cuda_float_param_4];
	setp.lt.s32 	%p478, %r1211, %r1169;
	mov.f32 	%f712, %f228;
	mov.f32 	%f711, %f227;
	@%p478 bra 	$L__BB7_223;

$L__BB7_454:
	mov.u32 	%r1168, %tid.x;
	mov.u32 	%r1167, %ntid.x;
	mov.u32 	%r1166, %ctaid.x;
	mad.lo.s32 	%r1165, %r1166, %r1167, %r1168;
	mul.wide.s32 	%rd387, %r1165, 4;
	ld.param.u64 	%rd386, [bd09_to_wgs84_exact_cuda_float_param_1];
	cvta.to.global.u64 	%rd385, %rd386;
	add.s64 	%rd384, %rd385, %rd387;
	ld.param.u64 	%rd383, [bd09_to_wgs84_exact_cuda_float_param_0];
	cvta.to.global.u64 	%rd382, %rd383;
	add.s64 	%rd381, %rd382, %rd387;
	st.global.f32 	[%rd381], %f711;
	st.global.f32 	[%rd384], %f712;
	ret;

$L__BB7_445:
	mul.rn.f64 	%fd944, %fd294, 0d400921FB54442D18;
	div.rn.f64 	%fd945, %fd944, 0d4066800000000000;
	cvt.rn.f32.f64 	%f635, %fd945;
	cvt.f64.f32 	%fd946, %f711;
	mul.rn.f64 	%fd947, %fd946, 0d400921FB54442D18;
	div.rn.f64 	%fd948, %fd947, 0d4066800000000000;
	cvt.rn.f32.f64 	%f636, %fd948;
	cvt.f64.f32 	%fd949, %f228;
	mul.rn.f64 	%fd950, %fd949, 0d400921FB54442D18;
	div.rn.f64 	%fd951, %fd950, 0d4066800000000000;
	cvt.rn.f32.f64 	%f637, %fd951;
	cvt.f64.f32 	%fd952, %f227;
	mul.rn.f64 	%fd953, %fd952, 0d400921FB54442D18;
	div.rn.f64 	%fd954, %fd953, 0d4066800000000000;
	cvt.rn.f32.f64 	%f638, %fd954;
	sub.rn.f32 	%f639, %f637, %f635;
	sub.rn.f32 	%f229, %f638, %f636;
	cvt.f64.f32 	%fd955, %f639;
	mul.rn.f64 	%fd319, %fd955, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1157, %temp}, %fd319;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1158}, %fd319;
	}
	and.b32  	%r1159, %r1158, 2147483647;
	setp.eq.s32 	%p468, %r1159, 2146435072;
	setp.eq.s32 	%p469, %r1157, 0;
	and.pred  	%p470, %p469, %p468;
	@%p470 bra 	$L__BB7_448;

	mul.rn.f64 	%fd956, %fd319, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1160, %fd956;
	st.local.u32 	[%rd1], %r1160;
	abs.f64 	%fd957, %fd319;
	setp.ltu.f64 	%p471, %fd957, 0d41E0000000000000;
	@%p471 bra 	$L__BB7_448;

	{ // callseq 94, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd319;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd958, [retval0+0];
	} // callseq 94

$L__BB7_448:
	cvt.f64.f32 	%fd959, %f229;
	mul.rn.f64 	%fd320, %fd959, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r1161, %temp}, %fd320;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1162}, %fd320;
	}
	and.b32  	%r1163, %r1162, 2147483647;
	setp.eq.s32 	%p472, %r1163, 2146435072;
	setp.eq.s32 	%p473, %r1161, 0;
	and.pred  	%p474, %p473, %p472;
	@%p474 bra 	$L__BB7_451;

	mul.rn.f64 	%fd960, %fd320, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r1164, %fd960;
	st.local.u32 	[%rd1], %r1164;
	abs.f64 	%fd961, %fd320;
	setp.ltu.f64 	%p475, %fd961, 0d41E0000000000000;
	@%p475 bra 	$L__BB7_451;

	{ // callseq 95, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd320;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd103;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd962, [retval0+0];
	} // callseq 95

$L__BB7_451:

}
	// .globl	bd09_to_gcj02_exact_cuda_float
.visible .entry bd09_to_gcj02_exact_cuda_float(
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_0,
	.param .u64 bd09_to_gcj02_exact_cuda_float_param_1,
	.param .f32 bd09_to_gcj02_exact_cuda_float_param_2,
	.param .u8 bd09_to_gcj02_exact_cuda_float_param_3,
	.param .u32 bd09_to_gcj02_exact_cuda_float_param_4
)
{
	.local .align 4 .b8 	__local_depot8[28];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<209>;
	.reg .b16 	%rs<2>;
	.reg .f32 	%f<378>;
	.reg .b32 	%r<553>;
	.reg .f64 	%fd<148>;
	.reg .b64 	%rd<169>;


	mov.u64 	%SPL, __local_depot8;
	cvta.local.u64 	%SP, %SPL;
	ld.param.s8 	%rs1, [bd09_to_gcj02_exact_cuda_float_param_3];
	ld.param.u64 	%rd45, [bd09_to_gcj02_exact_cuda_float_param_0];
	ld.param.u64 	%rd46, [bd09_to_gcj02_exact_cuda_float_param_1];
	ld.param.f32 	%f128, [bd09_to_gcj02_exact_cuda_float_param_2];
	ld.param.u32 	%r154, [bd09_to_gcj02_exact_cuda_float_param_4];
	add.u64 	%rd47, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r155, %ntid.x;
	mov.u32 	%r156, %ctaid.x;
	mov.u32 	%r157, %tid.x;
	mad.lo.s32 	%r158, %r156, %r155, %r157;
	cvta.to.global.u64 	%rd48, %rd45;
	mul.wide.s32 	%rd49, %r158, 4;
	add.s64 	%rd2, %rd48, %rd49;
	cvta.to.global.u64 	%rd50, %rd46;
	add.s64 	%rd3, %rd50, %rd49;
	ld.global.f32 	%f1, [%rd2];
	cvt.f64.f32 	%fd50, %f1;
	add.rn.f64 	%fd51, %fd50, 0dBF7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f2, %fd51;
	ld.global.f32 	%f3, [%rd3];
	cvt.f64.f32 	%fd52, %f3;
	add.rn.f64 	%fd53, %fd52, 0dBF789374BC6A7EFA;
	cvt.rn.f32.f64 	%f4, %fd53;
	cvt.f64.f32 	%fd1, %f2;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd54, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd54;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p5, %r3, 1062207488;
	abs.f64 	%fd2, %fd1;
	{ // callseq 96, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd2;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd138, [retval0+0];
	} // callseq 96
	setp.lt.s32 	%p6, %r1, 0;
	and.pred  	%p1, %p6, %p5;
	not.pred 	%p7, %p1;
	@%p7 bra 	$L__BB8_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r159}, %fd138;
	}
	xor.b32  	%r160, %r159, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd138;
	}
	mov.b64 	%fd138, {%r161, %r160};

$L__BB8_2:
	setp.eq.f32 	%p8, %f2, 0f00000000;
	@%p8 bra 	$L__BB8_6;
	bra.uni 	$L__BB8_3;

$L__BB8_6:
	selp.b32 	%r162, %r1, 0, %p5;
	mov.u32 	%r163, 0;
	or.b32  	%r164, %r162, 2146435072;
	setp.lt.s32 	%p12, %r2, 0;
	selp.b32 	%r165, %r164, %r162, %p12;
	mov.b64 	%fd138, {%r163, %r165};
	bra.uni 	$L__BB8_7;

$L__BB8_3:
	setp.gt.s32 	%p9, %r1, -1;
	@%p9 bra 	$L__BB8_7;

	mov.f64 	%fd55, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd56, %fd55;
	setp.eq.f64 	%p10, %fd56, 0d4000000000000000;
	@%p10 bra 	$L__BB8_7;

	mov.f64 	%fd138, 0dFFF8000000000000;

$L__BB8_7:
	add.rn.f64 	%fd58, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r166}, %fd58;
	}
	and.b32  	%r167, %r166, 2146435072;
	setp.ne.s32 	%p13, %r167, 2146435072;
	@%p13 bra 	$L__BB8_14;

	setp.gtu.f64 	%p14, %fd2, 0d7FF0000000000000;
	@%p14 bra 	$L__BB8_13;
	bra.uni 	$L__BB8_9;

$L__BB8_13:
	mov.f64 	%fd60, 0d4000000000000000;
	add.rn.f64 	%fd138, %fd1, %fd60;
	bra.uni 	$L__BB8_14;

$L__BB8_9:
	mov.f64 	%fd59, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r168, %temp}, %fd59;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p15, %r4, 2146435072;
	setp.eq.s32 	%p16, %r168, 0;
	and.pred  	%p17, %p15, %p16;
	@%p17 bra 	$L__BB8_12;
	bra.uni 	$L__BB8_10;

$L__BB8_12:
	setp.gt.f64 	%p24, %fd2, 0d3FF0000000000000;
	selp.b32 	%r175, 2146435072, 0, %p24;
	mov.u32 	%r176, 0;
	xor.b32  	%r177, %r175, 2146435072;
	setp.lt.s32 	%p25, %r2, 0;
	selp.b32 	%r178, %r177, %r175, %p25;
	setp.eq.f32 	%p26, %f2, 0fBF800000;
	selp.b32 	%r179, 1072693248, %r178, %p26;
	mov.b64 	%fd138, {%r176, %r179};
	bra.uni 	$L__BB8_14;

$L__BB8_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd1;
	}
	and.b32  	%r170, %r1, 2147483647;
	setp.ne.s32 	%p18, %r170, 2146435072;
	setp.ne.s32 	%p19, %r169, 0;
	or.pred  	%p20, %p18, %p19;
	@%p20 bra 	$L__BB8_14;

	setp.gt.s32 	%p21, %r2, -1;
	selp.b32 	%r171, 2146435072, 0, %p21;
	mov.u32 	%r172, 0;
	setp.ne.s32 	%p22, %r4, 1071644672;
	and.pred  	%p23, %p22, %p1;
	or.b32  	%r173, %r171, -2147483648;
	selp.b32 	%r174, %r173, %r171, %p23;
	mov.b64 	%fd138, {%r172, %r174};

$L__BB8_14:
	cvt.f64.f32 	%fd12, %f4;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd12;
	}
	abs.f64 	%fd13, %fd12;
	{ // callseq 97, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd141, [retval0+0];
	} // callseq 97
	setp.lt.s32 	%p27, %r5, 0;
	and.pred  	%p2, %p27, %p5;
	not.pred 	%p29, %p2;
	@%p29 bra 	$L__BB8_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r180}, %fd141;
	}
	xor.b32  	%r181, %r180, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd141;
	}
	mov.b64 	%fd141, {%r182, %r181};

$L__BB8_16:
	setp.eq.f32 	%p30, %f4, 0f00000000;
	@%p30 bra 	$L__BB8_20;
	bra.uni 	$L__BB8_17;

$L__BB8_20:
	selp.b32 	%r183, %r5, 0, %p5;
	mov.u32 	%r184, 0;
	or.b32  	%r185, %r183, 2146435072;
	setp.lt.s32 	%p34, %r2, 0;
	selp.b32 	%r186, %r185, %r183, %p34;
	mov.b64 	%fd141, {%r184, %r186};
	bra.uni 	$L__BB8_21;

$L__BB8_17:
	setp.gt.s32 	%p31, %r5, -1;
	@%p31 bra 	$L__BB8_21;

	mov.f64 	%fd61, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd62, %fd61;
	setp.eq.f64 	%p32, %fd62, 0d4000000000000000;
	@%p32 bra 	$L__BB8_21;

	mov.f64 	%fd141, 0dFFF8000000000000;

$L__BB8_21:
	add.rn.f64 	%fd64, %fd12, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r187}, %fd64;
	}
	and.b32  	%r188, %r187, 2146435072;
	setp.ne.s32 	%p35, %r188, 2146435072;
	@%p35 bra 	$L__BB8_28;

	setp.gtu.f64 	%p36, %fd13, 0d7FF0000000000000;
	@%p36 bra 	$L__BB8_27;
	bra.uni 	$L__BB8_23;

$L__BB8_27:
	mov.f64 	%fd66, 0d4000000000000000;
	add.rn.f64 	%fd141, %fd12, %fd66;
	bra.uni 	$L__BB8_28;

$L__BB8_23:
	mov.f64 	%fd65, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r189, %temp}, %fd65;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p37, %r6, 2146435072;
	setp.eq.s32 	%p38, %r189, 0;
	and.pred  	%p39, %p37, %p38;
	@%p39 bra 	$L__BB8_26;
	bra.uni 	$L__BB8_24;

$L__BB8_26:
	setp.gt.f64 	%p46, %fd13, 0d3FF0000000000000;
	selp.b32 	%r196, 2146435072, 0, %p46;
	mov.u32 	%r197, 0;
	xor.b32  	%r198, %r196, 2146435072;
	setp.lt.s32 	%p47, %r2, 0;
	selp.b32 	%r199, %r198, %r196, %p47;
	setp.eq.f32 	%p48, %f4, 0fBF800000;
	selp.b32 	%r200, 1072693248, %r199, %p48;
	mov.b64 	%fd141, {%r197, %r200};
	bra.uni 	$L__BB8_28;

$L__BB8_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r190, %temp}, %fd12;
	}
	and.b32  	%r191, %r5, 2147483647;
	setp.ne.s32 	%p40, %r191, 2146435072;
	setp.ne.s32 	%p41, %r190, 0;
	or.pred  	%p42, %p40, %p41;
	@%p42 bra 	$L__BB8_28;

	setp.gt.s32 	%p43, %r2, -1;
	selp.b32 	%r192, 2146435072, 0, %p43;
	mov.u32 	%r193, 0;
	setp.ne.s32 	%p44, %r6, 1071644672;
	and.pred  	%p45, %p44, %p2;
	or.b32  	%r194, %r192, -2147483648;
	selp.b32 	%r195, %r194, %r192, %p45;
	mov.b64 	%fd141, {%r193, %r195};

$L__BB8_28:
	setp.eq.f32 	%p49, %f4, 0f3F800000;
	selp.f64 	%fd67, 0d3FF0000000000000, %fd141, %p49;
	setp.eq.f32 	%p50, %f2, 0f3F800000;
	selp.f64 	%fd68, 0d3FF0000000000000, %fd138, %p50;
	add.rn.f64 	%fd23, %fd68, %fd67;
	mul.rn.f32 	%f5, %f4, 0f42517084;
	mul.rn.f32 	%f129, %f5, 0f3F22F983;
	cvt.rni.s32.f32 	%r526, %f129;
	cvt.rn.f32.s32 	%f130, %r526;
	mov.f32 	%f131, 0fBFC90FDA;
	fma.rn.f32 	%f132, %f130, %f131, %f5;
	mov.f32 	%f133, 0fB3A22168;
	fma.rn.f32 	%f134, %f130, %f133, %f132;
	mov.f32 	%f135, 0fA7C234C5;
	fma.rn.f32 	%f348, %f130, %f135, %f134;
	abs.f32 	%f7, %f5;
	setp.ltu.f32 	%p51, %f7, 0f47CE4780;
	@%p51 bra 	$L__BB8_36;

	setp.eq.f32 	%p52, %f7, 0f7F800000;
	@%p52 bra 	$L__BB8_35;
	bra.uni 	$L__BB8_30;

$L__BB8_35:
	mov.f32 	%f138, 0f00000000;
	mul.rn.f32 	%f348, %f5, %f138;
	mov.u32 	%r526, 0;
	bra.uni 	$L__BB8_36;

$L__BB8_30:
	mov.b32 	%r8, %f5;
	bfe.u32 	%r202, %r8, 23, 8;
	add.s32 	%r9, %r202, -128;
	shl.b32 	%r203, %r8, 8;
	or.b32  	%r10, %r203, -2147483648;
	shr.u32 	%r11, %r9, 5;
	mov.u64 	%rd151, 0;
	mov.u32 	%r523, 0;
	mov.u64 	%rd150, __cudart_i2opi_f;
	mov.u64 	%rd149, %rd1;

$L__BB8_31:
	.pragma "nounroll";
	ld.global.nc.u32 	%r204, [%rd150];
	mad.wide.u32 	%rd53, %r204, %r10, %rd151;
	shr.u64 	%rd151, %rd53, 32;
	st.local.u32 	[%rd149], %rd53;
	add.s64 	%rd150, %rd150, 4;
	add.s64 	%rd149, %rd149, 4;
	add.s32 	%r523, %r523, 1;
	setp.ne.s32 	%p53, %r523, 6;
	@%p53 bra 	$L__BB8_31;

	st.local.u32 	[%rd1+24], %rd151;
	mov.u32 	%r205, 4;
	sub.s32 	%r14, %r205, %r11;
	mov.u32 	%r206, 6;
	sub.s32 	%r207, %r206, %r11;
	mul.wide.s32 	%rd54, %r207, 4;
	add.s64 	%rd55, %rd1, %rd54;
	ld.local.u32 	%r524, [%rd55];
	ld.local.u32 	%r525, [%rd55+-4];
	and.b32  	%r17, %r9, 31;
	setp.eq.s32 	%p54, %r17, 0;
	@%p54 bra 	$L__BB8_34;

	mov.u32 	%r208, 32;
	sub.s32 	%r209, %r208, %r17;
	shr.u32 	%r210, %r525, %r209;
	shl.b32 	%r211, %r524, %r17;
	add.s32 	%r524, %r210, %r211;
	mul.wide.s32 	%rd56, %r14, 4;
	add.s64 	%rd57, %rd1, %rd56;
	ld.local.u32 	%r212, [%rd57];
	shr.u32 	%r213, %r212, %r209;
	shl.b32 	%r214, %r525, %r17;
	add.s32 	%r525, %r213, %r214;

$L__BB8_34:
	and.b32  	%r215, %r8, -2147483648;
	shr.u32 	%r216, %r525, 30;
	shl.b32 	%r217, %r524, 2;
	or.b32  	%r218, %r216, %r217;
	shr.u32 	%r219, %r218, 31;
	shr.u32 	%r220, %r524, 30;
	add.s32 	%r221, %r219, %r220;
	neg.s32 	%r222, %r221;
	setp.eq.s32 	%p55, %r215, 0;
	selp.b32 	%r526, %r221, %r222, %p55;
	setp.ne.s32 	%p56, %r219, 0;
	xor.b32  	%r223, %r215, -2147483648;
	selp.b32 	%r224, %r223, %r215, %p56;
	selp.b32 	%r225, -1, 0, %p56;
	xor.b32  	%r226, %r218, %r225;
	shl.b32 	%r227, %r525, 2;
	xor.b32  	%r228, %r227, %r225;
	cvt.u64.u32 	%rd58, %r226;
	cvt.u64.u32 	%rd59, %r228;
	bfi.b64 	%rd60, %rd58, %rd59, 32, 32;
	cvt.rn.f64.s64 	%fd69, %rd60;
	mul.rn.f64 	%fd70, %fd69, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f136, %fd70;
	setp.eq.s32 	%p57, %r224, 0;
	neg.f32 	%f137, %f136;
	selp.f32 	%f348, %f136, %f137, %p57;

$L__BB8_36:
	and.b32  	%r24, %r526, 1;
	setp.eq.s32 	%p58, %r24, 0;
	selp.f32 	%f11, %f348, 0f3F800000, %p58;
	mul.rn.f32 	%f12, %f348, %f348;
	mov.f32 	%f349, 0fB94D4153;
	@%p58 bra 	$L__BB8_38;

	mov.f32 	%f140, 0fBAB607ED;
	mov.f32 	%f141, 0f37CBAC00;
	fma.rn.f32 	%f349, %f141, %f12, %f140;

$L__BB8_38:
	selp.f32 	%f142, 0f3C0885E4, 0f3D2AAABB, %p58;
	fma.rn.f32 	%f143, %f349, %f12, %f142;
	selp.f32 	%f144, 0fBE2AAAA8, 0fBEFFFFFF, %p58;
	fma.rn.f32 	%f145, %f143, %f12, %f144;
	mov.f32 	%f146, 0f00000000;
	fma.rn.f32 	%f147, %f12, %f11, %f146;
	fma.rn.f32 	%f350, %f145, %f147, %f11;
	and.b32  	%r230, %r526, 2;
	setp.eq.s32 	%p60, %r230, 0;
	@%p60 bra 	$L__BB8_40;

	mov.f32 	%f149, 0fBF800000;
	fma.rn.f32 	%f350, %f350, %f149, %f146;

$L__BB8_40:
	cvt.f64.f32 	%fd71, %f350;
	mul.rn.f64 	%fd72, %fd71, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd73, %fd23;
	add.rn.f64 	%fd74, %fd73, %fd72;
	cvt.rn.f32.f64 	%f18, %fd74;
	abs.f32 	%f19, %f2;
	setp.eq.f32 	%p61, %f19, 0f00000000;
	abs.f32 	%f20, %f4;
	setp.eq.f32 	%p62, %f20, 0f00000000;
	and.pred  	%p63, %p61, %p62;
	@%p63 bra 	$L__BB8_44;
	bra.uni 	$L__BB8_41;

$L__BB8_44:
	mov.b32 	%r241, %f2;
	shr.s32 	%r242, %r241, 31;
	and.b32  	%r243, %r242, 1078530011;
	mov.b32 	%r244, %f4;
	and.b32  	%r245, %r244, -2147483648;
	or.b32  	%r246, %r243, %r245;
	mov.b32 	%f351, %r246;
	bra.uni 	$L__BB8_45;

$L__BB8_41:
	setp.eq.f32 	%p64, %f19, 0f7F800000;
	setp.eq.f32 	%p65, %f20, 0f7F800000;
	and.pred  	%p66, %p64, %p65;
	@%p66 bra 	$L__BB8_43;
	bra.uni 	$L__BB8_42;

$L__BB8_43:
	mov.b32 	%r236, %f2;
	setp.lt.s32 	%p70, %r236, 0;
	selp.b32 	%r237, 1075235812, 1061752795, %p70;
	mov.b32 	%r238, %f4;
	and.b32  	%r239, %r238, -2147483648;
	or.b32  	%r240, %r237, %r239;
	mov.b32 	%f351, %r240;
	bra.uni 	$L__BB8_45;

$L__BB8_42:
	max.f32 	%f150, %f20, %f19;
	min.f32 	%f151, %f20, %f19;
	div.rn.f32 	%f152, %f151, %f150;
	mul.rn.f32 	%f153, %f152, %f152;
	mov.f32 	%f154, 0fC0B59883;
	mov.f32 	%f155, 0fBF52C7EA;
	fma.rn.f32 	%f156, %f153, %f155, %f154;
	mov.f32 	%f157, 0fC0D21907;
	fma.rn.f32 	%f158, %f156, %f153, %f157;
	mul.rn.f32 	%f159, %f153, %f158;
	mul.rn.f32 	%f160, %f152, %f159;
	add.rn.f32 	%f161, %f153, 0f41355DC0;
	mov.f32 	%f162, 0f41E6BD60;
	fma.rn.f32 	%f163, %f161, %f153, %f162;
	mov.f32 	%f164, 0f419D92C8;
	fma.rn.f32 	%f165, %f163, %f153, %f164;
	rcp.rn.f32 	%f166, %f165;
	fma.rn.f32 	%f167, %f160, %f166, %f152;
	mov.f32 	%f168, 0f3FC90FDB;
	sub.rn.f32 	%f169, %f168, %f167;
	setp.gt.f32 	%p67, %f20, %f19;
	selp.f32 	%f170, %f169, %f167, %p67;
	mov.b32 	%r231, %f2;
	setp.lt.s32 	%p68, %r231, 0;
	mov.f32 	%f171, 0f40490FDB;
	sub.rn.f32 	%f172, %f171, %f170;
	selp.f32 	%f173, %f172, %f170, %p68;
	mov.b32 	%r232, %f173;
	mov.b32 	%r233, %f4;
	and.b32  	%r234, %r233, -2147483648;
	or.b32  	%r235, %r234, %r232;
	mov.b32 	%f174, %r235;
	add.rn.f32 	%f175, %f19, %f20;
	setp.le.f32 	%p69, %f175, 0f7F800000;
	selp.f32 	%f351, %f174, %f175, %p69;

$L__BB8_45:
	mul.rn.f32 	%f25, %f2, 0f42517084;
	mul.rn.f32 	%f176, %f25, 0f3F22F983;
	cvt.rni.s32.f32 	%r530, %f176;
	cvt.rn.f32.s32 	%f177, %r530;
	mov.f32 	%f178, 0fBFC90FDA;
	fma.rn.f32 	%f179, %f177, %f178, %f25;
	mov.f32 	%f180, 0fB3A22168;
	fma.rn.f32 	%f181, %f177, %f180, %f179;
	mov.f32 	%f182, 0fA7C234C5;
	fma.rn.f32 	%f352, %f177, %f182, %f181;
	abs.f32 	%f27, %f25;
	setp.ltu.f32 	%p71, %f27, 0f47CE4780;
	@%p71 bra 	$L__BB8_53;

	setp.eq.f32 	%p72, %f27, 0f7F800000;
	@%p72 bra 	$L__BB8_52;
	bra.uni 	$L__BB8_47;

$L__BB8_52:
	mov.f32 	%f185, 0f00000000;
	mul.rn.f32 	%f352, %f25, %f185;
	mov.u32 	%r530, 0;
	bra.uni 	$L__BB8_53;

$L__BB8_47:
	mov.b32 	%r26, %f25;
	bfe.u32 	%r248, %r26, 23, 8;
	add.s32 	%r27, %r248, -128;
	shl.b32 	%r249, %r26, 8;
	or.b32  	%r28, %r249, -2147483648;
	shr.u32 	%r29, %r27, 5;
	mov.u64 	%rd154, 0;
	mov.u32 	%r527, 0;
	mov.u64 	%rd153, __cudart_i2opi_f;
	mov.u64 	%rd152, %rd1;

$L__BB8_48:
	.pragma "nounroll";
	ld.global.nc.u32 	%r250, [%rd153];
	mad.wide.u32 	%rd63, %r250, %r28, %rd154;
	shr.u64 	%rd154, %rd63, 32;
	st.local.u32 	[%rd152], %rd63;
	add.s64 	%rd153, %rd153, 4;
	add.s64 	%rd152, %rd152, 4;
	add.s32 	%r527, %r527, 1;
	setp.ne.s32 	%p73, %r527, 6;
	@%p73 bra 	$L__BB8_48;

	st.local.u32 	[%rd1+24], %rd154;
	mov.u32 	%r251, 4;
	sub.s32 	%r32, %r251, %r29;
	mov.u32 	%r252, 6;
	sub.s32 	%r253, %r252, %r29;
	mul.wide.s32 	%rd64, %r253, 4;
	add.s64 	%rd65, %rd1, %rd64;
	ld.local.u32 	%r528, [%rd65];
	ld.local.u32 	%r529, [%rd65+-4];
	and.b32  	%r35, %r27, 31;
	setp.eq.s32 	%p74, %r35, 0;
	@%p74 bra 	$L__BB8_51;

	mov.u32 	%r254, 32;
	sub.s32 	%r255, %r254, %r35;
	shr.u32 	%r256, %r529, %r255;
	shl.b32 	%r257, %r528, %r35;
	add.s32 	%r528, %r256, %r257;
	mul.wide.s32 	%rd66, %r32, 4;
	add.s64 	%rd67, %rd1, %rd66;
	ld.local.u32 	%r258, [%rd67];
	shr.u32 	%r259, %r258, %r255;
	shl.b32 	%r260, %r529, %r35;
	add.s32 	%r529, %r259, %r260;

$L__BB8_51:
	and.b32  	%r261, %r26, -2147483648;
	shr.u32 	%r262, %r529, 30;
	shl.b32 	%r263, %r528, 2;
	or.b32  	%r264, %r262, %r263;
	shr.u32 	%r265, %r264, 31;
	shr.u32 	%r266, %r528, 30;
	add.s32 	%r267, %r265, %r266;
	neg.s32 	%r268, %r267;
	setp.eq.s32 	%p75, %r261, 0;
	selp.b32 	%r530, %r267, %r268, %p75;
	setp.ne.s32 	%p76, %r265, 0;
	xor.b32  	%r269, %r261, -2147483648;
	selp.b32 	%r270, %r269, %r261, %p76;
	selp.b32 	%r271, -1, 0, %p76;
	xor.b32  	%r272, %r264, %r271;
	shl.b32 	%r273, %r529, 2;
	xor.b32  	%r274, %r273, %r271;
	cvt.u64.u32 	%rd68, %r272;
	cvt.u64.u32 	%rd69, %r274;
	bfi.b64 	%rd70, %rd68, %rd69, 32, 32;
	cvt.rn.f64.s64 	%fd75, %rd70;
	mul.rn.f64 	%fd76, %fd75, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f183, %fd76;
	setp.eq.s32 	%p77, %r270, 0;
	neg.f32 	%f184, %f183;
	selp.f32 	%f352, %f183, %f184, %p77;

$L__BB8_53:
	add.s32 	%r42, %r530, 1;
	and.b32  	%r43, %r42, 1;
	setp.eq.s32 	%p78, %r43, 0;
	selp.f32 	%f31, %f352, 0f3F800000, %p78;
	mul.rn.f32 	%f32, %f352, %f352;
	mov.f32 	%f353, 0fB94D4153;
	@%p78 bra 	$L__BB8_55;

	mov.f32 	%f187, 0fBAB607ED;
	mov.f32 	%f188, 0f37CBAC00;
	fma.rn.f32 	%f353, %f188, %f32, %f187;

$L__BB8_55:
	selp.f32 	%f189, 0f3C0885E4, 0f3D2AAABB, %p78;
	fma.rn.f32 	%f190, %f353, %f32, %f189;
	selp.f32 	%f191, 0fBE2AAAA8, 0fBEFFFFFF, %p78;
	fma.rn.f32 	%f192, %f190, %f32, %f191;
	mov.f32 	%f193, 0f00000000;
	fma.rn.f32 	%f194, %f32, %f31, %f193;
	fma.rn.f32 	%f354, %f192, %f194, %f31;
	and.b32  	%r276, %r42, 2;
	setp.eq.s32 	%p80, %r276, 0;
	@%p80 bra 	$L__BB8_57;

	mov.f32 	%f196, 0fBF800000;
	fma.rn.f32 	%f354, %f354, %f196, %f193;

$L__BB8_57:
	cvt.f64.f32 	%fd77, %f354;
	mul.rn.f64 	%fd78, %fd77, 0dBEC92A737110E454;
	cvt.f64.f32 	%fd79, %f351;
	add.rn.f64 	%fd80, %fd79, %fd78;
	cvt.rn.f32.f64 	%f38, %fd80;
	mul.rn.f32 	%f197, %f38, 0f3F22F983;
	cvt.rni.s32.f32 	%r538, %f197;
	cvt.rn.f32.s32 	%f198, %r538;
	mov.f32 	%f199, 0fBFC90FDA;
	fma.rn.f32 	%f200, %f198, %f199, %f38;
	mov.f32 	%f201, 0fB3A22168;
	fma.rn.f32 	%f202, %f198, %f201, %f200;
	mov.f32 	%f203, 0fA7C234C5;
	fma.rn.f32 	%f358, %f198, %f203, %f202;
	abs.f32 	%f40, %f38;
	setp.ltu.f32 	%p81, %f40, 0f47CE4780;
	mov.u32 	%r534, %r538;
	mov.f32 	%f355, %f358;
	@%p81 bra 	$L__BB8_65;

	setp.eq.f32 	%p82, %f40, 0f7F800000;
	@%p82 bra 	$L__BB8_64;
	bra.uni 	$L__BB8_59;

$L__BB8_64:
	mov.f32 	%f206, 0f00000000;
	mul.rn.f32 	%f355, %f38, %f206;
	mov.u32 	%r534, 0;
	bra.uni 	$L__BB8_65;

$L__BB8_59:
	mov.b32 	%r45, %f38;
	bfe.u32 	%r278, %r45, 23, 8;
	add.s32 	%r46, %r278, -128;
	shl.b32 	%r279, %r45, 8;
	or.b32  	%r47, %r279, -2147483648;
	shr.u32 	%r48, %r46, 5;
	mov.u64 	%rd157, 0;
	mov.u32 	%r531, 0;
	mov.u64 	%rd156, __cudart_i2opi_f;
	mov.u64 	%rd155, %rd1;

$L__BB8_60:
	.pragma "nounroll";
	ld.global.nc.u32 	%r280, [%rd156];
	mad.wide.u32 	%rd73, %r280, %r47, %rd157;
	shr.u64 	%rd157, %rd73, 32;
	st.local.u32 	[%rd155], %rd73;
	add.s64 	%rd156, %rd156, 4;
	add.s64 	%rd155, %rd155, 4;
	add.s32 	%r531, %r531, 1;
	setp.ne.s32 	%p83, %r531, 6;
	@%p83 bra 	$L__BB8_60;

	st.local.u32 	[%rd1+24], %rd157;
	mov.u32 	%r281, 4;
	sub.s32 	%r51, %r281, %r48;
	mov.u32 	%r282, 6;
	sub.s32 	%r283, %r282, %r48;
	mul.wide.s32 	%rd74, %r283, 4;
	add.s64 	%rd75, %rd1, %rd74;
	ld.local.u32 	%r532, [%rd75];
	ld.local.u32 	%r533, [%rd75+-4];
	and.b32  	%r54, %r46, 31;
	setp.eq.s32 	%p84, %r54, 0;
	@%p84 bra 	$L__BB8_63;

	mov.u32 	%r284, 32;
	sub.s32 	%r285, %r284, %r54;
	shr.u32 	%r286, %r533, %r285;
	shl.b32 	%r287, %r532, %r54;
	add.s32 	%r532, %r286, %r287;
	mul.wide.s32 	%rd76, %r51, 4;
	add.s64 	%rd77, %rd1, %rd76;
	ld.local.u32 	%r288, [%rd77];
	shr.u32 	%r289, %r288, %r285;
	shl.b32 	%r290, %r533, %r54;
	add.s32 	%r533, %r289, %r290;

$L__BB8_63:
	and.b32  	%r291, %r45, -2147483648;
	shr.u32 	%r292, %r533, 30;
	shl.b32 	%r293, %r532, 2;
	or.b32  	%r294, %r292, %r293;
	shr.u32 	%r295, %r294, 31;
	shr.u32 	%r296, %r532, 30;
	add.s32 	%r297, %r295, %r296;
	neg.s32 	%r298, %r297;
	setp.eq.s32 	%p85, %r291, 0;
	selp.b32 	%r534, %r297, %r298, %p85;
	setp.ne.s32 	%p86, %r295, 0;
	xor.b32  	%r299, %r291, -2147483648;
	selp.b32 	%r300, %r299, %r291, %p86;
	selp.b32 	%r301, -1, 0, %p86;
	xor.b32  	%r302, %r294, %r301;
	shl.b32 	%r303, %r533, 2;
	xor.b32  	%r304, %r303, %r301;
	cvt.u64.u32 	%rd78, %r302;
	cvt.u64.u32 	%rd79, %r304;
	bfi.b64 	%rd80, %rd78, %rd79, 32, 32;
	cvt.rn.f64.s64 	%fd81, %rd80;
	mul.rn.f64 	%fd82, %fd81, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f204, %fd82;
	setp.eq.s32 	%p87, %r300, 0;
	neg.f32 	%f205, %f204;
	selp.f32 	%f355, %f204, %f205, %p87;

$L__BB8_65:
	add.s32 	%r61, %r534, 1;
	and.b32  	%r62, %r61, 1;
	setp.eq.s32 	%p88, %r62, 0;
	selp.f32 	%f44, %f355, 0f3F800000, %p88;
	mul.rn.f32 	%f45, %f355, %f355;
	mov.f32 	%f356, 0fB94D4153;
	@%p88 bra 	$L__BB8_67;

	mov.f32 	%f208, 0fBAB607ED;
	mov.f32 	%f209, 0f37CBAC00;
	fma.rn.f32 	%f356, %f209, %f45, %f208;

$L__BB8_67:
	selp.f32 	%f210, 0f3C0885E4, 0f3D2AAABB, %p88;
	fma.rn.f32 	%f211, %f356, %f45, %f210;
	selp.f32 	%f212, 0fBE2AAAA8, 0fBEFFFFFF, %p88;
	fma.rn.f32 	%f213, %f211, %f45, %f212;
	mov.f32 	%f214, 0f00000000;
	fma.rn.f32 	%f215, %f45, %f44, %f214;
	fma.rn.f32 	%f357, %f213, %f215, %f44;
	and.b32  	%r306, %r61, 2;
	setp.eq.s32 	%p90, %r306, 0;
	@%p90 bra 	$L__BB8_69;

	mov.f32 	%f217, 0fBF800000;
	fma.rn.f32 	%f357, %f357, %f217, %f214;

$L__BB8_69:
	mul.rn.f32 	%f376, %f357, %f18;
	@%p81 bra 	$L__BB8_77;

	setp.eq.f32 	%p92, %f40, 0f7F800000;
	@%p92 bra 	$L__BB8_76;
	bra.uni 	$L__BB8_71;

$L__BB8_76:
	mov.f32 	%f220, 0f00000000;
	mul.rn.f32 	%f358, %f38, %f220;
	mov.u32 	%r538, 0;
	bra.uni 	$L__BB8_77;

$L__BB8_71:
	mov.b32 	%r63, %f38;
	bfe.u32 	%r308, %r63, 23, 8;
	add.s32 	%r64, %r308, -128;
	shl.b32 	%r309, %r63, 8;
	or.b32  	%r65, %r309, -2147483648;
	shr.u32 	%r66, %r64, 5;
	mov.u64 	%rd158, 0;
	mov.u32 	%r535, 0;
	mov.u64 	%rd84, __cudart_i2opi_f;
	mov.u64 	%rd159, %rd158;

$L__BB8_72:
	.pragma "nounroll";
	shl.b64 	%rd83, %rd158, 2;
	add.s64 	%rd85, %rd84, %rd83;
	ld.global.nc.u32 	%r310, [%rd85];
	mad.wide.u32 	%rd86, %r310, %r65, %rd159;
	shr.u64 	%rd159, %rd86, 32;
	add.s64 	%rd87, %rd1, %rd83;
	st.local.u32 	[%rd87], %rd86;
	add.s32 	%r535, %r535, 1;
	cvt.s64.s32 	%rd158, %r535;
	setp.ne.s32 	%p93, %r535, 6;
	@%p93 bra 	$L__BB8_72;

	st.local.u32 	[%rd1+24], %rd159;
	mov.u32 	%r311, 4;
	sub.s32 	%r69, %r311, %r66;
	mov.u32 	%r312, 6;
	sub.s32 	%r313, %r312, %r66;
	mul.wide.s32 	%rd88, %r313, 4;
	add.s64 	%rd89, %rd1, %rd88;
	ld.local.u32 	%r536, [%rd89];
	ld.local.u32 	%r537, [%rd89+-4];
	and.b32  	%r72, %r64, 31;
	setp.eq.s32 	%p94, %r72, 0;
	@%p94 bra 	$L__BB8_75;

	mov.u32 	%r314, 32;
	sub.s32 	%r315, %r314, %r72;
	shr.u32 	%r316, %r537, %r315;
	shl.b32 	%r317, %r536, %r72;
	add.s32 	%r536, %r316, %r317;
	mul.wide.s32 	%rd90, %r69, 4;
	add.s64 	%rd91, %rd1, %rd90;
	ld.local.u32 	%r318, [%rd91];
	shr.u32 	%r319, %r318, %r315;
	shl.b32 	%r320, %r537, %r72;
	add.s32 	%r537, %r319, %r320;

$L__BB8_75:
	and.b32  	%r321, %r63, -2147483648;
	shr.u32 	%r322, %r537, 30;
	shl.b32 	%r323, %r536, 2;
	or.b32  	%r324, %r322, %r323;
	shr.u32 	%r325, %r324, 31;
	shr.u32 	%r326, %r536, 30;
	add.s32 	%r327, %r325, %r326;
	neg.s32 	%r328, %r327;
	setp.eq.s32 	%p95, %r321, 0;
	selp.b32 	%r538, %r327, %r328, %p95;
	setp.ne.s32 	%p96, %r325, 0;
	xor.b32  	%r329, %r321, -2147483648;
	selp.b32 	%r330, %r329, %r321, %p96;
	selp.b32 	%r331, -1, 0, %p96;
	xor.b32  	%r332, %r324, %r331;
	shl.b32 	%r333, %r537, 2;
	xor.b32  	%r334, %r333, %r331;
	cvt.u64.u32 	%rd92, %r332;
	cvt.u64.u32 	%rd93, %r334;
	bfi.b64 	%rd94, %rd92, %rd93, 32, 32;
	cvt.rn.f64.s64 	%fd83, %rd94;
	mul.rn.f64 	%fd84, %fd83, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f218, %fd84;
	setp.eq.s32 	%p97, %r330, 0;
	neg.f32 	%f219, %f218;
	selp.f32 	%f358, %f218, %f219, %p97;

$L__BB8_77:
	and.b32  	%r79, %r538, 1;
	setp.eq.s32 	%p98, %r79, 0;
	selp.f32 	%f55, %f358, 0f3F800000, %p98;
	mul.rn.f32 	%f56, %f358, %f358;
	mov.f32 	%f359, 0fB94D4153;
	@%p98 bra 	$L__BB8_79;

	mov.f32 	%f222, 0fBAB607ED;
	mov.f32 	%f223, 0f37CBAC00;
	fma.rn.f32 	%f359, %f223, %f56, %f222;

$L__BB8_79:
	selp.f32 	%f224, 0f3C0885E4, 0f3D2AAABB, %p98;
	fma.rn.f32 	%f225, %f359, %f56, %f224;
	selp.f32 	%f226, 0fBE2AAAA8, 0fBEFFFFFF, %p98;
	fma.rn.f32 	%f227, %f225, %f56, %f226;
	mov.f32 	%f228, 0f00000000;
	fma.rn.f32 	%f229, %f56, %f55, %f228;
	fma.rn.f32 	%f360, %f227, %f229, %f55;
	and.b32  	%r336, %r538, 2;
	setp.eq.s32 	%p100, %r336, 0;
	@%p100 bra 	$L__BB8_81;

	mov.f32 	%f231, 0fBF800000;
	fma.rn.f32 	%f360, %f360, %f231, %f228;

$L__BB8_81:
	mul.rn.f32 	%f377, %f360, %f18;
	setp.lt.s32 	%p101, %r154, 1;
	@%p101 bra 	$L__BB8_174;

	and.b32  	%r80, %r2, 2147483647;
	setp.gt.s32 	%p102, %r2, -1;
	selp.b32 	%r81, 2146435072, 0, %p102;
	mov.u32 	%r539, 0;
	or.b32  	%r82, %r81, -2147483648;
	mov.u64 	%rd95, __cudart_i2opi_f;

$L__BB8_83:
	cvt.f64.f32 	%fd24, %f376;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r84}, %fd24;
	}
	abs.f64 	%fd25, %fd24;
	{ // callseq 98, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd25;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd144, [retval0+0];
	} // callseq 98
	setp.lt.s32 	%p103, %r84, 0;
	and.pred  	%p3, %p103, %p5;
	not.pred 	%p105, %p3;
	@%p105 bra 	$L__BB8_85;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r338}, %fd144;
	}
	xor.b32  	%r339, %r338, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r340, %temp}, %fd144;
	}
	mov.b64 	%fd144, {%r340, %r339};

$L__BB8_85:
	setp.eq.f32 	%p106, %f376, 0f00000000;
	@%p106 bra 	$L__BB8_89;
	bra.uni 	$L__BB8_86;

$L__BB8_89:
	setp.lt.s32 	%p109, %r2, 0;
	mov.u32 	%r341, 0;
	selp.b32 	%r342, %r84, 0, %p5;
	or.b32  	%r343, %r342, 2146435072;
	selp.b32 	%r344, %r343, %r342, %p109;
	mov.b64 	%fd144, {%r341, %r344};
	bra.uni 	$L__BB8_90;

$L__BB8_86:
	setp.gt.s32 	%p107, %r84, -1;
	@%p107 bra 	$L__BB8_90;

	mov.f64 	%fd85, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd86, %fd85;
	setp.eq.f64 	%p108, %fd86, 0d4000000000000000;
	@%p108 bra 	$L__BB8_90;

	mov.f64 	%fd144, 0dFFF8000000000000;

$L__BB8_90:
	add.rn.f64 	%fd88, %fd24, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r345}, %fd88;
	}
	and.b32  	%r346, %r345, 2146435072;
	setp.ne.s32 	%p111, %r346, 2146435072;
	@%p111 bra 	$L__BB8_97;

	setp.gtu.f64 	%p112, %fd25, 0d7FF0000000000000;
	@%p112 bra 	$L__BB8_96;
	bra.uni 	$L__BB8_92;

$L__BB8_96:
	mov.f64 	%fd90, 0d4000000000000000;
	add.rn.f64 	%fd144, %fd24, %fd90;
	bra.uni 	$L__BB8_97;

$L__BB8_92:
	setp.eq.s32 	%p113, %r80, 2146435072;
	mov.f64 	%fd89, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r347, %temp}, %fd89;
	}
	setp.eq.s32 	%p114, %r347, 0;
	and.pred  	%p115, %p113, %p114;
	@%p115 bra 	$L__BB8_95;
	bra.uni 	$L__BB8_93;

$L__BB8_95:
	setp.lt.s32 	%p121, %r2, 0;
	mov.u32 	%r352, 0;
	setp.gt.f64 	%p122, %fd25, 0d3FF0000000000000;
	selp.b32 	%r353, 2146435072, 0, %p122;
	xor.b32  	%r354, %r353, 2146435072;
	selp.b32 	%r355, %r354, %r353, %p121;
	setp.eq.f32 	%p123, %f376, 0fBF800000;
	selp.b32 	%r356, 1072693248, %r355, %p123;
	mov.b64 	%fd144, {%r352, %r356};
	bra.uni 	$L__BB8_97;

$L__BB8_93:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r348, %temp}, %fd24;
	}
	and.b32  	%r349, %r84, 2147483647;
	setp.ne.s32 	%p116, %r349, 2146435072;
	setp.ne.s32 	%p117, %r348, 0;
	or.pred  	%p118, %p116, %p117;
	@%p118 bra 	$L__BB8_97;

	setp.ne.s32 	%p119, %r80, 1071644672;
	and.pred  	%p120, %p119, %p3;
	selp.b32 	%r350, %r82, %r81, %p120;
	mov.u32 	%r351, 0;
	mov.b64 	%fd144, {%r351, %r350};

$L__BB8_97:
	cvt.f64.f32 	%fd35, %f377;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd35;
	}
	abs.f64 	%fd36, %fd35;
	{ // callseq 99, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd36;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd147, [retval0+0];
	} // callseq 99
	setp.lt.s32 	%p124, %r85, 0;
	and.pred  	%p4, %p124, %p5;
	not.pred 	%p126, %p4;
	@%p126 bra 	$L__BB8_99;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd147;
	}
	xor.b32  	%r358, %r357, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r359, %temp}, %fd147;
	}
	mov.b64 	%fd147, {%r359, %r358};

$L__BB8_99:
	setp.eq.f32 	%p127, %f377, 0f00000000;
	@%p127 bra 	$L__BB8_103;
	bra.uni 	$L__BB8_100;

$L__BB8_103:
	setp.lt.s32 	%p130, %r2, 0;
	mov.u32 	%r360, 0;
	selp.b32 	%r361, %r85, 0, %p5;
	or.b32  	%r362, %r361, 2146435072;
	selp.b32 	%r363, %r362, %r361, %p130;
	mov.b64 	%fd147, {%r360, %r363};
	bra.uni 	$L__BB8_104;

$L__BB8_100:
	setp.gt.s32 	%p128, %r85, -1;
	@%p128 bra 	$L__BB8_104;

	mov.f64 	%fd91, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd92, %fd91;
	setp.eq.f64 	%p129, %fd92, 0d4000000000000000;
	@%p129 bra 	$L__BB8_104;

	mov.f64 	%fd147, 0dFFF8000000000000;

$L__BB8_104:
	add.rn.f64 	%fd94, %fd35, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r364}, %fd94;
	}
	and.b32  	%r365, %r364, 2146435072;
	setp.ne.s32 	%p132, %r365, 2146435072;
	@%p132 bra 	$L__BB8_111;

	setp.gtu.f64 	%p133, %fd36, 0d7FF0000000000000;
	@%p133 bra 	$L__BB8_110;
	bra.uni 	$L__BB8_106;

$L__BB8_110:
	mov.f64 	%fd96, 0d4000000000000000;
	add.rn.f64 	%fd147, %fd35, %fd96;
	bra.uni 	$L__BB8_111;

$L__BB8_106:
	setp.eq.s32 	%p134, %r80, 2146435072;
	mov.f64 	%fd95, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r366, %temp}, %fd95;
	}
	setp.eq.s32 	%p135, %r366, 0;
	and.pred  	%p136, %p134, %p135;
	@%p136 bra 	$L__BB8_109;
	bra.uni 	$L__BB8_107;

$L__BB8_109:
	setp.lt.s32 	%p142, %r2, 0;
	mov.u32 	%r371, 0;
	setp.gt.f64 	%p143, %fd36, 0d3FF0000000000000;
	selp.b32 	%r372, 2146435072, 0, %p143;
	xor.b32  	%r373, %r372, 2146435072;
	selp.b32 	%r374, %r373, %r372, %p142;
	setp.eq.f32 	%p144, %f377, 0fBF800000;
	selp.b32 	%r375, 1072693248, %r374, %p144;
	mov.b64 	%fd147, {%r371, %r375};
	bra.uni 	$L__BB8_111;

$L__BB8_107:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd35;
	}
	and.b32  	%r368, %r85, 2147483647;
	setp.ne.s32 	%p137, %r368, 2146435072;
	setp.ne.s32 	%p138, %r367, 0;
	or.pred  	%p139, %p137, %p138;
	@%p139 bra 	$L__BB8_111;

	setp.ne.s32 	%p140, %r80, 1071644672;
	and.pred  	%p141, %p140, %p4;
	selp.b32 	%r369, %r82, %r81, %p141;
	mov.u32 	%r370, 0;
	mov.b64 	%fd147, {%r370, %r369};

$L__BB8_111:
	setp.eq.f32 	%p145, %f377, 0f3F800000;
	selp.f64 	%fd97, 0d3FF0000000000000, %fd147, %p145;
	setp.eq.f32 	%p146, %f376, 0f3F800000;
	selp.f64 	%fd98, 0d3FF0000000000000, %fd144, %p146;
	add.rn.f64 	%fd46, %fd98, %fd97;
	mul.rn.f32 	%f65, %f377, 0f42517084;
	mul.rn.f32 	%f232, %f65, 0f3F22F983;
	cvt.rni.s32.f32 	%r543, %f232;
	cvt.rn.f32.s32 	%f233, %r543;
	mov.f32 	%f234, 0fBFC90FDA;
	fma.rn.f32 	%f235, %f233, %f234, %f65;
	mov.f32 	%f236, 0fB3A22168;
	fma.rn.f32 	%f237, %f233, %f236, %f235;
	mov.f32 	%f238, 0fA7C234C5;
	fma.rn.f32 	%f363, %f233, %f238, %f237;
	abs.f32 	%f67, %f65;
	setp.ltu.f32 	%p147, %f67, 0f47CE4780;
	@%p147 bra 	$L__BB8_119;

	setp.eq.f32 	%p148, %f67, 0f7F800000;
	@%p148 bra 	$L__BB8_118;
	bra.uni 	$L__BB8_113;

$L__BB8_118:
	mov.f32 	%f241, 0f00000000;
	mul.rn.f32 	%f363, %f65, %f241;
	mov.u32 	%r543, 0;
	bra.uni 	$L__BB8_119;

$L__BB8_113:
	mov.b32 	%r87, %f65;
	bfe.u32 	%r377, %r87, 23, 8;
	add.s32 	%r88, %r377, -128;
	shl.b32 	%r378, %r87, 8;
	or.b32  	%r89, %r378, -2147483648;
	shr.u32 	%r90, %r88, 5;
	mov.u64 	%rd162, 0;
	mov.u32 	%r540, 0;
	mov.u64 	%rd160, %rd1;
	mov.u64 	%rd161, %rd95;

$L__BB8_114:
	.pragma "nounroll";
	ld.global.nc.u32 	%r379, [%rd161];
	mad.wide.u32 	%rd97, %r379, %r89, %rd162;
	shr.u64 	%rd162, %rd97, 32;
	st.local.u32 	[%rd160], %rd97;
	add.s64 	%rd161, %rd161, 4;
	add.s64 	%rd160, %rd160, 4;
	add.s32 	%r540, %r540, 1;
	setp.ne.s32 	%p149, %r540, 6;
	@%p149 bra 	$L__BB8_114;

	st.local.u32 	[%rd1+24], %rd162;
	mov.u32 	%r380, 4;
	sub.s32 	%r93, %r380, %r90;
	mov.u32 	%r381, 6;
	sub.s32 	%r382, %r381, %r90;
	mul.wide.s32 	%rd98, %r382, 4;
	add.s64 	%rd99, %rd1, %rd98;
	ld.local.u32 	%r541, [%rd99];
	ld.local.u32 	%r542, [%rd99+-4];
	and.b32  	%r96, %r88, 31;
	setp.eq.s32 	%p150, %r96, 0;
	@%p150 bra 	$L__BB8_117;

	mov.u32 	%r383, 32;
	sub.s32 	%r384, %r383, %r96;
	shr.u32 	%r385, %r542, %r384;
	shl.b32 	%r386, %r541, %r96;
	add.s32 	%r541, %r385, %r386;
	mul.wide.s32 	%rd100, %r93, 4;
	add.s64 	%rd101, %rd1, %rd100;
	ld.local.u32 	%r387, [%rd101];
	shr.u32 	%r388, %r387, %r384;
	shl.b32 	%r389, %r542, %r96;
	add.s32 	%r542, %r388, %r389;

$L__BB8_117:
	and.b32  	%r390, %r87, -2147483648;
	shr.u32 	%r391, %r542, 30;
	shl.b32 	%r392, %r541, 2;
	or.b32  	%r393, %r391, %r392;
	shr.u32 	%r394, %r393, 31;
	shr.u32 	%r395, %r541, 30;
	add.s32 	%r396, %r394, %r395;
	neg.s32 	%r397, %r396;
	setp.eq.s32 	%p151, %r390, 0;
	selp.b32 	%r543, %r396, %r397, %p151;
	setp.ne.s32 	%p152, %r394, 0;
	xor.b32  	%r398, %r390, -2147483648;
	selp.b32 	%r399, %r398, %r390, %p152;
	selp.b32 	%r400, -1, 0, %p152;
	xor.b32  	%r401, %r393, %r400;
	shl.b32 	%r402, %r542, 2;
	xor.b32  	%r403, %r402, %r400;
	cvt.u64.u32 	%rd102, %r401;
	cvt.u64.u32 	%rd103, %r403;
	bfi.b64 	%rd104, %rd102, %rd103, 32, 32;
	cvt.rn.f64.s64 	%fd99, %rd104;
	mul.rn.f64 	%fd100, %fd99, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f239, %fd100;
	setp.eq.s32 	%p153, %r399, 0;
	neg.f32 	%f240, %f239;
	selp.f32 	%f363, %f239, %f240, %p153;

$L__BB8_119:
	and.b32  	%r103, %r543, 1;
	setp.eq.s32 	%p154, %r103, 0;
	selp.f32 	%f71, %f363, 0f3F800000, %p154;
	mul.rn.f32 	%f72, %f363, %f363;
	mov.f32 	%f364, 0fB94D4153;
	@%p154 bra 	$L__BB8_121;

	mov.f32 	%f243, 0fBAB607ED;
	mov.f32 	%f244, 0f37CBAC00;
	fma.rn.f32 	%f364, %f244, %f72, %f243;

$L__BB8_121:
	selp.f32 	%f245, 0f3C0885E4, 0f3D2AAABB, %p154;
	fma.rn.f32 	%f246, %f364, %f72, %f245;
	selp.f32 	%f247, 0fBE2AAAA8, 0fBEFFFFFF, %p154;
	fma.rn.f32 	%f248, %f246, %f72, %f247;
	mov.f32 	%f249, 0f00000000;
	fma.rn.f32 	%f250, %f72, %f71, %f249;
	fma.rn.f32 	%f365, %f248, %f250, %f71;
	and.b32  	%r405, %r543, 2;
	setp.eq.s32 	%p156, %r405, 0;
	@%p156 bra 	$L__BB8_123;

	mov.f32 	%f252, 0fBF800000;
	fma.rn.f32 	%f365, %f365, %f252, %f249;

$L__BB8_123:
	cvt.f64.f32 	%fd101, %f365;
	mul.rn.f64 	%fd102, %fd101, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd103, %fd46;
	add.rn.f64 	%fd47, %fd103, %fd102;
	abs.f32 	%f78, %f376;
	setp.eq.f32 	%p157, %f78, 0f00000000;
	abs.f32 	%f79, %f377;
	setp.eq.f32 	%p158, %f79, 0f00000000;
	and.pred  	%p159, %p157, %p158;
	@%p159 bra 	$L__BB8_127;
	bra.uni 	$L__BB8_124;

$L__BB8_127:
	mov.b32 	%r416, %f376;
	shr.s32 	%r417, %r416, 31;
	and.b32  	%r418, %r417, 1078530011;
	mov.b32 	%r419, %f377;
	and.b32  	%r420, %r419, -2147483648;
	or.b32  	%r421, %r418, %r420;
	mov.b32 	%f366, %r421;
	bra.uni 	$L__BB8_128;

$L__BB8_124:
	setp.eq.f32 	%p160, %f78, 0f7F800000;
	setp.eq.f32 	%p161, %f79, 0f7F800000;
	and.pred  	%p162, %p160, %p161;
	@%p162 bra 	$L__BB8_126;
	bra.uni 	$L__BB8_125;

$L__BB8_126:
	mov.b32 	%r411, %f376;
	setp.lt.s32 	%p166, %r411, 0;
	selp.b32 	%r412, 1075235812, 1061752795, %p166;
	mov.b32 	%r413, %f377;
	and.b32  	%r414, %r413, -2147483648;
	or.b32  	%r415, %r412, %r414;
	mov.b32 	%f366, %r415;
	bra.uni 	$L__BB8_128;

$L__BB8_125:
	max.f32 	%f253, %f79, %f78;
	min.f32 	%f254, %f79, %f78;
	div.rn.f32 	%f255, %f254, %f253;
	mul.rn.f32 	%f256, %f255, %f255;
	mov.f32 	%f257, 0fC0B59883;
	mov.f32 	%f258, 0fBF52C7EA;
	fma.rn.f32 	%f259, %f256, %f258, %f257;
	mov.f32 	%f260, 0fC0D21907;
	fma.rn.f32 	%f261, %f259, %f256, %f260;
	mul.rn.f32 	%f262, %f256, %f261;
	mul.rn.f32 	%f263, %f255, %f262;
	add.rn.f32 	%f264, %f256, 0f41355DC0;
	mov.f32 	%f265, 0f41E6BD60;
	fma.rn.f32 	%f266, %f264, %f256, %f265;
	mov.f32 	%f267, 0f419D92C8;
	fma.rn.f32 	%f268, %f266, %f256, %f267;
	rcp.rn.f32 	%f269, %f268;
	fma.rn.f32 	%f270, %f263, %f269, %f255;
	mov.f32 	%f271, 0f3FC90FDB;
	sub.rn.f32 	%f272, %f271, %f270;
	setp.gt.f32 	%p163, %f79, %f78;
	selp.f32 	%f273, %f272, %f270, %p163;
	mov.b32 	%r406, %f376;
	setp.lt.s32 	%p164, %r406, 0;
	mov.f32 	%f274, 0f40490FDB;
	sub.rn.f32 	%f275, %f274, %f273;
	selp.f32 	%f276, %f275, %f273, %p164;
	mov.b32 	%r407, %f276;
	mov.b32 	%r408, %f377;
	and.b32  	%r409, %r408, -2147483648;
	or.b32  	%r410, %r409, %r407;
	mov.b32 	%f277, %r410;
	add.rn.f32 	%f278, %f78, %f79;
	setp.le.f32 	%p165, %f278, 0f7F800000;
	selp.f32 	%f366, %f277, %f278, %p165;

$L__BB8_128:
	mul.rn.f32 	%f84, %f376, 0f42517084;
	mul.rn.f32 	%f279, %f84, 0f3F22F983;
	cvt.rni.s32.f32 	%r546, %f279;
	cvt.rn.f32.s32 	%f280, %r546;
	mov.f32 	%f281, 0fBFC90FDA;
	fma.rn.f32 	%f282, %f280, %f281, %f84;
	mov.f32 	%f283, 0fB3A22168;
	fma.rn.f32 	%f284, %f280, %f283, %f282;
	mov.f32 	%f285, 0fA7C234C5;
	fma.rn.f32 	%f367, %f280, %f285, %f284;
	abs.f32 	%f86, %f84;
	setp.ltu.f32 	%p167, %f86, 0f47CE4780;
	@%p167 bra 	$L__BB8_136;

	setp.eq.f32 	%p168, %f86, 0f7F800000;
	@%p168 bra 	$L__BB8_135;
	bra.uni 	$L__BB8_130;

$L__BB8_135:
	mov.f32 	%f288, 0f00000000;
	mul.rn.f32 	%f367, %f84, %f288;
	mov.u32 	%r546, 0;
	bra.uni 	$L__BB8_136;

$L__BB8_130:
	mov.b32 	%r105, %f84;
	bfe.u32 	%r422, %r105, 23, 8;
	add.s32 	%r106, %r422, -128;
	shl.b32 	%r423, %r105, 8;
	or.b32  	%r107, %r423, -2147483648;
	shr.u32 	%r108, %r106, 5;
	mov.u64 	%rd163, 0;
	mov.u64 	%rd164, %rd163;

$L__BB8_131:
	.pragma "nounroll";
	shl.b64 	%rd107, %rd163, 2;
	mov.u64 	%rd108, __cudart_i2opi_f;
	add.s64 	%rd109, %rd108, %rd107;
	ld.global.nc.u32 	%r424, [%rd109];
	mad.wide.u32 	%rd110, %r424, %r107, %rd164;
	shr.u64 	%rd164, %rd110, 32;
	add.s64 	%rd111, %rd1, %rd107;
	st.local.u32 	[%rd111], %rd110;
	cvt.u32.u64 	%r425, %rd163;
	add.s32 	%r426, %r425, 1;
	cvt.s64.s32 	%rd163, %r426;
	setp.ne.s32 	%p169, %r426, 6;
	@%p169 bra 	$L__BB8_131;

	st.local.u32 	[%rd1+24], %rd164;
	mov.u32 	%r427, 4;
	sub.s32 	%r109, %r427, %r108;
	mov.u32 	%r428, 6;
	sub.s32 	%r429, %r428, %r108;
	mul.wide.s32 	%rd112, %r429, 4;
	add.s64 	%rd113, %rd1, %rd112;
	ld.local.u32 	%r544, [%rd113];
	ld.local.u32 	%r545, [%rd113+-4];
	and.b32  	%r112, %r106, 31;
	setp.eq.s32 	%p170, %r112, 0;
	@%p170 bra 	$L__BB8_134;

	mov.u32 	%r430, 32;
	sub.s32 	%r431, %r430, %r112;
	shr.u32 	%r432, %r545, %r431;
	shl.b32 	%r433, %r544, %r112;
	add.s32 	%r544, %r432, %r433;
	mul.wide.s32 	%rd114, %r109, 4;
	add.s64 	%rd115, %rd1, %rd114;
	ld.local.u32 	%r434, [%rd115];
	shr.u32 	%r435, %r434, %r431;
	shl.b32 	%r436, %r545, %r112;
	add.s32 	%r545, %r435, %r436;

$L__BB8_134:
	and.b32  	%r437, %r105, -2147483648;
	shr.u32 	%r438, %r545, 30;
	shl.b32 	%r439, %r544, 2;
	or.b32  	%r440, %r438, %r439;
	shr.u32 	%r441, %r440, 31;
	shr.u32 	%r442, %r544, 30;
	add.s32 	%r443, %r441, %r442;
	neg.s32 	%r444, %r443;
	setp.eq.s32 	%p171, %r437, 0;
	selp.b32 	%r546, %r443, %r444, %p171;
	setp.ne.s32 	%p172, %r441, 0;
	xor.b32  	%r445, %r437, -2147483648;
	selp.b32 	%r446, %r445, %r437, %p172;
	selp.b32 	%r447, -1, 0, %p172;
	xor.b32  	%r448, %r440, %r447;
	shl.b32 	%r449, %r545, 2;
	xor.b32  	%r450, %r449, %r447;
	cvt.u64.u32 	%rd116, %r448;
	cvt.u64.u32 	%rd117, %r450;
	bfi.b64 	%rd118, %rd116, %rd117, 32, 32;
	cvt.rn.f64.s64 	%fd104, %rd118;
	mul.rn.f64 	%fd105, %fd104, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f286, %fd105;
	setp.eq.s32 	%p173, %r446, 0;
	neg.f32 	%f287, %f286;
	selp.f32 	%f367, %f286, %f287, %p173;

$L__BB8_136:
	cvt.rn.f32.f64 	%f90, %fd47;
	add.s32 	%r119, %r546, 1;
	and.b32  	%r120, %r119, 1;
	setp.eq.s32 	%p174, %r120, 0;
	selp.f32 	%f91, %f367, 0f3F800000, %p174;
	mul.rn.f32 	%f92, %f367, %f367;
	mov.f32 	%f368, 0fB94D4153;
	@%p174 bra 	$L__BB8_138;

	mov.f32 	%f290, 0fBAB607ED;
	mov.f32 	%f291, 0f37CBAC00;
	fma.rn.f32 	%f368, %f291, %f92, %f290;

$L__BB8_138:
	selp.f32 	%f292, 0f3C0885E4, 0f3D2AAABB, %p174;
	fma.rn.f32 	%f293, %f368, %f92, %f292;
	selp.f32 	%f294, 0fBE2AAAA8, 0fBEFFFFFF, %p174;
	fma.rn.f32 	%f295, %f293, %f92, %f294;
	mov.f32 	%f296, 0f00000000;
	fma.rn.f32 	%f297, %f92, %f91, %f296;
	fma.rn.f32 	%f369, %f295, %f297, %f91;
	and.b32  	%r452, %r119, 2;
	setp.eq.s32 	%p176, %r452, 0;
	@%p176 bra 	$L__BB8_140;

	mov.f32 	%f299, 0fBF800000;
	fma.rn.f32 	%f369, %f369, %f299, %f296;

$L__BB8_140:
	cvt.f64.f32 	%fd106, %f369;
	mul.rn.f64 	%fd107, %fd106, 0d3EC92A737110E454;
	cvt.f64.f32 	%fd108, %f366;
	add.rn.f64 	%fd109, %fd107, %fd108;
	cvt.rn.f32.f64 	%f98, %fd109;
	mul.rn.f32 	%f300, %f98, 0f3F22F983;
	cvt.rni.s32.f32 	%r552, %f300;
	cvt.rn.f32.s32 	%f301, %r552;
	mov.f32 	%f302, 0fBFC90FDA;
	fma.rn.f32 	%f303, %f301, %f302, %f98;
	mov.f32 	%f304, 0fB3A22168;
	fma.rn.f32 	%f305, %f301, %f304, %f303;
	mov.f32 	%f306, 0fA7C234C5;
	fma.rn.f32 	%f373, %f301, %f306, %f305;
	abs.f32 	%f100, %f98;
	setp.ltu.f32 	%p177, %f100, 0f47CE4780;
	mov.u32 	%r549, %r552;
	mov.f32 	%f370, %f373;
	@%p177 bra 	$L__BB8_148;

	setp.eq.f32 	%p178, %f100, 0f7F800000;
	@%p178 bra 	$L__BB8_147;
	bra.uni 	$L__BB8_142;

$L__BB8_147:
	mov.f32 	%f309, 0f00000000;
	mul.rn.f32 	%f370, %f98, %f309;
	mov.u32 	%r549, 0;
	bra.uni 	$L__BB8_148;

$L__BB8_142:
	mov.b32 	%r122, %f98;
	bfe.u32 	%r453, %r122, 23, 8;
	add.s32 	%r123, %r453, -128;
	shl.b32 	%r454, %r122, 8;
	or.b32  	%r124, %r454, -2147483648;
	shr.u32 	%r125, %r123, 5;
	mov.u64 	%rd165, 0;
	mov.u64 	%rd166, %rd165;

$L__BB8_143:
	.pragma "nounroll";
	shl.b64 	%rd121, %rd165, 2;
	mov.u64 	%rd122, __cudart_i2opi_f;
	add.s64 	%rd123, %rd122, %rd121;
	ld.global.nc.u32 	%r455, [%rd123];
	mad.wide.u32 	%rd124, %r455, %r124, %rd166;
	shr.u64 	%rd166, %rd124, 32;
	add.s64 	%rd125, %rd1, %rd121;
	st.local.u32 	[%rd125], %rd124;
	cvt.u32.u64 	%r456, %rd165;
	add.s32 	%r457, %r456, 1;
	cvt.s64.s32 	%rd165, %r457;
	setp.ne.s32 	%p179, %r457, 6;
	@%p179 bra 	$L__BB8_143;

	st.local.u32 	[%rd1+24], %rd166;
	mov.u32 	%r458, 4;
	sub.s32 	%r126, %r458, %r125;
	mov.u32 	%r459, 6;
	sub.s32 	%r460, %r459, %r125;
	mul.wide.s32 	%rd126, %r460, 4;
	add.s64 	%rd127, %rd1, %rd126;
	ld.local.u32 	%r547, [%rd127];
	ld.local.u32 	%r548, [%rd127+-4];
	and.b32  	%r129, %r123, 31;
	setp.eq.s32 	%p180, %r129, 0;
	@%p180 bra 	$L__BB8_146;

	mov.u32 	%r461, 32;
	sub.s32 	%r462, %r461, %r129;
	shr.u32 	%r463, %r548, %r462;
	shl.b32 	%r464, %r547, %r129;
	add.s32 	%r547, %r463, %r464;
	mul.wide.s32 	%rd128, %r126, 4;
	add.s64 	%rd129, %rd1, %rd128;
	ld.local.u32 	%r465, [%rd129];
	shr.u32 	%r466, %r465, %r462;
	shl.b32 	%r467, %r548, %r129;
	add.s32 	%r548, %r466, %r467;

$L__BB8_146:
	and.b32  	%r468, %r122, -2147483648;
	shr.u32 	%r469, %r548, 30;
	shl.b32 	%r470, %r547, 2;
	or.b32  	%r471, %r469, %r470;
	shr.u32 	%r472, %r471, 31;
	shr.u32 	%r473, %r547, 30;
	add.s32 	%r474, %r472, %r473;
	neg.s32 	%r475, %r474;
	setp.eq.s32 	%p181, %r468, 0;
	selp.b32 	%r549, %r474, %r475, %p181;
	setp.ne.s32 	%p182, %r472, 0;
	xor.b32  	%r476, %r468, -2147483648;
	selp.b32 	%r477, %r476, %r468, %p182;
	selp.b32 	%r478, -1, 0, %p182;
	xor.b32  	%r479, %r471, %r478;
	shl.b32 	%r480, %r548, 2;
	xor.b32  	%r481, %r480, %r478;
	cvt.u64.u32 	%rd130, %r479;
	cvt.u64.u32 	%rd131, %r481;
	bfi.b64 	%rd132, %rd130, %rd131, 32, 32;
	cvt.rn.f64.s64 	%fd110, %rd132;
	mul.rn.f64 	%fd111, %fd110, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f307, %fd111;
	setp.eq.s32 	%p183, %r477, 0;
	neg.f32 	%f308, %f307;
	selp.f32 	%f370, %f307, %f308, %p183;

$L__BB8_148:
	add.s32 	%r136, %r549, 1;
	and.b32  	%r137, %r136, 1;
	setp.eq.s32 	%p184, %r137, 0;
	selp.f32 	%f104, %f370, 0f3F800000, %p184;
	mul.rn.f32 	%f105, %f370, %f370;
	mov.f32 	%f371, 0fB94D4153;
	@%p184 bra 	$L__BB8_150;

	mov.f32 	%f311, 0fBAB607ED;
	mov.f32 	%f312, 0f37CBAC00;
	fma.rn.f32 	%f371, %f312, %f105, %f311;

$L__BB8_150:
	selp.f32 	%f313, 0f3C0885E4, 0f3D2AAABB, %p184;
	fma.rn.f32 	%f314, %f371, %f105, %f313;
	selp.f32 	%f315, 0fBE2AAAA8, 0fBEFFFFFF, %p184;
	fma.rn.f32 	%f316, %f314, %f105, %f315;
	mov.f32 	%f317, 0f00000000;
	fma.rn.f32 	%f318, %f105, %f104, %f317;
	fma.rn.f32 	%f372, %f316, %f318, %f104;
	and.b32  	%r483, %r136, 2;
	setp.eq.s32 	%p186, %r483, 0;
	@%p186 bra 	$L__BB8_152;

	mov.f32 	%f320, 0fBF800000;
	fma.rn.f32 	%f372, %f372, %f320, %f317;

$L__BB8_152:
	@%p177 bra 	$L__BB8_160;

	setp.eq.f32 	%p188, %f100, 0f7F800000;
	@%p188 bra 	$L__BB8_159;
	bra.uni 	$L__BB8_154;

$L__BB8_159:
	mov.f32 	%f323, 0f00000000;
	mul.rn.f32 	%f373, %f98, %f323;
	mov.u32 	%r552, 0;
	bra.uni 	$L__BB8_160;

$L__BB8_154:
	mov.b32 	%r138, %f98;
	bfe.u32 	%r484, %r138, 23, 8;
	add.s32 	%r139, %r484, -128;
	shl.b32 	%r485, %r138, 8;
	or.b32  	%r140, %r485, -2147483648;
	shr.u32 	%r141, %r139, 5;
	mov.u64 	%rd167, 0;
	mov.u64 	%rd168, %rd167;

$L__BB8_155:
	.pragma "nounroll";
	shl.b64 	%rd135, %rd167, 2;
	mov.u64 	%rd136, __cudart_i2opi_f;
	add.s64 	%rd137, %rd136, %rd135;
	ld.global.nc.u32 	%r486, [%rd137];
	mad.wide.u32 	%rd138, %r486, %r140, %rd168;
	shr.u64 	%rd168, %rd138, 32;
	add.s64 	%rd139, %rd1, %rd135;
	st.local.u32 	[%rd139], %rd138;
	cvt.u32.u64 	%r487, %rd167;
	add.s32 	%r488, %r487, 1;
	cvt.s64.s32 	%rd167, %r488;
	setp.ne.s32 	%p189, %r488, 6;
	@%p189 bra 	$L__BB8_155;

	st.local.u32 	[%rd1+24], %rd168;
	mov.u32 	%r489, 4;
	sub.s32 	%r142, %r489, %r141;
	mov.u32 	%r490, 6;
	sub.s32 	%r491, %r490, %r141;
	mul.wide.s32 	%rd140, %r491, 4;
	add.s64 	%rd141, %rd1, %rd140;
	ld.local.u32 	%r550, [%rd141];
	ld.local.u32 	%r551, [%rd141+-4];
	and.b32  	%r145, %r139, 31;
	setp.eq.s32 	%p190, %r145, 0;
	@%p190 bra 	$L__BB8_158;

	mov.u32 	%r492, 32;
	sub.s32 	%r493, %r492, %r145;
	shr.u32 	%r494, %r551, %r493;
	shl.b32 	%r495, %r550, %r145;
	add.s32 	%r550, %r494, %r495;
	mul.wide.s32 	%rd142, %r142, 4;
	add.s64 	%rd143, %rd1, %rd142;
	ld.local.u32 	%r496, [%rd143];
	shr.u32 	%r497, %r496, %r493;
	shl.b32 	%r498, %r551, %r145;
	add.s32 	%r551, %r497, %r498;

$L__BB8_158:
	and.b32  	%r499, %r138, -2147483648;
	shr.u32 	%r500, %r551, 30;
	shl.b32 	%r501, %r550, 2;
	or.b32  	%r502, %r500, %r501;
	shr.u32 	%r503, %r502, 31;
	shr.u32 	%r504, %r550, 30;
	add.s32 	%r505, %r503, %r504;
	neg.s32 	%r506, %r505;
	setp.eq.s32 	%p191, %r499, 0;
	selp.b32 	%r552, %r505, %r506, %p191;
	setp.ne.s32 	%p192, %r503, 0;
	xor.b32  	%r507, %r499, -2147483648;
	selp.b32 	%r508, %r507, %r499, %p192;
	selp.b32 	%r509, -1, 0, %p192;
	xor.b32  	%r510, %r502, %r509;
	shl.b32 	%r511, %r551, 2;
	xor.b32  	%r512, %r511, %r509;
	cvt.u64.u32 	%rd144, %r510;
	cvt.u64.u32 	%rd145, %r512;
	bfi.b64 	%rd146, %rd144, %rd145, 32, 32;
	cvt.rn.f64.s64 	%fd112, %rd146;
	mul.rn.f64 	%fd113, %fd112, 0d3BF921FB54442D19;
	cvt.rn.f32.f64 	%f321, %fd113;
	setp.eq.s32 	%p193, %r508, 0;
	neg.f32 	%f322, %f321;
	selp.f32 	%f373, %f321, %f322, %p193;

$L__BB8_160:
	and.b32  	%r152, %r552, 1;
	setp.eq.s32 	%p194, %r152, 0;
	selp.f32 	%f114, %f373, 0f3F800000, %p194;
	mul.rn.f32 	%f115, %f373, %f373;
	mov.f32 	%f374, 0fB94D4153;
	@%p194 bra 	$L__BB8_162;

	mov.f32 	%f325, 0fBAB607ED;
	mov.f32 	%f326, 0f37CBAC00;
	fma.rn.f32 	%f374, %f326, %f115, %f325;

$L__BB8_162:
	selp.f32 	%f327, 0f3C0885E4, 0f3D2AAABB, %p194;
	fma.rn.f32 	%f328, %f374, %f115, %f327;
	selp.f32 	%f329, 0fBE2AAAA8, 0fBEFFFFFF, %p194;
	fma.rn.f32 	%f330, %f328, %f115, %f329;
	mov.f32 	%f331, 0f00000000;
	fma.rn.f32 	%f332, %f115, %f114, %f331;
	fma.rn.f32 	%f375, %f330, %f332, %f114;
	and.b32  	%r514, %r552, 2;
	setp.eq.s32 	%p196, %r514, 0;
	@%p196 bra 	$L__BB8_164;

	mov.f32 	%f334, 0fBF800000;
	fma.rn.f32 	%f375, %f375, %f334, %f331;

$L__BB8_164:
	mul.rn.f32 	%f335, %f375, %f90;
	cvt.f64.f32 	%fd114, %f335;
	add.rn.f64 	%fd115, %fd114, 0d3F789374BC6A7EFA;
	cvt.rn.f32.f64 	%f336, %fd115;
	sub.rn.f32 	%f121, %f3, %f336;
	mul.rn.f32 	%f337, %f372, %f90;
	cvt.f64.f32 	%fd116, %f337;
	add.rn.f64 	%fd117, %fd116, 0d3F7A9FBE76C8B439;
	cvt.rn.f32.f64 	%f338, %fd117;
	sub.rn.f32 	%f122, %f1, %f338;
	add.rn.f32 	%f123, %f376, %f122;
	add.rn.f32 	%f124, %f377, %f121;
	setp.eq.s16 	%p197, %rs1, 0;
	@%p197 bra 	$L__BB8_172;
	bra.uni 	$L__BB8_165;

$L__BB8_172:
	abs.f32 	%f344, %f122;
	abs.f32 	%f345, %f121;
	mul.rn.f32 	%f346, %f345, %f128;
	setp.lt.f32 	%p206, %f344, %f346;
	selp.f32 	%f347, 0f3F800000, 0f00000000, %p206;
	setp.lt.f32 	%p207, %f347, %f128;
	add.s32 	%r539, %r539, 1;
	@%p207 bra 	$L__BB8_174;

	setp.lt.s32 	%p208, %r539, %r154;
	mov.f32 	%f377, %f124;
	mov.f32 	%f376, %f123;
	@%p208 bra 	$L__BB8_83;

$L__BB8_174:
	st.global.f32 	[%rd2], %f376;
	st.global.f32 	[%rd3], %f377;
	ret;

$L__BB8_165:
	mul.rn.f64 	%fd118, %fd35, 0d400921FB54442D18;
	div.rn.f64 	%fd119, %fd118, 0d4066800000000000;
	cvt.rn.f32.f64 	%f339, %fd119;
	mul.rn.f64 	%fd120, %fd24, 0d400921FB54442D18;
	div.rn.f64 	%fd121, %fd120, 0d4066800000000000;
	cvt.rn.f32.f64 	%f340, %fd121;
	cvt.f64.f32 	%fd122, %f124;
	mul.rn.f64 	%fd123, %fd122, 0d400921FB54442D18;
	div.rn.f64 	%fd124, %fd123, 0d4066800000000000;
	cvt.rn.f32.f64 	%f341, %fd124;
	cvt.f64.f32 	%fd125, %f123;
	mul.rn.f64 	%fd126, %fd125, 0d400921FB54442D18;
	div.rn.f64 	%fd127, %fd126, 0d4066800000000000;
	cvt.rn.f32.f64 	%f342, %fd127;
	sub.rn.f32 	%f343, %f341, %f339;
	sub.rn.f32 	%f125, %f342, %f340;
	cvt.f64.f32 	%fd128, %f343;
	mul.rn.f64 	%fd48, %fd128, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r515, %temp}, %fd48;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r516}, %fd48;
	}
	and.b32  	%r517, %r516, 2147483647;
	setp.eq.s32 	%p198, %r517, 2146435072;
	setp.eq.s32 	%p199, %r515, 0;
	and.pred  	%p200, %p199, %p198;
	@%p200 bra 	$L__BB8_168;

	mul.rn.f64 	%fd129, %fd48, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r518, %fd129;
	st.local.u32 	[%rd1], %r518;
	abs.f64 	%fd130, %fd48;
	setp.ltu.f64 	%p201, %fd130, 0d41E0000000000000;
	@%p201 bra 	$L__BB8_168;

	{ // callseq 100, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd48;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd47;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd131, [retval0+0];
	} // callseq 100

$L__BB8_168:
	cvt.f64.f32 	%fd132, %f125;
	mul.rn.f64 	%fd49, %fd132, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r519, %temp}, %fd49;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r520}, %fd49;
	}
	and.b32  	%r521, %r520, 2147483647;
	setp.eq.s32 	%p202, %r521, 2146435072;
	setp.eq.s32 	%p203, %r519, 0;
	and.pred  	%p204, %p203, %p202;
	@%p204 bra 	$L__BB8_171;

	mul.rn.f64 	%fd133, %fd49, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r522, %fd133;
	st.local.u32 	[%rd1], %r522;
	abs.f64 	%fd134, %fd49;
	setp.ltu.f64 	%p205, %fd134, 0d41E0000000000000;
	@%p205 bra 	$L__BB8_171;

	{ // callseq 101, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd49;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd47;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd135, [retval0+0];
	} // callseq 101

$L__BB8_171:

}
	// .globl	bd09_to_gcj02_cuda_double
.visible .entry bd09_to_gcj02_cuda_double(
	.param .u64 bd09_to_gcj02_cuda_double_param_0,
	.param .u64 bd09_to_gcj02_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot9[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<81>;
	.reg .b32 	%r<124>;
	.reg .f64 	%fd<275>;
	.reg .b64 	%rd<46>;


	mov.u64 	%SPL, __local_depot9;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [bd09_to_gcj02_cuda_double_param_0];
	ld.param.u64 	%rd8, [bd09_to_gcj02_cuda_double_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r26, %r24, %r23, %r25;
	cvta.to.global.u64 	%rd14, %rd7;
	mul.wide.s32 	%rd15, %r26, 8;
	add.s64 	%rd5, %rd14, %rd15;
	add.s64 	%rd6, %rd9, %rd15;
	ld.global.f64 	%fd78, [%rd5];
	add.rn.f64 	%fd1, %fd78, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd79, [%rd6];
	add.rn.f64 	%fd2, %fd79, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd80;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p4, %r3, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 102, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd256, [retval0+0];
	} // callseq 102
	setp.lt.s32 	%p5, %r1, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB9_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd256;
	}
	xor.b32  	%r28, %r27, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd256;
	}
	mov.b64 	%fd256, {%r29, %r28};

$L__BB9_2:
	setp.eq.f64 	%p7, %fd1, 0d0000000000000000;
	@%p7 bra 	$L__BB9_6;
	bra.uni 	$L__BB9_3;

$L__BB9_6:
	selp.b32 	%r30, %r1, 0, %p4;
	mov.u32 	%r31, 0;
	or.b32  	%r32, %r30, 2146435072;
	setp.lt.s32 	%p11, %r2, 0;
	selp.b32 	%r33, %r32, %r30, %p11;
	mov.b64 	%fd256, {%r31, %r33};
	bra.uni 	$L__BB9_7;

$L__BB9_3:
	setp.gt.s32 	%p8, %r1, -1;
	@%p8 bra 	$L__BB9_7;

	mov.f64 	%fd81, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd82, %fd81;
	setp.eq.f64 	%p9, %fd82, 0d4000000000000000;
	@%p9 bra 	$L__BB9_7;

	mov.f64 	%fd256, 0dFFF8000000000000;

$L__BB9_7:
	add.rn.f64 	%fd84, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd84;
	}
	and.b32  	%r35, %r34, 2146435072;
	setp.ne.s32 	%p12, %r35, 2146435072;
	@%p12 bra 	$L__BB9_14;

	setp.gtu.f64 	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	$L__BB9_13;
	bra.uni 	$L__BB9_9;

$L__BB9_13:
	mov.f64 	%fd86, 0d4000000000000000;
	add.rn.f64 	%fd256, %fd1, %fd86;
	bra.uni 	$L__BB9_14;

$L__BB9_9:
	mov.f64 	%fd85, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd85;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p14, %r4, 2146435072;
	setp.eq.s32 	%p15, %r36, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB9_12;
	bra.uni 	$L__BB9_10;

$L__BB9_12:
	setp.gt.f64 	%p23, %fd3, 0d3FF0000000000000;
	selp.b32 	%r43, 2146435072, 0, %p23;
	mov.u32 	%r44, 0;
	xor.b32  	%r45, %r43, 2146435072;
	setp.lt.s32 	%p24, %r2, 0;
	selp.b32 	%r46, %r45, %r43, %p24;
	setp.eq.f64 	%p25, %fd1, 0dBFF0000000000000;
	selp.b32 	%r47, 1072693248, %r46, %p25;
	mov.b64 	%fd256, {%r44, %r47};
	bra.uni 	$L__BB9_14;

$L__BB9_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd1;
	}
	and.b32  	%r38, %r1, 2147483647;
	setp.ne.s32 	%p17, %r38, 2146435072;
	setp.ne.s32 	%p18, %r37, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB9_14;

	setp.gt.s32 	%p20, %r2, -1;
	selp.b32 	%r39, 2146435072, 0, %p20;
	mov.u32 	%r40, 0;
	setp.ne.s32 	%p21, %r4, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r41, %r39, -2147483648;
	selp.b32 	%r42, %r41, %r39, %p22;
	mov.b64 	%fd256, {%r40, %r42};

$L__BB9_14:
	abs.f64 	%fd13, %fd2;
	{ // callseq 103, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 103
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd2;
	}
	setp.lt.s32 	%p26, %r5, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB9_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd259;
	}
	xor.b32  	%r49, %r48, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd259;
	}
	mov.b64 	%fd259, {%r50, %r49};

$L__BB9_16:
	setp.eq.f64 	%p29, %fd2, 0d0000000000000000;
	@%p29 bra 	$L__BB9_20;
	bra.uni 	$L__BB9_17;

$L__BB9_20:
	selp.b32 	%r51, %r5, 0, %p4;
	mov.u32 	%r52, 0;
	or.b32  	%r53, %r51, 2146435072;
	setp.lt.s32 	%p33, %r2, 0;
	selp.b32 	%r54, %r53, %r51, %p33;
	mov.b64 	%fd259, {%r52, %r54};
	bra.uni 	$L__BB9_21;

$L__BB9_17:
	setp.gt.s32 	%p30, %r5, -1;
	@%p30 bra 	$L__BB9_21;

	mov.f64 	%fd87, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd88, %fd87;
	setp.eq.f64 	%p31, %fd88, 0d4000000000000000;
	@%p31 bra 	$L__BB9_21;

	mov.f64 	%fd259, 0dFFF8000000000000;

$L__BB9_21:
	add.rn.f64 	%fd90, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd90;
	}
	and.b32  	%r56, %r55, 2146435072;
	setp.ne.s32 	%p34, %r56, 2146435072;
	@%p34 bra 	$L__BB9_28;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB9_27;
	bra.uni 	$L__BB9_23;

$L__BB9_27:
	mov.f64 	%fd92, 0d4000000000000000;
	add.rn.f64 	%fd259, %fd2, %fd92;
	bra.uni 	$L__BB9_28;

$L__BB9_23:
	mov.f64 	%fd91, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd91;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p36, %r6, 2146435072;
	setp.eq.s32 	%p37, %r57, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB9_26;
	bra.uni 	$L__BB9_24;

$L__BB9_26:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r64, 2146435072, 0, %p45;
	mov.u32 	%r65, 0;
	xor.b32  	%r66, %r64, 2146435072;
	setp.lt.s32 	%p46, %r2, 0;
	selp.b32 	%r67, %r66, %r64, %p46;
	setp.eq.f64 	%p47, %fd2, 0dBFF0000000000000;
	selp.b32 	%r68, 1072693248, %r67, %p47;
	mov.b64 	%fd259, {%r65, %r68};
	bra.uni 	$L__BB9_28;

$L__BB9_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd2;
	}
	and.b32  	%r59, %r5, 2147483647;
	setp.ne.s32 	%p39, %r59, 2146435072;
	setp.ne.s32 	%p40, %r58, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB9_28;

	setp.gt.s32 	%p42, %r2, -1;
	selp.b32 	%r60, 2146435072, 0, %p42;
	mov.u32 	%r61, 0;
	setp.ne.s32 	%p43, %r6, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r62, %r60, -2147483648;
	selp.b32 	%r63, %r62, %r60, %p44;
	mov.b64 	%fd259, {%r61, %r63};

$L__BB9_28:
	setp.eq.f64 	%p48, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd93, 0d3FF0000000000000, %fd259, %p48;
	setp.eq.f64 	%p49, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd94, 0d3FF0000000000000, %fd256, %p49;
	add.rn.f64 	%fd23, %fd94, %fd93;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd24;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p50, %r71, 2146435072;
	setp.eq.s32 	%p51, %r69, 0;
	and.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB9_31;
	bra.uni 	$L__BB9_29;

$L__BB9_31:
	mov.f64 	%fd104, 0d0000000000000000;
	mul.rn.f64 	%fd260, %fd24, %fd104;
	mov.u32 	%r118, 0;
	bra.uni 	$L__BB9_32;

$L__BB9_29:
	mul.rn.f64 	%fd95, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd95;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd96, %r118;
	neg.f64 	%fd97, %fd96;
	mov.f64 	%fd98, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd99, %fd97, %fd98, %fd24;
	mov.f64 	%fd100, 0d3C91A62633145C00;
	fma.rn.f64 	%fd101, %fd97, %fd100, %fd99;
	mov.f64 	%fd102, 0d397B839A252049C0;
	fma.rn.f64 	%fd260, %fd97, %fd102, %fd101;
	abs.f64 	%fd103, %fd24;
	setp.ltu.f64 	%p53, %fd103, 0d41E0000000000000;
	@%p53 bra 	$L__BB9_32;

	{ // callseq 104, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd260, [retval0+0];
	} // callseq 104
	ld.local.u32 	%r118, [%rd1];

$L__BB9_32:
	and.b32  	%r73, %r118, 1;
	shl.b32 	%r74, %r118, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p54, %r73, 0;
	selp.f64 	%fd105, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	mul.wide.s32 	%rd17, %r75, 8;
	mov.u64 	%rd18, __cudart_sin_cos_coeffs;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.nc.f64 	%fd106, [%rd19+8];
	mul.rn.f64 	%fd29, %fd260, %fd260;
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd19+16];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd19+24];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd19+32];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd19+40];
	fma.rn.f64 	%fd115, %fd113, %fd29, %fd114;
	ld.global.nc.f64 	%fd116, [%rd19+48];
	fma.rn.f64 	%fd30, %fd115, %fd29, %fd116;
	fma.rn.f64 	%fd262, %fd30, %fd260, %fd260;
	@%p54 bra 	$L__BB9_34;

	mov.f64 	%fd117, 0d3FF0000000000000;
	fma.rn.f64 	%fd262, %fd30, %fd29, %fd117;

$L__BB9_34:
	and.b32  	%r76, %r118, 2;
	setp.eq.s32 	%p55, %r76, 0;
	@%p55 bra 	$L__BB9_36;

	mov.f64 	%fd118, 0d0000000000000000;
	mov.f64 	%fd119, 0dBFF0000000000000;
	fma.rn.f64 	%fd262, %fd262, %fd119, %fd118;

$L__BB9_36:
	mul.rn.f64 	%fd120, %fd262, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd121, %fd23;
	add.rn.f64 	%fd36, %fd121, %fd120;
	setp.eq.f64 	%p56, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p57, %fd3, 0d0000000000000000;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB9_40;
	bra.uni 	$L__BB9_37;

$L__BB9_40:
	selp.f64 	%fd174, 0d400921FB54442D18, 0d0000000000000000, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd174;
	}
	and.b32  	%r87, %r5, -2147483648;
	or.b32  	%r88, %r86, %r87;
	mov.b64 	%fd263, {%r85, %r88};
	bra.uni 	$L__BB9_41;

$L__BB9_37:
	setp.eq.f64 	%p59, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p60, %fd13, 0d7FF0000000000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB9_39;
	bra.uni 	$L__BB9_38;

$L__BB9_39:
	selp.f64 	%fd173, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd173;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd173;
	}
	and.b32  	%r83, %r5, -2147483648;
	or.b32  	%r84, %r82, %r83;
	mov.b64 	%fd263, {%r81, %r84};
	bra.uni 	$L__BB9_41;

$L__BB9_38:
	min.f64 	%fd122, %fd13, %fd3;
	max.f64 	%fd123, %fd13, %fd3;
	div.rn.f64 	%fd124, %fd122, %fd123;
	mul.rn.f64 	%fd125, %fd124, %fd124;
	mov.f64 	%fd126, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd127, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd128, %fd127, %fd125, %fd126;
	mov.f64 	%fd129, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd130, %fd128, %fd125, %fd129;
	mov.f64 	%fd131, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd132, %fd130, %fd125, %fd131;
	mov.f64 	%fd133, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd134, %fd132, %fd125, %fd133;
	mov.f64 	%fd135, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd136, %fd134, %fd125, %fd135;
	mov.f64 	%fd137, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd138, %fd136, %fd125, %fd137;
	mov.f64 	%fd139, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd140, %fd138, %fd125, %fd139;
	mov.f64 	%fd141, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd142, %fd140, %fd125, %fd141;
	mov.f64 	%fd143, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd144, %fd142, %fd125, %fd143;
	mov.f64 	%fd145, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd146, %fd144, %fd125, %fd145;
	mov.f64 	%fd147, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd148, %fd146, %fd125, %fd147;
	mov.f64 	%fd149, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd150, %fd148, %fd125, %fd149;
	mov.f64 	%fd151, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd152, %fd150, %fd125, %fd151;
	mov.f64 	%fd153, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd154, %fd152, %fd125, %fd153;
	mov.f64 	%fd155, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd156, %fd154, %fd125, %fd155;
	mov.f64 	%fd157, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd158, %fd156, %fd125, %fd157;
	mov.f64 	%fd159, 0d3FC99999999840D2;
	fma.rn.f64 	%fd160, %fd158, %fd125, %fd159;
	mov.f64 	%fd161, 0dBFD555555555544C;
	fma.rn.f64 	%fd162, %fd160, %fd125, %fd161;
	mul.rn.f64 	%fd163, %fd125, %fd162;
	fma.rn.f64 	%fd164, %fd163, %fd124, %fd124;
	mov.f64 	%fd165, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd166, %fd165, %fd164;
	setp.gt.f64 	%p63, %fd13, %fd3;
	selp.f64 	%fd167, %fd166, %fd164, %p63;
	mov.f64 	%fd168, 0d400921FB54442D18;
	sub.rn.f64 	%fd169, %fd168, %fd167;
	selp.f64 	%fd170, %fd169, %fd167, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd170;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd170;
	}
	and.b32  	%r79, %r5, -2147483648;
	or.b32  	%r80, %r78, %r79;
	mov.b64 	%fd171, {%r77, %r80};
	add.rn.f64 	%fd172, %fd3, %fd13;
	setp.le.f64 	%p64, %fd172, 0d7FF0000000000000;
	selp.f64 	%fd263, %fd171, %fd172, %p64;

$L__BB9_41:
	add.rn.f64 	%fd253, %fd78, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd253, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd41;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p67, %r91, 2146435072;
	setp.eq.s32 	%p68, %r89, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB9_45;
	bra.uni 	$L__BB9_42;

$L__BB9_45:
	mov.f64 	%fd184, 0d0000000000000000;
	mul.rn.f64 	%fd265, %fd41, %fd184;
	mov.u32 	%r120, 1;
	bra.uni 	$L__BB9_46;

$L__BB9_42:
	mul.rn.f64 	%fd175, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r119, %fd175;
	st.local.u32 	[%rd1], %r119;
	cvt.rn.f64.s32 	%fd176, %r119;
	neg.f64 	%fd177, %fd176;
	mov.f64 	%fd178, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd179, %fd177, %fd178, %fd41;
	mov.f64 	%fd180, 0d3C91A62633145C00;
	fma.rn.f64 	%fd181, %fd177, %fd180, %fd179;
	mov.f64 	%fd182, 0d397B839A252049C0;
	fma.rn.f64 	%fd265, %fd177, %fd182, %fd181;
	abs.f64 	%fd183, %fd41;
	setp.ltu.f64 	%p70, %fd183, 0d41E0000000000000;
	@%p70 bra 	$L__BB9_44;

	add.u64 	%rd40, %SP, 0;
	{ // callseq 105, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd40;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd265, [retval0+0];
	} // callseq 105
	ld.local.u32 	%r119, [%rd1];

$L__BB9_44:
	add.s32 	%r120, %r119, 1;

$L__BB9_46:
	mov.u64 	%rd41, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r120, 1;
	shl.b32 	%r94, %r120, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p71, %r93, 0;
	selp.f64 	%fd185, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd21, %r95, 8;
	add.s64 	%rd23, %rd41, %rd21;
	ld.global.nc.f64 	%fd186, [%rd23+8];
	mul.rn.f64 	%fd47, %fd265, %fd265;
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd23+16];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd23+24];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd23+32];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd23+40];
	fma.rn.f64 	%fd195, %fd193, %fd47, %fd194;
	ld.global.nc.f64 	%fd196, [%rd23+48];
	fma.rn.f64 	%fd48, %fd195, %fd47, %fd196;
	fma.rn.f64 	%fd267, %fd48, %fd265, %fd265;
	@%p71 bra 	$L__BB9_48;

	mov.f64 	%fd197, 0d3FF0000000000000;
	fma.rn.f64 	%fd267, %fd48, %fd47, %fd197;

$L__BB9_48:
	and.b32  	%r96, %r120, 2;
	setp.eq.s32 	%p72, %r96, 0;
	@%p72 bra 	$L__BB9_50;

	mov.f64 	%fd198, 0d0000000000000000;
	mov.f64 	%fd199, 0dBFF0000000000000;
	fma.rn.f64 	%fd267, %fd267, %fd199, %fd198;

$L__BB9_50:
	mul.rn.f64 	%fd200, %fd267, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd263, %fd200;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd54;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p73, %r99, 2146435072;
	setp.eq.s32 	%p74, %r97, 0;
	and.pred  	%p3, %p74, %p73;
	@%p3 bra 	$L__BB9_54;
	bra.uni 	$L__BB9_51;

$L__BB9_54:
	mov.f64 	%fd210, 0d0000000000000000;
	mul.rn.f64 	%fd269, %fd54, %fd210;
	mov.u32 	%r122, 1;
	bra.uni 	$L__BB9_55;

$L__BB9_51:
	mul.rn.f64 	%fd201, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r121, %fd201;
	st.local.u32 	[%rd1], %r121;
	cvt.rn.f64.s32 	%fd202, %r121;
	neg.f64 	%fd203, %fd202;
	mov.f64 	%fd204, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd205, %fd203, %fd204, %fd54;
	mov.f64 	%fd206, 0d3C91A62633145C00;
	fma.rn.f64 	%fd207, %fd203, %fd206, %fd205;
	mov.f64 	%fd208, 0d397B839A252049C0;
	fma.rn.f64 	%fd269, %fd203, %fd208, %fd207;
	abs.f64 	%fd209, %fd54;
	setp.ltu.f64 	%p75, %fd209, 0d41E0000000000000;
	@%p75 bra 	$L__BB9_53;

	add.u64 	%rd42, %SP, 0;
	{ // callseq 106, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd269, [retval0+0];
	} // callseq 106
	ld.local.u32 	%r121, [%rd1];

$L__BB9_53:
	add.s32 	%r122, %r121, 1;

$L__BB9_55:
	mov.u64 	%rd43, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r122, 1;
	shl.b32 	%r102, %r122, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p76, %r101, 0;
	selp.f64 	%fd211, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd25, %r103, 8;
	add.s64 	%rd27, %rd43, %rd25;
	ld.global.nc.f64 	%fd212, [%rd27+8];
	mul.rn.f64 	%fd60, %fd269, %fd269;
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd27+16];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd27+24];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd27+32];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd27+40];
	fma.rn.f64 	%fd221, %fd219, %fd60, %fd220;
	ld.global.nc.f64 	%fd222, [%rd27+48];
	fma.rn.f64 	%fd61, %fd221, %fd60, %fd222;
	fma.rn.f64 	%fd271, %fd61, %fd269, %fd269;
	@%p76 bra 	$L__BB9_57;

	mov.f64 	%fd223, 0d3FF0000000000000;
	fma.rn.f64 	%fd271, %fd61, %fd60, %fd223;

$L__BB9_57:
	and.b32  	%r104, %r122, 2;
	setp.eq.s32 	%p77, %r104, 0;
	@%p77 bra 	$L__BB9_59;

	mov.f64 	%fd224, 0d0000000000000000;
	mov.f64 	%fd225, 0dBFF0000000000000;
	fma.rn.f64 	%fd271, %fd271, %fd225, %fd224;

$L__BB9_59:
	ld.param.u64 	%rd35, [bd09_to_gcj02_cuda_double_param_0];
	mov.u32 	%r113, %tid.x;
	mov.u32 	%r112, %ntid.x;
	mov.u32 	%r111, %ctaid.x;
	mad.lo.s32 	%r110, %r111, %r112, %r113;
	mul.wide.s32 	%rd34, %r110, 8;
	cvta.to.global.u64 	%rd33, %rd35;
	add.s64 	%rd32, %rd33, %rd34;
	mul.rn.f64 	%fd226, %fd36, %fd271;
	st.global.f64 	[%rd32], %fd226;
	@%p3 bra 	$L__BB9_62;
	bra.uni 	$L__BB9_60;

$L__BB9_62:
	mov.f64 	%fd236, 0d0000000000000000;
	mul.rn.f64 	%fd272, %fd54, %fd236;
	mov.u32 	%r123, 0;
	bra.uni 	$L__BB9_63;

$L__BB9_60:
	mul.rn.f64 	%fd227, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r123, %fd227;
	st.local.u32 	[%rd1], %r123;
	cvt.rn.f64.s32 	%fd228, %r123;
	neg.f64 	%fd229, %fd228;
	mov.f64 	%fd230, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd231, %fd229, %fd230, %fd54;
	mov.f64 	%fd232, 0d3C91A62633145C00;
	fma.rn.f64 	%fd233, %fd229, %fd232, %fd231;
	mov.f64 	%fd234, 0d397B839A252049C0;
	fma.rn.f64 	%fd272, %fd229, %fd234, %fd233;
	abs.f64 	%fd235, %fd54;
	setp.ltu.f64 	%p78, %fd235, 0d41E0000000000000;
	@%p78 bra 	$L__BB9_63;

	add.u64 	%rd44, %SP, 0;
	{ // callseq 107, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd44;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd272, [retval0+0];
	} // callseq 107
	ld.local.u32 	%r123, [%rd1];

$L__BB9_63:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r106, %r123, 1;
	shl.b32 	%r107, %r123, 3;
	and.b32  	%r108, %r107, 8;
	setp.eq.s32 	%p79, %r106, 0;
	selp.f64 	%fd237, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd29, %r108, 8;
	add.s64 	%rd31, %rd45, %rd29;
	ld.global.nc.f64 	%fd238, [%rd31+8];
	mul.rn.f64 	%fd71, %fd272, %fd272;
	fma.rn.f64 	%fd239, %fd237, %fd71, %fd238;
	ld.global.nc.f64 	%fd240, [%rd31+16];
	fma.rn.f64 	%fd241, %fd239, %fd71, %fd240;
	ld.global.nc.f64 	%fd242, [%rd31+24];
	fma.rn.f64 	%fd243, %fd241, %fd71, %fd242;
	ld.global.nc.f64 	%fd244, [%rd31+32];
	fma.rn.f64 	%fd245, %fd243, %fd71, %fd244;
	ld.global.nc.f64 	%fd246, [%rd31+40];
	fma.rn.f64 	%fd247, %fd245, %fd71, %fd246;
	ld.global.nc.f64 	%fd248, [%rd31+48];
	fma.rn.f64 	%fd72, %fd247, %fd71, %fd248;
	fma.rn.f64 	%fd274, %fd72, %fd272, %fd272;
	@%p79 bra 	$L__BB9_65;

	mov.f64 	%fd249, 0d3FF0000000000000;
	fma.rn.f64 	%fd274, %fd72, %fd71, %fd249;

$L__BB9_65:
	and.b32  	%r109, %r123, 2;
	setp.eq.s32 	%p80, %r109, 0;
	@%p80 bra 	$L__BB9_67;

	mov.f64 	%fd250, 0d0000000000000000;
	mov.f64 	%fd251, 0dBFF0000000000000;
	fma.rn.f64 	%fd274, %fd274, %fd251, %fd250;

$L__BB9_67:
	ld.param.u64 	%rd39, [bd09_to_gcj02_cuda_double_param_1];
	mov.u32 	%r117, %tid.x;
	mov.u32 	%r116, %ntid.x;
	mov.u32 	%r115, %ctaid.x;
	mad.lo.s32 	%r114, %r115, %r116, %r117;
	mul.wide.s32 	%rd38, %r114, 8;
	cvta.to.global.u64 	%rd37, %rd39;
	add.s64 	%rd36, %rd37, %rd38;
	mul.rn.f64 	%fd252, %fd36, %fd274;
	st.global.f64 	[%rd36], %fd252;
	ret;

}
	// .globl	gcj02_to_bd09_cuda_double
.visible .entry gcj02_to_bd09_cuda_double(
	.param .u64 gcj02_to_bd09_cuda_double_param_0,
	.param .u64 gcj02_to_bd09_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot10[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<81>;
	.reg .b32 	%r<124>;
	.reg .f64 	%fd<274>;
	.reg .b64 	%rd<46>;


	mov.u64 	%SPL, __local_depot10;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd7, [gcj02_to_bd09_cuda_double_param_0];
	ld.param.u64 	%rd8, [gcj02_to_bd09_cuda_double_param_1];
	cvta.to.global.u64 	%rd9, %rd8;
	add.u64 	%rd10, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r23, %ntid.x;
	mov.u32 	%r24, %ctaid.x;
	mov.u32 	%r25, %tid.x;
	mad.lo.s32 	%r26, %r24, %r23, %r25;
	cvta.to.global.u64 	%rd14, %rd7;
	mul.wide.s32 	%rd15, %r26, 8;
	add.s64 	%rd5, %rd14, %rd15;
	add.s64 	%rd6, %rd9, %rd15;
	ld.global.f64 	%fd1, [%rd6];
	ld.global.f64 	%fd2, [%rd5];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd78, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd78;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p4, %r3, 1062207488;
	abs.f64 	%fd3, %fd2;
	{ // callseq 108, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd255, [retval0+0];
	} // callseq 108
	setp.lt.s32 	%p5, %r1, 0;
	and.pred  	%p1, %p5, %p4;
	not.pred 	%p6, %p1;
	@%p6 bra 	$L__BB10_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd255;
	}
	xor.b32  	%r28, %r27, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r29, %temp}, %fd255;
	}
	mov.b64 	%fd255, {%r29, %r28};

$L__BB10_2:
	setp.eq.f64 	%p7, %fd2, 0d0000000000000000;
	@%p7 bra 	$L__BB10_6;
	bra.uni 	$L__BB10_3;

$L__BB10_6:
	selp.b32 	%r30, %r1, 0, %p4;
	mov.u32 	%r31, 0;
	or.b32  	%r32, %r30, 2146435072;
	setp.lt.s32 	%p11, %r2, 0;
	selp.b32 	%r33, %r32, %r30, %p11;
	mov.b64 	%fd255, {%r31, %r33};
	bra.uni 	$L__BB10_7;

$L__BB10_3:
	setp.gt.s32 	%p8, %r1, -1;
	@%p8 bra 	$L__BB10_7;

	mov.f64 	%fd79, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd80, %fd79;
	setp.eq.f64 	%p9, %fd80, 0d4000000000000000;
	@%p9 bra 	$L__BB10_7;

	mov.f64 	%fd255, 0dFFF8000000000000;

$L__BB10_7:
	add.rn.f64 	%fd82, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r34}, %fd82;
	}
	and.b32  	%r35, %r34, 2146435072;
	setp.ne.s32 	%p12, %r35, 2146435072;
	@%p12 bra 	$L__BB10_14;

	setp.gtu.f64 	%p13, %fd3, 0d7FF0000000000000;
	@%p13 bra 	$L__BB10_13;
	bra.uni 	$L__BB10_9;

$L__BB10_13:
	mov.f64 	%fd84, 0d4000000000000000;
	add.rn.f64 	%fd255, %fd2, %fd84;
	bra.uni 	$L__BB10_14;

$L__BB10_9:
	mov.f64 	%fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r36, %temp}, %fd83;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p14, %r4, 2146435072;
	setp.eq.s32 	%p15, %r36, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	$L__BB10_12;
	bra.uni 	$L__BB10_10;

$L__BB10_12:
	setp.gt.f64 	%p23, %fd3, 0d3FF0000000000000;
	selp.b32 	%r43, 2146435072, 0, %p23;
	mov.u32 	%r44, 0;
	xor.b32  	%r45, %r43, 2146435072;
	setp.lt.s32 	%p24, %r2, 0;
	selp.b32 	%r46, %r45, %r43, %p24;
	setp.eq.f64 	%p25, %fd2, 0dBFF0000000000000;
	selp.b32 	%r47, 1072693248, %r46, %p25;
	mov.b64 	%fd255, {%r44, %r47};
	bra.uni 	$L__BB10_14;

$L__BB10_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r37, %temp}, %fd2;
	}
	and.b32  	%r38, %r1, 2147483647;
	setp.ne.s32 	%p17, %r38, 2146435072;
	setp.ne.s32 	%p18, %r37, 0;
	or.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB10_14;

	setp.gt.s32 	%p20, %r2, -1;
	selp.b32 	%r39, 2146435072, 0, %p20;
	mov.u32 	%r40, 0;
	setp.ne.s32 	%p21, %r4, 1071644672;
	and.pred  	%p22, %p21, %p1;
	or.b32  	%r41, %r39, -2147483648;
	selp.b32 	%r42, %r41, %r39, %p22;
	mov.b64 	%fd255, {%r40, %r42};

$L__BB10_14:
	abs.f64 	%fd13, %fd1;
	{ // callseq 109, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd258, [retval0+0];
	} // callseq 109
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd1;
	}
	setp.lt.s32 	%p26, %r5, 0;
	and.pred  	%p2, %p26, %p4;
	not.pred 	%p28, %p2;
	@%p28 bra 	$L__BB10_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd258;
	}
	xor.b32  	%r49, %r48, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r50, %temp}, %fd258;
	}
	mov.b64 	%fd258, {%r50, %r49};

$L__BB10_16:
	setp.eq.f64 	%p29, %fd1, 0d0000000000000000;
	@%p29 bra 	$L__BB10_20;
	bra.uni 	$L__BB10_17;

$L__BB10_20:
	selp.b32 	%r51, %r5, 0, %p4;
	mov.u32 	%r52, 0;
	or.b32  	%r53, %r51, 2146435072;
	setp.lt.s32 	%p33, %r2, 0;
	selp.b32 	%r54, %r53, %r51, %p33;
	mov.b64 	%fd258, {%r52, %r54};
	bra.uni 	$L__BB10_21;

$L__BB10_17:
	setp.gt.s32 	%p30, %r5, -1;
	@%p30 bra 	$L__BB10_21;

	mov.f64 	%fd85, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd86, %fd85;
	setp.eq.f64 	%p31, %fd86, 0d4000000000000000;
	@%p31 bra 	$L__BB10_21;

	mov.f64 	%fd258, 0dFFF8000000000000;

$L__BB10_21:
	add.rn.f64 	%fd88, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd88;
	}
	and.b32  	%r56, %r55, 2146435072;
	setp.ne.s32 	%p34, %r56, 2146435072;
	@%p34 bra 	$L__BB10_28;

	setp.gtu.f64 	%p35, %fd13, 0d7FF0000000000000;
	@%p35 bra 	$L__BB10_27;
	bra.uni 	$L__BB10_23;

$L__BB10_27:
	mov.f64 	%fd90, 0d4000000000000000;
	add.rn.f64 	%fd258, %fd1, %fd90;
	bra.uni 	$L__BB10_28;

$L__BB10_23:
	mov.f64 	%fd89, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd89;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p36, %r6, 2146435072;
	setp.eq.s32 	%p37, %r57, 0;
	and.pred  	%p38, %p36, %p37;
	@%p38 bra 	$L__BB10_26;
	bra.uni 	$L__BB10_24;

$L__BB10_26:
	setp.gt.f64 	%p45, %fd13, 0d3FF0000000000000;
	selp.b32 	%r64, 2146435072, 0, %p45;
	mov.u32 	%r65, 0;
	xor.b32  	%r66, %r64, 2146435072;
	setp.lt.s32 	%p46, %r2, 0;
	selp.b32 	%r67, %r66, %r64, %p46;
	setp.eq.f64 	%p47, %fd1, 0dBFF0000000000000;
	selp.b32 	%r68, 1072693248, %r67, %p47;
	mov.b64 	%fd258, {%r65, %r68};
	bra.uni 	$L__BB10_28;

$L__BB10_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r58, %temp}, %fd1;
	}
	and.b32  	%r59, %r5, 2147483647;
	setp.ne.s32 	%p39, %r59, 2146435072;
	setp.ne.s32 	%p40, %r58, 0;
	or.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB10_28;

	setp.gt.s32 	%p42, %r2, -1;
	selp.b32 	%r60, 2146435072, 0, %p42;
	mov.u32 	%r61, 0;
	setp.ne.s32 	%p43, %r6, 1071644672;
	and.pred  	%p44, %p43, %p2;
	or.b32  	%r62, %r60, -2147483648;
	selp.b32 	%r63, %r62, %r60, %p44;
	mov.b64 	%fd258, {%r61, %r63};

$L__BB10_28:
	setp.eq.f64 	%p48, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd91, 0d3FF0000000000000, %fd258, %p48;
	setp.eq.f64 	%p49, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd92, 0d3FF0000000000000, %fd255, %p49;
	add.rn.f64 	%fd23, %fd92, %fd91;
	mul.rn.f64 	%fd24, %fd1, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd24;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p50, %r71, 2146435072;
	setp.eq.s32 	%p51, %r69, 0;
	and.pred  	%p52, %p51, %p50;
	@%p52 bra 	$L__BB10_31;
	bra.uni 	$L__BB10_29;

$L__BB10_31:
	mov.f64 	%fd102, 0d0000000000000000;
	mul.rn.f64 	%fd259, %fd24, %fd102;
	mov.u32 	%r118, 0;
	bra.uni 	$L__BB10_32;

$L__BB10_29:
	mul.rn.f64 	%fd93, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r118, %fd93;
	st.local.u32 	[%rd1], %r118;
	cvt.rn.f64.s32 	%fd94, %r118;
	neg.f64 	%fd95, %fd94;
	mov.f64 	%fd96, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd97, %fd95, %fd96, %fd24;
	mov.f64 	%fd98, 0d3C91A62633145C00;
	fma.rn.f64 	%fd99, %fd95, %fd98, %fd97;
	mov.f64 	%fd100, 0d397B839A252049C0;
	fma.rn.f64 	%fd259, %fd95, %fd100, %fd99;
	abs.f64 	%fd101, %fd24;
	setp.ltu.f64 	%p53, %fd101, 0d41E0000000000000;
	@%p53 bra 	$L__BB10_32;

	{ // callseq 110, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd10;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd259, [retval0+0];
	} // callseq 110
	ld.local.u32 	%r118, [%rd1];

$L__BB10_32:
	and.b32  	%r73, %r118, 1;
	shl.b32 	%r74, %r118, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p54, %r73, 0;
	selp.f64 	%fd103, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p54;
	mul.wide.s32 	%rd17, %r75, 8;
	mov.u64 	%rd18, __cudart_sin_cos_coeffs;
	add.s64 	%rd19, %rd18, %rd17;
	ld.global.nc.f64 	%fd104, [%rd19+8];
	mul.rn.f64 	%fd29, %fd259, %fd259;
	fma.rn.f64 	%fd105, %fd103, %fd29, %fd104;
	ld.global.nc.f64 	%fd106, [%rd19+16];
	fma.rn.f64 	%fd107, %fd105, %fd29, %fd106;
	ld.global.nc.f64 	%fd108, [%rd19+24];
	fma.rn.f64 	%fd109, %fd107, %fd29, %fd108;
	ld.global.nc.f64 	%fd110, [%rd19+32];
	fma.rn.f64 	%fd111, %fd109, %fd29, %fd110;
	ld.global.nc.f64 	%fd112, [%rd19+40];
	fma.rn.f64 	%fd113, %fd111, %fd29, %fd112;
	ld.global.nc.f64 	%fd114, [%rd19+48];
	fma.rn.f64 	%fd30, %fd113, %fd29, %fd114;
	fma.rn.f64 	%fd261, %fd30, %fd259, %fd259;
	@%p54 bra 	$L__BB10_34;

	mov.f64 	%fd115, 0d3FF0000000000000;
	fma.rn.f64 	%fd261, %fd30, %fd29, %fd115;

$L__BB10_34:
	and.b32  	%r76, %r118, 2;
	setp.eq.s32 	%p55, %r76, 0;
	@%p55 bra 	$L__BB10_36;

	mov.f64 	%fd116, 0d0000000000000000;
	mov.f64 	%fd117, 0dBFF0000000000000;
	fma.rn.f64 	%fd261, %fd261, %fd117, %fd116;

$L__BB10_36:
	mul.rn.f64 	%fd118, %fd261, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd119, %fd23;
	add.rn.f64 	%fd36, %fd119, %fd118;
	setp.eq.f64 	%p56, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p57, %fd3, 0d0000000000000000;
	and.pred  	%p58, %p57, %p56;
	@%p58 bra 	$L__BB10_40;
	bra.uni 	$L__BB10_37;

$L__BB10_40:
	selp.f64 	%fd172, 0d400921FB54442D18, 0d0000000000000000, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r85, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r86}, %fd172;
	}
	and.b32  	%r87, %r5, -2147483648;
	or.b32  	%r88, %r86, %r87;
	mov.b64 	%fd262, {%r85, %r88};
	bra.uni 	$L__BB10_41;

$L__BB10_37:
	setp.eq.f64 	%p59, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p60, %fd13, 0d7FF0000000000000;
	and.pred  	%p61, %p59, %p60;
	@%p61 bra 	$L__BB10_39;
	bra.uni 	$L__BB10_38;

$L__BB10_39:
	selp.f64 	%fd171, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd171;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd171;
	}
	and.b32  	%r83, %r5, -2147483648;
	or.b32  	%r84, %r82, %r83;
	mov.b64 	%fd262, {%r81, %r84};
	bra.uni 	$L__BB10_41;

$L__BB10_38:
	min.f64 	%fd120, %fd13, %fd3;
	max.f64 	%fd121, %fd13, %fd3;
	div.rn.f64 	%fd122, %fd120, %fd121;
	mul.rn.f64 	%fd123, %fd122, %fd122;
	mov.f64 	%fd124, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd125, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd126, %fd125, %fd123, %fd124;
	mov.f64 	%fd127, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd128, %fd126, %fd123, %fd127;
	mov.f64 	%fd129, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd130, %fd128, %fd123, %fd129;
	mov.f64 	%fd131, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd132, %fd130, %fd123, %fd131;
	mov.f64 	%fd133, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd134, %fd132, %fd123, %fd133;
	mov.f64 	%fd135, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd136, %fd134, %fd123, %fd135;
	mov.f64 	%fd137, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd138, %fd136, %fd123, %fd137;
	mov.f64 	%fd139, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd140, %fd138, %fd123, %fd139;
	mov.f64 	%fd141, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd142, %fd140, %fd123, %fd141;
	mov.f64 	%fd143, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd144, %fd142, %fd123, %fd143;
	mov.f64 	%fd145, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd146, %fd144, %fd123, %fd145;
	mov.f64 	%fd147, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd148, %fd146, %fd123, %fd147;
	mov.f64 	%fd149, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd150, %fd148, %fd123, %fd149;
	mov.f64 	%fd151, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd152, %fd150, %fd123, %fd151;
	mov.f64 	%fd153, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd154, %fd152, %fd123, %fd153;
	mov.f64 	%fd155, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd156, %fd154, %fd123, %fd155;
	mov.f64 	%fd157, 0d3FC99999999840D2;
	fma.rn.f64 	%fd158, %fd156, %fd123, %fd157;
	mov.f64 	%fd159, 0dBFD555555555544C;
	fma.rn.f64 	%fd160, %fd158, %fd123, %fd159;
	mul.rn.f64 	%fd161, %fd123, %fd160;
	fma.rn.f64 	%fd162, %fd161, %fd122, %fd122;
	mov.f64 	%fd163, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd164, %fd163, %fd162;
	setp.gt.f64 	%p63, %fd13, %fd3;
	selp.f64 	%fd165, %fd164, %fd162, %p63;
	mov.f64 	%fd166, 0d400921FB54442D18;
	sub.rn.f64 	%fd167, %fd166, %fd165;
	selp.f64 	%fd168, %fd167, %fd165, %p5;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd168;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd168;
	}
	and.b32  	%r79, %r5, -2147483648;
	or.b32  	%r80, %r78, %r79;
	mov.b64 	%fd169, {%r77, %r80};
	add.rn.f64 	%fd170, %fd3, %fd13;
	setp.le.f64 	%p64, %fd170, 0d7FF0000000000000;
	selp.f64 	%fd262, %fd169, %fd170, %p64;

$L__BB10_41:
	mul.rn.f64 	%fd41, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd41;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p67, %r91, 2146435072;
	setp.eq.s32 	%p68, %r89, 0;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB10_45;
	bra.uni 	$L__BB10_42;

$L__BB10_45:
	mov.f64 	%fd182, 0d0000000000000000;
	mul.rn.f64 	%fd264, %fd41, %fd182;
	mov.u32 	%r120, 1;
	bra.uni 	$L__BB10_46;

$L__BB10_42:
	mul.rn.f64 	%fd173, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r119, %fd173;
	st.local.u32 	[%rd1], %r119;
	cvt.rn.f64.s32 	%fd174, %r119;
	neg.f64 	%fd175, %fd174;
	mov.f64 	%fd176, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd177, %fd175, %fd176, %fd41;
	mov.f64 	%fd178, 0d3C91A62633145C00;
	fma.rn.f64 	%fd179, %fd175, %fd178, %fd177;
	mov.f64 	%fd180, 0d397B839A252049C0;
	fma.rn.f64 	%fd264, %fd175, %fd180, %fd179;
	abs.f64 	%fd181, %fd41;
	setp.ltu.f64 	%p70, %fd181, 0d41E0000000000000;
	@%p70 bra 	$L__BB10_44;

	add.u64 	%rd32, %SP, 0;
	{ // callseq 111, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd32;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd264, [retval0+0];
	} // callseq 111
	ld.local.u32 	%r119, [%rd1];

$L__BB10_44:
	add.s32 	%r120, %r119, 1;

$L__BB10_46:
	mov.u64 	%rd43, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r120, 1;
	shl.b32 	%r94, %r120, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p71, %r93, 0;
	selp.f64 	%fd183, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p71;
	mul.wide.s32 	%rd21, %r95, 8;
	add.s64 	%rd23, %rd43, %rd21;
	ld.global.nc.f64 	%fd184, [%rd23+8];
	mul.rn.f64 	%fd47, %fd264, %fd264;
	fma.rn.f64 	%fd185, %fd183, %fd47, %fd184;
	ld.global.nc.f64 	%fd186, [%rd23+16];
	fma.rn.f64 	%fd187, %fd185, %fd47, %fd186;
	ld.global.nc.f64 	%fd188, [%rd23+24];
	fma.rn.f64 	%fd189, %fd187, %fd47, %fd188;
	ld.global.nc.f64 	%fd190, [%rd23+32];
	fma.rn.f64 	%fd191, %fd189, %fd47, %fd190;
	ld.global.nc.f64 	%fd192, [%rd23+40];
	fma.rn.f64 	%fd193, %fd191, %fd47, %fd192;
	ld.global.nc.f64 	%fd194, [%rd23+48];
	fma.rn.f64 	%fd48, %fd193, %fd47, %fd194;
	fma.rn.f64 	%fd266, %fd48, %fd264, %fd264;
	@%p71 bra 	$L__BB10_48;

	mov.f64 	%fd195, 0d3FF0000000000000;
	fma.rn.f64 	%fd266, %fd48, %fd47, %fd195;

$L__BB10_48:
	and.b32  	%r96, %r120, 2;
	setp.eq.s32 	%p72, %r96, 0;
	@%p72 bra 	$L__BB10_50;

	mov.f64 	%fd196, 0d0000000000000000;
	mov.f64 	%fd197, 0dBFF0000000000000;
	fma.rn.f64 	%fd266, %fd266, %fd197, %fd196;

$L__BB10_50:
	mul.rn.f64 	%fd198, %fd266, 0d3EC92A737110E454;
	add.rn.f64 	%fd54, %fd262, %fd198;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r97, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r98}, %fd54;
	}
	and.b32  	%r99, %r98, 2147483647;
	setp.eq.s32 	%p73, %r99, 2146435072;
	setp.eq.s32 	%p74, %r97, 0;
	and.pred  	%p3, %p74, %p73;
	@%p3 bra 	$L__BB10_54;
	bra.uni 	$L__BB10_51;

$L__BB10_54:
	mov.f64 	%fd208, 0d0000000000000000;
	mul.rn.f64 	%fd268, %fd54, %fd208;
	mov.u32 	%r122, 1;
	bra.uni 	$L__BB10_55;

$L__BB10_51:
	mul.rn.f64 	%fd199, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r121, %fd199;
	st.local.u32 	[%rd1], %r121;
	cvt.rn.f64.s32 	%fd200, %r121;
	neg.f64 	%fd201, %fd200;
	mov.f64 	%fd202, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd203, %fd201, %fd202, %fd54;
	mov.f64 	%fd204, 0d3C91A62633145C00;
	fma.rn.f64 	%fd205, %fd201, %fd204, %fd203;
	mov.f64 	%fd206, 0d397B839A252049C0;
	fma.rn.f64 	%fd268, %fd201, %fd206, %fd205;
	abs.f64 	%fd207, %fd54;
	setp.ltu.f64 	%p75, %fd207, 0d41E0000000000000;
	@%p75 bra 	$L__BB10_53;

	add.u64 	%rd33, %SP, 0;
	{ // callseq 112, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd33;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd268, [retval0+0];
	} // callseq 112
	ld.local.u32 	%r121, [%rd1];

$L__BB10_53:
	add.s32 	%r122, %r121, 1;

$L__BB10_55:
	mov.u64 	%rd44, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r122, 1;
	shl.b32 	%r102, %r122, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p76, %r101, 0;
	selp.f64 	%fd209, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd25, %r103, 8;
	add.s64 	%rd27, %rd44, %rd25;
	ld.global.nc.f64 	%fd210, [%rd27+8];
	mul.rn.f64 	%fd60, %fd268, %fd268;
	fma.rn.f64 	%fd211, %fd209, %fd60, %fd210;
	ld.global.nc.f64 	%fd212, [%rd27+16];
	fma.rn.f64 	%fd213, %fd211, %fd60, %fd212;
	ld.global.nc.f64 	%fd214, [%rd27+24];
	fma.rn.f64 	%fd215, %fd213, %fd60, %fd214;
	ld.global.nc.f64 	%fd216, [%rd27+32];
	fma.rn.f64 	%fd217, %fd215, %fd60, %fd216;
	ld.global.nc.f64 	%fd218, [%rd27+40];
	fma.rn.f64 	%fd219, %fd217, %fd60, %fd218;
	ld.global.nc.f64 	%fd220, [%rd27+48];
	fma.rn.f64 	%fd61, %fd219, %fd60, %fd220;
	fma.rn.f64 	%fd270, %fd61, %fd268, %fd268;
	@%p76 bra 	$L__BB10_57;

	mov.f64 	%fd221, 0d3FF0000000000000;
	fma.rn.f64 	%fd270, %fd61, %fd60, %fd221;

$L__BB10_57:
	and.b32  	%r104, %r122, 2;
	setp.eq.s32 	%p77, %r104, 0;
	@%p77 bra 	$L__BB10_59;

	mov.f64 	%fd222, 0d0000000000000000;
	mov.f64 	%fd223, 0dBFF0000000000000;
	fma.rn.f64 	%fd270, %fd270, %fd223, %fd222;

$L__BB10_59:
	ld.param.u64 	%rd37, [gcj02_to_bd09_cuda_double_param_0];
	mov.u32 	%r113, %tid.x;
	mov.u32 	%r112, %ntid.x;
	mov.u32 	%r111, %ctaid.x;
	mad.lo.s32 	%r110, %r111, %r112, %r113;
	mul.wide.s32 	%rd36, %r110, 8;
	cvta.to.global.u64 	%rd35, %rd37;
	add.s64 	%rd34, %rd35, %rd36;
	mul.rn.f64 	%fd224, %fd36, %fd270;
	add.rn.f64 	%fd225, %fd224, 0d3F7A9FBE76C8B439;
	st.global.f64 	[%rd34], %fd225;
	@%p3 bra 	$L__BB10_62;
	bra.uni 	$L__BB10_60;

$L__BB10_62:
	mov.f64 	%fd235, 0d0000000000000000;
	mul.rn.f64 	%fd271, %fd54, %fd235;
	mov.u32 	%r123, 0;
	bra.uni 	$L__BB10_63;

$L__BB10_60:
	mul.rn.f64 	%fd226, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r123, %fd226;
	st.local.u32 	[%rd1], %r123;
	cvt.rn.f64.s32 	%fd227, %r123;
	neg.f64 	%fd228, %fd227;
	mov.f64 	%fd229, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd230, %fd228, %fd229, %fd54;
	mov.f64 	%fd231, 0d3C91A62633145C00;
	fma.rn.f64 	%fd232, %fd228, %fd231, %fd230;
	mov.f64 	%fd233, 0d397B839A252049C0;
	fma.rn.f64 	%fd271, %fd228, %fd233, %fd232;
	abs.f64 	%fd234, %fd54;
	setp.ltu.f64 	%p78, %fd234, 0d41E0000000000000;
	@%p78 bra 	$L__BB10_63;

	add.u64 	%rd38, %SP, 0;
	{ // callseq 113, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd38;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd271, [retval0+0];
	} // callseq 113
	ld.local.u32 	%r123, [%rd1];

$L__BB10_63:
	mov.u64 	%rd45, __cudart_sin_cos_coeffs;
	and.b32  	%r106, %r123, 1;
	shl.b32 	%r107, %r123, 3;
	and.b32  	%r108, %r107, 8;
	setp.eq.s32 	%p79, %r106, 0;
	selp.f64 	%fd236, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd29, %r108, 8;
	add.s64 	%rd31, %rd45, %rd29;
	ld.global.nc.f64 	%fd237, [%rd31+8];
	mul.rn.f64 	%fd71, %fd271, %fd271;
	fma.rn.f64 	%fd238, %fd236, %fd71, %fd237;
	ld.global.nc.f64 	%fd239, [%rd31+16];
	fma.rn.f64 	%fd240, %fd238, %fd71, %fd239;
	ld.global.nc.f64 	%fd241, [%rd31+24];
	fma.rn.f64 	%fd242, %fd240, %fd71, %fd241;
	ld.global.nc.f64 	%fd243, [%rd31+32];
	fma.rn.f64 	%fd244, %fd242, %fd71, %fd243;
	ld.global.nc.f64 	%fd245, [%rd31+40];
	fma.rn.f64 	%fd246, %fd244, %fd71, %fd245;
	ld.global.nc.f64 	%fd247, [%rd31+48];
	fma.rn.f64 	%fd72, %fd246, %fd71, %fd247;
	fma.rn.f64 	%fd273, %fd72, %fd271, %fd271;
	@%p79 bra 	$L__BB10_65;

	mov.f64 	%fd248, 0d3FF0000000000000;
	fma.rn.f64 	%fd273, %fd72, %fd71, %fd248;

$L__BB10_65:
	and.b32  	%r109, %r123, 2;
	setp.eq.s32 	%p80, %r109, 0;
	@%p80 bra 	$L__BB10_67;

	mov.f64 	%fd249, 0d0000000000000000;
	mov.f64 	%fd250, 0dBFF0000000000000;
	fma.rn.f64 	%fd273, %fd273, %fd250, %fd249;

$L__BB10_67:
	ld.param.u64 	%rd42, [gcj02_to_bd09_cuda_double_param_1];
	mov.u32 	%r117, %tid.x;
	mov.u32 	%r116, %ntid.x;
	mov.u32 	%r115, %ctaid.x;
	mad.lo.s32 	%r114, %r115, %r116, %r117;
	mul.wide.s32 	%rd41, %r114, 8;
	cvta.to.global.u64 	%rd40, %rd42;
	add.s64 	%rd39, %rd40, %rd41;
	mul.rn.f64 	%fd251, %fd36, %fd273;
	add.rn.f64 	%fd252, %fd251, 0d3F789374BC6A7EFA;
	st.global.f64 	[%rd39], %fd252;
	ret;

}
	// .globl	gcj02_to_wgs84_cuda_double
.visible .entry gcj02_to_wgs84_cuda_double(
	.param .u64 gcj02_to_wgs84_cuda_double_param_0,
	.param .u64 gcj02_to_wgs84_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot11[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<118>;
	.reg .b32 	%r<201>;
	.reg .f64 	%fd<601>;
	.reg .b64 	%rd<110>;


	mov.u64 	%SPL, __local_depot11;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [gcj02_to_wgs84_cuda_double_param_0];
	ld.param.u64 	%rd16, [gcj02_to_wgs84_cuda_double_param_1];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r48, %r46, %r45, %r47;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r48, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd9;
	}
	and.b32  	%r51, %r50, 2147483647;
	setp.eq.s32 	%p4, %r51, 2146435072;
	setp.eq.s32 	%p5, %r49, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB11_3;
	bra.uni 	$L__BB11_1;

$L__BB11_3:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd558, %fd9, %fd192;
	mov.u32 	%r188, 0;
	bra.uni 	$L__BB11_4;

$L__BB11_1:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r188, %fd183;
	st.local.u32 	[%rd1], %r188;
	cvt.rn.f64.s32 	%fd184, %r188;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd558, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p7, %fd191, 0d41E0000000000000;
	@%p7 bra 	$L__BB11_4;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 114, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd558, [retval0+0];
	} // callseq 114
	ld.local.u32 	%r188, [%rd1];

$L__BB11_4:
	and.b32  	%r53, %r188, 1;
	shl.b32 	%r54, %r188, 3;
	and.b32  	%r55, %r54, 8;
	setp.eq.s32 	%p8, %r53, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd33, %r55, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd194, [%rd35+8];
	mul.rn.f64 	%fd14, %fd558, %fd558;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd35+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd35+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd35+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd35+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd35+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd560, %fd15, %fd558, %fd558;
	@%p8 bra 	$L__BB11_6;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd560, %fd15, %fd14, %fd205;

$L__BB11_6:
	and.b32  	%r56, %r188, 2;
	setp.eq.s32 	%p9, %r56, 0;
	@%p9 bra 	$L__BB11_8;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd560, %fd560, %fd207, %fd206;

$L__BB11_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd21;
	}
	and.b32  	%r59, %r58, 2147483647;
	setp.eq.s32 	%p10, %r59, 2146435072;
	setp.eq.s32 	%p11, %r57, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB11_11;
	bra.uni 	$L__BB11_9;

$L__BB11_11:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd561, %fd21, %fd217;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB11_12;

$L__BB11_9:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd208;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd209, %r189;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd561, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p13, %fd216, 0d41E0000000000000;
	@%p13 bra 	$L__BB11_12;

	add.u64 	%rd98, %SP, 0;
	{ // callseq 115, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd98;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd561, [retval0+0];
	} // callseq 115
	ld.local.u32 	%r189, [%rd1];

$L__BB11_12:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r61, %r189, 1;
	shl.b32 	%r62, %r189, 3;
	and.b32  	%r63, %r62, 8;
	setp.eq.s32 	%p14, %r61, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd37, %r63, 8;
	add.s64 	%rd39, %rd108, %rd37;
	ld.global.nc.f64 	%fd219, [%rd39+8];
	mul.rn.f64 	%fd26, %fd561, %fd561;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd39+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd39+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd39+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd39+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd39+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd563, %fd27, %fd561, %fd561;
	@%p14 bra 	$L__BB11_14;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd563, %fd27, %fd26, %fd230;

$L__BB11_14:
	and.b32  	%r64, %r189, 2;
	setp.eq.s32 	%p15, %r64, 0;
	@%p15 bra 	$L__BB11_16;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd563, %fd563, %fd232, %fd231;

$L__BB11_16:
	mul.rn.f64 	%fd233, %fd563, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd560, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd8;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.eq.s32 	%p16, %r66, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd8;
	}
	setp.eq.s32 	%p17, %r67, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB11_19;
	bra.uni 	$L__BB11_17;

$L__BB11_19:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd564, %fd8, %fd244;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB11_20;

$L__BB11_17:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd235;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd236, %r190;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd564, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p19, %fd243, 0d41E0000000000000;
	@%p19 bra 	$L__BB11_20;

	add.u64 	%rd80, %SP, 0;
	{ // callseq 116, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd564, [retval0+0];
	} // callseq 116
	ld.local.u32 	%r190, [%rd1];

$L__BB11_20:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r69, %r190, 1;
	shl.b32 	%r70, %r190, 3;
	and.b32  	%r71, %r70, 8;
	setp.eq.s32 	%p20, %r69, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd41, %r71, 8;
	add.s64 	%rd43, %rd109, %rd41;
	ld.global.nc.f64 	%fd246, [%rd43+8];
	mul.rn.f64 	%fd38, %fd564, %fd564;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd43+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd43+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd43+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd43+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd43+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd566, %fd39, %fd564, %fd564;
	@%p20 bra 	$L__BB11_22;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd566, %fd39, %fd38, %fd257;

$L__BB11_22:
	and.b32  	%r72, %r190, 2;
	setp.eq.s32 	%p21, %r72, 0;
	@%p21 bra 	$L__BB11_24;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd566, %fd566, %fd259, %fd258;

$L__BB11_24:
	add.rn.f64 	%fd557, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd556, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd45;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.eq.s32 	%p22, %r75, 2146435072;
	setp.eq.s32 	%p23, %r73, 0;
	and.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB11_27;
	bra.uni 	$L__BB11_25;

$L__BB11_27:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd567, %fd45, %fd269;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB11_28;

$L__BB11_25:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd260;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd261, %r191;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd567, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p25, %fd268, 0d41E0000000000000;
	@%p25 bra 	$L__BB11_28;

	add.u64 	%rd81, %SP, 0;
	{ // callseq 117, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd567, [retval0+0];
	} // callseq 117
	ld.local.u32 	%r191, [%rd1];

$L__BB11_28:
	mov.u64 	%rd99, __cudart_sin_cos_coeffs;
	and.b32  	%r77, %r191, 1;
	shl.b32 	%r78, %r191, 3;
	and.b32  	%r79, %r78, 8;
	setp.eq.s32 	%p26, %r77, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	mul.wide.s32 	%rd45, %r79, 8;
	add.s64 	%rd47, %rd99, %rd45;
	ld.global.nc.f64 	%fd271, [%rd47+8];
	mul.rn.f64 	%fd50, %fd567, %fd567;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd47+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd47+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd47+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd47+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd47+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd569, %fd51, %fd567, %fd567;
	@%p26 bra 	$L__BB11_30;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd569, %fd51, %fd50, %fd282;

$L__BB11_30:
	and.b32  	%r80, %r191, 2;
	setp.eq.s32 	%p27, %r80, 0;
	@%p27 bra 	$L__BB11_32;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd569, %fd569, %fd284, %fd283;

$L__BB11_32:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd569, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd566, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd58;
	}
	and.b32  	%r83, %r82, 2147483647;
	setp.eq.s32 	%p28, %r83, 2146435072;
	setp.eq.s32 	%p29, %r81, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB11_35;
	bra.uni 	$L__BB11_33;

$L__BB11_35:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd570, %fd58, %fd296;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB11_36;

$L__BB11_33:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd287;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd288, %r192;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd570, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p31, %fd295, 0d41E0000000000000;
	@%p31 bra 	$L__BB11_36;

	add.u64 	%rd82, %SP, 0;
	{ // callseq 118, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd570, [retval0+0];
	} // callseq 118
	ld.local.u32 	%r192, [%rd1];

$L__BB11_36:
	mov.u64 	%rd100, __cudart_sin_cos_coeffs;
	and.b32  	%r85, %r192, 1;
	shl.b32 	%r86, %r192, 3;
	and.b32  	%r87, %r86, 8;
	setp.eq.s32 	%p32, %r85, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd49, %r87, 8;
	add.s64 	%rd51, %rd100, %rd49;
	ld.global.nc.f64 	%fd298, [%rd51+8];
	mul.rn.f64 	%fd63, %fd570, %fd570;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd51+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd51+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd51+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd51+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd51+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd572, %fd64, %fd570, %fd570;
	@%p32 bra 	$L__BB11_38;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd572, %fd64, %fd63, %fd309;

$L__BB11_38:
	and.b32  	%r88, %r192, 2;
	setp.eq.s32 	%p33, %r88, 0;
	@%p33 bra 	$L__BB11_40;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd572, %fd572, %fd311, %fd310;

$L__BB11_40:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd572, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd71;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p34, %r91, 2146435072;
	setp.eq.s32 	%p35, %r89, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB11_43;
	bra.uni 	$L__BB11_41;

$L__BB11_43:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd573, %fd71, %fd322;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB11_44;

$L__BB11_41:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd313;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd314, %r193;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd573, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p37, %fd321, 0d41E0000000000000;
	@%p37 bra 	$L__BB11_44;

	add.u64 	%rd83, %SP, 0;
	{ // callseq 119, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd573, [retval0+0];
	} // callseq 119
	ld.local.u32 	%r193, [%rd1];

$L__BB11_44:
	mov.u64 	%rd101, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r193, 1;
	shl.b32 	%r94, %r193, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p38, %r93, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd53, %r95, 8;
	add.s64 	%rd55, %rd101, %rd53;
	ld.global.nc.f64 	%fd324, [%rd55+8];
	mul.rn.f64 	%fd76, %fd573, %fd573;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd55+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd55+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd55+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd55+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd55+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd575, %fd77, %fd573, %fd573;
	@%p38 bra 	$L__BB11_46;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd575, %fd77, %fd76, %fd335;

$L__BB11_46:
	and.b32  	%r96, %r193, 2;
	setp.eq.s32 	%p39, %r96, 0;
	@%p39 bra 	$L__BB11_48;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd575, %fd575, %fd337, %fd336;

$L__BB11_48:
	mul.rn.f64 	%fd338, %fd575, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd7;
	}
	and.b32  	%r98, %r97, 2147483647;
	setp.eq.s32 	%p40, %r98, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd7;
	}
	setp.eq.s32 	%p41, %r99, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB11_51;
	bra.uni 	$L__BB11_49;

$L__BB11_51:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd576, %fd7, %fd348;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB11_52;

$L__BB11_49:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd339;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd340, %r194;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd576, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p43, %fd347, 0d41E0000000000000;
	@%p43 bra 	$L__BB11_52;

	add.u64 	%rd84, %SP, 0;
	{ // callseq 120, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd576, [retval0+0];
	} // callseq 120
	ld.local.u32 	%r194, [%rd1];

$L__BB11_52:
	mov.u64 	%rd102, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r194, 1;
	shl.b32 	%r102, %r194, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p44, %r101, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd57, %r103, 8;
	add.s64 	%rd59, %rd102, %rd57;
	ld.global.nc.f64 	%fd350, [%rd59+8];
	mul.rn.f64 	%fd88, %fd576, %fd576;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd59+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd59+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd59+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd59+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd59+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd578, %fd89, %fd576, %fd576;
	@%p44 bra 	$L__BB11_54;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd578, %fd89, %fd88, %fd361;

$L__BB11_54:
	and.b32  	%r104, %r194, 2;
	setp.eq.s32 	%p45, %r104, 0;
	@%p45 bra 	$L__BB11_56;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd578, %fd578, %fd363, %fd362;

$L__BB11_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r105, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd95;
	}
	and.b32  	%r107, %r106, 2147483647;
	setp.eq.s32 	%p46, %r107, 2146435072;
	setp.eq.s32 	%p47, %r105, 0;
	and.pred  	%p48, %p47, %p46;
	@%p48 bra 	$L__BB11_59;
	bra.uni 	$L__BB11_57;

$L__BB11_59:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd579, %fd95, %fd373;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB11_60;

$L__BB11_57:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd364;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd365, %r195;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd579, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p49, %fd372, 0d41E0000000000000;
	@%p49 bra 	$L__BB11_60;

	add.u64 	%rd85, %SP, 0;
	{ // callseq 121, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd579, [retval0+0];
	} // callseq 121
	ld.local.u32 	%r195, [%rd1];

$L__BB11_60:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r109, %r195, 1;
	shl.b32 	%r110, %r195, 3;
	and.b32  	%r111, %r110, 8;
	setp.eq.s32 	%p50, %r109, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	mul.wide.s32 	%rd61, %r111, 8;
	add.s64 	%rd63, %rd103, %rd61;
	ld.global.nc.f64 	%fd375, [%rd63+8];
	mul.rn.f64 	%fd100, %fd579, %fd579;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd63+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd63+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd63+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd63+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd63+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd581, %fd101, %fd579, %fd579;
	@%p50 bra 	$L__BB11_62;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd581, %fd101, %fd100, %fd386;

$L__BB11_62:
	and.b32  	%r112, %r195, 2;
	setp.eq.s32 	%p51, %r112, 0;
	@%p51 bra 	$L__BB11_64;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd581, %fd581, %fd388, %fd387;

$L__BB11_64:
	mul.rn.f64 	%fd389, %fd581, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd578, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd108;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p52, %r115, 2146435072;
	setp.eq.s32 	%p53, %r113, 0;
	and.pred  	%p54, %p53, %p52;
	@%p54 bra 	$L__BB11_67;
	bra.uni 	$L__BB11_65;

$L__BB11_67:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd582, %fd108, %fd400;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB11_68;

$L__BB11_65:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd391;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd392, %r196;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd582, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p55, %fd399, 0d41E0000000000000;
	@%p55 bra 	$L__BB11_68;

	add.u64 	%rd86, %SP, 0;
	{ // callseq 122, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd86;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd582, [retval0+0];
	} // callseq 122
	ld.local.u32 	%r196, [%rd1];

$L__BB11_68:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r117, %r196, 1;
	shl.b32 	%r118, %r196, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p56, %r117, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p56;
	mul.wide.s32 	%rd65, %r119, 8;
	add.s64 	%rd67, %rd104, %rd65;
	ld.global.nc.f64 	%fd402, [%rd67+8];
	mul.rn.f64 	%fd113, %fd582, %fd582;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd67+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd67+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd67+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd67+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd67+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd584, %fd114, %fd582, %fd582;
	@%p56 bra 	$L__BB11_70;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd584, %fd114, %fd113, %fd413;

$L__BB11_70:
	and.b32  	%r120, %r196, 2;
	setp.eq.s32 	%p57, %r120, 0;
	@%p57 bra 	$L__BB11_72;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd584, %fd584, %fd415, %fd414;

$L__BB11_72:
	mul.rn.f64 	%fd416, %fd584, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd121;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p58, %r123, 2146435072;
	setp.eq.s32 	%p59, %r121, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB11_75;
	bra.uni 	$L__BB11_73;

$L__BB11_75:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd585, %fd121, %fd426;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB11_76;

$L__BB11_73:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd417;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd418, %r197;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd585, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p61, %fd425, 0d41E0000000000000;
	@%p61 bra 	$L__BB11_76;

	add.u64 	%rd87, %SP, 0;
	{ // callseq 123, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd585, [retval0+0];
	} // callseq 123
	ld.local.u32 	%r197, [%rd1];

$L__BB11_76:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r125, %r197, 1;
	shl.b32 	%r126, %r197, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p62, %r125, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd105, %rd69;
	ld.global.nc.f64 	%fd428, [%rd71+8];
	mul.rn.f64 	%fd126, %fd585, %fd585;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd71+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd71+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd71+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd71+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd71+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd587, %fd127, %fd585, %fd585;
	@%p62 bra 	$L__BB11_78;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd587, %fd127, %fd126, %fd439;

$L__BB11_78:
	and.b32  	%r128, %r197, 2;
	setp.eq.s32 	%p63, %r128, 0;
	@%p63 bra 	$L__BB11_80;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd587, %fd587, %fd441, %fd440;

$L__BB11_80:
	mul.rn.f64 	%fd442, %fd587, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd445;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p64, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 124, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd590, [retval0+0];
	} // callseq 124
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p65, %r33, 0;
	and.pred  	%p1, %p65, %p64;
	not.pred 	%p66, %p1;
	@%p66 bra 	$L__BB11_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd590;
	}
	xor.b32  	%r130, %r129, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd590;
	}
	mov.b64 	%fd590, {%r131, %r130};

$L__BB11_82:
	setp.eq.f64 	%p67, %fd4, 0d0000000000000000;
	@%p67 bra 	$L__BB11_86;
	bra.uni 	$L__BB11_83;

$L__BB11_86:
	selp.b32 	%r132, %r33, 0, %p64;
	mov.u32 	%r133, 0;
	or.b32  	%r134, %r132, 2146435072;
	setp.lt.s32 	%p71, %r31, 0;
	selp.b32 	%r135, %r134, %r132, %p71;
	mov.b64 	%fd590, {%r133, %r135};
	bra.uni 	$L__BB11_87;

$L__BB11_83:
	setp.gt.s32 	%p68, %r33, -1;
	@%p68 bra 	$L__BB11_87;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p69, %fd449, 0d4000000000000000;
	@%p69 bra 	$L__BB11_87;

	mov.f64 	%fd590, 0dFFF8000000000000;

$L__BB11_87:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd451;
	}
	and.b32  	%r137, %r136, 2146435072;
	setp.ne.s32 	%p72, %r137, 2146435072;
	@%p72 bra 	$L__BB11_94;

	setp.gtu.f64 	%p73, %fd136, 0d7FF0000000000000;
	@%p73 bra 	$L__BB11_93;
	bra.uni 	$L__BB11_89;

$L__BB11_93:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd590, %fd4, %fd453;
	bra.uni 	$L__BB11_94;

$L__BB11_89:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd452;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p74, %r34, 2146435072;
	setp.eq.s32 	%p75, %r138, 0;
	and.pred  	%p76, %p74, %p75;
	@%p76 bra 	$L__BB11_92;
	bra.uni 	$L__BB11_90;

$L__BB11_92:
	setp.gt.f64 	%p83, %fd136, 0d3FF0000000000000;
	selp.b32 	%r145, 2146435072, 0, %p83;
	mov.u32 	%r146, 0;
	xor.b32  	%r147, %r145, 2146435072;
	setp.lt.s32 	%p84, %r31, 0;
	selp.b32 	%r148, %r147, %r145, %p84;
	setp.eq.f64 	%p85, %fd4, 0dBFF0000000000000;
	selp.b32 	%r149, 1072693248, %r148, %p85;
	mov.b64 	%fd590, {%r146, %r149};
	bra.uni 	$L__BB11_94;

$L__BB11_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd4;
	}
	and.b32  	%r140, %r33, 2147483647;
	setp.ne.s32 	%p77, %r140, 2146435072;
	setp.ne.s32 	%p78, %r139, 0;
	or.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB11_94;

	setp.gt.s32 	%p80, %r31, -1;
	selp.b32 	%r141, 2146435072, 0, %p80;
	mov.u32 	%r142, 0;
	setp.ne.s32 	%p81, %r34, 1071644672;
	and.pred  	%p82, %p81, %p1;
	or.b32  	%r143, %r141, -2147483648;
	selp.b32 	%r144, %r143, %r141, %p82;
	mov.b64 	%fd590, {%r142, %r144};

$L__BB11_94:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd590, 0d3FC999999999999A;
	setp.eq.f64 	%p86, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p86;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 125, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd593, [retval0+0];
	} // callseq 125
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd547;
	}
	setp.lt.s32 	%p87, %r35, 0;
	and.pred  	%p2, %p87, %p64;
	not.pred 	%p89, %p2;
	@%p89 bra 	$L__BB11_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd593;
	}
	xor.b32  	%r151, %r150, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd593;
	}
	mov.b64 	%fd593, {%r152, %r151};

$L__BB11_96:
	setp.eq.f64 	%p90, %fd2, 0d0000000000000000;
	@%p90 bra 	$L__BB11_100;
	bra.uni 	$L__BB11_97;

$L__BB11_100:
	selp.b32 	%r153, %r35, 0, %p64;
	mov.u32 	%r154, 0;
	or.b32  	%r155, %r153, 2146435072;
	setp.lt.s32 	%p94, %r31, 0;
	selp.b32 	%r156, %r155, %r153, %p94;
	mov.b64 	%fd593, {%r154, %r156};
	bra.uni 	$L__BB11_101;

$L__BB11_97:
	setp.gt.s32 	%p91, %r35, -1;
	@%p91 bra 	$L__BB11_101;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p92, %fd465, 0d4000000000000000;
	@%p92 bra 	$L__BB11_101;

	mov.f64 	%fd593, 0dFFF8000000000000;

$L__BB11_101:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd467;
	}
	and.b32  	%r158, %r157, 2146435072;
	setp.ne.s32 	%p95, %r158, 2146435072;
	@%p95 bra 	$L__BB11_108;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p96, %fd548, 0d7FF0000000000000;
	@%p96 bra 	$L__BB11_107;
	bra.uni 	$L__BB11_103;

$L__BB11_107:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd593, %fd2, %fd469;
	bra.uni 	$L__BB11_108;

$L__BB11_103:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd468;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p97, %r36, 2146435072;
	setp.eq.s32 	%p98, %r159, 0;
	and.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB11_106;
	bra.uni 	$L__BB11_104;

$L__BB11_106:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p106, %fd550, 0d3FF0000000000000;
	selp.b32 	%r166, 2146435072, 0, %p106;
	mov.u32 	%r167, 0;
	xor.b32  	%r168, %r166, 2146435072;
	setp.lt.s32 	%p107, %r31, 0;
	selp.b32 	%r169, %r168, %r166, %p107;
	setp.eq.f64 	%p108, %fd551, 0dBFF0000000000000;
	selp.b32 	%r170, 1072693248, %r169, %p108;
	mov.b64 	%fd593, {%r167, %r170};
	bra.uni 	$L__BB11_108;

$L__BB11_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd2;
	}
	and.b32  	%r161, %r35, 2147483647;
	setp.ne.s32 	%p100, %r161, 2146435072;
	setp.ne.s32 	%p101, %r160, 0;
	or.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB11_108;

	setp.gt.s32 	%p103, %r31, -1;
	selp.b32 	%r162, 2146435072, 0, %p103;
	mov.u32 	%r163, 0;
	setp.ne.s32 	%p104, %r36, 1071644672;
	and.pred  	%p105, %p104, %p2;
	or.b32  	%r164, %r162, -2147483648;
	selp.b32 	%r165, %r164, %r162, %p105;
	mov.b64 	%fd593, {%r163, %r165};

$L__BB11_108:
	mul.rn.f64 	%fd470, %fd593, 0d3FB999999999999A;
	setp.eq.f64 	%p109, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p109;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd159;
	}
	and.b32  	%r173, %r172, 2147483647;
	setp.eq.s32 	%p110, %r173, 2146435072;
	setp.eq.s32 	%p111, %r171, 0;
	and.pred  	%p3, %p111, %p110;
	@%p3 bra 	$L__BB11_111;
	bra.uni 	$L__BB11_109;

$L__BB11_111:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd594, %fd159, %fd487;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB11_112;

$L__BB11_109:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd478;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd479, %r198;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd594, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p112, %fd486, 0d41E0000000000000;
	@%p112 bra 	$L__BB11_112;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 126, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 126
	ld.local.u32 	%r198, [%rd1];

$L__BB11_112:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r175, %r198, 1;
	shl.b32 	%r176, %r198, 3;
	and.b32  	%r177, %r176, 8;
	setp.eq.s32 	%p113, %r175, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd73, %r177, 8;
	add.s64 	%rd75, %rd106, %rd73;
	ld.global.nc.f64 	%fd489, [%rd75+8];
	mul.rn.f64 	%fd164, %fd594, %fd594;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd75+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd75+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd75+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd75+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd75+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd596, %fd165, %fd594, %fd594;
	@%p113 bra 	$L__BB11_114;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd596, %fd165, %fd164, %fd500;

$L__BB11_114:
	and.b32  	%r178, %r198, 2;
	setp.eq.s32 	%p114, %r178, 0;
	@%p114 bra 	$L__BB11_116;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd596, %fd596, %fd502, %fd501;

$L__BB11_116:
	@%p3 bra 	$L__BB11_120;
	bra.uni 	$L__BB11_117;

$L__BB11_120:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd512;
	mov.u32 	%r200, 1;
	bra.uni 	$L__BB11_121;

$L__BB11_117:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd503;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd504, %r199;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p115, %fd511, 0d41E0000000000000;
	@%p115 bra 	$L__BB11_119;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 127, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 127
	ld.local.u32 	%r199, [%rd1];

$L__BB11_119:
	add.s32 	%r200, %r199, 1;

$L__BB11_121:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r180, %r200, 1;
	shl.b32 	%r181, %r200, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p116, %r180, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd77, %r182, 8;
	add.s64 	%rd79, %rd107, %rd77;
	ld.global.nc.f64 	%fd514, [%rd79+8];
	mul.rn.f64 	%fd176, %fd598, %fd598;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd79+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd79+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd79+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd79+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd79+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd600, %fd177, %fd598, %fd598;
	@%p116 bra 	$L__BB11_123;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd177, %fd176, %fd525;

$L__BB11_123:
	and.b32  	%r183, %r200, 2;
	setp.eq.s32 	%p117, %r183, 0;
	@%p117 bra 	$L__BB11_125;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd527, %fd526;

$L__BB11_125:
	mov.u32 	%r187, %tid.x;
	mov.u32 	%r186, %ntid.x;
	mov.u32 	%r185, %ctaid.x;
	mad.lo.s32 	%r184, %r185, %r186, %r187;
	mul.wide.s32 	%rd96, %r184, 8;
	ld.param.u64 	%rd95, [gcj02_to_wgs84_cuda_double_param_1];
	cvta.to.global.u64 	%rd94, %rd95;
	add.s64 	%rd93, %rd94, %rd96;
	ld.param.u64 	%rd92, [gcj02_to_wgs84_cuda_double_param_0];
	cvta.to.global.u64 	%rd91, %rd92;
	add.s64 	%rd90, %rd91, %rd96;
	mul.rn.f64 	%fd528, %fd596, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd596, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0dC15854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd600;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	st.global.f64 	[%rd90], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0dC1582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	st.global.f64 	[%rd93], %fd545;
	ret;

}
	// .globl	wgs84_to_gcj02_cuda_double
.visible .entry wgs84_to_gcj02_cuda_double(
	.param .u64 wgs84_to_gcj02_cuda_double_param_0,
	.param .u64 wgs84_to_gcj02_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot12[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<118>;
	.reg .b32 	%r<201>;
	.reg .f64 	%fd<601>;
	.reg .b64 	%rd<110>;


	mov.u64 	%SPL, __local_depot12;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [wgs84_to_gcj02_cuda_double_param_0];
	ld.param.u64 	%rd16, [wgs84_to_gcj02_cuda_double_param_1];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r45, %ntid.x;
	mov.u32 	%r46, %ctaid.x;
	mov.u32 	%r47, %tid.x;
	mad.lo.s32 	%r48, %r46, %r45, %r47;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r48, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd9;
	}
	and.b32  	%r51, %r50, 2147483647;
	setp.eq.s32 	%p4, %r51, 2146435072;
	setp.eq.s32 	%p5, %r49, 0;
	and.pred  	%p6, %p5, %p4;
	@%p6 bra 	$L__BB12_3;
	bra.uni 	$L__BB12_1;

$L__BB12_3:
	mov.f64 	%fd192, 0d0000000000000000;
	mul.rn.f64 	%fd558, %fd9, %fd192;
	mov.u32 	%r188, 0;
	bra.uni 	$L__BB12_4;

$L__BB12_1:
	mul.rn.f64 	%fd183, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r188, %fd183;
	st.local.u32 	[%rd1], %r188;
	cvt.rn.f64.s32 	%fd184, %r188;
	neg.f64 	%fd185, %fd184;
	mov.f64 	%fd186, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd187, %fd185, %fd186, %fd9;
	mov.f64 	%fd188, 0d3C91A62633145C00;
	fma.rn.f64 	%fd189, %fd185, %fd188, %fd187;
	mov.f64 	%fd190, 0d397B839A252049C0;
	fma.rn.f64 	%fd558, %fd185, %fd190, %fd189;
	abs.f64 	%fd191, %fd9;
	setp.ltu.f64 	%p7, %fd191, 0d41E0000000000000;
	@%p7 bra 	$L__BB12_4;

	add.u64 	%rd97, %SP, 0;
	{ // callseq 128, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd97;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd558, [retval0+0];
	} // callseq 128
	ld.local.u32 	%r188, [%rd1];

$L__BB12_4:
	and.b32  	%r53, %r188, 1;
	shl.b32 	%r54, %r188, 3;
	and.b32  	%r55, %r54, 8;
	setp.eq.s32 	%p8, %r53, 0;
	selp.f64 	%fd193, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p8;
	mul.wide.s32 	%rd33, %r55, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd194, [%rd35+8];
	mul.rn.f64 	%fd14, %fd558, %fd558;
	fma.rn.f64 	%fd195, %fd193, %fd14, %fd194;
	ld.global.nc.f64 	%fd196, [%rd35+16];
	fma.rn.f64 	%fd197, %fd195, %fd14, %fd196;
	ld.global.nc.f64 	%fd198, [%rd35+24];
	fma.rn.f64 	%fd199, %fd197, %fd14, %fd198;
	ld.global.nc.f64 	%fd200, [%rd35+32];
	fma.rn.f64 	%fd201, %fd199, %fd14, %fd200;
	ld.global.nc.f64 	%fd202, [%rd35+40];
	fma.rn.f64 	%fd203, %fd201, %fd14, %fd202;
	ld.global.nc.f64 	%fd204, [%rd35+48];
	fma.rn.f64 	%fd15, %fd203, %fd14, %fd204;
	fma.rn.f64 	%fd560, %fd15, %fd558, %fd558;
	@%p8 bra 	$L__BB12_6;

	mov.f64 	%fd205, 0d3FF0000000000000;
	fma.rn.f64 	%fd560, %fd15, %fd14, %fd205;

$L__BB12_6:
	and.b32  	%r56, %r188, 2;
	setp.eq.s32 	%p9, %r56, 0;
	@%p9 bra 	$L__BB12_8;

	mov.f64 	%fd206, 0d0000000000000000;
	mov.f64 	%fd207, 0dBFF0000000000000;
	fma.rn.f64 	%fd560, %fd560, %fd207, %fd206;

$L__BB12_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r57, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r58}, %fd21;
	}
	and.b32  	%r59, %r58, 2147483647;
	setp.eq.s32 	%p10, %r59, 2146435072;
	setp.eq.s32 	%p11, %r57, 0;
	and.pred  	%p12, %p11, %p10;
	@%p12 bra 	$L__BB12_11;
	bra.uni 	$L__BB12_9;

$L__BB12_11:
	mov.f64 	%fd217, 0d0000000000000000;
	mul.rn.f64 	%fd561, %fd21, %fd217;
	mov.u32 	%r189, 0;
	bra.uni 	$L__BB12_12;

$L__BB12_9:
	mul.rn.f64 	%fd208, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r189, %fd208;
	st.local.u32 	[%rd1], %r189;
	cvt.rn.f64.s32 	%fd209, %r189;
	neg.f64 	%fd210, %fd209;
	mov.f64 	%fd211, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd212, %fd210, %fd211, %fd21;
	mov.f64 	%fd213, 0d3C91A62633145C00;
	fma.rn.f64 	%fd214, %fd210, %fd213, %fd212;
	mov.f64 	%fd215, 0d397B839A252049C0;
	fma.rn.f64 	%fd561, %fd210, %fd215, %fd214;
	abs.f64 	%fd216, %fd21;
	setp.ltu.f64 	%p13, %fd216, 0d41E0000000000000;
	@%p13 bra 	$L__BB12_12;

	add.u64 	%rd98, %SP, 0;
	{ // callseq 129, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd98;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd561, [retval0+0];
	} // callseq 129
	ld.local.u32 	%r189, [%rd1];

$L__BB12_12:
	mov.u64 	%rd108, __cudart_sin_cos_coeffs;
	and.b32  	%r61, %r189, 1;
	shl.b32 	%r62, %r189, 3;
	and.b32  	%r63, %r62, 8;
	setp.eq.s32 	%p14, %r61, 0;
	selp.f64 	%fd218, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p14;
	mul.wide.s32 	%rd37, %r63, 8;
	add.s64 	%rd39, %rd108, %rd37;
	ld.global.nc.f64 	%fd219, [%rd39+8];
	mul.rn.f64 	%fd26, %fd561, %fd561;
	fma.rn.f64 	%fd220, %fd218, %fd26, %fd219;
	ld.global.nc.f64 	%fd221, [%rd39+16];
	fma.rn.f64 	%fd222, %fd220, %fd26, %fd221;
	ld.global.nc.f64 	%fd223, [%rd39+24];
	fma.rn.f64 	%fd224, %fd222, %fd26, %fd223;
	ld.global.nc.f64 	%fd225, [%rd39+32];
	fma.rn.f64 	%fd226, %fd224, %fd26, %fd225;
	ld.global.nc.f64 	%fd227, [%rd39+40];
	fma.rn.f64 	%fd228, %fd226, %fd26, %fd227;
	ld.global.nc.f64 	%fd229, [%rd39+48];
	fma.rn.f64 	%fd27, %fd228, %fd26, %fd229;
	fma.rn.f64 	%fd563, %fd27, %fd561, %fd561;
	@%p14 bra 	$L__BB12_14;

	mov.f64 	%fd230, 0d3FF0000000000000;
	fma.rn.f64 	%fd563, %fd27, %fd26, %fd230;

$L__BB12_14:
	and.b32  	%r64, %r189, 2;
	setp.eq.s32 	%p15, %r64, 0;
	@%p15 bra 	$L__BB12_16;

	mov.f64 	%fd231, 0d0000000000000000;
	mov.f64 	%fd232, 0dBFF0000000000000;
	fma.rn.f64 	%fd563, %fd563, %fd232, %fd231;

$L__BB12_16:
	mul.rn.f64 	%fd233, %fd563, 0d4034000000000000;
	mul.rn.f64 	%fd234, %fd560, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd234, %fd233;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r65}, %fd8;
	}
	and.b32  	%r66, %r65, 2147483647;
	setp.eq.s32 	%p16, %r66, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r67, %temp}, %fd8;
	}
	setp.eq.s32 	%p17, %r67, 0;
	and.pred  	%p18, %p17, %p16;
	@%p18 bra 	$L__BB12_19;
	bra.uni 	$L__BB12_17;

$L__BB12_19:
	mov.f64 	%fd244, 0d0000000000000000;
	mul.rn.f64 	%fd564, %fd8, %fd244;
	mov.u32 	%r190, 0;
	bra.uni 	$L__BB12_20;

$L__BB12_17:
	mul.rn.f64 	%fd235, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r190, %fd235;
	st.local.u32 	[%rd1], %r190;
	cvt.rn.f64.s32 	%fd236, %r190;
	neg.f64 	%fd237, %fd236;
	mov.f64 	%fd238, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd239, %fd237, %fd238, %fd8;
	mov.f64 	%fd240, 0d3C91A62633145C00;
	fma.rn.f64 	%fd241, %fd237, %fd240, %fd239;
	mov.f64 	%fd242, 0d397B839A252049C0;
	fma.rn.f64 	%fd564, %fd237, %fd242, %fd241;
	abs.f64 	%fd243, %fd8;
	setp.ltu.f64 	%p19, %fd243, 0d41E0000000000000;
	@%p19 bra 	$L__BB12_20;

	add.u64 	%rd80, %SP, 0;
	{ // callseq 130, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd80;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd564, [retval0+0];
	} // callseq 130
	ld.local.u32 	%r190, [%rd1];

$L__BB12_20:
	mov.u64 	%rd109, __cudart_sin_cos_coeffs;
	and.b32  	%r69, %r190, 1;
	shl.b32 	%r70, %r190, 3;
	and.b32  	%r71, %r70, 8;
	setp.eq.s32 	%p20, %r69, 0;
	selp.f64 	%fd245, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p20;
	mul.wide.s32 	%rd41, %r71, 8;
	add.s64 	%rd43, %rd109, %rd41;
	ld.global.nc.f64 	%fd246, [%rd43+8];
	mul.rn.f64 	%fd38, %fd564, %fd564;
	fma.rn.f64 	%fd247, %fd245, %fd38, %fd246;
	ld.global.nc.f64 	%fd248, [%rd43+16];
	fma.rn.f64 	%fd249, %fd247, %fd38, %fd248;
	ld.global.nc.f64 	%fd250, [%rd43+24];
	fma.rn.f64 	%fd251, %fd249, %fd38, %fd250;
	ld.global.nc.f64 	%fd252, [%rd43+32];
	fma.rn.f64 	%fd253, %fd251, %fd38, %fd252;
	ld.global.nc.f64 	%fd254, [%rd43+40];
	fma.rn.f64 	%fd255, %fd253, %fd38, %fd254;
	ld.global.nc.f64 	%fd256, [%rd43+48];
	fma.rn.f64 	%fd39, %fd255, %fd38, %fd256;
	fma.rn.f64 	%fd566, %fd39, %fd564, %fd564;
	@%p20 bra 	$L__BB12_22;

	mov.f64 	%fd257, 0d3FF0000000000000;
	fma.rn.f64 	%fd566, %fd39, %fd38, %fd257;

$L__BB12_22:
	and.b32  	%r72, %r190, 2;
	setp.eq.s32 	%p21, %r72, 0;
	@%p21 bra 	$L__BB12_24;

	mov.f64 	%fd258, 0d0000000000000000;
	mov.f64 	%fd259, 0dBFF0000000000000;
	fma.rn.f64 	%fd566, %fd566, %fd259, %fd258;

$L__BB12_24:
	add.rn.f64 	%fd557, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd556, %fd557, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd556, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r73, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r74}, %fd45;
	}
	and.b32  	%r75, %r74, 2147483647;
	setp.eq.s32 	%p22, %r75, 2146435072;
	setp.eq.s32 	%p23, %r73, 0;
	and.pred  	%p24, %p23, %p22;
	@%p24 bra 	$L__BB12_27;
	bra.uni 	$L__BB12_25;

$L__BB12_27:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd567, %fd45, %fd269;
	mov.u32 	%r191, 0;
	bra.uni 	$L__BB12_28;

$L__BB12_25:
	mul.rn.f64 	%fd260, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r191, %fd260;
	st.local.u32 	[%rd1], %r191;
	cvt.rn.f64.s32 	%fd261, %r191;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd45;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd567, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd45;
	setp.ltu.f64 	%p25, %fd268, 0d41E0000000000000;
	@%p25 bra 	$L__BB12_28;

	add.u64 	%rd81, %SP, 0;
	{ // callseq 131, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd81;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd567, [retval0+0];
	} // callseq 131
	ld.local.u32 	%r191, [%rd1];

$L__BB12_28:
	mov.u64 	%rd99, __cudart_sin_cos_coeffs;
	and.b32  	%r77, %r191, 1;
	shl.b32 	%r78, %r191, 3;
	and.b32  	%r79, %r78, 8;
	setp.eq.s32 	%p26, %r77, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p26;
	mul.wide.s32 	%rd45, %r79, 8;
	add.s64 	%rd47, %rd99, %rd45;
	ld.global.nc.f64 	%fd271, [%rd47+8];
	mul.rn.f64 	%fd50, %fd567, %fd567;
	fma.rn.f64 	%fd272, %fd270, %fd50, %fd271;
	ld.global.nc.f64 	%fd273, [%rd47+16];
	fma.rn.f64 	%fd274, %fd272, %fd50, %fd273;
	ld.global.nc.f64 	%fd275, [%rd47+24];
	fma.rn.f64 	%fd276, %fd274, %fd50, %fd275;
	ld.global.nc.f64 	%fd277, [%rd47+32];
	fma.rn.f64 	%fd278, %fd276, %fd50, %fd277;
	ld.global.nc.f64 	%fd279, [%rd47+40];
	fma.rn.f64 	%fd280, %fd278, %fd50, %fd279;
	ld.global.nc.f64 	%fd281, [%rd47+48];
	fma.rn.f64 	%fd51, %fd280, %fd50, %fd281;
	fma.rn.f64 	%fd569, %fd51, %fd567, %fd567;
	@%p26 bra 	$L__BB12_30;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd569, %fd51, %fd50, %fd282;

$L__BB12_30:
	and.b32  	%r80, %r191, 2;
	setp.eq.s32 	%p27, %r80, 0;
	@%p27 bra 	$L__BB12_32;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd569, %fd569, %fd284, %fd283;

$L__BB12_32:
	add.rn.f64 	%fd553, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd552, %fd553, 0d400921FB54442D18;
	mul.rn.f64 	%fd285, %fd569, 0d4044000000000000;
	mul.rn.f64 	%fd286, %fd566, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd286, %fd285;
	div.rn.f64 	%fd58, %fd552, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r81, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r82}, %fd58;
	}
	and.b32  	%r83, %r82, 2147483647;
	setp.eq.s32 	%p28, %r83, 2146435072;
	setp.eq.s32 	%p29, %r81, 0;
	and.pred  	%p30, %p29, %p28;
	@%p30 bra 	$L__BB12_35;
	bra.uni 	$L__BB12_33;

$L__BB12_35:
	mov.f64 	%fd296, 0d0000000000000000;
	mul.rn.f64 	%fd570, %fd58, %fd296;
	mov.u32 	%r192, 0;
	bra.uni 	$L__BB12_36;

$L__BB12_33:
	mul.rn.f64 	%fd287, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r192, %fd287;
	st.local.u32 	[%rd1], %r192;
	cvt.rn.f64.s32 	%fd288, %r192;
	neg.f64 	%fd289, %fd288;
	mov.f64 	%fd290, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd291, %fd289, %fd290, %fd58;
	mov.f64 	%fd292, 0d3C91A62633145C00;
	fma.rn.f64 	%fd293, %fd289, %fd292, %fd291;
	mov.f64 	%fd294, 0d397B839A252049C0;
	fma.rn.f64 	%fd570, %fd289, %fd294, %fd293;
	abs.f64 	%fd295, %fd58;
	setp.ltu.f64 	%p31, %fd295, 0d41E0000000000000;
	@%p31 bra 	$L__BB12_36;

	add.u64 	%rd82, %SP, 0;
	{ // callseq 132, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd570, [retval0+0];
	} // callseq 132
	ld.local.u32 	%r192, [%rd1];

$L__BB12_36:
	mov.u64 	%rd100, __cudart_sin_cos_coeffs;
	and.b32  	%r85, %r192, 1;
	shl.b32 	%r86, %r192, 3;
	and.b32  	%r87, %r86, 8;
	setp.eq.s32 	%p32, %r85, 0;
	selp.f64 	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p32;
	mul.wide.s32 	%rd49, %r87, 8;
	add.s64 	%rd51, %rd100, %rd49;
	ld.global.nc.f64 	%fd298, [%rd51+8];
	mul.rn.f64 	%fd63, %fd570, %fd570;
	fma.rn.f64 	%fd299, %fd297, %fd63, %fd298;
	ld.global.nc.f64 	%fd300, [%rd51+16];
	fma.rn.f64 	%fd301, %fd299, %fd63, %fd300;
	ld.global.nc.f64 	%fd302, [%rd51+24];
	fma.rn.f64 	%fd303, %fd301, %fd63, %fd302;
	ld.global.nc.f64 	%fd304, [%rd51+32];
	fma.rn.f64 	%fd305, %fd303, %fd63, %fd304;
	ld.global.nc.f64 	%fd306, [%rd51+40];
	fma.rn.f64 	%fd307, %fd305, %fd63, %fd306;
	ld.global.nc.f64 	%fd308, [%rd51+48];
	fma.rn.f64 	%fd64, %fd307, %fd63, %fd308;
	fma.rn.f64 	%fd572, %fd64, %fd570, %fd570;
	@%p32 bra 	$L__BB12_38;

	mov.f64 	%fd309, 0d3FF0000000000000;
	fma.rn.f64 	%fd572, %fd64, %fd63, %fd309;

$L__BB12_38:
	and.b32  	%r88, %r192, 2;
	setp.eq.s32 	%p33, %r88, 0;
	@%p33 bra 	$L__BB12_40;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd572, %fd572, %fd311, %fd310;

$L__BB12_40:
	add.rn.f64 	%fd555, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd554, %fd555, 0d400921FB54442D18;
	mul.rn.f64 	%fd312, %fd572, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd312;
	div.rn.f64 	%fd71, %fd554, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r89, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd71;
	}
	and.b32  	%r91, %r90, 2147483647;
	setp.eq.s32 	%p34, %r91, 2146435072;
	setp.eq.s32 	%p35, %r89, 0;
	and.pred  	%p36, %p35, %p34;
	@%p36 bra 	$L__BB12_43;
	bra.uni 	$L__BB12_41;

$L__BB12_43:
	mov.f64 	%fd322, 0d0000000000000000;
	mul.rn.f64 	%fd573, %fd71, %fd322;
	mov.u32 	%r193, 0;
	bra.uni 	$L__BB12_44;

$L__BB12_41:
	mul.rn.f64 	%fd313, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r193, %fd313;
	st.local.u32 	[%rd1], %r193;
	cvt.rn.f64.s32 	%fd314, %r193;
	neg.f64 	%fd315, %fd314;
	mov.f64 	%fd316, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd317, %fd315, %fd316, %fd71;
	mov.f64 	%fd318, 0d3C91A62633145C00;
	fma.rn.f64 	%fd319, %fd315, %fd318, %fd317;
	mov.f64 	%fd320, 0d397B839A252049C0;
	fma.rn.f64 	%fd573, %fd315, %fd320, %fd319;
	abs.f64 	%fd321, %fd71;
	setp.ltu.f64 	%p37, %fd321, 0d41E0000000000000;
	@%p37 bra 	$L__BB12_44;

	add.u64 	%rd83, %SP, 0;
	{ // callseq 133, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd83;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd573, [retval0+0];
	} // callseq 133
	ld.local.u32 	%r193, [%rd1];

$L__BB12_44:
	mov.u64 	%rd101, __cudart_sin_cos_coeffs;
	and.b32  	%r93, %r193, 1;
	shl.b32 	%r94, %r193, 3;
	and.b32  	%r95, %r94, 8;
	setp.eq.s32 	%p38, %r93, 0;
	selp.f64 	%fd323, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p38;
	mul.wide.s32 	%rd53, %r95, 8;
	add.s64 	%rd55, %rd101, %rd53;
	ld.global.nc.f64 	%fd324, [%rd55+8];
	mul.rn.f64 	%fd76, %fd573, %fd573;
	fma.rn.f64 	%fd325, %fd323, %fd76, %fd324;
	ld.global.nc.f64 	%fd326, [%rd55+16];
	fma.rn.f64 	%fd327, %fd325, %fd76, %fd326;
	ld.global.nc.f64 	%fd328, [%rd55+24];
	fma.rn.f64 	%fd329, %fd327, %fd76, %fd328;
	ld.global.nc.f64 	%fd330, [%rd55+32];
	fma.rn.f64 	%fd331, %fd329, %fd76, %fd330;
	ld.global.nc.f64 	%fd332, [%rd55+40];
	fma.rn.f64 	%fd333, %fd331, %fd76, %fd332;
	ld.global.nc.f64 	%fd334, [%rd55+48];
	fma.rn.f64 	%fd77, %fd333, %fd76, %fd334;
	fma.rn.f64 	%fd575, %fd77, %fd573, %fd573;
	@%p38 bra 	$L__BB12_46;

	mov.f64 	%fd335, 0d3FF0000000000000;
	fma.rn.f64 	%fd575, %fd77, %fd76, %fd335;

$L__BB12_46:
	and.b32  	%r96, %r193, 2;
	setp.eq.s32 	%p39, %r96, 0;
	@%p39 bra 	$L__BB12_48;

	mov.f64 	%fd336, 0d0000000000000000;
	mov.f64 	%fd337, 0dBFF0000000000000;
	fma.rn.f64 	%fd575, %fd575, %fd337, %fd336;

$L__BB12_48:
	mul.rn.f64 	%fd338, %fd575, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd338;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd7;
	}
	and.b32  	%r98, %r97, 2147483647;
	setp.eq.s32 	%p40, %r98, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd7;
	}
	setp.eq.s32 	%p41, %r99, 0;
	and.pred  	%p42, %p41, %p40;
	@%p42 bra 	$L__BB12_51;
	bra.uni 	$L__BB12_49;

$L__BB12_51:
	mov.f64 	%fd348, 0d0000000000000000;
	mul.rn.f64 	%fd576, %fd7, %fd348;
	mov.u32 	%r194, 0;
	bra.uni 	$L__BB12_52;

$L__BB12_49:
	mul.rn.f64 	%fd339, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r194, %fd339;
	st.local.u32 	[%rd1], %r194;
	cvt.rn.f64.s32 	%fd340, %r194;
	neg.f64 	%fd341, %fd340;
	mov.f64 	%fd342, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd343, %fd341, %fd342, %fd7;
	mov.f64 	%fd344, 0d3C91A62633145C00;
	fma.rn.f64 	%fd345, %fd341, %fd344, %fd343;
	mov.f64 	%fd346, 0d397B839A252049C0;
	fma.rn.f64 	%fd576, %fd341, %fd346, %fd345;
	abs.f64 	%fd347, %fd7;
	setp.ltu.f64 	%p43, %fd347, 0d41E0000000000000;
	@%p43 bra 	$L__BB12_52;

	add.u64 	%rd84, %SP, 0;
	{ // callseq 134, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd576, [retval0+0];
	} // callseq 134
	ld.local.u32 	%r194, [%rd1];

$L__BB12_52:
	mov.u64 	%rd102, __cudart_sin_cos_coeffs;
	and.b32  	%r101, %r194, 1;
	shl.b32 	%r102, %r194, 3;
	and.b32  	%r103, %r102, 8;
	setp.eq.s32 	%p44, %r101, 0;
	selp.f64 	%fd349, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p44;
	mul.wide.s32 	%rd57, %r103, 8;
	add.s64 	%rd59, %rd102, %rd57;
	ld.global.nc.f64 	%fd350, [%rd59+8];
	mul.rn.f64 	%fd88, %fd576, %fd576;
	fma.rn.f64 	%fd351, %fd349, %fd88, %fd350;
	ld.global.nc.f64 	%fd352, [%rd59+16];
	fma.rn.f64 	%fd353, %fd351, %fd88, %fd352;
	ld.global.nc.f64 	%fd354, [%rd59+24];
	fma.rn.f64 	%fd355, %fd353, %fd88, %fd354;
	ld.global.nc.f64 	%fd356, [%rd59+32];
	fma.rn.f64 	%fd357, %fd355, %fd88, %fd356;
	ld.global.nc.f64 	%fd358, [%rd59+40];
	fma.rn.f64 	%fd359, %fd357, %fd88, %fd358;
	ld.global.nc.f64 	%fd360, [%rd59+48];
	fma.rn.f64 	%fd89, %fd359, %fd88, %fd360;
	fma.rn.f64 	%fd578, %fd89, %fd576, %fd576;
	@%p44 bra 	$L__BB12_54;

	mov.f64 	%fd361, 0d3FF0000000000000;
	fma.rn.f64 	%fd578, %fd89, %fd88, %fd361;

$L__BB12_54:
	and.b32  	%r104, %r194, 2;
	setp.eq.s32 	%p45, %r104, 0;
	@%p45 bra 	$L__BB12_56;

	mov.f64 	%fd362, 0d0000000000000000;
	mov.f64 	%fd363, 0dBFF0000000000000;
	fma.rn.f64 	%fd578, %fd578, %fd363, %fd362;

$L__BB12_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r105, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd95;
	}
	and.b32  	%r107, %r106, 2147483647;
	setp.eq.s32 	%p46, %r107, 2146435072;
	setp.eq.s32 	%p47, %r105, 0;
	and.pred  	%p48, %p47, %p46;
	@%p48 bra 	$L__BB12_59;
	bra.uni 	$L__BB12_57;

$L__BB12_59:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd579, %fd95, %fd373;
	mov.u32 	%r195, 0;
	bra.uni 	$L__BB12_60;

$L__BB12_57:
	mul.rn.f64 	%fd364, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r195, %fd364;
	st.local.u32 	[%rd1], %r195;
	cvt.rn.f64.s32 	%fd365, %r195;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd95;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd579, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd95;
	setp.ltu.f64 	%p49, %fd372, 0d41E0000000000000;
	@%p49 bra 	$L__BB12_60;

	add.u64 	%rd85, %SP, 0;
	{ // callseq 135, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd85;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd579, [retval0+0];
	} // callseq 135
	ld.local.u32 	%r195, [%rd1];

$L__BB12_60:
	mov.u64 	%rd103, __cudart_sin_cos_coeffs;
	and.b32  	%r109, %r195, 1;
	shl.b32 	%r110, %r195, 3;
	and.b32  	%r111, %r110, 8;
	setp.eq.s32 	%p50, %r109, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p50;
	mul.wide.s32 	%rd61, %r111, 8;
	add.s64 	%rd63, %rd103, %rd61;
	ld.global.nc.f64 	%fd375, [%rd63+8];
	mul.rn.f64 	%fd100, %fd579, %fd579;
	fma.rn.f64 	%fd376, %fd374, %fd100, %fd375;
	ld.global.nc.f64 	%fd377, [%rd63+16];
	fma.rn.f64 	%fd378, %fd376, %fd100, %fd377;
	ld.global.nc.f64 	%fd379, [%rd63+24];
	fma.rn.f64 	%fd380, %fd378, %fd100, %fd379;
	ld.global.nc.f64 	%fd381, [%rd63+32];
	fma.rn.f64 	%fd382, %fd380, %fd100, %fd381;
	ld.global.nc.f64 	%fd383, [%rd63+40];
	fma.rn.f64 	%fd384, %fd382, %fd100, %fd383;
	ld.global.nc.f64 	%fd385, [%rd63+48];
	fma.rn.f64 	%fd101, %fd384, %fd100, %fd385;
	fma.rn.f64 	%fd581, %fd101, %fd579, %fd579;
	@%p50 bra 	$L__BB12_62;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd581, %fd101, %fd100, %fd386;

$L__BB12_62:
	and.b32  	%r112, %r195, 2;
	setp.eq.s32 	%p51, %r112, 0;
	@%p51 bra 	$L__BB12_64;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd581, %fd581, %fd388, %fd387;

$L__BB12_64:
	mul.rn.f64 	%fd389, %fd581, 0d4044000000000000;
	mul.rn.f64 	%fd390, %fd578, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd390, %fd389;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd108;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p52, %r115, 2146435072;
	setp.eq.s32 	%p53, %r113, 0;
	and.pred  	%p54, %p53, %p52;
	@%p54 bra 	$L__BB12_67;
	bra.uni 	$L__BB12_65;

$L__BB12_67:
	mov.f64 	%fd400, 0d0000000000000000;
	mul.rn.f64 	%fd582, %fd108, %fd400;
	mov.u32 	%r196, 0;
	bra.uni 	$L__BB12_68;

$L__BB12_65:
	mul.rn.f64 	%fd391, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r196, %fd391;
	st.local.u32 	[%rd1], %r196;
	cvt.rn.f64.s32 	%fd392, %r196;
	neg.f64 	%fd393, %fd392;
	mov.f64 	%fd394, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd395, %fd393, %fd394, %fd108;
	mov.f64 	%fd396, 0d3C91A62633145C00;
	fma.rn.f64 	%fd397, %fd393, %fd396, %fd395;
	mov.f64 	%fd398, 0d397B839A252049C0;
	fma.rn.f64 	%fd582, %fd393, %fd398, %fd397;
	abs.f64 	%fd399, %fd108;
	setp.ltu.f64 	%p55, %fd399, 0d41E0000000000000;
	@%p55 bra 	$L__BB12_68;

	add.u64 	%rd86, %SP, 0;
	{ // callseq 136, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd86;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd582, [retval0+0];
	} // callseq 136
	ld.local.u32 	%r196, [%rd1];

$L__BB12_68:
	mov.u64 	%rd104, __cudart_sin_cos_coeffs;
	and.b32  	%r117, %r196, 1;
	shl.b32 	%r118, %r196, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p56, %r117, 0;
	selp.f64 	%fd401, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p56;
	mul.wide.s32 	%rd65, %r119, 8;
	add.s64 	%rd67, %rd104, %rd65;
	ld.global.nc.f64 	%fd402, [%rd67+8];
	mul.rn.f64 	%fd113, %fd582, %fd582;
	fma.rn.f64 	%fd403, %fd401, %fd113, %fd402;
	ld.global.nc.f64 	%fd404, [%rd67+16];
	fma.rn.f64 	%fd405, %fd403, %fd113, %fd404;
	ld.global.nc.f64 	%fd406, [%rd67+24];
	fma.rn.f64 	%fd407, %fd405, %fd113, %fd406;
	ld.global.nc.f64 	%fd408, [%rd67+32];
	fma.rn.f64 	%fd409, %fd407, %fd113, %fd408;
	ld.global.nc.f64 	%fd410, [%rd67+40];
	fma.rn.f64 	%fd411, %fd409, %fd113, %fd410;
	ld.global.nc.f64 	%fd412, [%rd67+48];
	fma.rn.f64 	%fd114, %fd411, %fd113, %fd412;
	fma.rn.f64 	%fd584, %fd114, %fd582, %fd582;
	@%p56 bra 	$L__BB12_70;

	mov.f64 	%fd413, 0d3FF0000000000000;
	fma.rn.f64 	%fd584, %fd114, %fd113, %fd413;

$L__BB12_70:
	and.b32  	%r120, %r196, 2;
	setp.eq.s32 	%p57, %r120, 0;
	@%p57 bra 	$L__BB12_72;

	mov.f64 	%fd414, 0d0000000000000000;
	mov.f64 	%fd415, 0dBFF0000000000000;
	fma.rn.f64 	%fd584, %fd584, %fd415, %fd414;

$L__BB12_72:
	mul.rn.f64 	%fd416, %fd584, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd416;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd121;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p58, %r123, 2146435072;
	setp.eq.s32 	%p59, %r121, 0;
	and.pred  	%p60, %p59, %p58;
	@%p60 bra 	$L__BB12_75;
	bra.uni 	$L__BB12_73;

$L__BB12_75:
	mov.f64 	%fd426, 0d0000000000000000;
	mul.rn.f64 	%fd585, %fd121, %fd426;
	mov.u32 	%r197, 0;
	bra.uni 	$L__BB12_76;

$L__BB12_73:
	mul.rn.f64 	%fd417, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r197, %fd417;
	st.local.u32 	[%rd1], %r197;
	cvt.rn.f64.s32 	%fd418, %r197;
	neg.f64 	%fd419, %fd418;
	mov.f64 	%fd420, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd421, %fd419, %fd420, %fd121;
	mov.f64 	%fd422, 0d3C91A62633145C00;
	fma.rn.f64 	%fd423, %fd419, %fd422, %fd421;
	mov.f64 	%fd424, 0d397B839A252049C0;
	fma.rn.f64 	%fd585, %fd419, %fd424, %fd423;
	abs.f64 	%fd425, %fd121;
	setp.ltu.f64 	%p61, %fd425, 0d41E0000000000000;
	@%p61 bra 	$L__BB12_76;

	add.u64 	%rd87, %SP, 0;
	{ // callseq 137, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd87;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd585, [retval0+0];
	} // callseq 137
	ld.local.u32 	%r197, [%rd1];

$L__BB12_76:
	mov.u64 	%rd105, __cudart_sin_cos_coeffs;
	and.b32  	%r125, %r197, 1;
	shl.b32 	%r126, %r197, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p62, %r125, 0;
	selp.f64 	%fd427, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p62;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd105, %rd69;
	ld.global.nc.f64 	%fd428, [%rd71+8];
	mul.rn.f64 	%fd126, %fd585, %fd585;
	fma.rn.f64 	%fd429, %fd427, %fd126, %fd428;
	ld.global.nc.f64 	%fd430, [%rd71+16];
	fma.rn.f64 	%fd431, %fd429, %fd126, %fd430;
	ld.global.nc.f64 	%fd432, [%rd71+24];
	fma.rn.f64 	%fd433, %fd431, %fd126, %fd432;
	ld.global.nc.f64 	%fd434, [%rd71+32];
	fma.rn.f64 	%fd435, %fd433, %fd126, %fd434;
	ld.global.nc.f64 	%fd436, [%rd71+40];
	fma.rn.f64 	%fd437, %fd435, %fd126, %fd436;
	ld.global.nc.f64 	%fd438, [%rd71+48];
	fma.rn.f64 	%fd127, %fd437, %fd126, %fd438;
	fma.rn.f64 	%fd587, %fd127, %fd585, %fd585;
	@%p62 bra 	$L__BB12_78;

	mov.f64 	%fd439, 0d3FF0000000000000;
	fma.rn.f64 	%fd587, %fd127, %fd126, %fd439;

$L__BB12_78:
	and.b32  	%r128, %r197, 2;
	setp.eq.s32 	%p63, %r128, 0;
	@%p63 bra 	$L__BB12_80;

	mov.f64 	%fd440, 0d0000000000000000;
	mov.f64 	%fd441, 0dBFF0000000000000;
	fma.rn.f64 	%fd587, %fd587, %fd441, %fd440;

$L__BB12_80:
	mul.rn.f64 	%fd442, %fd587, 0d4072C00000000000;
	add.rn.f64 	%fd443, %fd120, %fd442;
	add.rn.f64 	%fd133, %fd33, %fd443;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd444, %fd2, %fd2;
	mov.f64 	%fd445, 0d4000000000000000;
	add.rn.f64 	%fd446, %fd444, 0dC059000000000000;
	mul.rn.f64 	%fd447, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd446, %fd447;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd445;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p64, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 138, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd590, [retval0+0];
	} // callseq 138
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p65, %r33, 0;
	and.pred  	%p1, %p65, %p64;
	not.pred 	%p66, %p1;
	@%p66 bra 	$L__BB12_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd590;
	}
	xor.b32  	%r130, %r129, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd590;
	}
	mov.b64 	%fd590, {%r131, %r130};

$L__BB12_82:
	setp.eq.f64 	%p67, %fd4, 0d0000000000000000;
	@%p67 bra 	$L__BB12_86;
	bra.uni 	$L__BB12_83;

$L__BB12_86:
	selp.b32 	%r132, %r33, 0, %p64;
	mov.u32 	%r133, 0;
	or.b32  	%r134, %r132, 2146435072;
	setp.lt.s32 	%p71, %r31, 0;
	selp.b32 	%r135, %r134, %r132, %p71;
	mov.b64 	%fd590, {%r133, %r135};
	bra.uni 	$L__BB12_87;

$L__BB12_83:
	setp.gt.s32 	%p68, %r33, -1;
	@%p68 bra 	$L__BB12_87;

	mov.f64 	%fd448, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd449, %fd448;
	setp.eq.f64 	%p69, %fd449, 0d4000000000000000;
	@%p69 bra 	$L__BB12_87;

	mov.f64 	%fd590, 0dFFF8000000000000;

$L__BB12_87:
	add.rn.f64 	%fd451, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r136}, %fd451;
	}
	and.b32  	%r137, %r136, 2146435072;
	setp.ne.s32 	%p72, %r137, 2146435072;
	@%p72 bra 	$L__BB12_94;

	setp.gtu.f64 	%p73, %fd136, 0d7FF0000000000000;
	@%p73 bra 	$L__BB12_93;
	bra.uni 	$L__BB12_89;

$L__BB12_93:
	mov.f64 	%fd453, 0d4000000000000000;
	add.rn.f64 	%fd590, %fd4, %fd453;
	bra.uni 	$L__BB12_94;

$L__BB12_89:
	mov.f64 	%fd452, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r138, %temp}, %fd452;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p74, %r34, 2146435072;
	setp.eq.s32 	%p75, %r138, 0;
	and.pred  	%p76, %p74, %p75;
	@%p76 bra 	$L__BB12_92;
	bra.uni 	$L__BB12_90;

$L__BB12_92:
	setp.gt.f64 	%p83, %fd136, 0d3FF0000000000000;
	selp.b32 	%r145, 2146435072, 0, %p83;
	mov.u32 	%r146, 0;
	xor.b32  	%r147, %r145, 2146435072;
	setp.lt.s32 	%p84, %r31, 0;
	selp.b32 	%r148, %r147, %r145, %p84;
	setp.eq.f64 	%p85, %fd4, 0dBFF0000000000000;
	selp.b32 	%r149, 1072693248, %r148, %p85;
	mov.b64 	%fd590, {%r146, %r149};
	bra.uni 	$L__BB12_94;

$L__BB12_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd4;
	}
	and.b32  	%r140, %r33, 2147483647;
	setp.ne.s32 	%p77, %r140, 2146435072;
	setp.ne.s32 	%p78, %r139, 0;
	or.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB12_94;

	setp.gt.s32 	%p80, %r31, -1;
	selp.b32 	%r141, 2146435072, 0, %p80;
	mov.u32 	%r142, 0;
	setp.ne.s32 	%p81, %r34, 1071644672;
	and.pred  	%p82, %p81, %p1;
	or.b32  	%r143, %r141, -2147483648;
	selp.b32 	%r144, %r143, %r141, %p82;
	mov.b64 	%fd590, {%r142, %r144};

$L__BB12_94:
	add.rn.f64 	%fd547, %fd1, 0dC05A400000000000;
	abs.f64 	%fd546, %fd547;
	mul.rn.f64 	%fd454, %fd590, 0d3FC999999999999A;
	setp.eq.f64 	%p86, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd455, 0d3FC999999999999A, %fd454, %p86;
	add.rn.f64 	%fd456, %fd135, %fd455;
	mul.rn.f64 	%fd457, %fd547, %fd4;
	mul.rn.f64 	%fd146, %fd457, 0d3FB999999999999A;
	add.rn.f64 	%fd458, %fd146, %fd456;
	mul.rn.f64 	%fd459, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd460, %fd459, %fd458;
	mul.rn.f64 	%fd461, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd461, %fd460;
	add.rn.f64 	%fd462, %fd4, %fd4;
	add.rn.f64 	%fd463, %fd547, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd463, %fd462;
	{ // callseq 139, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd546;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd593, [retval0+0];
	} // callseq 139
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd547;
	}
	setp.lt.s32 	%p87, %r35, 0;
	and.pred  	%p2, %p87, %p64;
	not.pred 	%p89, %p2;
	@%p89 bra 	$L__BB12_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r150}, %fd593;
	}
	xor.b32  	%r151, %r150, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd593;
	}
	mov.b64 	%fd593, {%r152, %r151};

$L__BB12_96:
	setp.eq.f64 	%p90, %fd2, 0d0000000000000000;
	@%p90 bra 	$L__BB12_100;
	bra.uni 	$L__BB12_97;

$L__BB12_100:
	selp.b32 	%r153, %r35, 0, %p64;
	mov.u32 	%r154, 0;
	or.b32  	%r155, %r153, 2146435072;
	setp.lt.s32 	%p94, %r31, 0;
	selp.b32 	%r156, %r155, %r153, %p94;
	mov.b64 	%fd593, {%r154, %r156};
	bra.uni 	$L__BB12_101;

$L__BB12_97:
	setp.gt.s32 	%p91, %r35, -1;
	@%p91 bra 	$L__BB12_101;

	mov.f64 	%fd464, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd465, %fd464;
	setp.eq.f64 	%p92, %fd465, 0d4000000000000000;
	@%p92 bra 	$L__BB12_101;

	mov.f64 	%fd593, 0dFFF8000000000000;

$L__BB12_101:
	add.rn.f64 	%fd467, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r157}, %fd467;
	}
	and.b32  	%r158, %r157, 2146435072;
	setp.ne.s32 	%p95, %r158, 2146435072;
	@%p95 bra 	$L__BB12_108;

	add.rn.f64 	%fd549, %fd1, 0dC05A400000000000;
	abs.f64 	%fd548, %fd549;
	setp.gtu.f64 	%p96, %fd548, 0d7FF0000000000000;
	@%p96 bra 	$L__BB12_107;
	bra.uni 	$L__BB12_103;

$L__BB12_107:
	mov.f64 	%fd469, 0d4000000000000000;
	add.rn.f64 	%fd593, %fd2, %fd469;
	bra.uni 	$L__BB12_108;

$L__BB12_103:
	mov.f64 	%fd468, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd468;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p97, %r36, 2146435072;
	setp.eq.s32 	%p98, %r159, 0;
	and.pred  	%p99, %p97, %p98;
	@%p99 bra 	$L__BB12_106;
	bra.uni 	$L__BB12_104;

$L__BB12_106:
	add.rn.f64 	%fd551, %fd1, 0dC05A400000000000;
	abs.f64 	%fd550, %fd551;
	setp.gt.f64 	%p106, %fd550, 0d3FF0000000000000;
	selp.b32 	%r166, 2146435072, 0, %p106;
	mov.u32 	%r167, 0;
	xor.b32  	%r168, %r166, 2146435072;
	setp.lt.s32 	%p107, %r31, 0;
	selp.b32 	%r169, %r168, %r166, %p107;
	setp.eq.f64 	%p108, %fd551, 0dBFF0000000000000;
	selp.b32 	%r170, 1072693248, %r169, %p108;
	mov.b64 	%fd593, {%r167, %r170};
	bra.uni 	$L__BB12_108;

$L__BB12_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd2;
	}
	and.b32  	%r161, %r35, 2147483647;
	setp.ne.s32 	%p100, %r161, 2146435072;
	setp.ne.s32 	%p101, %r160, 0;
	or.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB12_108;

	setp.gt.s32 	%p103, %r31, -1;
	selp.b32 	%r162, 2146435072, 0, %p103;
	mov.u32 	%r163, 0;
	setp.ne.s32 	%p104, %r36, 1071644672;
	and.pred  	%p105, %p104, %p2;
	or.b32  	%r164, %r162, -2147483648;
	selp.b32 	%r165, %r164, %r162, %p105;
	mov.b64 	%fd593, {%r163, %r165};

$L__BB12_108:
	mul.rn.f64 	%fd470, %fd593, 0d3FB999999999999A;
	setp.eq.f64 	%p109, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd471, 0d3FB999999999999A, %fd470, %p109;
	add.rn.f64 	%fd472, %fd148, %fd471;
	add.rn.f64 	%fd473, %fd146, %fd472;
	mul.rn.f64 	%fd474, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd475, %fd474, %fd473;
	mul.rn.f64 	%fd476, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd476, %fd475;
	div.rn.f64 	%fd477, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd477, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r171, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd159;
	}
	and.b32  	%r173, %r172, 2147483647;
	setp.eq.s32 	%p110, %r173, 2146435072;
	setp.eq.s32 	%p111, %r171, 0;
	and.pred  	%p3, %p111, %p110;
	@%p3 bra 	$L__BB12_111;
	bra.uni 	$L__BB12_109;

$L__BB12_111:
	mov.f64 	%fd487, 0d0000000000000000;
	mul.rn.f64 	%fd594, %fd159, %fd487;
	mov.u32 	%r198, 0;
	bra.uni 	$L__BB12_112;

$L__BB12_109:
	mul.rn.f64 	%fd478, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r198, %fd478;
	st.local.u32 	[%rd1], %r198;
	cvt.rn.f64.s32 	%fd479, %r198;
	neg.f64 	%fd480, %fd479;
	mov.f64 	%fd481, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd482, %fd480, %fd481, %fd159;
	mov.f64 	%fd483, 0d3C91A62633145C00;
	fma.rn.f64 	%fd484, %fd480, %fd483, %fd482;
	mov.f64 	%fd485, 0d397B839A252049C0;
	fma.rn.f64 	%fd594, %fd480, %fd485, %fd484;
	abs.f64 	%fd486, %fd159;
	setp.ltu.f64 	%p112, %fd486, 0d41E0000000000000;
	@%p112 bra 	$L__BB12_112;

	add.u64 	%rd88, %SP, 0;
	{ // callseq 140, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd88;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd594, [retval0+0];
	} // callseq 140
	ld.local.u32 	%r198, [%rd1];

$L__BB12_112:
	mov.u64 	%rd106, __cudart_sin_cos_coeffs;
	and.b32  	%r175, %r198, 1;
	shl.b32 	%r176, %r198, 3;
	and.b32  	%r177, %r176, 8;
	setp.eq.s32 	%p113, %r175, 0;
	selp.f64 	%fd488, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p113;
	mul.wide.s32 	%rd73, %r177, 8;
	add.s64 	%rd75, %rd106, %rd73;
	ld.global.nc.f64 	%fd489, [%rd75+8];
	mul.rn.f64 	%fd164, %fd594, %fd594;
	fma.rn.f64 	%fd490, %fd488, %fd164, %fd489;
	ld.global.nc.f64 	%fd491, [%rd75+16];
	fma.rn.f64 	%fd492, %fd490, %fd164, %fd491;
	ld.global.nc.f64 	%fd493, [%rd75+24];
	fma.rn.f64 	%fd494, %fd492, %fd164, %fd493;
	ld.global.nc.f64 	%fd495, [%rd75+32];
	fma.rn.f64 	%fd496, %fd494, %fd164, %fd495;
	ld.global.nc.f64 	%fd497, [%rd75+40];
	fma.rn.f64 	%fd498, %fd496, %fd164, %fd497;
	ld.global.nc.f64 	%fd499, [%rd75+48];
	fma.rn.f64 	%fd165, %fd498, %fd164, %fd499;
	fma.rn.f64 	%fd596, %fd165, %fd594, %fd594;
	@%p113 bra 	$L__BB12_114;

	mov.f64 	%fd500, 0d3FF0000000000000;
	fma.rn.f64 	%fd596, %fd165, %fd164, %fd500;

$L__BB12_114:
	and.b32  	%r178, %r198, 2;
	setp.eq.s32 	%p114, %r178, 0;
	@%p114 bra 	$L__BB12_116;

	mov.f64 	%fd501, 0d0000000000000000;
	mov.f64 	%fd502, 0dBFF0000000000000;
	fma.rn.f64 	%fd596, %fd596, %fd502, %fd501;

$L__BB12_116:
	@%p3 bra 	$L__BB12_120;
	bra.uni 	$L__BB12_117;

$L__BB12_120:
	mov.f64 	%fd512, 0d0000000000000000;
	mul.rn.f64 	%fd598, %fd159, %fd512;
	mov.u32 	%r200, 1;
	bra.uni 	$L__BB12_121;

$L__BB12_117:
	mul.rn.f64 	%fd503, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r199, %fd503;
	st.local.u32 	[%rd1], %r199;
	cvt.rn.f64.s32 	%fd504, %r199;
	neg.f64 	%fd505, %fd504;
	mov.f64 	%fd506, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd507, %fd505, %fd506, %fd159;
	mov.f64 	%fd508, 0d3C91A62633145C00;
	fma.rn.f64 	%fd509, %fd505, %fd508, %fd507;
	mov.f64 	%fd510, 0d397B839A252049C0;
	fma.rn.f64 	%fd598, %fd505, %fd510, %fd509;
	abs.f64 	%fd511, %fd159;
	setp.ltu.f64 	%p115, %fd511, 0d41E0000000000000;
	@%p115 bra 	$L__BB12_119;

	add.u64 	%rd89, %SP, 0;
	{ // callseq 141, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd89;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd598, [retval0+0];
	} // callseq 141
	ld.local.u32 	%r199, [%rd1];

$L__BB12_119:
	add.s32 	%r200, %r199, 1;

$L__BB12_121:
	mov.u64 	%rd107, __cudart_sin_cos_coeffs;
	and.b32  	%r180, %r200, 1;
	shl.b32 	%r181, %r200, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p116, %r180, 0;
	selp.f64 	%fd513, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd77, %r182, 8;
	add.s64 	%rd79, %rd107, %rd77;
	ld.global.nc.f64 	%fd514, [%rd79+8];
	mul.rn.f64 	%fd176, %fd598, %fd598;
	fma.rn.f64 	%fd515, %fd513, %fd176, %fd514;
	ld.global.nc.f64 	%fd516, [%rd79+16];
	fma.rn.f64 	%fd517, %fd515, %fd176, %fd516;
	ld.global.nc.f64 	%fd518, [%rd79+24];
	fma.rn.f64 	%fd519, %fd517, %fd176, %fd518;
	ld.global.nc.f64 	%fd520, [%rd79+32];
	fma.rn.f64 	%fd521, %fd519, %fd176, %fd520;
	ld.global.nc.f64 	%fd522, [%rd79+40];
	fma.rn.f64 	%fd523, %fd521, %fd176, %fd522;
	ld.global.nc.f64 	%fd524, [%rd79+48];
	fma.rn.f64 	%fd177, %fd523, %fd176, %fd524;
	fma.rn.f64 	%fd600, %fd177, %fd598, %fd598;
	@%p116 bra 	$L__BB12_123;

	mov.f64 	%fd525, 0d3FF0000000000000;
	fma.rn.f64 	%fd600, %fd177, %fd176, %fd525;

$L__BB12_123:
	and.b32  	%r183, %r200, 2;
	setp.eq.s32 	%p117, %r183, 0;
	@%p117 bra 	$L__BB12_125;

	mov.f64 	%fd526, 0d0000000000000000;
	mov.f64 	%fd527, 0dBFF0000000000000;
	fma.rn.f64 	%fd600, %fd600, %fd527, %fd526;

$L__BB12_125:
	mov.u32 	%r187, %tid.x;
	mov.u32 	%r186, %ntid.x;
	mov.u32 	%r185, %ctaid.x;
	mad.lo.s32 	%r184, %r185, %r186, %r187;
	mul.wide.s32 	%rd96, %r184, 8;
	ld.param.u64 	%rd95, [wgs84_to_gcj02_cuda_double_param_1];
	cvta.to.global.u64 	%rd94, %rd95;
	add.s64 	%rd93, %rd94, %rd96;
	ld.param.u64 	%rd92, [wgs84_to_gcj02_cuda_double_param_0];
	cvta.to.global.u64 	%rd91, %rd92;
	add.s64 	%rd90, %rd91, %rd96;
	mul.rn.f64 	%fd528, %fd596, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd529, %fd596, %fd528;
	add.rn.f64 	%fd530, %fd529, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd531, %fd530;
	mov.f64 	%fd532, 0d415854C140000000;
	div.rn.f64 	%fd533, %fd532, %fd531;
	mul.rn.f64 	%fd534, %fd533, %fd600;
	mul.rn.f64 	%fd535, %fd534, 0d400921FB54442D18;
	mul.rn.f64 	%fd536, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd537, %fd536, %fd535;
	add.rn.f64 	%fd538, %fd1, %fd537;
	st.global.f64 	[%rd90], %fd538;
	mul.rn.f64 	%fd539, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd540, %fd531, %fd530;
	mov.f64 	%fd541, 0d41582B102DE355C1;
	div.rn.f64 	%fd542, %fd541, %fd540;
	mul.rn.f64 	%fd543, %fd542, 0d400921FB54442D18;
	div.rn.f64 	%fd544, %fd539, %fd543;
	add.rn.f64 	%fd545, %fd3, %fd544;
	st.global.f64 	[%rd93], %fd545;
	ret;

}
	// .globl	wgs84_to_bd09_cuda_double
.visible .entry wgs84_to_bd09_cuda_double(
	.param .u64 wgs84_to_bd09_cuda_double_param_0,
	.param .u64 wgs84_to_bd09_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot13[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<198>;
	.reg .b32 	%r<318>;
	.reg .f64 	%fd<878>;
	.reg .b64 	%rd<150>;


	mov.u64 	%SPL, __local_depot13;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [wgs84_to_bd09_cuda_double_param_0];
	ld.param.u64 	%rd20, [wgs84_to_bd09_cuda_double_param_1];
	cvta.to.global.u64 	%rd21, %rd20;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd38, %rd19;
	mul.wide.s32 	%rd39, %r68, 8;
	add.s64 	%rd17, %rd38, %rd39;
	add.s64 	%rd18, %rd21, %rd39;
	ld.global.f64 	%fd1, [%rd17];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd18];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r69, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r70}, %fd9;
	}
	and.b32  	%r71, %r70, 2147483647;
	setp.eq.s32 	%p7, %r71, 2146435072;
	setp.eq.s32 	%p8, %r69, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB13_3;
	bra.uni 	$L__BB13_1;

$L__BB13_3:
	mov.f64 	%fd269, 0d0000000000000000;
	mul.rn.f64 	%fd814, %fd9, %fd269;
	mov.u32 	%r299, 0;
	bra.uni 	$L__BB13_4;

$L__BB13_1:
	mul.rn.f64 	%fd260, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd260;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd261, %r299;
	neg.f64 	%fd262, %fd261;
	mov.f64 	%fd263, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd264, %fd262, %fd263, %fd9;
	mov.f64 	%fd265, 0d3C91A62633145C00;
	fma.rn.f64 	%fd266, %fd262, %fd265, %fd264;
	mov.f64 	%fd267, 0d397B839A252049C0;
	fma.rn.f64 	%fd814, %fd262, %fd267, %fd266;
	abs.f64 	%fd268, %fd9;
	setp.ltu.f64 	%p10, %fd268, 0d41E0000000000000;
	@%p10 bra 	$L__BB13_4;

	add.u64 	%rd147, %SP, 0;
	{ // callseq 142, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd147;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd814, [retval0+0];
	} // callseq 142
	ld.local.u32 	%r299, [%rd1];

$L__BB13_4:
	and.b32  	%r73, %r299, 1;
	shl.b32 	%r74, %r299, 3;
	and.b32  	%r75, %r74, 8;
	setp.eq.s32 	%p11, %r73, 0;
	selp.f64 	%fd270, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p11;
	mul.wide.s32 	%rd41, %r75, 8;
	mov.u64 	%rd42, __cudart_sin_cos_coeffs;
	add.s64 	%rd43, %rd42, %rd41;
	ld.global.nc.f64 	%fd271, [%rd43+8];
	mul.rn.f64 	%fd14, %fd814, %fd814;
	fma.rn.f64 	%fd272, %fd270, %fd14, %fd271;
	ld.global.nc.f64 	%fd273, [%rd43+16];
	fma.rn.f64 	%fd274, %fd272, %fd14, %fd273;
	ld.global.nc.f64 	%fd275, [%rd43+24];
	fma.rn.f64 	%fd276, %fd274, %fd14, %fd275;
	ld.global.nc.f64 	%fd277, [%rd43+32];
	fma.rn.f64 	%fd278, %fd276, %fd14, %fd277;
	ld.global.nc.f64 	%fd279, [%rd43+40];
	fma.rn.f64 	%fd280, %fd278, %fd14, %fd279;
	ld.global.nc.f64 	%fd281, [%rd43+48];
	fma.rn.f64 	%fd15, %fd280, %fd14, %fd281;
	fma.rn.f64 	%fd816, %fd15, %fd814, %fd814;
	@%p11 bra 	$L__BB13_6;

	mov.f64 	%fd282, 0d3FF0000000000000;
	fma.rn.f64 	%fd816, %fd15, %fd14, %fd282;

$L__BB13_6:
	and.b32  	%r76, %r299, 2;
	setp.eq.s32 	%p12, %r76, 0;
	@%p12 bra 	$L__BB13_8;

	mov.f64 	%fd283, 0d0000000000000000;
	mov.f64 	%fd284, 0dBFF0000000000000;
	fma.rn.f64 	%fd816, %fd816, %fd284, %fd283;

$L__BB13_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r77, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r78}, %fd21;
	}
	and.b32  	%r79, %r78, 2147483647;
	setp.eq.s32 	%p13, %r79, 2146435072;
	setp.eq.s32 	%p14, %r77, 0;
	and.pred  	%p15, %p14, %p13;
	@%p15 bra 	$L__BB13_11;
	bra.uni 	$L__BB13_9;

$L__BB13_11:
	mov.f64 	%fd294, 0d0000000000000000;
	mul.rn.f64 	%fd817, %fd21, %fd294;
	mov.u32 	%r300, 0;
	bra.uni 	$L__BB13_12;

$L__BB13_9:
	mul.rn.f64 	%fd285, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r300, %fd285;
	st.local.u32 	[%rd1], %r300;
	cvt.rn.f64.s32 	%fd286, %r300;
	neg.f64 	%fd287, %fd286;
	mov.f64 	%fd288, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd289, %fd287, %fd288, %fd21;
	mov.f64 	%fd290, 0d3C91A62633145C00;
	fma.rn.f64 	%fd291, %fd287, %fd290, %fd289;
	mov.f64 	%fd292, 0d397B839A252049C0;
	fma.rn.f64 	%fd817, %fd287, %fd292, %fd291;
	abs.f64 	%fd293, %fd21;
	setp.ltu.f64 	%p16, %fd293, 0d41E0000000000000;
	@%p16 bra 	$L__BB13_12;

	add.u64 	%rd148, %SP, 0;
	{ // callseq 143, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd148;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd817, [retval0+0];
	} // callseq 143
	ld.local.u32 	%r300, [%rd1];

$L__BB13_12:
	mov.u64 	%rd149, __cudart_sin_cos_coeffs;
	and.b32  	%r81, %r300, 1;
	shl.b32 	%r82, %r300, 3;
	and.b32  	%r83, %r82, 8;
	setp.eq.s32 	%p17, %r81, 0;
	selp.f64 	%fd295, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p17;
	mul.wide.s32 	%rd45, %r83, 8;
	add.s64 	%rd47, %rd149, %rd45;
	ld.global.nc.f64 	%fd296, [%rd47+8];
	mul.rn.f64 	%fd26, %fd817, %fd817;
	fma.rn.f64 	%fd297, %fd295, %fd26, %fd296;
	ld.global.nc.f64 	%fd298, [%rd47+16];
	fma.rn.f64 	%fd299, %fd297, %fd26, %fd298;
	ld.global.nc.f64 	%fd300, [%rd47+24];
	fma.rn.f64 	%fd301, %fd299, %fd26, %fd300;
	ld.global.nc.f64 	%fd302, [%rd47+32];
	fma.rn.f64 	%fd303, %fd301, %fd26, %fd302;
	ld.global.nc.f64 	%fd304, [%rd47+40];
	fma.rn.f64 	%fd305, %fd303, %fd26, %fd304;
	ld.global.nc.f64 	%fd306, [%rd47+48];
	fma.rn.f64 	%fd27, %fd305, %fd26, %fd306;
	fma.rn.f64 	%fd819, %fd27, %fd817, %fd817;
	@%p17 bra 	$L__BB13_14;

	mov.f64 	%fd307, 0d3FF0000000000000;
	fma.rn.f64 	%fd819, %fd27, %fd26, %fd307;

$L__BB13_14:
	and.b32  	%r84, %r300, 2;
	setp.eq.s32 	%p18, %r84, 0;
	@%p18 bra 	$L__BB13_16;

	mov.f64 	%fd308, 0d0000000000000000;
	mov.f64 	%fd309, 0dBFF0000000000000;
	fma.rn.f64 	%fd819, %fd819, %fd309, %fd308;

$L__BB13_16:
	mul.rn.f64 	%fd310, %fd819, 0d4034000000000000;
	mul.rn.f64 	%fd311, %fd816, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd311, %fd310;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r85}, %fd8;
	}
	and.b32  	%r86, %r85, 2147483647;
	setp.eq.s32 	%p19, %r86, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r87, %temp}, %fd8;
	}
	setp.eq.s32 	%p20, %r87, 0;
	and.pred  	%p21, %p20, %p19;
	@%p21 bra 	$L__BB13_19;
	bra.uni 	$L__BB13_17;

$L__BB13_19:
	mov.f64 	%fd321, 0d0000000000000000;
	mul.rn.f64 	%fd820, %fd8, %fd321;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB13_20;

$L__BB13_17:
	mul.rn.f64 	%fd312, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd312;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd313, %r301;
	neg.f64 	%fd314, %fd313;
	mov.f64 	%fd315, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd316, %fd314, %fd315, %fd8;
	mov.f64 	%fd317, 0d3C91A62633145C00;
	fma.rn.f64 	%fd318, %fd314, %fd317, %fd316;
	mov.f64 	%fd319, 0d397B839A252049C0;
	fma.rn.f64 	%fd820, %fd314, %fd319, %fd318;
	abs.f64 	%fd320, %fd8;
	setp.ltu.f64 	%p22, %fd320, 0d41E0000000000000;
	@%p22 bra 	$L__BB13_20;

	add.u64 	%rd131, %SP, 0;
	{ // callseq 144, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd131;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd820, [retval0+0];
	} // callseq 144
	ld.local.u32 	%r301, [%rd1];

$L__BB13_20:
	mov.u64 	%rd132, __cudart_sin_cos_coeffs;
	and.b32  	%r89, %r301, 1;
	shl.b32 	%r90, %r301, 3;
	and.b32  	%r91, %r90, 8;
	setp.eq.s32 	%p23, %r89, 0;
	selp.f64 	%fd322, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p23;
	mul.wide.s32 	%rd49, %r91, 8;
	add.s64 	%rd51, %rd132, %rd49;
	ld.global.nc.f64 	%fd323, [%rd51+8];
	mul.rn.f64 	%fd38, %fd820, %fd820;
	fma.rn.f64 	%fd324, %fd322, %fd38, %fd323;
	ld.global.nc.f64 	%fd325, [%rd51+16];
	fma.rn.f64 	%fd326, %fd324, %fd38, %fd325;
	ld.global.nc.f64 	%fd327, [%rd51+24];
	fma.rn.f64 	%fd328, %fd326, %fd38, %fd327;
	ld.global.nc.f64 	%fd329, [%rd51+32];
	fma.rn.f64 	%fd330, %fd328, %fd38, %fd329;
	ld.global.nc.f64 	%fd331, [%rd51+40];
	fma.rn.f64 	%fd332, %fd330, %fd38, %fd331;
	ld.global.nc.f64 	%fd333, [%rd51+48];
	fma.rn.f64 	%fd39, %fd332, %fd38, %fd333;
	fma.rn.f64 	%fd822, %fd39, %fd820, %fd820;
	@%p23 bra 	$L__BB13_22;

	mov.f64 	%fd334, 0d3FF0000000000000;
	fma.rn.f64 	%fd822, %fd39, %fd38, %fd334;

$L__BB13_22:
	and.b32  	%r92, %r301, 2;
	setp.eq.s32 	%p24, %r92, 0;
	@%p24 bra 	$L__BB13_24;

	mov.f64 	%fd335, 0d0000000000000000;
	mov.f64 	%fd336, 0dBFF0000000000000;
	fma.rn.f64 	%fd822, %fd822, %fd336, %fd335;

$L__BB13_24:
	add.rn.f64 	%fd811, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd810, %fd811, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd810, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r93, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r94}, %fd45;
	}
	and.b32  	%r95, %r94, 2147483647;
	setp.eq.s32 	%p25, %r95, 2146435072;
	setp.eq.s32 	%p26, %r93, 0;
	and.pred  	%p27, %p26, %p25;
	@%p27 bra 	$L__BB13_27;
	bra.uni 	$L__BB13_25;

$L__BB13_27:
	mov.f64 	%fd346, 0d0000000000000000;
	mul.rn.f64 	%fd823, %fd45, %fd346;
	mov.u32 	%r302, 0;
	bra.uni 	$L__BB13_28;

$L__BB13_25:
	mul.rn.f64 	%fd337, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd337;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd338, %r302;
	neg.f64 	%fd339, %fd338;
	mov.f64 	%fd340, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd341, %fd339, %fd340, %fd45;
	mov.f64 	%fd342, 0d3C91A62633145C00;
	fma.rn.f64 	%fd343, %fd339, %fd342, %fd341;
	mov.f64 	%fd344, 0d397B839A252049C0;
	fma.rn.f64 	%fd823, %fd339, %fd344, %fd343;
	abs.f64 	%fd345, %fd45;
	setp.ltu.f64 	%p28, %fd345, 0d41E0000000000000;
	@%p28 bra 	$L__BB13_28;

	add.u64 	%rd133, %SP, 0;
	{ // callseq 145, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd133;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd823, [retval0+0];
	} // callseq 145
	ld.local.u32 	%r302, [%rd1];

$L__BB13_28:
	mov.u64 	%rd134, __cudart_sin_cos_coeffs;
	and.b32  	%r97, %r302, 1;
	shl.b32 	%r98, %r302, 3;
	and.b32  	%r99, %r98, 8;
	setp.eq.s32 	%p29, %r97, 0;
	selp.f64 	%fd347, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p29;
	mul.wide.s32 	%rd53, %r99, 8;
	add.s64 	%rd55, %rd134, %rd53;
	ld.global.nc.f64 	%fd348, [%rd55+8];
	mul.rn.f64 	%fd50, %fd823, %fd823;
	fma.rn.f64 	%fd349, %fd347, %fd50, %fd348;
	ld.global.nc.f64 	%fd350, [%rd55+16];
	fma.rn.f64 	%fd351, %fd349, %fd50, %fd350;
	ld.global.nc.f64 	%fd352, [%rd55+24];
	fma.rn.f64 	%fd353, %fd351, %fd50, %fd352;
	ld.global.nc.f64 	%fd354, [%rd55+32];
	fma.rn.f64 	%fd355, %fd353, %fd50, %fd354;
	ld.global.nc.f64 	%fd356, [%rd55+40];
	fma.rn.f64 	%fd357, %fd355, %fd50, %fd356;
	ld.global.nc.f64 	%fd358, [%rd55+48];
	fma.rn.f64 	%fd51, %fd357, %fd50, %fd358;
	fma.rn.f64 	%fd825, %fd51, %fd823, %fd823;
	@%p29 bra 	$L__BB13_30;

	mov.f64 	%fd359, 0d3FF0000000000000;
	fma.rn.f64 	%fd825, %fd51, %fd50, %fd359;

$L__BB13_30:
	and.b32  	%r100, %r302, 2;
	setp.eq.s32 	%p30, %r100, 0;
	@%p30 bra 	$L__BB13_32;

	mov.f64 	%fd360, 0d0000000000000000;
	mov.f64 	%fd361, 0dBFF0000000000000;
	fma.rn.f64 	%fd825, %fd825, %fd361, %fd360;

$L__BB13_32:
	add.rn.f64 	%fd803, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd802, %fd803, 0d400921FB54442D18;
	mul.rn.f64 	%fd362, %fd825, 0d4044000000000000;
	mul.rn.f64 	%fd363, %fd822, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd363, %fd362;
	div.rn.f64 	%fd58, %fd802, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r101, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r102}, %fd58;
	}
	and.b32  	%r103, %r102, 2147483647;
	setp.eq.s32 	%p31, %r103, 2146435072;
	setp.eq.s32 	%p32, %r101, 0;
	and.pred  	%p33, %p32, %p31;
	@%p33 bra 	$L__BB13_35;
	bra.uni 	$L__BB13_33;

$L__BB13_35:
	mov.f64 	%fd373, 0d0000000000000000;
	mul.rn.f64 	%fd826, %fd58, %fd373;
	mov.u32 	%r303, 0;
	bra.uni 	$L__BB13_36;

$L__BB13_33:
	mul.rn.f64 	%fd364, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r303, %fd364;
	st.local.u32 	[%rd1], %r303;
	cvt.rn.f64.s32 	%fd365, %r303;
	neg.f64 	%fd366, %fd365;
	mov.f64 	%fd367, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd368, %fd366, %fd367, %fd58;
	mov.f64 	%fd369, 0d3C91A62633145C00;
	fma.rn.f64 	%fd370, %fd366, %fd369, %fd368;
	mov.f64 	%fd371, 0d397B839A252049C0;
	fma.rn.f64 	%fd826, %fd366, %fd371, %fd370;
	abs.f64 	%fd372, %fd58;
	setp.ltu.f64 	%p34, %fd372, 0d41E0000000000000;
	@%p34 bra 	$L__BB13_36;

	add.u64 	%rd135, %SP, 0;
	{ // callseq 146, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd135;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd826, [retval0+0];
	} // callseq 146
	ld.local.u32 	%r303, [%rd1];

$L__BB13_36:
	mov.u64 	%rd136, __cudart_sin_cos_coeffs;
	and.b32  	%r105, %r303, 1;
	shl.b32 	%r106, %r303, 3;
	and.b32  	%r107, %r106, 8;
	setp.eq.s32 	%p35, %r105, 0;
	selp.f64 	%fd374, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p35;
	mul.wide.s32 	%rd57, %r107, 8;
	add.s64 	%rd59, %rd136, %rd57;
	ld.global.nc.f64 	%fd375, [%rd59+8];
	mul.rn.f64 	%fd63, %fd826, %fd826;
	fma.rn.f64 	%fd376, %fd374, %fd63, %fd375;
	ld.global.nc.f64 	%fd377, [%rd59+16];
	fma.rn.f64 	%fd378, %fd376, %fd63, %fd377;
	ld.global.nc.f64 	%fd379, [%rd59+24];
	fma.rn.f64 	%fd380, %fd378, %fd63, %fd379;
	ld.global.nc.f64 	%fd381, [%rd59+32];
	fma.rn.f64 	%fd382, %fd380, %fd63, %fd381;
	ld.global.nc.f64 	%fd383, [%rd59+40];
	fma.rn.f64 	%fd384, %fd382, %fd63, %fd383;
	ld.global.nc.f64 	%fd385, [%rd59+48];
	fma.rn.f64 	%fd64, %fd384, %fd63, %fd385;
	fma.rn.f64 	%fd828, %fd64, %fd826, %fd826;
	@%p35 bra 	$L__BB13_38;

	mov.f64 	%fd386, 0d3FF0000000000000;
	fma.rn.f64 	%fd828, %fd64, %fd63, %fd386;

$L__BB13_38:
	and.b32  	%r108, %r303, 2;
	setp.eq.s32 	%p36, %r108, 0;
	@%p36 bra 	$L__BB13_40;

	mov.f64 	%fd387, 0d0000000000000000;
	mov.f64 	%fd388, 0dBFF0000000000000;
	fma.rn.f64 	%fd828, %fd828, %fd388, %fd387;

$L__BB13_40:
	add.rn.f64 	%fd805, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd804, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd389, %fd828, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd389;
	div.rn.f64 	%fd71, %fd804, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r109, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd71;
	}
	and.b32  	%r111, %r110, 2147483647;
	setp.eq.s32 	%p37, %r111, 2146435072;
	setp.eq.s32 	%p38, %r109, 0;
	and.pred  	%p39, %p38, %p37;
	@%p39 bra 	$L__BB13_43;
	bra.uni 	$L__BB13_41;

$L__BB13_43:
	mov.f64 	%fd399, 0d0000000000000000;
	mul.rn.f64 	%fd829, %fd71, %fd399;
	mov.u32 	%r304, 0;
	bra.uni 	$L__BB13_44;

$L__BB13_41:
	mul.rn.f64 	%fd390, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd390;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd391, %r304;
	neg.f64 	%fd392, %fd391;
	mov.f64 	%fd393, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd394, %fd392, %fd393, %fd71;
	mov.f64 	%fd395, 0d3C91A62633145C00;
	fma.rn.f64 	%fd396, %fd392, %fd395, %fd394;
	mov.f64 	%fd397, 0d397B839A252049C0;
	fma.rn.f64 	%fd829, %fd392, %fd397, %fd396;
	abs.f64 	%fd398, %fd71;
	setp.ltu.f64 	%p40, %fd398, 0d41E0000000000000;
	@%p40 bra 	$L__BB13_44;

	add.u64 	%rd137, %SP, 0;
	{ // callseq 147, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd137;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd829, [retval0+0];
	} // callseq 147
	ld.local.u32 	%r304, [%rd1];

$L__BB13_44:
	mov.u64 	%rd138, __cudart_sin_cos_coeffs;
	and.b32  	%r113, %r304, 1;
	shl.b32 	%r114, %r304, 3;
	and.b32  	%r115, %r114, 8;
	setp.eq.s32 	%p41, %r113, 0;
	selp.f64 	%fd400, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p41;
	mul.wide.s32 	%rd61, %r115, 8;
	add.s64 	%rd63, %rd138, %rd61;
	ld.global.nc.f64 	%fd401, [%rd63+8];
	mul.rn.f64 	%fd76, %fd829, %fd829;
	fma.rn.f64 	%fd402, %fd400, %fd76, %fd401;
	ld.global.nc.f64 	%fd403, [%rd63+16];
	fma.rn.f64 	%fd404, %fd402, %fd76, %fd403;
	ld.global.nc.f64 	%fd405, [%rd63+24];
	fma.rn.f64 	%fd406, %fd404, %fd76, %fd405;
	ld.global.nc.f64 	%fd407, [%rd63+32];
	fma.rn.f64 	%fd408, %fd406, %fd76, %fd407;
	ld.global.nc.f64 	%fd409, [%rd63+40];
	fma.rn.f64 	%fd410, %fd408, %fd76, %fd409;
	ld.global.nc.f64 	%fd411, [%rd63+48];
	fma.rn.f64 	%fd77, %fd410, %fd76, %fd411;
	fma.rn.f64 	%fd831, %fd77, %fd829, %fd829;
	@%p41 bra 	$L__BB13_46;

	mov.f64 	%fd412, 0d3FF0000000000000;
	fma.rn.f64 	%fd831, %fd77, %fd76, %fd412;

$L__BB13_46:
	and.b32  	%r116, %r304, 2;
	setp.eq.s32 	%p42, %r116, 0;
	@%p42 bra 	$L__BB13_48;

	mov.f64 	%fd413, 0d0000000000000000;
	mov.f64 	%fd414, 0dBFF0000000000000;
	fma.rn.f64 	%fd831, %fd831, %fd414, %fd413;

$L__BB13_48:
	mul.rn.f64 	%fd415, %fd831, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd415;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r117}, %fd7;
	}
	and.b32  	%r118, %r117, 2147483647;
	setp.eq.s32 	%p43, %r118, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd7;
	}
	setp.eq.s32 	%p44, %r119, 0;
	and.pred  	%p45, %p44, %p43;
	@%p45 bra 	$L__BB13_51;
	bra.uni 	$L__BB13_49;

$L__BB13_51:
	mov.f64 	%fd425, 0d0000000000000000;
	mul.rn.f64 	%fd832, %fd7, %fd425;
	mov.u32 	%r305, 0;
	bra.uni 	$L__BB13_52;

$L__BB13_49:
	mul.rn.f64 	%fd416, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r305, %fd416;
	st.local.u32 	[%rd1], %r305;
	cvt.rn.f64.s32 	%fd417, %r305;
	neg.f64 	%fd418, %fd417;
	mov.f64 	%fd419, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd420, %fd418, %fd419, %fd7;
	mov.f64 	%fd421, 0d3C91A62633145C00;
	fma.rn.f64 	%fd422, %fd418, %fd421, %fd420;
	mov.f64 	%fd423, 0d397B839A252049C0;
	fma.rn.f64 	%fd832, %fd418, %fd423, %fd422;
	abs.f64 	%fd424, %fd7;
	setp.ltu.f64 	%p46, %fd424, 0d41E0000000000000;
	@%p46 bra 	$L__BB13_52;

	add.u64 	%rd104, %SP, 0;
	{ // callseq 148, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd104;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd832, [retval0+0];
	} // callseq 148
	ld.local.u32 	%r305, [%rd1];

$L__BB13_52:
	mov.u64 	%rd139, __cudart_sin_cos_coeffs;
	and.b32  	%r121, %r305, 1;
	shl.b32 	%r122, %r305, 3;
	and.b32  	%r123, %r122, 8;
	setp.eq.s32 	%p47, %r121, 0;
	selp.f64 	%fd426, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p47;
	mul.wide.s32 	%rd65, %r123, 8;
	add.s64 	%rd67, %rd139, %rd65;
	ld.global.nc.f64 	%fd427, [%rd67+8];
	mul.rn.f64 	%fd88, %fd832, %fd832;
	fma.rn.f64 	%fd428, %fd426, %fd88, %fd427;
	ld.global.nc.f64 	%fd429, [%rd67+16];
	fma.rn.f64 	%fd430, %fd428, %fd88, %fd429;
	ld.global.nc.f64 	%fd431, [%rd67+24];
	fma.rn.f64 	%fd432, %fd430, %fd88, %fd431;
	ld.global.nc.f64 	%fd433, [%rd67+32];
	fma.rn.f64 	%fd434, %fd432, %fd88, %fd433;
	ld.global.nc.f64 	%fd435, [%rd67+40];
	fma.rn.f64 	%fd436, %fd434, %fd88, %fd435;
	ld.global.nc.f64 	%fd437, [%rd67+48];
	fma.rn.f64 	%fd89, %fd436, %fd88, %fd437;
	fma.rn.f64 	%fd834, %fd89, %fd832, %fd832;
	@%p47 bra 	$L__BB13_54;

	mov.f64 	%fd438, 0d3FF0000000000000;
	fma.rn.f64 	%fd834, %fd89, %fd88, %fd438;

$L__BB13_54:
	and.b32  	%r124, %r305, 2;
	setp.eq.s32 	%p48, %r124, 0;
	@%p48 bra 	$L__BB13_56;

	mov.f64 	%fd439, 0d0000000000000000;
	mov.f64 	%fd440, 0dBFF0000000000000;
	fma.rn.f64 	%fd834, %fd834, %fd440, %fd439;

$L__BB13_56:
	add.rn.f64 	%fd813, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd812, %fd813, 0d400921FB54442D18;
	div.rn.f64 	%fd95, %fd812, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r125, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r126}, %fd95;
	}
	and.b32  	%r127, %r126, 2147483647;
	setp.eq.s32 	%p49, %r127, 2146435072;
	setp.eq.s32 	%p50, %r125, 0;
	and.pred  	%p51, %p50, %p49;
	@%p51 bra 	$L__BB13_59;
	bra.uni 	$L__BB13_57;

$L__BB13_59:
	mov.f64 	%fd450, 0d0000000000000000;
	mul.rn.f64 	%fd835, %fd95, %fd450;
	mov.u32 	%r306, 0;
	bra.uni 	$L__BB13_60;

$L__BB13_57:
	mul.rn.f64 	%fd441, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r306, %fd441;
	st.local.u32 	[%rd1], %r306;
	cvt.rn.f64.s32 	%fd442, %r306;
	neg.f64 	%fd443, %fd442;
	mov.f64 	%fd444, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd445, %fd443, %fd444, %fd95;
	mov.f64 	%fd446, 0d3C91A62633145C00;
	fma.rn.f64 	%fd447, %fd443, %fd446, %fd445;
	mov.f64 	%fd448, 0d397B839A252049C0;
	fma.rn.f64 	%fd835, %fd443, %fd448, %fd447;
	abs.f64 	%fd449, %fd95;
	setp.ltu.f64 	%p52, %fd449, 0d41E0000000000000;
	@%p52 bra 	$L__BB13_60;

	add.u64 	%rd105, %SP, 0;
	{ // callseq 149, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd105;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd835, [retval0+0];
	} // callseq 149
	ld.local.u32 	%r306, [%rd1];

$L__BB13_60:
	mov.u64 	%rd114, __cudart_sin_cos_coeffs;
	and.b32  	%r129, %r306, 1;
	shl.b32 	%r130, %r306, 3;
	and.b32  	%r131, %r130, 8;
	setp.eq.s32 	%p53, %r129, 0;
	selp.f64 	%fd451, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p53;
	mul.wide.s32 	%rd69, %r131, 8;
	add.s64 	%rd71, %rd114, %rd69;
	ld.global.nc.f64 	%fd452, [%rd71+8];
	mul.rn.f64 	%fd100, %fd835, %fd835;
	fma.rn.f64 	%fd453, %fd451, %fd100, %fd452;
	ld.global.nc.f64 	%fd454, [%rd71+16];
	fma.rn.f64 	%fd455, %fd453, %fd100, %fd454;
	ld.global.nc.f64 	%fd456, [%rd71+24];
	fma.rn.f64 	%fd457, %fd455, %fd100, %fd456;
	ld.global.nc.f64 	%fd458, [%rd71+32];
	fma.rn.f64 	%fd459, %fd457, %fd100, %fd458;
	ld.global.nc.f64 	%fd460, [%rd71+40];
	fma.rn.f64 	%fd461, %fd459, %fd100, %fd460;
	ld.global.nc.f64 	%fd462, [%rd71+48];
	fma.rn.f64 	%fd101, %fd461, %fd100, %fd462;
	fma.rn.f64 	%fd837, %fd101, %fd835, %fd835;
	@%p53 bra 	$L__BB13_62;

	mov.f64 	%fd463, 0d3FF0000000000000;
	fma.rn.f64 	%fd837, %fd101, %fd100, %fd463;

$L__BB13_62:
	and.b32  	%r132, %r306, 2;
	setp.eq.s32 	%p54, %r132, 0;
	@%p54 bra 	$L__BB13_64;

	mov.f64 	%fd464, 0d0000000000000000;
	mov.f64 	%fd465, 0dBFF0000000000000;
	fma.rn.f64 	%fd837, %fd837, %fd465, %fd464;

$L__BB13_64:
	add.rn.f64 	%fd807, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd806, %fd807, 0d400921FB54442D18;
	mul.rn.f64 	%fd466, %fd837, 0d4044000000000000;
	mul.rn.f64 	%fd467, %fd834, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd467, %fd466;
	div.rn.f64 	%fd108, %fd806, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r133, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r134}, %fd108;
	}
	and.b32  	%r135, %r134, 2147483647;
	setp.eq.s32 	%p55, %r135, 2146435072;
	setp.eq.s32 	%p56, %r133, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB13_67;
	bra.uni 	$L__BB13_65;

$L__BB13_67:
	mov.f64 	%fd477, 0d0000000000000000;
	mul.rn.f64 	%fd838, %fd108, %fd477;
	mov.u32 	%r307, 0;
	bra.uni 	$L__BB13_68;

$L__BB13_65:
	mul.rn.f64 	%fd468, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r307, %fd468;
	st.local.u32 	[%rd1], %r307;
	cvt.rn.f64.s32 	%fd469, %r307;
	neg.f64 	%fd470, %fd469;
	mov.f64 	%fd471, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd472, %fd470, %fd471, %fd108;
	mov.f64 	%fd473, 0d3C91A62633145C00;
	fma.rn.f64 	%fd474, %fd470, %fd473, %fd472;
	mov.f64 	%fd475, 0d397B839A252049C0;
	fma.rn.f64 	%fd838, %fd470, %fd475, %fd474;
	abs.f64 	%fd476, %fd108;
	setp.ltu.f64 	%p58, %fd476, 0d41E0000000000000;
	@%p58 bra 	$L__BB13_68;

	add.u64 	%rd106, %SP, 0;
	{ // callseq 150, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd106;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd838, [retval0+0];
	} // callseq 150
	ld.local.u32 	%r307, [%rd1];

$L__BB13_68:
	mov.u64 	%rd115, __cudart_sin_cos_coeffs;
	and.b32  	%r137, %r307, 1;
	shl.b32 	%r138, %r307, 3;
	and.b32  	%r139, %r138, 8;
	setp.eq.s32 	%p59, %r137, 0;
	selp.f64 	%fd478, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd73, %r139, 8;
	add.s64 	%rd75, %rd115, %rd73;
	ld.global.nc.f64 	%fd479, [%rd75+8];
	mul.rn.f64 	%fd113, %fd838, %fd838;
	fma.rn.f64 	%fd480, %fd478, %fd113, %fd479;
	ld.global.nc.f64 	%fd481, [%rd75+16];
	fma.rn.f64 	%fd482, %fd480, %fd113, %fd481;
	ld.global.nc.f64 	%fd483, [%rd75+24];
	fma.rn.f64 	%fd484, %fd482, %fd113, %fd483;
	ld.global.nc.f64 	%fd485, [%rd75+32];
	fma.rn.f64 	%fd486, %fd484, %fd113, %fd485;
	ld.global.nc.f64 	%fd487, [%rd75+40];
	fma.rn.f64 	%fd488, %fd486, %fd113, %fd487;
	ld.global.nc.f64 	%fd489, [%rd75+48];
	fma.rn.f64 	%fd114, %fd488, %fd113, %fd489;
	fma.rn.f64 	%fd840, %fd114, %fd838, %fd838;
	@%p59 bra 	$L__BB13_70;

	mov.f64 	%fd490, 0d3FF0000000000000;
	fma.rn.f64 	%fd840, %fd114, %fd113, %fd490;

$L__BB13_70:
	and.b32  	%r140, %r307, 2;
	setp.eq.s32 	%p60, %r140, 0;
	@%p60 bra 	$L__BB13_72;

	mov.f64 	%fd491, 0d0000000000000000;
	mov.f64 	%fd492, 0dBFF0000000000000;
	fma.rn.f64 	%fd840, %fd840, %fd492, %fd491;

$L__BB13_72:
	add.rn.f64 	%fd809, %fd1, 0dC05A400000000000;
	mul.rn.f64 	%fd808, %fd809, 0d400921FB54442D18;
	mul.rn.f64 	%fd493, %fd840, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd493;
	div.rn.f64 	%fd121, %fd808, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r141, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r142}, %fd121;
	}
	and.b32  	%r143, %r142, 2147483647;
	setp.eq.s32 	%p61, %r143, 2146435072;
	setp.eq.s32 	%p62, %r141, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB13_75;
	bra.uni 	$L__BB13_73;

$L__BB13_75:
	mov.f64 	%fd503, 0d0000000000000000;
	mul.rn.f64 	%fd841, %fd121, %fd503;
	mov.u32 	%r308, 0;
	bra.uni 	$L__BB13_76;

$L__BB13_73:
	mul.rn.f64 	%fd494, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r308, %fd494;
	st.local.u32 	[%rd1], %r308;
	cvt.rn.f64.s32 	%fd495, %r308;
	neg.f64 	%fd496, %fd495;
	mov.f64 	%fd497, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd498, %fd496, %fd497, %fd121;
	mov.f64 	%fd499, 0d3C91A62633145C00;
	fma.rn.f64 	%fd500, %fd496, %fd499, %fd498;
	mov.f64 	%fd501, 0d397B839A252049C0;
	fma.rn.f64 	%fd841, %fd496, %fd501, %fd500;
	abs.f64 	%fd502, %fd121;
	setp.ltu.f64 	%p64, %fd502, 0d41E0000000000000;
	@%p64 bra 	$L__BB13_76;

	add.u64 	%rd107, %SP, 0;
	{ // callseq 151, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd107;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd841, [retval0+0];
	} // callseq 151
	ld.local.u32 	%r308, [%rd1];

$L__BB13_76:
	mov.u64 	%rd116, __cudart_sin_cos_coeffs;
	and.b32  	%r145, %r308, 1;
	shl.b32 	%r146, %r308, 3;
	and.b32  	%r147, %r146, 8;
	setp.eq.s32 	%p65, %r145, 0;
	selp.f64 	%fd504, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd77, %r147, 8;
	add.s64 	%rd79, %rd116, %rd77;
	ld.global.nc.f64 	%fd505, [%rd79+8];
	mul.rn.f64 	%fd126, %fd841, %fd841;
	fma.rn.f64 	%fd506, %fd504, %fd126, %fd505;
	ld.global.nc.f64 	%fd507, [%rd79+16];
	fma.rn.f64 	%fd508, %fd506, %fd126, %fd507;
	ld.global.nc.f64 	%fd509, [%rd79+24];
	fma.rn.f64 	%fd510, %fd508, %fd126, %fd509;
	ld.global.nc.f64 	%fd511, [%rd79+32];
	fma.rn.f64 	%fd512, %fd510, %fd126, %fd511;
	ld.global.nc.f64 	%fd513, [%rd79+40];
	fma.rn.f64 	%fd514, %fd512, %fd126, %fd513;
	ld.global.nc.f64 	%fd515, [%rd79+48];
	fma.rn.f64 	%fd127, %fd514, %fd126, %fd515;
	fma.rn.f64 	%fd843, %fd127, %fd841, %fd841;
	@%p65 bra 	$L__BB13_78;

	mov.f64 	%fd516, 0d3FF0000000000000;
	fma.rn.f64 	%fd843, %fd127, %fd126, %fd516;

$L__BB13_78:
	and.b32  	%r148, %r308, 2;
	setp.eq.s32 	%p66, %r148, 0;
	@%p66 bra 	$L__BB13_80;

	mov.f64 	%fd517, 0d0000000000000000;
	mov.f64 	%fd518, 0dBFF0000000000000;
	fma.rn.f64 	%fd843, %fd843, %fd518, %fd517;

$L__BB13_80:
	mul.rn.f64 	%fd519, %fd843, 0d4072C00000000000;
	add.rn.f64 	%fd520, %fd120, %fd519;
	add.rn.f64 	%fd133, %fd33, %fd520;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd521, %fd2, %fd2;
	mov.f64 	%fd522, 0d4000000000000000;
	add.rn.f64 	%fd523, %fd521, 0dC059000000000000;
	mul.rn.f64 	%fd524, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd523, %fd524;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd522;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p67, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 152, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd846, [retval0+0];
	} // callseq 152
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p68, %r33, 0;
	and.pred  	%p1, %p68, %p67;
	not.pred 	%p69, %p1;
	@%p69 bra 	$L__BB13_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r149}, %fd846;
	}
	xor.b32  	%r150, %r149, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r151, %temp}, %fd846;
	}
	mov.b64 	%fd846, {%r151, %r150};

$L__BB13_82:
	setp.eq.f64 	%p70, %fd4, 0d0000000000000000;
	@%p70 bra 	$L__BB13_86;
	bra.uni 	$L__BB13_83;

$L__BB13_86:
	selp.b32 	%r152, %r33, 0, %p67;
	mov.u32 	%r153, 0;
	or.b32  	%r154, %r152, 2146435072;
	setp.lt.s32 	%p74, %r31, 0;
	selp.b32 	%r155, %r154, %r152, %p74;
	mov.b64 	%fd846, {%r153, %r155};
	bra.uni 	$L__BB13_87;

$L__BB13_83:
	setp.gt.s32 	%p71, %r33, -1;
	@%p71 bra 	$L__BB13_87;

	mov.f64 	%fd525, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd526, %fd525;
	setp.eq.f64 	%p72, %fd526, 0d4000000000000000;
	@%p72 bra 	$L__BB13_87;

	mov.f64 	%fd846, 0dFFF8000000000000;

$L__BB13_87:
	add.rn.f64 	%fd528, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r156}, %fd528;
	}
	and.b32  	%r157, %r156, 2146435072;
	setp.ne.s32 	%p75, %r157, 2146435072;
	@%p75 bra 	$L__BB13_94;

	setp.gtu.f64 	%p76, %fd136, 0d7FF0000000000000;
	@%p76 bra 	$L__BB13_93;
	bra.uni 	$L__BB13_89;

$L__BB13_93:
	mov.f64 	%fd530, 0d4000000000000000;
	add.rn.f64 	%fd846, %fd4, %fd530;
	bra.uni 	$L__BB13_94;

$L__BB13_89:
	mov.f64 	%fd529, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r158, %temp}, %fd529;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p77, %r34, 2146435072;
	setp.eq.s32 	%p78, %r158, 0;
	and.pred  	%p79, %p77, %p78;
	@%p79 bra 	$L__BB13_92;
	bra.uni 	$L__BB13_90;

$L__BB13_92:
	setp.gt.f64 	%p86, %fd136, 0d3FF0000000000000;
	selp.b32 	%r165, 2146435072, 0, %p86;
	mov.u32 	%r166, 0;
	xor.b32  	%r167, %r165, 2146435072;
	setp.lt.s32 	%p87, %r31, 0;
	selp.b32 	%r168, %r167, %r165, %p87;
	setp.eq.f64 	%p88, %fd4, 0dBFF0000000000000;
	selp.b32 	%r169, 1072693248, %r168, %p88;
	mov.b64 	%fd846, {%r166, %r169};
	bra.uni 	$L__BB13_94;

$L__BB13_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r159, %temp}, %fd4;
	}
	and.b32  	%r160, %r33, 2147483647;
	setp.ne.s32 	%p80, %r160, 2146435072;
	setp.ne.s32 	%p81, %r159, 0;
	or.pred  	%p82, %p80, %p81;
	@%p82 bra 	$L__BB13_94;

	setp.gt.s32 	%p83, %r31, -1;
	selp.b32 	%r161, 2146435072, 0, %p83;
	mov.u32 	%r162, 0;
	setp.ne.s32 	%p84, %r34, 1071644672;
	and.pred  	%p85, %p84, %p1;
	or.b32  	%r163, %r161, -2147483648;
	selp.b32 	%r164, %r163, %r161, %p85;
	mov.b64 	%fd846, {%r162, %r164};

$L__BB13_94:
	add.rn.f64 	%fd797, %fd1, 0dC05A400000000000;
	abs.f64 	%fd796, %fd797;
	mul.rn.f64 	%fd531, %fd846, 0d3FC999999999999A;
	setp.eq.f64 	%p89, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd532, 0d3FC999999999999A, %fd531, %p89;
	add.rn.f64 	%fd533, %fd135, %fd532;
	mul.rn.f64 	%fd534, %fd797, %fd4;
	mul.rn.f64 	%fd146, %fd534, 0d3FB999999999999A;
	add.rn.f64 	%fd535, %fd146, %fd533;
	mul.rn.f64 	%fd536, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd537, %fd536, %fd535;
	mul.rn.f64 	%fd538, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd538, %fd537;
	add.rn.f64 	%fd539, %fd4, %fd4;
	add.rn.f64 	%fd540, %fd797, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd540, %fd539;
	{ // callseq 153, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd796;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd849, [retval0+0];
	} // callseq 153
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd797;
	}
	setp.lt.s32 	%p90, %r35, 0;
	and.pred  	%p2, %p90, %p67;
	not.pred 	%p92, %p2;
	@%p92 bra 	$L__BB13_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd849;
	}
	xor.b32  	%r171, %r170, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r172, %temp}, %fd849;
	}
	mov.b64 	%fd849, {%r172, %r171};

$L__BB13_96:
	setp.eq.f64 	%p93, %fd2, 0d0000000000000000;
	@%p93 bra 	$L__BB13_100;
	bra.uni 	$L__BB13_97;

$L__BB13_100:
	selp.b32 	%r173, %r35, 0, %p67;
	mov.u32 	%r174, 0;
	or.b32  	%r175, %r173, 2146435072;
	setp.lt.s32 	%p97, %r31, 0;
	selp.b32 	%r176, %r175, %r173, %p97;
	mov.b64 	%fd849, {%r174, %r176};
	bra.uni 	$L__BB13_101;

$L__BB13_97:
	setp.gt.s32 	%p94, %r35, -1;
	@%p94 bra 	$L__BB13_101;

	mov.f64 	%fd541, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd542, %fd541;
	setp.eq.f64 	%p95, %fd542, 0d4000000000000000;
	@%p95 bra 	$L__BB13_101;

	mov.f64 	%fd849, 0dFFF8000000000000;

$L__BB13_101:
	add.rn.f64 	%fd544, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd544;
	}
	and.b32  	%r178, %r177, 2146435072;
	setp.ne.s32 	%p98, %r178, 2146435072;
	@%p98 bra 	$L__BB13_108;

	add.rn.f64 	%fd799, %fd1, 0dC05A400000000000;
	abs.f64 	%fd798, %fd799;
	setp.gtu.f64 	%p99, %fd798, 0d7FF0000000000000;
	@%p99 bra 	$L__BB13_107;
	bra.uni 	$L__BB13_103;

$L__BB13_107:
	mov.f64 	%fd546, 0d4000000000000000;
	add.rn.f64 	%fd849, %fd2, %fd546;
	bra.uni 	$L__BB13_108;

$L__BB13_103:
	mov.f64 	%fd545, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r179, %temp}, %fd545;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p100, %r36, 2146435072;
	setp.eq.s32 	%p101, %r179, 0;
	and.pred  	%p102, %p100, %p101;
	@%p102 bra 	$L__BB13_106;
	bra.uni 	$L__BB13_104;

$L__BB13_106:
	add.rn.f64 	%fd801, %fd1, 0dC05A400000000000;
	abs.f64 	%fd800, %fd801;
	setp.gt.f64 	%p109, %fd800, 0d3FF0000000000000;
	selp.b32 	%r186, 2146435072, 0, %p109;
	mov.u32 	%r187, 0;
	xor.b32  	%r188, %r186, 2146435072;
	setp.lt.s32 	%p110, %r31, 0;
	selp.b32 	%r189, %r188, %r186, %p110;
	setp.eq.f64 	%p111, %fd801, 0dBFF0000000000000;
	selp.b32 	%r190, 1072693248, %r189, %p111;
	mov.b64 	%fd849, {%r187, %r190};
	bra.uni 	$L__BB13_108;

$L__BB13_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r180, %temp}, %fd2;
	}
	and.b32  	%r181, %r35, 2147483647;
	setp.ne.s32 	%p103, %r181, 2146435072;
	setp.ne.s32 	%p104, %r180, 0;
	or.pred  	%p105, %p103, %p104;
	@%p105 bra 	$L__BB13_108;

	setp.gt.s32 	%p106, %r31, -1;
	selp.b32 	%r182, 2146435072, 0, %p106;
	mov.u32 	%r183, 0;
	setp.ne.s32 	%p107, %r36, 1071644672;
	and.pred  	%p108, %p107, %p2;
	or.b32  	%r184, %r182, -2147483648;
	selp.b32 	%r185, %r184, %r182, %p108;
	mov.b64 	%fd849, {%r183, %r185};

$L__BB13_108:
	mul.rn.f64 	%fd547, %fd849, 0d3FB999999999999A;
	setp.eq.f64 	%p112, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd548, 0d3FB999999999999A, %fd547, %p112;
	add.rn.f64 	%fd549, %fd148, %fd548;
	add.rn.f64 	%fd550, %fd146, %fd549;
	mul.rn.f64 	%fd551, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd552, %fd551, %fd550;
	mul.rn.f64 	%fd553, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd553, %fd552;
	div.rn.f64 	%fd554, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd554, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r191, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd159;
	}
	and.b32  	%r193, %r192, 2147483647;
	setp.eq.s32 	%p113, %r193, 2146435072;
	setp.eq.s32 	%p114, %r191, 0;
	and.pred  	%p3, %p114, %p113;
	@%p3 bra 	$L__BB13_111;
	bra.uni 	$L__BB13_109;

$L__BB13_111:
	mov.f64 	%fd564, 0d0000000000000000;
	mul.rn.f64 	%fd850, %fd159, %fd564;
	mov.u32 	%r309, 0;
	bra.uni 	$L__BB13_112;

$L__BB13_109:
	mul.rn.f64 	%fd555, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r309, %fd555;
	st.local.u32 	[%rd1], %r309;
	cvt.rn.f64.s32 	%fd556, %r309;
	neg.f64 	%fd557, %fd556;
	mov.f64 	%fd558, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd559, %fd557, %fd558, %fd159;
	mov.f64 	%fd560, 0d3C91A62633145C00;
	fma.rn.f64 	%fd561, %fd557, %fd560, %fd559;
	mov.f64 	%fd562, 0d397B839A252049C0;
	fma.rn.f64 	%fd850, %fd557, %fd562, %fd561;
	abs.f64 	%fd563, %fd159;
	setp.ltu.f64 	%p115, %fd563, 0d41E0000000000000;
	@%p115 bra 	$L__BB13_112;

	add.u64 	%rd108, %SP, 0;
	{ // callseq 154, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd108;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 154
	ld.local.u32 	%r309, [%rd1];

$L__BB13_112:
	mov.u64 	%rd117, __cudart_sin_cos_coeffs;
	and.b32  	%r195, %r309, 1;
	shl.b32 	%r196, %r309, 3;
	and.b32  	%r197, %r196, 8;
	setp.eq.s32 	%p116, %r195, 0;
	selp.f64 	%fd565, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p116;
	mul.wide.s32 	%rd81, %r197, 8;
	add.s64 	%rd83, %rd117, %rd81;
	ld.global.nc.f64 	%fd566, [%rd83+8];
	mul.rn.f64 	%fd164, %fd850, %fd850;
	fma.rn.f64 	%fd567, %fd565, %fd164, %fd566;
	ld.global.nc.f64 	%fd568, [%rd83+16];
	fma.rn.f64 	%fd569, %fd567, %fd164, %fd568;
	ld.global.nc.f64 	%fd570, [%rd83+24];
	fma.rn.f64 	%fd571, %fd569, %fd164, %fd570;
	ld.global.nc.f64 	%fd572, [%rd83+32];
	fma.rn.f64 	%fd573, %fd571, %fd164, %fd572;
	ld.global.nc.f64 	%fd574, [%rd83+40];
	fma.rn.f64 	%fd575, %fd573, %fd164, %fd574;
	ld.global.nc.f64 	%fd576, [%rd83+48];
	fma.rn.f64 	%fd165, %fd575, %fd164, %fd576;
	fma.rn.f64 	%fd852, %fd165, %fd850, %fd850;
	@%p116 bra 	$L__BB13_114;

	mov.f64 	%fd577, 0d3FF0000000000000;
	fma.rn.f64 	%fd852, %fd165, %fd164, %fd577;

$L__BB13_114:
	and.b32  	%r198, %r309, 2;
	setp.eq.s32 	%p117, %r198, 0;
	@%p117 bra 	$L__BB13_116;

	mov.f64 	%fd578, 0d0000000000000000;
	mov.f64 	%fd579, 0dBFF0000000000000;
	fma.rn.f64 	%fd852, %fd852, %fd579, %fd578;

$L__BB13_116:
	@%p3 bra 	$L__BB13_120;
	bra.uni 	$L__BB13_117;

$L__BB13_120:
	mov.f64 	%fd589, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd159, %fd589;
	mov.u32 	%r311, 1;
	bra.uni 	$L__BB13_121;

$L__BB13_117:
	mul.rn.f64 	%fd580, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r310, %fd580;
	st.local.u32 	[%rd1], %r310;
	cvt.rn.f64.s32 	%fd581, %r310;
	neg.f64 	%fd582, %fd581;
	mov.f64 	%fd583, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd584, %fd582, %fd583, %fd159;
	mov.f64 	%fd585, 0d3C91A62633145C00;
	fma.rn.f64 	%fd586, %fd582, %fd585, %fd584;
	mov.f64 	%fd587, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd582, %fd587, %fd586;
	abs.f64 	%fd588, %fd159;
	setp.ltu.f64 	%p118, %fd588, 0d41E0000000000000;
	@%p118 bra 	$L__BB13_119;

	add.u64 	%rd109, %SP, 0;
	{ // callseq 155, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd109;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 155
	ld.local.u32 	%r310, [%rd1];

$L__BB13_119:
	add.s32 	%r311, %r310, 1;

$L__BB13_121:
	mov.u64 	%rd118, __cudart_sin_cos_coeffs;
	and.b32  	%r200, %r311, 1;
	shl.b32 	%r201, %r311, 3;
	and.b32  	%r202, %r201, 8;
	setp.eq.s32 	%p119, %r200, 0;
	selp.f64 	%fd590, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p119;
	mul.wide.s32 	%rd85, %r202, 8;
	add.s64 	%rd87, %rd118, %rd85;
	ld.global.nc.f64 	%fd591, [%rd87+8];
	mul.rn.f64 	%fd176, %fd854, %fd854;
	fma.rn.f64 	%fd592, %fd590, %fd176, %fd591;
	ld.global.nc.f64 	%fd593, [%rd87+16];
	fma.rn.f64 	%fd594, %fd592, %fd176, %fd593;
	ld.global.nc.f64 	%fd595, [%rd87+24];
	fma.rn.f64 	%fd596, %fd594, %fd176, %fd595;
	ld.global.nc.f64 	%fd597, [%rd87+32];
	fma.rn.f64 	%fd598, %fd596, %fd176, %fd597;
	ld.global.nc.f64 	%fd599, [%rd87+40];
	fma.rn.f64 	%fd600, %fd598, %fd176, %fd599;
	ld.global.nc.f64 	%fd601, [%rd87+48];
	fma.rn.f64 	%fd177, %fd600, %fd176, %fd601;
	fma.rn.f64 	%fd856, %fd177, %fd854, %fd854;
	@%p119 bra 	$L__BB13_123;

	mov.f64 	%fd602, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd177, %fd176, %fd602;

$L__BB13_123:
	and.b32  	%r203, %r311, 2;
	setp.eq.s32 	%p120, %r203, 0;
	@%p120 bra 	$L__BB13_125;

	mov.f64 	%fd603, 0d0000000000000000;
	mov.f64 	%fd604, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd604, %fd603;

$L__BB13_125:
	mov.u32 	%r298, %tid.x;
	mov.u32 	%r297, %ntid.x;
	mov.u32 	%r296, %ctaid.x;
	mad.lo.s32 	%r295, %r296, %r297, %r298;
	mul.wide.s32 	%rd146, %r295, 8;
	ld.param.u64 	%rd145, [wgs84_to_bd09_cuda_double_param_1];
	cvta.to.global.u64 	%rd144, %rd145;
	add.s64 	%rd143, %rd144, %rd146;
	ld.param.u64 	%rd142, [wgs84_to_bd09_cuda_double_param_0];
	cvta.to.global.u64 	%rd141, %rd142;
	add.s64 	%rd140, %rd141, %rd146;
	mul.rn.f64 	%fd605, %fd852, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd606, %fd852, %fd605;
	add.rn.f64 	%fd607, %fd606, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd608, %fd607;
	mov.f64 	%fd609, 0d415854C140000000;
	div.rn.f64 	%fd610, %fd609, %fd608;
	mul.rn.f64 	%fd611, %fd610, %fd856;
	mul.rn.f64 	%fd612, %fd611, 0d400921FB54442D18;
	mul.rn.f64 	%fd613, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd614, %fd613, %fd612;
	add.rn.f64 	%fd615, %fd1, %fd614;
	st.global.f64 	[%rd140], %fd615;
	mul.rn.f64 	%fd616, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd617, %fd608, %fd607;
	mov.f64 	%fd618, 0d41582B102DE355C1;
	div.rn.f64 	%fd619, %fd618, %fd617;
	mul.rn.f64 	%fd620, %fd619, 0d400921FB54442D18;
	div.rn.f64 	%fd621, %fd616, %fd620;
	add.rn.f64 	%fd183, %fd3, %fd621;
	st.global.f64 	[%rd143], %fd183;
	ld.global.f64 	%fd184, [%rd140];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd184;
	}
	abs.f64 	%fd185, %fd184;
	{ // callseq 156, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd185;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd859, [retval0+0];
	} // callseq 156
	setp.lt.s32 	%p121, %r45, 0;
	and.pred  	%p4, %p121, %p67;
	not.pred 	%p123, %p4;
	@%p123 bra 	$L__BB13_127;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd859;
	}
	xor.b32  	%r205, %r204, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r206, %temp}, %fd859;
	}
	mov.b64 	%fd859, {%r206, %r205};

$L__BB13_127:
	setp.eq.f64 	%p124, %fd184, 0d0000000000000000;
	@%p124 bra 	$L__BB13_131;
	bra.uni 	$L__BB13_128;

$L__BB13_131:
	selp.b32 	%r207, %r45, 0, %p67;
	mov.u32 	%r208, 0;
	or.b32  	%r209, %r207, 2146435072;
	setp.lt.s32 	%p128, %r31, 0;
	selp.b32 	%r210, %r209, %r207, %p128;
	mov.b64 	%fd859, {%r208, %r210};
	bra.uni 	$L__BB13_132;

$L__BB13_128:
	setp.gt.s32 	%p125, %r45, -1;
	@%p125 bra 	$L__BB13_132;

	mov.f64 	%fd622, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd623, %fd622;
	setp.eq.f64 	%p126, %fd623, 0d4000000000000000;
	@%p126 bra 	$L__BB13_132;

	mov.f64 	%fd859, 0dFFF8000000000000;

$L__BB13_132:
	add.rn.f64 	%fd625, %fd184, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r211}, %fd625;
	}
	and.b32  	%r212, %r211, 2146435072;
	setp.ne.s32 	%p129, %r212, 2146435072;
	@%p129 bra 	$L__BB13_139;

	setp.gtu.f64 	%p130, %fd185, 0d7FF0000000000000;
	@%p130 bra 	$L__BB13_138;
	bra.uni 	$L__BB13_134;

$L__BB13_138:
	mov.f64 	%fd627, 0d4000000000000000;
	add.rn.f64 	%fd859, %fd184, %fd627;
	bra.uni 	$L__BB13_139;

$L__BB13_134:
	mov.f64 	%fd626, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd626;
	}
	and.b32  	%r46, %r31, 2147483647;
	setp.eq.s32 	%p131, %r46, 2146435072;
	setp.eq.s32 	%p132, %r213, 0;
	and.pred  	%p133, %p131, %p132;
	@%p133 bra 	$L__BB13_137;
	bra.uni 	$L__BB13_135;

$L__BB13_137:
	setp.gt.f64 	%p140, %fd185, 0d3FF0000000000000;
	selp.b32 	%r220, 2146435072, 0, %p140;
	mov.u32 	%r221, 0;
	xor.b32  	%r222, %r220, 2146435072;
	setp.lt.s32 	%p141, %r31, 0;
	selp.b32 	%r223, %r222, %r220, %p141;
	setp.eq.f64 	%p142, %fd184, 0dBFF0000000000000;
	selp.b32 	%r224, 1072693248, %r223, %p142;
	mov.b64 	%fd859, {%r221, %r224};
	bra.uni 	$L__BB13_139;

$L__BB13_135:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd184;
	}
	and.b32  	%r215, %r45, 2147483647;
	setp.ne.s32 	%p134, %r215, 2146435072;
	setp.ne.s32 	%p135, %r214, 0;
	or.pred  	%p136, %p134, %p135;
	@%p136 bra 	$L__BB13_139;

	setp.gt.s32 	%p137, %r31, -1;
	selp.b32 	%r216, 2146435072, 0, %p137;
	mov.u32 	%r217, 0;
	setp.ne.s32 	%p138, %r46, 1071644672;
	and.pred  	%p139, %p138, %p4;
	or.b32  	%r218, %r216, -2147483648;
	selp.b32 	%r219, %r218, %r216, %p139;
	mov.b64 	%fd859, {%r217, %r219};

$L__BB13_139:
	abs.f64 	%fd195, %fd183;
	{ // callseq 157, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd195;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd862, [retval0+0];
	} // callseq 157
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r47}, %fd183;
	}
	setp.lt.s32 	%p143, %r47, 0;
	and.pred  	%p5, %p143, %p67;
	not.pred 	%p145, %p5;
	@%p145 bra 	$L__BB13_141;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd862;
	}
	xor.b32  	%r226, %r225, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r227, %temp}, %fd862;
	}
	mov.b64 	%fd862, {%r227, %r226};

$L__BB13_141:
	setp.eq.f64 	%p146, %fd183, 0d0000000000000000;
	@%p146 bra 	$L__BB13_145;
	bra.uni 	$L__BB13_142;

$L__BB13_145:
	selp.b32 	%r228, %r47, 0, %p67;
	mov.u32 	%r229, 0;
	or.b32  	%r230, %r228, 2146435072;
	setp.lt.s32 	%p150, %r31, 0;
	selp.b32 	%r231, %r230, %r228, %p150;
	mov.b64 	%fd862, {%r229, %r231};
	bra.uni 	$L__BB13_146;

$L__BB13_142:
	setp.gt.s32 	%p147, %r47, -1;
	@%p147 bra 	$L__BB13_146;

	mov.f64 	%fd628, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd629, %fd628;
	setp.eq.f64 	%p148, %fd629, 0d4000000000000000;
	@%p148 bra 	$L__BB13_146;

	mov.f64 	%fd862, 0dFFF8000000000000;

$L__BB13_146:
	add.rn.f64 	%fd631, %fd183, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd631;
	}
	and.b32  	%r233, %r232, 2146435072;
	setp.ne.s32 	%p151, %r233, 2146435072;
	@%p151 bra 	$L__BB13_153;

	setp.gtu.f64 	%p152, %fd195, 0d7FF0000000000000;
	@%p152 bra 	$L__BB13_152;
	bra.uni 	$L__BB13_148;

$L__BB13_152:
	mov.f64 	%fd633, 0d4000000000000000;
	add.rn.f64 	%fd862, %fd183, %fd633;
	bra.uni 	$L__BB13_153;

$L__BB13_148:
	mov.f64 	%fd632, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd632;
	}
	and.b32  	%r48, %r31, 2147483647;
	setp.eq.s32 	%p153, %r48, 2146435072;
	setp.eq.s32 	%p154, %r234, 0;
	and.pred  	%p155, %p153, %p154;
	@%p155 bra 	$L__BB13_151;
	bra.uni 	$L__BB13_149;

$L__BB13_151:
	setp.gt.f64 	%p162, %fd195, 0d3FF0000000000000;
	selp.b32 	%r241, 2146435072, 0, %p162;
	mov.u32 	%r242, 0;
	xor.b32  	%r243, %r241, 2146435072;
	setp.lt.s32 	%p163, %r31, 0;
	selp.b32 	%r244, %r243, %r241, %p163;
	setp.eq.f64 	%p164, %fd183, 0dBFF0000000000000;
	selp.b32 	%r245, 1072693248, %r244, %p164;
	mov.b64 	%fd862, {%r242, %r245};
	bra.uni 	$L__BB13_153;

$L__BB13_149:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd183;
	}
	and.b32  	%r236, %r47, 2147483647;
	setp.ne.s32 	%p156, %r236, 2146435072;
	setp.ne.s32 	%p157, %r235, 0;
	or.pred  	%p158, %p156, %p157;
	@%p158 bra 	$L__BB13_153;

	setp.gt.s32 	%p159, %r31, -1;
	selp.b32 	%r237, 2146435072, 0, %p159;
	mov.u32 	%r238, 0;
	setp.ne.s32 	%p160, %r48, 1071644672;
	and.pred  	%p161, %p160, %p5;
	or.b32  	%r239, %r237, -2147483648;
	selp.b32 	%r240, %r239, %r237, %p161;
	mov.b64 	%fd862, {%r238, %r240};

$L__BB13_153:
	setp.eq.f64 	%p165, %fd183, 0d3FF0000000000000;
	selp.f64 	%fd634, 0d3FF0000000000000, %fd862, %p165;
	setp.eq.f64 	%p166, %fd184, 0d3FF0000000000000;
	selp.f64 	%fd635, 0d3FF0000000000000, %fd859, %p166;
	add.rn.f64 	%fd205, %fd635, %fd634;
	mul.rn.f64 	%fd206, %fd183, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r246, %temp}, %fd206;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd206;
	}
	and.b32  	%r248, %r247, 2147483647;
	setp.eq.s32 	%p167, %r248, 2146435072;
	setp.eq.s32 	%p168, %r246, 0;
	and.pred  	%p169, %p168, %p167;
	@%p169 bra 	$L__BB13_156;
	bra.uni 	$L__BB13_154;

$L__BB13_156:
	mov.f64 	%fd645, 0d0000000000000000;
	mul.rn.f64 	%fd863, %fd206, %fd645;
	mov.u32 	%r312, 0;
	bra.uni 	$L__BB13_157;

$L__BB13_154:
	mul.rn.f64 	%fd636, %fd206, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r312, %fd636;
	st.local.u32 	[%rd1], %r312;
	cvt.rn.f64.s32 	%fd637, %r312;
	neg.f64 	%fd638, %fd637;
	mov.f64 	%fd639, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd640, %fd638, %fd639, %fd206;
	mov.f64 	%fd641, 0d3C91A62633145C00;
	fma.rn.f64 	%fd642, %fd638, %fd641, %fd640;
	mov.f64 	%fd643, 0d397B839A252049C0;
	fma.rn.f64 	%fd863, %fd638, %fd643, %fd642;
	abs.f64 	%fd644, %fd206;
	setp.ltu.f64 	%p170, %fd644, 0d41E0000000000000;
	@%p170 bra 	$L__BB13_157;

	add.u64 	%rd110, %SP, 0;
	{ // callseq 158, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd206;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd110;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd863, [retval0+0];
	} // callseq 158
	ld.local.u32 	%r312, [%rd1];

$L__BB13_157:
	mov.u64 	%rd119, __cudart_sin_cos_coeffs;
	and.b32  	%r250, %r312, 1;
	shl.b32 	%r251, %r312, 3;
	and.b32  	%r252, %r251, 8;
	setp.eq.s32 	%p171, %r250, 0;
	selp.f64 	%fd646, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p171;
	mul.wide.s32 	%rd89, %r252, 8;
	add.s64 	%rd91, %rd119, %rd89;
	ld.global.nc.f64 	%fd647, [%rd91+8];
	mul.rn.f64 	%fd211, %fd863, %fd863;
	fma.rn.f64 	%fd648, %fd646, %fd211, %fd647;
	ld.global.nc.f64 	%fd649, [%rd91+16];
	fma.rn.f64 	%fd650, %fd648, %fd211, %fd649;
	ld.global.nc.f64 	%fd651, [%rd91+24];
	fma.rn.f64 	%fd652, %fd650, %fd211, %fd651;
	ld.global.nc.f64 	%fd653, [%rd91+32];
	fma.rn.f64 	%fd654, %fd652, %fd211, %fd653;
	ld.global.nc.f64 	%fd655, [%rd91+40];
	fma.rn.f64 	%fd656, %fd654, %fd211, %fd655;
	ld.global.nc.f64 	%fd657, [%rd91+48];
	fma.rn.f64 	%fd212, %fd656, %fd211, %fd657;
	fma.rn.f64 	%fd865, %fd212, %fd863, %fd863;
	@%p171 bra 	$L__BB13_159;

	mov.f64 	%fd658, 0d3FF0000000000000;
	fma.rn.f64 	%fd865, %fd212, %fd211, %fd658;

$L__BB13_159:
	and.b32  	%r253, %r312, 2;
	setp.eq.s32 	%p172, %r253, 0;
	@%p172 bra 	$L__BB13_161;

	mov.f64 	%fd659, 0d0000000000000000;
	mov.f64 	%fd660, 0dBFF0000000000000;
	fma.rn.f64 	%fd865, %fd865, %fd660, %fd659;

$L__BB13_161:
	mul.rn.f64 	%fd661, %fd865, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd662, %fd205;
	add.rn.f64 	%fd218, %fd662, %fd661;
	setp.eq.f64 	%p173, %fd195, 0d0000000000000000;
	setp.eq.f64 	%p174, %fd185, 0d0000000000000000;
	and.pred  	%p175, %p174, %p173;
	@%p175 bra 	$L__BB13_165;
	bra.uni 	$L__BB13_162;

$L__BB13_165:
	selp.f64 	%fd715, 0d400921FB54442D18, 0d0000000000000000, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd715;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r263}, %fd715;
	}
	and.b32  	%r264, %r47, -2147483648;
	or.b32  	%r265, %r263, %r264;
	mov.b64 	%fd866, {%r262, %r265};
	bra.uni 	$L__BB13_166;

$L__BB13_162:
	setp.eq.f64 	%p176, %fd185, 0d7FF0000000000000;
	setp.eq.f64 	%p177, %fd195, 0d7FF0000000000000;
	and.pred  	%p178, %p176, %p177;
	@%p178 bra 	$L__BB13_164;
	bra.uni 	$L__BB13_163;

$L__BB13_164:
	selp.f64 	%fd714, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r258, %temp}, %fd714;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd714;
	}
	and.b32  	%r260, %r47, -2147483648;
	or.b32  	%r261, %r259, %r260;
	mov.b64 	%fd866, {%r258, %r261};
	bra.uni 	$L__BB13_166;

$L__BB13_163:
	min.f64 	%fd663, %fd195, %fd185;
	max.f64 	%fd664, %fd195, %fd185;
	div.rn.f64 	%fd665, %fd663, %fd664;
	mul.rn.f64 	%fd666, %fd665, %fd665;
	mov.f64 	%fd667, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd668, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd669, %fd668, %fd666, %fd667;
	mov.f64 	%fd670, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd671, %fd669, %fd666, %fd670;
	mov.f64 	%fd672, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd673, %fd671, %fd666, %fd672;
	mov.f64 	%fd674, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd675, %fd673, %fd666, %fd674;
	mov.f64 	%fd676, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd677, %fd675, %fd666, %fd676;
	mov.f64 	%fd678, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd679, %fd677, %fd666, %fd678;
	mov.f64 	%fd680, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd681, %fd679, %fd666, %fd680;
	mov.f64 	%fd682, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd683, %fd681, %fd666, %fd682;
	mov.f64 	%fd684, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd685, %fd683, %fd666, %fd684;
	mov.f64 	%fd686, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd687, %fd685, %fd666, %fd686;
	mov.f64 	%fd688, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd689, %fd687, %fd666, %fd688;
	mov.f64 	%fd690, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd691, %fd689, %fd666, %fd690;
	mov.f64 	%fd692, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd693, %fd691, %fd666, %fd692;
	mov.f64 	%fd694, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd695, %fd693, %fd666, %fd694;
	mov.f64 	%fd696, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd697, %fd695, %fd666, %fd696;
	mov.f64 	%fd698, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd699, %fd697, %fd666, %fd698;
	mov.f64 	%fd700, 0d3FC99999999840D2;
	fma.rn.f64 	%fd701, %fd699, %fd666, %fd700;
	mov.f64 	%fd702, 0dBFD555555555544C;
	fma.rn.f64 	%fd703, %fd701, %fd666, %fd702;
	mul.rn.f64 	%fd704, %fd666, %fd703;
	fma.rn.f64 	%fd705, %fd704, %fd665, %fd665;
	mov.f64 	%fd706, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd707, %fd706, %fd705;
	setp.gt.f64 	%p180, %fd195, %fd185;
	selp.f64 	%fd708, %fd707, %fd705, %p180;
	mov.f64 	%fd709, 0d400921FB54442D18;
	sub.rn.f64 	%fd710, %fd709, %fd708;
	selp.f64 	%fd711, %fd710, %fd708, %p121;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r254, %temp}, %fd711;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r255}, %fd711;
	}
	and.b32  	%r256, %r47, -2147483648;
	or.b32  	%r257, %r255, %r256;
	mov.b64 	%fd712, {%r254, %r257};
	add.rn.f64 	%fd713, %fd185, %fd195;
	setp.le.f64 	%p181, %fd713, 0d7FF0000000000000;
	selp.f64 	%fd866, %fd712, %fd713, %p181;

$L__BB13_166:
	mul.rn.f64 	%fd223, %fd184, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r266, %temp}, %fd223;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd223;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p184, %r268, 2146435072;
	setp.eq.s32 	%p185, %r266, 0;
	and.pred  	%p186, %p185, %p184;
	@%p186 bra 	$L__BB13_170;
	bra.uni 	$L__BB13_167;

$L__BB13_170:
	mov.f64 	%fd725, 0d0000000000000000;
	mul.rn.f64 	%fd868, %fd223, %fd725;
	mov.u32 	%r314, 1;
	bra.uni 	$L__BB13_171;

$L__BB13_167:
	mul.rn.f64 	%fd716, %fd223, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r313, %fd716;
	st.local.u32 	[%rd1], %r313;
	cvt.rn.f64.s32 	%fd717, %r313;
	neg.f64 	%fd718, %fd717;
	mov.f64 	%fd719, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd720, %fd718, %fd719, %fd223;
	mov.f64 	%fd721, 0d3C91A62633145C00;
	fma.rn.f64 	%fd722, %fd718, %fd721, %fd720;
	mov.f64 	%fd723, 0d397B839A252049C0;
	fma.rn.f64 	%fd868, %fd718, %fd723, %fd722;
	abs.f64 	%fd724, %fd223;
	setp.ltu.f64 	%p187, %fd724, 0d41E0000000000000;
	@%p187 bra 	$L__BB13_169;

	add.u64 	%rd111, %SP, 0;
	{ // callseq 159, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd223;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd111;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd868, [retval0+0];
	} // callseq 159
	ld.local.u32 	%r313, [%rd1];

$L__BB13_169:
	add.s32 	%r314, %r313, 1;

$L__BB13_171:
	mov.u64 	%rd120, __cudart_sin_cos_coeffs;
	and.b32  	%r270, %r314, 1;
	shl.b32 	%r271, %r314, 3;
	and.b32  	%r272, %r271, 8;
	setp.eq.s32 	%p188, %r270, 0;
	selp.f64 	%fd726, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p188;
	mul.wide.s32 	%rd93, %r272, 8;
	add.s64 	%rd95, %rd120, %rd93;
	ld.global.nc.f64 	%fd727, [%rd95+8];
	mul.rn.f64 	%fd229, %fd868, %fd868;
	fma.rn.f64 	%fd728, %fd726, %fd229, %fd727;
	ld.global.nc.f64 	%fd729, [%rd95+16];
	fma.rn.f64 	%fd730, %fd728, %fd229, %fd729;
	ld.global.nc.f64 	%fd731, [%rd95+24];
	fma.rn.f64 	%fd732, %fd730, %fd229, %fd731;
	ld.global.nc.f64 	%fd733, [%rd95+32];
	fma.rn.f64 	%fd734, %fd732, %fd229, %fd733;
	ld.global.nc.f64 	%fd735, [%rd95+40];
	fma.rn.f64 	%fd736, %fd734, %fd229, %fd735;
	ld.global.nc.f64 	%fd737, [%rd95+48];
	fma.rn.f64 	%fd230, %fd736, %fd229, %fd737;
	fma.rn.f64 	%fd870, %fd230, %fd868, %fd868;
	@%p188 bra 	$L__BB13_173;

	mov.f64 	%fd738, 0d3FF0000000000000;
	fma.rn.f64 	%fd870, %fd230, %fd229, %fd738;

$L__BB13_173:
	and.b32  	%r273, %r314, 2;
	setp.eq.s32 	%p189, %r273, 0;
	@%p189 bra 	$L__BB13_175;

	mov.f64 	%fd739, 0d0000000000000000;
	mov.f64 	%fd740, 0dBFF0000000000000;
	fma.rn.f64 	%fd870, %fd870, %fd740, %fd739;

$L__BB13_175:
	mul.rn.f64 	%fd741, %fd870, 0d3EC92A737110E454;
	add.rn.f64 	%fd236, %fd866, %fd741;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd236;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd236;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p190, %r276, 2146435072;
	setp.eq.s32 	%p191, %r274, 0;
	and.pred  	%p6, %p191, %p190;
	@%p6 bra 	$L__BB13_179;
	bra.uni 	$L__BB13_176;

$L__BB13_179:
	mov.f64 	%fd751, 0d0000000000000000;
	mul.rn.f64 	%fd872, %fd236, %fd751;
	mov.u32 	%r316, 1;
	bra.uni 	$L__BB13_180;

$L__BB13_176:
	mul.rn.f64 	%fd742, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r315, %fd742;
	st.local.u32 	[%rd1], %r315;
	cvt.rn.f64.s32 	%fd743, %r315;
	neg.f64 	%fd744, %fd743;
	mov.f64 	%fd745, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd746, %fd744, %fd745, %fd236;
	mov.f64 	%fd747, 0d3C91A62633145C00;
	fma.rn.f64 	%fd748, %fd744, %fd747, %fd746;
	mov.f64 	%fd749, 0d397B839A252049C0;
	fma.rn.f64 	%fd872, %fd744, %fd749, %fd748;
	abs.f64 	%fd750, %fd236;
	setp.ltu.f64 	%p192, %fd750, 0d41E0000000000000;
	@%p192 bra 	$L__BB13_178;

	add.u64 	%rd112, %SP, 0;
	{ // callseq 160, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd112;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd872, [retval0+0];
	} // callseq 160
	ld.local.u32 	%r315, [%rd1];

$L__BB13_178:
	add.s32 	%r316, %r315, 1;

$L__BB13_180:
	mov.u64 	%rd121, __cudart_sin_cos_coeffs;
	and.b32  	%r278, %r316, 1;
	shl.b32 	%r279, %r316, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p193, %r278, 0;
	selp.f64 	%fd752, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p193;
	mul.wide.s32 	%rd97, %r280, 8;
	add.s64 	%rd99, %rd121, %rd97;
	ld.global.nc.f64 	%fd753, [%rd99+8];
	mul.rn.f64 	%fd242, %fd872, %fd872;
	fma.rn.f64 	%fd754, %fd752, %fd242, %fd753;
	ld.global.nc.f64 	%fd755, [%rd99+16];
	fma.rn.f64 	%fd756, %fd754, %fd242, %fd755;
	ld.global.nc.f64 	%fd757, [%rd99+24];
	fma.rn.f64 	%fd758, %fd756, %fd242, %fd757;
	ld.global.nc.f64 	%fd759, [%rd99+32];
	fma.rn.f64 	%fd760, %fd758, %fd242, %fd759;
	ld.global.nc.f64 	%fd761, [%rd99+40];
	fma.rn.f64 	%fd762, %fd760, %fd242, %fd761;
	ld.global.nc.f64 	%fd763, [%rd99+48];
	fma.rn.f64 	%fd243, %fd762, %fd242, %fd763;
	fma.rn.f64 	%fd874, %fd243, %fd872, %fd872;
	@%p193 bra 	$L__BB13_182;

	mov.f64 	%fd764, 0d3FF0000000000000;
	fma.rn.f64 	%fd874, %fd243, %fd242, %fd764;

$L__BB13_182:
	and.b32  	%r281, %r316, 2;
	setp.eq.s32 	%p194, %r281, 0;
	@%p194 bra 	$L__BB13_184;

	mov.f64 	%fd765, 0d0000000000000000;
	mov.f64 	%fd766, 0dBFF0000000000000;
	fma.rn.f64 	%fd874, %fd874, %fd766, %fd765;

$L__BB13_184:
	ld.param.u64 	%rd126, [wgs84_to_bd09_cuda_double_param_0];
	mov.u32 	%r290, %tid.x;
	mov.u32 	%r289, %ntid.x;
	mov.u32 	%r288, %ctaid.x;
	mad.lo.s32 	%r287, %r288, %r289, %r290;
	mul.wide.s32 	%rd125, %r287, 8;
	cvta.to.global.u64 	%rd124, %rd126;
	add.s64 	%rd123, %rd124, %rd125;
	mul.rn.f64 	%fd767, %fd218, %fd874;
	add.rn.f64 	%fd768, %fd767, 0d3F7A9FBE76C8B439;
	st.global.f64 	[%rd123], %fd768;
	@%p6 bra 	$L__BB13_187;
	bra.uni 	$L__BB13_185;

$L__BB13_187:
	mov.f64 	%fd778, 0d0000000000000000;
	mul.rn.f64 	%fd875, %fd236, %fd778;
	mov.u32 	%r317, 0;
	bra.uni 	$L__BB13_188;

$L__BB13_185:
	mul.rn.f64 	%fd769, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r317, %fd769;
	st.local.u32 	[%rd1], %r317;
	cvt.rn.f64.s32 	%fd770, %r317;
	neg.f64 	%fd771, %fd770;
	mov.f64 	%fd772, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd773, %fd771, %fd772, %fd236;
	mov.f64 	%fd774, 0d3C91A62633145C00;
	fma.rn.f64 	%fd775, %fd771, %fd774, %fd773;
	mov.f64 	%fd776, 0d397B839A252049C0;
	fma.rn.f64 	%fd875, %fd771, %fd776, %fd775;
	abs.f64 	%fd777, %fd236;
	setp.ltu.f64 	%p195, %fd777, 0d41E0000000000000;
	@%p195 bra 	$L__BB13_188;

	add.u64 	%rd113, %SP, 0;
	{ // callseq 161, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd113;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd875, [retval0+0];
	} // callseq 161
	ld.local.u32 	%r317, [%rd1];

$L__BB13_188:
	mov.u64 	%rd122, __cudart_sin_cos_coeffs;
	and.b32  	%r283, %r317, 1;
	shl.b32 	%r284, %r317, 3;
	and.b32  	%r285, %r284, 8;
	setp.eq.s32 	%p196, %r283, 0;
	selp.f64 	%fd779, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd101, %r285, 8;
	add.s64 	%rd103, %rd122, %rd101;
	ld.global.nc.f64 	%fd780, [%rd103+8];
	mul.rn.f64 	%fd253, %fd875, %fd875;
	fma.rn.f64 	%fd781, %fd779, %fd253, %fd780;
	ld.global.nc.f64 	%fd782, [%rd103+16];
	fma.rn.f64 	%fd783, %fd781, %fd253, %fd782;
	ld.global.nc.f64 	%fd784, [%rd103+24];
	fma.rn.f64 	%fd785, %fd783, %fd253, %fd784;
	ld.global.nc.f64 	%fd786, [%rd103+32];
	fma.rn.f64 	%fd787, %fd785, %fd253, %fd786;
	ld.global.nc.f64 	%fd788, [%rd103+40];
	fma.rn.f64 	%fd789, %fd787, %fd253, %fd788;
	ld.global.nc.f64 	%fd790, [%rd103+48];
	fma.rn.f64 	%fd254, %fd789, %fd253, %fd790;
	fma.rn.f64 	%fd877, %fd254, %fd875, %fd875;
	@%p196 bra 	$L__BB13_190;

	mov.f64 	%fd791, 0d3FF0000000000000;
	fma.rn.f64 	%fd877, %fd254, %fd253, %fd791;

$L__BB13_190:
	and.b32  	%r286, %r317, 2;
	setp.eq.s32 	%p197, %r286, 0;
	@%p197 bra 	$L__BB13_192;

	mov.f64 	%fd792, 0d0000000000000000;
	mov.f64 	%fd793, 0dBFF0000000000000;
	fma.rn.f64 	%fd877, %fd877, %fd793, %fd792;

$L__BB13_192:
	ld.param.u64 	%rd130, [wgs84_to_bd09_cuda_double_param_1];
	mov.u32 	%r294, %tid.x;
	mov.u32 	%r293, %ntid.x;
	mov.u32 	%r292, %ctaid.x;
	mad.lo.s32 	%r291, %r292, %r293, %r294;
	mul.wide.s32 	%rd129, %r291, 8;
	cvta.to.global.u64 	%rd128, %rd130;
	add.s64 	%rd127, %rd128, %rd129;
	mul.rn.f64 	%fd794, %fd218, %fd877;
	add.rn.f64 	%fd795, %fd794, 0d3F789374BC6A7EFA;
	st.global.f64 	[%rd127], %fd795;
	ret;

}
	// .globl	bd09_to_wgs84_cuda_double
.visible .entry bd09_to_wgs84_cuda_double(
	.param .u64 bd09_to_wgs84_cuda_double_param_0,
	.param .u64 bd09_to_wgs84_cuda_double_param_1
)
{
	.local .align 4 .b8 	__local_depot14[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<198>;
	.reg .b32 	%r<306>;
	.reg .f64 	%fd<861>;
	.reg .b64 	%rd<104>;


	mov.u64 	%SPL, __local_depot14;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd19, [bd09_to_wgs84_cuda_double_param_0];
	ld.param.u64 	%rd20, [bd09_to_wgs84_cuda_double_param_1];
	cvta.to.global.u64 	%rd21, %rd20;
	add.u64 	%rd22, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd38, %rd19;
	mul.wide.s32 	%rd39, %r68, 8;
	add.s64 	%rd17, %rd38, %rd39;
	add.s64 	%rd18, %rd21, %rd39;
	ld.global.f64 	%fd260, [%rd17];
	add.rn.f64 	%fd1, %fd260, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd261, [%rd18];
	add.rn.f64 	%fd2, %fd261, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd1;
	}
	mov.f64 	%fd262, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd262;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p7, %r3, 1062207488;
	abs.f64 	%fd3, %fd1;
	{ // callseq 162, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd3;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd799, [retval0+0];
	} // callseq 162
	setp.lt.s32 	%p8, %r1, 0;
	and.pred  	%p1, %p8, %p7;
	not.pred 	%p9, %p1;
	@%p9 bra 	$L__BB14_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd799;
	}
	xor.b32  	%r70, %r69, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd799;
	}
	mov.b64 	%fd799, {%r71, %r70};

$L__BB14_2:
	setp.eq.f64 	%p10, %fd1, 0d0000000000000000;
	@%p10 bra 	$L__BB14_6;
	bra.uni 	$L__BB14_3;

$L__BB14_6:
	selp.b32 	%r72, %r1, 0, %p7;
	mov.u32 	%r73, 0;
	or.b32  	%r74, %r72, 2146435072;
	setp.lt.s32 	%p14, %r2, 0;
	selp.b32 	%r75, %r74, %r72, %p14;
	mov.b64 	%fd799, {%r73, %r75};
	bra.uni 	$L__BB14_7;

$L__BB14_3:
	setp.gt.s32 	%p11, %r1, -1;
	@%p11 bra 	$L__BB14_7;

	mov.f64 	%fd263, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd264, %fd263;
	setp.eq.f64 	%p12, %fd264, 0d4000000000000000;
	@%p12 bra 	$L__BB14_7;

	mov.f64 	%fd799, 0dFFF8000000000000;

$L__BB14_7:
	add.rn.f64 	%fd266, %fd1, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd266;
	}
	and.b32  	%r77, %r76, 2146435072;
	setp.ne.s32 	%p15, %r77, 2146435072;
	@%p15 bra 	$L__BB14_14;

	setp.gtu.f64 	%p16, %fd3, 0d7FF0000000000000;
	@%p16 bra 	$L__BB14_13;
	bra.uni 	$L__BB14_9;

$L__BB14_13:
	mov.f64 	%fd268, 0d4000000000000000;
	add.rn.f64 	%fd799, %fd1, %fd268;
	bra.uni 	$L__BB14_14;

$L__BB14_9:
	mov.f64 	%fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd267;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p17, %r4, 2146435072;
	setp.eq.s32 	%p18, %r78, 0;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB14_12;
	bra.uni 	$L__BB14_10;

$L__BB14_12:
	setp.gt.f64 	%p26, %fd3, 0d3FF0000000000000;
	selp.b32 	%r85, 2146435072, 0, %p26;
	mov.u32 	%r86, 0;
	xor.b32  	%r87, %r85, 2146435072;
	setp.lt.s32 	%p27, %r2, 0;
	selp.b32 	%r88, %r87, %r85, %p27;
	setp.eq.f64 	%p28, %fd1, 0dBFF0000000000000;
	selp.b32 	%r89, 1072693248, %r88, %p28;
	mov.b64 	%fd799, {%r86, %r89};
	bra.uni 	$L__BB14_14;

$L__BB14_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd1;
	}
	and.b32  	%r80, %r1, 2147483647;
	setp.ne.s32 	%p20, %r80, 2146435072;
	setp.ne.s32 	%p21, %r79, 0;
	or.pred  	%p22, %p20, %p21;
	@%p22 bra 	$L__BB14_14;

	setp.gt.s32 	%p23, %r2, -1;
	selp.b32 	%r81, 2146435072, 0, %p23;
	mov.u32 	%r82, 0;
	setp.ne.s32 	%p24, %r4, 1071644672;
	and.pred  	%p25, %p24, %p1;
	or.b32  	%r83, %r81, -2147483648;
	selp.b32 	%r84, %r83, %r81, %p25;
	mov.b64 	%fd799, {%r82, %r84};

$L__BB14_14:
	abs.f64 	%fd13, %fd2;
	{ // callseq 163, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd13;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd802, [retval0+0];
	} // callseq 163
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd2;
	}
	setp.lt.s32 	%p29, %r5, 0;
	and.pred  	%p2, %p29, %p7;
	not.pred 	%p31, %p2;
	@%p31 bra 	$L__BB14_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd802;
	}
	xor.b32  	%r91, %r90, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r92, %temp}, %fd802;
	}
	mov.b64 	%fd802, {%r92, %r91};

$L__BB14_16:
	setp.eq.f64 	%p32, %fd2, 0d0000000000000000;
	@%p32 bra 	$L__BB14_20;
	bra.uni 	$L__BB14_17;

$L__BB14_20:
	selp.b32 	%r93, %r5, 0, %p7;
	mov.u32 	%r94, 0;
	or.b32  	%r95, %r93, 2146435072;
	setp.lt.s32 	%p36, %r2, 0;
	selp.b32 	%r96, %r95, %r93, %p36;
	mov.b64 	%fd802, {%r94, %r96};
	bra.uni 	$L__BB14_21;

$L__BB14_17:
	setp.gt.s32 	%p33, %r5, -1;
	@%p33 bra 	$L__BB14_21;

	mov.f64 	%fd269, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd270, %fd269;
	setp.eq.f64 	%p34, %fd270, 0d4000000000000000;
	@%p34 bra 	$L__BB14_21;

	mov.f64 	%fd802, 0dFFF8000000000000;

$L__BB14_21:
	add.rn.f64 	%fd272, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd272;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32 	%p37, %r98, 2146435072;
	@%p37 bra 	$L__BB14_28;

	setp.gtu.f64 	%p38, %fd13, 0d7FF0000000000000;
	@%p38 bra 	$L__BB14_27;
	bra.uni 	$L__BB14_23;

$L__BB14_27:
	mov.f64 	%fd274, 0d4000000000000000;
	add.rn.f64 	%fd802, %fd2, %fd274;
	bra.uni 	$L__BB14_28;

$L__BB14_23:
	mov.f64 	%fd273, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd273;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p39, %r6, 2146435072;
	setp.eq.s32 	%p40, %r99, 0;
	and.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB14_26;
	bra.uni 	$L__BB14_24;

$L__BB14_26:
	setp.gt.f64 	%p48, %fd13, 0d3FF0000000000000;
	selp.b32 	%r106, 2146435072, 0, %p48;
	mov.u32 	%r107, 0;
	xor.b32  	%r108, %r106, 2146435072;
	setp.lt.s32 	%p49, %r2, 0;
	selp.b32 	%r109, %r108, %r106, %p49;
	setp.eq.f64 	%p50, %fd2, 0dBFF0000000000000;
	selp.b32 	%r110, 1072693248, %r109, %p50;
	mov.b64 	%fd802, {%r107, %r110};
	bra.uni 	$L__BB14_28;

$L__BB14_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd2;
	}
	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32 	%p42, %r101, 2146435072;
	setp.ne.s32 	%p43, %r100, 0;
	or.pred  	%p44, %p42, %p43;
	@%p44 bra 	$L__BB14_28;

	setp.gt.s32 	%p45, %r2, -1;
	selp.b32 	%r102, 2146435072, 0, %p45;
	mov.u32 	%r103, 0;
	setp.ne.s32 	%p46, %r6, 1071644672;
	and.pred  	%p47, %p46, %p2;
	or.b32  	%r104, %r102, -2147483648;
	selp.b32 	%r105, %r104, %r102, %p47;
	mov.b64 	%fd802, {%r103, %r105};

$L__BB14_28:
	setp.eq.f64 	%p51, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd275, 0d3FF0000000000000, %fd802, %p51;
	setp.eq.f64 	%p52, %fd1, 0d3FF0000000000000;
	selp.f64 	%fd276, 0d3FF0000000000000, %fd799, %p52;
	add.rn.f64 	%fd23, %fd276, %fd275;
	mul.rn.f64 	%fd24, %fd2, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd24;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd24;
	}
	and.b32  	%r113, %r112, 2147483647;
	setp.eq.s32 	%p53, %r113, 2146435072;
	setp.eq.s32 	%p54, %r111, 0;
	and.pred  	%p55, %p54, %p53;
	@%p55 bra 	$L__BB14_31;
	bra.uni 	$L__BB14_29;

$L__BB14_31:
	mov.f64 	%fd286, 0d0000000000000000;
	mul.rn.f64 	%fd803, %fd24, %fd286;
	mov.u32 	%r287, 0;
	bra.uni 	$L__BB14_32;

$L__BB14_29:
	mul.rn.f64 	%fd277, %fd24, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r287, %fd277;
	st.local.u32 	[%rd1], %r287;
	cvt.rn.f64.s32 	%fd278, %r287;
	neg.f64 	%fd279, %fd278;
	mov.f64 	%fd280, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd281, %fd279, %fd280, %fd24;
	mov.f64 	%fd282, 0d3C91A62633145C00;
	fma.rn.f64 	%fd283, %fd279, %fd282, %fd281;
	mov.f64 	%fd284, 0d397B839A252049C0;
	fma.rn.f64 	%fd803, %fd279, %fd284, %fd283;
	abs.f64 	%fd285, %fd24;
	setp.ltu.f64 	%p56, %fd285, 0d41E0000000000000;
	@%p56 bra 	$L__BB14_32;

	{ // callseq 164, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd24;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd803, [retval0+0];
	} // callseq 164
	ld.local.u32 	%r287, [%rd1];

$L__BB14_32:
	and.b32  	%r115, %r287, 1;
	shl.b32 	%r116, %r287, 3;
	and.b32  	%r117, %r116, 8;
	setp.eq.s32 	%p57, %r115, 0;
	selp.f64 	%fd287, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p57;
	mul.wide.s32 	%rd41, %r117, 8;
	mov.u64 	%rd42, __cudart_sin_cos_coeffs;
	add.s64 	%rd43, %rd42, %rd41;
	ld.global.nc.f64 	%fd288, [%rd43+8];
	mul.rn.f64 	%fd29, %fd803, %fd803;
	fma.rn.f64 	%fd289, %fd287, %fd29, %fd288;
	ld.global.nc.f64 	%fd290, [%rd43+16];
	fma.rn.f64 	%fd291, %fd289, %fd29, %fd290;
	ld.global.nc.f64 	%fd292, [%rd43+24];
	fma.rn.f64 	%fd293, %fd291, %fd29, %fd292;
	ld.global.nc.f64 	%fd294, [%rd43+32];
	fma.rn.f64 	%fd295, %fd293, %fd29, %fd294;
	ld.global.nc.f64 	%fd296, [%rd43+40];
	fma.rn.f64 	%fd297, %fd295, %fd29, %fd296;
	ld.global.nc.f64 	%fd298, [%rd43+48];
	fma.rn.f64 	%fd30, %fd297, %fd29, %fd298;
	fma.rn.f64 	%fd805, %fd30, %fd803, %fd803;
	@%p57 bra 	$L__BB14_34;

	mov.f64 	%fd299, 0d3FF0000000000000;
	fma.rn.f64 	%fd805, %fd30, %fd29, %fd299;

$L__BB14_34:
	and.b32  	%r118, %r287, 2;
	setp.eq.s32 	%p58, %r118, 0;
	@%p58 bra 	$L__BB14_36;

	mov.f64 	%fd300, 0d0000000000000000;
	mov.f64 	%fd301, 0dBFF0000000000000;
	fma.rn.f64 	%fd805, %fd805, %fd301, %fd300;

$L__BB14_36:
	mul.rn.f64 	%fd302, %fd805, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd303, %fd23;
	add.rn.f64 	%fd36, %fd303, %fd302;
	setp.eq.f64 	%p59, %fd13, 0d0000000000000000;
	setp.eq.f64 	%p60, %fd3, 0d0000000000000000;
	and.pred  	%p61, %p60, %p59;
	@%p61 bra 	$L__BB14_40;
	bra.uni 	$L__BB14_37;

$L__BB14_40:
	selp.f64 	%fd356, 0d400921FB54442D18, 0d0000000000000000, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd356;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd356;
	}
	and.b32  	%r129, %r5, -2147483648;
	or.b32  	%r130, %r128, %r129;
	mov.b64 	%fd806, {%r127, %r130};
	bra.uni 	$L__BB14_41;

$L__BB14_37:
	setp.eq.f64 	%p62, %fd3, 0d7FF0000000000000;
	setp.eq.f64 	%p63, %fd13, 0d7FF0000000000000;
	and.pred  	%p64, %p62, %p63;
	@%p64 bra 	$L__BB14_39;
	bra.uni 	$L__BB14_38;

$L__BB14_39:
	selp.f64 	%fd355, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd355;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r124}, %fd355;
	}
	and.b32  	%r125, %r5, -2147483648;
	or.b32  	%r126, %r124, %r125;
	mov.b64 	%fd806, {%r123, %r126};
	bra.uni 	$L__BB14_41;

$L__BB14_38:
	min.f64 	%fd304, %fd13, %fd3;
	max.f64 	%fd305, %fd13, %fd3;
	div.rn.f64 	%fd306, %fd304, %fd305;
	mul.rn.f64 	%fd307, %fd306, %fd306;
	mov.f64 	%fd308, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd309, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd310, %fd309, %fd307, %fd308;
	mov.f64 	%fd311, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd312, %fd310, %fd307, %fd311;
	mov.f64 	%fd313, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd314, %fd312, %fd307, %fd313;
	mov.f64 	%fd315, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd316, %fd314, %fd307, %fd315;
	mov.f64 	%fd317, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd318, %fd316, %fd307, %fd317;
	mov.f64 	%fd319, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd320, %fd318, %fd307, %fd319;
	mov.f64 	%fd321, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd322, %fd320, %fd307, %fd321;
	mov.f64 	%fd323, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd324, %fd322, %fd307, %fd323;
	mov.f64 	%fd325, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd326, %fd324, %fd307, %fd325;
	mov.f64 	%fd327, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd328, %fd326, %fd307, %fd327;
	mov.f64 	%fd329, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd330, %fd328, %fd307, %fd329;
	mov.f64 	%fd331, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd332, %fd330, %fd307, %fd331;
	mov.f64 	%fd333, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd334, %fd332, %fd307, %fd333;
	mov.f64 	%fd335, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd336, %fd334, %fd307, %fd335;
	mov.f64 	%fd337, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd338, %fd336, %fd307, %fd337;
	mov.f64 	%fd339, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd340, %fd338, %fd307, %fd339;
	mov.f64 	%fd341, 0d3FC99999999840D2;
	fma.rn.f64 	%fd342, %fd340, %fd307, %fd341;
	mov.f64 	%fd343, 0dBFD555555555544C;
	fma.rn.f64 	%fd344, %fd342, %fd307, %fd343;
	mul.rn.f64 	%fd345, %fd307, %fd344;
	fma.rn.f64 	%fd346, %fd345, %fd306, %fd306;
	mov.f64 	%fd347, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd348, %fd347, %fd346;
	setp.gt.f64 	%p66, %fd13, %fd3;
	selp.f64 	%fd349, %fd348, %fd346, %p66;
	mov.f64 	%fd350, 0d400921FB54442D18;
	sub.rn.f64 	%fd351, %fd350, %fd349;
	selp.f64 	%fd352, %fd351, %fd349, %p8;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd352;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd352;
	}
	and.b32  	%r121, %r5, -2147483648;
	or.b32  	%r122, %r120, %r121;
	mov.b64 	%fd353, {%r119, %r122};
	add.rn.f64 	%fd354, %fd3, %fd13;
	setp.le.f64 	%p67, %fd354, 0d7FF0000000000000;
	selp.f64 	%fd806, %fd353, %fd354, %p67;

$L__BB14_41:
	add.rn.f64 	%fd796, %fd260, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd41, %fd796, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd41;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd41;
	}
	and.b32  	%r133, %r132, 2147483647;
	setp.eq.s32 	%p70, %r133, 2146435072;
	setp.eq.s32 	%p71, %r131, 0;
	and.pred  	%p72, %p71, %p70;
	@%p72 bra 	$L__BB14_45;
	bra.uni 	$L__BB14_42;

$L__BB14_45:
	mov.f64 	%fd366, 0d0000000000000000;
	mul.rn.f64 	%fd808, %fd41, %fd366;
	mov.u32 	%r289, 1;
	bra.uni 	$L__BB14_46;

$L__BB14_42:
	mul.rn.f64 	%fd357, %fd41, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r288, %fd357;
	st.local.u32 	[%rd1], %r288;
	cvt.rn.f64.s32 	%fd358, %r288;
	neg.f64 	%fd359, %fd358;
	mov.f64 	%fd360, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd361, %fd359, %fd360, %fd41;
	mov.f64 	%fd362, 0d3C91A62633145C00;
	fma.rn.f64 	%fd363, %fd359, %fd362, %fd361;
	mov.f64 	%fd364, 0d397B839A252049C0;
	fma.rn.f64 	%fd808, %fd359, %fd364, %fd363;
	abs.f64 	%fd365, %fd41;
	setp.ltu.f64 	%p73, %fd365, 0d41E0000000000000;
	@%p73 bra 	$L__BB14_44;

	{ // callseq 165, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd41;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd808, [retval0+0];
	} // callseq 165
	ld.local.u32 	%r288, [%rd1];

$L__BB14_44:
	add.s32 	%r289, %r288, 1;

$L__BB14_46:
	and.b32  	%r135, %r289, 1;
	shl.b32 	%r136, %r289, 3;
	and.b32  	%r137, %r136, 8;
	setp.eq.s32 	%p74, %r135, 0;
	selp.f64 	%fd367, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p74;
	mul.wide.s32 	%rd45, %r137, 8;
	add.s64 	%rd47, %rd42, %rd45;
	ld.global.nc.f64 	%fd368, [%rd47+8];
	mul.rn.f64 	%fd47, %fd808, %fd808;
	fma.rn.f64 	%fd369, %fd367, %fd47, %fd368;
	ld.global.nc.f64 	%fd370, [%rd47+16];
	fma.rn.f64 	%fd371, %fd369, %fd47, %fd370;
	ld.global.nc.f64 	%fd372, [%rd47+24];
	fma.rn.f64 	%fd373, %fd371, %fd47, %fd372;
	ld.global.nc.f64 	%fd374, [%rd47+32];
	fma.rn.f64 	%fd375, %fd373, %fd47, %fd374;
	ld.global.nc.f64 	%fd376, [%rd47+40];
	fma.rn.f64 	%fd377, %fd375, %fd47, %fd376;
	ld.global.nc.f64 	%fd378, [%rd47+48];
	fma.rn.f64 	%fd48, %fd377, %fd47, %fd378;
	fma.rn.f64 	%fd810, %fd48, %fd808, %fd808;
	@%p74 bra 	$L__BB14_48;

	mov.f64 	%fd379, 0d3FF0000000000000;
	fma.rn.f64 	%fd810, %fd48, %fd47, %fd379;

$L__BB14_48:
	and.b32  	%r138, %r289, 2;
	setp.eq.s32 	%p75, %r138, 0;
	@%p75 bra 	$L__BB14_50;

	mov.f64 	%fd380, 0d0000000000000000;
	mov.f64 	%fd381, 0dBFF0000000000000;
	fma.rn.f64 	%fd810, %fd810, %fd381, %fd380;

$L__BB14_50:
	mul.rn.f64 	%fd382, %fd810, 0dBEC92A737110E454;
	add.rn.f64 	%fd54, %fd806, %fd382;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd54;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd54;
	}
	and.b32  	%r141, %r140, 2147483647;
	setp.eq.s32 	%p76, %r141, 2146435072;
	setp.eq.s32 	%p77, %r139, 0;
	and.pred  	%p3, %p77, %p76;
	@%p3 bra 	$L__BB14_54;
	bra.uni 	$L__BB14_51;

$L__BB14_54:
	mov.f64 	%fd392, 0d0000000000000000;
	mul.rn.f64 	%fd812, %fd54, %fd392;
	mov.u32 	%r291, 1;
	bra.uni 	$L__BB14_55;

$L__BB14_51:
	mul.rn.f64 	%fd383, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r290, %fd383;
	st.local.u32 	[%rd1], %r290;
	cvt.rn.f64.s32 	%fd384, %r290;
	neg.f64 	%fd385, %fd384;
	mov.f64 	%fd386, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd387, %fd385, %fd386, %fd54;
	mov.f64 	%fd388, 0d3C91A62633145C00;
	fma.rn.f64 	%fd389, %fd385, %fd388, %fd387;
	mov.f64 	%fd390, 0d397B839A252049C0;
	fma.rn.f64 	%fd812, %fd385, %fd390, %fd389;
	abs.f64 	%fd391, %fd54;
	setp.ltu.f64 	%p78, %fd391, 0d41E0000000000000;
	@%p78 bra 	$L__BB14_53;

	{ // callseq 166, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd812, [retval0+0];
	} // callseq 166
	ld.local.u32 	%r290, [%rd1];

$L__BB14_53:
	add.s32 	%r291, %r290, 1;

$L__BB14_55:
	and.b32  	%r143, %r291, 1;
	shl.b32 	%r144, %r291, 3;
	and.b32  	%r145, %r144, 8;
	setp.eq.s32 	%p79, %r143, 0;
	selp.f64 	%fd393, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p79;
	mul.wide.s32 	%rd49, %r145, 8;
	add.s64 	%rd51, %rd42, %rd49;
	ld.global.nc.f64 	%fd394, [%rd51+8];
	mul.rn.f64 	%fd60, %fd812, %fd812;
	fma.rn.f64 	%fd395, %fd393, %fd60, %fd394;
	ld.global.nc.f64 	%fd396, [%rd51+16];
	fma.rn.f64 	%fd397, %fd395, %fd60, %fd396;
	ld.global.nc.f64 	%fd398, [%rd51+24];
	fma.rn.f64 	%fd399, %fd397, %fd60, %fd398;
	ld.global.nc.f64 	%fd400, [%rd51+32];
	fma.rn.f64 	%fd401, %fd399, %fd60, %fd400;
	ld.global.nc.f64 	%fd402, [%rd51+40];
	fma.rn.f64 	%fd403, %fd401, %fd60, %fd402;
	ld.global.nc.f64 	%fd404, [%rd51+48];
	fma.rn.f64 	%fd61, %fd403, %fd60, %fd404;
	fma.rn.f64 	%fd814, %fd61, %fd812, %fd812;
	@%p79 bra 	$L__BB14_57;

	mov.f64 	%fd405, 0d3FF0000000000000;
	fma.rn.f64 	%fd814, %fd61, %fd60, %fd405;

$L__BB14_57:
	and.b32  	%r146, %r291, 2;
	setp.eq.s32 	%p80, %r146, 0;
	@%p80 bra 	$L__BB14_59;

	mov.f64 	%fd406, 0d0000000000000000;
	mov.f64 	%fd407, 0dBFF0000000000000;
	fma.rn.f64 	%fd814, %fd814, %fd407, %fd406;

$L__BB14_59:
	mul.rn.f64 	%fd408, %fd36, %fd814;
	st.global.f64 	[%rd17], %fd408;
	@%p3 bra 	$L__BB14_62;
	bra.uni 	$L__BB14_60;

$L__BB14_62:
	mov.f64 	%fd418, 0d0000000000000000;
	mul.rn.f64 	%fd815, %fd54, %fd418;
	mov.u32 	%r292, 0;
	bra.uni 	$L__BB14_63;

$L__BB14_60:
	mul.rn.f64 	%fd409, %fd54, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r292, %fd409;
	st.local.u32 	[%rd1], %r292;
	cvt.rn.f64.s32 	%fd410, %r292;
	neg.f64 	%fd411, %fd410;
	mov.f64 	%fd412, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd413, %fd411, %fd412, %fd54;
	mov.f64 	%fd414, 0d3C91A62633145C00;
	fma.rn.f64 	%fd415, %fd411, %fd414, %fd413;
	mov.f64 	%fd416, 0d397B839A252049C0;
	fma.rn.f64 	%fd815, %fd411, %fd416, %fd415;
	abs.f64 	%fd417, %fd54;
	setp.ltu.f64 	%p81, %fd417, 0d41E0000000000000;
	@%p81 bra 	$L__BB14_63;

	{ // callseq 167, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd54;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd815, [retval0+0];
	} // callseq 167
	ld.local.u32 	%r292, [%rd1];

$L__BB14_63:
	and.b32  	%r148, %r292, 1;
	shl.b32 	%r149, %r292, 3;
	and.b32  	%r150, %r149, 8;
	setp.eq.s32 	%p82, %r148, 0;
	selp.f64 	%fd419, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p82;
	mul.wide.s32 	%rd53, %r150, 8;
	add.s64 	%rd55, %rd42, %rd53;
	ld.global.nc.f64 	%fd420, [%rd55+8];
	mul.rn.f64 	%fd71, %fd815, %fd815;
	fma.rn.f64 	%fd421, %fd419, %fd71, %fd420;
	ld.global.nc.f64 	%fd422, [%rd55+16];
	fma.rn.f64 	%fd423, %fd421, %fd71, %fd422;
	ld.global.nc.f64 	%fd424, [%rd55+24];
	fma.rn.f64 	%fd425, %fd423, %fd71, %fd424;
	ld.global.nc.f64 	%fd426, [%rd55+32];
	fma.rn.f64 	%fd427, %fd425, %fd71, %fd426;
	ld.global.nc.f64 	%fd428, [%rd55+40];
	fma.rn.f64 	%fd429, %fd427, %fd71, %fd428;
	ld.global.nc.f64 	%fd430, [%rd55+48];
	fma.rn.f64 	%fd72, %fd429, %fd71, %fd430;
	fma.rn.f64 	%fd817, %fd72, %fd815, %fd815;
	@%p82 bra 	$L__BB14_65;

	mov.f64 	%fd431, 0d3FF0000000000000;
	fma.rn.f64 	%fd817, %fd72, %fd71, %fd431;

$L__BB14_65:
	and.b32  	%r151, %r292, 2;
	setp.eq.s32 	%p83, %r151, 0;
	@%p83 bra 	$L__BB14_67;

	mov.f64 	%fd432, 0d0000000000000000;
	mov.f64 	%fd433, 0dBFF0000000000000;
	fma.rn.f64 	%fd817, %fd817, %fd433, %fd432;

$L__BB14_67:
	mul.rn.f64 	%fd78, %fd36, %fd817;
	st.global.f64 	[%rd18], %fd78;
	ld.global.f64 	%fd79, [%rd17];
	add.rn.f64 	%fd80, %fd79, 0dC05A400000000000;
	add.rn.f64 	%fd81, %fd78, 0dC041800000000000;
	abs.f64 	%fd82, %fd80;
	sqrt.rn.f64 	%fd83, %fd82;
	mul.rn.f64 	%fd84, %fd80, 0d400921FB54442D18;
	mul.rn.f64 	%fd85, %fd81, 0d400921FB54442D18;
	mul.rn.f64 	%fd86, %fd84, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r152, %temp}, %fd86;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd86;
	}
	and.b32  	%r154, %r153, 2147483647;
	setp.eq.s32 	%p84, %r154, 2146435072;
	setp.eq.s32 	%p85, %r152, 0;
	and.pred  	%p86, %p85, %p84;
	@%p86 bra 	$L__BB14_70;
	bra.uni 	$L__BB14_68;

$L__BB14_70:
	mov.f64 	%fd443, 0d0000000000000000;
	mul.rn.f64 	%fd818, %fd86, %fd443;
	mov.u32 	%r293, 0;
	bra.uni 	$L__BB14_71;

$L__BB14_68:
	mul.rn.f64 	%fd434, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r293, %fd434;
	st.local.u32 	[%rd1], %r293;
	cvt.rn.f64.s32 	%fd435, %r293;
	neg.f64 	%fd436, %fd435;
	mov.f64 	%fd437, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd438, %fd436, %fd437, %fd86;
	mov.f64 	%fd439, 0d3C91A62633145C00;
	fma.rn.f64 	%fd440, %fd436, %fd439, %fd438;
	mov.f64 	%fd441, 0d397B839A252049C0;
	fma.rn.f64 	%fd818, %fd436, %fd441, %fd440;
	abs.f64 	%fd442, %fd86;
	setp.ltu.f64 	%p87, %fd442, 0d41E0000000000000;
	@%p87 bra 	$L__BB14_71;

	{ // callseq 168, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd818, [retval0+0];
	} // callseq 168
	ld.local.u32 	%r293, [%rd1];

$L__BB14_71:
	and.b32  	%r156, %r293, 1;
	shl.b32 	%r157, %r293, 3;
	and.b32  	%r158, %r157, 8;
	setp.eq.s32 	%p88, %r156, 0;
	selp.f64 	%fd444, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p88;
	mul.wide.s32 	%rd57, %r158, 8;
	add.s64 	%rd59, %rd42, %rd57;
	ld.global.nc.f64 	%fd445, [%rd59+8];
	mul.rn.f64 	%fd91, %fd818, %fd818;
	fma.rn.f64 	%fd446, %fd444, %fd91, %fd445;
	ld.global.nc.f64 	%fd447, [%rd59+16];
	fma.rn.f64 	%fd448, %fd446, %fd91, %fd447;
	ld.global.nc.f64 	%fd449, [%rd59+24];
	fma.rn.f64 	%fd450, %fd448, %fd91, %fd449;
	ld.global.nc.f64 	%fd451, [%rd59+32];
	fma.rn.f64 	%fd452, %fd450, %fd91, %fd451;
	ld.global.nc.f64 	%fd453, [%rd59+40];
	fma.rn.f64 	%fd454, %fd452, %fd91, %fd453;
	ld.global.nc.f64 	%fd455, [%rd59+48];
	fma.rn.f64 	%fd92, %fd454, %fd91, %fd455;
	fma.rn.f64 	%fd820, %fd92, %fd818, %fd818;
	@%p88 bra 	$L__BB14_73;

	mov.f64 	%fd456, 0d3FF0000000000000;
	fma.rn.f64 	%fd820, %fd92, %fd91, %fd456;

$L__BB14_73:
	and.b32  	%r159, %r293, 2;
	setp.eq.s32 	%p89, %r159, 0;
	@%p89 bra 	$L__BB14_75;

	mov.f64 	%fd457, 0d0000000000000000;
	mov.f64 	%fd458, 0dBFF0000000000000;
	fma.rn.f64 	%fd820, %fd820, %fd458, %fd457;

$L__BB14_75:
	add.rn.f64 	%fd98, %fd84, %fd84;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd98;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd98;
	}
	and.b32  	%r162, %r161, 2147483647;
	setp.eq.s32 	%p90, %r162, 2146435072;
	setp.eq.s32 	%p91, %r160, 0;
	and.pred  	%p92, %p91, %p90;
	@%p92 bra 	$L__BB14_78;
	bra.uni 	$L__BB14_76;

$L__BB14_78:
	mov.f64 	%fd468, 0d0000000000000000;
	mul.rn.f64 	%fd821, %fd98, %fd468;
	mov.u32 	%r294, 0;
	bra.uni 	$L__BB14_79;

$L__BB14_76:
	mul.rn.f64 	%fd459, %fd98, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r294, %fd459;
	st.local.u32 	[%rd1], %r294;
	cvt.rn.f64.s32 	%fd460, %r294;
	neg.f64 	%fd461, %fd460;
	mov.f64 	%fd462, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd463, %fd461, %fd462, %fd98;
	mov.f64 	%fd464, 0d3C91A62633145C00;
	fma.rn.f64 	%fd465, %fd461, %fd464, %fd463;
	mov.f64 	%fd466, 0d397B839A252049C0;
	fma.rn.f64 	%fd821, %fd461, %fd466, %fd465;
	abs.f64 	%fd467, %fd98;
	setp.ltu.f64 	%p93, %fd467, 0d41E0000000000000;
	@%p93 bra 	$L__BB14_79;

	{ // callseq 169, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd98;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd821, [retval0+0];
	} // callseq 169
	ld.local.u32 	%r294, [%rd1];

$L__BB14_79:
	and.b32  	%r164, %r294, 1;
	shl.b32 	%r165, %r294, 3;
	and.b32  	%r166, %r165, 8;
	setp.eq.s32 	%p94, %r164, 0;
	selp.f64 	%fd469, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p94;
	mul.wide.s32 	%rd61, %r166, 8;
	add.s64 	%rd63, %rd42, %rd61;
	ld.global.nc.f64 	%fd470, [%rd63+8];
	mul.rn.f64 	%fd103, %fd821, %fd821;
	fma.rn.f64 	%fd471, %fd469, %fd103, %fd470;
	ld.global.nc.f64 	%fd472, [%rd63+16];
	fma.rn.f64 	%fd473, %fd471, %fd103, %fd472;
	ld.global.nc.f64 	%fd474, [%rd63+24];
	fma.rn.f64 	%fd475, %fd473, %fd103, %fd474;
	ld.global.nc.f64 	%fd476, [%rd63+32];
	fma.rn.f64 	%fd477, %fd475, %fd103, %fd476;
	ld.global.nc.f64 	%fd478, [%rd63+40];
	fma.rn.f64 	%fd479, %fd477, %fd103, %fd478;
	ld.global.nc.f64 	%fd480, [%rd63+48];
	fma.rn.f64 	%fd104, %fd479, %fd103, %fd480;
	fma.rn.f64 	%fd823, %fd104, %fd821, %fd821;
	@%p94 bra 	$L__BB14_81;

	mov.f64 	%fd481, 0d3FF0000000000000;
	fma.rn.f64 	%fd823, %fd104, %fd103, %fd481;

$L__BB14_81:
	and.b32  	%r167, %r294, 2;
	setp.eq.s32 	%p95, %r167, 0;
	@%p95 bra 	$L__BB14_83;

	mov.f64 	%fd482, 0d0000000000000000;
	mov.f64 	%fd483, 0dBFF0000000000000;
	fma.rn.f64 	%fd823, %fd823, %fd483, %fd482;

$L__BB14_83:
	mul.rn.f64 	%fd484, %fd823, 0d4034000000000000;
	mul.rn.f64 	%fd485, %fd820, 0d4034000000000000;
	add.rn.f64 	%fd110, %fd485, %fd484;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r168}, %fd85;
	}
	and.b32  	%r169, %r168, 2147483647;
	setp.eq.s32 	%p96, %r169, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r170, %temp}, %fd85;
	}
	setp.eq.s32 	%p97, %r170, 0;
	and.pred  	%p98, %p97, %p96;
	@%p98 bra 	$L__BB14_86;
	bra.uni 	$L__BB14_84;

$L__BB14_86:
	mov.f64 	%fd495, 0d0000000000000000;
	mul.rn.f64 	%fd824, %fd85, %fd495;
	mov.u32 	%r295, 0;
	bra.uni 	$L__BB14_87;

$L__BB14_84:
	mul.rn.f64 	%fd486, %fd85, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r295, %fd486;
	st.local.u32 	[%rd1], %r295;
	cvt.rn.f64.s32 	%fd487, %r295;
	neg.f64 	%fd488, %fd487;
	mov.f64 	%fd489, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd490, %fd488, %fd489, %fd85;
	mov.f64 	%fd491, 0d3C91A62633145C00;
	fma.rn.f64 	%fd492, %fd488, %fd491, %fd490;
	mov.f64 	%fd493, 0d397B839A252049C0;
	fma.rn.f64 	%fd824, %fd488, %fd493, %fd492;
	abs.f64 	%fd494, %fd85;
	setp.ltu.f64 	%p99, %fd494, 0d41E0000000000000;
	@%p99 bra 	$L__BB14_87;

	{ // callseq 170, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd85;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd824, [retval0+0];
	} // callseq 170
	ld.local.u32 	%r295, [%rd1];

$L__BB14_87:
	and.b32  	%r172, %r295, 1;
	shl.b32 	%r173, %r295, 3;
	and.b32  	%r174, %r173, 8;
	setp.eq.s32 	%p100, %r172, 0;
	selp.f64 	%fd496, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p100;
	mul.wide.s32 	%rd65, %r174, 8;
	add.s64 	%rd67, %rd42, %rd65;
	ld.global.nc.f64 	%fd497, [%rd67+8];
	mul.rn.f64 	%fd115, %fd824, %fd824;
	fma.rn.f64 	%fd498, %fd496, %fd115, %fd497;
	ld.global.nc.f64 	%fd499, [%rd67+16];
	fma.rn.f64 	%fd500, %fd498, %fd115, %fd499;
	ld.global.nc.f64 	%fd501, [%rd67+24];
	fma.rn.f64 	%fd502, %fd500, %fd115, %fd501;
	ld.global.nc.f64 	%fd503, [%rd67+32];
	fma.rn.f64 	%fd504, %fd502, %fd115, %fd503;
	ld.global.nc.f64 	%fd505, [%rd67+40];
	fma.rn.f64 	%fd506, %fd504, %fd115, %fd505;
	ld.global.nc.f64 	%fd507, [%rd67+48];
	fma.rn.f64 	%fd116, %fd506, %fd115, %fd507;
	fma.rn.f64 	%fd826, %fd116, %fd824, %fd824;
	@%p100 bra 	$L__BB14_89;

	mov.f64 	%fd508, 0d3FF0000000000000;
	fma.rn.f64 	%fd826, %fd116, %fd115, %fd508;

$L__BB14_89:
	and.b32  	%r175, %r295, 2;
	setp.eq.s32 	%p101, %r175, 0;
	@%p101 bra 	$L__BB14_91;

	mov.f64 	%fd509, 0d0000000000000000;
	mov.f64 	%fd510, 0dBFF0000000000000;
	fma.rn.f64 	%fd826, %fd826, %fd510, %fd509;

$L__BB14_91:
	div.rn.f64 	%fd122, %fd85, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r176, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r177}, %fd122;
	}
	and.b32  	%r178, %r177, 2147483647;
	setp.eq.s32 	%p102, %r178, 2146435072;
	setp.eq.s32 	%p103, %r176, 0;
	and.pred  	%p104, %p103, %p102;
	@%p104 bra 	$L__BB14_94;
	bra.uni 	$L__BB14_92;

$L__BB14_94:
	mov.f64 	%fd520, 0d0000000000000000;
	mul.rn.f64 	%fd827, %fd122, %fd520;
	mov.u32 	%r296, 0;
	bra.uni 	$L__BB14_95;

$L__BB14_92:
	mul.rn.f64 	%fd511, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r296, %fd511;
	st.local.u32 	[%rd1], %r296;
	cvt.rn.f64.s32 	%fd512, %r296;
	neg.f64 	%fd513, %fd512;
	mov.f64 	%fd514, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd515, %fd513, %fd514, %fd122;
	mov.f64 	%fd516, 0d3C91A62633145C00;
	fma.rn.f64 	%fd517, %fd513, %fd516, %fd515;
	mov.f64 	%fd518, 0d397B839A252049C0;
	fma.rn.f64 	%fd827, %fd513, %fd518, %fd517;
	abs.f64 	%fd519, %fd122;
	setp.ltu.f64 	%p105, %fd519, 0d41E0000000000000;
	@%p105 bra 	$L__BB14_95;

	{ // callseq 171, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd827, [retval0+0];
	} // callseq 171
	ld.local.u32 	%r296, [%rd1];

$L__BB14_95:
	and.b32  	%r180, %r296, 1;
	shl.b32 	%r181, %r296, 3;
	and.b32  	%r182, %r181, 8;
	setp.eq.s32 	%p106, %r180, 0;
	selp.f64 	%fd521, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p106;
	mul.wide.s32 	%rd69, %r182, 8;
	add.s64 	%rd71, %rd42, %rd69;
	ld.global.nc.f64 	%fd522, [%rd71+8];
	mul.rn.f64 	%fd127, %fd827, %fd827;
	fma.rn.f64 	%fd523, %fd521, %fd127, %fd522;
	ld.global.nc.f64 	%fd524, [%rd71+16];
	fma.rn.f64 	%fd525, %fd523, %fd127, %fd524;
	ld.global.nc.f64 	%fd526, [%rd71+24];
	fma.rn.f64 	%fd527, %fd525, %fd127, %fd526;
	ld.global.nc.f64 	%fd528, [%rd71+32];
	fma.rn.f64 	%fd529, %fd527, %fd127, %fd528;
	ld.global.nc.f64 	%fd530, [%rd71+40];
	fma.rn.f64 	%fd531, %fd529, %fd127, %fd530;
	ld.global.nc.f64 	%fd532, [%rd71+48];
	fma.rn.f64 	%fd128, %fd531, %fd127, %fd532;
	fma.rn.f64 	%fd829, %fd128, %fd827, %fd827;
	@%p106 bra 	$L__BB14_97;

	mov.f64 	%fd533, 0d3FF0000000000000;
	fma.rn.f64 	%fd829, %fd128, %fd127, %fd533;

$L__BB14_97:
	and.b32  	%r183, %r296, 2;
	setp.eq.s32 	%p107, %r183, 0;
	@%p107 bra 	$L__BB14_99;

	mov.f64 	%fd534, 0d0000000000000000;
	mov.f64 	%fd535, 0dBFF0000000000000;
	fma.rn.f64 	%fd829, %fd829, %fd535, %fd534;

$L__BB14_99:
	mul.rn.f64 	%fd536, %fd829, 0d4044000000000000;
	mul.rn.f64 	%fd537, %fd826, 0d4034000000000000;
	add.rn.f64 	%fd134, %fd537, %fd536;
	div.rn.f64 	%fd135, %fd85, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r184, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r185}, %fd135;
	}
	and.b32  	%r186, %r185, 2147483647;
	setp.eq.s32 	%p108, %r186, 2146435072;
	setp.eq.s32 	%p109, %r184, 0;
	and.pred  	%p110, %p109, %p108;
	@%p110 bra 	$L__BB14_102;
	bra.uni 	$L__BB14_100;

$L__BB14_102:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd830, %fd135, %fd547;
	mov.u32 	%r297, 0;
	bra.uni 	$L__BB14_103;

$L__BB14_100:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r297, %fd538;
	st.local.u32 	[%rd1], %r297;
	cvt.rn.f64.s32 	%fd539, %r297;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd830, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p111, %fd546, 0d41E0000000000000;
	@%p111 bra 	$L__BB14_103;

	{ // callseq 172, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd830, [retval0+0];
	} // callseq 172
	ld.local.u32 	%r297, [%rd1];

$L__BB14_103:
	and.b32  	%r188, %r297, 1;
	shl.b32 	%r189, %r297, 3;
	and.b32  	%r190, %r189, 8;
	setp.eq.s32 	%p112, %r188, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p112;
	mul.wide.s32 	%rd73, %r190, 8;
	add.s64 	%rd75, %rd42, %rd73;
	ld.global.nc.f64 	%fd549, [%rd75+8];
	mul.rn.f64 	%fd140, %fd830, %fd830;
	fma.rn.f64 	%fd550, %fd548, %fd140, %fd549;
	ld.global.nc.f64 	%fd551, [%rd75+16];
	fma.rn.f64 	%fd552, %fd550, %fd140, %fd551;
	ld.global.nc.f64 	%fd553, [%rd75+24];
	fma.rn.f64 	%fd554, %fd552, %fd140, %fd553;
	ld.global.nc.f64 	%fd555, [%rd75+32];
	fma.rn.f64 	%fd556, %fd554, %fd140, %fd555;
	ld.global.nc.f64 	%fd557, [%rd75+40];
	fma.rn.f64 	%fd558, %fd556, %fd140, %fd557;
	ld.global.nc.f64 	%fd559, [%rd75+48];
	fma.rn.f64 	%fd141, %fd558, %fd140, %fd559;
	fma.rn.f64 	%fd832, %fd141, %fd830, %fd830;
	@%p112 bra 	$L__BB14_105;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd832, %fd141, %fd140, %fd560;

$L__BB14_105:
	and.b32  	%r191, %r297, 2;
	setp.eq.s32 	%p113, %r191, 0;
	@%p113 bra 	$L__BB14_107;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd832, %fd832, %fd562, %fd561;

$L__BB14_107:
	mul.rn.f64 	%fd563, %fd832, 0d4064000000000000;
	add.rn.f64 	%fd147, %fd134, %fd563;
	div.rn.f64 	%fd148, %fd85, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r192, %temp}, %fd148;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd148;
	}
	and.b32  	%r194, %r193, 2147483647;
	setp.eq.s32 	%p114, %r194, 2146435072;
	setp.eq.s32 	%p115, %r192, 0;
	and.pred  	%p116, %p115, %p114;
	@%p116 bra 	$L__BB14_110;
	bra.uni 	$L__BB14_108;

$L__BB14_110:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd833, %fd148, %fd573;
	mov.u32 	%r298, 0;
	bra.uni 	$L__BB14_111;

$L__BB14_108:
	mul.rn.f64 	%fd564, %fd148, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r298, %fd564;
	st.local.u32 	[%rd1], %r298;
	cvt.rn.f64.s32 	%fd565, %r298;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd148;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd833, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd148;
	setp.ltu.f64 	%p117, %fd572, 0d41E0000000000000;
	@%p117 bra 	$L__BB14_111;

	{ // callseq 173, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd148;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd833, [retval0+0];
	} // callseq 173
	ld.local.u32 	%r298, [%rd1];

$L__BB14_111:
	and.b32  	%r196, %r298, 1;
	shl.b32 	%r197, %r298, 3;
	and.b32  	%r198, %r197, 8;
	setp.eq.s32 	%p118, %r196, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd77, %r198, 8;
	add.s64 	%rd79, %rd42, %rd77;
	ld.global.nc.f64 	%fd575, [%rd79+8];
	mul.rn.f64 	%fd153, %fd833, %fd833;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd79+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd79+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd79+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd79+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd79+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd835, %fd154, %fd833, %fd833;
	@%p118 bra 	$L__BB14_113;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd835, %fd154, %fd153, %fd586;

$L__BB14_113:
	and.b32  	%r199, %r298, 2;
	setp.eq.s32 	%p119, %r199, 0;
	@%p119 bra 	$L__BB14_115;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd835, %fd835, %fd588, %fd587;

$L__BB14_115:
	mul.rn.f64 	%fd589, %fd835, 0d4074000000000000;
	add.rn.f64 	%fd160, %fd147, %fd589;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd84;
	}
	and.b32  	%r201, %r200, 2147483647;
	setp.eq.s32 	%p120, %r201, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r202, %temp}, %fd84;
	}
	setp.eq.s32 	%p121, %r202, 0;
	and.pred  	%p122, %p121, %p120;
	@%p122 bra 	$L__BB14_118;
	bra.uni 	$L__BB14_116;

$L__BB14_118:
	mov.f64 	%fd599, 0d0000000000000000;
	mul.rn.f64 	%fd836, %fd84, %fd599;
	mov.u32 	%r299, 0;
	bra.uni 	$L__BB14_119;

$L__BB14_116:
	mul.rn.f64 	%fd590, %fd84, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r299, %fd590;
	st.local.u32 	[%rd1], %r299;
	cvt.rn.f64.s32 	%fd591, %r299;
	neg.f64 	%fd592, %fd591;
	mov.f64 	%fd593, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd594, %fd592, %fd593, %fd84;
	mov.f64 	%fd595, 0d3C91A62633145C00;
	fma.rn.f64 	%fd596, %fd592, %fd595, %fd594;
	mov.f64 	%fd597, 0d397B839A252049C0;
	fma.rn.f64 	%fd836, %fd592, %fd597, %fd596;
	abs.f64 	%fd598, %fd84;
	setp.ltu.f64 	%p123, %fd598, 0d41E0000000000000;
	@%p123 bra 	$L__BB14_119;

	{ // callseq 174, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd836, [retval0+0];
	} // callseq 174
	ld.local.u32 	%r299, [%rd1];

$L__BB14_119:
	and.b32  	%r204, %r299, 1;
	shl.b32 	%r205, %r299, 3;
	and.b32  	%r206, %r205, 8;
	setp.eq.s32 	%p124, %r204, 0;
	selp.f64 	%fd600, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p124;
	mul.wide.s32 	%rd81, %r206, 8;
	add.s64 	%rd83, %rd42, %rd81;
	ld.global.nc.f64 	%fd601, [%rd83+8];
	mul.rn.f64 	%fd165, %fd836, %fd836;
	fma.rn.f64 	%fd602, %fd600, %fd165, %fd601;
	ld.global.nc.f64 	%fd603, [%rd83+16];
	fma.rn.f64 	%fd604, %fd602, %fd165, %fd603;
	ld.global.nc.f64 	%fd605, [%rd83+24];
	fma.rn.f64 	%fd606, %fd604, %fd165, %fd605;
	ld.global.nc.f64 	%fd607, [%rd83+32];
	fma.rn.f64 	%fd608, %fd606, %fd165, %fd607;
	ld.global.nc.f64 	%fd609, [%rd83+40];
	fma.rn.f64 	%fd610, %fd608, %fd165, %fd609;
	ld.global.nc.f64 	%fd611, [%rd83+48];
	fma.rn.f64 	%fd166, %fd610, %fd165, %fd611;
	fma.rn.f64 	%fd838, %fd166, %fd836, %fd836;
	@%p124 bra 	$L__BB14_121;

	mov.f64 	%fd612, 0d3FF0000000000000;
	fma.rn.f64 	%fd838, %fd166, %fd165, %fd612;

$L__BB14_121:
	and.b32  	%r207, %r299, 2;
	setp.eq.s32 	%p125, %r207, 0;
	@%p125 bra 	$L__BB14_123;

	mov.f64 	%fd613, 0d0000000000000000;
	mov.f64 	%fd614, 0dBFF0000000000000;
	fma.rn.f64 	%fd838, %fd838, %fd614, %fd613;

$L__BB14_123:
	div.rn.f64 	%fd172, %fd84, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd172;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd172;
	}
	and.b32  	%r210, %r209, 2147483647;
	setp.eq.s32 	%p126, %r210, 2146435072;
	setp.eq.s32 	%p127, %r208, 0;
	and.pred  	%p128, %p127, %p126;
	@%p128 bra 	$L__BB14_126;
	bra.uni 	$L__BB14_124;

$L__BB14_126:
	mov.f64 	%fd624, 0d0000000000000000;
	mul.rn.f64 	%fd839, %fd172, %fd624;
	mov.u32 	%r300, 0;
	bra.uni 	$L__BB14_127;

$L__BB14_124:
	mul.rn.f64 	%fd615, %fd172, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r300, %fd615;
	st.local.u32 	[%rd1], %r300;
	cvt.rn.f64.s32 	%fd616, %r300;
	neg.f64 	%fd617, %fd616;
	mov.f64 	%fd618, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd619, %fd617, %fd618, %fd172;
	mov.f64 	%fd620, 0d3C91A62633145C00;
	fma.rn.f64 	%fd621, %fd617, %fd620, %fd619;
	mov.f64 	%fd622, 0d397B839A252049C0;
	fma.rn.f64 	%fd839, %fd617, %fd622, %fd621;
	abs.f64 	%fd623, %fd172;
	setp.ltu.f64 	%p129, %fd623, 0d41E0000000000000;
	@%p129 bra 	$L__BB14_127;

	{ // callseq 175, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd172;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd839, [retval0+0];
	} // callseq 175
	ld.local.u32 	%r300, [%rd1];

$L__BB14_127:
	and.b32  	%r212, %r300, 1;
	shl.b32 	%r213, %r300, 3;
	and.b32  	%r214, %r213, 8;
	setp.eq.s32 	%p130, %r212, 0;
	selp.f64 	%fd625, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p130;
	mul.wide.s32 	%rd85, %r214, 8;
	add.s64 	%rd87, %rd42, %rd85;
	ld.global.nc.f64 	%fd626, [%rd87+8];
	mul.rn.f64 	%fd177, %fd839, %fd839;
	fma.rn.f64 	%fd627, %fd625, %fd177, %fd626;
	ld.global.nc.f64 	%fd628, [%rd87+16];
	fma.rn.f64 	%fd629, %fd627, %fd177, %fd628;
	ld.global.nc.f64 	%fd630, [%rd87+24];
	fma.rn.f64 	%fd631, %fd629, %fd177, %fd630;
	ld.global.nc.f64 	%fd632, [%rd87+32];
	fma.rn.f64 	%fd633, %fd631, %fd177, %fd632;
	ld.global.nc.f64 	%fd634, [%rd87+40];
	fma.rn.f64 	%fd635, %fd633, %fd177, %fd634;
	ld.global.nc.f64 	%fd636, [%rd87+48];
	fma.rn.f64 	%fd178, %fd635, %fd177, %fd636;
	fma.rn.f64 	%fd841, %fd178, %fd839, %fd839;
	@%p130 bra 	$L__BB14_129;

	mov.f64 	%fd637, 0d3FF0000000000000;
	fma.rn.f64 	%fd841, %fd178, %fd177, %fd637;

$L__BB14_129:
	and.b32  	%r215, %r300, 2;
	setp.eq.s32 	%p131, %r215, 0;
	@%p131 bra 	$L__BB14_131;

	mov.f64 	%fd638, 0d0000000000000000;
	mov.f64 	%fd639, 0dBFF0000000000000;
	fma.rn.f64 	%fd841, %fd841, %fd639, %fd638;

$L__BB14_131:
	mul.rn.f64 	%fd640, %fd841, 0d4044000000000000;
	mul.rn.f64 	%fd641, %fd838, 0d4034000000000000;
	add.rn.f64 	%fd184, %fd641, %fd640;
	div.rn.f64 	%fd185, %fd84, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd185;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r217}, %fd185;
	}
	and.b32  	%r218, %r217, 2147483647;
	setp.eq.s32 	%p132, %r218, 2146435072;
	setp.eq.s32 	%p133, %r216, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB14_134;
	bra.uni 	$L__BB14_132;

$L__BB14_134:
	mov.f64 	%fd651, 0d0000000000000000;
	mul.rn.f64 	%fd842, %fd185, %fd651;
	mov.u32 	%r301, 0;
	bra.uni 	$L__BB14_135;

$L__BB14_132:
	mul.rn.f64 	%fd642, %fd185, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r301, %fd642;
	st.local.u32 	[%rd1], %r301;
	cvt.rn.f64.s32 	%fd643, %r301;
	neg.f64 	%fd644, %fd643;
	mov.f64 	%fd645, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd646, %fd644, %fd645, %fd185;
	mov.f64 	%fd647, 0d3C91A62633145C00;
	fma.rn.f64 	%fd648, %fd644, %fd647, %fd646;
	mov.f64 	%fd649, 0d397B839A252049C0;
	fma.rn.f64 	%fd842, %fd644, %fd649, %fd648;
	abs.f64 	%fd650, %fd185;
	setp.ltu.f64 	%p135, %fd650, 0d41E0000000000000;
	@%p135 bra 	$L__BB14_135;

	{ // callseq 176, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd185;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd842, [retval0+0];
	} // callseq 176
	ld.local.u32 	%r301, [%rd1];

$L__BB14_135:
	and.b32  	%r220, %r301, 1;
	shl.b32 	%r221, %r301, 3;
	and.b32  	%r222, %r221, 8;
	setp.eq.s32 	%p136, %r220, 0;
	selp.f64 	%fd652, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd89, %r222, 8;
	add.s64 	%rd91, %rd42, %rd89;
	ld.global.nc.f64 	%fd653, [%rd91+8];
	mul.rn.f64 	%fd190, %fd842, %fd842;
	fma.rn.f64 	%fd654, %fd652, %fd190, %fd653;
	ld.global.nc.f64 	%fd655, [%rd91+16];
	fma.rn.f64 	%fd656, %fd654, %fd190, %fd655;
	ld.global.nc.f64 	%fd657, [%rd91+24];
	fma.rn.f64 	%fd658, %fd656, %fd190, %fd657;
	ld.global.nc.f64 	%fd659, [%rd91+32];
	fma.rn.f64 	%fd660, %fd658, %fd190, %fd659;
	ld.global.nc.f64 	%fd661, [%rd91+40];
	fma.rn.f64 	%fd662, %fd660, %fd190, %fd661;
	ld.global.nc.f64 	%fd663, [%rd91+48];
	fma.rn.f64 	%fd191, %fd662, %fd190, %fd663;
	fma.rn.f64 	%fd844, %fd191, %fd842, %fd842;
	@%p136 bra 	$L__BB14_137;

	mov.f64 	%fd664, 0d3FF0000000000000;
	fma.rn.f64 	%fd844, %fd191, %fd190, %fd664;

$L__BB14_137:
	and.b32  	%r223, %r301, 2;
	setp.eq.s32 	%p137, %r223, 0;
	@%p137 bra 	$L__BB14_139;

	mov.f64 	%fd665, 0d0000000000000000;
	mov.f64 	%fd666, 0dBFF0000000000000;
	fma.rn.f64 	%fd844, %fd844, %fd666, %fd665;

$L__BB14_139:
	mul.rn.f64 	%fd667, %fd844, 0d4062C00000000000;
	add.rn.f64 	%fd197, %fd184, %fd667;
	div.rn.f64 	%fd198, %fd84, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd198;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r225}, %fd198;
	}
	and.b32  	%r226, %r225, 2147483647;
	setp.eq.s32 	%p138, %r226, 2146435072;
	setp.eq.s32 	%p139, %r224, 0;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB14_142;
	bra.uni 	$L__BB14_140;

$L__BB14_142:
	mov.f64 	%fd677, 0d0000000000000000;
	mul.rn.f64 	%fd845, %fd198, %fd677;
	mov.u32 	%r302, 0;
	bra.uni 	$L__BB14_143;

$L__BB14_140:
	mul.rn.f64 	%fd668, %fd198, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r302, %fd668;
	st.local.u32 	[%rd1], %r302;
	cvt.rn.f64.s32 	%fd669, %r302;
	neg.f64 	%fd670, %fd669;
	mov.f64 	%fd671, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd672, %fd670, %fd671, %fd198;
	mov.f64 	%fd673, 0d3C91A62633145C00;
	fma.rn.f64 	%fd674, %fd670, %fd673, %fd672;
	mov.f64 	%fd675, 0d397B839A252049C0;
	fma.rn.f64 	%fd845, %fd670, %fd675, %fd674;
	abs.f64 	%fd676, %fd198;
	setp.ltu.f64 	%p141, %fd676, 0d41E0000000000000;
	@%p141 bra 	$L__BB14_143;

	{ // callseq 177, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd198;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd845, [retval0+0];
	} // callseq 177
	ld.local.u32 	%r302, [%rd1];

$L__BB14_143:
	and.b32  	%r228, %r302, 1;
	shl.b32 	%r229, %r302, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p142, %r228, 0;
	selp.f64 	%fd678, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p142;
	mul.wide.s32 	%rd93, %r230, 8;
	add.s64 	%rd95, %rd42, %rd93;
	ld.global.nc.f64 	%fd679, [%rd95+8];
	mul.rn.f64 	%fd203, %fd845, %fd845;
	fma.rn.f64 	%fd680, %fd678, %fd203, %fd679;
	ld.global.nc.f64 	%fd681, [%rd95+16];
	fma.rn.f64 	%fd682, %fd680, %fd203, %fd681;
	ld.global.nc.f64 	%fd683, [%rd95+24];
	fma.rn.f64 	%fd684, %fd682, %fd203, %fd683;
	ld.global.nc.f64 	%fd685, [%rd95+32];
	fma.rn.f64 	%fd686, %fd684, %fd203, %fd685;
	ld.global.nc.f64 	%fd687, [%rd95+40];
	fma.rn.f64 	%fd688, %fd686, %fd203, %fd687;
	ld.global.nc.f64 	%fd689, [%rd95+48];
	fma.rn.f64 	%fd204, %fd688, %fd203, %fd689;
	fma.rn.f64 	%fd847, %fd204, %fd845, %fd845;
	@%p142 bra 	$L__BB14_145;

	mov.f64 	%fd690, 0d3FF0000000000000;
	fma.rn.f64 	%fd847, %fd204, %fd203, %fd690;

$L__BB14_145:
	and.b32  	%r231, %r302, 2;
	setp.eq.s32 	%p143, %r231, 0;
	@%p143 bra 	$L__BB14_147;

	mov.f64 	%fd691, 0d0000000000000000;
	mov.f64 	%fd692, 0dBFF0000000000000;
	fma.rn.f64 	%fd847, %fd847, %fd692, %fd691;

$L__BB14_147:
	mul.rn.f64 	%fd693, %fd847, 0d4072C00000000000;
	add.rn.f64 	%fd694, %fd197, %fd693;
	add.rn.f64 	%fd210, %fd110, %fd694;
	add.rn.f64 	%fd211, %fd110, %fd160;
	add.rn.f64 	%fd695, %fd80, %fd80;
	add.rn.f64 	%fd696, %fd695, 0dC059000000000000;
	mul.rn.f64 	%fd697, %fd81, 0d4008000000000000;
	add.rn.f64 	%fd212, %fd697, %fd696;
	abs.f64 	%fd213, %fd81;
	{ // callseq 178, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd213;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd850, [retval0+0];
	} // callseq 178
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd81;
	}
	setp.lt.s32 	%p144, %r53, 0;
	and.pred  	%p4, %p144, %p7;
	not.pred 	%p146, %p4;
	@%p146 bra 	$L__BB14_149;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r232}, %fd850;
	}
	xor.b32  	%r233, %r232, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd850;
	}
	mov.b64 	%fd850, {%r234, %r233};

$L__BB14_149:
	setp.eq.f64 	%p147, %fd81, 0d0000000000000000;
	@%p147 bra 	$L__BB14_153;
	bra.uni 	$L__BB14_150;

$L__BB14_153:
	selp.b32 	%r235, %r53, 0, %p7;
	mov.u32 	%r236, 0;
	or.b32  	%r237, %r235, 2146435072;
	setp.lt.s32 	%p151, %r2, 0;
	selp.b32 	%r238, %r237, %r235, %p151;
	mov.b64 	%fd850, {%r236, %r238};
	bra.uni 	$L__BB14_154;

$L__BB14_150:
	setp.gt.s32 	%p148, %r53, -1;
	@%p148 bra 	$L__BB14_154;

	mov.f64 	%fd698, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd699, %fd698;
	setp.eq.f64 	%p149, %fd699, 0d4000000000000000;
	@%p149 bra 	$L__BB14_154;

	mov.f64 	%fd850, 0dFFF8000000000000;

$L__BB14_154:
	add.rn.f64 	%fd701, %fd81, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r239}, %fd701;
	}
	and.b32  	%r240, %r239, 2146435072;
	setp.ne.s32 	%p152, %r240, 2146435072;
	@%p152 bra 	$L__BB14_161;

	setp.gtu.f64 	%p153, %fd213, 0d7FF0000000000000;
	@%p153 bra 	$L__BB14_160;
	bra.uni 	$L__BB14_156;

$L__BB14_160:
	mov.f64 	%fd703, 0d4000000000000000;
	add.rn.f64 	%fd850, %fd81, %fd703;
	bra.uni 	$L__BB14_161;

$L__BB14_156:
	mov.f64 	%fd702, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r241, %temp}, %fd702;
	}
	and.b32  	%r54, %r2, 2147483647;
	setp.eq.s32 	%p154, %r54, 2146435072;
	setp.eq.s32 	%p155, %r241, 0;
	and.pred  	%p156, %p154, %p155;
	@%p156 bra 	$L__BB14_159;
	bra.uni 	$L__BB14_157;

$L__BB14_159:
	setp.gt.f64 	%p163, %fd213, 0d3FF0000000000000;
	selp.b32 	%r248, 2146435072, 0, %p163;
	mov.u32 	%r249, 0;
	xor.b32  	%r250, %r248, 2146435072;
	setp.lt.s32 	%p164, %r2, 0;
	selp.b32 	%r251, %r250, %r248, %p164;
	setp.eq.f64 	%p165, %fd81, 0dBFF0000000000000;
	selp.b32 	%r252, 1072693248, %r251, %p165;
	mov.b64 	%fd850, {%r249, %r252};
	bra.uni 	$L__BB14_161;

$L__BB14_157:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd81;
	}
	and.b32  	%r243, %r53, 2147483647;
	setp.ne.s32 	%p157, %r243, 2146435072;
	setp.ne.s32 	%p158, %r242, 0;
	or.pred  	%p159, %p157, %p158;
	@%p159 bra 	$L__BB14_161;

	setp.gt.s32 	%p160, %r2, -1;
	selp.b32 	%r244, 2146435072, 0, %p160;
	mov.u32 	%r245, 0;
	setp.ne.s32 	%p161, %r54, 1071644672;
	and.pred  	%p162, %p161, %p4;
	or.b32  	%r246, %r244, -2147483648;
	selp.b32 	%r247, %r246, %r244, %p162;
	mov.b64 	%fd850, {%r245, %r247};

$L__BB14_161:
	mul.rn.f64 	%fd704, %fd850, 0d3FC999999999999A;
	setp.eq.f64 	%p166, %fd81, 0d3FF0000000000000;
	selp.f64 	%fd705, 0d3FC999999999999A, %fd704, %p166;
	add.rn.f64 	%fd706, %fd212, %fd705;
	mul.rn.f64 	%fd707, %fd81, %fd80;
	mul.rn.f64 	%fd223, %fd707, 0d3FB999999999999A;
	add.rn.f64 	%fd708, %fd223, %fd706;
	mul.rn.f64 	%fd709, %fd83, 0d3FC999999999999A;
	add.rn.f64 	%fd710, %fd709, %fd708;
	mul.rn.f64 	%fd711, %fd211, 0d3FE5555555555555;
	add.rn.f64 	%fd224, %fd711, %fd710;
	add.rn.f64 	%fd712, %fd81, %fd81;
	add.rn.f64 	%fd713, %fd80, 0d4072C00000000000;
	add.rn.f64 	%fd225, %fd712, %fd713;
	{ // callseq 179, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd82;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd853, [retval0+0];
	} // callseq 179
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd80;
	}
	setp.lt.s32 	%p167, %r55, 0;
	and.pred  	%p5, %p167, %p7;
	not.pred 	%p169, %p5;
	@%p169 bra 	$L__BB14_163;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r253}, %fd853;
	}
	xor.b32  	%r254, %r253, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r255, %temp}, %fd853;
	}
	mov.b64 	%fd853, {%r255, %r254};

$L__BB14_163:
	setp.eq.f64 	%p170, %fd80, 0d0000000000000000;
	@%p170 bra 	$L__BB14_167;
	bra.uni 	$L__BB14_164;

$L__BB14_167:
	selp.b32 	%r256, %r55, 0, %p7;
	mov.u32 	%r257, 0;
	or.b32  	%r258, %r256, 2146435072;
	setp.lt.s32 	%p174, %r2, 0;
	selp.b32 	%r259, %r258, %r256, %p174;
	mov.b64 	%fd853, {%r257, %r259};
	bra.uni 	$L__BB14_168;

$L__BB14_164:
	setp.gt.s32 	%p171, %r55, -1;
	@%p171 bra 	$L__BB14_168;

	mov.f64 	%fd714, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd715, %fd714;
	setp.eq.f64 	%p172, %fd715, 0d4000000000000000;
	@%p172 bra 	$L__BB14_168;

	mov.f64 	%fd853, 0dFFF8000000000000;

$L__BB14_168:
	add.rn.f64 	%fd717, %fd80, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r260}, %fd717;
	}
	and.b32  	%r261, %r260, 2146435072;
	setp.ne.s32 	%p175, %r261, 2146435072;
	@%p175 bra 	$L__BB14_175;

	setp.gtu.f64 	%p176, %fd82, 0d7FF0000000000000;
	@%p176 bra 	$L__BB14_174;
	bra.uni 	$L__BB14_170;

$L__BB14_174:
	mov.f64 	%fd719, 0d4000000000000000;
	add.rn.f64 	%fd853, %fd80, %fd719;
	bra.uni 	$L__BB14_175;

$L__BB14_170:
	mov.f64 	%fd718, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r262, %temp}, %fd718;
	}
	and.b32  	%r56, %r2, 2147483647;
	setp.eq.s32 	%p177, %r56, 2146435072;
	setp.eq.s32 	%p178, %r262, 0;
	and.pred  	%p179, %p177, %p178;
	@%p179 bra 	$L__BB14_173;
	bra.uni 	$L__BB14_171;

$L__BB14_173:
	setp.gt.f64 	%p186, %fd82, 0d3FF0000000000000;
	selp.b32 	%r269, 2146435072, 0, %p186;
	mov.u32 	%r270, 0;
	xor.b32  	%r271, %r269, 2146435072;
	setp.lt.s32 	%p187, %r2, 0;
	selp.b32 	%r272, %r271, %r269, %p187;
	setp.eq.f64 	%p188, %fd80, 0dBFF0000000000000;
	selp.b32 	%r273, 1072693248, %r272, %p188;
	mov.b64 	%fd853, {%r270, %r273};
	bra.uni 	$L__BB14_175;

$L__BB14_171:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r263, %temp}, %fd80;
	}
	and.b32  	%r264, %r55, 2147483647;
	setp.ne.s32 	%p180, %r264, 2146435072;
	setp.ne.s32 	%p181, %r263, 0;
	or.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB14_175;

	setp.gt.s32 	%p183, %r2, -1;
	selp.b32 	%r265, 2146435072, 0, %p183;
	mov.u32 	%r266, 0;
	setp.ne.s32 	%p184, %r56, 1071644672;
	and.pred  	%p185, %p184, %p5;
	or.b32  	%r267, %r265, -2147483648;
	selp.b32 	%r268, %r267, %r265, %p185;
	mov.b64 	%fd853, {%r266, %r268};

$L__BB14_175:
	mul.rn.f64 	%fd720, %fd853, 0d3FB999999999999A;
	setp.eq.f64 	%p189, %fd80, 0d3FF0000000000000;
	selp.f64 	%fd721, 0d3FB999999999999A, %fd720, %p189;
	add.rn.f64 	%fd722, %fd225, %fd721;
	add.rn.f64 	%fd723, %fd223, %fd722;
	mul.rn.f64 	%fd724, %fd83, 0d3FB999999999999A;
	add.rn.f64 	%fd725, %fd724, %fd723;
	mul.rn.f64 	%fd726, %fd210, 0d3FE5555555555555;
	add.rn.f64 	%fd235, %fd726, %fd725;
	div.rn.f64 	%fd727, %fd78, 0d4066800000000000;
	mul.rn.f64 	%fd236, %fd727, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd236;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd236;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p190, %r276, 2146435072;
	setp.eq.s32 	%p191, %r274, 0;
	and.pred  	%p6, %p191, %p190;
	@%p6 bra 	$L__BB14_178;
	bra.uni 	$L__BB14_176;

$L__BB14_178:
	mov.f64 	%fd737, 0d0000000000000000;
	mul.rn.f64 	%fd854, %fd236, %fd737;
	mov.u32 	%r303, 0;
	bra.uni 	$L__BB14_179;

$L__BB14_176:
	mul.rn.f64 	%fd728, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r303, %fd728;
	st.local.u32 	[%rd1], %r303;
	cvt.rn.f64.s32 	%fd729, %r303;
	neg.f64 	%fd730, %fd729;
	mov.f64 	%fd731, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd732, %fd730, %fd731, %fd236;
	mov.f64 	%fd733, 0d3C91A62633145C00;
	fma.rn.f64 	%fd734, %fd730, %fd733, %fd732;
	mov.f64 	%fd735, 0d397B839A252049C0;
	fma.rn.f64 	%fd854, %fd730, %fd735, %fd734;
	abs.f64 	%fd736, %fd236;
	setp.ltu.f64 	%p192, %fd736, 0d41E0000000000000;
	@%p192 bra 	$L__BB14_179;

	{ // callseq 180, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd854, [retval0+0];
	} // callseq 180
	ld.local.u32 	%r303, [%rd1];

$L__BB14_179:
	and.b32  	%r278, %r303, 1;
	shl.b32 	%r279, %r303, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p193, %r278, 0;
	selp.f64 	%fd738, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p193;
	mul.wide.s32 	%rd97, %r280, 8;
	add.s64 	%rd99, %rd42, %rd97;
	ld.global.nc.f64 	%fd739, [%rd99+8];
	mul.rn.f64 	%fd241, %fd854, %fd854;
	fma.rn.f64 	%fd740, %fd738, %fd241, %fd739;
	ld.global.nc.f64 	%fd741, [%rd99+16];
	fma.rn.f64 	%fd742, %fd740, %fd241, %fd741;
	ld.global.nc.f64 	%fd743, [%rd99+24];
	fma.rn.f64 	%fd744, %fd742, %fd241, %fd743;
	ld.global.nc.f64 	%fd745, [%rd99+32];
	fma.rn.f64 	%fd746, %fd744, %fd241, %fd745;
	ld.global.nc.f64 	%fd747, [%rd99+40];
	fma.rn.f64 	%fd748, %fd746, %fd241, %fd747;
	ld.global.nc.f64 	%fd749, [%rd99+48];
	fma.rn.f64 	%fd242, %fd748, %fd241, %fd749;
	fma.rn.f64 	%fd856, %fd242, %fd854, %fd854;
	@%p193 bra 	$L__BB14_181;

	mov.f64 	%fd750, 0d3FF0000000000000;
	fma.rn.f64 	%fd856, %fd242, %fd241, %fd750;

$L__BB14_181:
	and.b32  	%r281, %r303, 2;
	setp.eq.s32 	%p194, %r281, 0;
	@%p194 bra 	$L__BB14_183;

	mov.f64 	%fd751, 0d0000000000000000;
	mov.f64 	%fd752, 0dBFF0000000000000;
	fma.rn.f64 	%fd856, %fd856, %fd752, %fd751;

$L__BB14_183:
	@%p6 bra 	$L__BB14_187;
	bra.uni 	$L__BB14_184;

$L__BB14_187:
	mov.f64 	%fd762, 0d0000000000000000;
	mul.rn.f64 	%fd858, %fd236, %fd762;
	mov.u32 	%r305, 1;
	bra.uni 	$L__BB14_188;

$L__BB14_184:
	mul.rn.f64 	%fd753, %fd236, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r304, %fd753;
	st.local.u32 	[%rd1], %r304;
	cvt.rn.f64.s32 	%fd754, %r304;
	neg.f64 	%fd755, %fd754;
	mov.f64 	%fd756, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd757, %fd755, %fd756, %fd236;
	mov.f64 	%fd758, 0d3C91A62633145C00;
	fma.rn.f64 	%fd759, %fd755, %fd758, %fd757;
	mov.f64 	%fd760, 0d397B839A252049C0;
	fma.rn.f64 	%fd858, %fd755, %fd760, %fd759;
	abs.f64 	%fd761, %fd236;
	setp.ltu.f64 	%p195, %fd761, 0d41E0000000000000;
	@%p195 bra 	$L__BB14_186;

	{ // callseq 181, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd236;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd22;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd858, [retval0+0];
	} // callseq 181
	ld.local.u32 	%r304, [%rd1];

$L__BB14_186:
	add.s32 	%r305, %r304, 1;

$L__BB14_188:
	and.b32  	%r283, %r305, 1;
	shl.b32 	%r284, %r305, 3;
	and.b32  	%r285, %r284, 8;
	setp.eq.s32 	%p196, %r283, 0;
	selp.f64 	%fd763, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd101, %r285, 8;
	add.s64 	%rd103, %rd42, %rd101;
	ld.global.nc.f64 	%fd764, [%rd103+8];
	mul.rn.f64 	%fd253, %fd858, %fd858;
	fma.rn.f64 	%fd765, %fd763, %fd253, %fd764;
	ld.global.nc.f64 	%fd766, [%rd103+16];
	fma.rn.f64 	%fd767, %fd765, %fd253, %fd766;
	ld.global.nc.f64 	%fd768, [%rd103+24];
	fma.rn.f64 	%fd769, %fd767, %fd253, %fd768;
	ld.global.nc.f64 	%fd770, [%rd103+32];
	fma.rn.f64 	%fd771, %fd769, %fd253, %fd770;
	ld.global.nc.f64 	%fd772, [%rd103+40];
	fma.rn.f64 	%fd773, %fd771, %fd253, %fd772;
	ld.global.nc.f64 	%fd774, [%rd103+48];
	fma.rn.f64 	%fd254, %fd773, %fd253, %fd774;
	fma.rn.f64 	%fd860, %fd254, %fd858, %fd858;
	@%p196 bra 	$L__BB14_190;

	mov.f64 	%fd775, 0d3FF0000000000000;
	fma.rn.f64 	%fd860, %fd254, %fd253, %fd775;

$L__BB14_190:
	and.b32  	%r286, %r305, 2;
	setp.eq.s32 	%p197, %r286, 0;
	@%p197 bra 	$L__BB14_192;

	mov.f64 	%fd776, 0d0000000000000000;
	mov.f64 	%fd777, 0dBFF0000000000000;
	fma.rn.f64 	%fd860, %fd860, %fd777, %fd776;

$L__BB14_192:
	mul.rn.f64 	%fd778, %fd856, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd779, %fd856, %fd778;
	add.rn.f64 	%fd780, %fd779, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd781, %fd780;
	mov.f64 	%fd782, 0dC15854C140000000;
	div.rn.f64 	%fd783, %fd782, %fd781;
	mul.rn.f64 	%fd784, %fd783, %fd860;
	mul.rn.f64 	%fd785, %fd784, 0d400921FB54442D18;
	mul.rn.f64 	%fd786, %fd235, 0d4066800000000000;
	div.rn.f64 	%fd787, %fd786, %fd785;
	add.rn.f64 	%fd788, %fd79, %fd787;
	st.global.f64 	[%rd17], %fd788;
	mul.rn.f64 	%fd789, %fd224, 0d4066800000000000;
	mul.rn.f64 	%fd790, %fd781, %fd780;
	mov.f64 	%fd791, 0dC1582B102DE355C1;
	div.rn.f64 	%fd792, %fd791, %fd790;
	mul.rn.f64 	%fd793, %fd792, 0d400921FB54442D18;
	div.rn.f64 	%fd794, %fd789, %fd793;
	add.rn.f64 	%fd795, %fd78, %fd794;
	st.global.f64 	[%rd18], %fd795;
	ret;

}
	// .globl	gcj02_to_wgs84_exact_cuda_double
.visible .entry gcj02_to_wgs84_exact_cuda_double(
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_0,
	.param .u64 gcj02_to_wgs84_exact_cuda_double_param_1,
	.param .f64 gcj02_to_wgs84_exact_cuda_double_param_2,
	.param .u8 gcj02_to_wgs84_exact_cuda_double_param_3,
	.param .u32 gcj02_to_wgs84_exact_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot15[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<321>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<511>;
	.reg .f64 	%fd<1484>;
	.reg .b64 	%rd<184>;


	mov.u64 	%SPL, __local_depot15;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd31, [gcj02_to_wgs84_exact_cuda_double_param_0];
	ld.param.u64 	%rd32, [gcj02_to_wgs84_exact_cuda_double_param_1];
	ld.param.f64 	%fd453, [gcj02_to_wgs84_exact_cuda_double_param_2];
	cvta.to.global.u64 	%rd33, %rd32;
	add.u64 	%rd34, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r109, %ntid.x;
	mov.u32 	%r110, %ctaid.x;
	mov.u32 	%r111, %tid.x;
	mad.lo.s32 	%r112, %r110, %r109, %r111;
	cvta.to.global.u64 	%rd62, %rd31;
	mul.wide.s32 	%rd63, %r112, 8;
	add.s64 	%rd29, %rd62, %rd63;
	add.s64 	%rd30, %rd33, %rd63;
	ld.global.f64 	%fd1, [%rd29];
	add.rn.f64 	%fd2, %fd1, 0dC05A400000000000;
	ld.global.f64 	%fd3, [%rd30];
	add.rn.f64 	%fd4, %fd3, 0dC041800000000000;
	abs.f64 	%fd5, %fd2;
	sqrt.rn.f64 	%fd6, %fd5;
	mul.rn.f64 	%fd7, %fd2, 0d400921FB54442D18;
	mul.rn.f64 	%fd8, %fd4, 0d400921FB54442D18;
	mul.rn.f64 	%fd9, %fd7, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r113, %temp}, %fd9;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r114}, %fd9;
	}
	and.b32  	%r115, %r114, 2147483647;
	setp.eq.s32 	%p9, %r115, 2146435072;
	setp.eq.s32 	%p10, %r113, 0;
	and.pred  	%p11, %p10, %p9;
	@%p11 bra 	$L__BB15_3;
	bra.uni 	$L__BB15_1;

$L__BB15_3:
	mov.f64 	%fd463, 0d0000000000000000;
	mul.rn.f64 	%fd1373, %fd9, %fd463;
	mov.u32 	%r478, 0;
	bra.uni 	$L__BB15_4;

$L__BB15_1:
	mul.rn.f64 	%fd454, %fd9, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r478, %fd454;
	st.local.u32 	[%rd1], %r478;
	cvt.rn.f64.s32 	%fd455, %r478;
	neg.f64 	%fd456, %fd455;
	mov.f64 	%fd457, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd458, %fd456, %fd457, %fd9;
	mov.f64 	%fd459, 0d3C91A62633145C00;
	fma.rn.f64 	%fd460, %fd456, %fd459, %fd458;
	mov.f64 	%fd461, 0d397B839A252049C0;
	fma.rn.f64 	%fd1373, %fd456, %fd461, %fd460;
	abs.f64 	%fd462, %fd9;
	setp.ltu.f64 	%p12, %fd462, 0d41E0000000000000;
	@%p12 bra 	$L__BB15_4;

	{ // callseq 182, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd9;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1373, [retval0+0];
	} // callseq 182
	ld.local.u32 	%r478, [%rd1];

$L__BB15_4:
	and.b32  	%r117, %r478, 1;
	shl.b32 	%r118, %r478, 3;
	and.b32  	%r119, %r118, 8;
	setp.eq.s32 	%p13, %r117, 0;
	selp.f64 	%fd464, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p13;
	mul.wide.s32 	%rd65, %r119, 8;
	mov.u64 	%rd66, __cudart_sin_cos_coeffs;
	add.s64 	%rd67, %rd66, %rd65;
	ld.global.nc.f64 	%fd465, [%rd67+8];
	mul.rn.f64 	%fd14, %fd1373, %fd1373;
	fma.rn.f64 	%fd466, %fd464, %fd14, %fd465;
	ld.global.nc.f64 	%fd467, [%rd67+16];
	fma.rn.f64 	%fd468, %fd466, %fd14, %fd467;
	ld.global.nc.f64 	%fd469, [%rd67+24];
	fma.rn.f64 	%fd470, %fd468, %fd14, %fd469;
	ld.global.nc.f64 	%fd471, [%rd67+32];
	fma.rn.f64 	%fd472, %fd470, %fd14, %fd471;
	ld.global.nc.f64 	%fd473, [%rd67+40];
	fma.rn.f64 	%fd474, %fd472, %fd14, %fd473;
	ld.global.nc.f64 	%fd475, [%rd67+48];
	fma.rn.f64 	%fd15, %fd474, %fd14, %fd475;
	fma.rn.f64 	%fd1375, %fd15, %fd1373, %fd1373;
	@%p13 bra 	$L__BB15_6;

	mov.f64 	%fd476, 0d3FF0000000000000;
	fma.rn.f64 	%fd1375, %fd15, %fd14, %fd476;

$L__BB15_6:
	and.b32  	%r120, %r478, 2;
	setp.eq.s32 	%p14, %r120, 0;
	@%p14 bra 	$L__BB15_8;

	mov.f64 	%fd477, 0d0000000000000000;
	mov.f64 	%fd478, 0dBFF0000000000000;
	fma.rn.f64 	%fd1375, %fd1375, %fd478, %fd477;

$L__BB15_8:
	add.rn.f64 	%fd21, %fd7, %fd7;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r121, %temp}, %fd21;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r122}, %fd21;
	}
	and.b32  	%r123, %r122, 2147483647;
	setp.eq.s32 	%p15, %r123, 2146435072;
	setp.eq.s32 	%p16, %r121, 0;
	and.pred  	%p17, %p16, %p15;
	@%p17 bra 	$L__BB15_11;
	bra.uni 	$L__BB15_9;

$L__BB15_11:
	mov.f64 	%fd488, 0d0000000000000000;
	mul.rn.f64 	%fd1376, %fd21, %fd488;
	mov.u32 	%r479, 0;
	bra.uni 	$L__BB15_12;

$L__BB15_9:
	mul.rn.f64 	%fd479, %fd21, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r479, %fd479;
	st.local.u32 	[%rd1], %r479;
	cvt.rn.f64.s32 	%fd480, %r479;
	neg.f64 	%fd481, %fd480;
	mov.f64 	%fd482, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd483, %fd481, %fd482, %fd21;
	mov.f64 	%fd484, 0d3C91A62633145C00;
	fma.rn.f64 	%fd485, %fd481, %fd484, %fd483;
	mov.f64 	%fd486, 0d397B839A252049C0;
	fma.rn.f64 	%fd1376, %fd481, %fd486, %fd485;
	abs.f64 	%fd487, %fd21;
	setp.ltu.f64 	%p18, %fd487, 0d41E0000000000000;
	@%p18 bra 	$L__BB15_12;

	{ // callseq 183, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd21;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1376, [retval0+0];
	} // callseq 183
	ld.local.u32 	%r479, [%rd1];

$L__BB15_12:
	and.b32  	%r125, %r479, 1;
	shl.b32 	%r126, %r479, 3;
	and.b32  	%r127, %r126, 8;
	setp.eq.s32 	%p19, %r125, 0;
	selp.f64 	%fd489, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p19;
	mul.wide.s32 	%rd69, %r127, 8;
	add.s64 	%rd71, %rd66, %rd69;
	ld.global.nc.f64 	%fd490, [%rd71+8];
	mul.rn.f64 	%fd26, %fd1376, %fd1376;
	fma.rn.f64 	%fd491, %fd489, %fd26, %fd490;
	ld.global.nc.f64 	%fd492, [%rd71+16];
	fma.rn.f64 	%fd493, %fd491, %fd26, %fd492;
	ld.global.nc.f64 	%fd494, [%rd71+24];
	fma.rn.f64 	%fd495, %fd493, %fd26, %fd494;
	ld.global.nc.f64 	%fd496, [%rd71+32];
	fma.rn.f64 	%fd497, %fd495, %fd26, %fd496;
	ld.global.nc.f64 	%fd498, [%rd71+40];
	fma.rn.f64 	%fd499, %fd497, %fd26, %fd498;
	ld.global.nc.f64 	%fd500, [%rd71+48];
	fma.rn.f64 	%fd27, %fd499, %fd26, %fd500;
	fma.rn.f64 	%fd1378, %fd27, %fd1376, %fd1376;
	@%p19 bra 	$L__BB15_14;

	mov.f64 	%fd501, 0d3FF0000000000000;
	fma.rn.f64 	%fd1378, %fd27, %fd26, %fd501;

$L__BB15_14:
	and.b32  	%r128, %r479, 2;
	setp.eq.s32 	%p20, %r128, 0;
	@%p20 bra 	$L__BB15_16;

	mov.f64 	%fd502, 0d0000000000000000;
	mov.f64 	%fd503, 0dBFF0000000000000;
	fma.rn.f64 	%fd1378, %fd1378, %fd503, %fd502;

$L__BB15_16:
	mul.rn.f64 	%fd504, %fd1378, 0d4034000000000000;
	mul.rn.f64 	%fd505, %fd1375, 0d4034000000000000;
	add.rn.f64 	%fd33, %fd505, %fd504;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r129}, %fd8;
	}
	and.b32  	%r130, %r129, 2147483647;
	setp.eq.s32 	%p21, %r130, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd8;
	}
	setp.eq.s32 	%p22, %r131, 0;
	and.pred  	%p23, %p22, %p21;
	@%p23 bra 	$L__BB15_19;
	bra.uni 	$L__BB15_17;

$L__BB15_19:
	mov.f64 	%fd515, 0d0000000000000000;
	mul.rn.f64 	%fd1379, %fd8, %fd515;
	mov.u32 	%r480, 0;
	bra.uni 	$L__BB15_20;

$L__BB15_17:
	mul.rn.f64 	%fd506, %fd8, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r480, %fd506;
	st.local.u32 	[%rd1], %r480;
	cvt.rn.f64.s32 	%fd507, %r480;
	neg.f64 	%fd508, %fd507;
	mov.f64 	%fd509, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd510, %fd508, %fd509, %fd8;
	mov.f64 	%fd511, 0d3C91A62633145C00;
	fma.rn.f64 	%fd512, %fd508, %fd511, %fd510;
	mov.f64 	%fd513, 0d397B839A252049C0;
	fma.rn.f64 	%fd1379, %fd508, %fd513, %fd512;
	abs.f64 	%fd514, %fd8;
	setp.ltu.f64 	%p24, %fd514, 0d41E0000000000000;
	@%p24 bra 	$L__BB15_20;

	{ // callseq 184, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd8;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1379, [retval0+0];
	} // callseq 184
	ld.local.u32 	%r480, [%rd1];

$L__BB15_20:
	and.b32  	%r133, %r480, 1;
	shl.b32 	%r134, %r480, 3;
	and.b32  	%r135, %r134, 8;
	setp.eq.s32 	%p25, %r133, 0;
	selp.f64 	%fd516, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p25;
	mul.wide.s32 	%rd73, %r135, 8;
	add.s64 	%rd75, %rd66, %rd73;
	ld.global.nc.f64 	%fd517, [%rd75+8];
	mul.rn.f64 	%fd38, %fd1379, %fd1379;
	fma.rn.f64 	%fd518, %fd516, %fd38, %fd517;
	ld.global.nc.f64 	%fd519, [%rd75+16];
	fma.rn.f64 	%fd520, %fd518, %fd38, %fd519;
	ld.global.nc.f64 	%fd521, [%rd75+24];
	fma.rn.f64 	%fd522, %fd520, %fd38, %fd521;
	ld.global.nc.f64 	%fd523, [%rd75+32];
	fma.rn.f64 	%fd524, %fd522, %fd38, %fd523;
	ld.global.nc.f64 	%fd525, [%rd75+40];
	fma.rn.f64 	%fd526, %fd524, %fd38, %fd525;
	ld.global.nc.f64 	%fd527, [%rd75+48];
	fma.rn.f64 	%fd39, %fd526, %fd38, %fd527;
	fma.rn.f64 	%fd1381, %fd39, %fd1379, %fd1379;
	@%p25 bra 	$L__BB15_22;

	mov.f64 	%fd528, 0d3FF0000000000000;
	fma.rn.f64 	%fd1381, %fd39, %fd38, %fd528;

$L__BB15_22:
	and.b32  	%r136, %r480, 2;
	setp.eq.s32 	%p26, %r136, 0;
	@%p26 bra 	$L__BB15_24;

	mov.f64 	%fd529, 0d0000000000000000;
	mov.f64 	%fd530, 0dBFF0000000000000;
	fma.rn.f64 	%fd1381, %fd1381, %fd530, %fd529;

$L__BB15_24:
	add.rn.f64 	%fd1372, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1371, %fd1372, 0d400921FB54442D18;
	div.rn.f64 	%fd45, %fd1371, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r137, %temp}, %fd45;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r138}, %fd45;
	}
	and.b32  	%r139, %r138, 2147483647;
	setp.eq.s32 	%p27, %r139, 2146435072;
	setp.eq.s32 	%p28, %r137, 0;
	and.pred  	%p29, %p28, %p27;
	@%p29 bra 	$L__BB15_27;
	bra.uni 	$L__BB15_25;

$L__BB15_27:
	mov.f64 	%fd540, 0d0000000000000000;
	mul.rn.f64 	%fd1382, %fd45, %fd540;
	mov.u32 	%r481, 0;
	bra.uni 	$L__BB15_28;

$L__BB15_25:
	mul.rn.f64 	%fd531, %fd45, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r481, %fd531;
	st.local.u32 	[%rd1], %r481;
	cvt.rn.f64.s32 	%fd532, %r481;
	neg.f64 	%fd533, %fd532;
	mov.f64 	%fd534, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd535, %fd533, %fd534, %fd45;
	mov.f64 	%fd536, 0d3C91A62633145C00;
	fma.rn.f64 	%fd537, %fd533, %fd536, %fd535;
	mov.f64 	%fd538, 0d397B839A252049C0;
	fma.rn.f64 	%fd1382, %fd533, %fd538, %fd537;
	abs.f64 	%fd539, %fd45;
	setp.ltu.f64 	%p30, %fd539, 0d41E0000000000000;
	@%p30 bra 	$L__BB15_28;

	{ // callseq 185, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd45;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1382, [retval0+0];
	} // callseq 185
	ld.local.u32 	%r481, [%rd1];

$L__BB15_28:
	and.b32  	%r141, %r481, 1;
	shl.b32 	%r142, %r481, 3;
	and.b32  	%r143, %r142, 8;
	setp.eq.s32 	%p31, %r141, 0;
	selp.f64 	%fd541, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p31;
	mul.wide.s32 	%rd77, %r143, 8;
	add.s64 	%rd79, %rd66, %rd77;
	ld.global.nc.f64 	%fd542, [%rd79+8];
	mul.rn.f64 	%fd50, %fd1382, %fd1382;
	fma.rn.f64 	%fd543, %fd541, %fd50, %fd542;
	ld.global.nc.f64 	%fd544, [%rd79+16];
	fma.rn.f64 	%fd545, %fd543, %fd50, %fd544;
	ld.global.nc.f64 	%fd546, [%rd79+24];
	fma.rn.f64 	%fd547, %fd545, %fd50, %fd546;
	ld.global.nc.f64 	%fd548, [%rd79+32];
	fma.rn.f64 	%fd549, %fd547, %fd50, %fd548;
	ld.global.nc.f64 	%fd550, [%rd79+40];
	fma.rn.f64 	%fd551, %fd549, %fd50, %fd550;
	ld.global.nc.f64 	%fd552, [%rd79+48];
	fma.rn.f64 	%fd51, %fd551, %fd50, %fd552;
	fma.rn.f64 	%fd1384, %fd51, %fd1382, %fd1382;
	@%p31 bra 	$L__BB15_30;

	mov.f64 	%fd553, 0d3FF0000000000000;
	fma.rn.f64 	%fd1384, %fd51, %fd50, %fd553;

$L__BB15_30:
	and.b32  	%r144, %r481, 2;
	setp.eq.s32 	%p32, %r144, 0;
	@%p32 bra 	$L__BB15_32;

	mov.f64 	%fd554, 0d0000000000000000;
	mov.f64 	%fd555, 0dBFF0000000000000;
	fma.rn.f64 	%fd1384, %fd1384, %fd555, %fd554;

$L__BB15_32:
	add.rn.f64 	%fd1368, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1367, %fd1368, 0d400921FB54442D18;
	mul.rn.f64 	%fd556, %fd1384, 0d4044000000000000;
	mul.rn.f64 	%fd557, %fd1381, 0d4034000000000000;
	add.rn.f64 	%fd57, %fd557, %fd556;
	div.rn.f64 	%fd58, %fd1367, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r145, %temp}, %fd58;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r146}, %fd58;
	}
	and.b32  	%r147, %r146, 2147483647;
	setp.eq.s32 	%p33, %r147, 2146435072;
	setp.eq.s32 	%p34, %r145, 0;
	and.pred  	%p35, %p34, %p33;
	@%p35 bra 	$L__BB15_35;
	bra.uni 	$L__BB15_33;

$L__BB15_35:
	mov.f64 	%fd567, 0d0000000000000000;
	mul.rn.f64 	%fd1385, %fd58, %fd567;
	mov.u32 	%r482, 0;
	bra.uni 	$L__BB15_36;

$L__BB15_33:
	mul.rn.f64 	%fd558, %fd58, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r482, %fd558;
	st.local.u32 	[%rd1], %r482;
	cvt.rn.f64.s32 	%fd559, %r482;
	neg.f64 	%fd560, %fd559;
	mov.f64 	%fd561, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd562, %fd560, %fd561, %fd58;
	mov.f64 	%fd563, 0d3C91A62633145C00;
	fma.rn.f64 	%fd564, %fd560, %fd563, %fd562;
	mov.f64 	%fd565, 0d397B839A252049C0;
	fma.rn.f64 	%fd1385, %fd560, %fd565, %fd564;
	abs.f64 	%fd566, %fd58;
	setp.ltu.f64 	%p36, %fd566, 0d41E0000000000000;
	@%p36 bra 	$L__BB15_36;

	{ // callseq 186, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd58;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1385, [retval0+0];
	} // callseq 186
	ld.local.u32 	%r482, [%rd1];

$L__BB15_36:
	and.b32  	%r149, %r482, 1;
	shl.b32 	%r150, %r482, 3;
	and.b32  	%r151, %r150, 8;
	setp.eq.s32 	%p37, %r149, 0;
	selp.f64 	%fd568, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p37;
	mul.wide.s32 	%rd81, %r151, 8;
	add.s64 	%rd83, %rd66, %rd81;
	ld.global.nc.f64 	%fd569, [%rd83+8];
	mul.rn.f64 	%fd63, %fd1385, %fd1385;
	fma.rn.f64 	%fd570, %fd568, %fd63, %fd569;
	ld.global.nc.f64 	%fd571, [%rd83+16];
	fma.rn.f64 	%fd572, %fd570, %fd63, %fd571;
	ld.global.nc.f64 	%fd573, [%rd83+24];
	fma.rn.f64 	%fd574, %fd572, %fd63, %fd573;
	ld.global.nc.f64 	%fd575, [%rd83+32];
	fma.rn.f64 	%fd576, %fd574, %fd63, %fd575;
	ld.global.nc.f64 	%fd577, [%rd83+40];
	fma.rn.f64 	%fd578, %fd576, %fd63, %fd577;
	ld.global.nc.f64 	%fd579, [%rd83+48];
	fma.rn.f64 	%fd64, %fd578, %fd63, %fd579;
	fma.rn.f64 	%fd1387, %fd64, %fd1385, %fd1385;
	@%p37 bra 	$L__BB15_38;

	mov.f64 	%fd580, 0d3FF0000000000000;
	fma.rn.f64 	%fd1387, %fd64, %fd63, %fd580;

$L__BB15_38:
	and.b32  	%r152, %r482, 2;
	setp.eq.s32 	%p38, %r152, 0;
	@%p38 bra 	$L__BB15_40;

	mov.f64 	%fd581, 0d0000000000000000;
	mov.f64 	%fd582, 0dBFF0000000000000;
	fma.rn.f64 	%fd1387, %fd1387, %fd582, %fd581;

$L__BB15_40:
	add.rn.f64 	%fd1370, %fd3, 0dC041800000000000;
	mul.rn.f64 	%fd1369, %fd1370, 0d400921FB54442D18;
	mul.rn.f64 	%fd583, %fd1387, 0d4064000000000000;
	add.rn.f64 	%fd70, %fd57, %fd583;
	div.rn.f64 	%fd71, %fd1369, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd71;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r154}, %fd71;
	}
	and.b32  	%r155, %r154, 2147483647;
	setp.eq.s32 	%p39, %r155, 2146435072;
	setp.eq.s32 	%p40, %r153, 0;
	and.pred  	%p41, %p40, %p39;
	@%p41 bra 	$L__BB15_43;
	bra.uni 	$L__BB15_41;

$L__BB15_43:
	mov.f64 	%fd593, 0d0000000000000000;
	mul.rn.f64 	%fd1388, %fd71, %fd593;
	mov.u32 	%r483, 0;
	bra.uni 	$L__BB15_44;

$L__BB15_41:
	mul.rn.f64 	%fd584, %fd71, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r483, %fd584;
	st.local.u32 	[%rd1], %r483;
	cvt.rn.f64.s32 	%fd585, %r483;
	neg.f64 	%fd586, %fd585;
	mov.f64 	%fd587, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd588, %fd586, %fd587, %fd71;
	mov.f64 	%fd589, 0d3C91A62633145C00;
	fma.rn.f64 	%fd590, %fd586, %fd589, %fd588;
	mov.f64 	%fd591, 0d397B839A252049C0;
	fma.rn.f64 	%fd1388, %fd586, %fd591, %fd590;
	abs.f64 	%fd592, %fd71;
	setp.ltu.f64 	%p42, %fd592, 0d41E0000000000000;
	@%p42 bra 	$L__BB15_44;

	{ // callseq 187, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd71;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1388, [retval0+0];
	} // callseq 187
	ld.local.u32 	%r483, [%rd1];

$L__BB15_44:
	and.b32  	%r157, %r483, 1;
	shl.b32 	%r158, %r483, 3;
	and.b32  	%r159, %r158, 8;
	setp.eq.s32 	%p43, %r157, 0;
	selp.f64 	%fd594, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p43;
	mul.wide.s32 	%rd85, %r159, 8;
	add.s64 	%rd87, %rd66, %rd85;
	ld.global.nc.f64 	%fd595, [%rd87+8];
	mul.rn.f64 	%fd76, %fd1388, %fd1388;
	fma.rn.f64 	%fd596, %fd594, %fd76, %fd595;
	ld.global.nc.f64 	%fd597, [%rd87+16];
	fma.rn.f64 	%fd598, %fd596, %fd76, %fd597;
	ld.global.nc.f64 	%fd599, [%rd87+24];
	fma.rn.f64 	%fd600, %fd598, %fd76, %fd599;
	ld.global.nc.f64 	%fd601, [%rd87+32];
	fma.rn.f64 	%fd602, %fd600, %fd76, %fd601;
	ld.global.nc.f64 	%fd603, [%rd87+40];
	fma.rn.f64 	%fd604, %fd602, %fd76, %fd603;
	ld.global.nc.f64 	%fd605, [%rd87+48];
	fma.rn.f64 	%fd77, %fd604, %fd76, %fd605;
	fma.rn.f64 	%fd1390, %fd77, %fd1388, %fd1388;
	@%p43 bra 	$L__BB15_46;

	mov.f64 	%fd606, 0d3FF0000000000000;
	fma.rn.f64 	%fd1390, %fd77, %fd76, %fd606;

$L__BB15_46:
	and.b32  	%r160, %r483, 2;
	setp.eq.s32 	%p44, %r160, 0;
	@%p44 bra 	$L__BB15_48;

	mov.f64 	%fd607, 0d0000000000000000;
	mov.f64 	%fd608, 0dBFF0000000000000;
	fma.rn.f64 	%fd1390, %fd1390, %fd608, %fd607;

$L__BB15_48:
	mul.rn.f64 	%fd609, %fd1390, 0d4074000000000000;
	add.rn.f64 	%fd83, %fd70, %fd609;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r161}, %fd7;
	}
	and.b32  	%r162, %r161, 2147483647;
	setp.eq.s32 	%p45, %r162, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r163, %temp}, %fd7;
	}
	setp.eq.s32 	%p46, %r163, 0;
	and.pred  	%p47, %p46, %p45;
	@%p47 bra 	$L__BB15_51;
	bra.uni 	$L__BB15_49;

$L__BB15_51:
	mov.f64 	%fd619, 0d0000000000000000;
	mul.rn.f64 	%fd1391, %fd7, %fd619;
	mov.u32 	%r484, 0;
	bra.uni 	$L__BB15_52;

$L__BB15_49:
	mul.rn.f64 	%fd610, %fd7, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r484, %fd610;
	st.local.u32 	[%rd1], %r484;
	cvt.rn.f64.s32 	%fd611, %r484;
	neg.f64 	%fd612, %fd611;
	mov.f64 	%fd613, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd614, %fd612, %fd613, %fd7;
	mov.f64 	%fd615, 0d3C91A62633145C00;
	fma.rn.f64 	%fd616, %fd612, %fd615, %fd614;
	mov.f64 	%fd617, 0d397B839A252049C0;
	fma.rn.f64 	%fd1391, %fd612, %fd617, %fd616;
	abs.f64 	%fd618, %fd7;
	setp.ltu.f64 	%p48, %fd618, 0d41E0000000000000;
	@%p48 bra 	$L__BB15_52;

	{ // callseq 188, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd7;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1391, [retval0+0];
	} // callseq 188
	ld.local.u32 	%r484, [%rd1];

$L__BB15_52:
	and.b32  	%r165, %r484, 1;
	shl.b32 	%r166, %r484, 3;
	and.b32  	%r167, %r166, 8;
	setp.eq.s32 	%p49, %r165, 0;
	selp.f64 	%fd620, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p49;
	mul.wide.s32 	%rd89, %r167, 8;
	add.s64 	%rd91, %rd66, %rd89;
	ld.global.nc.f64 	%fd621, [%rd91+8];
	mul.rn.f64 	%fd88, %fd1391, %fd1391;
	fma.rn.f64 	%fd622, %fd620, %fd88, %fd621;
	ld.global.nc.f64 	%fd623, [%rd91+16];
	fma.rn.f64 	%fd624, %fd622, %fd88, %fd623;
	ld.global.nc.f64 	%fd625, [%rd91+24];
	fma.rn.f64 	%fd626, %fd624, %fd88, %fd625;
	ld.global.nc.f64 	%fd627, [%rd91+32];
	fma.rn.f64 	%fd628, %fd626, %fd88, %fd627;
	ld.global.nc.f64 	%fd629, [%rd91+40];
	fma.rn.f64 	%fd630, %fd628, %fd88, %fd629;
	ld.global.nc.f64 	%fd631, [%rd91+48];
	fma.rn.f64 	%fd89, %fd630, %fd88, %fd631;
	fma.rn.f64 	%fd1393, %fd89, %fd1391, %fd1391;
	@%p49 bra 	$L__BB15_54;

	mov.f64 	%fd632, 0d3FF0000000000000;
	fma.rn.f64 	%fd1393, %fd89, %fd88, %fd632;

$L__BB15_54:
	and.b32  	%r168, %r484, 2;
	setp.eq.s32 	%p50, %r168, 0;
	@%p50 bra 	$L__BB15_56;

	mov.f64 	%fd633, 0d0000000000000000;
	mov.f64 	%fd634, 0dBFF0000000000000;
	fma.rn.f64 	%fd1393, %fd1393, %fd634, %fd633;

$L__BB15_56:
	div.rn.f64 	%fd95, %fd7, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r169, %temp}, %fd95;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r170}, %fd95;
	}
	and.b32  	%r171, %r170, 2147483647;
	setp.eq.s32 	%p51, %r171, 2146435072;
	setp.eq.s32 	%p52, %r169, 0;
	and.pred  	%p53, %p52, %p51;
	@%p53 bra 	$L__BB15_59;
	bra.uni 	$L__BB15_57;

$L__BB15_59:
	mov.f64 	%fd644, 0d0000000000000000;
	mul.rn.f64 	%fd1394, %fd95, %fd644;
	mov.u32 	%r485, 0;
	bra.uni 	$L__BB15_60;

$L__BB15_57:
	mul.rn.f64 	%fd635, %fd95, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r485, %fd635;
	st.local.u32 	[%rd1], %r485;
	cvt.rn.f64.s32 	%fd636, %r485;
	neg.f64 	%fd637, %fd636;
	mov.f64 	%fd638, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd639, %fd637, %fd638, %fd95;
	mov.f64 	%fd640, 0d3C91A62633145C00;
	fma.rn.f64 	%fd641, %fd637, %fd640, %fd639;
	mov.f64 	%fd642, 0d397B839A252049C0;
	fma.rn.f64 	%fd1394, %fd637, %fd642, %fd641;
	abs.f64 	%fd643, %fd95;
	setp.ltu.f64 	%p54, %fd643, 0d41E0000000000000;
	@%p54 bra 	$L__BB15_60;

	{ // callseq 189, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd95;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1394, [retval0+0];
	} // callseq 189
	ld.local.u32 	%r485, [%rd1];

$L__BB15_60:
	and.b32  	%r173, %r485, 1;
	shl.b32 	%r174, %r485, 3;
	and.b32  	%r175, %r174, 8;
	setp.eq.s32 	%p55, %r173, 0;
	selp.f64 	%fd645, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p55;
	mul.wide.s32 	%rd93, %r175, 8;
	add.s64 	%rd95, %rd66, %rd93;
	ld.global.nc.f64 	%fd646, [%rd95+8];
	mul.rn.f64 	%fd100, %fd1394, %fd1394;
	fma.rn.f64 	%fd647, %fd645, %fd100, %fd646;
	ld.global.nc.f64 	%fd648, [%rd95+16];
	fma.rn.f64 	%fd649, %fd647, %fd100, %fd648;
	ld.global.nc.f64 	%fd650, [%rd95+24];
	fma.rn.f64 	%fd651, %fd649, %fd100, %fd650;
	ld.global.nc.f64 	%fd652, [%rd95+32];
	fma.rn.f64 	%fd653, %fd651, %fd100, %fd652;
	ld.global.nc.f64 	%fd654, [%rd95+40];
	fma.rn.f64 	%fd655, %fd653, %fd100, %fd654;
	ld.global.nc.f64 	%fd656, [%rd95+48];
	fma.rn.f64 	%fd101, %fd655, %fd100, %fd656;
	fma.rn.f64 	%fd1396, %fd101, %fd1394, %fd1394;
	@%p55 bra 	$L__BB15_62;

	mov.f64 	%fd657, 0d3FF0000000000000;
	fma.rn.f64 	%fd1396, %fd101, %fd100, %fd657;

$L__BB15_62:
	and.b32  	%r176, %r485, 2;
	setp.eq.s32 	%p56, %r176, 0;
	@%p56 bra 	$L__BB15_64;

	mov.f64 	%fd658, 0d0000000000000000;
	mov.f64 	%fd659, 0dBFF0000000000000;
	fma.rn.f64 	%fd1396, %fd1396, %fd659, %fd658;

$L__BB15_64:
	mul.rn.f64 	%fd660, %fd1396, 0d4044000000000000;
	mul.rn.f64 	%fd661, %fd1393, 0d4034000000000000;
	add.rn.f64 	%fd107, %fd661, %fd660;
	div.rn.f64 	%fd108, %fd7, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r177, %temp}, %fd108;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r178}, %fd108;
	}
	and.b32  	%r179, %r178, 2147483647;
	setp.eq.s32 	%p57, %r179, 2146435072;
	setp.eq.s32 	%p58, %r177, 0;
	and.pred  	%p59, %p58, %p57;
	@%p59 bra 	$L__BB15_67;
	bra.uni 	$L__BB15_65;

$L__BB15_67:
	mov.f64 	%fd671, 0d0000000000000000;
	mul.rn.f64 	%fd1397, %fd108, %fd671;
	mov.u32 	%r486, 0;
	bra.uni 	$L__BB15_68;

$L__BB15_65:
	mul.rn.f64 	%fd662, %fd108, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r486, %fd662;
	st.local.u32 	[%rd1], %r486;
	cvt.rn.f64.s32 	%fd663, %r486;
	neg.f64 	%fd664, %fd663;
	mov.f64 	%fd665, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd666, %fd664, %fd665, %fd108;
	mov.f64 	%fd667, 0d3C91A62633145C00;
	fma.rn.f64 	%fd668, %fd664, %fd667, %fd666;
	mov.f64 	%fd669, 0d397B839A252049C0;
	fma.rn.f64 	%fd1397, %fd664, %fd669, %fd668;
	abs.f64 	%fd670, %fd108;
	setp.ltu.f64 	%p60, %fd670, 0d41E0000000000000;
	@%p60 bra 	$L__BB15_68;

	{ // callseq 190, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd108;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1397, [retval0+0];
	} // callseq 190
	ld.local.u32 	%r486, [%rd1];

$L__BB15_68:
	and.b32  	%r181, %r486, 1;
	shl.b32 	%r182, %r486, 3;
	and.b32  	%r183, %r182, 8;
	setp.eq.s32 	%p61, %r181, 0;
	selp.f64 	%fd672, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p61;
	mul.wide.s32 	%rd97, %r183, 8;
	add.s64 	%rd99, %rd66, %rd97;
	ld.global.nc.f64 	%fd673, [%rd99+8];
	mul.rn.f64 	%fd113, %fd1397, %fd1397;
	fma.rn.f64 	%fd674, %fd672, %fd113, %fd673;
	ld.global.nc.f64 	%fd675, [%rd99+16];
	fma.rn.f64 	%fd676, %fd674, %fd113, %fd675;
	ld.global.nc.f64 	%fd677, [%rd99+24];
	fma.rn.f64 	%fd678, %fd676, %fd113, %fd677;
	ld.global.nc.f64 	%fd679, [%rd99+32];
	fma.rn.f64 	%fd680, %fd678, %fd113, %fd679;
	ld.global.nc.f64 	%fd681, [%rd99+40];
	fma.rn.f64 	%fd682, %fd680, %fd113, %fd681;
	ld.global.nc.f64 	%fd683, [%rd99+48];
	fma.rn.f64 	%fd114, %fd682, %fd113, %fd683;
	fma.rn.f64 	%fd1399, %fd114, %fd1397, %fd1397;
	@%p61 bra 	$L__BB15_70;

	mov.f64 	%fd684, 0d3FF0000000000000;
	fma.rn.f64 	%fd1399, %fd114, %fd113, %fd684;

$L__BB15_70:
	and.b32  	%r184, %r486, 2;
	setp.eq.s32 	%p62, %r184, 0;
	@%p62 bra 	$L__BB15_72;

	mov.f64 	%fd685, 0d0000000000000000;
	mov.f64 	%fd686, 0dBFF0000000000000;
	fma.rn.f64 	%fd1399, %fd1399, %fd686, %fd685;

$L__BB15_72:
	mul.rn.f64 	%fd687, %fd1399, 0d4062C00000000000;
	add.rn.f64 	%fd120, %fd107, %fd687;
	div.rn.f64 	%fd121, %fd7, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r185, %temp}, %fd121;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r186}, %fd121;
	}
	and.b32  	%r187, %r186, 2147483647;
	setp.eq.s32 	%p63, %r187, 2146435072;
	setp.eq.s32 	%p64, %r185, 0;
	and.pred  	%p65, %p64, %p63;
	@%p65 bra 	$L__BB15_75;
	bra.uni 	$L__BB15_73;

$L__BB15_75:
	mov.f64 	%fd697, 0d0000000000000000;
	mul.rn.f64 	%fd1400, %fd121, %fd697;
	mov.u32 	%r487, 0;
	bra.uni 	$L__BB15_76;

$L__BB15_73:
	mul.rn.f64 	%fd688, %fd121, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r487, %fd688;
	st.local.u32 	[%rd1], %r487;
	cvt.rn.f64.s32 	%fd689, %r487;
	neg.f64 	%fd690, %fd689;
	mov.f64 	%fd691, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd692, %fd690, %fd691, %fd121;
	mov.f64 	%fd693, 0d3C91A62633145C00;
	fma.rn.f64 	%fd694, %fd690, %fd693, %fd692;
	mov.f64 	%fd695, 0d397B839A252049C0;
	fma.rn.f64 	%fd1400, %fd690, %fd695, %fd694;
	abs.f64 	%fd696, %fd121;
	setp.ltu.f64 	%p66, %fd696, 0d41E0000000000000;
	@%p66 bra 	$L__BB15_76;

	{ // callseq 191, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd121;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1400, [retval0+0];
	} // callseq 191
	ld.local.u32 	%r487, [%rd1];

$L__BB15_76:
	and.b32  	%r189, %r487, 1;
	shl.b32 	%r190, %r487, 3;
	and.b32  	%r191, %r190, 8;
	setp.eq.s32 	%p67, %r189, 0;
	selp.f64 	%fd698, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p67;
	mul.wide.s32 	%rd101, %r191, 8;
	add.s64 	%rd103, %rd66, %rd101;
	ld.global.nc.f64 	%fd699, [%rd103+8];
	mul.rn.f64 	%fd126, %fd1400, %fd1400;
	fma.rn.f64 	%fd700, %fd698, %fd126, %fd699;
	ld.global.nc.f64 	%fd701, [%rd103+16];
	fma.rn.f64 	%fd702, %fd700, %fd126, %fd701;
	ld.global.nc.f64 	%fd703, [%rd103+24];
	fma.rn.f64 	%fd704, %fd702, %fd126, %fd703;
	ld.global.nc.f64 	%fd705, [%rd103+32];
	fma.rn.f64 	%fd706, %fd704, %fd126, %fd705;
	ld.global.nc.f64 	%fd707, [%rd103+40];
	fma.rn.f64 	%fd708, %fd706, %fd126, %fd707;
	ld.global.nc.f64 	%fd709, [%rd103+48];
	fma.rn.f64 	%fd127, %fd708, %fd126, %fd709;
	fma.rn.f64 	%fd1402, %fd127, %fd1400, %fd1400;
	@%p67 bra 	$L__BB15_78;

	mov.f64 	%fd710, 0d3FF0000000000000;
	fma.rn.f64 	%fd1402, %fd127, %fd126, %fd710;

$L__BB15_78:
	and.b32  	%r192, %r487, 2;
	setp.eq.s32 	%p68, %r192, 0;
	@%p68 bra 	$L__BB15_80;

	mov.f64 	%fd711, 0d0000000000000000;
	mov.f64 	%fd712, 0dBFF0000000000000;
	fma.rn.f64 	%fd1402, %fd1402, %fd712, %fd711;

$L__BB15_80:
	mul.rn.f64 	%fd713, %fd1402, 0d4072C00000000000;
	add.rn.f64 	%fd714, %fd120, %fd713;
	add.rn.f64 	%fd133, %fd33, %fd714;
	add.rn.f64 	%fd134, %fd33, %fd83;
	add.rn.f64 	%fd715, %fd2, %fd2;
	mov.f64 	%fd716, 0d4000000000000000;
	add.rn.f64 	%fd717, %fd715, 0dC059000000000000;
	mul.rn.f64 	%fd718, %fd4, 0d4008000000000000;
	add.rn.f64 	%fd135, %fd717, %fd718;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r31}, %fd716;
	}
	and.b32  	%r32, %r31, 2146435072;
	setp.eq.s32 	%p69, %r32, 1062207488;
	abs.f64 	%fd136, %fd4;
	{ // callseq 192, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd136;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1405, [retval0+0];
	} // callseq 192
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r33}, %fd4;
	}
	setp.lt.s32 	%p70, %r33, 0;
	and.pred  	%p1, %p70, %p69;
	not.pred 	%p71, %p1;
	@%p71 bra 	$L__BB15_82;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r193}, %fd1405;
	}
	xor.b32  	%r194, %r193, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r195, %temp}, %fd1405;
	}
	mov.b64 	%fd1405, {%r195, %r194};

$L__BB15_82:
	setp.eq.f64 	%p72, %fd4, 0d0000000000000000;
	@%p72 bra 	$L__BB15_86;
	bra.uni 	$L__BB15_83;

$L__BB15_86:
	selp.b32 	%r196, %r33, 0, %p69;
	mov.u32 	%r197, 0;
	or.b32  	%r198, %r196, 2146435072;
	setp.lt.s32 	%p76, %r31, 0;
	selp.b32 	%r199, %r198, %r196, %p76;
	mov.b64 	%fd1405, {%r197, %r199};
	bra.uni 	$L__BB15_87;

$L__BB15_83:
	setp.gt.s32 	%p73, %r33, -1;
	@%p73 bra 	$L__BB15_87;

	mov.f64 	%fd719, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd720, %fd719;
	setp.eq.f64 	%p74, %fd720, 0d4000000000000000;
	@%p74 bra 	$L__BB15_87;

	mov.f64 	%fd1405, 0dFFF8000000000000;

$L__BB15_87:
	add.rn.f64 	%fd722, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd722;
	}
	and.b32  	%r201, %r200, 2146435072;
	setp.ne.s32 	%p77, %r201, 2146435072;
	@%p77 bra 	$L__BB15_94;

	setp.gtu.f64 	%p78, %fd136, 0d7FF0000000000000;
	@%p78 bra 	$L__BB15_93;
	bra.uni 	$L__BB15_89;

$L__BB15_93:
	mov.f64 	%fd724, 0d4000000000000000;
	add.rn.f64 	%fd1405, %fd4, %fd724;
	bra.uni 	$L__BB15_94;

$L__BB15_89:
	mov.f64 	%fd723, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r202, %temp}, %fd723;
	}
	and.b32  	%r34, %r31, 2147483647;
	setp.eq.s32 	%p79, %r34, 2146435072;
	setp.eq.s32 	%p80, %r202, 0;
	and.pred  	%p81, %p79, %p80;
	@%p81 bra 	$L__BB15_92;
	bra.uni 	$L__BB15_90;

$L__BB15_92:
	setp.gt.f64 	%p88, %fd136, 0d3FF0000000000000;
	selp.b32 	%r209, 2146435072, 0, %p88;
	mov.u32 	%r210, 0;
	xor.b32  	%r211, %r209, 2146435072;
	setp.lt.s32 	%p89, %r31, 0;
	selp.b32 	%r212, %r211, %r209, %p89;
	setp.eq.f64 	%p90, %fd4, 0dBFF0000000000000;
	selp.b32 	%r213, 1072693248, %r212, %p90;
	mov.b64 	%fd1405, {%r210, %r213};
	bra.uni 	$L__BB15_94;

$L__BB15_90:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd4;
	}
	and.b32  	%r204, %r33, 2147483647;
	setp.ne.s32 	%p82, %r204, 2146435072;
	setp.ne.s32 	%p83, %r203, 0;
	or.pred  	%p84, %p82, %p83;
	@%p84 bra 	$L__BB15_94;

	setp.gt.s32 	%p85, %r31, -1;
	selp.b32 	%r205, 2146435072, 0, %p85;
	mov.u32 	%r206, 0;
	setp.ne.s32 	%p86, %r34, 1071644672;
	and.pred  	%p87, %p86, %p1;
	or.b32  	%r207, %r205, -2147483648;
	selp.b32 	%r208, %r207, %r205, %p87;
	mov.b64 	%fd1405, {%r206, %r208};

$L__BB15_94:
	add.rn.f64 	%fd1362, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1361, %fd1362;
	mul.rn.f64 	%fd725, %fd1405, 0d3FC999999999999A;
	setp.eq.f64 	%p91, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd726, 0d3FC999999999999A, %fd725, %p91;
	add.rn.f64 	%fd727, %fd135, %fd726;
	mul.rn.f64 	%fd728, %fd1362, %fd4;
	mul.rn.f64 	%fd146, %fd728, 0d3FB999999999999A;
	add.rn.f64 	%fd729, %fd146, %fd727;
	mul.rn.f64 	%fd730, %fd6, 0d3FC999999999999A;
	add.rn.f64 	%fd731, %fd730, %fd729;
	mul.rn.f64 	%fd732, %fd134, 0d3FE5555555555555;
	add.rn.f64 	%fd147, %fd732, %fd731;
	add.rn.f64 	%fd733, %fd4, %fd4;
	add.rn.f64 	%fd734, %fd1362, 0d4072C00000000000;
	add.rn.f64 	%fd148, %fd734, %fd733;
	{ // callseq 193, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd1361;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1408, [retval0+0];
	} // callseq 193
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd1362;
	}
	setp.lt.s32 	%p92, %r35, 0;
	and.pred  	%p2, %p92, %p69;
	not.pred 	%p94, %p2;
	@%p94 bra 	$L__BB15_96;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd1408;
	}
	xor.b32  	%r215, %r214, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r216, %temp}, %fd1408;
	}
	mov.b64 	%fd1408, {%r216, %r215};

$L__BB15_96:
	setp.eq.f64 	%p95, %fd2, 0d0000000000000000;
	@%p95 bra 	$L__BB15_100;
	bra.uni 	$L__BB15_97;

$L__BB15_100:
	selp.b32 	%r217, %r35, 0, %p69;
	mov.u32 	%r218, 0;
	or.b32  	%r219, %r217, 2146435072;
	setp.lt.s32 	%p99, %r31, 0;
	selp.b32 	%r220, %r219, %r217, %p99;
	mov.b64 	%fd1408, {%r218, %r220};
	bra.uni 	$L__BB15_101;

$L__BB15_97:
	setp.gt.s32 	%p96, %r35, -1;
	@%p96 bra 	$L__BB15_101;

	mov.f64 	%fd735, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd736, %fd735;
	setp.eq.f64 	%p97, %fd736, 0d4000000000000000;
	@%p97 bra 	$L__BB15_101;

	mov.f64 	%fd1408, 0dFFF8000000000000;

$L__BB15_101:
	add.rn.f64 	%fd738, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r221}, %fd738;
	}
	and.b32  	%r222, %r221, 2146435072;
	setp.ne.s32 	%p100, %r222, 2146435072;
	@%p100 bra 	$L__BB15_108;

	add.rn.f64 	%fd1364, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1363, %fd1364;
	setp.gtu.f64 	%p101, %fd1363, 0d7FF0000000000000;
	@%p101 bra 	$L__BB15_107;
	bra.uni 	$L__BB15_103;

$L__BB15_107:
	mov.f64 	%fd740, 0d4000000000000000;
	add.rn.f64 	%fd1408, %fd2, %fd740;
	bra.uni 	$L__BB15_108;

$L__BB15_103:
	mov.f64 	%fd739, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r223, %temp}, %fd739;
	}
	and.b32  	%r36, %r31, 2147483647;
	setp.eq.s32 	%p102, %r36, 2146435072;
	setp.eq.s32 	%p103, %r223, 0;
	and.pred  	%p104, %p102, %p103;
	@%p104 bra 	$L__BB15_106;
	bra.uni 	$L__BB15_104;

$L__BB15_106:
	add.rn.f64 	%fd1366, %fd1, 0dC05A400000000000;
	abs.f64 	%fd1365, %fd1366;
	setp.gt.f64 	%p111, %fd1365, 0d3FF0000000000000;
	selp.b32 	%r230, 2146435072, 0, %p111;
	mov.u32 	%r231, 0;
	xor.b32  	%r232, %r230, 2146435072;
	setp.lt.s32 	%p112, %r31, 0;
	selp.b32 	%r233, %r232, %r230, %p112;
	setp.eq.f64 	%p113, %fd1366, 0dBFF0000000000000;
	selp.b32 	%r234, 1072693248, %r233, %p113;
	mov.b64 	%fd1408, {%r231, %r234};
	bra.uni 	$L__BB15_108;

$L__BB15_104:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r224, %temp}, %fd2;
	}
	and.b32  	%r225, %r35, 2147483647;
	setp.ne.s32 	%p105, %r225, 2146435072;
	setp.ne.s32 	%p106, %r224, 0;
	or.pred  	%p107, %p105, %p106;
	@%p107 bra 	$L__BB15_108;

	setp.gt.s32 	%p108, %r31, -1;
	selp.b32 	%r226, 2146435072, 0, %p108;
	mov.u32 	%r227, 0;
	setp.ne.s32 	%p109, %r36, 1071644672;
	and.pred  	%p110, %p109, %p2;
	or.b32  	%r228, %r226, -2147483648;
	selp.b32 	%r229, %r228, %r226, %p110;
	mov.b64 	%fd1408, {%r227, %r229};

$L__BB15_108:
	mul.rn.f64 	%fd741, %fd1408, 0d3FB999999999999A;
	setp.eq.f64 	%p114, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd742, 0d3FB999999999999A, %fd741, %p114;
	add.rn.f64 	%fd743, %fd148, %fd742;
	add.rn.f64 	%fd744, %fd146, %fd743;
	mul.rn.f64 	%fd745, %fd6, 0d3FB999999999999A;
	add.rn.f64 	%fd746, %fd745, %fd744;
	mul.rn.f64 	%fd747, %fd133, 0d3FE5555555555555;
	add.rn.f64 	%fd158, %fd747, %fd746;
	div.rn.f64 	%fd748, %fd3, 0d4066800000000000;
	mul.rn.f64 	%fd159, %fd748, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r235, %temp}, %fd159;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r236}, %fd159;
	}
	and.b32  	%r237, %r236, 2147483647;
	setp.eq.s32 	%p115, %r237, 2146435072;
	setp.eq.s32 	%p116, %r235, 0;
	and.pred  	%p3, %p116, %p115;
	@%p3 bra 	$L__BB15_111;
	bra.uni 	$L__BB15_109;

$L__BB15_111:
	mov.f64 	%fd758, 0d0000000000000000;
	mul.rn.f64 	%fd1409, %fd159, %fd758;
	mov.u32 	%r488, 0;
	bra.uni 	$L__BB15_112;

$L__BB15_109:
	mul.rn.f64 	%fd749, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r488, %fd749;
	st.local.u32 	[%rd1], %r488;
	cvt.rn.f64.s32 	%fd750, %r488;
	neg.f64 	%fd751, %fd750;
	mov.f64 	%fd752, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd753, %fd751, %fd752, %fd159;
	mov.f64 	%fd754, 0d3C91A62633145C00;
	fma.rn.f64 	%fd755, %fd751, %fd754, %fd753;
	mov.f64 	%fd756, 0d397B839A252049C0;
	fma.rn.f64 	%fd1409, %fd751, %fd756, %fd755;
	abs.f64 	%fd757, %fd159;
	setp.ltu.f64 	%p117, %fd757, 0d41E0000000000000;
	@%p117 bra 	$L__BB15_112;

	{ // callseq 194, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1409, [retval0+0];
	} // callseq 194
	ld.local.u32 	%r488, [%rd1];

$L__BB15_112:
	and.b32  	%r239, %r488, 1;
	shl.b32 	%r240, %r488, 3;
	and.b32  	%r241, %r240, 8;
	setp.eq.s32 	%p118, %r239, 0;
	selp.f64 	%fd759, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p118;
	mul.wide.s32 	%rd105, %r241, 8;
	add.s64 	%rd107, %rd66, %rd105;
	ld.global.nc.f64 	%fd760, [%rd107+8];
	mul.rn.f64 	%fd164, %fd1409, %fd1409;
	fma.rn.f64 	%fd761, %fd759, %fd164, %fd760;
	ld.global.nc.f64 	%fd762, [%rd107+16];
	fma.rn.f64 	%fd763, %fd761, %fd164, %fd762;
	ld.global.nc.f64 	%fd764, [%rd107+24];
	fma.rn.f64 	%fd765, %fd763, %fd164, %fd764;
	ld.global.nc.f64 	%fd766, [%rd107+32];
	fma.rn.f64 	%fd767, %fd765, %fd164, %fd766;
	ld.global.nc.f64 	%fd768, [%rd107+40];
	fma.rn.f64 	%fd769, %fd767, %fd164, %fd768;
	ld.global.nc.f64 	%fd770, [%rd107+48];
	fma.rn.f64 	%fd165, %fd769, %fd164, %fd770;
	fma.rn.f64 	%fd1411, %fd165, %fd1409, %fd1409;
	@%p118 bra 	$L__BB15_114;

	mov.f64 	%fd771, 0d3FF0000000000000;
	fma.rn.f64 	%fd1411, %fd165, %fd164, %fd771;

$L__BB15_114:
	and.b32  	%r242, %r488, 2;
	setp.eq.s32 	%p119, %r242, 0;
	@%p119 bra 	$L__BB15_116;

	mov.f64 	%fd772, 0d0000000000000000;
	mov.f64 	%fd773, 0dBFF0000000000000;
	fma.rn.f64 	%fd1411, %fd1411, %fd773, %fd772;

$L__BB15_116:
	@%p3 bra 	$L__BB15_120;
	bra.uni 	$L__BB15_117;

$L__BB15_120:
	mov.f64 	%fd783, 0d0000000000000000;
	mul.rn.f64 	%fd1413, %fd159, %fd783;
	mov.u32 	%r490, 1;
	bra.uni 	$L__BB15_121;

$L__BB15_117:
	mul.rn.f64 	%fd774, %fd159, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r489, %fd774;
	st.local.u32 	[%rd1], %r489;
	cvt.rn.f64.s32 	%fd775, %r489;
	neg.f64 	%fd776, %fd775;
	mov.f64 	%fd777, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd778, %fd776, %fd777, %fd159;
	mov.f64 	%fd779, 0d3C91A62633145C00;
	fma.rn.f64 	%fd780, %fd776, %fd779, %fd778;
	mov.f64 	%fd781, 0d397B839A252049C0;
	fma.rn.f64 	%fd1413, %fd776, %fd781, %fd780;
	abs.f64 	%fd782, %fd159;
	setp.ltu.f64 	%p120, %fd782, 0d41E0000000000000;
	@%p120 bra 	$L__BB15_119;

	{ // callseq 195, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd159;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1413, [retval0+0];
	} // callseq 195
	ld.local.u32 	%r489, [%rd1];

$L__BB15_119:
	add.s32 	%r490, %r489, 1;

$L__BB15_121:
	and.b32  	%r244, %r490, 1;
	shl.b32 	%r245, %r490, 3;
	and.b32  	%r246, %r245, 8;
	setp.eq.s32 	%p121, %r244, 0;
	selp.f64 	%fd784, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p121;
	mul.wide.s32 	%rd109, %r246, 8;
	add.s64 	%rd111, %rd66, %rd109;
	ld.global.nc.f64 	%fd785, [%rd111+8];
	mul.rn.f64 	%fd176, %fd1413, %fd1413;
	fma.rn.f64 	%fd786, %fd784, %fd176, %fd785;
	ld.global.nc.f64 	%fd787, [%rd111+16];
	fma.rn.f64 	%fd788, %fd786, %fd176, %fd787;
	ld.global.nc.f64 	%fd789, [%rd111+24];
	fma.rn.f64 	%fd790, %fd788, %fd176, %fd789;
	ld.global.nc.f64 	%fd791, [%rd111+32];
	fma.rn.f64 	%fd792, %fd790, %fd176, %fd791;
	ld.global.nc.f64 	%fd793, [%rd111+40];
	fma.rn.f64 	%fd794, %fd792, %fd176, %fd793;
	ld.global.nc.f64 	%fd795, [%rd111+48];
	fma.rn.f64 	%fd177, %fd794, %fd176, %fd795;
	fma.rn.f64 	%fd1415, %fd177, %fd1413, %fd1413;
	@%p121 bra 	$L__BB15_123;

	mov.f64 	%fd796, 0d3FF0000000000000;
	fma.rn.f64 	%fd1415, %fd177, %fd176, %fd796;

$L__BB15_123:
	and.b32  	%r247, %r490, 2;
	setp.eq.s32 	%p122, %r247, 0;
	@%p122 bra 	$L__BB15_125;

	mov.f64 	%fd797, 0d0000000000000000;
	mov.f64 	%fd798, 0dBFF0000000000000;
	fma.rn.f64 	%fd1415, %fd1415, %fd798, %fd797;

$L__BB15_125:
	ld.param.u32 	%r473, [gcj02_to_wgs84_exact_cuda_double_param_4];
	mul.rn.f64 	%fd799, %fd1411, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd800, %fd1411, %fd799;
	add.rn.f64 	%fd801, %fd800, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd802, %fd801;
	mov.f64 	%fd803, 0dC15854C140000000;
	div.rn.f64 	%fd804, %fd803, %fd802;
	mul.rn.f64 	%fd805, %fd804, %fd1415;
	mul.rn.f64 	%fd806, %fd805, 0d400921FB54442D18;
	mul.rn.f64 	%fd807, %fd158, 0d4066800000000000;
	div.rn.f64 	%fd808, %fd807, %fd806;
	add.rn.f64 	%fd1482, %fd1, %fd808;
	mul.rn.f64 	%fd809, %fd147, 0d4066800000000000;
	mul.rn.f64 	%fd810, %fd802, %fd801;
	mov.f64 	%fd811, 0dC1582B102DE355C1;
	div.rn.f64 	%fd812, %fd811, %fd810;
	mul.rn.f64 	%fd813, %fd812, 0d400921FB54442D18;
	div.rn.f64 	%fd814, %fd809, %fd813;
	add.rn.f64 	%fd1483, %fd3, %fd814;
	setp.lt.s32 	%p123, %r473, 1;
	@%p123 bra 	$L__BB15_323;

	and.b32  	%r45, %r31, 2147483647;
	setp.gt.s32 	%p124, %r31, -1;
	selp.b32 	%r46, 2146435072, 0, %p124;
	mov.u32 	%r491, 0;
	or.b32  	%r47, %r46, -2147483648;

$L__BB15_127:
	add.rn.f64 	%fd187, %fd1483, 0dC041800000000000;
	add.rn.f64 	%fd188, %fd1482, 0dC05A400000000000;
	abs.f64 	%fd189, %fd188;
	sqrt.rn.f64 	%fd190, %fd189;
	mul.rn.f64 	%fd191, %fd188, 0d400921FB54442D18;
	mul.rn.f64 	%fd192, %fd187, 0d400921FB54442D18;
	mul.rn.f64 	%fd193, %fd191, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r249, %temp}, %fd193;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd193;
	}
	and.b32  	%r251, %r250, 2147483647;
	setp.eq.s32 	%p125, %r251, 2146435072;
	setp.eq.s32 	%p126, %r249, 0;
	and.pred  	%p127, %p126, %p125;
	@%p127 bra 	$L__BB15_130;
	bra.uni 	$L__BB15_128;

$L__BB15_130:
	mov.f64 	%fd824, 0d0000000000000000;
	mul.rn.f64 	%fd1418, %fd193, %fd824;
	mov.u32 	%r492, 0;
	bra.uni 	$L__BB15_131;

$L__BB15_128:
	mul.rn.f64 	%fd815, %fd193, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r492, %fd815;
	st.local.u32 	[%rd1], %r492;
	cvt.rn.f64.s32 	%fd816, %r492;
	neg.f64 	%fd817, %fd816;
	mov.f64 	%fd818, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd819, %fd817, %fd818, %fd193;
	mov.f64 	%fd820, 0d3C91A62633145C00;
	fma.rn.f64 	%fd821, %fd817, %fd820, %fd819;
	mov.f64 	%fd822, 0d397B839A252049C0;
	fma.rn.f64 	%fd1418, %fd817, %fd822, %fd821;
	abs.f64 	%fd823, %fd193;
	setp.ltu.f64 	%p128, %fd823, 0d41E0000000000000;
	@%p128 bra 	$L__BB15_131;

	{ // callseq 196, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd193;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1418, [retval0+0];
	} // callseq 196
	ld.local.u32 	%r492, [%rd1];

$L__BB15_131:
	and.b32  	%r253, %r492, 1;
	shl.b32 	%r254, %r492, 3;
	and.b32  	%r255, %r254, 8;
	setp.eq.s32 	%p129, %r253, 0;
	selp.f64 	%fd825, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p129;
	mul.wide.s32 	%rd113, %r255, 8;
	add.s64 	%rd115, %rd66, %rd113;
	ld.global.nc.f64 	%fd826, [%rd115+8];
	mul.rn.f64 	%fd198, %fd1418, %fd1418;
	fma.rn.f64 	%fd827, %fd825, %fd198, %fd826;
	ld.global.nc.f64 	%fd828, [%rd115+16];
	fma.rn.f64 	%fd829, %fd827, %fd198, %fd828;
	ld.global.nc.f64 	%fd830, [%rd115+24];
	fma.rn.f64 	%fd831, %fd829, %fd198, %fd830;
	ld.global.nc.f64 	%fd832, [%rd115+32];
	fma.rn.f64 	%fd833, %fd831, %fd198, %fd832;
	ld.global.nc.f64 	%fd834, [%rd115+40];
	fma.rn.f64 	%fd835, %fd833, %fd198, %fd834;
	ld.global.nc.f64 	%fd836, [%rd115+48];
	fma.rn.f64 	%fd199, %fd835, %fd198, %fd836;
	fma.rn.f64 	%fd1420, %fd199, %fd1418, %fd1418;
	@%p129 bra 	$L__BB15_133;

	mov.f64 	%fd837, 0d3FF0000000000000;
	fma.rn.f64 	%fd1420, %fd199, %fd198, %fd837;

$L__BB15_133:
	and.b32  	%r256, %r492, 2;
	setp.eq.s32 	%p130, %r256, 0;
	@%p130 bra 	$L__BB15_135;

	mov.f64 	%fd838, 0d0000000000000000;
	mov.f64 	%fd839, 0dBFF0000000000000;
	fma.rn.f64 	%fd1420, %fd1420, %fd839, %fd838;

$L__BB15_135:
	add.rn.f64 	%fd205, %fd191, %fd191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r257, %temp}, %fd205;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r258}, %fd205;
	}
	and.b32  	%r259, %r258, 2147483647;
	setp.eq.s32 	%p131, %r259, 2146435072;
	setp.eq.s32 	%p132, %r257, 0;
	and.pred  	%p133, %p132, %p131;
	@%p133 bra 	$L__BB15_138;
	bra.uni 	$L__BB15_136;

$L__BB15_138:
	mov.f64 	%fd849, 0d0000000000000000;
	mul.rn.f64 	%fd1421, %fd205, %fd849;
	mov.u32 	%r493, 0;
	bra.uni 	$L__BB15_139;

$L__BB15_136:
	mul.rn.f64 	%fd840, %fd205, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r493, %fd840;
	st.local.u32 	[%rd1], %r493;
	cvt.rn.f64.s32 	%fd841, %r493;
	neg.f64 	%fd842, %fd841;
	mov.f64 	%fd843, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd844, %fd842, %fd843, %fd205;
	mov.f64 	%fd845, 0d3C91A62633145C00;
	fma.rn.f64 	%fd846, %fd842, %fd845, %fd844;
	mov.f64 	%fd847, 0d397B839A252049C0;
	fma.rn.f64 	%fd1421, %fd842, %fd847, %fd846;
	abs.f64 	%fd848, %fd205;
	setp.ltu.f64 	%p134, %fd848, 0d41E0000000000000;
	@%p134 bra 	$L__BB15_139;

	{ // callseq 197, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd205;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1421, [retval0+0];
	} // callseq 197
	ld.local.u32 	%r493, [%rd1];

$L__BB15_139:
	and.b32  	%r261, %r493, 1;
	shl.b32 	%r262, %r493, 3;
	and.b32  	%r263, %r262, 8;
	setp.eq.s32 	%p135, %r261, 0;
	selp.f64 	%fd850, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p135;
	mul.wide.s32 	%rd117, %r263, 8;
	add.s64 	%rd119, %rd66, %rd117;
	ld.global.nc.f64 	%fd851, [%rd119+8];
	mul.rn.f64 	%fd210, %fd1421, %fd1421;
	fma.rn.f64 	%fd852, %fd850, %fd210, %fd851;
	ld.global.nc.f64 	%fd853, [%rd119+16];
	fma.rn.f64 	%fd854, %fd852, %fd210, %fd853;
	ld.global.nc.f64 	%fd855, [%rd119+24];
	fma.rn.f64 	%fd856, %fd854, %fd210, %fd855;
	ld.global.nc.f64 	%fd857, [%rd119+32];
	fma.rn.f64 	%fd858, %fd856, %fd210, %fd857;
	ld.global.nc.f64 	%fd859, [%rd119+40];
	fma.rn.f64 	%fd860, %fd858, %fd210, %fd859;
	ld.global.nc.f64 	%fd861, [%rd119+48];
	fma.rn.f64 	%fd211, %fd860, %fd210, %fd861;
	fma.rn.f64 	%fd1423, %fd211, %fd1421, %fd1421;
	@%p135 bra 	$L__BB15_141;

	mov.f64 	%fd862, 0d3FF0000000000000;
	fma.rn.f64 	%fd1423, %fd211, %fd210, %fd862;

$L__BB15_141:
	and.b32  	%r264, %r493, 2;
	setp.eq.s32 	%p136, %r264, 0;
	@%p136 bra 	$L__BB15_143;

	mov.f64 	%fd863, 0d0000000000000000;
	mov.f64 	%fd864, 0dBFF0000000000000;
	fma.rn.f64 	%fd1423, %fd1423, %fd864, %fd863;

$L__BB15_143:
	mul.rn.f64 	%fd865, %fd1423, 0d4034000000000000;
	mul.rn.f64 	%fd866, %fd1420, 0d4034000000000000;
	add.rn.f64 	%fd217, %fd866, %fd865;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r265}, %fd192;
	}
	and.b32  	%r266, %r265, 2147483647;
	setp.eq.s32 	%p137, %r266, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r267, %temp}, %fd192;
	}
	setp.eq.s32 	%p138, %r267, 0;
	and.pred  	%p139, %p138, %p137;
	@%p139 bra 	$L__BB15_146;
	bra.uni 	$L__BB15_144;

$L__BB15_146:
	mov.f64 	%fd876, 0d0000000000000000;
	mul.rn.f64 	%fd1424, %fd192, %fd876;
	mov.u32 	%r494, 0;
	bra.uni 	$L__BB15_147;

$L__BB15_144:
	mul.rn.f64 	%fd867, %fd192, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r494, %fd867;
	st.local.u32 	[%rd1], %r494;
	cvt.rn.f64.s32 	%fd868, %r494;
	neg.f64 	%fd869, %fd868;
	mov.f64 	%fd870, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd871, %fd869, %fd870, %fd192;
	mov.f64 	%fd872, 0d3C91A62633145C00;
	fma.rn.f64 	%fd873, %fd869, %fd872, %fd871;
	mov.f64 	%fd874, 0d397B839A252049C0;
	fma.rn.f64 	%fd1424, %fd869, %fd874, %fd873;
	abs.f64 	%fd875, %fd192;
	setp.ltu.f64 	%p140, %fd875, 0d41E0000000000000;
	@%p140 bra 	$L__BB15_147;

	{ // callseq 198, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd192;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1424, [retval0+0];
	} // callseq 198
	ld.local.u32 	%r494, [%rd1];

$L__BB15_147:
	and.b32  	%r269, %r494, 1;
	shl.b32 	%r270, %r494, 3;
	and.b32  	%r271, %r270, 8;
	setp.eq.s32 	%p141, %r269, 0;
	selp.f64 	%fd877, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p141;
	mul.wide.s32 	%rd121, %r271, 8;
	add.s64 	%rd123, %rd66, %rd121;
	ld.global.nc.f64 	%fd878, [%rd123+8];
	mul.rn.f64 	%fd222, %fd1424, %fd1424;
	fma.rn.f64 	%fd879, %fd877, %fd222, %fd878;
	ld.global.nc.f64 	%fd880, [%rd123+16];
	fma.rn.f64 	%fd881, %fd879, %fd222, %fd880;
	ld.global.nc.f64 	%fd882, [%rd123+24];
	fma.rn.f64 	%fd883, %fd881, %fd222, %fd882;
	ld.global.nc.f64 	%fd884, [%rd123+32];
	fma.rn.f64 	%fd885, %fd883, %fd222, %fd884;
	ld.global.nc.f64 	%fd886, [%rd123+40];
	fma.rn.f64 	%fd887, %fd885, %fd222, %fd886;
	ld.global.nc.f64 	%fd888, [%rd123+48];
	fma.rn.f64 	%fd223, %fd887, %fd222, %fd888;
	fma.rn.f64 	%fd1426, %fd223, %fd1424, %fd1424;
	@%p141 bra 	$L__BB15_149;

	mov.f64 	%fd889, 0d3FF0000000000000;
	fma.rn.f64 	%fd1426, %fd223, %fd222, %fd889;

$L__BB15_149:
	and.b32  	%r272, %r494, 2;
	setp.eq.s32 	%p142, %r272, 0;
	@%p142 bra 	$L__BB15_151;

	mov.f64 	%fd890, 0d0000000000000000;
	mov.f64 	%fd891, 0dBFF0000000000000;
	fma.rn.f64 	%fd1426, %fd1426, %fd891, %fd890;

$L__BB15_151:
	div.rn.f64 	%fd229, %fd192, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r273, %temp}, %fd229;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r274}, %fd229;
	}
	and.b32  	%r275, %r274, 2147483647;
	setp.eq.s32 	%p143, %r275, 2146435072;
	setp.eq.s32 	%p144, %r273, 0;
	and.pred  	%p145, %p144, %p143;
	@%p145 bra 	$L__BB15_154;
	bra.uni 	$L__BB15_152;

$L__BB15_154:
	mov.f64 	%fd901, 0d0000000000000000;
	mul.rn.f64 	%fd1427, %fd229, %fd901;
	mov.u32 	%r495, 0;
	bra.uni 	$L__BB15_155;

$L__BB15_152:
	mul.rn.f64 	%fd892, %fd229, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r495, %fd892;
	st.local.u32 	[%rd1], %r495;
	cvt.rn.f64.s32 	%fd893, %r495;
	neg.f64 	%fd894, %fd893;
	mov.f64 	%fd895, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd896, %fd894, %fd895, %fd229;
	mov.f64 	%fd897, 0d3C91A62633145C00;
	fma.rn.f64 	%fd898, %fd894, %fd897, %fd896;
	mov.f64 	%fd899, 0d397B839A252049C0;
	fma.rn.f64 	%fd1427, %fd894, %fd899, %fd898;
	abs.f64 	%fd900, %fd229;
	setp.ltu.f64 	%p146, %fd900, 0d41E0000000000000;
	@%p146 bra 	$L__BB15_155;

	{ // callseq 199, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd229;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1427, [retval0+0];
	} // callseq 199
	ld.local.u32 	%r495, [%rd1];

$L__BB15_155:
	and.b32  	%r277, %r495, 1;
	shl.b32 	%r278, %r495, 3;
	and.b32  	%r279, %r278, 8;
	setp.eq.s32 	%p147, %r277, 0;
	selp.f64 	%fd902, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p147;
	mul.wide.s32 	%rd125, %r279, 8;
	add.s64 	%rd127, %rd66, %rd125;
	ld.global.nc.f64 	%fd903, [%rd127+8];
	mul.rn.f64 	%fd234, %fd1427, %fd1427;
	fma.rn.f64 	%fd904, %fd902, %fd234, %fd903;
	ld.global.nc.f64 	%fd905, [%rd127+16];
	fma.rn.f64 	%fd906, %fd904, %fd234, %fd905;
	ld.global.nc.f64 	%fd907, [%rd127+24];
	fma.rn.f64 	%fd908, %fd906, %fd234, %fd907;
	ld.global.nc.f64 	%fd909, [%rd127+32];
	fma.rn.f64 	%fd910, %fd908, %fd234, %fd909;
	ld.global.nc.f64 	%fd911, [%rd127+40];
	fma.rn.f64 	%fd912, %fd910, %fd234, %fd911;
	ld.global.nc.f64 	%fd913, [%rd127+48];
	fma.rn.f64 	%fd235, %fd912, %fd234, %fd913;
	fma.rn.f64 	%fd1429, %fd235, %fd1427, %fd1427;
	@%p147 bra 	$L__BB15_157;

	mov.f64 	%fd914, 0d3FF0000000000000;
	fma.rn.f64 	%fd1429, %fd235, %fd234, %fd914;

$L__BB15_157:
	and.b32  	%r280, %r495, 2;
	setp.eq.s32 	%p148, %r280, 0;
	@%p148 bra 	$L__BB15_159;

	mov.f64 	%fd915, 0d0000000000000000;
	mov.f64 	%fd916, 0dBFF0000000000000;
	fma.rn.f64 	%fd1429, %fd1429, %fd916, %fd915;

$L__BB15_159:
	mul.rn.f64 	%fd917, %fd1429, 0d4044000000000000;
	mul.rn.f64 	%fd918, %fd1426, 0d4034000000000000;
	add.rn.f64 	%fd241, %fd918, %fd917;
	div.rn.f64 	%fd242, %fd192, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r281, %temp}, %fd242;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r282}, %fd242;
	}
	and.b32  	%r283, %r282, 2147483647;
	setp.eq.s32 	%p149, %r283, 2146435072;
	setp.eq.s32 	%p150, %r281, 0;
	and.pred  	%p151, %p150, %p149;
	@%p151 bra 	$L__BB15_162;
	bra.uni 	$L__BB15_160;

$L__BB15_162:
	mov.f64 	%fd928, 0d0000000000000000;
	mul.rn.f64 	%fd1430, %fd242, %fd928;
	mov.u32 	%r496, 0;
	bra.uni 	$L__BB15_163;

$L__BB15_160:
	mul.rn.f64 	%fd919, %fd242, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r496, %fd919;
	st.local.u32 	[%rd1], %r496;
	cvt.rn.f64.s32 	%fd920, %r496;
	neg.f64 	%fd921, %fd920;
	mov.f64 	%fd922, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd923, %fd921, %fd922, %fd242;
	mov.f64 	%fd924, 0d3C91A62633145C00;
	fma.rn.f64 	%fd925, %fd921, %fd924, %fd923;
	mov.f64 	%fd926, 0d397B839A252049C0;
	fma.rn.f64 	%fd1430, %fd921, %fd926, %fd925;
	abs.f64 	%fd927, %fd242;
	setp.ltu.f64 	%p152, %fd927, 0d41E0000000000000;
	@%p152 bra 	$L__BB15_163;

	{ // callseq 200, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd242;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1430, [retval0+0];
	} // callseq 200
	ld.local.u32 	%r496, [%rd1];

$L__BB15_163:
	and.b32  	%r285, %r496, 1;
	shl.b32 	%r286, %r496, 3;
	and.b32  	%r287, %r286, 8;
	setp.eq.s32 	%p153, %r285, 0;
	selp.f64 	%fd929, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p153;
	mul.wide.s32 	%rd129, %r287, 8;
	add.s64 	%rd131, %rd66, %rd129;
	ld.global.nc.f64 	%fd930, [%rd131+8];
	mul.rn.f64 	%fd247, %fd1430, %fd1430;
	fma.rn.f64 	%fd931, %fd929, %fd247, %fd930;
	ld.global.nc.f64 	%fd932, [%rd131+16];
	fma.rn.f64 	%fd933, %fd931, %fd247, %fd932;
	ld.global.nc.f64 	%fd934, [%rd131+24];
	fma.rn.f64 	%fd935, %fd933, %fd247, %fd934;
	ld.global.nc.f64 	%fd936, [%rd131+32];
	fma.rn.f64 	%fd937, %fd935, %fd247, %fd936;
	ld.global.nc.f64 	%fd938, [%rd131+40];
	fma.rn.f64 	%fd939, %fd937, %fd247, %fd938;
	ld.global.nc.f64 	%fd940, [%rd131+48];
	fma.rn.f64 	%fd248, %fd939, %fd247, %fd940;
	fma.rn.f64 	%fd1432, %fd248, %fd1430, %fd1430;
	@%p153 bra 	$L__BB15_165;

	mov.f64 	%fd941, 0d3FF0000000000000;
	fma.rn.f64 	%fd1432, %fd248, %fd247, %fd941;

$L__BB15_165:
	and.b32  	%r288, %r496, 2;
	setp.eq.s32 	%p154, %r288, 0;
	@%p154 bra 	$L__BB15_167;

	mov.f64 	%fd942, 0d0000000000000000;
	mov.f64 	%fd943, 0dBFF0000000000000;
	fma.rn.f64 	%fd1432, %fd1432, %fd943, %fd942;

$L__BB15_167:
	mul.rn.f64 	%fd944, %fd1432, 0d4064000000000000;
	add.rn.f64 	%fd254, %fd241, %fd944;
	div.rn.f64 	%fd255, %fd192, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r289, %temp}, %fd255;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %fd255;
	}
	and.b32  	%r291, %r290, 2147483647;
	setp.eq.s32 	%p155, %r291, 2146435072;
	setp.eq.s32 	%p156, %r289, 0;
	and.pred  	%p157, %p156, %p155;
	@%p157 bra 	$L__BB15_170;
	bra.uni 	$L__BB15_168;

$L__BB15_170:
	mov.f64 	%fd954, 0d0000000000000000;
	mul.rn.f64 	%fd1433, %fd255, %fd954;
	mov.u32 	%r497, 0;
	bra.uni 	$L__BB15_171;

$L__BB15_168:
	mul.rn.f64 	%fd945, %fd255, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r497, %fd945;
	st.local.u32 	[%rd1], %r497;
	cvt.rn.f64.s32 	%fd946, %r497;
	neg.f64 	%fd947, %fd946;
	mov.f64 	%fd948, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd949, %fd947, %fd948, %fd255;
	mov.f64 	%fd950, 0d3C91A62633145C00;
	fma.rn.f64 	%fd951, %fd947, %fd950, %fd949;
	mov.f64 	%fd952, 0d397B839A252049C0;
	fma.rn.f64 	%fd1433, %fd947, %fd952, %fd951;
	abs.f64 	%fd953, %fd255;
	setp.ltu.f64 	%p158, %fd953, 0d41E0000000000000;
	@%p158 bra 	$L__BB15_171;

	{ // callseq 201, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd255;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1433, [retval0+0];
	} // callseq 201
	ld.local.u32 	%r497, [%rd1];

$L__BB15_171:
	and.b32  	%r293, %r497, 1;
	shl.b32 	%r294, %r497, 3;
	and.b32  	%r295, %r294, 8;
	setp.eq.s32 	%p159, %r293, 0;
	selp.f64 	%fd955, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p159;
	mul.wide.s32 	%rd133, %r295, 8;
	add.s64 	%rd135, %rd66, %rd133;
	ld.global.nc.f64 	%fd956, [%rd135+8];
	mul.rn.f64 	%fd260, %fd1433, %fd1433;
	fma.rn.f64 	%fd957, %fd955, %fd260, %fd956;
	ld.global.nc.f64 	%fd958, [%rd135+16];
	fma.rn.f64 	%fd959, %fd957, %fd260, %fd958;
	ld.global.nc.f64 	%fd960, [%rd135+24];
	fma.rn.f64 	%fd961, %fd959, %fd260, %fd960;
	ld.global.nc.f64 	%fd962, [%rd135+32];
	fma.rn.f64 	%fd963, %fd961, %fd260, %fd962;
	ld.global.nc.f64 	%fd964, [%rd135+40];
	fma.rn.f64 	%fd965, %fd963, %fd260, %fd964;
	ld.global.nc.f64 	%fd966, [%rd135+48];
	fma.rn.f64 	%fd261, %fd965, %fd260, %fd966;
	fma.rn.f64 	%fd1435, %fd261, %fd1433, %fd1433;
	@%p159 bra 	$L__BB15_173;

	mov.f64 	%fd967, 0d3FF0000000000000;
	fma.rn.f64 	%fd1435, %fd261, %fd260, %fd967;

$L__BB15_173:
	and.b32  	%r296, %r497, 2;
	setp.eq.s32 	%p160, %r296, 0;
	@%p160 bra 	$L__BB15_175;

	mov.f64 	%fd968, 0d0000000000000000;
	mov.f64 	%fd969, 0dBFF0000000000000;
	fma.rn.f64 	%fd1435, %fd1435, %fd969, %fd968;

$L__BB15_175:
	mul.rn.f64 	%fd970, %fd1435, 0d4074000000000000;
	add.rn.f64 	%fd267, %fd254, %fd970;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r297}, %fd191;
	}
	and.b32  	%r298, %r297, 2147483647;
	setp.eq.s32 	%p161, %r298, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r299, %temp}, %fd191;
	}
	setp.eq.s32 	%p162, %r299, 0;
	and.pred  	%p163, %p162, %p161;
	@%p163 bra 	$L__BB15_178;
	bra.uni 	$L__BB15_176;

$L__BB15_178:
	mov.f64 	%fd980, 0d0000000000000000;
	mul.rn.f64 	%fd1436, %fd191, %fd980;
	mov.u32 	%r498, 0;
	bra.uni 	$L__BB15_179;

$L__BB15_176:
	mul.rn.f64 	%fd971, %fd191, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r498, %fd971;
	st.local.u32 	[%rd1], %r498;
	cvt.rn.f64.s32 	%fd972, %r498;
	neg.f64 	%fd973, %fd972;
	mov.f64 	%fd974, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd975, %fd973, %fd974, %fd191;
	mov.f64 	%fd976, 0d3C91A62633145C00;
	fma.rn.f64 	%fd977, %fd973, %fd976, %fd975;
	mov.f64 	%fd978, 0d397B839A252049C0;
	fma.rn.f64 	%fd1436, %fd973, %fd978, %fd977;
	abs.f64 	%fd979, %fd191;
	setp.ltu.f64 	%p164, %fd979, 0d41E0000000000000;
	@%p164 bra 	$L__BB15_179;

	{ // callseq 202, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd191;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1436, [retval0+0];
	} // callseq 202
	ld.local.u32 	%r498, [%rd1];

$L__BB15_179:
	and.b32  	%r301, %r498, 1;
	shl.b32 	%r302, %r498, 3;
	and.b32  	%r303, %r302, 8;
	setp.eq.s32 	%p165, %r301, 0;
	selp.f64 	%fd981, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p165;
	mul.wide.s32 	%rd137, %r303, 8;
	add.s64 	%rd139, %rd66, %rd137;
	ld.global.nc.f64 	%fd982, [%rd139+8];
	mul.rn.f64 	%fd272, %fd1436, %fd1436;
	fma.rn.f64 	%fd983, %fd981, %fd272, %fd982;
	ld.global.nc.f64 	%fd984, [%rd139+16];
	fma.rn.f64 	%fd985, %fd983, %fd272, %fd984;
	ld.global.nc.f64 	%fd986, [%rd139+24];
	fma.rn.f64 	%fd987, %fd985, %fd272, %fd986;
	ld.global.nc.f64 	%fd988, [%rd139+32];
	fma.rn.f64 	%fd989, %fd987, %fd272, %fd988;
	ld.global.nc.f64 	%fd990, [%rd139+40];
	fma.rn.f64 	%fd991, %fd989, %fd272, %fd990;
	ld.global.nc.f64 	%fd992, [%rd139+48];
	fma.rn.f64 	%fd273, %fd991, %fd272, %fd992;
	fma.rn.f64 	%fd1438, %fd273, %fd1436, %fd1436;
	@%p165 bra 	$L__BB15_181;

	mov.f64 	%fd993, 0d3FF0000000000000;
	fma.rn.f64 	%fd1438, %fd273, %fd272, %fd993;

$L__BB15_181:
	and.b32  	%r304, %r498, 2;
	setp.eq.s32 	%p166, %r304, 0;
	@%p166 bra 	$L__BB15_183;

	mov.f64 	%fd994, 0d0000000000000000;
	mov.f64 	%fd995, 0dBFF0000000000000;
	fma.rn.f64 	%fd1438, %fd1438, %fd995, %fd994;

$L__BB15_183:
	div.rn.f64 	%fd279, %fd191, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r305, %temp}, %fd279;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r306}, %fd279;
	}
	and.b32  	%r307, %r306, 2147483647;
	setp.eq.s32 	%p167, %r307, 2146435072;
	setp.eq.s32 	%p168, %r305, 0;
	and.pred  	%p169, %p168, %p167;
	@%p169 bra 	$L__BB15_186;
	bra.uni 	$L__BB15_184;

$L__BB15_186:
	mov.f64 	%fd1005, 0d0000000000000000;
	mul.rn.f64 	%fd1439, %fd279, %fd1005;
	mov.u32 	%r499, 0;
	bra.uni 	$L__BB15_187;

$L__BB15_184:
	mul.rn.f64 	%fd996, %fd279, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r499, %fd996;
	st.local.u32 	[%rd1], %r499;
	cvt.rn.f64.s32 	%fd997, %r499;
	neg.f64 	%fd998, %fd997;
	mov.f64 	%fd999, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1000, %fd998, %fd999, %fd279;
	mov.f64 	%fd1001, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1002, %fd998, %fd1001, %fd1000;
	mov.f64 	%fd1003, 0d397B839A252049C0;
	fma.rn.f64 	%fd1439, %fd998, %fd1003, %fd1002;
	abs.f64 	%fd1004, %fd279;
	setp.ltu.f64 	%p170, %fd1004, 0d41E0000000000000;
	@%p170 bra 	$L__BB15_187;

	{ // callseq 203, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd279;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1439, [retval0+0];
	} // callseq 203
	ld.local.u32 	%r499, [%rd1];

$L__BB15_187:
	and.b32  	%r309, %r499, 1;
	shl.b32 	%r310, %r499, 3;
	and.b32  	%r311, %r310, 8;
	setp.eq.s32 	%p171, %r309, 0;
	selp.f64 	%fd1006, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p171;
	mul.wide.s32 	%rd141, %r311, 8;
	add.s64 	%rd143, %rd66, %rd141;
	ld.global.nc.f64 	%fd1007, [%rd143+8];
	mul.rn.f64 	%fd284, %fd1439, %fd1439;
	fma.rn.f64 	%fd1008, %fd1006, %fd284, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd143+16];
	fma.rn.f64 	%fd1010, %fd1008, %fd284, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd143+24];
	fma.rn.f64 	%fd1012, %fd1010, %fd284, %fd1011;
	ld.global.nc.f64 	%fd1013, [%rd143+32];
	fma.rn.f64 	%fd1014, %fd1012, %fd284, %fd1013;
	ld.global.nc.f64 	%fd1015, [%rd143+40];
	fma.rn.f64 	%fd1016, %fd1014, %fd284, %fd1015;
	ld.global.nc.f64 	%fd1017, [%rd143+48];
	fma.rn.f64 	%fd285, %fd1016, %fd284, %fd1017;
	fma.rn.f64 	%fd1441, %fd285, %fd1439, %fd1439;
	@%p171 bra 	$L__BB15_189;

	mov.f64 	%fd1018, 0d3FF0000000000000;
	fma.rn.f64 	%fd1441, %fd285, %fd284, %fd1018;

$L__BB15_189:
	and.b32  	%r312, %r499, 2;
	setp.eq.s32 	%p172, %r312, 0;
	@%p172 bra 	$L__BB15_191;

	mov.f64 	%fd1019, 0d0000000000000000;
	mov.f64 	%fd1020, 0dBFF0000000000000;
	fma.rn.f64 	%fd1441, %fd1441, %fd1020, %fd1019;

$L__BB15_191:
	mul.rn.f64 	%fd1021, %fd1441, 0d4044000000000000;
	mul.rn.f64 	%fd1022, %fd1438, 0d4034000000000000;
	add.rn.f64 	%fd291, %fd1022, %fd1021;
	div.rn.f64 	%fd292, %fd191, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r313, %temp}, %fd292;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd292;
	}
	and.b32  	%r315, %r314, 2147483647;
	setp.eq.s32 	%p173, %r315, 2146435072;
	setp.eq.s32 	%p174, %r313, 0;
	and.pred  	%p175, %p174, %p173;
	@%p175 bra 	$L__BB15_194;
	bra.uni 	$L__BB15_192;

$L__BB15_194:
	mov.f64 	%fd1032, 0d0000000000000000;
	mul.rn.f64 	%fd1442, %fd292, %fd1032;
	mov.u32 	%r500, 0;
	bra.uni 	$L__BB15_195;

$L__BB15_192:
	mul.rn.f64 	%fd1023, %fd292, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r500, %fd1023;
	st.local.u32 	[%rd1], %r500;
	cvt.rn.f64.s32 	%fd1024, %r500;
	neg.f64 	%fd1025, %fd1024;
	mov.f64 	%fd1026, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1027, %fd1025, %fd1026, %fd292;
	mov.f64 	%fd1028, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1029, %fd1025, %fd1028, %fd1027;
	mov.f64 	%fd1030, 0d397B839A252049C0;
	fma.rn.f64 	%fd1442, %fd1025, %fd1030, %fd1029;
	abs.f64 	%fd1031, %fd292;
	setp.ltu.f64 	%p176, %fd1031, 0d41E0000000000000;
	@%p176 bra 	$L__BB15_195;

	{ // callseq 204, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd292;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1442, [retval0+0];
	} // callseq 204
	ld.local.u32 	%r500, [%rd1];

$L__BB15_195:
	and.b32  	%r317, %r500, 1;
	shl.b32 	%r318, %r500, 3;
	and.b32  	%r319, %r318, 8;
	setp.eq.s32 	%p177, %r317, 0;
	selp.f64 	%fd1033, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p177;
	mul.wide.s32 	%rd145, %r319, 8;
	add.s64 	%rd147, %rd66, %rd145;
	ld.global.nc.f64 	%fd1034, [%rd147+8];
	mul.rn.f64 	%fd297, %fd1442, %fd1442;
	fma.rn.f64 	%fd1035, %fd1033, %fd297, %fd1034;
	ld.global.nc.f64 	%fd1036, [%rd147+16];
	fma.rn.f64 	%fd1037, %fd1035, %fd297, %fd1036;
	ld.global.nc.f64 	%fd1038, [%rd147+24];
	fma.rn.f64 	%fd1039, %fd1037, %fd297, %fd1038;
	ld.global.nc.f64 	%fd1040, [%rd147+32];
	fma.rn.f64 	%fd1041, %fd1039, %fd297, %fd1040;
	ld.global.nc.f64 	%fd1042, [%rd147+40];
	fma.rn.f64 	%fd1043, %fd1041, %fd297, %fd1042;
	ld.global.nc.f64 	%fd1044, [%rd147+48];
	fma.rn.f64 	%fd298, %fd1043, %fd297, %fd1044;
	fma.rn.f64 	%fd1444, %fd298, %fd1442, %fd1442;
	@%p177 bra 	$L__BB15_197;

	mov.f64 	%fd1045, 0d3FF0000000000000;
	fma.rn.f64 	%fd1444, %fd298, %fd297, %fd1045;

$L__BB15_197:
	and.b32  	%r320, %r500, 2;
	setp.eq.s32 	%p178, %r320, 0;
	@%p178 bra 	$L__BB15_199;

	mov.f64 	%fd1046, 0d0000000000000000;
	mov.f64 	%fd1047, 0dBFF0000000000000;
	fma.rn.f64 	%fd1444, %fd1444, %fd1047, %fd1046;

$L__BB15_199:
	mul.rn.f64 	%fd1048, %fd1444, 0d4062C00000000000;
	add.rn.f64 	%fd304, %fd291, %fd1048;
	div.rn.f64 	%fd305, %fd191, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r321, %temp}, %fd305;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r322}, %fd305;
	}
	and.b32  	%r323, %r322, 2147483647;
	setp.eq.s32 	%p179, %r323, 2146435072;
	setp.eq.s32 	%p180, %r321, 0;
	and.pred  	%p181, %p180, %p179;
	@%p181 bra 	$L__BB15_202;
	bra.uni 	$L__BB15_200;

$L__BB15_202:
	mov.f64 	%fd1058, 0d0000000000000000;
	mul.rn.f64 	%fd1445, %fd305, %fd1058;
	mov.u32 	%r501, 0;
	bra.uni 	$L__BB15_203;

$L__BB15_200:
	mul.rn.f64 	%fd1049, %fd305, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r501, %fd1049;
	st.local.u32 	[%rd1], %r501;
	cvt.rn.f64.s32 	%fd1050, %r501;
	neg.f64 	%fd1051, %fd1050;
	mov.f64 	%fd1052, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1053, %fd1051, %fd1052, %fd305;
	mov.f64 	%fd1054, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1055, %fd1051, %fd1054, %fd1053;
	mov.f64 	%fd1056, 0d397B839A252049C0;
	fma.rn.f64 	%fd1445, %fd1051, %fd1056, %fd1055;
	abs.f64 	%fd1057, %fd305;
	setp.ltu.f64 	%p182, %fd1057, 0d41E0000000000000;
	@%p182 bra 	$L__BB15_203;

	{ // callseq 205, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd305;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1445, [retval0+0];
	} // callseq 205
	ld.local.u32 	%r501, [%rd1];

$L__BB15_203:
	and.b32  	%r325, %r501, 1;
	shl.b32 	%r326, %r501, 3;
	and.b32  	%r327, %r326, 8;
	setp.eq.s32 	%p183, %r325, 0;
	selp.f64 	%fd1059, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p183;
	mul.wide.s32 	%rd149, %r327, 8;
	add.s64 	%rd151, %rd66, %rd149;
	ld.global.nc.f64 	%fd1060, [%rd151+8];
	mul.rn.f64 	%fd310, %fd1445, %fd1445;
	fma.rn.f64 	%fd1061, %fd1059, %fd310, %fd1060;
	ld.global.nc.f64 	%fd1062, [%rd151+16];
	fma.rn.f64 	%fd1063, %fd1061, %fd310, %fd1062;
	ld.global.nc.f64 	%fd1064, [%rd151+24];
	fma.rn.f64 	%fd1065, %fd1063, %fd310, %fd1064;
	ld.global.nc.f64 	%fd1066, [%rd151+32];
	fma.rn.f64 	%fd1067, %fd1065, %fd310, %fd1066;
	ld.global.nc.f64 	%fd1068, [%rd151+40];
	fma.rn.f64 	%fd1069, %fd1067, %fd310, %fd1068;
	ld.global.nc.f64 	%fd1070, [%rd151+48];
	fma.rn.f64 	%fd311, %fd1069, %fd310, %fd1070;
	fma.rn.f64 	%fd1447, %fd311, %fd1445, %fd1445;
	@%p183 bra 	$L__BB15_205;

	mov.f64 	%fd1071, 0d3FF0000000000000;
	fma.rn.f64 	%fd1447, %fd311, %fd310, %fd1071;

$L__BB15_205:
	and.b32  	%r328, %r501, 2;
	setp.eq.s32 	%p184, %r328, 0;
	@%p184 bra 	$L__BB15_207;

	mov.f64 	%fd1072, 0d0000000000000000;
	mov.f64 	%fd1073, 0dBFF0000000000000;
	fma.rn.f64 	%fd1447, %fd1447, %fd1073, %fd1072;

$L__BB15_207:
	mul.rn.f64 	%fd1074, %fd1447, 0d4072C00000000000;
	add.rn.f64 	%fd1075, %fd304, %fd1074;
	add.rn.f64 	%fd317, %fd217, %fd1075;
	add.rn.f64 	%fd318, %fd217, %fd267;
	add.rn.f64 	%fd1076, %fd188, %fd188;
	add.rn.f64 	%fd1077, %fd1076, 0dC059000000000000;
	mul.rn.f64 	%fd1078, %fd187, 0d4008000000000000;
	add.rn.f64 	%fd319, %fd1077, %fd1078;
	abs.f64 	%fd320, %fd187;
	{ // callseq 206, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd320;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1450, [retval0+0];
	} // callseq 206
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r79}, %fd187;
	}
	setp.lt.s32 	%p185, %r79, 0;
	and.pred  	%p4, %p185, %p69;
	not.pred 	%p187, %p4;
	@%p187 bra 	$L__BB15_209;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r329}, %fd1450;
	}
	xor.b32  	%r330, %r329, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r331, %temp}, %fd1450;
	}
	mov.b64 	%fd1450, {%r331, %r330};

$L__BB15_209:
	setp.eq.f64 	%p188, %fd187, 0d0000000000000000;
	@%p188 bra 	$L__BB15_213;
	bra.uni 	$L__BB15_210;

$L__BB15_213:
	setp.lt.s32 	%p191, %r31, 0;
	mov.u32 	%r332, 0;
	selp.b32 	%r333, %r79, 0, %p69;
	or.b32  	%r334, %r333, 2146435072;
	selp.b32 	%r335, %r334, %r333, %p191;
	mov.b64 	%fd1450, {%r332, %r335};
	bra.uni 	$L__BB15_214;

$L__BB15_210:
	setp.gt.s32 	%p189, %r79, -1;
	@%p189 bra 	$L__BB15_214;

	mov.f64 	%fd1079, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1080, %fd1079;
	setp.eq.f64 	%p190, %fd1080, 0d4000000000000000;
	@%p190 bra 	$L__BB15_214;

	mov.f64 	%fd1450, 0dFFF8000000000000;

$L__BB15_214:
	add.rn.f64 	%fd1082, %fd187, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r336}, %fd1082;
	}
	and.b32  	%r337, %r336, 2146435072;
	setp.ne.s32 	%p193, %r337, 2146435072;
	@%p193 bra 	$L__BB15_221;

	setp.gtu.f64 	%p194, %fd320, 0d7FF0000000000000;
	@%p194 bra 	$L__BB15_220;
	bra.uni 	$L__BB15_216;

$L__BB15_220:
	mov.f64 	%fd1084, 0d4000000000000000;
	add.rn.f64 	%fd1450, %fd187, %fd1084;
	bra.uni 	$L__BB15_221;

$L__BB15_216:
	setp.eq.s32 	%p195, %r45, 2146435072;
	mov.f64 	%fd1083, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r338, %temp}, %fd1083;
	}
	setp.eq.s32 	%p196, %r338, 0;
	and.pred  	%p197, %p195, %p196;
	@%p197 bra 	$L__BB15_219;
	bra.uni 	$L__BB15_217;

$L__BB15_219:
	setp.lt.s32 	%p203, %r31, 0;
	mov.u32 	%r343, 0;
	setp.gt.f64 	%p204, %fd320, 0d3FF0000000000000;
	selp.b32 	%r344, 2146435072, 0, %p204;
	xor.b32  	%r345, %r344, 2146435072;
	selp.b32 	%r346, %r345, %r344, %p203;
	setp.eq.f64 	%p205, %fd187, 0dBFF0000000000000;
	selp.b32 	%r347, 1072693248, %r346, %p205;
	mov.b64 	%fd1450, {%r343, %r347};
	bra.uni 	$L__BB15_221;

$L__BB15_217:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r339, %temp}, %fd187;
	}
	and.b32  	%r340, %r79, 2147483647;
	setp.ne.s32 	%p198, %r340, 2146435072;
	setp.ne.s32 	%p199, %r339, 0;
	or.pred  	%p200, %p198, %p199;
	@%p200 bra 	$L__BB15_221;

	setp.ne.s32 	%p201, %r45, 1071644672;
	and.pred  	%p202, %p201, %p4;
	selp.b32 	%r341, %r47, %r46, %p202;
	mov.u32 	%r342, 0;
	mov.b64 	%fd1450, {%r342, %r341};

$L__BB15_221:
	mul.rn.f64 	%fd1085, %fd1450, 0d3FC999999999999A;
	setp.eq.f64 	%p206, %fd187, 0d3FF0000000000000;
	selp.f64 	%fd1086, 0d3FC999999999999A, %fd1085, %p206;
	add.rn.f64 	%fd1087, %fd319, %fd1086;
	mul.rn.f64 	%fd1088, %fd188, %fd187;
	mul.rn.f64 	%fd330, %fd1088, 0d3FB999999999999A;
	add.rn.f64 	%fd1089, %fd330, %fd1087;
	mul.rn.f64 	%fd1090, %fd190, 0d3FC999999999999A;
	add.rn.f64 	%fd1091, %fd1090, %fd1089;
	mul.rn.f64 	%fd1092, %fd318, 0d3FE5555555555555;
	add.rn.f64 	%fd331, %fd1092, %fd1091;
	add.rn.f64 	%fd1093, %fd187, %fd187;
	add.rn.f64 	%fd1094, %fd188, 0d4072C00000000000;
	add.rn.f64 	%fd332, %fd1094, %fd1093;
	{ // callseq 207, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd189;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1453, [retval0+0];
	} // callseq 207
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r80}, %fd188;
	}
	setp.lt.s32 	%p207, %r80, 0;
	and.pred  	%p5, %p207, %p69;
	not.pred 	%p209, %p5;
	@%p209 bra 	$L__BB15_223;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r348}, %fd1453;
	}
	xor.b32  	%r349, %r348, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r350, %temp}, %fd1453;
	}
	mov.b64 	%fd1453, {%r350, %r349};

$L__BB15_223:
	setp.eq.f64 	%p210, %fd188, 0d0000000000000000;
	@%p210 bra 	$L__BB15_227;
	bra.uni 	$L__BB15_224;

$L__BB15_227:
	setp.lt.s32 	%p213, %r31, 0;
	mov.u32 	%r351, 0;
	selp.b32 	%r352, %r80, 0, %p69;
	or.b32  	%r353, %r352, 2146435072;
	selp.b32 	%r354, %r353, %r352, %p213;
	mov.b64 	%fd1453, {%r351, %r354};
	bra.uni 	$L__BB15_228;

$L__BB15_224:
	setp.gt.s32 	%p211, %r80, -1;
	@%p211 bra 	$L__BB15_228;

	mov.f64 	%fd1095, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1096, %fd1095;
	setp.eq.f64 	%p212, %fd1096, 0d4000000000000000;
	@%p212 bra 	$L__BB15_228;

	mov.f64 	%fd1453, 0dFFF8000000000000;

$L__BB15_228:
	add.rn.f64 	%fd1098, %fd188, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r355}, %fd1098;
	}
	and.b32  	%r356, %r355, 2146435072;
	setp.ne.s32 	%p215, %r356, 2146435072;
	@%p215 bra 	$L__BB15_235;

	setp.gtu.f64 	%p216, %fd189, 0d7FF0000000000000;
	@%p216 bra 	$L__BB15_234;
	bra.uni 	$L__BB15_230;

$L__BB15_234:
	mov.f64 	%fd1100, 0d4000000000000000;
	add.rn.f64 	%fd1453, %fd188, %fd1100;
	bra.uni 	$L__BB15_235;

$L__BB15_230:
	setp.eq.s32 	%p217, %r45, 2146435072;
	mov.f64 	%fd1099, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r357, %temp}, %fd1099;
	}
	setp.eq.s32 	%p218, %r357, 0;
	and.pred  	%p219, %p217, %p218;
	@%p219 bra 	$L__BB15_233;
	bra.uni 	$L__BB15_231;

$L__BB15_233:
	setp.lt.s32 	%p225, %r31, 0;
	mov.u32 	%r362, 0;
	setp.gt.f64 	%p226, %fd189, 0d3FF0000000000000;
	selp.b32 	%r363, 2146435072, 0, %p226;
	xor.b32  	%r364, %r363, 2146435072;
	selp.b32 	%r365, %r364, %r363, %p225;
	setp.eq.f64 	%p227, %fd188, 0dBFF0000000000000;
	selp.b32 	%r366, 1072693248, %r365, %p227;
	mov.b64 	%fd1453, {%r362, %r366};
	bra.uni 	$L__BB15_235;

$L__BB15_231:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r358, %temp}, %fd188;
	}
	and.b32  	%r359, %r80, 2147483647;
	setp.ne.s32 	%p220, %r359, 2146435072;
	setp.ne.s32 	%p221, %r358, 0;
	or.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB15_235;

	setp.ne.s32 	%p223, %r45, 1071644672;
	and.pred  	%p224, %p223, %p5;
	selp.b32 	%r360, %r47, %r46, %p224;
	mov.u32 	%r361, 0;
	mov.b64 	%fd1453, {%r361, %r360};

$L__BB15_235:
	mul.rn.f64 	%fd1101, %fd1453, 0d3FB999999999999A;
	setp.eq.f64 	%p228, %fd188, 0d3FF0000000000000;
	selp.f64 	%fd1102, 0d3FB999999999999A, %fd1101, %p228;
	add.rn.f64 	%fd1103, %fd332, %fd1102;
	add.rn.f64 	%fd1104, %fd330, %fd1103;
	mul.rn.f64 	%fd1105, %fd190, 0d3FB999999999999A;
	add.rn.f64 	%fd1106, %fd1105, %fd1104;
	mul.rn.f64 	%fd1107, %fd317, 0d3FE5555555555555;
	add.rn.f64 	%fd342, %fd1107, %fd1106;
	div.rn.f64 	%fd1108, %fd1483, 0d4066800000000000;
	mul.rn.f64 	%fd343, %fd1108, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r367, %temp}, %fd343;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r368}, %fd343;
	}
	and.b32  	%r369, %r368, 2147483647;
	setp.eq.s32 	%p229, %r369, 2146435072;
	setp.eq.s32 	%p230, %r367, 0;
	and.pred  	%p6, %p230, %p229;
	@%p6 bra 	$L__BB15_238;
	bra.uni 	$L__BB15_236;

$L__BB15_238:
	mov.f64 	%fd1118, 0d0000000000000000;
	mul.rn.f64 	%fd1454, %fd343, %fd1118;
	mov.u32 	%r502, 0;
	bra.uni 	$L__BB15_239;

$L__BB15_236:
	mul.rn.f64 	%fd1109, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r502, %fd1109;
	st.local.u32 	[%rd1], %r502;
	cvt.rn.f64.s32 	%fd1110, %r502;
	neg.f64 	%fd1111, %fd1110;
	mov.f64 	%fd1112, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1113, %fd1111, %fd1112, %fd343;
	mov.f64 	%fd1114, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1115, %fd1111, %fd1114, %fd1113;
	mov.f64 	%fd1116, 0d397B839A252049C0;
	fma.rn.f64 	%fd1454, %fd1111, %fd1116, %fd1115;
	abs.f64 	%fd1117, %fd343;
	setp.ltu.f64 	%p231, %fd1117, 0d41E0000000000000;
	@%p231 bra 	$L__BB15_239;

	{ // callseq 208, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1454, [retval0+0];
	} // callseq 208
	ld.local.u32 	%r502, [%rd1];

$L__BB15_239:
	and.b32  	%r371, %r502, 1;
	shl.b32 	%r372, %r502, 3;
	and.b32  	%r373, %r372, 8;
	setp.eq.s32 	%p232, %r371, 0;
	selp.f64 	%fd1119, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p232;
	mul.wide.s32 	%rd153, %r373, 8;
	add.s64 	%rd155, %rd66, %rd153;
	ld.global.nc.f64 	%fd1120, [%rd155+8];
	mul.rn.f64 	%fd348, %fd1454, %fd1454;
	fma.rn.f64 	%fd1121, %fd1119, %fd348, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd155+16];
	fma.rn.f64 	%fd1123, %fd1121, %fd348, %fd1122;
	ld.global.nc.f64 	%fd1124, [%rd155+24];
	fma.rn.f64 	%fd1125, %fd1123, %fd348, %fd1124;
	ld.global.nc.f64 	%fd1126, [%rd155+32];
	fma.rn.f64 	%fd1127, %fd1125, %fd348, %fd1126;
	ld.global.nc.f64 	%fd1128, [%rd155+40];
	fma.rn.f64 	%fd1129, %fd1127, %fd348, %fd1128;
	ld.global.nc.f64 	%fd1130, [%rd155+48];
	fma.rn.f64 	%fd349, %fd1129, %fd348, %fd1130;
	fma.rn.f64 	%fd1456, %fd349, %fd1454, %fd1454;
	@%p232 bra 	$L__BB15_241;

	mov.f64 	%fd1131, 0d3FF0000000000000;
	fma.rn.f64 	%fd1456, %fd349, %fd348, %fd1131;

$L__BB15_241:
	and.b32  	%r374, %r502, 2;
	setp.eq.s32 	%p233, %r374, 0;
	@%p233 bra 	$L__BB15_243;

	mov.f64 	%fd1132, 0d0000000000000000;
	mov.f64 	%fd1133, 0dBFF0000000000000;
	fma.rn.f64 	%fd1456, %fd1456, %fd1133, %fd1132;

$L__BB15_243:
	@%p6 bra 	$L__BB15_247;
	bra.uni 	$L__BB15_244;

$L__BB15_247:
	mov.f64 	%fd1143, 0d0000000000000000;
	mul.rn.f64 	%fd1458, %fd343, %fd1143;
	mov.u32 	%r504, 1;
	bra.uni 	$L__BB15_248;

$L__BB15_244:
	mul.rn.f64 	%fd1134, %fd343, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r503, %fd1134;
	st.local.u32 	[%rd1], %r503;
	cvt.rn.f64.s32 	%fd1135, %r503;
	neg.f64 	%fd1136, %fd1135;
	mov.f64 	%fd1137, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1138, %fd1136, %fd1137, %fd343;
	mov.f64 	%fd1139, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1140, %fd1136, %fd1139, %fd1138;
	mov.f64 	%fd1141, 0d397B839A252049C0;
	fma.rn.f64 	%fd1458, %fd1136, %fd1141, %fd1140;
	abs.f64 	%fd1142, %fd343;
	setp.ltu.f64 	%p234, %fd1142, 0d41E0000000000000;
	@%p234 bra 	$L__BB15_246;

	{ // callseq 209, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd343;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1458, [retval0+0];
	} // callseq 209
	ld.local.u32 	%r503, [%rd1];

$L__BB15_246:
	add.s32 	%r504, %r503, 1;

$L__BB15_248:
	and.b32  	%r376, %r504, 1;
	shl.b32 	%r377, %r504, 3;
	and.b32  	%r378, %r377, 8;
	setp.eq.s32 	%p235, %r376, 0;
	selp.f64 	%fd1144, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p235;
	mul.wide.s32 	%rd157, %r378, 8;
	add.s64 	%rd159, %rd66, %rd157;
	ld.global.nc.f64 	%fd1145, [%rd159+8];
	mul.rn.f64 	%fd360, %fd1458, %fd1458;
	fma.rn.f64 	%fd1146, %fd1144, %fd360, %fd1145;
	ld.global.nc.f64 	%fd1147, [%rd159+16];
	fma.rn.f64 	%fd1148, %fd1146, %fd360, %fd1147;
	ld.global.nc.f64 	%fd1149, [%rd159+24];
	fma.rn.f64 	%fd1150, %fd1148, %fd360, %fd1149;
	ld.global.nc.f64 	%fd1151, [%rd159+32];
	fma.rn.f64 	%fd1152, %fd1150, %fd360, %fd1151;
	ld.global.nc.f64 	%fd1153, [%rd159+40];
	fma.rn.f64 	%fd1154, %fd1152, %fd360, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd159+48];
	fma.rn.f64 	%fd361, %fd1154, %fd360, %fd1155;
	fma.rn.f64 	%fd1460, %fd361, %fd1458, %fd1458;
	@%p235 bra 	$L__BB15_250;

	mov.f64 	%fd1156, 0d3FF0000000000000;
	fma.rn.f64 	%fd1460, %fd361, %fd360, %fd1156;

$L__BB15_250:
	and.b32  	%r379, %r504, 2;
	setp.eq.s32 	%p236, %r379, 0;
	@%p236 bra 	$L__BB15_252;

	mov.f64 	%fd1157, 0d0000000000000000;
	mov.f64 	%fd1158, 0dBFF0000000000000;
	fma.rn.f64 	%fd1460, %fd1460, %fd1158, %fd1157;

$L__BB15_252:
	ld.param.s8 	%rs2, [gcj02_to_wgs84_exact_cuda_double_param_3];
	mul.rn.f64 	%fd1159, %fd1456, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1160, %fd1456, %fd1159;
	add.rn.f64 	%fd1161, %fd1160, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1162, %fd1161;
	mov.f64 	%fd1163, 0d415854C140000000;
	div.rn.f64 	%fd1164, %fd1163, %fd1162;
	mul.rn.f64 	%fd1165, %fd1164, %fd1460;
	mul.rn.f64 	%fd1166, %fd1165, 0d400921FB54442D18;
	mul.rn.f64 	%fd1167, %fd342, 0d4066800000000000;
	div.rn.f64 	%fd1168, %fd1167, %fd1166;
	add.rn.f64 	%fd1169, %fd1482, %fd1168;
	sub.rn.f64 	%fd367, %fd1, %fd1169;
	mul.rn.f64 	%fd1170, %fd331, 0d4066800000000000;
	mul.rn.f64 	%fd1171, %fd1162, %fd1161;
	mov.f64 	%fd1172, 0d41582B102DE355C1;
	div.rn.f64 	%fd1173, %fd1172, %fd1171;
	mul.rn.f64 	%fd1174, %fd1173, 0d400921FB54442D18;
	div.rn.f64 	%fd1175, %fd1170, %fd1174;
	add.rn.f64 	%fd1176, %fd1483, %fd1175;
	sub.rn.f64 	%fd368, %fd3, %fd1176;
	add.rn.f64 	%fd369, %fd1482, %fd367;
	add.rn.f64 	%fd370, %fd1483, %fd368;
	setp.eq.s16 	%p237, %rs2, 0;
	@%p237 bra 	$L__BB15_321;

	mul.rn.f64 	%fd1177, %fd1483, 0d400921FB54442D18;
	div.rn.f64 	%fd371, %fd1177, 0d4066800000000000;
	mul.rn.f64 	%fd1178, %fd370, 0d400921FB54442D18;
	div.rn.f64 	%fd372, %fd1178, 0d4066800000000000;
	sub.rn.f64 	%fd1179, %fd372, %fd371;
	mul.rn.f64 	%fd373, %fd1179, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r380, %temp}, %fd373;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r381}, %fd373;
	}
	and.b32  	%r382, %r381, 2147483647;
	setp.eq.s32 	%p238, %r382, 2146435072;
	setp.eq.s32 	%p239, %r380, 0;
	and.pred  	%p240, %p239, %p238;
	@%p240 bra 	$L__BB15_256;
	bra.uni 	$L__BB15_254;

$L__BB15_256:
	mov.f64 	%fd1189, 0d0000000000000000;
	mul.rn.f64 	%fd1461, %fd373, %fd1189;
	mov.u32 	%r505, 0;
	bra.uni 	$L__BB15_257;

$L__BB15_321:
	abs.f64 	%fd1357, %fd367;
	abs.f64 	%fd1358, %fd368;
	mul.rn.f64 	%fd1359, %fd1358, %fd453;
	setp.lt.f64 	%p318, %fd1357, %fd1359;
	selp.f64 	%fd1360, 0d3FF0000000000000, 0d0000000000000000, %p318;
	setp.lt.f64 	%p319, %fd1360, %fd453;
	@%p319 bra 	$L__BB15_323;
	bra.uni 	$L__BB15_322;

$L__BB15_254:
	mul.rn.f64 	%fd1180, %fd373, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r505, %fd1180;
	st.local.u32 	[%rd1], %r505;
	cvt.rn.f64.s32 	%fd1181, %r505;
	neg.f64 	%fd1182, %fd1181;
	mov.f64 	%fd1183, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1184, %fd1182, %fd1183, %fd373;
	mov.f64 	%fd1185, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1186, %fd1182, %fd1185, %fd1184;
	mov.f64 	%fd1187, 0d397B839A252049C0;
	fma.rn.f64 	%fd1461, %fd1182, %fd1187, %fd1186;
	abs.f64 	%fd1188, %fd373;
	setp.ltu.f64 	%p241, %fd1188, 0d41E0000000000000;
	@%p241 bra 	$L__BB15_257;

	{ // callseq 210, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd373;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1461, [retval0+0];
	} // callseq 210
	ld.local.u32 	%r505, [%rd1];

$L__BB15_257:
	and.b32  	%r384, %r505, 1;
	shl.b32 	%r385, %r505, 3;
	and.b32  	%r386, %r385, 8;
	setp.eq.s32 	%p242, %r384, 0;
	selp.f64 	%fd1190, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p242;
	mul.wide.s32 	%rd161, %r386, 8;
	add.s64 	%rd163, %rd66, %rd161;
	ld.global.nc.f64 	%fd1191, [%rd163+8];
	mul.rn.f64 	%fd378, %fd1461, %fd1461;
	fma.rn.f64 	%fd1192, %fd1190, %fd378, %fd1191;
	ld.global.nc.f64 	%fd1193, [%rd163+16];
	fma.rn.f64 	%fd1194, %fd1192, %fd378, %fd1193;
	ld.global.nc.f64 	%fd1195, [%rd163+24];
	fma.rn.f64 	%fd1196, %fd1194, %fd378, %fd1195;
	ld.global.nc.f64 	%fd1197, [%rd163+32];
	fma.rn.f64 	%fd1198, %fd1196, %fd378, %fd1197;
	ld.global.nc.f64 	%fd1199, [%rd163+40];
	fma.rn.f64 	%fd1200, %fd1198, %fd378, %fd1199;
	ld.global.nc.f64 	%fd1201, [%rd163+48];
	fma.rn.f64 	%fd379, %fd1200, %fd378, %fd1201;
	fma.rn.f64 	%fd1463, %fd379, %fd1461, %fd1461;
	@%p242 bra 	$L__BB15_259;

	mov.f64 	%fd1202, 0d3FF0000000000000;
	fma.rn.f64 	%fd1463, %fd379, %fd378, %fd1202;

$L__BB15_259:
	and.b32  	%r387, %r505, 2;
	setp.eq.s32 	%p243, %r387, 0;
	@%p243 bra 	$L__BB15_261;

	mov.f64 	%fd1203, 0d0000000000000000;
	mov.f64 	%fd1204, 0dBFF0000000000000;
	fma.rn.f64 	%fd1463, %fd1463, %fd1204, %fd1203;

$L__BB15_261:
	abs.f64 	%fd385, %fd1463;
	{ // callseq 211, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd385;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1466, [retval0+0];
	} // callseq 211
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r92}, %fd1463;
	}
	setp.lt.s32 	%p244, %r92, 0;
	and.pred  	%p7, %p244, %p69;
	not.pred 	%p246, %p7;
	@%p246 bra 	$L__BB15_263;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r388}, %fd1466;
	}
	xor.b32  	%r389, %r388, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r390, %temp}, %fd1466;
	}
	mov.b64 	%fd1466, {%r390, %r389};

$L__BB15_263:
	setp.eq.f64 	%p247, %fd1463, 0d0000000000000000;
	@%p247 bra 	$L__BB15_267;
	bra.uni 	$L__BB15_264;

$L__BB15_267:
	setp.lt.s32 	%p250, %r31, 0;
	mov.u32 	%r391, 0;
	selp.b32 	%r392, %r92, 0, %p69;
	or.b32  	%r393, %r392, 2146435072;
	selp.b32 	%r394, %r393, %r392, %p250;
	mov.b64 	%fd1466, {%r391, %r394};
	bra.uni 	$L__BB15_268;

$L__BB15_264:
	setp.gt.s32 	%p248, %r92, -1;
	@%p248 bra 	$L__BB15_268;

	mov.f64 	%fd1205, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1206, %fd1205;
	setp.eq.f64 	%p249, %fd1206, 0d4000000000000000;
	@%p249 bra 	$L__BB15_268;

	mov.f64 	%fd1466, 0dFFF8000000000000;

$L__BB15_268:
	add.rn.f64 	%fd1208, %fd1463, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r395}, %fd1208;
	}
	and.b32  	%r396, %r395, 2146435072;
	setp.ne.s32 	%p252, %r396, 2146435072;
	@%p252 bra 	$L__BB15_275;

	setp.gtu.f64 	%p253, %fd385, 0d7FF0000000000000;
	@%p253 bra 	$L__BB15_274;
	bra.uni 	$L__BB15_270;

$L__BB15_274:
	mov.f64 	%fd1210, 0d4000000000000000;
	add.rn.f64 	%fd1466, %fd1463, %fd1210;
	bra.uni 	$L__BB15_275;

$L__BB15_270:
	setp.eq.s32 	%p254, %r45, 2146435072;
	mov.f64 	%fd1209, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r397, %temp}, %fd1209;
	}
	setp.eq.s32 	%p255, %r397, 0;
	and.pred  	%p256, %p254, %p255;
	@%p256 bra 	$L__BB15_273;
	bra.uni 	$L__BB15_271;

$L__BB15_273:
	setp.lt.s32 	%p262, %r31, 0;
	mov.u32 	%r402, 0;
	setp.gt.f64 	%p263, %fd385, 0d3FF0000000000000;
	selp.b32 	%r403, 2146435072, 0, %p263;
	xor.b32  	%r404, %r403, 2146435072;
	selp.b32 	%r405, %r404, %r403, %p262;
	setp.eq.f64 	%p264, %fd1463, 0dBFF0000000000000;
	selp.b32 	%r406, 1072693248, %r405, %p264;
	mov.b64 	%fd1466, {%r402, %r406};
	bra.uni 	$L__BB15_275;

$L__BB15_271:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r398, %temp}, %fd1463;
	}
	and.b32  	%r399, %r92, 2147483647;
	setp.ne.s32 	%p257, %r399, 2146435072;
	setp.ne.s32 	%p258, %r398, 0;
	or.pred  	%p259, %p257, %p258;
	@%p259 bra 	$L__BB15_275;

	setp.ne.s32 	%p260, %r45, 1071644672;
	and.pred  	%p261, %p260, %p7;
	selp.b32 	%r400, %r47, %r46, %p261;
	mov.u32 	%r401, 0;
	mov.b64 	%fd1466, {%r401, %r400};

$L__BB15_275:
	setp.eq.f64 	%p265, %fd1463, 0d3FF0000000000000;
	selp.f64 	%fd395, 0d3FF0000000000000, %fd1466, %p265;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r407}, %fd371;
	}
	and.b32  	%r408, %r407, 2147483647;
	setp.eq.s32 	%p266, %r408, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r409, %temp}, %fd371;
	}
	setp.eq.s32 	%p267, %r409, 0;
	and.pred  	%p268, %p267, %p266;
	@%p268 bra 	$L__BB15_279;
	bra.uni 	$L__BB15_276;

$L__BB15_279:
	mov.f64 	%fd1220, 0d0000000000000000;
	mul.rn.f64 	%fd1468, %fd371, %fd1220;
	mov.u32 	%r507, 1;
	bra.uni 	$L__BB15_280;

$L__BB15_276:
	mul.rn.f64 	%fd1211, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r506, %fd1211;
	st.local.u32 	[%rd1], %r506;
	cvt.rn.f64.s32 	%fd1212, %r506;
	neg.f64 	%fd1213, %fd1212;
	mov.f64 	%fd1214, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1215, %fd1213, %fd1214, %fd371;
	mov.f64 	%fd1216, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1217, %fd1213, %fd1216, %fd1215;
	mov.f64 	%fd1218, 0d397B839A252049C0;
	fma.rn.f64 	%fd1468, %fd1213, %fd1218, %fd1217;
	abs.f64 	%fd1219, %fd371;
	setp.ltu.f64 	%p269, %fd1219, 0d41E0000000000000;
	@%p269 bra 	$L__BB15_278;

	{ // callseq 212, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1468, [retval0+0];
	} // callseq 212
	ld.local.u32 	%r506, [%rd1];

$L__BB15_278:
	add.s32 	%r507, %r506, 1;

$L__BB15_280:
	and.b32  	%r411, %r507, 1;
	shl.b32 	%r412, %r507, 3;
	and.b32  	%r413, %r412, 8;
	setp.eq.s32 	%p270, %r411, 0;
	selp.f64 	%fd1221, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p270;
	mul.wide.s32 	%rd165, %r413, 8;
	add.s64 	%rd167, %rd66, %rd165;
	ld.global.nc.f64 	%fd1222, [%rd167+8];
	mul.rn.f64 	%fd401, %fd1468, %fd1468;
	fma.rn.f64 	%fd1223, %fd1221, %fd401, %fd1222;
	ld.global.nc.f64 	%fd1224, [%rd167+16];
	fma.rn.f64 	%fd1225, %fd1223, %fd401, %fd1224;
	ld.global.nc.f64 	%fd1226, [%rd167+24];
	fma.rn.f64 	%fd1227, %fd1225, %fd401, %fd1226;
	ld.global.nc.f64 	%fd1228, [%rd167+32];
	fma.rn.f64 	%fd1229, %fd1227, %fd401, %fd1228;
	ld.global.nc.f64 	%fd1230, [%rd167+40];
	fma.rn.f64 	%fd1231, %fd1229, %fd401, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd167+48];
	fma.rn.f64 	%fd402, %fd1231, %fd401, %fd1232;
	fma.rn.f64 	%fd1470, %fd402, %fd1468, %fd1468;
	@%p270 bra 	$L__BB15_282;

	mov.f64 	%fd1233, 0d3FF0000000000000;
	fma.rn.f64 	%fd1470, %fd402, %fd401, %fd1233;

$L__BB15_282:
	and.b32  	%r414, %r507, 2;
	setp.eq.s32 	%p271, %r414, 0;
	@%p271 bra 	$L__BB15_284;

	mov.f64 	%fd1234, 0d0000000000000000;
	mov.f64 	%fd1235, 0dBFF0000000000000;
	fma.rn.f64 	%fd1470, %fd1470, %fd1235, %fd1234;

$L__BB15_284:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r415}, %fd372;
	}
	and.b32  	%r416, %r415, 2147483647;
	setp.eq.s32 	%p272, %r416, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r417, %temp}, %fd372;
	}
	setp.eq.s32 	%p273, %r417, 0;
	and.pred  	%p274, %p273, %p272;
	@%p274 bra 	$L__BB15_288;
	bra.uni 	$L__BB15_285;

$L__BB15_288:
	mov.f64 	%fd1245, 0d0000000000000000;
	mul.rn.f64 	%fd1472, %fd372, %fd1245;
	mov.u32 	%r509, 1;
	bra.uni 	$L__BB15_289;

$L__BB15_285:
	mul.rn.f64 	%fd1236, %fd372, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r508, %fd1236;
	st.local.u32 	[%rd1], %r508;
	cvt.rn.f64.s32 	%fd1237, %r508;
	neg.f64 	%fd1238, %fd1237;
	mov.f64 	%fd1239, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1240, %fd1238, %fd1239, %fd372;
	mov.f64 	%fd1241, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1242, %fd1238, %fd1241, %fd1240;
	mov.f64 	%fd1243, 0d397B839A252049C0;
	fma.rn.f64 	%fd1472, %fd1238, %fd1243, %fd1242;
	abs.f64 	%fd1244, %fd372;
	setp.ltu.f64 	%p275, %fd1244, 0d41E0000000000000;
	@%p275 bra 	$L__BB15_287;

	{ // callseq 213, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd372;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1472, [retval0+0];
	} // callseq 213
	ld.local.u32 	%r508, [%rd1];

$L__BB15_287:
	add.s32 	%r509, %r508, 1;

$L__BB15_289:
	and.b32  	%r419, %r509, 1;
	shl.b32 	%r420, %r509, 3;
	and.b32  	%r421, %r420, 8;
	setp.eq.s32 	%p276, %r419, 0;
	selp.f64 	%fd1246, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p276;
	mul.wide.s32 	%rd169, %r421, 8;
	add.s64 	%rd171, %rd66, %rd169;
	ld.global.nc.f64 	%fd1247, [%rd171+8];
	mul.rn.f64 	%fd413, %fd1472, %fd1472;
	fma.rn.f64 	%fd1248, %fd1246, %fd413, %fd1247;
	ld.global.nc.f64 	%fd1249, [%rd171+16];
	fma.rn.f64 	%fd1250, %fd1248, %fd413, %fd1249;
	ld.global.nc.f64 	%fd1251, [%rd171+24];
	fma.rn.f64 	%fd1252, %fd1250, %fd413, %fd1251;
	ld.global.nc.f64 	%fd1253, [%rd171+32];
	fma.rn.f64 	%fd1254, %fd1252, %fd413, %fd1253;
	ld.global.nc.f64 	%fd1255, [%rd171+40];
	fma.rn.f64 	%fd1256, %fd1254, %fd413, %fd1255;
	ld.global.nc.f64 	%fd1257, [%rd171+48];
	fma.rn.f64 	%fd414, %fd1256, %fd413, %fd1257;
	fma.rn.f64 	%fd1474, %fd414, %fd1472, %fd1472;
	@%p276 bra 	$L__BB15_291;

	mov.f64 	%fd1258, 0d3FF0000000000000;
	fma.rn.f64 	%fd1474, %fd414, %fd413, %fd1258;

$L__BB15_291:
	and.b32  	%r422, %r509, 2;
	setp.eq.s32 	%p277, %r422, 0;
	@%p277 bra 	$L__BB15_293;

	mov.f64 	%fd1259, 0d0000000000000000;
	mov.f64 	%fd1260, 0dBFF0000000000000;
	fma.rn.f64 	%fd1474, %fd1474, %fd1260, %fd1259;

$L__BB15_293:
	mul.rn.f64 	%fd420, %fd1470, %fd1474;
	mul.rn.f64 	%fd1261, %fd1482, 0d400921FB54442D18;
	div.rn.f64 	%fd1262, %fd1261, 0d4066800000000000;
	mul.rn.f64 	%fd1263, %fd369, 0d400921FB54442D18;
	div.rn.f64 	%fd1264, %fd1263, 0d4066800000000000;
	sub.rn.f64 	%fd1265, %fd1264, %fd1262;
	mul.rn.f64 	%fd421, %fd1265, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r423, %temp}, %fd421;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r424}, %fd421;
	}
	and.b32  	%r425, %r424, 2147483647;
	setp.eq.s32 	%p278, %r425, 2146435072;
	setp.eq.s32 	%p279, %r423, 0;
	and.pred  	%p280, %p279, %p278;
	@%p280 bra 	$L__BB15_296;
	bra.uni 	$L__BB15_294;

$L__BB15_296:
	mov.f64 	%fd1275, 0d0000000000000000;
	mul.rn.f64 	%fd1475, %fd421, %fd1275;
	mov.u32 	%r510, 0;
	bra.uni 	$L__BB15_297;

$L__BB15_294:
	mul.rn.f64 	%fd1266, %fd421, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r510, %fd1266;
	st.local.u32 	[%rd1], %r510;
	cvt.rn.f64.s32 	%fd1267, %r510;
	neg.f64 	%fd1268, %fd1267;
	mov.f64 	%fd1269, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1270, %fd1268, %fd1269, %fd421;
	mov.f64 	%fd1271, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1272, %fd1268, %fd1271, %fd1270;
	mov.f64 	%fd1273, 0d397B839A252049C0;
	fma.rn.f64 	%fd1475, %fd1268, %fd1273, %fd1272;
	abs.f64 	%fd1274, %fd421;
	setp.ltu.f64 	%p281, %fd1274, 0d41E0000000000000;
	@%p281 bra 	$L__BB15_297;

	{ // callseq 214, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd421;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd34;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1475, [retval0+0];
	} // callseq 214
	ld.local.u32 	%r510, [%rd1];

$L__BB15_297:
	and.b32  	%r427, %r510, 1;
	shl.b32 	%r428, %r510, 3;
	and.b32  	%r429, %r428, 8;
	setp.eq.s32 	%p282, %r427, 0;
	selp.f64 	%fd1276, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p282;
	mul.wide.s32 	%rd173, %r429, 8;
	add.s64 	%rd175, %rd66, %rd173;
	ld.global.nc.f64 	%fd1277, [%rd175+8];
	mul.rn.f64 	%fd426, %fd1475, %fd1475;
	fma.rn.f64 	%fd1278, %fd1276, %fd426, %fd1277;
	ld.global.nc.f64 	%fd1279, [%rd175+16];
	fma.rn.f64 	%fd1280, %fd1278, %fd426, %fd1279;
	ld.global.nc.f64 	%fd1281, [%rd175+24];
	fma.rn.f64 	%fd1282, %fd1280, %fd426, %fd1281;
	ld.global.nc.f64 	%fd1283, [%rd175+32];
	fma.rn.f64 	%fd1284, %fd1282, %fd426, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd175+40];
	fma.rn.f64 	%fd1286, %fd1284, %fd426, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd175+48];
	fma.rn.f64 	%fd427, %fd1286, %fd426, %fd1287;
	fma.rn.f64 	%fd1477, %fd427, %fd1475, %fd1475;
	@%p282 bra 	$L__BB15_299;

	mov.f64 	%fd1288, 0d3FF0000000000000;
	fma.rn.f64 	%fd1477, %fd427, %fd426, %fd1288;

$L__BB15_299:
	and.b32  	%r430, %r510, 2;
	setp.eq.s32 	%p283, %r430, 0;
	@%p283 bra 	$L__BB15_301;

	mov.f64 	%fd1289, 0d0000000000000000;
	mov.f64 	%fd1290, 0dBFF0000000000000;
	fma.rn.f64 	%fd1477, %fd1477, %fd1290, %fd1289;

$L__BB15_301:
	abs.f64 	%fd433, %fd1477;
	{ // callseq 215, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd433;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1480, [retval0+0];
	} // callseq 215
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r106}, %fd1477;
	}
	setp.lt.s32 	%p284, %r106, 0;
	and.pred  	%p8, %p284, %p69;
	not.pred 	%p286, %p8;
	@%p286 bra 	$L__BB15_303;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r431}, %fd1480;
	}
	xor.b32  	%r432, %r431, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r433, %temp}, %fd1480;
	}
	mov.b64 	%fd1480, {%r433, %r432};

$L__BB15_303:
	setp.eq.f64 	%p287, %fd1477, 0d0000000000000000;
	@%p287 bra 	$L__BB15_307;
	bra.uni 	$L__BB15_304;

$L__BB15_307:
	setp.lt.s32 	%p290, %r31, 0;
	mov.u32 	%r434, 0;
	selp.b32 	%r435, %r106, 0, %p69;
	or.b32  	%r436, %r435, 2146435072;
	selp.b32 	%r437, %r436, %r435, %p290;
	mov.b64 	%fd1480, {%r434, %r437};
	bra.uni 	$L__BB15_308;

$L__BB15_304:
	setp.gt.s32 	%p288, %r106, -1;
	@%p288 bra 	$L__BB15_308;

	mov.f64 	%fd1291, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1292, %fd1291;
	setp.eq.f64 	%p289, %fd1292, 0d4000000000000000;
	@%p289 bra 	$L__BB15_308;

	mov.f64 	%fd1480, 0dFFF8000000000000;

$L__BB15_308:
	add.rn.f64 	%fd1294, %fd1477, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r438}, %fd1294;
	}
	and.b32  	%r439, %r438, 2146435072;
	setp.ne.s32 	%p292, %r439, 2146435072;
	@%p292 bra 	$L__BB15_315;

	setp.gtu.f64 	%p293, %fd433, 0d7FF0000000000000;
	@%p293 bra 	$L__BB15_314;
	bra.uni 	$L__BB15_310;

$L__BB15_314:
	mov.f64 	%fd1296, 0d4000000000000000;
	add.rn.f64 	%fd1480, %fd1477, %fd1296;
	bra.uni 	$L__BB15_315;

$L__BB15_310:
	setp.eq.s32 	%p294, %r45, 2146435072;
	mov.f64 	%fd1295, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r440, %temp}, %fd1295;
	}
	setp.eq.s32 	%p295, %r440, 0;
	and.pred  	%p296, %p294, %p295;
	@%p296 bra 	$L__BB15_313;
	bra.uni 	$L__BB15_311;

$L__BB15_313:
	setp.lt.s32 	%p302, %r31, 0;
	mov.u32 	%r445, 0;
	setp.gt.f64 	%p303, %fd433, 0d3FF0000000000000;
	selp.b32 	%r446, 2146435072, 0, %p303;
	xor.b32  	%r447, %r446, 2146435072;
	selp.b32 	%r448, %r447, %r446, %p302;
	setp.eq.f64 	%p304, %fd1477, 0dBFF0000000000000;
	selp.b32 	%r449, 1072693248, %r448, %p304;
	mov.b64 	%fd1480, {%r445, %r449};
	bra.uni 	$L__BB15_315;

$L__BB15_311:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r441, %temp}, %fd1477;
	}
	and.b32  	%r442, %r106, 2147483647;
	setp.ne.s32 	%p297, %r442, 2146435072;
	setp.ne.s32 	%p298, %r441, 0;
	or.pred  	%p299, %p297, %p298;
	@%p299 bra 	$L__BB15_315;

	setp.ne.s32 	%p300, %r45, 1071644672;
	and.pred  	%p301, %p300, %p8;
	selp.b32 	%r443, %r47, %r46, %p301;
	mov.u32 	%r444, 0;
	mov.b64 	%fd1480, {%r444, %r443};

$L__BB15_315:
	setp.eq.f64 	%p305, %fd1477, 0d3FF0000000000000;
	mov.f64 	%fd1297, 0d3FF0000000000000;
	selp.f64 	%fd1298, 0d3FF0000000000000, %fd1480, %p305;
	mul.rn.f64 	%fd1299, %fd420, %fd1298;
	add.rn.f64 	%fd1300, %fd395, %fd1299;
	sqrt.rn.f64 	%fd443, %fd1300;
	sub.rn.f64 	%fd1301, %fd1297, %fd1300;
	sqrt.rn.f64 	%fd444, %fd1301;
	abs.f64 	%fd445, %fd444;
	abs.f64 	%fd446, %fd443;
	setp.eq.f64 	%p306, %fd445, 0d0000000000000000;
	setp.eq.f64 	%p307, %fd446, 0d0000000000000000;
	and.pred  	%p308, %p306, %p307;
	@%p308 bra 	$L__BB15_319;
	bra.uni 	$L__BB15_316;

$L__BB15_319:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r462}, %fd444;
	}
	setp.lt.s32 	%p316, %r462, 0;
	selp.f64 	%fd1354, 0d400921FB54442D18, 0d0000000000000000, %p316;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r463, %temp}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r464}, %fd1354;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r465}, %fd443;
	}
	and.b32  	%r466, %r465, -2147483648;
	or.b32  	%r467, %r464, %r466;
	mov.b64 	%fd1481, {%r463, %r467};
	bra.uni 	$L__BB15_320;

$L__BB15_316:
	setp.eq.f64 	%p309, %fd445, 0d7FF0000000000000;
	setp.eq.f64 	%p310, %fd446, 0d7FF0000000000000;
	and.pred  	%p311, %p309, %p310;
	@%p311 bra 	$L__BB15_318;
	bra.uni 	$L__BB15_317;

$L__BB15_318:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r456}, %fd444;
	}
	setp.lt.s32 	%p315, %r456, 0;
	selp.f64 	%fd1353, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p315;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r457, %temp}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r458}, %fd1353;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r459}, %fd443;
	}
	and.b32  	%r460, %r459, -2147483648;
	or.b32  	%r461, %r458, %r460;
	mov.b64 	%fd1481, {%r457, %r461};
	bra.uni 	$L__BB15_320;

$L__BB15_317:
	max.f64 	%fd1302, %fd446, %fd445;
	min.f64 	%fd1303, %fd446, %fd445;
	div.rn.f64 	%fd1304, %fd1303, %fd1302;
	mul.rn.f64 	%fd1305, %fd1304, %fd1304;
	mov.f64 	%fd1306, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1307, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1308, %fd1307, %fd1305, %fd1306;
	mov.f64 	%fd1309, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1310, %fd1308, %fd1305, %fd1309;
	mov.f64 	%fd1311, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1312, %fd1310, %fd1305, %fd1311;
	mov.f64 	%fd1313, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1314, %fd1312, %fd1305, %fd1313;
	mov.f64 	%fd1315, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1316, %fd1314, %fd1305, %fd1315;
	mov.f64 	%fd1317, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1318, %fd1316, %fd1305, %fd1317;
	mov.f64 	%fd1319, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1320, %fd1318, %fd1305, %fd1319;
	mov.f64 	%fd1321, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1322, %fd1320, %fd1305, %fd1321;
	mov.f64 	%fd1323, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1324, %fd1322, %fd1305, %fd1323;
	mov.f64 	%fd1325, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1326, %fd1324, %fd1305, %fd1325;
	mov.f64 	%fd1327, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1328, %fd1326, %fd1305, %fd1327;
	mov.f64 	%fd1329, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1330, %fd1328, %fd1305, %fd1329;
	mov.f64 	%fd1331, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1332, %fd1330, %fd1305, %fd1331;
	mov.f64 	%fd1333, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1334, %fd1332, %fd1305, %fd1333;
	mov.f64 	%fd1335, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1336, %fd1334, %fd1305, %fd1335;
	mov.f64 	%fd1337, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1338, %fd1336, %fd1305, %fd1337;
	mov.f64 	%fd1339, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1340, %fd1338, %fd1305, %fd1339;
	mov.f64 	%fd1341, 0dBFD555555555544C;
	fma.rn.f64 	%fd1342, %fd1340, %fd1305, %fd1341;
	mul.rn.f64 	%fd1343, %fd1305, %fd1342;
	fma.rn.f64 	%fd1344, %fd1343, %fd1304, %fd1304;
	mov.f64 	%fd1345, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1346, %fd1345, %fd1344;
	setp.gt.f64 	%p312, %fd446, %fd445;
	selp.f64 	%fd1347, %fd1346, %fd1344, %p312;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r450}, %fd444;
	}
	setp.lt.s32 	%p313, %r450, 0;
	mov.f64 	%fd1348, 0d400921FB54442D18;
	sub.rn.f64 	%fd1349, %fd1348, %fd1347;
	selp.f64 	%fd1350, %fd1349, %fd1347, %p313;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r451, %temp}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r452}, %fd1350;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r453}, %fd443;
	}
	and.b32  	%r454, %r453, -2147483648;
	or.b32  	%r455, %r452, %r454;
	mov.b64 	%fd1351, {%r451, %r455};
	add.rn.f64 	%fd1352, %fd445, %fd446;
	setp.le.f64 	%p314, %fd1352, 0d7FF0000000000000;
	selp.f64 	%fd1481, %fd1351, %fd1352, %p314;

$L__BB15_320:
	add.rn.f64 	%fd1355, %fd1481, %fd1481;
	mul.rn.f64 	%fd1356, %fd1355, 0d415854A640000000;
	setp.lt.f64 	%p317, %fd1356, %fd453;
	@%p317 bra 	$L__BB15_323;

$L__BB15_322:
	ld.param.u32 	%r468, [gcj02_to_wgs84_exact_cuda_double_param_4];
	add.s32 	%r491, %r491, 1;
	setp.lt.s32 	%p320, %r491, %r468;
	mov.f64 	%fd1483, %fd370;
	mov.f64 	%fd1482, %fd369;
	@%p320 bra 	$L__BB15_127;

$L__BB15_323:
	ld.param.u64 	%rd183, [gcj02_to_wgs84_exact_cuda_double_param_1];
	mov.u32 	%r477, %tid.x;
	mov.u32 	%r476, %ntid.x;
	mov.u32 	%r475, %ctaid.x;
	mad.lo.s32 	%r474, %r475, %r476, %r477;
	mul.wide.s32 	%rd182, %r474, 8;
	cvta.to.global.u64 	%rd181, %rd183;
	add.s64 	%rd180, %rd181, %rd182;
	ld.param.u64 	%rd179, [gcj02_to_wgs84_exact_cuda_double_param_0];
	mov.u32 	%r472, %tid.x;
	mov.u32 	%r471, %ntid.x;
	mov.u32 	%r470, %ctaid.x;
	mad.lo.s32 	%r469, %r470, %r471, %r472;
	mul.wide.s32 	%rd178, %r469, 8;
	cvta.to.global.u64 	%rd177, %rd179;
	add.s64 	%rd176, %rd177, %rd178;
	st.global.f64 	[%rd176], %fd1482;
	st.global.f64 	[%rd180], %fd1483;
	ret;

}
	// .globl	bd09_to_wgs84_exact_cuda_double
.visible .entry bd09_to_wgs84_exact_cuda_double(
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_0,
	.param .u64 bd09_to_wgs84_exact_cuda_double_param_1,
	.param .f64 bd09_to_wgs84_exact_cuda_double_param_2,
	.param .u8 bd09_to_wgs84_exact_cuda_double_param_3,
	.param .u32 bd09_to_wgs84_exact_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot16[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<479>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<721>;
	.reg .f64 	%fd<2013>;
	.reg .b64 	%rd<232>;


	mov.u64 	%SPL, __local_depot16;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd39, [bd09_to_wgs84_exact_cuda_double_param_0];
	ld.param.u64 	%rd40, [bd09_to_wgs84_exact_cuda_double_param_1];
	ld.param.f64 	%fd610, [bd09_to_wgs84_exact_cuda_double_param_2];
	ld.param.u32 	%r146, [bd09_to_wgs84_exact_cuda_double_param_4];
	cvta.to.global.u64 	%rd41, %rd40;
	add.u64 	%rd42, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r147, %ntid.x;
	mov.u32 	%r148, %ctaid.x;
	mov.u32 	%r149, %tid.x;
	mad.lo.s32 	%r150, %r148, %r147, %r149;
	cvta.to.global.u64 	%rd78, %rd39;
	mul.wide.s32 	%rd79, %r150, 8;
	add.s64 	%rd37, %rd78, %rd79;
	add.s64 	%rd38, %rd41, %rd79;
	ld.global.f64 	%fd1, [%rd37];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd38];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd611, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd611;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p15, %r3, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 216, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1862, [retval0+0];
	} // callseq 216
	setp.lt.s32 	%p16, %r1, 0;
	and.pred  	%p1, %p16, %p15;
	not.pred 	%p17, %p1;
	@%p17 bra 	$L__BB16_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r151}, %fd1862;
	}
	xor.b32  	%r152, %r151, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r153, %temp}, %fd1862;
	}
	mov.b64 	%fd1862, {%r153, %r152};

$L__BB16_2:
	setp.eq.f64 	%p18, %fd2, 0d0000000000000000;
	@%p18 bra 	$L__BB16_6;
	bra.uni 	$L__BB16_3;

$L__BB16_6:
	selp.b32 	%r154, %r1, 0, %p15;
	mov.u32 	%r155, 0;
	or.b32  	%r156, %r154, 2146435072;
	setp.lt.s32 	%p22, %r2, 0;
	selp.b32 	%r157, %r156, %r154, %p22;
	mov.b64 	%fd1862, {%r155, %r157};
	bra.uni 	$L__BB16_7;

$L__BB16_3:
	setp.gt.s32 	%p19, %r1, -1;
	@%p19 bra 	$L__BB16_7;

	mov.f64 	%fd612, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd613, %fd612;
	setp.eq.f64 	%p20, %fd613, 0d4000000000000000;
	@%p20 bra 	$L__BB16_7;

	mov.f64 	%fd1862, 0dFFF8000000000000;

$L__BB16_7:
	add.rn.f64 	%fd615, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r158}, %fd615;
	}
	and.b32  	%r159, %r158, 2146435072;
	setp.ne.s32 	%p23, %r159, 2146435072;
	@%p23 bra 	$L__BB16_14;

	setp.gtu.f64 	%p24, %fd5, 0d7FF0000000000000;
	@%p24 bra 	$L__BB16_13;
	bra.uni 	$L__BB16_9;

$L__BB16_13:
	mov.f64 	%fd617, 0d4000000000000000;
	add.rn.f64 	%fd1862, %fd2, %fd617;
	bra.uni 	$L__BB16_14;

$L__BB16_9:
	mov.f64 	%fd616, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r160, %temp}, %fd616;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p25, %r4, 2146435072;
	setp.eq.s32 	%p26, %r160, 0;
	and.pred  	%p27, %p25, %p26;
	@%p27 bra 	$L__BB16_12;
	bra.uni 	$L__BB16_10;

$L__BB16_12:
	setp.gt.f64 	%p34, %fd5, 0d3FF0000000000000;
	selp.b32 	%r167, 2146435072, 0, %p34;
	mov.u32 	%r168, 0;
	xor.b32  	%r169, %r167, 2146435072;
	setp.lt.s32 	%p35, %r2, 0;
	selp.b32 	%r170, %r169, %r167, %p35;
	setp.eq.f64 	%p36, %fd2, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p36;
	mov.b64 	%fd1862, {%r168, %r171};
	bra.uni 	$L__BB16_14;

$L__BB16_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r161, %temp}, %fd2;
	}
	and.b32  	%r162, %r1, 2147483647;
	setp.ne.s32 	%p28, %r162, 2146435072;
	setp.ne.s32 	%p29, %r161, 0;
	or.pred  	%p30, %p28, %p29;
	@%p30 bra 	$L__BB16_14;

	setp.gt.s32 	%p31, %r2, -1;
	selp.b32 	%r163, 2146435072, 0, %p31;
	mov.u32 	%r164, 0;
	setp.ne.s32 	%p32, %r4, 1071644672;
	and.pred  	%p33, %p32, %p1;
	or.b32  	%r165, %r163, -2147483648;
	selp.b32 	%r166, %r165, %r163, %p33;
	mov.b64 	%fd1862, {%r164, %r166};

$L__BB16_14:
	abs.f64 	%fd15, %fd4;
	{ // callseq 217, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1865, [retval0+0];
	} // callseq 217
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd4;
	}
	setp.lt.s32 	%p37, %r5, 0;
	and.pred  	%p2, %p37, %p15;
	not.pred 	%p39, %p2;
	@%p39 bra 	$L__BB16_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd1865;
	}
	xor.b32  	%r173, %r172, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r174, %temp}, %fd1865;
	}
	mov.b64 	%fd1865, {%r174, %r173};

$L__BB16_16:
	setp.eq.f64 	%p40, %fd4, 0d0000000000000000;
	@%p40 bra 	$L__BB16_20;
	bra.uni 	$L__BB16_17;

$L__BB16_20:
	selp.b32 	%r175, %r5, 0, %p15;
	mov.u32 	%r176, 0;
	or.b32  	%r177, %r175, 2146435072;
	setp.lt.s32 	%p44, %r2, 0;
	selp.b32 	%r178, %r177, %r175, %p44;
	mov.b64 	%fd1865, {%r176, %r178};
	bra.uni 	$L__BB16_21;

$L__BB16_17:
	setp.gt.s32 	%p41, %r5, -1;
	@%p41 bra 	$L__BB16_21;

	mov.f64 	%fd618, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd619, %fd618;
	setp.eq.f64 	%p42, %fd619, 0d4000000000000000;
	@%p42 bra 	$L__BB16_21;

	mov.f64 	%fd1865, 0dFFF8000000000000;

$L__BB16_21:
	add.rn.f64 	%fd621, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd621;
	}
	and.b32  	%r180, %r179, 2146435072;
	setp.ne.s32 	%p45, %r180, 2146435072;
	@%p45 bra 	$L__BB16_28;

	setp.gtu.f64 	%p46, %fd15, 0d7FF0000000000000;
	@%p46 bra 	$L__BB16_27;
	bra.uni 	$L__BB16_23;

$L__BB16_27:
	mov.f64 	%fd623, 0d4000000000000000;
	add.rn.f64 	%fd1865, %fd4, %fd623;
	bra.uni 	$L__BB16_28;

$L__BB16_23:
	mov.f64 	%fd622, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %fd622;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p47, %r6, 2146435072;
	setp.eq.s32 	%p48, %r181, 0;
	and.pred  	%p49, %p47, %p48;
	@%p49 bra 	$L__BB16_26;
	bra.uni 	$L__BB16_24;

$L__BB16_26:
	setp.gt.f64 	%p56, %fd15, 0d3FF0000000000000;
	selp.b32 	%r188, 2146435072, 0, %p56;
	mov.u32 	%r189, 0;
	xor.b32  	%r190, %r188, 2146435072;
	setp.lt.s32 	%p57, %r2, 0;
	selp.b32 	%r191, %r190, %r188, %p57;
	setp.eq.f64 	%p58, %fd4, 0dBFF0000000000000;
	selp.b32 	%r192, 1072693248, %r191, %p58;
	mov.b64 	%fd1865, {%r189, %r192};
	bra.uni 	$L__BB16_28;

$L__BB16_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd4;
	}
	and.b32  	%r183, %r5, 2147483647;
	setp.ne.s32 	%p50, %r183, 2146435072;
	setp.ne.s32 	%p51, %r182, 0;
	or.pred  	%p52, %p50, %p51;
	@%p52 bra 	$L__BB16_28;

	setp.gt.s32 	%p53, %r2, -1;
	selp.b32 	%r184, 2146435072, 0, %p53;
	mov.u32 	%r185, 0;
	setp.ne.s32 	%p54, %r6, 1071644672;
	and.pred  	%p55, %p54, %p2;
	or.b32  	%r186, %r184, -2147483648;
	selp.b32 	%r187, %r186, %r184, %p55;
	mov.b64 	%fd1865, {%r185, %r187};

$L__BB16_28:
	setp.eq.f64 	%p59, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd624, 0d3FF0000000000000, %fd1865, %p59;
	setp.eq.f64 	%p60, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd625, 0d3FF0000000000000, %fd1862, %p60;
	add.rn.f64 	%fd25, %fd625, %fd624;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r193, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r194}, %fd26;
	}
	and.b32  	%r195, %r194, 2147483647;
	setp.eq.s32 	%p61, %r195, 2146435072;
	setp.eq.s32 	%p62, %r193, 0;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB16_31;
	bra.uni 	$L__BB16_29;

$L__BB16_31:
	mov.f64 	%fd635, 0d0000000000000000;
	mul.rn.f64 	%fd1866, %fd26, %fd635;
	mov.u32 	%r676, 0;
	bra.uni 	$L__BB16_32;

$L__BB16_29:
	mul.rn.f64 	%fd626, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r676, %fd626;
	st.local.u32 	[%rd1], %r676;
	cvt.rn.f64.s32 	%fd627, %r676;
	neg.f64 	%fd628, %fd627;
	mov.f64 	%fd629, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd630, %fd628, %fd629, %fd26;
	mov.f64 	%fd631, 0d3C91A62633145C00;
	fma.rn.f64 	%fd632, %fd628, %fd631, %fd630;
	mov.f64 	%fd633, 0d397B839A252049C0;
	fma.rn.f64 	%fd1866, %fd628, %fd633, %fd632;
	abs.f64 	%fd634, %fd26;
	setp.ltu.f64 	%p64, %fd634, 0d41E0000000000000;
	@%p64 bra 	$L__BB16_32;

	{ // callseq 218, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1866, [retval0+0];
	} // callseq 218
	ld.local.u32 	%r676, [%rd1];

$L__BB16_32:
	and.b32  	%r197, %r676, 1;
	shl.b32 	%r198, %r676, 3;
	and.b32  	%r199, %r198, 8;
	setp.eq.s32 	%p65, %r197, 0;
	selp.f64 	%fd636, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p65;
	mul.wide.s32 	%rd81, %r199, 8;
	mov.u64 	%rd82, __cudart_sin_cos_coeffs;
	add.s64 	%rd83, %rd82, %rd81;
	ld.global.nc.f64 	%fd637, [%rd83+8];
	mul.rn.f64 	%fd31, %fd1866, %fd1866;
	fma.rn.f64 	%fd638, %fd636, %fd31, %fd637;
	ld.global.nc.f64 	%fd639, [%rd83+16];
	fma.rn.f64 	%fd640, %fd638, %fd31, %fd639;
	ld.global.nc.f64 	%fd641, [%rd83+24];
	fma.rn.f64 	%fd642, %fd640, %fd31, %fd641;
	ld.global.nc.f64 	%fd643, [%rd83+32];
	fma.rn.f64 	%fd644, %fd642, %fd31, %fd643;
	ld.global.nc.f64 	%fd645, [%rd83+40];
	fma.rn.f64 	%fd646, %fd644, %fd31, %fd645;
	ld.global.nc.f64 	%fd647, [%rd83+48];
	fma.rn.f64 	%fd32, %fd646, %fd31, %fd647;
	fma.rn.f64 	%fd1868, %fd32, %fd1866, %fd1866;
	@%p65 bra 	$L__BB16_34;

	mov.f64 	%fd648, 0d3FF0000000000000;
	fma.rn.f64 	%fd1868, %fd32, %fd31, %fd648;

$L__BB16_34:
	and.b32  	%r200, %r676, 2;
	setp.eq.s32 	%p66, %r200, 0;
	@%p66 bra 	$L__BB16_36;

	mov.f64 	%fd649, 0d0000000000000000;
	mov.f64 	%fd650, 0dBFF0000000000000;
	fma.rn.f64 	%fd1868, %fd1868, %fd650, %fd649;

$L__BB16_36:
	mul.rn.f64 	%fd651, %fd1868, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd652, %fd25;
	add.rn.f64 	%fd38, %fd652, %fd651;
	setp.eq.f64 	%p67, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p68, %fd5, 0d0000000000000000;
	and.pred  	%p69, %p68, %p67;
	@%p69 bra 	$L__BB16_40;
	bra.uni 	$L__BB16_37;

$L__BB16_40:
	selp.f64 	%fd705, 0d400921FB54442D18, 0d0000000000000000, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r209, %temp}, %fd705;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r210}, %fd705;
	}
	and.b32  	%r211, %r5, -2147483648;
	or.b32  	%r212, %r210, %r211;
	mov.b64 	%fd1869, {%r209, %r212};
	bra.uni 	$L__BB16_41;

$L__BB16_37:
	setp.eq.f64 	%p70, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p71, %fd15, 0d7FF0000000000000;
	and.pred  	%p72, %p70, %p71;
	@%p72 bra 	$L__BB16_39;
	bra.uni 	$L__BB16_38;

$L__BB16_39:
	selp.f64 	%fd704, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r205, %temp}, %fd704;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r206}, %fd704;
	}
	and.b32  	%r207, %r5, -2147483648;
	or.b32  	%r208, %r206, %r207;
	mov.b64 	%fd1869, {%r205, %r208};
	bra.uni 	$L__BB16_41;

$L__BB16_38:
	min.f64 	%fd653, %fd15, %fd5;
	max.f64 	%fd654, %fd15, %fd5;
	div.rn.f64 	%fd655, %fd653, %fd654;
	mul.rn.f64 	%fd656, %fd655, %fd655;
	mov.f64 	%fd657, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd658, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd659, %fd658, %fd656, %fd657;
	mov.f64 	%fd660, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd661, %fd659, %fd656, %fd660;
	mov.f64 	%fd662, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd663, %fd661, %fd656, %fd662;
	mov.f64 	%fd664, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd665, %fd663, %fd656, %fd664;
	mov.f64 	%fd666, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd667, %fd665, %fd656, %fd666;
	mov.f64 	%fd668, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd669, %fd667, %fd656, %fd668;
	mov.f64 	%fd670, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd671, %fd669, %fd656, %fd670;
	mov.f64 	%fd672, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd673, %fd671, %fd656, %fd672;
	mov.f64 	%fd674, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd675, %fd673, %fd656, %fd674;
	mov.f64 	%fd676, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd677, %fd675, %fd656, %fd676;
	mov.f64 	%fd678, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd679, %fd677, %fd656, %fd678;
	mov.f64 	%fd680, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd681, %fd679, %fd656, %fd680;
	mov.f64 	%fd682, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd683, %fd681, %fd656, %fd682;
	mov.f64 	%fd684, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd685, %fd683, %fd656, %fd684;
	mov.f64 	%fd686, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd687, %fd685, %fd656, %fd686;
	mov.f64 	%fd688, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd689, %fd687, %fd656, %fd688;
	mov.f64 	%fd690, 0d3FC99999999840D2;
	fma.rn.f64 	%fd691, %fd689, %fd656, %fd690;
	mov.f64 	%fd692, 0dBFD555555555544C;
	fma.rn.f64 	%fd693, %fd691, %fd656, %fd692;
	mul.rn.f64 	%fd694, %fd656, %fd693;
	fma.rn.f64 	%fd695, %fd694, %fd655, %fd655;
	mov.f64 	%fd696, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd697, %fd696, %fd695;
	setp.gt.f64 	%p74, %fd15, %fd5;
	selp.f64 	%fd698, %fd697, %fd695, %p74;
	mov.f64 	%fd699, 0d400921FB54442D18;
	sub.rn.f64 	%fd700, %fd699, %fd698;
	selp.f64 	%fd701, %fd700, %fd698, %p16;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r201, %temp}, %fd701;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r202}, %fd701;
	}
	and.b32  	%r203, %r5, -2147483648;
	or.b32  	%r204, %r202, %r203;
	mov.b64 	%fd702, {%r201, %r204};
	add.rn.f64 	%fd703, %fd5, %fd15;
	setp.le.f64 	%p75, %fd703, 0d7FF0000000000000;
	selp.f64 	%fd1869, %fd702, %fd703, %p75;

$L__BB16_41:
	add.rn.f64 	%fd1859, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd1859, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r213, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r214}, %fd43;
	}
	and.b32  	%r215, %r214, 2147483647;
	setp.eq.s32 	%p78, %r215, 2146435072;
	setp.eq.s32 	%p79, %r213, 0;
	and.pred  	%p80, %p79, %p78;
	@%p80 bra 	$L__BB16_45;
	bra.uni 	$L__BB16_42;

$L__BB16_45:
	mov.f64 	%fd715, 0d0000000000000000;
	mul.rn.f64 	%fd1871, %fd43, %fd715;
	mov.u32 	%r678, 1;
	bra.uni 	$L__BB16_46;

$L__BB16_42:
	mul.rn.f64 	%fd706, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r677, %fd706;
	st.local.u32 	[%rd1], %r677;
	cvt.rn.f64.s32 	%fd707, %r677;
	neg.f64 	%fd708, %fd707;
	mov.f64 	%fd709, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd710, %fd708, %fd709, %fd43;
	mov.f64 	%fd711, 0d3C91A62633145C00;
	fma.rn.f64 	%fd712, %fd708, %fd711, %fd710;
	mov.f64 	%fd713, 0d397B839A252049C0;
	fma.rn.f64 	%fd1871, %fd708, %fd713, %fd712;
	abs.f64 	%fd714, %fd43;
	setp.ltu.f64 	%p81, %fd714, 0d41E0000000000000;
	@%p81 bra 	$L__BB16_44;

	{ // callseq 219, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1871, [retval0+0];
	} // callseq 219
	ld.local.u32 	%r677, [%rd1];

$L__BB16_44:
	add.s32 	%r678, %r677, 1;

$L__BB16_46:
	and.b32  	%r217, %r678, 1;
	shl.b32 	%r218, %r678, 3;
	and.b32  	%r219, %r218, 8;
	setp.eq.s32 	%p82, %r217, 0;
	selp.f64 	%fd716, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p82;
	mul.wide.s32 	%rd85, %r219, 8;
	add.s64 	%rd87, %rd82, %rd85;
	ld.global.nc.f64 	%fd717, [%rd87+8];
	mul.rn.f64 	%fd49, %fd1871, %fd1871;
	fma.rn.f64 	%fd718, %fd716, %fd49, %fd717;
	ld.global.nc.f64 	%fd719, [%rd87+16];
	fma.rn.f64 	%fd720, %fd718, %fd49, %fd719;
	ld.global.nc.f64 	%fd721, [%rd87+24];
	fma.rn.f64 	%fd722, %fd720, %fd49, %fd721;
	ld.global.nc.f64 	%fd723, [%rd87+32];
	fma.rn.f64 	%fd724, %fd722, %fd49, %fd723;
	ld.global.nc.f64 	%fd725, [%rd87+40];
	fma.rn.f64 	%fd726, %fd724, %fd49, %fd725;
	ld.global.nc.f64 	%fd727, [%rd87+48];
	fma.rn.f64 	%fd50, %fd726, %fd49, %fd727;
	fma.rn.f64 	%fd1873, %fd50, %fd1871, %fd1871;
	@%p82 bra 	$L__BB16_48;

	mov.f64 	%fd728, 0d3FF0000000000000;
	fma.rn.f64 	%fd1873, %fd50, %fd49, %fd728;

$L__BB16_48:
	and.b32  	%r220, %r678, 2;
	setp.eq.s32 	%p83, %r220, 0;
	@%p83 bra 	$L__BB16_50;

	mov.f64 	%fd729, 0d0000000000000000;
	mov.f64 	%fd730, 0dBFF0000000000000;
	fma.rn.f64 	%fd1873, %fd1873, %fd730, %fd729;

$L__BB16_50:
	mul.rn.f64 	%fd731, %fd1873, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd1869, %fd731;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r221, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r222}, %fd56;
	}
	and.b32  	%r223, %r222, 2147483647;
	setp.eq.s32 	%p84, %r223, 2146435072;
	setp.eq.s32 	%p85, %r221, 0;
	and.pred  	%p3, %p85, %p84;
	@%p3 bra 	$L__BB16_54;
	bra.uni 	$L__BB16_51;

$L__BB16_54:
	mov.f64 	%fd741, 0d0000000000000000;
	mul.rn.f64 	%fd1875, %fd56, %fd741;
	mov.u32 	%r680, 1;
	bra.uni 	$L__BB16_55;

$L__BB16_51:
	mul.rn.f64 	%fd732, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r679, %fd732;
	st.local.u32 	[%rd1], %r679;
	cvt.rn.f64.s32 	%fd733, %r679;
	neg.f64 	%fd734, %fd733;
	mov.f64 	%fd735, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd736, %fd734, %fd735, %fd56;
	mov.f64 	%fd737, 0d3C91A62633145C00;
	fma.rn.f64 	%fd738, %fd734, %fd737, %fd736;
	mov.f64 	%fd739, 0d397B839A252049C0;
	fma.rn.f64 	%fd1875, %fd734, %fd739, %fd738;
	abs.f64 	%fd740, %fd56;
	setp.ltu.f64 	%p86, %fd740, 0d41E0000000000000;
	@%p86 bra 	$L__BB16_53;

	{ // callseq 220, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1875, [retval0+0];
	} // callseq 220
	ld.local.u32 	%r679, [%rd1];

$L__BB16_53:
	add.s32 	%r680, %r679, 1;

$L__BB16_55:
	and.b32  	%r225, %r680, 1;
	shl.b32 	%r226, %r680, 3;
	and.b32  	%r227, %r226, 8;
	setp.eq.s32 	%p87, %r225, 0;
	selp.f64 	%fd742, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p87;
	mul.wide.s32 	%rd89, %r227, 8;
	add.s64 	%rd91, %rd82, %rd89;
	ld.global.nc.f64 	%fd743, [%rd91+8];
	mul.rn.f64 	%fd62, %fd1875, %fd1875;
	fma.rn.f64 	%fd744, %fd742, %fd62, %fd743;
	ld.global.nc.f64 	%fd745, [%rd91+16];
	fma.rn.f64 	%fd746, %fd744, %fd62, %fd745;
	ld.global.nc.f64 	%fd747, [%rd91+24];
	fma.rn.f64 	%fd748, %fd746, %fd62, %fd747;
	ld.global.nc.f64 	%fd749, [%rd91+32];
	fma.rn.f64 	%fd750, %fd748, %fd62, %fd749;
	ld.global.nc.f64 	%fd751, [%rd91+40];
	fma.rn.f64 	%fd752, %fd750, %fd62, %fd751;
	ld.global.nc.f64 	%fd753, [%rd91+48];
	fma.rn.f64 	%fd63, %fd752, %fd62, %fd753;
	fma.rn.f64 	%fd1877, %fd63, %fd1875, %fd1875;
	@%p87 bra 	$L__BB16_57;

	mov.f64 	%fd754, 0d3FF0000000000000;
	fma.rn.f64 	%fd1877, %fd63, %fd62, %fd754;

$L__BB16_57:
	and.b32  	%r228, %r680, 2;
	setp.eq.s32 	%p88, %r228, 0;
	@%p88 bra 	$L__BB16_59;

	mov.f64 	%fd755, 0d0000000000000000;
	mov.f64 	%fd756, 0dBFF0000000000000;
	fma.rn.f64 	%fd1877, %fd1877, %fd756, %fd755;

$L__BB16_59:
	mul.rn.f64 	%fd69, %fd38, %fd1877;
	@%p3 bra 	$L__BB16_62;
	bra.uni 	$L__BB16_60;

$L__BB16_62:
	mov.f64 	%fd766, 0d0000000000000000;
	mul.rn.f64 	%fd1878, %fd56, %fd766;
	mov.u32 	%r681, 0;
	bra.uni 	$L__BB16_63;

$L__BB16_60:
	mul.rn.f64 	%fd757, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r681, %fd757;
	st.local.u32 	[%rd1], %r681;
	cvt.rn.f64.s32 	%fd758, %r681;
	neg.f64 	%fd759, %fd758;
	mov.f64 	%fd760, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd761, %fd759, %fd760, %fd56;
	mov.f64 	%fd762, 0d3C91A62633145C00;
	fma.rn.f64 	%fd763, %fd759, %fd762, %fd761;
	mov.f64 	%fd764, 0d397B839A252049C0;
	fma.rn.f64 	%fd1878, %fd759, %fd764, %fd763;
	abs.f64 	%fd765, %fd56;
	setp.ltu.f64 	%p89, %fd765, 0d41E0000000000000;
	@%p89 bra 	$L__BB16_63;

	{ // callseq 221, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1878, [retval0+0];
	} // callseq 221
	ld.local.u32 	%r681, [%rd1];

$L__BB16_63:
	and.b32  	%r230, %r681, 1;
	shl.b32 	%r231, %r681, 3;
	and.b32  	%r232, %r231, 8;
	setp.eq.s32 	%p90, %r230, 0;
	selp.f64 	%fd767, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p90;
	mul.wide.s32 	%rd93, %r232, 8;
	add.s64 	%rd95, %rd82, %rd93;
	ld.global.nc.f64 	%fd768, [%rd95+8];
	mul.rn.f64 	%fd74, %fd1878, %fd1878;
	fma.rn.f64 	%fd769, %fd767, %fd74, %fd768;
	ld.global.nc.f64 	%fd770, [%rd95+16];
	fma.rn.f64 	%fd771, %fd769, %fd74, %fd770;
	ld.global.nc.f64 	%fd772, [%rd95+24];
	fma.rn.f64 	%fd773, %fd771, %fd74, %fd772;
	ld.global.nc.f64 	%fd774, [%rd95+32];
	fma.rn.f64 	%fd775, %fd773, %fd74, %fd774;
	ld.global.nc.f64 	%fd776, [%rd95+40];
	fma.rn.f64 	%fd777, %fd775, %fd74, %fd776;
	ld.global.nc.f64 	%fd778, [%rd95+48];
	fma.rn.f64 	%fd75, %fd777, %fd74, %fd778;
	fma.rn.f64 	%fd1880, %fd75, %fd1878, %fd1878;
	@%p90 bra 	$L__BB16_65;

	mov.f64 	%fd779, 0d3FF0000000000000;
	fma.rn.f64 	%fd1880, %fd75, %fd74, %fd779;

$L__BB16_65:
	and.b32  	%r233, %r681, 2;
	setp.eq.s32 	%p91, %r233, 0;
	@%p91 bra 	$L__BB16_67;

	mov.f64 	%fd780, 0d0000000000000000;
	mov.f64 	%fd781, 0dBFF0000000000000;
	fma.rn.f64 	%fd1880, %fd1880, %fd781, %fd780;

$L__BB16_67:
	mul.rn.f64 	%fd81, %fd38, %fd1880;
	add.rn.f64 	%fd82, %fd81, 0dC041800000000000;
	add.rn.f64 	%fd83, %fd69, 0dC05A400000000000;
	abs.f64 	%fd84, %fd83;
	sqrt.rn.f64 	%fd85, %fd84;
	mul.rn.f64 	%fd86, %fd83, 0d400921FB54442D18;
	mul.rn.f64 	%fd87, %fd82, 0d400921FB54442D18;
	mul.rn.f64 	%fd88, %fd86, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r234, %temp}, %fd88;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r235}, %fd88;
	}
	and.b32  	%r236, %r235, 2147483647;
	setp.eq.s32 	%p92, %r236, 2146435072;
	setp.eq.s32 	%p93, %r234, 0;
	and.pred  	%p94, %p93, %p92;
	@%p94 bra 	$L__BB16_70;
	bra.uni 	$L__BB16_68;

$L__BB16_70:
	mov.f64 	%fd791, 0d0000000000000000;
	mul.rn.f64 	%fd1881, %fd88, %fd791;
	mov.u32 	%r682, 0;
	bra.uni 	$L__BB16_71;

$L__BB16_68:
	mul.rn.f64 	%fd782, %fd88, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r682, %fd782;
	st.local.u32 	[%rd1], %r682;
	cvt.rn.f64.s32 	%fd783, %r682;
	neg.f64 	%fd784, %fd783;
	mov.f64 	%fd785, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd786, %fd784, %fd785, %fd88;
	mov.f64 	%fd787, 0d3C91A62633145C00;
	fma.rn.f64 	%fd788, %fd784, %fd787, %fd786;
	mov.f64 	%fd789, 0d397B839A252049C0;
	fma.rn.f64 	%fd1881, %fd784, %fd789, %fd788;
	abs.f64 	%fd790, %fd88;
	setp.ltu.f64 	%p95, %fd790, 0d41E0000000000000;
	@%p95 bra 	$L__BB16_71;

	{ // callseq 222, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd88;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1881, [retval0+0];
	} // callseq 222
	ld.local.u32 	%r682, [%rd1];

$L__BB16_71:
	and.b32  	%r238, %r682, 1;
	shl.b32 	%r239, %r682, 3;
	and.b32  	%r240, %r239, 8;
	setp.eq.s32 	%p96, %r238, 0;
	selp.f64 	%fd792, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p96;
	mul.wide.s32 	%rd97, %r240, 8;
	add.s64 	%rd99, %rd82, %rd97;
	ld.global.nc.f64 	%fd793, [%rd99+8];
	mul.rn.f64 	%fd93, %fd1881, %fd1881;
	fma.rn.f64 	%fd794, %fd792, %fd93, %fd793;
	ld.global.nc.f64 	%fd795, [%rd99+16];
	fma.rn.f64 	%fd796, %fd794, %fd93, %fd795;
	ld.global.nc.f64 	%fd797, [%rd99+24];
	fma.rn.f64 	%fd798, %fd796, %fd93, %fd797;
	ld.global.nc.f64 	%fd799, [%rd99+32];
	fma.rn.f64 	%fd800, %fd798, %fd93, %fd799;
	ld.global.nc.f64 	%fd801, [%rd99+40];
	fma.rn.f64 	%fd802, %fd800, %fd93, %fd801;
	ld.global.nc.f64 	%fd803, [%rd99+48];
	fma.rn.f64 	%fd94, %fd802, %fd93, %fd803;
	fma.rn.f64 	%fd1883, %fd94, %fd1881, %fd1881;
	@%p96 bra 	$L__BB16_73;

	mov.f64 	%fd804, 0d3FF0000000000000;
	fma.rn.f64 	%fd1883, %fd94, %fd93, %fd804;

$L__BB16_73:
	and.b32  	%r241, %r682, 2;
	setp.eq.s32 	%p97, %r241, 0;
	@%p97 bra 	$L__BB16_75;

	mov.f64 	%fd805, 0d0000000000000000;
	mov.f64 	%fd806, 0dBFF0000000000000;
	fma.rn.f64 	%fd1883, %fd1883, %fd806, %fd805;

$L__BB16_75:
	add.rn.f64 	%fd100, %fd86, %fd86;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd100;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r243}, %fd100;
	}
	and.b32  	%r244, %r243, 2147483647;
	setp.eq.s32 	%p98, %r244, 2146435072;
	setp.eq.s32 	%p99, %r242, 0;
	and.pred  	%p100, %p99, %p98;
	@%p100 bra 	$L__BB16_78;
	bra.uni 	$L__BB16_76;

$L__BB16_78:
	mov.f64 	%fd816, 0d0000000000000000;
	mul.rn.f64 	%fd1884, %fd100, %fd816;
	mov.u32 	%r683, 0;
	bra.uni 	$L__BB16_79;

$L__BB16_76:
	mul.rn.f64 	%fd807, %fd100, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r683, %fd807;
	st.local.u32 	[%rd1], %r683;
	cvt.rn.f64.s32 	%fd808, %r683;
	neg.f64 	%fd809, %fd808;
	mov.f64 	%fd810, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd811, %fd809, %fd810, %fd100;
	mov.f64 	%fd812, 0d3C91A62633145C00;
	fma.rn.f64 	%fd813, %fd809, %fd812, %fd811;
	mov.f64 	%fd814, 0d397B839A252049C0;
	fma.rn.f64 	%fd1884, %fd809, %fd814, %fd813;
	abs.f64 	%fd815, %fd100;
	setp.ltu.f64 	%p101, %fd815, 0d41E0000000000000;
	@%p101 bra 	$L__BB16_79;

	{ // callseq 223, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd100;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1884, [retval0+0];
	} // callseq 223
	ld.local.u32 	%r683, [%rd1];

$L__BB16_79:
	and.b32  	%r246, %r683, 1;
	shl.b32 	%r247, %r683, 3;
	and.b32  	%r248, %r247, 8;
	setp.eq.s32 	%p102, %r246, 0;
	selp.f64 	%fd817, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p102;
	mul.wide.s32 	%rd101, %r248, 8;
	add.s64 	%rd103, %rd82, %rd101;
	ld.global.nc.f64 	%fd818, [%rd103+8];
	mul.rn.f64 	%fd105, %fd1884, %fd1884;
	fma.rn.f64 	%fd819, %fd817, %fd105, %fd818;
	ld.global.nc.f64 	%fd820, [%rd103+16];
	fma.rn.f64 	%fd821, %fd819, %fd105, %fd820;
	ld.global.nc.f64 	%fd822, [%rd103+24];
	fma.rn.f64 	%fd823, %fd821, %fd105, %fd822;
	ld.global.nc.f64 	%fd824, [%rd103+32];
	fma.rn.f64 	%fd825, %fd823, %fd105, %fd824;
	ld.global.nc.f64 	%fd826, [%rd103+40];
	fma.rn.f64 	%fd827, %fd825, %fd105, %fd826;
	ld.global.nc.f64 	%fd828, [%rd103+48];
	fma.rn.f64 	%fd106, %fd827, %fd105, %fd828;
	fma.rn.f64 	%fd1886, %fd106, %fd1884, %fd1884;
	@%p102 bra 	$L__BB16_81;

	mov.f64 	%fd829, 0d3FF0000000000000;
	fma.rn.f64 	%fd1886, %fd106, %fd105, %fd829;

$L__BB16_81:
	and.b32  	%r249, %r683, 2;
	setp.eq.s32 	%p103, %r249, 0;
	@%p103 bra 	$L__BB16_83;

	mov.f64 	%fd830, 0d0000000000000000;
	mov.f64 	%fd831, 0dBFF0000000000000;
	fma.rn.f64 	%fd1886, %fd1886, %fd831, %fd830;

$L__BB16_83:
	mul.rn.f64 	%fd832, %fd1886, 0d4034000000000000;
	mul.rn.f64 	%fd833, %fd1883, 0d4034000000000000;
	add.rn.f64 	%fd112, %fd833, %fd832;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r250}, %fd87;
	}
	and.b32  	%r251, %r250, 2147483647;
	setp.eq.s32 	%p104, %r251, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r252, %temp}, %fd87;
	}
	setp.eq.s32 	%p105, %r252, 0;
	and.pred  	%p106, %p105, %p104;
	@%p106 bra 	$L__BB16_86;
	bra.uni 	$L__BB16_84;

$L__BB16_86:
	mov.f64 	%fd843, 0d0000000000000000;
	mul.rn.f64 	%fd1887, %fd87, %fd843;
	mov.u32 	%r684, 0;
	bra.uni 	$L__BB16_87;

$L__BB16_84:
	mul.rn.f64 	%fd834, %fd87, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r684, %fd834;
	st.local.u32 	[%rd1], %r684;
	cvt.rn.f64.s32 	%fd835, %r684;
	neg.f64 	%fd836, %fd835;
	mov.f64 	%fd837, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd838, %fd836, %fd837, %fd87;
	mov.f64 	%fd839, 0d3C91A62633145C00;
	fma.rn.f64 	%fd840, %fd836, %fd839, %fd838;
	mov.f64 	%fd841, 0d397B839A252049C0;
	fma.rn.f64 	%fd1887, %fd836, %fd841, %fd840;
	abs.f64 	%fd842, %fd87;
	setp.ltu.f64 	%p107, %fd842, 0d41E0000000000000;
	@%p107 bra 	$L__BB16_87;

	{ // callseq 224, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd87;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1887, [retval0+0];
	} // callseq 224
	ld.local.u32 	%r684, [%rd1];

$L__BB16_87:
	and.b32  	%r254, %r684, 1;
	shl.b32 	%r255, %r684, 3;
	and.b32  	%r256, %r255, 8;
	setp.eq.s32 	%p108, %r254, 0;
	selp.f64 	%fd844, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p108;
	mul.wide.s32 	%rd105, %r256, 8;
	add.s64 	%rd107, %rd82, %rd105;
	ld.global.nc.f64 	%fd845, [%rd107+8];
	mul.rn.f64 	%fd117, %fd1887, %fd1887;
	fma.rn.f64 	%fd846, %fd844, %fd117, %fd845;
	ld.global.nc.f64 	%fd847, [%rd107+16];
	fma.rn.f64 	%fd848, %fd846, %fd117, %fd847;
	ld.global.nc.f64 	%fd849, [%rd107+24];
	fma.rn.f64 	%fd850, %fd848, %fd117, %fd849;
	ld.global.nc.f64 	%fd851, [%rd107+32];
	fma.rn.f64 	%fd852, %fd850, %fd117, %fd851;
	ld.global.nc.f64 	%fd853, [%rd107+40];
	fma.rn.f64 	%fd854, %fd852, %fd117, %fd853;
	ld.global.nc.f64 	%fd855, [%rd107+48];
	fma.rn.f64 	%fd118, %fd854, %fd117, %fd855;
	fma.rn.f64 	%fd1889, %fd118, %fd1887, %fd1887;
	@%p108 bra 	$L__BB16_89;

	mov.f64 	%fd856, 0d3FF0000000000000;
	fma.rn.f64 	%fd1889, %fd118, %fd117, %fd856;

$L__BB16_89:
	and.b32  	%r257, %r684, 2;
	setp.eq.s32 	%p109, %r257, 0;
	@%p109 bra 	$L__BB16_91;

	mov.f64 	%fd857, 0d0000000000000000;
	mov.f64 	%fd858, 0dBFF0000000000000;
	fma.rn.f64 	%fd1889, %fd1889, %fd858, %fd857;

$L__BB16_91:
	div.rn.f64 	%fd124, %fd87, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r258, %temp}, %fd124;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd124;
	}
	and.b32  	%r260, %r259, 2147483647;
	setp.eq.s32 	%p110, %r260, 2146435072;
	setp.eq.s32 	%p111, %r258, 0;
	and.pred  	%p112, %p111, %p110;
	@%p112 bra 	$L__BB16_94;
	bra.uni 	$L__BB16_92;

$L__BB16_94:
	mov.f64 	%fd868, 0d0000000000000000;
	mul.rn.f64 	%fd1890, %fd124, %fd868;
	mov.u32 	%r685, 0;
	bra.uni 	$L__BB16_95;

$L__BB16_92:
	mul.rn.f64 	%fd859, %fd124, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r685, %fd859;
	st.local.u32 	[%rd1], %r685;
	cvt.rn.f64.s32 	%fd860, %r685;
	neg.f64 	%fd861, %fd860;
	mov.f64 	%fd862, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd863, %fd861, %fd862, %fd124;
	mov.f64 	%fd864, 0d3C91A62633145C00;
	fma.rn.f64 	%fd865, %fd861, %fd864, %fd863;
	mov.f64 	%fd866, 0d397B839A252049C0;
	fma.rn.f64 	%fd1890, %fd861, %fd866, %fd865;
	abs.f64 	%fd867, %fd124;
	setp.ltu.f64 	%p113, %fd867, 0d41E0000000000000;
	@%p113 bra 	$L__BB16_95;

	{ // callseq 225, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd124;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1890, [retval0+0];
	} // callseq 225
	ld.local.u32 	%r685, [%rd1];

$L__BB16_95:
	and.b32  	%r262, %r685, 1;
	shl.b32 	%r263, %r685, 3;
	and.b32  	%r264, %r263, 8;
	setp.eq.s32 	%p114, %r262, 0;
	selp.f64 	%fd869, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p114;
	mul.wide.s32 	%rd109, %r264, 8;
	add.s64 	%rd111, %rd82, %rd109;
	ld.global.nc.f64 	%fd870, [%rd111+8];
	mul.rn.f64 	%fd129, %fd1890, %fd1890;
	fma.rn.f64 	%fd871, %fd869, %fd129, %fd870;
	ld.global.nc.f64 	%fd872, [%rd111+16];
	fma.rn.f64 	%fd873, %fd871, %fd129, %fd872;
	ld.global.nc.f64 	%fd874, [%rd111+24];
	fma.rn.f64 	%fd875, %fd873, %fd129, %fd874;
	ld.global.nc.f64 	%fd876, [%rd111+32];
	fma.rn.f64 	%fd877, %fd875, %fd129, %fd876;
	ld.global.nc.f64 	%fd878, [%rd111+40];
	fma.rn.f64 	%fd879, %fd877, %fd129, %fd878;
	ld.global.nc.f64 	%fd880, [%rd111+48];
	fma.rn.f64 	%fd130, %fd879, %fd129, %fd880;
	fma.rn.f64 	%fd1892, %fd130, %fd1890, %fd1890;
	@%p114 bra 	$L__BB16_97;

	mov.f64 	%fd881, 0d3FF0000000000000;
	fma.rn.f64 	%fd1892, %fd130, %fd129, %fd881;

$L__BB16_97:
	and.b32  	%r265, %r685, 2;
	setp.eq.s32 	%p115, %r265, 0;
	@%p115 bra 	$L__BB16_99;

	mov.f64 	%fd882, 0d0000000000000000;
	mov.f64 	%fd883, 0dBFF0000000000000;
	fma.rn.f64 	%fd1892, %fd1892, %fd883, %fd882;

$L__BB16_99:
	mul.rn.f64 	%fd884, %fd1892, 0d4044000000000000;
	mul.rn.f64 	%fd885, %fd1889, 0d4034000000000000;
	add.rn.f64 	%fd136, %fd885, %fd884;
	div.rn.f64 	%fd137, %fd87, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r266, %temp}, %fd137;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd137;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p116, %r268, 2146435072;
	setp.eq.s32 	%p117, %r266, 0;
	and.pred  	%p118, %p117, %p116;
	@%p118 bra 	$L__BB16_102;
	bra.uni 	$L__BB16_100;

$L__BB16_102:
	mov.f64 	%fd895, 0d0000000000000000;
	mul.rn.f64 	%fd1893, %fd137, %fd895;
	mov.u32 	%r686, 0;
	bra.uni 	$L__BB16_103;

$L__BB16_100:
	mul.rn.f64 	%fd886, %fd137, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r686, %fd886;
	st.local.u32 	[%rd1], %r686;
	cvt.rn.f64.s32 	%fd887, %r686;
	neg.f64 	%fd888, %fd887;
	mov.f64 	%fd889, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd890, %fd888, %fd889, %fd137;
	mov.f64 	%fd891, 0d3C91A62633145C00;
	fma.rn.f64 	%fd892, %fd888, %fd891, %fd890;
	mov.f64 	%fd893, 0d397B839A252049C0;
	fma.rn.f64 	%fd1893, %fd888, %fd893, %fd892;
	abs.f64 	%fd894, %fd137;
	setp.ltu.f64 	%p119, %fd894, 0d41E0000000000000;
	@%p119 bra 	$L__BB16_103;

	{ // callseq 226, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd137;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1893, [retval0+0];
	} // callseq 226
	ld.local.u32 	%r686, [%rd1];

$L__BB16_103:
	and.b32  	%r270, %r686, 1;
	shl.b32 	%r271, %r686, 3;
	and.b32  	%r272, %r271, 8;
	setp.eq.s32 	%p120, %r270, 0;
	selp.f64 	%fd896, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p120;
	mul.wide.s32 	%rd113, %r272, 8;
	add.s64 	%rd115, %rd82, %rd113;
	ld.global.nc.f64 	%fd897, [%rd115+8];
	mul.rn.f64 	%fd142, %fd1893, %fd1893;
	fma.rn.f64 	%fd898, %fd896, %fd142, %fd897;
	ld.global.nc.f64 	%fd899, [%rd115+16];
	fma.rn.f64 	%fd900, %fd898, %fd142, %fd899;
	ld.global.nc.f64 	%fd901, [%rd115+24];
	fma.rn.f64 	%fd902, %fd900, %fd142, %fd901;
	ld.global.nc.f64 	%fd903, [%rd115+32];
	fma.rn.f64 	%fd904, %fd902, %fd142, %fd903;
	ld.global.nc.f64 	%fd905, [%rd115+40];
	fma.rn.f64 	%fd906, %fd904, %fd142, %fd905;
	ld.global.nc.f64 	%fd907, [%rd115+48];
	fma.rn.f64 	%fd143, %fd906, %fd142, %fd907;
	fma.rn.f64 	%fd1895, %fd143, %fd1893, %fd1893;
	@%p120 bra 	$L__BB16_105;

	mov.f64 	%fd908, 0d3FF0000000000000;
	fma.rn.f64 	%fd1895, %fd143, %fd142, %fd908;

$L__BB16_105:
	and.b32  	%r273, %r686, 2;
	setp.eq.s32 	%p121, %r273, 0;
	@%p121 bra 	$L__BB16_107;

	mov.f64 	%fd909, 0d0000000000000000;
	mov.f64 	%fd910, 0dBFF0000000000000;
	fma.rn.f64 	%fd1895, %fd1895, %fd910, %fd909;

$L__BB16_107:
	mul.rn.f64 	%fd911, %fd1895, 0d4064000000000000;
	add.rn.f64 	%fd149, %fd136, %fd911;
	div.rn.f64 	%fd150, %fd87, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r274, %temp}, %fd150;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r275}, %fd150;
	}
	and.b32  	%r276, %r275, 2147483647;
	setp.eq.s32 	%p122, %r276, 2146435072;
	setp.eq.s32 	%p123, %r274, 0;
	and.pred  	%p124, %p123, %p122;
	@%p124 bra 	$L__BB16_110;
	bra.uni 	$L__BB16_108;

$L__BB16_110:
	mov.f64 	%fd921, 0d0000000000000000;
	mul.rn.f64 	%fd1896, %fd150, %fd921;
	mov.u32 	%r687, 0;
	bra.uni 	$L__BB16_111;

$L__BB16_108:
	mul.rn.f64 	%fd912, %fd150, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r687, %fd912;
	st.local.u32 	[%rd1], %r687;
	cvt.rn.f64.s32 	%fd913, %r687;
	neg.f64 	%fd914, %fd913;
	mov.f64 	%fd915, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd916, %fd914, %fd915, %fd150;
	mov.f64 	%fd917, 0d3C91A62633145C00;
	fma.rn.f64 	%fd918, %fd914, %fd917, %fd916;
	mov.f64 	%fd919, 0d397B839A252049C0;
	fma.rn.f64 	%fd1896, %fd914, %fd919, %fd918;
	abs.f64 	%fd920, %fd150;
	setp.ltu.f64 	%p125, %fd920, 0d41E0000000000000;
	@%p125 bra 	$L__BB16_111;

	{ // callseq 227, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd150;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1896, [retval0+0];
	} // callseq 227
	ld.local.u32 	%r687, [%rd1];

$L__BB16_111:
	and.b32  	%r278, %r687, 1;
	shl.b32 	%r279, %r687, 3;
	and.b32  	%r280, %r279, 8;
	setp.eq.s32 	%p126, %r278, 0;
	selp.f64 	%fd922, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p126;
	mul.wide.s32 	%rd117, %r280, 8;
	add.s64 	%rd119, %rd82, %rd117;
	ld.global.nc.f64 	%fd923, [%rd119+8];
	mul.rn.f64 	%fd155, %fd1896, %fd1896;
	fma.rn.f64 	%fd924, %fd922, %fd155, %fd923;
	ld.global.nc.f64 	%fd925, [%rd119+16];
	fma.rn.f64 	%fd926, %fd924, %fd155, %fd925;
	ld.global.nc.f64 	%fd927, [%rd119+24];
	fma.rn.f64 	%fd928, %fd926, %fd155, %fd927;
	ld.global.nc.f64 	%fd929, [%rd119+32];
	fma.rn.f64 	%fd930, %fd928, %fd155, %fd929;
	ld.global.nc.f64 	%fd931, [%rd119+40];
	fma.rn.f64 	%fd932, %fd930, %fd155, %fd931;
	ld.global.nc.f64 	%fd933, [%rd119+48];
	fma.rn.f64 	%fd156, %fd932, %fd155, %fd933;
	fma.rn.f64 	%fd1898, %fd156, %fd1896, %fd1896;
	@%p126 bra 	$L__BB16_113;

	mov.f64 	%fd934, 0d3FF0000000000000;
	fma.rn.f64 	%fd1898, %fd156, %fd155, %fd934;

$L__BB16_113:
	and.b32  	%r281, %r687, 2;
	setp.eq.s32 	%p127, %r281, 0;
	@%p127 bra 	$L__BB16_115;

	mov.f64 	%fd935, 0d0000000000000000;
	mov.f64 	%fd936, 0dBFF0000000000000;
	fma.rn.f64 	%fd1898, %fd1898, %fd936, %fd935;

$L__BB16_115:
	mul.rn.f64 	%fd937, %fd1898, 0d4074000000000000;
	add.rn.f64 	%fd162, %fd149, %fd937;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r282}, %fd86;
	}
	and.b32  	%r283, %r282, 2147483647;
	setp.eq.s32 	%p128, %r283, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r284, %temp}, %fd86;
	}
	setp.eq.s32 	%p129, %r284, 0;
	and.pred  	%p130, %p129, %p128;
	@%p130 bra 	$L__BB16_118;
	bra.uni 	$L__BB16_116;

$L__BB16_118:
	mov.f64 	%fd947, 0d0000000000000000;
	mul.rn.f64 	%fd1899, %fd86, %fd947;
	mov.u32 	%r688, 0;
	bra.uni 	$L__BB16_119;

$L__BB16_116:
	mul.rn.f64 	%fd938, %fd86, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r688, %fd938;
	st.local.u32 	[%rd1], %r688;
	cvt.rn.f64.s32 	%fd939, %r688;
	neg.f64 	%fd940, %fd939;
	mov.f64 	%fd941, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd942, %fd940, %fd941, %fd86;
	mov.f64 	%fd943, 0d3C91A62633145C00;
	fma.rn.f64 	%fd944, %fd940, %fd943, %fd942;
	mov.f64 	%fd945, 0d397B839A252049C0;
	fma.rn.f64 	%fd1899, %fd940, %fd945, %fd944;
	abs.f64 	%fd946, %fd86;
	setp.ltu.f64 	%p131, %fd946, 0d41E0000000000000;
	@%p131 bra 	$L__BB16_119;

	{ // callseq 228, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd86;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1899, [retval0+0];
	} // callseq 228
	ld.local.u32 	%r688, [%rd1];

$L__BB16_119:
	and.b32  	%r286, %r688, 1;
	shl.b32 	%r287, %r688, 3;
	and.b32  	%r288, %r287, 8;
	setp.eq.s32 	%p132, %r286, 0;
	selp.f64 	%fd948, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p132;
	mul.wide.s32 	%rd121, %r288, 8;
	add.s64 	%rd123, %rd82, %rd121;
	ld.global.nc.f64 	%fd949, [%rd123+8];
	mul.rn.f64 	%fd167, %fd1899, %fd1899;
	fma.rn.f64 	%fd950, %fd948, %fd167, %fd949;
	ld.global.nc.f64 	%fd951, [%rd123+16];
	fma.rn.f64 	%fd952, %fd950, %fd167, %fd951;
	ld.global.nc.f64 	%fd953, [%rd123+24];
	fma.rn.f64 	%fd954, %fd952, %fd167, %fd953;
	ld.global.nc.f64 	%fd955, [%rd123+32];
	fma.rn.f64 	%fd956, %fd954, %fd167, %fd955;
	ld.global.nc.f64 	%fd957, [%rd123+40];
	fma.rn.f64 	%fd958, %fd956, %fd167, %fd957;
	ld.global.nc.f64 	%fd959, [%rd123+48];
	fma.rn.f64 	%fd168, %fd958, %fd167, %fd959;
	fma.rn.f64 	%fd1901, %fd168, %fd1899, %fd1899;
	@%p132 bra 	$L__BB16_121;

	mov.f64 	%fd960, 0d3FF0000000000000;
	fma.rn.f64 	%fd1901, %fd168, %fd167, %fd960;

$L__BB16_121:
	and.b32  	%r289, %r688, 2;
	setp.eq.s32 	%p133, %r289, 0;
	@%p133 bra 	$L__BB16_123;

	mov.f64 	%fd961, 0d0000000000000000;
	mov.f64 	%fd962, 0dBFF0000000000000;
	fma.rn.f64 	%fd1901, %fd1901, %fd962, %fd961;

$L__BB16_123:
	div.rn.f64 	%fd174, %fd86, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r290, %temp}, %fd174;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r291}, %fd174;
	}
	and.b32  	%r292, %r291, 2147483647;
	setp.eq.s32 	%p134, %r292, 2146435072;
	setp.eq.s32 	%p135, %r290, 0;
	and.pred  	%p136, %p135, %p134;
	@%p136 bra 	$L__BB16_126;
	bra.uni 	$L__BB16_124;

$L__BB16_126:
	mov.f64 	%fd972, 0d0000000000000000;
	mul.rn.f64 	%fd1902, %fd174, %fd972;
	mov.u32 	%r689, 0;
	bra.uni 	$L__BB16_127;

$L__BB16_124:
	mul.rn.f64 	%fd963, %fd174, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r689, %fd963;
	st.local.u32 	[%rd1], %r689;
	cvt.rn.f64.s32 	%fd964, %r689;
	neg.f64 	%fd965, %fd964;
	mov.f64 	%fd966, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd967, %fd965, %fd966, %fd174;
	mov.f64 	%fd968, 0d3C91A62633145C00;
	fma.rn.f64 	%fd969, %fd965, %fd968, %fd967;
	mov.f64 	%fd970, 0d397B839A252049C0;
	fma.rn.f64 	%fd1902, %fd965, %fd970, %fd969;
	abs.f64 	%fd971, %fd174;
	setp.ltu.f64 	%p137, %fd971, 0d41E0000000000000;
	@%p137 bra 	$L__BB16_127;

	{ // callseq 229, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd174;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1902, [retval0+0];
	} // callseq 229
	ld.local.u32 	%r689, [%rd1];

$L__BB16_127:
	and.b32  	%r294, %r689, 1;
	shl.b32 	%r295, %r689, 3;
	and.b32  	%r296, %r295, 8;
	setp.eq.s32 	%p138, %r294, 0;
	selp.f64 	%fd973, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p138;
	mul.wide.s32 	%rd125, %r296, 8;
	add.s64 	%rd127, %rd82, %rd125;
	ld.global.nc.f64 	%fd974, [%rd127+8];
	mul.rn.f64 	%fd179, %fd1902, %fd1902;
	fma.rn.f64 	%fd975, %fd973, %fd179, %fd974;
	ld.global.nc.f64 	%fd976, [%rd127+16];
	fma.rn.f64 	%fd977, %fd975, %fd179, %fd976;
	ld.global.nc.f64 	%fd978, [%rd127+24];
	fma.rn.f64 	%fd979, %fd977, %fd179, %fd978;
	ld.global.nc.f64 	%fd980, [%rd127+32];
	fma.rn.f64 	%fd981, %fd979, %fd179, %fd980;
	ld.global.nc.f64 	%fd982, [%rd127+40];
	fma.rn.f64 	%fd983, %fd981, %fd179, %fd982;
	ld.global.nc.f64 	%fd984, [%rd127+48];
	fma.rn.f64 	%fd180, %fd983, %fd179, %fd984;
	fma.rn.f64 	%fd1904, %fd180, %fd1902, %fd1902;
	@%p138 bra 	$L__BB16_129;

	mov.f64 	%fd985, 0d3FF0000000000000;
	fma.rn.f64 	%fd1904, %fd180, %fd179, %fd985;

$L__BB16_129:
	and.b32  	%r297, %r689, 2;
	setp.eq.s32 	%p139, %r297, 0;
	@%p139 bra 	$L__BB16_131;

	mov.f64 	%fd986, 0d0000000000000000;
	mov.f64 	%fd987, 0dBFF0000000000000;
	fma.rn.f64 	%fd1904, %fd1904, %fd987, %fd986;

$L__BB16_131:
	mul.rn.f64 	%fd988, %fd1904, 0d4044000000000000;
	mul.rn.f64 	%fd989, %fd1901, 0d4034000000000000;
	add.rn.f64 	%fd186, %fd989, %fd988;
	div.rn.f64 	%fd187, %fd86, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r298, %temp}, %fd187;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r299}, %fd187;
	}
	and.b32  	%r300, %r299, 2147483647;
	setp.eq.s32 	%p140, %r300, 2146435072;
	setp.eq.s32 	%p141, %r298, 0;
	and.pred  	%p142, %p141, %p140;
	@%p142 bra 	$L__BB16_134;
	bra.uni 	$L__BB16_132;

$L__BB16_134:
	mov.f64 	%fd999, 0d0000000000000000;
	mul.rn.f64 	%fd1905, %fd187, %fd999;
	mov.u32 	%r690, 0;
	bra.uni 	$L__BB16_135;

$L__BB16_132:
	mul.rn.f64 	%fd990, %fd187, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r690, %fd990;
	st.local.u32 	[%rd1], %r690;
	cvt.rn.f64.s32 	%fd991, %r690;
	neg.f64 	%fd992, %fd991;
	mov.f64 	%fd993, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd994, %fd992, %fd993, %fd187;
	mov.f64 	%fd995, 0d3C91A62633145C00;
	fma.rn.f64 	%fd996, %fd992, %fd995, %fd994;
	mov.f64 	%fd997, 0d397B839A252049C0;
	fma.rn.f64 	%fd1905, %fd992, %fd997, %fd996;
	abs.f64 	%fd998, %fd187;
	setp.ltu.f64 	%p143, %fd998, 0d41E0000000000000;
	@%p143 bra 	$L__BB16_135;

	{ // callseq 230, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd187;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1905, [retval0+0];
	} // callseq 230
	ld.local.u32 	%r690, [%rd1];

$L__BB16_135:
	and.b32  	%r302, %r690, 1;
	shl.b32 	%r303, %r690, 3;
	and.b32  	%r304, %r303, 8;
	setp.eq.s32 	%p144, %r302, 0;
	selp.f64 	%fd1000, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p144;
	mul.wide.s32 	%rd129, %r304, 8;
	add.s64 	%rd131, %rd82, %rd129;
	ld.global.nc.f64 	%fd1001, [%rd131+8];
	mul.rn.f64 	%fd192, %fd1905, %fd1905;
	fma.rn.f64 	%fd1002, %fd1000, %fd192, %fd1001;
	ld.global.nc.f64 	%fd1003, [%rd131+16];
	fma.rn.f64 	%fd1004, %fd1002, %fd192, %fd1003;
	ld.global.nc.f64 	%fd1005, [%rd131+24];
	fma.rn.f64 	%fd1006, %fd1004, %fd192, %fd1005;
	ld.global.nc.f64 	%fd1007, [%rd131+32];
	fma.rn.f64 	%fd1008, %fd1006, %fd192, %fd1007;
	ld.global.nc.f64 	%fd1009, [%rd131+40];
	fma.rn.f64 	%fd1010, %fd1008, %fd192, %fd1009;
	ld.global.nc.f64 	%fd1011, [%rd131+48];
	fma.rn.f64 	%fd193, %fd1010, %fd192, %fd1011;
	fma.rn.f64 	%fd1907, %fd193, %fd1905, %fd1905;
	@%p144 bra 	$L__BB16_137;

	mov.f64 	%fd1012, 0d3FF0000000000000;
	fma.rn.f64 	%fd1907, %fd193, %fd192, %fd1012;

$L__BB16_137:
	and.b32  	%r305, %r690, 2;
	setp.eq.s32 	%p145, %r305, 0;
	@%p145 bra 	$L__BB16_139;

	mov.f64 	%fd1013, 0d0000000000000000;
	mov.f64 	%fd1014, 0dBFF0000000000000;
	fma.rn.f64 	%fd1907, %fd1907, %fd1014, %fd1013;

$L__BB16_139:
	mul.rn.f64 	%fd1015, %fd1907, 0d4062C00000000000;
	add.rn.f64 	%fd199, %fd186, %fd1015;
	div.rn.f64 	%fd200, %fd86, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r306, %temp}, %fd200;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r307}, %fd200;
	}
	and.b32  	%r308, %r307, 2147483647;
	setp.eq.s32 	%p146, %r308, 2146435072;
	setp.eq.s32 	%p147, %r306, 0;
	and.pred  	%p148, %p147, %p146;
	@%p148 bra 	$L__BB16_142;
	bra.uni 	$L__BB16_140;

$L__BB16_142:
	mov.f64 	%fd1025, 0d0000000000000000;
	mul.rn.f64 	%fd1908, %fd200, %fd1025;
	mov.u32 	%r691, 0;
	bra.uni 	$L__BB16_143;

$L__BB16_140:
	mul.rn.f64 	%fd1016, %fd200, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r691, %fd1016;
	st.local.u32 	[%rd1], %r691;
	cvt.rn.f64.s32 	%fd1017, %r691;
	neg.f64 	%fd1018, %fd1017;
	mov.f64 	%fd1019, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1020, %fd1018, %fd1019, %fd200;
	mov.f64 	%fd1021, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1022, %fd1018, %fd1021, %fd1020;
	mov.f64 	%fd1023, 0d397B839A252049C0;
	fma.rn.f64 	%fd1908, %fd1018, %fd1023, %fd1022;
	abs.f64 	%fd1024, %fd200;
	setp.ltu.f64 	%p149, %fd1024, 0d41E0000000000000;
	@%p149 bra 	$L__BB16_143;

	{ // callseq 231, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd200;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1908, [retval0+0];
	} // callseq 231
	ld.local.u32 	%r691, [%rd1];

$L__BB16_143:
	and.b32  	%r310, %r691, 1;
	shl.b32 	%r311, %r691, 3;
	and.b32  	%r312, %r311, 8;
	setp.eq.s32 	%p150, %r310, 0;
	selp.f64 	%fd1026, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p150;
	mul.wide.s32 	%rd133, %r312, 8;
	add.s64 	%rd135, %rd82, %rd133;
	ld.global.nc.f64 	%fd1027, [%rd135+8];
	mul.rn.f64 	%fd205, %fd1908, %fd1908;
	fma.rn.f64 	%fd1028, %fd1026, %fd205, %fd1027;
	ld.global.nc.f64 	%fd1029, [%rd135+16];
	fma.rn.f64 	%fd1030, %fd1028, %fd205, %fd1029;
	ld.global.nc.f64 	%fd1031, [%rd135+24];
	fma.rn.f64 	%fd1032, %fd1030, %fd205, %fd1031;
	ld.global.nc.f64 	%fd1033, [%rd135+32];
	fma.rn.f64 	%fd1034, %fd1032, %fd205, %fd1033;
	ld.global.nc.f64 	%fd1035, [%rd135+40];
	fma.rn.f64 	%fd1036, %fd1034, %fd205, %fd1035;
	ld.global.nc.f64 	%fd1037, [%rd135+48];
	fma.rn.f64 	%fd206, %fd1036, %fd205, %fd1037;
	fma.rn.f64 	%fd1910, %fd206, %fd1908, %fd1908;
	@%p150 bra 	$L__BB16_145;

	mov.f64 	%fd1038, 0d3FF0000000000000;
	fma.rn.f64 	%fd1910, %fd206, %fd205, %fd1038;

$L__BB16_145:
	and.b32  	%r313, %r691, 2;
	setp.eq.s32 	%p151, %r313, 0;
	@%p151 bra 	$L__BB16_147;

	mov.f64 	%fd1039, 0d0000000000000000;
	mov.f64 	%fd1040, 0dBFF0000000000000;
	fma.rn.f64 	%fd1910, %fd1910, %fd1040, %fd1039;

$L__BB16_147:
	mul.rn.f64 	%fd1041, %fd1910, 0d4072C00000000000;
	add.rn.f64 	%fd1042, %fd199, %fd1041;
	add.rn.f64 	%fd212, %fd112, %fd1042;
	add.rn.f64 	%fd213, %fd112, %fd162;
	add.rn.f64 	%fd1043, %fd83, %fd83;
	add.rn.f64 	%fd1044, %fd1043, 0dC059000000000000;
	mul.rn.f64 	%fd1045, %fd82, 0d4008000000000000;
	add.rn.f64 	%fd214, %fd1044, %fd1045;
	abs.f64 	%fd215, %fd82;
	{ // callseq 232, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd215;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1913, [retval0+0];
	} // callseq 232
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r53}, %fd82;
	}
	setp.lt.s32 	%p152, %r53, 0;
	and.pred  	%p4, %p152, %p15;
	not.pred 	%p154, %p4;
	@%p154 bra 	$L__BB16_149;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd1913;
	}
	xor.b32  	%r315, %r314, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r316, %temp}, %fd1913;
	}
	mov.b64 	%fd1913, {%r316, %r315};

$L__BB16_149:
	setp.eq.f64 	%p155, %fd82, 0d0000000000000000;
	@%p155 bra 	$L__BB16_153;
	bra.uni 	$L__BB16_150;

$L__BB16_153:
	selp.b32 	%r317, %r53, 0, %p15;
	mov.u32 	%r318, 0;
	or.b32  	%r319, %r317, 2146435072;
	setp.lt.s32 	%p159, %r2, 0;
	selp.b32 	%r320, %r319, %r317, %p159;
	mov.b64 	%fd1913, {%r318, %r320};
	bra.uni 	$L__BB16_154;

$L__BB16_150:
	setp.gt.s32 	%p156, %r53, -1;
	@%p156 bra 	$L__BB16_154;

	mov.f64 	%fd1046, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1047, %fd1046;
	setp.eq.f64 	%p157, %fd1047, 0d4000000000000000;
	@%p157 bra 	$L__BB16_154;

	mov.f64 	%fd1913, 0dFFF8000000000000;

$L__BB16_154:
	add.rn.f64 	%fd1049, %fd82, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r321}, %fd1049;
	}
	and.b32  	%r322, %r321, 2146435072;
	setp.ne.s32 	%p160, %r322, 2146435072;
	@%p160 bra 	$L__BB16_161;

	setp.gtu.f64 	%p161, %fd215, 0d7FF0000000000000;
	@%p161 bra 	$L__BB16_160;
	bra.uni 	$L__BB16_156;

$L__BB16_160:
	mov.f64 	%fd1051, 0d4000000000000000;
	add.rn.f64 	%fd1913, %fd82, %fd1051;
	bra.uni 	$L__BB16_161;

$L__BB16_156:
	mov.f64 	%fd1050, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r323, %temp}, %fd1050;
	}
	and.b32  	%r54, %r2, 2147483647;
	setp.eq.s32 	%p162, %r54, 2146435072;
	setp.eq.s32 	%p163, %r323, 0;
	and.pred  	%p164, %p162, %p163;
	@%p164 bra 	$L__BB16_159;
	bra.uni 	$L__BB16_157;

$L__BB16_159:
	setp.gt.f64 	%p171, %fd215, 0d3FF0000000000000;
	selp.b32 	%r330, 2146435072, 0, %p171;
	mov.u32 	%r331, 0;
	xor.b32  	%r332, %r330, 2146435072;
	setp.lt.s32 	%p172, %r2, 0;
	selp.b32 	%r333, %r332, %r330, %p172;
	setp.eq.f64 	%p173, %fd82, 0dBFF0000000000000;
	selp.b32 	%r334, 1072693248, %r333, %p173;
	mov.b64 	%fd1913, {%r331, %r334};
	bra.uni 	$L__BB16_161;

$L__BB16_157:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r324, %temp}, %fd82;
	}
	and.b32  	%r325, %r53, 2147483647;
	setp.ne.s32 	%p165, %r325, 2146435072;
	setp.ne.s32 	%p166, %r324, 0;
	or.pred  	%p167, %p165, %p166;
	@%p167 bra 	$L__BB16_161;

	setp.gt.s32 	%p168, %r2, -1;
	selp.b32 	%r326, 2146435072, 0, %p168;
	mov.u32 	%r327, 0;
	setp.ne.s32 	%p169, %r54, 1071644672;
	and.pred  	%p170, %p169, %p4;
	or.b32  	%r328, %r326, -2147483648;
	selp.b32 	%r329, %r328, %r326, %p170;
	mov.b64 	%fd1913, {%r327, %r329};

$L__BB16_161:
	mul.rn.f64 	%fd1052, %fd1913, 0d3FC999999999999A;
	setp.eq.f64 	%p174, %fd82, 0d3FF0000000000000;
	selp.f64 	%fd1053, 0d3FC999999999999A, %fd1052, %p174;
	add.rn.f64 	%fd1054, %fd214, %fd1053;
	mul.rn.f64 	%fd1055, %fd83, %fd82;
	mul.rn.f64 	%fd225, %fd1055, 0d3FB999999999999A;
	add.rn.f64 	%fd1056, %fd225, %fd1054;
	mul.rn.f64 	%fd1057, %fd85, 0d3FC999999999999A;
	add.rn.f64 	%fd1058, %fd1057, %fd1056;
	mul.rn.f64 	%fd1059, %fd213, 0d3FE5555555555555;
	add.rn.f64 	%fd226, %fd1059, %fd1058;
	add.rn.f64 	%fd1060, %fd82, %fd82;
	add.rn.f64 	%fd1061, %fd83, 0d4072C00000000000;
	add.rn.f64 	%fd227, %fd1061, %fd1060;
	{ // callseq 233, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1916, [retval0+0];
	} // callseq 233
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r55}, %fd83;
	}
	setp.lt.s32 	%p175, %r55, 0;
	and.pred  	%p5, %p175, %p15;
	not.pred 	%p177, %p5;
	@%p177 bra 	$L__BB16_163;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r335}, %fd1916;
	}
	xor.b32  	%r336, %r335, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r337, %temp}, %fd1916;
	}
	mov.b64 	%fd1916, {%r337, %r336};

$L__BB16_163:
	setp.eq.f64 	%p178, %fd83, 0d0000000000000000;
	@%p178 bra 	$L__BB16_167;
	bra.uni 	$L__BB16_164;

$L__BB16_167:
	selp.b32 	%r338, %r55, 0, %p15;
	mov.u32 	%r339, 0;
	or.b32  	%r340, %r338, 2146435072;
	setp.lt.s32 	%p182, %r2, 0;
	selp.b32 	%r341, %r340, %r338, %p182;
	mov.b64 	%fd1916, {%r339, %r341};
	bra.uni 	$L__BB16_168;

$L__BB16_164:
	setp.gt.s32 	%p179, %r55, -1;
	@%p179 bra 	$L__BB16_168;

	mov.f64 	%fd1062, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1063, %fd1062;
	setp.eq.f64 	%p180, %fd1063, 0d4000000000000000;
	@%p180 bra 	$L__BB16_168;

	mov.f64 	%fd1916, 0dFFF8000000000000;

$L__BB16_168:
	add.rn.f64 	%fd1065, %fd83, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r342}, %fd1065;
	}
	and.b32  	%r343, %r342, 2146435072;
	setp.ne.s32 	%p183, %r343, 2146435072;
	@%p183 bra 	$L__BB16_175;

	setp.gtu.f64 	%p184, %fd84, 0d7FF0000000000000;
	@%p184 bra 	$L__BB16_174;
	bra.uni 	$L__BB16_170;

$L__BB16_174:
	mov.f64 	%fd1067, 0d4000000000000000;
	add.rn.f64 	%fd1916, %fd83, %fd1067;
	bra.uni 	$L__BB16_175;

$L__BB16_170:
	mov.f64 	%fd1066, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r344, %temp}, %fd1066;
	}
	and.b32  	%r56, %r2, 2147483647;
	setp.eq.s32 	%p185, %r56, 2146435072;
	setp.eq.s32 	%p186, %r344, 0;
	and.pred  	%p187, %p185, %p186;
	@%p187 bra 	$L__BB16_173;
	bra.uni 	$L__BB16_171;

$L__BB16_173:
	setp.gt.f64 	%p194, %fd84, 0d3FF0000000000000;
	selp.b32 	%r351, 2146435072, 0, %p194;
	mov.u32 	%r352, 0;
	xor.b32  	%r353, %r351, 2146435072;
	setp.lt.s32 	%p195, %r2, 0;
	selp.b32 	%r354, %r353, %r351, %p195;
	setp.eq.f64 	%p196, %fd83, 0dBFF0000000000000;
	selp.b32 	%r355, 1072693248, %r354, %p196;
	mov.b64 	%fd1916, {%r352, %r355};
	bra.uni 	$L__BB16_175;

$L__BB16_171:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r345, %temp}, %fd83;
	}
	and.b32  	%r346, %r55, 2147483647;
	setp.ne.s32 	%p188, %r346, 2146435072;
	setp.ne.s32 	%p189, %r345, 0;
	or.pred  	%p190, %p188, %p189;
	@%p190 bra 	$L__BB16_175;

	setp.gt.s32 	%p191, %r2, -1;
	selp.b32 	%r347, 2146435072, 0, %p191;
	mov.u32 	%r348, 0;
	setp.ne.s32 	%p192, %r56, 1071644672;
	and.pred  	%p193, %p192, %p5;
	or.b32  	%r349, %r347, -2147483648;
	selp.b32 	%r350, %r349, %r347, %p193;
	mov.b64 	%fd1916, {%r348, %r350};

$L__BB16_175:
	mul.rn.f64 	%fd1068, %fd1916, 0d3FB999999999999A;
	setp.eq.f64 	%p197, %fd83, 0d3FF0000000000000;
	selp.f64 	%fd1069, 0d3FB999999999999A, %fd1068, %p197;
	add.rn.f64 	%fd1070, %fd227, %fd1069;
	add.rn.f64 	%fd1071, %fd225, %fd1070;
	mul.rn.f64 	%fd1072, %fd85, 0d3FB999999999999A;
	add.rn.f64 	%fd1073, %fd1072, %fd1071;
	mul.rn.f64 	%fd1074, %fd212, 0d3FE5555555555555;
	add.rn.f64 	%fd237, %fd1074, %fd1073;
	div.rn.f64 	%fd1075, %fd81, 0d4066800000000000;
	mul.rn.f64 	%fd238, %fd1075, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r356, %temp}, %fd238;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r357}, %fd238;
	}
	and.b32  	%r358, %r357, 2147483647;
	setp.eq.s32 	%p198, %r358, 2146435072;
	setp.eq.s32 	%p199, %r356, 0;
	and.pred  	%p6, %p199, %p198;
	@%p6 bra 	$L__BB16_178;
	bra.uni 	$L__BB16_176;

$L__BB16_178:
	mov.f64 	%fd1085, 0d0000000000000000;
	mul.rn.f64 	%fd1917, %fd238, %fd1085;
	mov.u32 	%r692, 0;
	bra.uni 	$L__BB16_179;

$L__BB16_176:
	mul.rn.f64 	%fd1076, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r692, %fd1076;
	st.local.u32 	[%rd1], %r692;
	cvt.rn.f64.s32 	%fd1077, %r692;
	neg.f64 	%fd1078, %fd1077;
	mov.f64 	%fd1079, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1080, %fd1078, %fd1079, %fd238;
	mov.f64 	%fd1081, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1082, %fd1078, %fd1081, %fd1080;
	mov.f64 	%fd1083, 0d397B839A252049C0;
	fma.rn.f64 	%fd1917, %fd1078, %fd1083, %fd1082;
	abs.f64 	%fd1084, %fd238;
	setp.ltu.f64 	%p200, %fd1084, 0d41E0000000000000;
	@%p200 bra 	$L__BB16_179;

	{ // callseq 234, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1917, [retval0+0];
	} // callseq 234
	ld.local.u32 	%r692, [%rd1];

$L__BB16_179:
	and.b32  	%r360, %r692, 1;
	shl.b32 	%r361, %r692, 3;
	and.b32  	%r362, %r361, 8;
	setp.eq.s32 	%p201, %r360, 0;
	selp.f64 	%fd1086, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p201;
	mul.wide.s32 	%rd137, %r362, 8;
	add.s64 	%rd139, %rd82, %rd137;
	ld.global.nc.f64 	%fd1087, [%rd139+8];
	mul.rn.f64 	%fd243, %fd1917, %fd1917;
	fma.rn.f64 	%fd1088, %fd1086, %fd243, %fd1087;
	ld.global.nc.f64 	%fd1089, [%rd139+16];
	fma.rn.f64 	%fd1090, %fd1088, %fd243, %fd1089;
	ld.global.nc.f64 	%fd1091, [%rd139+24];
	fma.rn.f64 	%fd1092, %fd1090, %fd243, %fd1091;
	ld.global.nc.f64 	%fd1093, [%rd139+32];
	fma.rn.f64 	%fd1094, %fd1092, %fd243, %fd1093;
	ld.global.nc.f64 	%fd1095, [%rd139+40];
	fma.rn.f64 	%fd1096, %fd1094, %fd243, %fd1095;
	ld.global.nc.f64 	%fd1097, [%rd139+48];
	fma.rn.f64 	%fd244, %fd1096, %fd243, %fd1097;
	fma.rn.f64 	%fd1919, %fd244, %fd1917, %fd1917;
	@%p201 bra 	$L__BB16_181;

	mov.f64 	%fd1098, 0d3FF0000000000000;
	fma.rn.f64 	%fd1919, %fd244, %fd243, %fd1098;

$L__BB16_181:
	and.b32  	%r363, %r692, 2;
	setp.eq.s32 	%p202, %r363, 0;
	@%p202 bra 	$L__BB16_183;

	mov.f64 	%fd1099, 0d0000000000000000;
	mov.f64 	%fd1100, 0dBFF0000000000000;
	fma.rn.f64 	%fd1919, %fd1919, %fd1100, %fd1099;

$L__BB16_183:
	@%p6 bra 	$L__BB16_187;
	bra.uni 	$L__BB16_184;

$L__BB16_187:
	mov.f64 	%fd1110, 0d0000000000000000;
	mul.rn.f64 	%fd1921, %fd238, %fd1110;
	mov.u32 	%r694, 1;
	bra.uni 	$L__BB16_188;

$L__BB16_184:
	mul.rn.f64 	%fd1101, %fd238, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r693, %fd1101;
	st.local.u32 	[%rd1], %r693;
	cvt.rn.f64.s32 	%fd1102, %r693;
	neg.f64 	%fd1103, %fd1102;
	mov.f64 	%fd1104, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1105, %fd1103, %fd1104, %fd238;
	mov.f64 	%fd1106, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1107, %fd1103, %fd1106, %fd1105;
	mov.f64 	%fd1108, 0d397B839A252049C0;
	fma.rn.f64 	%fd1921, %fd1103, %fd1108, %fd1107;
	abs.f64 	%fd1109, %fd238;
	setp.ltu.f64 	%p203, %fd1109, 0d41E0000000000000;
	@%p203 bra 	$L__BB16_186;

	{ // callseq 235, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd238;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1921, [retval0+0];
	} // callseq 235
	ld.local.u32 	%r693, [%rd1];

$L__BB16_186:
	add.s32 	%r694, %r693, 1;

$L__BB16_188:
	and.b32  	%r365, %r694, 1;
	shl.b32 	%r366, %r694, 3;
	and.b32  	%r367, %r366, 8;
	setp.eq.s32 	%p204, %r365, 0;
	selp.f64 	%fd1111, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p204;
	mul.wide.s32 	%rd141, %r367, 8;
	add.s64 	%rd143, %rd82, %rd141;
	ld.global.nc.f64 	%fd1112, [%rd143+8];
	mul.rn.f64 	%fd255, %fd1921, %fd1921;
	fma.rn.f64 	%fd1113, %fd1111, %fd255, %fd1112;
	ld.global.nc.f64 	%fd1114, [%rd143+16];
	fma.rn.f64 	%fd1115, %fd1113, %fd255, %fd1114;
	ld.global.nc.f64 	%fd1116, [%rd143+24];
	fma.rn.f64 	%fd1117, %fd1115, %fd255, %fd1116;
	ld.global.nc.f64 	%fd1118, [%rd143+32];
	fma.rn.f64 	%fd1119, %fd1117, %fd255, %fd1118;
	ld.global.nc.f64 	%fd1120, [%rd143+40];
	fma.rn.f64 	%fd1121, %fd1119, %fd255, %fd1120;
	ld.global.nc.f64 	%fd1122, [%rd143+48];
	fma.rn.f64 	%fd256, %fd1121, %fd255, %fd1122;
	fma.rn.f64 	%fd1923, %fd256, %fd1921, %fd1921;
	@%p204 bra 	$L__BB16_190;

	mov.f64 	%fd1123, 0d3FF0000000000000;
	fma.rn.f64 	%fd1923, %fd256, %fd255, %fd1123;

$L__BB16_190:
	and.b32  	%r368, %r694, 2;
	setp.eq.s32 	%p205, %r368, 0;
	@%p205 bra 	$L__BB16_192;

	mov.f64 	%fd1124, 0d0000000000000000;
	mov.f64 	%fd1125, 0dBFF0000000000000;
	fma.rn.f64 	%fd1923, %fd1923, %fd1125, %fd1124;

$L__BB16_192:
	mul.rn.f64 	%fd1126, %fd1919, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1127, %fd1919, %fd1126;
	add.rn.f64 	%fd1128, %fd1127, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1129, %fd1128;
	mov.f64 	%fd1130, 0dC15854C140000000;
	div.rn.f64 	%fd1131, %fd1130, %fd1129;
	mul.rn.f64 	%fd1132, %fd1131, %fd1923;
	mul.rn.f64 	%fd1133, %fd1132, 0d400921FB54442D18;
	mul.rn.f64 	%fd1134, %fd237, 0d4066800000000000;
	div.rn.f64 	%fd1135, %fd1134, %fd1133;
	add.rn.f64 	%fd2011, %fd69, %fd1135;
	mul.rn.f64 	%fd1136, %fd226, 0d4066800000000000;
	mul.rn.f64 	%fd1137, %fd1129, %fd1128;
	mov.f64 	%fd1138, 0dC1582B102DE355C1;
	div.rn.f64 	%fd1139, %fd1138, %fd1137;
	mul.rn.f64 	%fd1140, %fd1139, 0d400921FB54442D18;
	div.rn.f64 	%fd1141, %fd1136, %fd1140;
	add.rn.f64 	%fd2012, %fd81, %fd1141;
	setp.lt.s32 	%p206, %r146, 1;
	@%p206 bra 	$L__BB16_457;

	and.b32  	%r65, %r2, 2147483647;
	setp.gt.s32 	%p207, %r2, -1;
	selp.b32 	%r66, 2146435072, 0, %p207;
	mov.u32 	%r695, 0;
	or.b32  	%r67, %r66, -2147483648;

$L__BB16_194:
	add.rn.f64 	%fd266, %fd2012, 0dC041800000000000;
	add.rn.f64 	%fd267, %fd2011, 0dC05A400000000000;
	abs.f64 	%fd268, %fd267;
	sqrt.rn.f64 	%fd269, %fd268;
	mul.rn.f64 	%fd270, %fd267, 0d400921FB54442D18;
	mul.rn.f64 	%fd271, %fd266, 0d400921FB54442D18;
	mul.rn.f64 	%fd272, %fd270, 0d4018000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r370, %temp}, %fd272;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r371}, %fd272;
	}
	and.b32  	%r372, %r371, 2147483647;
	setp.eq.s32 	%p208, %r372, 2146435072;
	setp.eq.s32 	%p209, %r370, 0;
	and.pred  	%p210, %p209, %p208;
	@%p210 bra 	$L__BB16_197;
	bra.uni 	$L__BB16_195;

$L__BB16_197:
	mov.f64 	%fd1151, 0d0000000000000000;
	mul.rn.f64 	%fd1926, %fd272, %fd1151;
	mov.u32 	%r696, 0;
	bra.uni 	$L__BB16_198;

$L__BB16_195:
	mul.rn.f64 	%fd1142, %fd272, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r696, %fd1142;
	st.local.u32 	[%rd1], %r696;
	cvt.rn.f64.s32 	%fd1143, %r696;
	neg.f64 	%fd1144, %fd1143;
	mov.f64 	%fd1145, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1146, %fd1144, %fd1145, %fd272;
	mov.f64 	%fd1147, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1148, %fd1144, %fd1147, %fd1146;
	mov.f64 	%fd1149, 0d397B839A252049C0;
	fma.rn.f64 	%fd1926, %fd1144, %fd1149, %fd1148;
	abs.f64 	%fd1150, %fd272;
	setp.ltu.f64 	%p211, %fd1150, 0d41E0000000000000;
	@%p211 bra 	$L__BB16_198;

	{ // callseq 236, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd272;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1926, [retval0+0];
	} // callseq 236
	ld.local.u32 	%r696, [%rd1];

$L__BB16_198:
	and.b32  	%r374, %r696, 1;
	shl.b32 	%r375, %r696, 3;
	and.b32  	%r376, %r375, 8;
	setp.eq.s32 	%p212, %r374, 0;
	selp.f64 	%fd1152, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p212;
	mul.wide.s32 	%rd145, %r376, 8;
	add.s64 	%rd147, %rd82, %rd145;
	ld.global.nc.f64 	%fd1153, [%rd147+8];
	mul.rn.f64 	%fd277, %fd1926, %fd1926;
	fma.rn.f64 	%fd1154, %fd1152, %fd277, %fd1153;
	ld.global.nc.f64 	%fd1155, [%rd147+16];
	fma.rn.f64 	%fd1156, %fd1154, %fd277, %fd1155;
	ld.global.nc.f64 	%fd1157, [%rd147+24];
	fma.rn.f64 	%fd1158, %fd1156, %fd277, %fd1157;
	ld.global.nc.f64 	%fd1159, [%rd147+32];
	fma.rn.f64 	%fd1160, %fd1158, %fd277, %fd1159;
	ld.global.nc.f64 	%fd1161, [%rd147+40];
	fma.rn.f64 	%fd1162, %fd1160, %fd277, %fd1161;
	ld.global.nc.f64 	%fd1163, [%rd147+48];
	fma.rn.f64 	%fd278, %fd1162, %fd277, %fd1163;
	fma.rn.f64 	%fd1928, %fd278, %fd1926, %fd1926;
	@%p212 bra 	$L__BB16_200;

	mov.f64 	%fd1164, 0d3FF0000000000000;
	fma.rn.f64 	%fd1928, %fd278, %fd277, %fd1164;

$L__BB16_200:
	and.b32  	%r377, %r696, 2;
	setp.eq.s32 	%p213, %r377, 0;
	@%p213 bra 	$L__BB16_202;

	mov.f64 	%fd1165, 0d0000000000000000;
	mov.f64 	%fd1166, 0dBFF0000000000000;
	fma.rn.f64 	%fd1928, %fd1928, %fd1166, %fd1165;

$L__BB16_202:
	add.rn.f64 	%fd284, %fd270, %fd270;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r378, %temp}, %fd284;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r379}, %fd284;
	}
	and.b32  	%r380, %r379, 2147483647;
	setp.eq.s32 	%p214, %r380, 2146435072;
	setp.eq.s32 	%p215, %r378, 0;
	and.pred  	%p216, %p215, %p214;
	@%p216 bra 	$L__BB16_205;
	bra.uni 	$L__BB16_203;

$L__BB16_205:
	mov.f64 	%fd1176, 0d0000000000000000;
	mul.rn.f64 	%fd1929, %fd284, %fd1176;
	mov.u32 	%r697, 0;
	bra.uni 	$L__BB16_206;

$L__BB16_203:
	mul.rn.f64 	%fd1167, %fd284, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r697, %fd1167;
	st.local.u32 	[%rd1], %r697;
	cvt.rn.f64.s32 	%fd1168, %r697;
	neg.f64 	%fd1169, %fd1168;
	mov.f64 	%fd1170, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1171, %fd1169, %fd1170, %fd284;
	mov.f64 	%fd1172, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1173, %fd1169, %fd1172, %fd1171;
	mov.f64 	%fd1174, 0d397B839A252049C0;
	fma.rn.f64 	%fd1929, %fd1169, %fd1174, %fd1173;
	abs.f64 	%fd1175, %fd284;
	setp.ltu.f64 	%p217, %fd1175, 0d41E0000000000000;
	@%p217 bra 	$L__BB16_206;

	{ // callseq 237, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd284;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1929, [retval0+0];
	} // callseq 237
	ld.local.u32 	%r697, [%rd1];

$L__BB16_206:
	and.b32  	%r382, %r697, 1;
	shl.b32 	%r383, %r697, 3;
	and.b32  	%r384, %r383, 8;
	setp.eq.s32 	%p218, %r382, 0;
	selp.f64 	%fd1177, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p218;
	mul.wide.s32 	%rd149, %r384, 8;
	add.s64 	%rd151, %rd82, %rd149;
	ld.global.nc.f64 	%fd1178, [%rd151+8];
	mul.rn.f64 	%fd289, %fd1929, %fd1929;
	fma.rn.f64 	%fd1179, %fd1177, %fd289, %fd1178;
	ld.global.nc.f64 	%fd1180, [%rd151+16];
	fma.rn.f64 	%fd1181, %fd1179, %fd289, %fd1180;
	ld.global.nc.f64 	%fd1182, [%rd151+24];
	fma.rn.f64 	%fd1183, %fd1181, %fd289, %fd1182;
	ld.global.nc.f64 	%fd1184, [%rd151+32];
	fma.rn.f64 	%fd1185, %fd1183, %fd289, %fd1184;
	ld.global.nc.f64 	%fd1186, [%rd151+40];
	fma.rn.f64 	%fd1187, %fd1185, %fd289, %fd1186;
	ld.global.nc.f64 	%fd1188, [%rd151+48];
	fma.rn.f64 	%fd290, %fd1187, %fd289, %fd1188;
	fma.rn.f64 	%fd1931, %fd290, %fd1929, %fd1929;
	@%p218 bra 	$L__BB16_208;

	mov.f64 	%fd1189, 0d3FF0000000000000;
	fma.rn.f64 	%fd1931, %fd290, %fd289, %fd1189;

$L__BB16_208:
	and.b32  	%r385, %r697, 2;
	setp.eq.s32 	%p219, %r385, 0;
	@%p219 bra 	$L__BB16_210;

	mov.f64 	%fd1190, 0d0000000000000000;
	mov.f64 	%fd1191, 0dBFF0000000000000;
	fma.rn.f64 	%fd1931, %fd1931, %fd1191, %fd1190;

$L__BB16_210:
	mul.rn.f64 	%fd1192, %fd1931, 0d4034000000000000;
	mul.rn.f64 	%fd1193, %fd1928, 0d4034000000000000;
	add.rn.f64 	%fd296, %fd1193, %fd1192;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r386}, %fd271;
	}
	and.b32  	%r387, %r386, 2147483647;
	setp.eq.s32 	%p220, %r387, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r388, %temp}, %fd271;
	}
	setp.eq.s32 	%p221, %r388, 0;
	and.pred  	%p222, %p221, %p220;
	@%p222 bra 	$L__BB16_213;
	bra.uni 	$L__BB16_211;

$L__BB16_213:
	mov.f64 	%fd1203, 0d0000000000000000;
	mul.rn.f64 	%fd1932, %fd271, %fd1203;
	mov.u32 	%r698, 0;
	bra.uni 	$L__BB16_214;

$L__BB16_211:
	mul.rn.f64 	%fd1194, %fd271, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r698, %fd1194;
	st.local.u32 	[%rd1], %r698;
	cvt.rn.f64.s32 	%fd1195, %r698;
	neg.f64 	%fd1196, %fd1195;
	mov.f64 	%fd1197, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1198, %fd1196, %fd1197, %fd271;
	mov.f64 	%fd1199, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1200, %fd1196, %fd1199, %fd1198;
	mov.f64 	%fd1201, 0d397B839A252049C0;
	fma.rn.f64 	%fd1932, %fd1196, %fd1201, %fd1200;
	abs.f64 	%fd1202, %fd271;
	setp.ltu.f64 	%p223, %fd1202, 0d41E0000000000000;
	@%p223 bra 	$L__BB16_214;

	{ // callseq 238, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd271;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1932, [retval0+0];
	} // callseq 238
	ld.local.u32 	%r698, [%rd1];

$L__BB16_214:
	and.b32  	%r390, %r698, 1;
	shl.b32 	%r391, %r698, 3;
	and.b32  	%r392, %r391, 8;
	setp.eq.s32 	%p224, %r390, 0;
	selp.f64 	%fd1204, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p224;
	mul.wide.s32 	%rd153, %r392, 8;
	add.s64 	%rd155, %rd82, %rd153;
	ld.global.nc.f64 	%fd1205, [%rd155+8];
	mul.rn.f64 	%fd301, %fd1932, %fd1932;
	fma.rn.f64 	%fd1206, %fd1204, %fd301, %fd1205;
	ld.global.nc.f64 	%fd1207, [%rd155+16];
	fma.rn.f64 	%fd1208, %fd1206, %fd301, %fd1207;
	ld.global.nc.f64 	%fd1209, [%rd155+24];
	fma.rn.f64 	%fd1210, %fd1208, %fd301, %fd1209;
	ld.global.nc.f64 	%fd1211, [%rd155+32];
	fma.rn.f64 	%fd1212, %fd1210, %fd301, %fd1211;
	ld.global.nc.f64 	%fd1213, [%rd155+40];
	fma.rn.f64 	%fd1214, %fd1212, %fd301, %fd1213;
	ld.global.nc.f64 	%fd1215, [%rd155+48];
	fma.rn.f64 	%fd302, %fd1214, %fd301, %fd1215;
	fma.rn.f64 	%fd1934, %fd302, %fd1932, %fd1932;
	@%p224 bra 	$L__BB16_216;

	mov.f64 	%fd1216, 0d3FF0000000000000;
	fma.rn.f64 	%fd1934, %fd302, %fd301, %fd1216;

$L__BB16_216:
	and.b32  	%r393, %r698, 2;
	setp.eq.s32 	%p225, %r393, 0;
	@%p225 bra 	$L__BB16_218;

	mov.f64 	%fd1217, 0d0000000000000000;
	mov.f64 	%fd1218, 0dBFF0000000000000;
	fma.rn.f64 	%fd1934, %fd1934, %fd1218, %fd1217;

$L__BB16_218:
	div.rn.f64 	%fd308, %fd271, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r394, %temp}, %fd308;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r395}, %fd308;
	}
	and.b32  	%r396, %r395, 2147483647;
	setp.eq.s32 	%p226, %r396, 2146435072;
	setp.eq.s32 	%p227, %r394, 0;
	and.pred  	%p228, %p227, %p226;
	@%p228 bra 	$L__BB16_221;
	bra.uni 	$L__BB16_219;

$L__BB16_221:
	mov.f64 	%fd1228, 0d0000000000000000;
	mul.rn.f64 	%fd1935, %fd308, %fd1228;
	mov.u32 	%r699, 0;
	bra.uni 	$L__BB16_222;

$L__BB16_219:
	mul.rn.f64 	%fd1219, %fd308, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r699, %fd1219;
	st.local.u32 	[%rd1], %r699;
	cvt.rn.f64.s32 	%fd1220, %r699;
	neg.f64 	%fd1221, %fd1220;
	mov.f64 	%fd1222, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1223, %fd1221, %fd1222, %fd308;
	mov.f64 	%fd1224, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1225, %fd1221, %fd1224, %fd1223;
	mov.f64 	%fd1226, 0d397B839A252049C0;
	fma.rn.f64 	%fd1935, %fd1221, %fd1226, %fd1225;
	abs.f64 	%fd1227, %fd308;
	setp.ltu.f64 	%p229, %fd1227, 0d41E0000000000000;
	@%p229 bra 	$L__BB16_222;

	{ // callseq 239, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd308;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1935, [retval0+0];
	} // callseq 239
	ld.local.u32 	%r699, [%rd1];

$L__BB16_222:
	and.b32  	%r398, %r699, 1;
	shl.b32 	%r399, %r699, 3;
	and.b32  	%r400, %r399, 8;
	setp.eq.s32 	%p230, %r398, 0;
	selp.f64 	%fd1229, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p230;
	mul.wide.s32 	%rd157, %r400, 8;
	add.s64 	%rd159, %rd82, %rd157;
	ld.global.nc.f64 	%fd1230, [%rd159+8];
	mul.rn.f64 	%fd313, %fd1935, %fd1935;
	fma.rn.f64 	%fd1231, %fd1229, %fd313, %fd1230;
	ld.global.nc.f64 	%fd1232, [%rd159+16];
	fma.rn.f64 	%fd1233, %fd1231, %fd313, %fd1232;
	ld.global.nc.f64 	%fd1234, [%rd159+24];
	fma.rn.f64 	%fd1235, %fd1233, %fd313, %fd1234;
	ld.global.nc.f64 	%fd1236, [%rd159+32];
	fma.rn.f64 	%fd1237, %fd1235, %fd313, %fd1236;
	ld.global.nc.f64 	%fd1238, [%rd159+40];
	fma.rn.f64 	%fd1239, %fd1237, %fd313, %fd1238;
	ld.global.nc.f64 	%fd1240, [%rd159+48];
	fma.rn.f64 	%fd314, %fd1239, %fd313, %fd1240;
	fma.rn.f64 	%fd1937, %fd314, %fd1935, %fd1935;
	@%p230 bra 	$L__BB16_224;

	mov.f64 	%fd1241, 0d3FF0000000000000;
	fma.rn.f64 	%fd1937, %fd314, %fd313, %fd1241;

$L__BB16_224:
	and.b32  	%r401, %r699, 2;
	setp.eq.s32 	%p231, %r401, 0;
	@%p231 bra 	$L__BB16_226;

	mov.f64 	%fd1242, 0d0000000000000000;
	mov.f64 	%fd1243, 0dBFF0000000000000;
	fma.rn.f64 	%fd1937, %fd1937, %fd1243, %fd1242;

$L__BB16_226:
	mul.rn.f64 	%fd1244, %fd1937, 0d4044000000000000;
	mul.rn.f64 	%fd1245, %fd1934, 0d4034000000000000;
	add.rn.f64 	%fd320, %fd1245, %fd1244;
	div.rn.f64 	%fd321, %fd271, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r402, %temp}, %fd321;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r403}, %fd321;
	}
	and.b32  	%r404, %r403, 2147483647;
	setp.eq.s32 	%p232, %r404, 2146435072;
	setp.eq.s32 	%p233, %r402, 0;
	and.pred  	%p234, %p233, %p232;
	@%p234 bra 	$L__BB16_229;
	bra.uni 	$L__BB16_227;

$L__BB16_229:
	mov.f64 	%fd1255, 0d0000000000000000;
	mul.rn.f64 	%fd1938, %fd321, %fd1255;
	mov.u32 	%r700, 0;
	bra.uni 	$L__BB16_230;

$L__BB16_227:
	mul.rn.f64 	%fd1246, %fd321, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r700, %fd1246;
	st.local.u32 	[%rd1], %r700;
	cvt.rn.f64.s32 	%fd1247, %r700;
	neg.f64 	%fd1248, %fd1247;
	mov.f64 	%fd1249, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1250, %fd1248, %fd1249, %fd321;
	mov.f64 	%fd1251, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1252, %fd1248, %fd1251, %fd1250;
	mov.f64 	%fd1253, 0d397B839A252049C0;
	fma.rn.f64 	%fd1938, %fd1248, %fd1253, %fd1252;
	abs.f64 	%fd1254, %fd321;
	setp.ltu.f64 	%p235, %fd1254, 0d41E0000000000000;
	@%p235 bra 	$L__BB16_230;

	{ // callseq 240, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd321;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1938, [retval0+0];
	} // callseq 240
	ld.local.u32 	%r700, [%rd1];

$L__BB16_230:
	and.b32  	%r406, %r700, 1;
	shl.b32 	%r407, %r700, 3;
	and.b32  	%r408, %r407, 8;
	setp.eq.s32 	%p236, %r406, 0;
	selp.f64 	%fd1256, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p236;
	mul.wide.s32 	%rd161, %r408, 8;
	add.s64 	%rd163, %rd82, %rd161;
	ld.global.nc.f64 	%fd1257, [%rd163+8];
	mul.rn.f64 	%fd326, %fd1938, %fd1938;
	fma.rn.f64 	%fd1258, %fd1256, %fd326, %fd1257;
	ld.global.nc.f64 	%fd1259, [%rd163+16];
	fma.rn.f64 	%fd1260, %fd1258, %fd326, %fd1259;
	ld.global.nc.f64 	%fd1261, [%rd163+24];
	fma.rn.f64 	%fd1262, %fd1260, %fd326, %fd1261;
	ld.global.nc.f64 	%fd1263, [%rd163+32];
	fma.rn.f64 	%fd1264, %fd1262, %fd326, %fd1263;
	ld.global.nc.f64 	%fd1265, [%rd163+40];
	fma.rn.f64 	%fd1266, %fd1264, %fd326, %fd1265;
	ld.global.nc.f64 	%fd1267, [%rd163+48];
	fma.rn.f64 	%fd327, %fd1266, %fd326, %fd1267;
	fma.rn.f64 	%fd1940, %fd327, %fd1938, %fd1938;
	@%p236 bra 	$L__BB16_232;

	mov.f64 	%fd1268, 0d3FF0000000000000;
	fma.rn.f64 	%fd1940, %fd327, %fd326, %fd1268;

$L__BB16_232:
	and.b32  	%r409, %r700, 2;
	setp.eq.s32 	%p237, %r409, 0;
	@%p237 bra 	$L__BB16_234;

	mov.f64 	%fd1269, 0d0000000000000000;
	mov.f64 	%fd1270, 0dBFF0000000000000;
	fma.rn.f64 	%fd1940, %fd1940, %fd1270, %fd1269;

$L__BB16_234:
	mul.rn.f64 	%fd1271, %fd1940, 0d4064000000000000;
	add.rn.f64 	%fd333, %fd320, %fd1271;
	div.rn.f64 	%fd334, %fd271, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r410, %temp}, %fd334;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r411}, %fd334;
	}
	and.b32  	%r412, %r411, 2147483647;
	setp.eq.s32 	%p238, %r412, 2146435072;
	setp.eq.s32 	%p239, %r410, 0;
	and.pred  	%p240, %p239, %p238;
	@%p240 bra 	$L__BB16_237;
	bra.uni 	$L__BB16_235;

$L__BB16_237:
	mov.f64 	%fd1281, 0d0000000000000000;
	mul.rn.f64 	%fd1941, %fd334, %fd1281;
	mov.u32 	%r701, 0;
	bra.uni 	$L__BB16_238;

$L__BB16_235:
	mul.rn.f64 	%fd1272, %fd334, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r701, %fd1272;
	st.local.u32 	[%rd1], %r701;
	cvt.rn.f64.s32 	%fd1273, %r701;
	neg.f64 	%fd1274, %fd1273;
	mov.f64 	%fd1275, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1276, %fd1274, %fd1275, %fd334;
	mov.f64 	%fd1277, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1278, %fd1274, %fd1277, %fd1276;
	mov.f64 	%fd1279, 0d397B839A252049C0;
	fma.rn.f64 	%fd1941, %fd1274, %fd1279, %fd1278;
	abs.f64 	%fd1280, %fd334;
	setp.ltu.f64 	%p241, %fd1280, 0d41E0000000000000;
	@%p241 bra 	$L__BB16_238;

	{ // callseq 241, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd334;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1941, [retval0+0];
	} // callseq 241
	ld.local.u32 	%r701, [%rd1];

$L__BB16_238:
	and.b32  	%r414, %r701, 1;
	shl.b32 	%r415, %r701, 3;
	and.b32  	%r416, %r415, 8;
	setp.eq.s32 	%p242, %r414, 0;
	selp.f64 	%fd1282, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p242;
	mul.wide.s32 	%rd165, %r416, 8;
	add.s64 	%rd167, %rd82, %rd165;
	ld.global.nc.f64 	%fd1283, [%rd167+8];
	mul.rn.f64 	%fd339, %fd1941, %fd1941;
	fma.rn.f64 	%fd1284, %fd1282, %fd339, %fd1283;
	ld.global.nc.f64 	%fd1285, [%rd167+16];
	fma.rn.f64 	%fd1286, %fd1284, %fd339, %fd1285;
	ld.global.nc.f64 	%fd1287, [%rd167+24];
	fma.rn.f64 	%fd1288, %fd1286, %fd339, %fd1287;
	ld.global.nc.f64 	%fd1289, [%rd167+32];
	fma.rn.f64 	%fd1290, %fd1288, %fd339, %fd1289;
	ld.global.nc.f64 	%fd1291, [%rd167+40];
	fma.rn.f64 	%fd1292, %fd1290, %fd339, %fd1291;
	ld.global.nc.f64 	%fd1293, [%rd167+48];
	fma.rn.f64 	%fd340, %fd1292, %fd339, %fd1293;
	fma.rn.f64 	%fd1943, %fd340, %fd1941, %fd1941;
	@%p242 bra 	$L__BB16_240;

	mov.f64 	%fd1294, 0d3FF0000000000000;
	fma.rn.f64 	%fd1943, %fd340, %fd339, %fd1294;

$L__BB16_240:
	and.b32  	%r417, %r701, 2;
	setp.eq.s32 	%p243, %r417, 0;
	@%p243 bra 	$L__BB16_242;

	mov.f64 	%fd1295, 0d0000000000000000;
	mov.f64 	%fd1296, 0dBFF0000000000000;
	fma.rn.f64 	%fd1943, %fd1943, %fd1296, %fd1295;

$L__BB16_242:
	mul.rn.f64 	%fd1297, %fd1943, 0d4074000000000000;
	add.rn.f64 	%fd346, %fd333, %fd1297;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r418}, %fd270;
	}
	and.b32  	%r419, %r418, 2147483647;
	setp.eq.s32 	%p244, %r419, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r420, %temp}, %fd270;
	}
	setp.eq.s32 	%p245, %r420, 0;
	and.pred  	%p246, %p245, %p244;
	@%p246 bra 	$L__BB16_245;
	bra.uni 	$L__BB16_243;

$L__BB16_245:
	mov.f64 	%fd1307, 0d0000000000000000;
	mul.rn.f64 	%fd1944, %fd270, %fd1307;
	mov.u32 	%r702, 0;
	bra.uni 	$L__BB16_246;

$L__BB16_243:
	mul.rn.f64 	%fd1298, %fd270, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r702, %fd1298;
	st.local.u32 	[%rd1], %r702;
	cvt.rn.f64.s32 	%fd1299, %r702;
	neg.f64 	%fd1300, %fd1299;
	mov.f64 	%fd1301, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1302, %fd1300, %fd1301, %fd270;
	mov.f64 	%fd1303, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1304, %fd1300, %fd1303, %fd1302;
	mov.f64 	%fd1305, 0d397B839A252049C0;
	fma.rn.f64 	%fd1944, %fd1300, %fd1305, %fd1304;
	abs.f64 	%fd1306, %fd270;
	setp.ltu.f64 	%p247, %fd1306, 0d41E0000000000000;
	@%p247 bra 	$L__BB16_246;

	{ // callseq 242, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd270;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1944, [retval0+0];
	} // callseq 242
	ld.local.u32 	%r702, [%rd1];

$L__BB16_246:
	and.b32  	%r422, %r702, 1;
	shl.b32 	%r423, %r702, 3;
	and.b32  	%r424, %r423, 8;
	setp.eq.s32 	%p248, %r422, 0;
	selp.f64 	%fd1308, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p248;
	mul.wide.s32 	%rd169, %r424, 8;
	add.s64 	%rd171, %rd82, %rd169;
	ld.global.nc.f64 	%fd1309, [%rd171+8];
	mul.rn.f64 	%fd351, %fd1944, %fd1944;
	fma.rn.f64 	%fd1310, %fd1308, %fd351, %fd1309;
	ld.global.nc.f64 	%fd1311, [%rd171+16];
	fma.rn.f64 	%fd1312, %fd1310, %fd351, %fd1311;
	ld.global.nc.f64 	%fd1313, [%rd171+24];
	fma.rn.f64 	%fd1314, %fd1312, %fd351, %fd1313;
	ld.global.nc.f64 	%fd1315, [%rd171+32];
	fma.rn.f64 	%fd1316, %fd1314, %fd351, %fd1315;
	ld.global.nc.f64 	%fd1317, [%rd171+40];
	fma.rn.f64 	%fd1318, %fd1316, %fd351, %fd1317;
	ld.global.nc.f64 	%fd1319, [%rd171+48];
	fma.rn.f64 	%fd352, %fd1318, %fd351, %fd1319;
	fma.rn.f64 	%fd1946, %fd352, %fd1944, %fd1944;
	@%p248 bra 	$L__BB16_248;

	mov.f64 	%fd1320, 0d3FF0000000000000;
	fma.rn.f64 	%fd1946, %fd352, %fd351, %fd1320;

$L__BB16_248:
	and.b32  	%r425, %r702, 2;
	setp.eq.s32 	%p249, %r425, 0;
	@%p249 bra 	$L__BB16_250;

	mov.f64 	%fd1321, 0d0000000000000000;
	mov.f64 	%fd1322, 0dBFF0000000000000;
	fma.rn.f64 	%fd1946, %fd1946, %fd1322, %fd1321;

$L__BB16_250:
	div.rn.f64 	%fd358, %fd270, 0d4008000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r426, %temp}, %fd358;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r427}, %fd358;
	}
	and.b32  	%r428, %r427, 2147483647;
	setp.eq.s32 	%p250, %r428, 2146435072;
	setp.eq.s32 	%p251, %r426, 0;
	and.pred  	%p252, %p251, %p250;
	@%p252 bra 	$L__BB16_253;
	bra.uni 	$L__BB16_251;

$L__BB16_253:
	mov.f64 	%fd1332, 0d0000000000000000;
	mul.rn.f64 	%fd1947, %fd358, %fd1332;
	mov.u32 	%r703, 0;
	bra.uni 	$L__BB16_254;

$L__BB16_251:
	mul.rn.f64 	%fd1323, %fd358, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r703, %fd1323;
	st.local.u32 	[%rd1], %r703;
	cvt.rn.f64.s32 	%fd1324, %r703;
	neg.f64 	%fd1325, %fd1324;
	mov.f64 	%fd1326, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1327, %fd1325, %fd1326, %fd358;
	mov.f64 	%fd1328, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1329, %fd1325, %fd1328, %fd1327;
	mov.f64 	%fd1330, 0d397B839A252049C0;
	fma.rn.f64 	%fd1947, %fd1325, %fd1330, %fd1329;
	abs.f64 	%fd1331, %fd358;
	setp.ltu.f64 	%p253, %fd1331, 0d41E0000000000000;
	@%p253 bra 	$L__BB16_254;

	{ // callseq 243, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd358;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1947, [retval0+0];
	} // callseq 243
	ld.local.u32 	%r703, [%rd1];

$L__BB16_254:
	and.b32  	%r430, %r703, 1;
	shl.b32 	%r431, %r703, 3;
	and.b32  	%r432, %r431, 8;
	setp.eq.s32 	%p254, %r430, 0;
	selp.f64 	%fd1333, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p254;
	mul.wide.s32 	%rd173, %r432, 8;
	add.s64 	%rd175, %rd82, %rd173;
	ld.global.nc.f64 	%fd1334, [%rd175+8];
	mul.rn.f64 	%fd363, %fd1947, %fd1947;
	fma.rn.f64 	%fd1335, %fd1333, %fd363, %fd1334;
	ld.global.nc.f64 	%fd1336, [%rd175+16];
	fma.rn.f64 	%fd1337, %fd1335, %fd363, %fd1336;
	ld.global.nc.f64 	%fd1338, [%rd175+24];
	fma.rn.f64 	%fd1339, %fd1337, %fd363, %fd1338;
	ld.global.nc.f64 	%fd1340, [%rd175+32];
	fma.rn.f64 	%fd1341, %fd1339, %fd363, %fd1340;
	ld.global.nc.f64 	%fd1342, [%rd175+40];
	fma.rn.f64 	%fd1343, %fd1341, %fd363, %fd1342;
	ld.global.nc.f64 	%fd1344, [%rd175+48];
	fma.rn.f64 	%fd364, %fd1343, %fd363, %fd1344;
	fma.rn.f64 	%fd1949, %fd364, %fd1947, %fd1947;
	@%p254 bra 	$L__BB16_256;

	mov.f64 	%fd1345, 0d3FF0000000000000;
	fma.rn.f64 	%fd1949, %fd364, %fd363, %fd1345;

$L__BB16_256:
	and.b32  	%r433, %r703, 2;
	setp.eq.s32 	%p255, %r433, 0;
	@%p255 bra 	$L__BB16_258;

	mov.f64 	%fd1346, 0d0000000000000000;
	mov.f64 	%fd1347, 0dBFF0000000000000;
	fma.rn.f64 	%fd1949, %fd1949, %fd1347, %fd1346;

$L__BB16_258:
	mul.rn.f64 	%fd1348, %fd1949, 0d4044000000000000;
	mul.rn.f64 	%fd1349, %fd1946, 0d4034000000000000;
	add.rn.f64 	%fd370, %fd1349, %fd1348;
	div.rn.f64 	%fd371, %fd270, 0d4028000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r434, %temp}, %fd371;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r435}, %fd371;
	}
	and.b32  	%r436, %r435, 2147483647;
	setp.eq.s32 	%p256, %r436, 2146435072;
	setp.eq.s32 	%p257, %r434, 0;
	and.pred  	%p258, %p257, %p256;
	@%p258 bra 	$L__BB16_261;
	bra.uni 	$L__BB16_259;

$L__BB16_261:
	mov.f64 	%fd1359, 0d0000000000000000;
	mul.rn.f64 	%fd1950, %fd371, %fd1359;
	mov.u32 	%r704, 0;
	bra.uni 	$L__BB16_262;

$L__BB16_259:
	mul.rn.f64 	%fd1350, %fd371, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r704, %fd1350;
	st.local.u32 	[%rd1], %r704;
	cvt.rn.f64.s32 	%fd1351, %r704;
	neg.f64 	%fd1352, %fd1351;
	mov.f64 	%fd1353, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1354, %fd1352, %fd1353, %fd371;
	mov.f64 	%fd1355, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1356, %fd1352, %fd1355, %fd1354;
	mov.f64 	%fd1357, 0d397B839A252049C0;
	fma.rn.f64 	%fd1950, %fd1352, %fd1357, %fd1356;
	abs.f64 	%fd1358, %fd371;
	setp.ltu.f64 	%p259, %fd1358, 0d41E0000000000000;
	@%p259 bra 	$L__BB16_262;

	{ // callseq 244, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd371;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1950, [retval0+0];
	} // callseq 244
	ld.local.u32 	%r704, [%rd1];

$L__BB16_262:
	and.b32  	%r438, %r704, 1;
	shl.b32 	%r439, %r704, 3;
	and.b32  	%r440, %r439, 8;
	setp.eq.s32 	%p260, %r438, 0;
	selp.f64 	%fd1360, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p260;
	mul.wide.s32 	%rd177, %r440, 8;
	add.s64 	%rd179, %rd82, %rd177;
	ld.global.nc.f64 	%fd1361, [%rd179+8];
	mul.rn.f64 	%fd376, %fd1950, %fd1950;
	fma.rn.f64 	%fd1362, %fd1360, %fd376, %fd1361;
	ld.global.nc.f64 	%fd1363, [%rd179+16];
	fma.rn.f64 	%fd1364, %fd1362, %fd376, %fd1363;
	ld.global.nc.f64 	%fd1365, [%rd179+24];
	fma.rn.f64 	%fd1366, %fd1364, %fd376, %fd1365;
	ld.global.nc.f64 	%fd1367, [%rd179+32];
	fma.rn.f64 	%fd1368, %fd1366, %fd376, %fd1367;
	ld.global.nc.f64 	%fd1369, [%rd179+40];
	fma.rn.f64 	%fd1370, %fd1368, %fd376, %fd1369;
	ld.global.nc.f64 	%fd1371, [%rd179+48];
	fma.rn.f64 	%fd377, %fd1370, %fd376, %fd1371;
	fma.rn.f64 	%fd1952, %fd377, %fd1950, %fd1950;
	@%p260 bra 	$L__BB16_264;

	mov.f64 	%fd1372, 0d3FF0000000000000;
	fma.rn.f64 	%fd1952, %fd377, %fd376, %fd1372;

$L__BB16_264:
	and.b32  	%r441, %r704, 2;
	setp.eq.s32 	%p261, %r441, 0;
	@%p261 bra 	$L__BB16_266;

	mov.f64 	%fd1373, 0d0000000000000000;
	mov.f64 	%fd1374, 0dBFF0000000000000;
	fma.rn.f64 	%fd1952, %fd1952, %fd1374, %fd1373;

$L__BB16_266:
	mul.rn.f64 	%fd1375, %fd1952, 0d4062C00000000000;
	add.rn.f64 	%fd383, %fd370, %fd1375;
	div.rn.f64 	%fd384, %fd270, 0d403E000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r442, %temp}, %fd384;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r443}, %fd384;
	}
	and.b32  	%r444, %r443, 2147483647;
	setp.eq.s32 	%p262, %r444, 2146435072;
	setp.eq.s32 	%p263, %r442, 0;
	and.pred  	%p264, %p263, %p262;
	@%p264 bra 	$L__BB16_269;
	bra.uni 	$L__BB16_267;

$L__BB16_269:
	mov.f64 	%fd1385, 0d0000000000000000;
	mul.rn.f64 	%fd1953, %fd384, %fd1385;
	mov.u32 	%r705, 0;
	bra.uni 	$L__BB16_270;

$L__BB16_267:
	mul.rn.f64 	%fd1376, %fd384, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r705, %fd1376;
	st.local.u32 	[%rd1], %r705;
	cvt.rn.f64.s32 	%fd1377, %r705;
	neg.f64 	%fd1378, %fd1377;
	mov.f64 	%fd1379, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1380, %fd1378, %fd1379, %fd384;
	mov.f64 	%fd1381, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1382, %fd1378, %fd1381, %fd1380;
	mov.f64 	%fd1383, 0d397B839A252049C0;
	fma.rn.f64 	%fd1953, %fd1378, %fd1383, %fd1382;
	abs.f64 	%fd1384, %fd384;
	setp.ltu.f64 	%p265, %fd1384, 0d41E0000000000000;
	@%p265 bra 	$L__BB16_270;

	{ // callseq 245, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd384;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1953, [retval0+0];
	} // callseq 245
	ld.local.u32 	%r705, [%rd1];

$L__BB16_270:
	and.b32  	%r446, %r705, 1;
	shl.b32 	%r447, %r705, 3;
	and.b32  	%r448, %r447, 8;
	setp.eq.s32 	%p266, %r446, 0;
	selp.f64 	%fd1386, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p266;
	mul.wide.s32 	%rd181, %r448, 8;
	add.s64 	%rd183, %rd82, %rd181;
	ld.global.nc.f64 	%fd1387, [%rd183+8];
	mul.rn.f64 	%fd389, %fd1953, %fd1953;
	fma.rn.f64 	%fd1388, %fd1386, %fd389, %fd1387;
	ld.global.nc.f64 	%fd1389, [%rd183+16];
	fma.rn.f64 	%fd1390, %fd1388, %fd389, %fd1389;
	ld.global.nc.f64 	%fd1391, [%rd183+24];
	fma.rn.f64 	%fd1392, %fd1390, %fd389, %fd1391;
	ld.global.nc.f64 	%fd1393, [%rd183+32];
	fma.rn.f64 	%fd1394, %fd1392, %fd389, %fd1393;
	ld.global.nc.f64 	%fd1395, [%rd183+40];
	fma.rn.f64 	%fd1396, %fd1394, %fd389, %fd1395;
	ld.global.nc.f64 	%fd1397, [%rd183+48];
	fma.rn.f64 	%fd390, %fd1396, %fd389, %fd1397;
	fma.rn.f64 	%fd1955, %fd390, %fd1953, %fd1953;
	@%p266 bra 	$L__BB16_272;

	mov.f64 	%fd1398, 0d3FF0000000000000;
	fma.rn.f64 	%fd1955, %fd390, %fd389, %fd1398;

$L__BB16_272:
	and.b32  	%r449, %r705, 2;
	setp.eq.s32 	%p267, %r449, 0;
	@%p267 bra 	$L__BB16_274;

	mov.f64 	%fd1399, 0d0000000000000000;
	mov.f64 	%fd1400, 0dBFF0000000000000;
	fma.rn.f64 	%fd1955, %fd1955, %fd1400, %fd1399;

$L__BB16_274:
	mul.rn.f64 	%fd1401, %fd1955, 0d4072C00000000000;
	add.rn.f64 	%fd1402, %fd383, %fd1401;
	add.rn.f64 	%fd396, %fd296, %fd1402;
	add.rn.f64 	%fd397, %fd296, %fd346;
	add.rn.f64 	%fd1403, %fd267, %fd267;
	add.rn.f64 	%fd1404, %fd1403, 0dC059000000000000;
	mul.rn.f64 	%fd1405, %fd266, 0d4008000000000000;
	add.rn.f64 	%fd398, %fd1404, %fd1405;
	abs.f64 	%fd399, %fd266;
	{ // callseq 246, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd399;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1958, [retval0+0];
	} // callseq 246
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r99}, %fd266;
	}
	setp.lt.s32 	%p268, %r99, 0;
	and.pred  	%p7, %p268, %p15;
	not.pred 	%p270, %p7;
	@%p270 bra 	$L__BB16_276;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r450}, %fd1958;
	}
	xor.b32  	%r451, %r450, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r452, %temp}, %fd1958;
	}
	mov.b64 	%fd1958, {%r452, %r451};

$L__BB16_276:
	setp.eq.f64 	%p271, %fd266, 0d0000000000000000;
	@%p271 bra 	$L__BB16_280;
	bra.uni 	$L__BB16_277;

$L__BB16_280:
	setp.lt.s32 	%p274, %r2, 0;
	mov.u32 	%r453, 0;
	selp.b32 	%r454, %r99, 0, %p15;
	or.b32  	%r455, %r454, 2146435072;
	selp.b32 	%r456, %r455, %r454, %p274;
	mov.b64 	%fd1958, {%r453, %r456};
	bra.uni 	$L__BB16_281;

$L__BB16_277:
	setp.gt.s32 	%p272, %r99, -1;
	@%p272 bra 	$L__BB16_281;

	mov.f64 	%fd1406, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1407, %fd1406;
	setp.eq.f64 	%p273, %fd1407, 0d4000000000000000;
	@%p273 bra 	$L__BB16_281;

	mov.f64 	%fd1958, 0dFFF8000000000000;

$L__BB16_281:
	add.rn.f64 	%fd1409, %fd266, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r457}, %fd1409;
	}
	and.b32  	%r458, %r457, 2146435072;
	setp.ne.s32 	%p276, %r458, 2146435072;
	@%p276 bra 	$L__BB16_288;

	setp.gtu.f64 	%p277, %fd399, 0d7FF0000000000000;
	@%p277 bra 	$L__BB16_287;
	bra.uni 	$L__BB16_283;

$L__BB16_287:
	mov.f64 	%fd1411, 0d4000000000000000;
	add.rn.f64 	%fd1958, %fd266, %fd1411;
	bra.uni 	$L__BB16_288;

$L__BB16_283:
	setp.eq.s32 	%p278, %r65, 2146435072;
	mov.f64 	%fd1410, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r459, %temp}, %fd1410;
	}
	setp.eq.s32 	%p279, %r459, 0;
	and.pred  	%p280, %p278, %p279;
	@%p280 bra 	$L__BB16_286;
	bra.uni 	$L__BB16_284;

$L__BB16_286:
	setp.lt.s32 	%p286, %r2, 0;
	mov.u32 	%r464, 0;
	setp.gt.f64 	%p287, %fd399, 0d3FF0000000000000;
	selp.b32 	%r465, 2146435072, 0, %p287;
	xor.b32  	%r466, %r465, 2146435072;
	selp.b32 	%r467, %r466, %r465, %p286;
	setp.eq.f64 	%p288, %fd266, 0dBFF0000000000000;
	selp.b32 	%r468, 1072693248, %r467, %p288;
	mov.b64 	%fd1958, {%r464, %r468};
	bra.uni 	$L__BB16_288;

$L__BB16_284:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r460, %temp}, %fd266;
	}
	and.b32  	%r461, %r99, 2147483647;
	setp.ne.s32 	%p281, %r461, 2146435072;
	setp.ne.s32 	%p282, %r460, 0;
	or.pred  	%p283, %p281, %p282;
	@%p283 bra 	$L__BB16_288;

	setp.ne.s32 	%p284, %r65, 1071644672;
	and.pred  	%p285, %p284, %p7;
	selp.b32 	%r462, %r67, %r66, %p285;
	mov.u32 	%r463, 0;
	mov.b64 	%fd1958, {%r463, %r462};

$L__BB16_288:
	mul.rn.f64 	%fd1412, %fd1958, 0d3FC999999999999A;
	setp.eq.f64 	%p289, %fd266, 0d3FF0000000000000;
	selp.f64 	%fd1413, 0d3FC999999999999A, %fd1412, %p289;
	add.rn.f64 	%fd1414, %fd398, %fd1413;
	mul.rn.f64 	%fd1415, %fd267, %fd266;
	mul.rn.f64 	%fd409, %fd1415, 0d3FB999999999999A;
	add.rn.f64 	%fd1416, %fd409, %fd1414;
	mul.rn.f64 	%fd1417, %fd269, 0d3FC999999999999A;
	add.rn.f64 	%fd1418, %fd1417, %fd1416;
	mul.rn.f64 	%fd1419, %fd397, 0d3FE5555555555555;
	add.rn.f64 	%fd410, %fd1419, %fd1418;
	add.rn.f64 	%fd1420, %fd266, %fd266;
	add.rn.f64 	%fd1421, %fd267, 0d4072C00000000000;
	add.rn.f64 	%fd411, %fd1421, %fd1420;
	{ // callseq 247, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd268;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1961, [retval0+0];
	} // callseq 247
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r100}, %fd267;
	}
	setp.lt.s32 	%p290, %r100, 0;
	and.pred  	%p8, %p290, %p15;
	not.pred 	%p292, %p8;
	@%p292 bra 	$L__BB16_290;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r469}, %fd1961;
	}
	xor.b32  	%r470, %r469, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r471, %temp}, %fd1961;
	}
	mov.b64 	%fd1961, {%r471, %r470};

$L__BB16_290:
	setp.eq.f64 	%p293, %fd267, 0d0000000000000000;
	@%p293 bra 	$L__BB16_294;
	bra.uni 	$L__BB16_291;

$L__BB16_294:
	setp.lt.s32 	%p296, %r2, 0;
	mov.u32 	%r472, 0;
	selp.b32 	%r473, %r100, 0, %p15;
	or.b32  	%r474, %r473, 2146435072;
	selp.b32 	%r475, %r474, %r473, %p296;
	mov.b64 	%fd1961, {%r472, %r475};
	bra.uni 	$L__BB16_295;

$L__BB16_291:
	setp.gt.s32 	%p294, %r100, -1;
	@%p294 bra 	$L__BB16_295;

	mov.f64 	%fd1422, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1423, %fd1422;
	setp.eq.f64 	%p295, %fd1423, 0d4000000000000000;
	@%p295 bra 	$L__BB16_295;

	mov.f64 	%fd1961, 0dFFF8000000000000;

$L__BB16_295:
	add.rn.f64 	%fd1425, %fd267, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r476}, %fd1425;
	}
	and.b32  	%r477, %r476, 2146435072;
	setp.ne.s32 	%p298, %r477, 2146435072;
	@%p298 bra 	$L__BB16_302;

	setp.gtu.f64 	%p299, %fd268, 0d7FF0000000000000;
	@%p299 bra 	$L__BB16_301;
	bra.uni 	$L__BB16_297;

$L__BB16_301:
	mov.f64 	%fd1427, 0d4000000000000000;
	add.rn.f64 	%fd1961, %fd267, %fd1427;
	bra.uni 	$L__BB16_302;

$L__BB16_297:
	setp.eq.s32 	%p300, %r65, 2146435072;
	mov.f64 	%fd1426, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r478, %temp}, %fd1426;
	}
	setp.eq.s32 	%p301, %r478, 0;
	and.pred  	%p302, %p300, %p301;
	@%p302 bra 	$L__BB16_300;
	bra.uni 	$L__BB16_298;

$L__BB16_300:
	setp.lt.s32 	%p308, %r2, 0;
	mov.u32 	%r483, 0;
	setp.gt.f64 	%p309, %fd268, 0d3FF0000000000000;
	selp.b32 	%r484, 2146435072, 0, %p309;
	xor.b32  	%r485, %r484, 2146435072;
	selp.b32 	%r486, %r485, %r484, %p308;
	setp.eq.f64 	%p310, %fd267, 0dBFF0000000000000;
	selp.b32 	%r487, 1072693248, %r486, %p310;
	mov.b64 	%fd1961, {%r483, %r487};
	bra.uni 	$L__BB16_302;

$L__BB16_298:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r479, %temp}, %fd267;
	}
	and.b32  	%r480, %r100, 2147483647;
	setp.ne.s32 	%p303, %r480, 2146435072;
	setp.ne.s32 	%p304, %r479, 0;
	or.pred  	%p305, %p303, %p304;
	@%p305 bra 	$L__BB16_302;

	setp.ne.s32 	%p306, %r65, 1071644672;
	and.pred  	%p307, %p306, %p8;
	selp.b32 	%r481, %r67, %r66, %p307;
	mov.u32 	%r482, 0;
	mov.b64 	%fd1961, {%r482, %r481};

$L__BB16_302:
	mul.rn.f64 	%fd1428, %fd1961, 0d3FB999999999999A;
	setp.eq.f64 	%p311, %fd267, 0d3FF0000000000000;
	selp.f64 	%fd1429, 0d3FB999999999999A, %fd1428, %p311;
	add.rn.f64 	%fd1430, %fd411, %fd1429;
	add.rn.f64 	%fd1431, %fd409, %fd1430;
	mul.rn.f64 	%fd1432, %fd269, 0d3FB999999999999A;
	add.rn.f64 	%fd1433, %fd1432, %fd1431;
	mul.rn.f64 	%fd1434, %fd396, 0d3FE5555555555555;
	add.rn.f64 	%fd421, %fd1434, %fd1433;
	div.rn.f64 	%fd1435, %fd2012, 0d4066800000000000;
	mul.rn.f64 	%fd422, %fd1435, 0d400921FB54442D18;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r488, %temp}, %fd422;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r489}, %fd422;
	}
	and.b32  	%r490, %r489, 2147483647;
	setp.eq.s32 	%p312, %r490, 2146435072;
	setp.eq.s32 	%p313, %r488, 0;
	and.pred  	%p9, %p313, %p312;
	@%p9 bra 	$L__BB16_305;
	bra.uni 	$L__BB16_303;

$L__BB16_305:
	mov.f64 	%fd1445, 0d0000000000000000;
	mul.rn.f64 	%fd1962, %fd422, %fd1445;
	mov.u32 	%r706, 0;
	bra.uni 	$L__BB16_306;

$L__BB16_303:
	mul.rn.f64 	%fd1436, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r706, %fd1436;
	st.local.u32 	[%rd1], %r706;
	cvt.rn.f64.s32 	%fd1437, %r706;
	neg.f64 	%fd1438, %fd1437;
	mov.f64 	%fd1439, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1440, %fd1438, %fd1439, %fd422;
	mov.f64 	%fd1441, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1442, %fd1438, %fd1441, %fd1440;
	mov.f64 	%fd1443, 0d397B839A252049C0;
	fma.rn.f64 	%fd1962, %fd1438, %fd1443, %fd1442;
	abs.f64 	%fd1444, %fd422;
	setp.ltu.f64 	%p314, %fd1444, 0d41E0000000000000;
	@%p314 bra 	$L__BB16_306;

	{ // callseq 248, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1962, [retval0+0];
	} // callseq 248
	ld.local.u32 	%r706, [%rd1];

$L__BB16_306:
	and.b32  	%r492, %r706, 1;
	shl.b32 	%r493, %r706, 3;
	and.b32  	%r494, %r493, 8;
	setp.eq.s32 	%p315, %r492, 0;
	selp.f64 	%fd1446, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p315;
	mul.wide.s32 	%rd185, %r494, 8;
	add.s64 	%rd187, %rd82, %rd185;
	ld.global.nc.f64 	%fd1447, [%rd187+8];
	mul.rn.f64 	%fd427, %fd1962, %fd1962;
	fma.rn.f64 	%fd1448, %fd1446, %fd427, %fd1447;
	ld.global.nc.f64 	%fd1449, [%rd187+16];
	fma.rn.f64 	%fd1450, %fd1448, %fd427, %fd1449;
	ld.global.nc.f64 	%fd1451, [%rd187+24];
	fma.rn.f64 	%fd1452, %fd1450, %fd427, %fd1451;
	ld.global.nc.f64 	%fd1453, [%rd187+32];
	fma.rn.f64 	%fd1454, %fd1452, %fd427, %fd1453;
	ld.global.nc.f64 	%fd1455, [%rd187+40];
	fma.rn.f64 	%fd1456, %fd1454, %fd427, %fd1455;
	ld.global.nc.f64 	%fd1457, [%rd187+48];
	fma.rn.f64 	%fd428, %fd1456, %fd427, %fd1457;
	fma.rn.f64 	%fd1964, %fd428, %fd1962, %fd1962;
	@%p315 bra 	$L__BB16_308;

	mov.f64 	%fd1458, 0d3FF0000000000000;
	fma.rn.f64 	%fd1964, %fd428, %fd427, %fd1458;

$L__BB16_308:
	and.b32  	%r495, %r706, 2;
	setp.eq.s32 	%p316, %r495, 0;
	@%p316 bra 	$L__BB16_310;

	mov.f64 	%fd1459, 0d0000000000000000;
	mov.f64 	%fd1460, 0dBFF0000000000000;
	fma.rn.f64 	%fd1964, %fd1964, %fd1460, %fd1459;

$L__BB16_310:
	@%p9 bra 	$L__BB16_314;
	bra.uni 	$L__BB16_311;

$L__BB16_314:
	mov.f64 	%fd1470, 0d0000000000000000;
	mul.rn.f64 	%fd1966, %fd422, %fd1470;
	mov.u32 	%r708, 1;
	bra.uni 	$L__BB16_315;

$L__BB16_311:
	mul.rn.f64 	%fd1461, %fd422, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r707, %fd1461;
	st.local.u32 	[%rd1], %r707;
	cvt.rn.f64.s32 	%fd1462, %r707;
	neg.f64 	%fd1463, %fd1462;
	mov.f64 	%fd1464, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1465, %fd1463, %fd1464, %fd422;
	mov.f64 	%fd1466, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1467, %fd1463, %fd1466, %fd1465;
	mov.f64 	%fd1468, 0d397B839A252049C0;
	fma.rn.f64 	%fd1966, %fd1463, %fd1468, %fd1467;
	abs.f64 	%fd1469, %fd422;
	setp.ltu.f64 	%p317, %fd1469, 0d41E0000000000000;
	@%p317 bra 	$L__BB16_313;

	{ // callseq 249, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd422;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1966, [retval0+0];
	} // callseq 249
	ld.local.u32 	%r707, [%rd1];

$L__BB16_313:
	add.s32 	%r708, %r707, 1;

$L__BB16_315:
	and.b32  	%r497, %r708, 1;
	shl.b32 	%r498, %r708, 3;
	and.b32  	%r499, %r498, 8;
	setp.eq.s32 	%p318, %r497, 0;
	selp.f64 	%fd1471, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p318;
	mul.wide.s32 	%rd189, %r499, 8;
	add.s64 	%rd191, %rd82, %rd189;
	ld.global.nc.f64 	%fd1472, [%rd191+8];
	mul.rn.f64 	%fd439, %fd1966, %fd1966;
	fma.rn.f64 	%fd1473, %fd1471, %fd439, %fd1472;
	ld.global.nc.f64 	%fd1474, [%rd191+16];
	fma.rn.f64 	%fd1475, %fd1473, %fd439, %fd1474;
	ld.global.nc.f64 	%fd1476, [%rd191+24];
	fma.rn.f64 	%fd1477, %fd1475, %fd439, %fd1476;
	ld.global.nc.f64 	%fd1478, [%rd191+32];
	fma.rn.f64 	%fd1479, %fd1477, %fd439, %fd1478;
	ld.global.nc.f64 	%fd1480, [%rd191+40];
	fma.rn.f64 	%fd1481, %fd1479, %fd439, %fd1480;
	ld.global.nc.f64 	%fd1482, [%rd191+48];
	fma.rn.f64 	%fd440, %fd1481, %fd439, %fd1482;
	fma.rn.f64 	%fd1968, %fd440, %fd1966, %fd1966;
	@%p318 bra 	$L__BB16_317;

	mov.f64 	%fd1483, 0d3FF0000000000000;
	fma.rn.f64 	%fd1968, %fd440, %fd439, %fd1483;

$L__BB16_317:
	and.b32  	%r500, %r708, 2;
	setp.eq.s32 	%p319, %r500, 0;
	@%p319 bra 	$L__BB16_319;

	mov.f64 	%fd1484, 0d0000000000000000;
	mov.f64 	%fd1485, 0dBFF0000000000000;
	fma.rn.f64 	%fd1968, %fd1968, %fd1485, %fd1484;

$L__BB16_319:
	mul.rn.f64 	%fd1486, %fd1964, 0dBF7B6A8FAF80EF0B;
	mul.rn.f64 	%fd1487, %fd1964, %fd1486;
	add.rn.f64 	%fd1488, %fd1487, 0d3FF0000000000000;
	sqrt.rn.f64 	%fd1489, %fd1488;
	mov.f64 	%fd1490, 0d415854C140000000;
	div.rn.f64 	%fd1491, %fd1490, %fd1489;
	mul.rn.f64 	%fd1492, %fd1491, %fd1968;
	mul.rn.f64 	%fd1493, %fd1492, 0d400921FB54442D18;
	mul.rn.f64 	%fd1494, %fd421, 0d4066800000000000;
	div.rn.f64 	%fd1495, %fd1494, %fd1493;
	add.rn.f64 	%fd446, %fd2011, %fd1495;
	mul.rn.f64 	%fd1496, %fd410, 0d4066800000000000;
	mul.rn.f64 	%fd1497, %fd1489, %fd1488;
	mov.f64 	%fd1498, 0d41582B102DE355C1;
	div.rn.f64 	%fd1499, %fd1498, %fd1497;
	mul.rn.f64 	%fd1500, %fd1499, 0d400921FB54442D18;
	div.rn.f64 	%fd1501, %fd1496, %fd1500;
	add.rn.f64 	%fd447, %fd2012, %fd1501;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r109}, %fd446;
	}
	abs.f64 	%fd448, %fd446;
	{ // callseq 250, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd448;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1971, [retval0+0];
	} // callseq 250
	setp.lt.s32 	%p320, %r109, 0;
	and.pred  	%p10, %p320, %p15;
	not.pred 	%p322, %p10;
	@%p322 bra 	$L__BB16_321;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r501}, %fd1971;
	}
	xor.b32  	%r502, %r501, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r503, %temp}, %fd1971;
	}
	mov.b64 	%fd1971, {%r503, %r502};

$L__BB16_321:
	setp.eq.f64 	%p323, %fd446, 0d0000000000000000;
	@%p323 bra 	$L__BB16_325;
	bra.uni 	$L__BB16_322;

$L__BB16_325:
	setp.lt.s32 	%p326, %r2, 0;
	mov.u32 	%r504, 0;
	selp.b32 	%r505, %r109, 0, %p15;
	or.b32  	%r506, %r505, 2146435072;
	selp.b32 	%r507, %r506, %r505, %p326;
	mov.b64 	%fd1971, {%r504, %r507};
	bra.uni 	$L__BB16_326;

$L__BB16_322:
	setp.gt.s32 	%p324, %r109, -1;
	@%p324 bra 	$L__BB16_326;

	mov.f64 	%fd1502, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1503, %fd1502;
	setp.eq.f64 	%p325, %fd1503, 0d4000000000000000;
	@%p325 bra 	$L__BB16_326;

	mov.f64 	%fd1971, 0dFFF8000000000000;

$L__BB16_326:
	add.rn.f64 	%fd1505, %fd446, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r508}, %fd1505;
	}
	and.b32  	%r509, %r508, 2146435072;
	setp.ne.s32 	%p328, %r509, 2146435072;
	@%p328 bra 	$L__BB16_333;

	setp.gtu.f64 	%p329, %fd448, 0d7FF0000000000000;
	@%p329 bra 	$L__BB16_332;
	bra.uni 	$L__BB16_328;

$L__BB16_332:
	mov.f64 	%fd1507, 0d4000000000000000;
	add.rn.f64 	%fd1971, %fd446, %fd1507;
	bra.uni 	$L__BB16_333;

$L__BB16_328:
	setp.eq.s32 	%p330, %r65, 2146435072;
	mov.f64 	%fd1506, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r510, %temp}, %fd1506;
	}
	setp.eq.s32 	%p331, %r510, 0;
	and.pred  	%p332, %p330, %p331;
	@%p332 bra 	$L__BB16_331;
	bra.uni 	$L__BB16_329;

$L__BB16_331:
	setp.lt.s32 	%p338, %r2, 0;
	mov.u32 	%r515, 0;
	setp.gt.f64 	%p339, %fd448, 0d3FF0000000000000;
	selp.b32 	%r516, 2146435072, 0, %p339;
	xor.b32  	%r517, %r516, 2146435072;
	selp.b32 	%r518, %r517, %r516, %p338;
	setp.eq.f64 	%p340, %fd446, 0dBFF0000000000000;
	selp.b32 	%r519, 1072693248, %r518, %p340;
	mov.b64 	%fd1971, {%r515, %r519};
	bra.uni 	$L__BB16_333;

$L__BB16_329:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r511, %temp}, %fd446;
	}
	and.b32  	%r512, %r109, 2147483647;
	setp.ne.s32 	%p333, %r512, 2146435072;
	setp.ne.s32 	%p334, %r511, 0;
	or.pred  	%p335, %p333, %p334;
	@%p335 bra 	$L__BB16_333;

	setp.ne.s32 	%p336, %r65, 1071644672;
	and.pred  	%p337, %p336, %p10;
	selp.b32 	%r513, %r67, %r66, %p337;
	mov.u32 	%r514, 0;
	mov.b64 	%fd1971, {%r514, %r513};

$L__BB16_333:
	abs.f64 	%fd458, %fd447;
	{ // callseq 251, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd458;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1974, [retval0+0];
	} // callseq 251
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r110}, %fd447;
	}
	setp.lt.s32 	%p341, %r110, 0;
	and.pred  	%p11, %p341, %p15;
	not.pred 	%p343, %p11;
	@%p343 bra 	$L__BB16_335;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r520}, %fd1974;
	}
	xor.b32  	%r521, %r520, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r522, %temp}, %fd1974;
	}
	mov.b64 	%fd1974, {%r522, %r521};

$L__BB16_335:
	setp.eq.f64 	%p344, %fd447, 0d0000000000000000;
	@%p344 bra 	$L__BB16_339;
	bra.uni 	$L__BB16_336;

$L__BB16_339:
	setp.lt.s32 	%p347, %r2, 0;
	mov.u32 	%r523, 0;
	selp.b32 	%r524, %r110, 0, %p15;
	or.b32  	%r525, %r524, 2146435072;
	selp.b32 	%r526, %r525, %r524, %p347;
	mov.b64 	%fd1974, {%r523, %r526};
	bra.uni 	$L__BB16_340;

$L__BB16_336:
	setp.gt.s32 	%p345, %r110, -1;
	@%p345 bra 	$L__BB16_340;

	mov.f64 	%fd1508, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1509, %fd1508;
	setp.eq.f64 	%p346, %fd1509, 0d4000000000000000;
	@%p346 bra 	$L__BB16_340;

	mov.f64 	%fd1974, 0dFFF8000000000000;

$L__BB16_340:
	add.rn.f64 	%fd1511, %fd447, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r527}, %fd1511;
	}
	and.b32  	%r528, %r527, 2146435072;
	setp.ne.s32 	%p349, %r528, 2146435072;
	@%p349 bra 	$L__BB16_347;

	setp.gtu.f64 	%p350, %fd458, 0d7FF0000000000000;
	@%p350 bra 	$L__BB16_346;
	bra.uni 	$L__BB16_342;

$L__BB16_346:
	mov.f64 	%fd1513, 0d4000000000000000;
	add.rn.f64 	%fd1974, %fd447, %fd1513;
	bra.uni 	$L__BB16_347;

$L__BB16_342:
	setp.eq.s32 	%p351, %r65, 2146435072;
	mov.f64 	%fd1512, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r529, %temp}, %fd1512;
	}
	setp.eq.s32 	%p352, %r529, 0;
	and.pred  	%p353, %p351, %p352;
	@%p353 bra 	$L__BB16_345;
	bra.uni 	$L__BB16_343;

$L__BB16_345:
	setp.lt.s32 	%p359, %r2, 0;
	mov.u32 	%r534, 0;
	setp.gt.f64 	%p360, %fd458, 0d3FF0000000000000;
	selp.b32 	%r535, 2146435072, 0, %p360;
	xor.b32  	%r536, %r535, 2146435072;
	selp.b32 	%r537, %r536, %r535, %p359;
	setp.eq.f64 	%p361, %fd447, 0dBFF0000000000000;
	selp.b32 	%r538, 1072693248, %r537, %p361;
	mov.b64 	%fd1974, {%r534, %r538};
	bra.uni 	$L__BB16_347;

$L__BB16_343:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r530, %temp}, %fd447;
	}
	and.b32  	%r531, %r110, 2147483647;
	setp.ne.s32 	%p354, %r531, 2146435072;
	setp.ne.s32 	%p355, %r530, 0;
	or.pred  	%p356, %p354, %p355;
	@%p356 bra 	$L__BB16_347;

	setp.ne.s32 	%p357, %r65, 1071644672;
	and.pred  	%p358, %p357, %p11;
	selp.b32 	%r532, %r67, %r66, %p358;
	mov.u32 	%r533, 0;
	mov.b64 	%fd1974, {%r533, %r532};

$L__BB16_347:
	setp.eq.f64 	%p362, %fd447, 0d3FF0000000000000;
	selp.f64 	%fd1514, 0d3FF0000000000000, %fd1974, %p362;
	setp.eq.f64 	%p363, %fd446, 0d3FF0000000000000;
	selp.f64 	%fd1515, 0d3FF0000000000000, %fd1971, %p363;
	add.rn.f64 	%fd468, %fd1515, %fd1514;
	mul.rn.f64 	%fd469, %fd447, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r539, %temp}, %fd469;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r540}, %fd469;
	}
	and.b32  	%r541, %r540, 2147483647;
	setp.eq.s32 	%p364, %r541, 2146435072;
	setp.eq.s32 	%p365, %r539, 0;
	and.pred  	%p366, %p365, %p364;
	@%p366 bra 	$L__BB16_350;
	bra.uni 	$L__BB16_348;

$L__BB16_350:
	mov.f64 	%fd1525, 0d0000000000000000;
	mul.rn.f64 	%fd1975, %fd469, %fd1525;
	mov.u32 	%r709, 0;
	bra.uni 	$L__BB16_351;

$L__BB16_348:
	mul.rn.f64 	%fd1516, %fd469, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r709, %fd1516;
	st.local.u32 	[%rd1], %r709;
	cvt.rn.f64.s32 	%fd1517, %r709;
	neg.f64 	%fd1518, %fd1517;
	mov.f64 	%fd1519, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1520, %fd1518, %fd1519, %fd469;
	mov.f64 	%fd1521, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1522, %fd1518, %fd1521, %fd1520;
	mov.f64 	%fd1523, 0d397B839A252049C0;
	fma.rn.f64 	%fd1975, %fd1518, %fd1523, %fd1522;
	abs.f64 	%fd1524, %fd469;
	setp.ltu.f64 	%p367, %fd1524, 0d41E0000000000000;
	@%p367 bra 	$L__BB16_351;

	{ // callseq 252, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd469;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1975, [retval0+0];
	} // callseq 252
	ld.local.u32 	%r709, [%rd1];

$L__BB16_351:
	and.b32  	%r543, %r709, 1;
	shl.b32 	%r544, %r709, 3;
	and.b32  	%r545, %r544, 8;
	setp.eq.s32 	%p368, %r543, 0;
	selp.f64 	%fd1526, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p368;
	mul.wide.s32 	%rd193, %r545, 8;
	add.s64 	%rd195, %rd82, %rd193;
	ld.global.nc.f64 	%fd1527, [%rd195+8];
	mul.rn.f64 	%fd474, %fd1975, %fd1975;
	fma.rn.f64 	%fd1528, %fd1526, %fd474, %fd1527;
	ld.global.nc.f64 	%fd1529, [%rd195+16];
	fma.rn.f64 	%fd1530, %fd1528, %fd474, %fd1529;
	ld.global.nc.f64 	%fd1531, [%rd195+24];
	fma.rn.f64 	%fd1532, %fd1530, %fd474, %fd1531;
	ld.global.nc.f64 	%fd1533, [%rd195+32];
	fma.rn.f64 	%fd1534, %fd1532, %fd474, %fd1533;
	ld.global.nc.f64 	%fd1535, [%rd195+40];
	fma.rn.f64 	%fd1536, %fd1534, %fd474, %fd1535;
	ld.global.nc.f64 	%fd1537, [%rd195+48];
	fma.rn.f64 	%fd475, %fd1536, %fd474, %fd1537;
	fma.rn.f64 	%fd1977, %fd475, %fd1975, %fd1975;
	@%p368 bra 	$L__BB16_353;

	mov.f64 	%fd1538, 0d3FF0000000000000;
	fma.rn.f64 	%fd1977, %fd475, %fd474, %fd1538;

$L__BB16_353:
	and.b32  	%r546, %r709, 2;
	setp.eq.s32 	%p369, %r546, 0;
	@%p369 bra 	$L__BB16_355;

	mov.f64 	%fd1539, 0d0000000000000000;
	mov.f64 	%fd1540, 0dBFF0000000000000;
	fma.rn.f64 	%fd1977, %fd1977, %fd1540, %fd1539;

$L__BB16_355:
	mul.rn.f64 	%fd1541, %fd1977, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd1542, %fd468;
	add.rn.f64 	%fd481, %fd1542, %fd1541;
	setp.eq.f64 	%p370, %fd458, 0d0000000000000000;
	setp.eq.f64 	%p371, %fd448, 0d0000000000000000;
	and.pred  	%p372, %p371, %p370;
	@%p372 bra 	$L__BB16_359;
	bra.uni 	$L__BB16_356;

$L__BB16_359:
	selp.f64 	%fd1595, 0d400921FB54442D18, 0d0000000000000000, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r555, %temp}, %fd1595;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r556}, %fd1595;
	}
	and.b32  	%r557, %r110, -2147483648;
	or.b32  	%r558, %r556, %r557;
	mov.b64 	%fd1978, {%r555, %r558};
	bra.uni 	$L__BB16_360;

$L__BB16_356:
	setp.eq.f64 	%p373, %fd448, 0d7FF0000000000000;
	setp.eq.f64 	%p374, %fd458, 0d7FF0000000000000;
	and.pred  	%p375, %p373, %p374;
	@%p375 bra 	$L__BB16_358;
	bra.uni 	$L__BB16_357;

$L__BB16_358:
	selp.f64 	%fd1594, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r551, %temp}, %fd1594;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r552}, %fd1594;
	}
	and.b32  	%r553, %r110, -2147483648;
	or.b32  	%r554, %r552, %r553;
	mov.b64 	%fd1978, {%r551, %r554};
	bra.uni 	$L__BB16_360;

$L__BB16_357:
	min.f64 	%fd1543, %fd458, %fd448;
	max.f64 	%fd1544, %fd458, %fd448;
	div.rn.f64 	%fd1545, %fd1543, %fd1544;
	mul.rn.f64 	%fd1546, %fd1545, %fd1545;
	mov.f64 	%fd1547, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1548, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1549, %fd1548, %fd1546, %fd1547;
	mov.f64 	%fd1550, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1551, %fd1549, %fd1546, %fd1550;
	mov.f64 	%fd1552, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1553, %fd1551, %fd1546, %fd1552;
	mov.f64 	%fd1554, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1555, %fd1553, %fd1546, %fd1554;
	mov.f64 	%fd1556, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1557, %fd1555, %fd1546, %fd1556;
	mov.f64 	%fd1558, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1559, %fd1557, %fd1546, %fd1558;
	mov.f64 	%fd1560, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1561, %fd1559, %fd1546, %fd1560;
	mov.f64 	%fd1562, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1563, %fd1561, %fd1546, %fd1562;
	mov.f64 	%fd1564, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1565, %fd1563, %fd1546, %fd1564;
	mov.f64 	%fd1566, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1567, %fd1565, %fd1546, %fd1566;
	mov.f64 	%fd1568, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1569, %fd1567, %fd1546, %fd1568;
	mov.f64 	%fd1570, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1571, %fd1569, %fd1546, %fd1570;
	mov.f64 	%fd1572, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1573, %fd1571, %fd1546, %fd1572;
	mov.f64 	%fd1574, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1575, %fd1573, %fd1546, %fd1574;
	mov.f64 	%fd1576, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1577, %fd1575, %fd1546, %fd1576;
	mov.f64 	%fd1578, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1579, %fd1577, %fd1546, %fd1578;
	mov.f64 	%fd1580, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1581, %fd1579, %fd1546, %fd1580;
	mov.f64 	%fd1582, 0dBFD555555555544C;
	fma.rn.f64 	%fd1583, %fd1581, %fd1546, %fd1582;
	mul.rn.f64 	%fd1584, %fd1546, %fd1583;
	fma.rn.f64 	%fd1585, %fd1584, %fd1545, %fd1545;
	mov.f64 	%fd1586, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1587, %fd1586, %fd1585;
	setp.gt.f64 	%p377, %fd458, %fd448;
	selp.f64 	%fd1588, %fd1587, %fd1585, %p377;
	mov.f64 	%fd1589, 0d400921FB54442D18;
	sub.rn.f64 	%fd1590, %fd1589, %fd1588;
	selp.f64 	%fd1591, %fd1590, %fd1588, %p320;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r547, %temp}, %fd1591;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r548}, %fd1591;
	}
	and.b32  	%r549, %r110, -2147483648;
	or.b32  	%r550, %r548, %r549;
	mov.b64 	%fd1592, {%r547, %r550};
	add.rn.f64 	%fd1593, %fd448, %fd458;
	setp.le.f64 	%p378, %fd1593, 0d7FF0000000000000;
	selp.f64 	%fd1978, %fd1592, %fd1593, %p378;

$L__BB16_360:
	mul.rn.f64 	%fd486, %fd446, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r559, %temp}, %fd486;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r560}, %fd486;
	}
	and.b32  	%r561, %r560, 2147483647;
	setp.eq.s32 	%p381, %r561, 2146435072;
	setp.eq.s32 	%p382, %r559, 0;
	and.pred  	%p383, %p382, %p381;
	@%p383 bra 	$L__BB16_364;
	bra.uni 	$L__BB16_361;

$L__BB16_364:
	mov.f64 	%fd1605, 0d0000000000000000;
	mul.rn.f64 	%fd1980, %fd486, %fd1605;
	mov.u32 	%r711, 1;
	bra.uni 	$L__BB16_365;

$L__BB16_361:
	mul.rn.f64 	%fd1596, %fd486, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r710, %fd1596;
	st.local.u32 	[%rd1], %r710;
	cvt.rn.f64.s32 	%fd1597, %r710;
	neg.f64 	%fd1598, %fd1597;
	mov.f64 	%fd1599, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1600, %fd1598, %fd1599, %fd486;
	mov.f64 	%fd1601, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1602, %fd1598, %fd1601, %fd1600;
	mov.f64 	%fd1603, 0d397B839A252049C0;
	fma.rn.f64 	%fd1980, %fd1598, %fd1603, %fd1602;
	abs.f64 	%fd1604, %fd486;
	setp.ltu.f64 	%p384, %fd1604, 0d41E0000000000000;
	@%p384 bra 	$L__BB16_363;

	{ // callseq 253, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd486;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1980, [retval0+0];
	} // callseq 253
	ld.local.u32 	%r710, [%rd1];

$L__BB16_363:
	add.s32 	%r711, %r710, 1;

$L__BB16_365:
	and.b32  	%r563, %r711, 1;
	shl.b32 	%r564, %r711, 3;
	and.b32  	%r565, %r564, 8;
	setp.eq.s32 	%p385, %r563, 0;
	selp.f64 	%fd1606, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p385;
	mul.wide.s32 	%rd197, %r565, 8;
	add.s64 	%rd199, %rd82, %rd197;
	ld.global.nc.f64 	%fd1607, [%rd199+8];
	mul.rn.f64 	%fd492, %fd1980, %fd1980;
	fma.rn.f64 	%fd1608, %fd1606, %fd492, %fd1607;
	ld.global.nc.f64 	%fd1609, [%rd199+16];
	fma.rn.f64 	%fd1610, %fd1608, %fd492, %fd1609;
	ld.global.nc.f64 	%fd1611, [%rd199+24];
	fma.rn.f64 	%fd1612, %fd1610, %fd492, %fd1611;
	ld.global.nc.f64 	%fd1613, [%rd199+32];
	fma.rn.f64 	%fd1614, %fd1612, %fd492, %fd1613;
	ld.global.nc.f64 	%fd1615, [%rd199+40];
	fma.rn.f64 	%fd1616, %fd1614, %fd492, %fd1615;
	ld.global.nc.f64 	%fd1617, [%rd199+48];
	fma.rn.f64 	%fd493, %fd1616, %fd492, %fd1617;
	fma.rn.f64 	%fd1982, %fd493, %fd1980, %fd1980;
	@%p385 bra 	$L__BB16_367;

	mov.f64 	%fd1618, 0d3FF0000000000000;
	fma.rn.f64 	%fd1982, %fd493, %fd492, %fd1618;

$L__BB16_367:
	and.b32  	%r566, %r711, 2;
	setp.eq.s32 	%p386, %r566, 0;
	@%p386 bra 	$L__BB16_369;

	mov.f64 	%fd1619, 0d0000000000000000;
	mov.f64 	%fd1620, 0dBFF0000000000000;
	fma.rn.f64 	%fd1982, %fd1982, %fd1620, %fd1619;

$L__BB16_369:
	mul.rn.f64 	%fd1621, %fd1982, 0d3EC92A737110E454;
	add.rn.f64 	%fd499, %fd1978, %fd1621;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r567, %temp}, %fd499;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r568}, %fd499;
	}
	and.b32  	%r569, %r568, 2147483647;
	setp.eq.s32 	%p387, %r569, 2146435072;
	setp.eq.s32 	%p388, %r567, 0;
	and.pred  	%p12, %p388, %p387;
	@%p12 bra 	$L__BB16_373;
	bra.uni 	$L__BB16_370;

$L__BB16_373:
	mov.f64 	%fd1631, 0d0000000000000000;
	mul.rn.f64 	%fd1984, %fd499, %fd1631;
	mov.u32 	%r713, 1;
	bra.uni 	$L__BB16_374;

$L__BB16_370:
	mul.rn.f64 	%fd1622, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r712, %fd1622;
	st.local.u32 	[%rd1], %r712;
	cvt.rn.f64.s32 	%fd1623, %r712;
	neg.f64 	%fd1624, %fd1623;
	mov.f64 	%fd1625, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1626, %fd1624, %fd1625, %fd499;
	mov.f64 	%fd1627, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1628, %fd1624, %fd1627, %fd1626;
	mov.f64 	%fd1629, 0d397B839A252049C0;
	fma.rn.f64 	%fd1984, %fd1624, %fd1629, %fd1628;
	abs.f64 	%fd1630, %fd499;
	setp.ltu.f64 	%p389, %fd1630, 0d41E0000000000000;
	@%p389 bra 	$L__BB16_372;

	{ // callseq 254, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1984, [retval0+0];
	} // callseq 254
	ld.local.u32 	%r712, [%rd1];

$L__BB16_372:
	add.s32 	%r713, %r712, 1;

$L__BB16_374:
	and.b32  	%r571, %r713, 1;
	shl.b32 	%r572, %r713, 3;
	and.b32  	%r573, %r572, 8;
	setp.eq.s32 	%p390, %r571, 0;
	selp.f64 	%fd1632, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p390;
	mul.wide.s32 	%rd201, %r573, 8;
	add.s64 	%rd203, %rd82, %rd201;
	ld.global.nc.f64 	%fd1633, [%rd203+8];
	mul.rn.f64 	%fd505, %fd1984, %fd1984;
	fma.rn.f64 	%fd1634, %fd1632, %fd505, %fd1633;
	ld.global.nc.f64 	%fd1635, [%rd203+16];
	fma.rn.f64 	%fd1636, %fd1634, %fd505, %fd1635;
	ld.global.nc.f64 	%fd1637, [%rd203+24];
	fma.rn.f64 	%fd1638, %fd1636, %fd505, %fd1637;
	ld.global.nc.f64 	%fd1639, [%rd203+32];
	fma.rn.f64 	%fd1640, %fd1638, %fd505, %fd1639;
	ld.global.nc.f64 	%fd1641, [%rd203+40];
	fma.rn.f64 	%fd1642, %fd1640, %fd505, %fd1641;
	ld.global.nc.f64 	%fd1643, [%rd203+48];
	fma.rn.f64 	%fd506, %fd1642, %fd505, %fd1643;
	fma.rn.f64 	%fd1986, %fd506, %fd1984, %fd1984;
	@%p390 bra 	$L__BB16_376;

	mov.f64 	%fd1644, 0d3FF0000000000000;
	fma.rn.f64 	%fd1986, %fd506, %fd505, %fd1644;

$L__BB16_376:
	and.b32  	%r574, %r713, 2;
	setp.eq.s32 	%p391, %r574, 0;
	@%p391 bra 	$L__BB16_378;

	mov.f64 	%fd1645, 0d0000000000000000;
	mov.f64 	%fd1646, 0dBFF0000000000000;
	fma.rn.f64 	%fd1986, %fd1986, %fd1646, %fd1645;

$L__BB16_378:
	mul.rn.f64 	%fd1647, %fd481, %fd1986;
	add.rn.f64 	%fd512, %fd1647, 0d3F7A9FBE76C8B439;
	@%p12 bra 	$L__BB16_381;
	bra.uni 	$L__BB16_379;

$L__BB16_381:
	mov.f64 	%fd1657, 0d0000000000000000;
	mul.rn.f64 	%fd1987, %fd499, %fd1657;
	mov.u32 	%r714, 0;
	bra.uni 	$L__BB16_382;

$L__BB16_379:
	mul.rn.f64 	%fd1648, %fd499, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r714, %fd1648;
	st.local.u32 	[%rd1], %r714;
	cvt.rn.f64.s32 	%fd1649, %r714;
	neg.f64 	%fd1650, %fd1649;
	mov.f64 	%fd1651, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1652, %fd1650, %fd1651, %fd499;
	mov.f64 	%fd1653, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1654, %fd1650, %fd1653, %fd1652;
	mov.f64 	%fd1655, 0d397B839A252049C0;
	fma.rn.f64 	%fd1987, %fd1650, %fd1655, %fd1654;
	abs.f64 	%fd1656, %fd499;
	setp.ltu.f64 	%p392, %fd1656, 0d41E0000000000000;
	@%p392 bra 	$L__BB16_382;

	{ // callseq 255, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd499;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1987, [retval0+0];
	} // callseq 255
	ld.local.u32 	%r714, [%rd1];

$L__BB16_382:
	and.b32  	%r576, %r714, 1;
	shl.b32 	%r577, %r714, 3;
	and.b32  	%r578, %r577, 8;
	setp.eq.s32 	%p393, %r576, 0;
	selp.f64 	%fd1658, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p393;
	mul.wide.s32 	%rd205, %r578, 8;
	add.s64 	%rd207, %rd82, %rd205;
	ld.global.nc.f64 	%fd1659, [%rd207+8];
	mul.rn.f64 	%fd517, %fd1987, %fd1987;
	fma.rn.f64 	%fd1660, %fd1658, %fd517, %fd1659;
	ld.global.nc.f64 	%fd1661, [%rd207+16];
	fma.rn.f64 	%fd1662, %fd1660, %fd517, %fd1661;
	ld.global.nc.f64 	%fd1663, [%rd207+24];
	fma.rn.f64 	%fd1664, %fd1662, %fd517, %fd1663;
	ld.global.nc.f64 	%fd1665, [%rd207+32];
	fma.rn.f64 	%fd1666, %fd1664, %fd517, %fd1665;
	ld.global.nc.f64 	%fd1667, [%rd207+40];
	fma.rn.f64 	%fd1668, %fd1666, %fd517, %fd1667;
	ld.global.nc.f64 	%fd1669, [%rd207+48];
	fma.rn.f64 	%fd518, %fd1668, %fd517, %fd1669;
	fma.rn.f64 	%fd1989, %fd518, %fd1987, %fd1987;
	@%p393 bra 	$L__BB16_384;

	mov.f64 	%fd1670, 0d3FF0000000000000;
	fma.rn.f64 	%fd1989, %fd518, %fd517, %fd1670;

$L__BB16_384:
	and.b32  	%r579, %r714, 2;
	setp.eq.s32 	%p394, %r579, 0;
	@%p394 bra 	$L__BB16_386;

	mov.f64 	%fd1671, 0d0000000000000000;
	mov.f64 	%fd1672, 0dBFF0000000000000;
	fma.rn.f64 	%fd1989, %fd1989, %fd1672, %fd1671;

$L__BB16_386:
	ld.param.s8 	%rs2, [bd09_to_wgs84_exact_cuda_double_param_3];
	mul.rn.f64 	%fd1673, %fd481, %fd1989;
	add.rn.f64 	%fd1674, %fd1673, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd524, %fd3, %fd1674;
	sub.rn.f64 	%fd525, %fd1, %fd512;
	add.rn.f64 	%fd526, %fd2011, %fd525;
	add.rn.f64 	%fd527, %fd2012, %fd524;
	setp.eq.s16 	%p395, %rs2, 0;
	@%p395 bra 	$L__BB16_455;

	mul.rn.f64 	%fd1675, %fd2012, 0d400921FB54442D18;
	div.rn.f64 	%fd528, %fd1675, 0d4066800000000000;
	mul.rn.f64 	%fd1676, %fd527, 0d400921FB54442D18;
	div.rn.f64 	%fd529, %fd1676, 0d4066800000000000;
	sub.rn.f64 	%fd1677, %fd529, %fd528;
	mul.rn.f64 	%fd530, %fd1677, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r580, %temp}, %fd530;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r581}, %fd530;
	}
	and.b32  	%r582, %r581, 2147483647;
	setp.eq.s32 	%p396, %r582, 2146435072;
	setp.eq.s32 	%p397, %r580, 0;
	and.pred  	%p398, %p397, %p396;
	@%p398 bra 	$L__BB16_390;
	bra.uni 	$L__BB16_388;

$L__BB16_390:
	mov.f64 	%fd1687, 0d0000000000000000;
	mul.rn.f64 	%fd1990, %fd530, %fd1687;
	mov.u32 	%r715, 0;
	bra.uni 	$L__BB16_391;

$L__BB16_455:
	abs.f64 	%fd1855, %fd525;
	abs.f64 	%fd1856, %fd524;
	mul.rn.f64 	%fd1857, %fd1856, %fd610;
	setp.lt.f64 	%p476, %fd1855, %fd1857;
	selp.f64 	%fd1858, 0d3FF0000000000000, 0d0000000000000000, %p476;
	setp.lt.f64 	%p477, %fd1858, %fd610;
	@%p477 bra 	$L__BB16_457;
	bra.uni 	$L__BB16_456;

$L__BB16_388:
	mul.rn.f64 	%fd1678, %fd530, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r715, %fd1678;
	st.local.u32 	[%rd1], %r715;
	cvt.rn.f64.s32 	%fd1679, %r715;
	neg.f64 	%fd1680, %fd1679;
	mov.f64 	%fd1681, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1682, %fd1680, %fd1681, %fd530;
	mov.f64 	%fd1683, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1684, %fd1680, %fd1683, %fd1682;
	mov.f64 	%fd1685, 0d397B839A252049C0;
	fma.rn.f64 	%fd1990, %fd1680, %fd1685, %fd1684;
	abs.f64 	%fd1686, %fd530;
	setp.ltu.f64 	%p399, %fd1686, 0d41E0000000000000;
	@%p399 bra 	$L__BB16_391;

	{ // callseq 256, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd530;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1990, [retval0+0];
	} // callseq 256
	ld.local.u32 	%r715, [%rd1];

$L__BB16_391:
	and.b32  	%r584, %r715, 1;
	shl.b32 	%r585, %r715, 3;
	and.b32  	%r586, %r585, 8;
	setp.eq.s32 	%p400, %r584, 0;
	selp.f64 	%fd1688, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p400;
	mul.wide.s32 	%rd209, %r586, 8;
	add.s64 	%rd211, %rd82, %rd209;
	ld.global.nc.f64 	%fd1689, [%rd211+8];
	mul.rn.f64 	%fd535, %fd1990, %fd1990;
	fma.rn.f64 	%fd1690, %fd1688, %fd535, %fd1689;
	ld.global.nc.f64 	%fd1691, [%rd211+16];
	fma.rn.f64 	%fd1692, %fd1690, %fd535, %fd1691;
	ld.global.nc.f64 	%fd1693, [%rd211+24];
	fma.rn.f64 	%fd1694, %fd1692, %fd535, %fd1693;
	ld.global.nc.f64 	%fd1695, [%rd211+32];
	fma.rn.f64 	%fd1696, %fd1694, %fd535, %fd1695;
	ld.global.nc.f64 	%fd1697, [%rd211+40];
	fma.rn.f64 	%fd1698, %fd1696, %fd535, %fd1697;
	ld.global.nc.f64 	%fd1699, [%rd211+48];
	fma.rn.f64 	%fd536, %fd1698, %fd535, %fd1699;
	fma.rn.f64 	%fd1992, %fd536, %fd1990, %fd1990;
	@%p400 bra 	$L__BB16_393;

	mov.f64 	%fd1700, 0d3FF0000000000000;
	fma.rn.f64 	%fd1992, %fd536, %fd535, %fd1700;

$L__BB16_393:
	and.b32  	%r587, %r715, 2;
	setp.eq.s32 	%p401, %r587, 0;
	@%p401 bra 	$L__BB16_395;

	mov.f64 	%fd1701, 0d0000000000000000;
	mov.f64 	%fd1702, 0dBFF0000000000000;
	fma.rn.f64 	%fd1992, %fd1992, %fd1702, %fd1701;

$L__BB16_395:
	abs.f64 	%fd542, %fd1992;
	{ // callseq 257, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd542;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd1995, [retval0+0];
	} // callseq 257
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r130}, %fd1992;
	}
	setp.lt.s32 	%p402, %r130, 0;
	and.pred  	%p13, %p402, %p15;
	not.pred 	%p404, %p13;
	@%p404 bra 	$L__BB16_397;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r588}, %fd1995;
	}
	xor.b32  	%r589, %r588, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r590, %temp}, %fd1995;
	}
	mov.b64 	%fd1995, {%r590, %r589};

$L__BB16_397:
	setp.eq.f64 	%p405, %fd1992, 0d0000000000000000;
	@%p405 bra 	$L__BB16_401;
	bra.uni 	$L__BB16_398;

$L__BB16_401:
	setp.lt.s32 	%p408, %r2, 0;
	mov.u32 	%r591, 0;
	selp.b32 	%r592, %r130, 0, %p15;
	or.b32  	%r593, %r592, 2146435072;
	selp.b32 	%r594, %r593, %r592, %p408;
	mov.b64 	%fd1995, {%r591, %r594};
	bra.uni 	$L__BB16_402;

$L__BB16_398:
	setp.gt.s32 	%p406, %r130, -1;
	@%p406 bra 	$L__BB16_402;

	mov.f64 	%fd1703, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1704, %fd1703;
	setp.eq.f64 	%p407, %fd1704, 0d4000000000000000;
	@%p407 bra 	$L__BB16_402;

	mov.f64 	%fd1995, 0dFFF8000000000000;

$L__BB16_402:
	add.rn.f64 	%fd1706, %fd1992, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r595}, %fd1706;
	}
	and.b32  	%r596, %r595, 2146435072;
	setp.ne.s32 	%p410, %r596, 2146435072;
	@%p410 bra 	$L__BB16_409;

	setp.gtu.f64 	%p411, %fd542, 0d7FF0000000000000;
	@%p411 bra 	$L__BB16_408;
	bra.uni 	$L__BB16_404;

$L__BB16_408:
	mov.f64 	%fd1708, 0d4000000000000000;
	add.rn.f64 	%fd1995, %fd1992, %fd1708;
	bra.uni 	$L__BB16_409;

$L__BB16_404:
	setp.eq.s32 	%p412, %r65, 2146435072;
	mov.f64 	%fd1707, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r597, %temp}, %fd1707;
	}
	setp.eq.s32 	%p413, %r597, 0;
	and.pred  	%p414, %p412, %p413;
	@%p414 bra 	$L__BB16_407;
	bra.uni 	$L__BB16_405;

$L__BB16_407:
	setp.lt.s32 	%p420, %r2, 0;
	mov.u32 	%r602, 0;
	setp.gt.f64 	%p421, %fd542, 0d3FF0000000000000;
	selp.b32 	%r603, 2146435072, 0, %p421;
	xor.b32  	%r604, %r603, 2146435072;
	selp.b32 	%r605, %r604, %r603, %p420;
	setp.eq.f64 	%p422, %fd1992, 0dBFF0000000000000;
	selp.b32 	%r606, 1072693248, %r605, %p422;
	mov.b64 	%fd1995, {%r602, %r606};
	bra.uni 	$L__BB16_409;

$L__BB16_405:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r598, %temp}, %fd1992;
	}
	and.b32  	%r599, %r130, 2147483647;
	setp.ne.s32 	%p415, %r599, 2146435072;
	setp.ne.s32 	%p416, %r598, 0;
	or.pred  	%p417, %p415, %p416;
	@%p417 bra 	$L__BB16_409;

	setp.ne.s32 	%p418, %r65, 1071644672;
	and.pred  	%p419, %p418, %p13;
	selp.b32 	%r600, %r67, %r66, %p419;
	mov.u32 	%r601, 0;
	mov.b64 	%fd1995, {%r601, %r600};

$L__BB16_409:
	setp.eq.f64 	%p423, %fd1992, 0d3FF0000000000000;
	selp.f64 	%fd552, 0d3FF0000000000000, %fd1995, %p423;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r607}, %fd528;
	}
	and.b32  	%r608, %r607, 2147483647;
	setp.eq.s32 	%p424, %r608, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r609, %temp}, %fd528;
	}
	setp.eq.s32 	%p425, %r609, 0;
	and.pred  	%p426, %p425, %p424;
	@%p426 bra 	$L__BB16_413;
	bra.uni 	$L__BB16_410;

$L__BB16_413:
	mov.f64 	%fd1718, 0d0000000000000000;
	mul.rn.f64 	%fd1997, %fd528, %fd1718;
	mov.u32 	%r717, 1;
	bra.uni 	$L__BB16_414;

$L__BB16_410:
	mul.rn.f64 	%fd1709, %fd528, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r716, %fd1709;
	st.local.u32 	[%rd1], %r716;
	cvt.rn.f64.s32 	%fd1710, %r716;
	neg.f64 	%fd1711, %fd1710;
	mov.f64 	%fd1712, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1713, %fd1711, %fd1712, %fd528;
	mov.f64 	%fd1714, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1715, %fd1711, %fd1714, %fd1713;
	mov.f64 	%fd1716, 0d397B839A252049C0;
	fma.rn.f64 	%fd1997, %fd1711, %fd1716, %fd1715;
	abs.f64 	%fd1717, %fd528;
	setp.ltu.f64 	%p427, %fd1717, 0d41E0000000000000;
	@%p427 bra 	$L__BB16_412;

	{ // callseq 258, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd528;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd1997, [retval0+0];
	} // callseq 258
	ld.local.u32 	%r716, [%rd1];

$L__BB16_412:
	add.s32 	%r717, %r716, 1;

$L__BB16_414:
	and.b32  	%r611, %r717, 1;
	shl.b32 	%r612, %r717, 3;
	and.b32  	%r613, %r612, 8;
	setp.eq.s32 	%p428, %r611, 0;
	selp.f64 	%fd1719, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p428;
	mul.wide.s32 	%rd213, %r613, 8;
	add.s64 	%rd215, %rd82, %rd213;
	ld.global.nc.f64 	%fd1720, [%rd215+8];
	mul.rn.f64 	%fd558, %fd1997, %fd1997;
	fma.rn.f64 	%fd1721, %fd1719, %fd558, %fd1720;
	ld.global.nc.f64 	%fd1722, [%rd215+16];
	fma.rn.f64 	%fd1723, %fd1721, %fd558, %fd1722;
	ld.global.nc.f64 	%fd1724, [%rd215+24];
	fma.rn.f64 	%fd1725, %fd1723, %fd558, %fd1724;
	ld.global.nc.f64 	%fd1726, [%rd215+32];
	fma.rn.f64 	%fd1727, %fd1725, %fd558, %fd1726;
	ld.global.nc.f64 	%fd1728, [%rd215+40];
	fma.rn.f64 	%fd1729, %fd1727, %fd558, %fd1728;
	ld.global.nc.f64 	%fd1730, [%rd215+48];
	fma.rn.f64 	%fd559, %fd1729, %fd558, %fd1730;
	fma.rn.f64 	%fd1999, %fd559, %fd1997, %fd1997;
	@%p428 bra 	$L__BB16_416;

	mov.f64 	%fd1731, 0d3FF0000000000000;
	fma.rn.f64 	%fd1999, %fd559, %fd558, %fd1731;

$L__BB16_416:
	and.b32  	%r614, %r717, 2;
	setp.eq.s32 	%p429, %r614, 0;
	@%p429 bra 	$L__BB16_418;

	mov.f64 	%fd1732, 0d0000000000000000;
	mov.f64 	%fd1733, 0dBFF0000000000000;
	fma.rn.f64 	%fd1999, %fd1999, %fd1733, %fd1732;

$L__BB16_418:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r615}, %fd529;
	}
	and.b32  	%r616, %r615, 2147483647;
	setp.eq.s32 	%p430, %r616, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r617, %temp}, %fd529;
	}
	setp.eq.s32 	%p431, %r617, 0;
	and.pred  	%p432, %p431, %p430;
	@%p432 bra 	$L__BB16_422;
	bra.uni 	$L__BB16_419;

$L__BB16_422:
	mov.f64 	%fd1743, 0d0000000000000000;
	mul.rn.f64 	%fd2001, %fd529, %fd1743;
	mov.u32 	%r719, 1;
	bra.uni 	$L__BB16_423;

$L__BB16_419:
	mul.rn.f64 	%fd1734, %fd529, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r718, %fd1734;
	st.local.u32 	[%rd1], %r718;
	cvt.rn.f64.s32 	%fd1735, %r718;
	neg.f64 	%fd1736, %fd1735;
	mov.f64 	%fd1737, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1738, %fd1736, %fd1737, %fd529;
	mov.f64 	%fd1739, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1740, %fd1736, %fd1739, %fd1738;
	mov.f64 	%fd1741, 0d397B839A252049C0;
	fma.rn.f64 	%fd2001, %fd1736, %fd1741, %fd1740;
	abs.f64 	%fd1742, %fd529;
	setp.ltu.f64 	%p433, %fd1742, 0d41E0000000000000;
	@%p433 bra 	$L__BB16_421;

	{ // callseq 259, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd529;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd2001, [retval0+0];
	} // callseq 259
	ld.local.u32 	%r718, [%rd1];

$L__BB16_421:
	add.s32 	%r719, %r718, 1;

$L__BB16_423:
	and.b32  	%r619, %r719, 1;
	shl.b32 	%r620, %r719, 3;
	and.b32  	%r621, %r620, 8;
	setp.eq.s32 	%p434, %r619, 0;
	selp.f64 	%fd1744, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p434;
	mul.wide.s32 	%rd217, %r621, 8;
	add.s64 	%rd219, %rd82, %rd217;
	ld.global.nc.f64 	%fd1745, [%rd219+8];
	mul.rn.f64 	%fd570, %fd2001, %fd2001;
	fma.rn.f64 	%fd1746, %fd1744, %fd570, %fd1745;
	ld.global.nc.f64 	%fd1747, [%rd219+16];
	fma.rn.f64 	%fd1748, %fd1746, %fd570, %fd1747;
	ld.global.nc.f64 	%fd1749, [%rd219+24];
	fma.rn.f64 	%fd1750, %fd1748, %fd570, %fd1749;
	ld.global.nc.f64 	%fd1751, [%rd219+32];
	fma.rn.f64 	%fd1752, %fd1750, %fd570, %fd1751;
	ld.global.nc.f64 	%fd1753, [%rd219+40];
	fma.rn.f64 	%fd1754, %fd1752, %fd570, %fd1753;
	ld.global.nc.f64 	%fd1755, [%rd219+48];
	fma.rn.f64 	%fd571, %fd1754, %fd570, %fd1755;
	fma.rn.f64 	%fd2003, %fd571, %fd2001, %fd2001;
	@%p434 bra 	$L__BB16_425;

	mov.f64 	%fd1756, 0d3FF0000000000000;
	fma.rn.f64 	%fd2003, %fd571, %fd570, %fd1756;

$L__BB16_425:
	and.b32  	%r622, %r719, 2;
	setp.eq.s32 	%p435, %r622, 0;
	@%p435 bra 	$L__BB16_427;

	mov.f64 	%fd1757, 0d0000000000000000;
	mov.f64 	%fd1758, 0dBFF0000000000000;
	fma.rn.f64 	%fd2003, %fd2003, %fd1758, %fd1757;

$L__BB16_427:
	mul.rn.f64 	%fd577, %fd1999, %fd2003;
	mul.rn.f64 	%fd1759, %fd2011, 0d400921FB54442D18;
	div.rn.f64 	%fd1760, %fd1759, 0d4066800000000000;
	mul.rn.f64 	%fd1761, %fd526, 0d400921FB54442D18;
	div.rn.f64 	%fd1762, %fd1761, 0d4066800000000000;
	sub.rn.f64 	%fd1763, %fd1762, %fd1760;
	mul.rn.f64 	%fd578, %fd1763, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r623, %temp}, %fd578;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r624}, %fd578;
	}
	and.b32  	%r625, %r624, 2147483647;
	setp.eq.s32 	%p436, %r625, 2146435072;
	setp.eq.s32 	%p437, %r623, 0;
	and.pred  	%p438, %p437, %p436;
	@%p438 bra 	$L__BB16_430;
	bra.uni 	$L__BB16_428;

$L__BB16_430:
	mov.f64 	%fd1773, 0d0000000000000000;
	mul.rn.f64 	%fd2004, %fd578, %fd1773;
	mov.u32 	%r720, 0;
	bra.uni 	$L__BB16_431;

$L__BB16_428:
	mul.rn.f64 	%fd1764, %fd578, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r720, %fd1764;
	st.local.u32 	[%rd1], %r720;
	cvt.rn.f64.s32 	%fd1765, %r720;
	neg.f64 	%fd1766, %fd1765;
	mov.f64 	%fd1767, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd1768, %fd1766, %fd1767, %fd578;
	mov.f64 	%fd1769, 0d3C91A62633145C00;
	fma.rn.f64 	%fd1770, %fd1766, %fd1769, %fd1768;
	mov.f64 	%fd1771, 0d397B839A252049C0;
	fma.rn.f64 	%fd2004, %fd1766, %fd1771, %fd1770;
	abs.f64 	%fd1772, %fd578;
	setp.ltu.f64 	%p439, %fd1772, 0d41E0000000000000;
	@%p439 bra 	$L__BB16_431;

	{ // callseq 260, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd578;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd42;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd2004, [retval0+0];
	} // callseq 260
	ld.local.u32 	%r720, [%rd1];

$L__BB16_431:
	and.b32  	%r627, %r720, 1;
	shl.b32 	%r628, %r720, 3;
	and.b32  	%r629, %r628, 8;
	setp.eq.s32 	%p440, %r627, 0;
	selp.f64 	%fd1774, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p440;
	mul.wide.s32 	%rd221, %r629, 8;
	add.s64 	%rd223, %rd82, %rd221;
	ld.global.nc.f64 	%fd1775, [%rd223+8];
	mul.rn.f64 	%fd583, %fd2004, %fd2004;
	fma.rn.f64 	%fd1776, %fd1774, %fd583, %fd1775;
	ld.global.nc.f64 	%fd1777, [%rd223+16];
	fma.rn.f64 	%fd1778, %fd1776, %fd583, %fd1777;
	ld.global.nc.f64 	%fd1779, [%rd223+24];
	fma.rn.f64 	%fd1780, %fd1778, %fd583, %fd1779;
	ld.global.nc.f64 	%fd1781, [%rd223+32];
	fma.rn.f64 	%fd1782, %fd1780, %fd583, %fd1781;
	ld.global.nc.f64 	%fd1783, [%rd223+40];
	fma.rn.f64 	%fd1784, %fd1782, %fd583, %fd1783;
	ld.global.nc.f64 	%fd1785, [%rd223+48];
	fma.rn.f64 	%fd584, %fd1784, %fd583, %fd1785;
	fma.rn.f64 	%fd2006, %fd584, %fd2004, %fd2004;
	@%p440 bra 	$L__BB16_433;

	mov.f64 	%fd1786, 0d3FF0000000000000;
	fma.rn.f64 	%fd2006, %fd584, %fd583, %fd1786;

$L__BB16_433:
	and.b32  	%r630, %r720, 2;
	setp.eq.s32 	%p441, %r630, 0;
	@%p441 bra 	$L__BB16_435;

	mov.f64 	%fd1787, 0d0000000000000000;
	mov.f64 	%fd1788, 0dBFF0000000000000;
	fma.rn.f64 	%fd2006, %fd2006, %fd1788, %fd1787;

$L__BB16_435:
	abs.f64 	%fd590, %fd2006;
	{ // callseq 261, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd590;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd2009, [retval0+0];
	} // callseq 261
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r144}, %fd2006;
	}
	setp.lt.s32 	%p442, %r144, 0;
	and.pred  	%p14, %p442, %p15;
	not.pred 	%p444, %p14;
	@%p444 bra 	$L__BB16_437;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r631}, %fd2009;
	}
	xor.b32  	%r632, %r631, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r633, %temp}, %fd2009;
	}
	mov.b64 	%fd2009, {%r633, %r632};

$L__BB16_437:
	setp.eq.f64 	%p445, %fd2006, 0d0000000000000000;
	@%p445 bra 	$L__BB16_441;
	bra.uni 	$L__BB16_438;

$L__BB16_441:
	setp.lt.s32 	%p448, %r2, 0;
	mov.u32 	%r634, 0;
	selp.b32 	%r635, %r144, 0, %p15;
	or.b32  	%r636, %r635, 2146435072;
	selp.b32 	%r637, %r636, %r635, %p448;
	mov.b64 	%fd2009, {%r634, %r637};
	bra.uni 	$L__BB16_442;

$L__BB16_438:
	setp.gt.s32 	%p446, %r144, -1;
	@%p446 bra 	$L__BB16_442;

	mov.f64 	%fd1789, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd1790, %fd1789;
	setp.eq.f64 	%p447, %fd1790, 0d4000000000000000;
	@%p447 bra 	$L__BB16_442;

	mov.f64 	%fd2009, 0dFFF8000000000000;

$L__BB16_442:
	add.rn.f64 	%fd1792, %fd2006, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r638}, %fd1792;
	}
	and.b32  	%r639, %r638, 2146435072;
	setp.ne.s32 	%p450, %r639, 2146435072;
	@%p450 bra 	$L__BB16_449;

	setp.gtu.f64 	%p451, %fd590, 0d7FF0000000000000;
	@%p451 bra 	$L__BB16_448;
	bra.uni 	$L__BB16_444;

$L__BB16_448:
	mov.f64 	%fd1794, 0d4000000000000000;
	add.rn.f64 	%fd2009, %fd2006, %fd1794;
	bra.uni 	$L__BB16_449;

$L__BB16_444:
	setp.eq.s32 	%p452, %r65, 2146435072;
	mov.f64 	%fd1793, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r640, %temp}, %fd1793;
	}
	setp.eq.s32 	%p453, %r640, 0;
	and.pred  	%p454, %p452, %p453;
	@%p454 bra 	$L__BB16_447;
	bra.uni 	$L__BB16_445;

$L__BB16_447:
	setp.lt.s32 	%p460, %r2, 0;
	mov.u32 	%r645, 0;
	setp.gt.f64 	%p461, %fd590, 0d3FF0000000000000;
	selp.b32 	%r646, 2146435072, 0, %p461;
	xor.b32  	%r647, %r646, 2146435072;
	selp.b32 	%r648, %r647, %r646, %p460;
	setp.eq.f64 	%p462, %fd2006, 0dBFF0000000000000;
	selp.b32 	%r649, 1072693248, %r648, %p462;
	mov.b64 	%fd2009, {%r645, %r649};
	bra.uni 	$L__BB16_449;

$L__BB16_445:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r641, %temp}, %fd2006;
	}
	and.b32  	%r642, %r144, 2147483647;
	setp.ne.s32 	%p455, %r642, 2146435072;
	setp.ne.s32 	%p456, %r641, 0;
	or.pred  	%p457, %p455, %p456;
	@%p457 bra 	$L__BB16_449;

	setp.ne.s32 	%p458, %r65, 1071644672;
	and.pred  	%p459, %p458, %p14;
	selp.b32 	%r643, %r67, %r66, %p459;
	mov.u32 	%r644, 0;
	mov.b64 	%fd2009, {%r644, %r643};

$L__BB16_449:
	setp.eq.f64 	%p463, %fd2006, 0d3FF0000000000000;
	mov.f64 	%fd1795, 0d3FF0000000000000;
	selp.f64 	%fd1796, 0d3FF0000000000000, %fd2009, %p463;
	mul.rn.f64 	%fd1797, %fd577, %fd1796;
	add.rn.f64 	%fd1798, %fd552, %fd1797;
	sqrt.rn.f64 	%fd600, %fd1798;
	sub.rn.f64 	%fd1799, %fd1795, %fd1798;
	sqrt.rn.f64 	%fd601, %fd1799;
	abs.f64 	%fd602, %fd601;
	abs.f64 	%fd603, %fd600;
	setp.eq.f64 	%p464, %fd602, 0d0000000000000000;
	setp.eq.f64 	%p465, %fd603, 0d0000000000000000;
	and.pred  	%p466, %p464, %p465;
	@%p466 bra 	$L__BB16_453;
	bra.uni 	$L__BB16_450;

$L__BB16_453:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r662}, %fd601;
	}
	setp.lt.s32 	%p474, %r662, 0;
	selp.f64 	%fd1852, 0d400921FB54442D18, 0d0000000000000000, %p474;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r663, %temp}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r664}, %fd1852;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r665}, %fd600;
	}
	and.b32  	%r666, %r665, -2147483648;
	or.b32  	%r667, %r664, %r666;
	mov.b64 	%fd2010, {%r663, %r667};
	bra.uni 	$L__BB16_454;

$L__BB16_450:
	setp.eq.f64 	%p467, %fd602, 0d7FF0000000000000;
	setp.eq.f64 	%p468, %fd603, 0d7FF0000000000000;
	and.pred  	%p469, %p467, %p468;
	@%p469 bra 	$L__BB16_452;
	bra.uni 	$L__BB16_451;

$L__BB16_452:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r656}, %fd601;
	}
	setp.lt.s32 	%p473, %r656, 0;
	selp.f64 	%fd1851, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p473;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r657, %temp}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r658}, %fd1851;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r659}, %fd600;
	}
	and.b32  	%r660, %r659, -2147483648;
	or.b32  	%r661, %r658, %r660;
	mov.b64 	%fd2010, {%r657, %r661};
	bra.uni 	$L__BB16_454;

$L__BB16_451:
	max.f64 	%fd1800, %fd603, %fd602;
	min.f64 	%fd1801, %fd603, %fd602;
	div.rn.f64 	%fd1802, %fd1801, %fd1800;
	mul.rn.f64 	%fd1803, %fd1802, %fd1802;
	mov.f64 	%fd1804, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd1805, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd1806, %fd1805, %fd1803, %fd1804;
	mov.f64 	%fd1807, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd1808, %fd1806, %fd1803, %fd1807;
	mov.f64 	%fd1809, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd1810, %fd1808, %fd1803, %fd1809;
	mov.f64 	%fd1811, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd1812, %fd1810, %fd1803, %fd1811;
	mov.f64 	%fd1813, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd1814, %fd1812, %fd1803, %fd1813;
	mov.f64 	%fd1815, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd1816, %fd1814, %fd1803, %fd1815;
	mov.f64 	%fd1817, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd1818, %fd1816, %fd1803, %fd1817;
	mov.f64 	%fd1819, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd1820, %fd1818, %fd1803, %fd1819;
	mov.f64 	%fd1821, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd1822, %fd1820, %fd1803, %fd1821;
	mov.f64 	%fd1823, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd1824, %fd1822, %fd1803, %fd1823;
	mov.f64 	%fd1825, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd1826, %fd1824, %fd1803, %fd1825;
	mov.f64 	%fd1827, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd1828, %fd1826, %fd1803, %fd1827;
	mov.f64 	%fd1829, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd1830, %fd1828, %fd1803, %fd1829;
	mov.f64 	%fd1831, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd1832, %fd1830, %fd1803, %fd1831;
	mov.f64 	%fd1833, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd1834, %fd1832, %fd1803, %fd1833;
	mov.f64 	%fd1835, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd1836, %fd1834, %fd1803, %fd1835;
	mov.f64 	%fd1837, 0d3FC99999999840D2;
	fma.rn.f64 	%fd1838, %fd1836, %fd1803, %fd1837;
	mov.f64 	%fd1839, 0dBFD555555555544C;
	fma.rn.f64 	%fd1840, %fd1838, %fd1803, %fd1839;
	mul.rn.f64 	%fd1841, %fd1803, %fd1840;
	fma.rn.f64 	%fd1842, %fd1841, %fd1802, %fd1802;
	mov.f64 	%fd1843, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd1844, %fd1843, %fd1842;
	setp.gt.f64 	%p470, %fd603, %fd602;
	selp.f64 	%fd1845, %fd1844, %fd1842, %p470;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r650}, %fd601;
	}
	setp.lt.s32 	%p471, %r650, 0;
	mov.f64 	%fd1846, 0d400921FB54442D18;
	sub.rn.f64 	%fd1847, %fd1846, %fd1845;
	selp.f64 	%fd1848, %fd1847, %fd1845, %p471;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r651, %temp}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r652}, %fd1848;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r653}, %fd600;
	}
	and.b32  	%r654, %r653, -2147483648;
	or.b32  	%r655, %r652, %r654;
	mov.b64 	%fd1849, {%r651, %r655};
	add.rn.f64 	%fd1850, %fd602, %fd603;
	setp.le.f64 	%p472, %fd1850, 0d7FF0000000000000;
	selp.f64 	%fd2010, %fd1849, %fd1850, %p472;

$L__BB16_454:
	add.rn.f64 	%fd1853, %fd2010, %fd2010;
	mul.rn.f64 	%fd1854, %fd1853, 0d415854A640000000;
	setp.lt.f64 	%p475, %fd1854, %fd610;
	@%p475 bra 	$L__BB16_457;

$L__BB16_456:
	add.s32 	%r695, %r695, 1;
	setp.lt.s32 	%p478, %r695, %r146;
	mov.f64 	%fd2012, %fd527;
	mov.f64 	%fd2011, %fd526;
	@%p478 bra 	$L__BB16_194;

$L__BB16_457:
	ld.param.u64 	%rd231, [bd09_to_wgs84_exact_cuda_double_param_1];
	mov.u32 	%r675, %tid.x;
	mov.u32 	%r674, %ntid.x;
	mov.u32 	%r673, %ctaid.x;
	mad.lo.s32 	%r672, %r673, %r674, %r675;
	mul.wide.s32 	%rd230, %r672, 8;
	cvta.to.global.u64 	%rd229, %rd231;
	add.s64 	%rd228, %rd229, %rd230;
	ld.param.u64 	%rd227, [bd09_to_wgs84_exact_cuda_double_param_0];
	mov.u32 	%r671, %tid.x;
	mov.u32 	%r670, %ntid.x;
	mov.u32 	%r669, %ctaid.x;
	mad.lo.s32 	%r668, %r669, %r670, %r671;
	mul.wide.s32 	%rd226, %r668, 8;
	cvta.to.global.u64 	%rd225, %rd227;
	add.s64 	%rd224, %rd225, %rd226;
	st.global.f64 	[%rd224], %fd2011;
	st.global.f64 	[%rd228], %fd2012;
	ret;

}
	// .globl	bd09_to_gcj02_exact_cuda_double
.visible .entry bd09_to_gcj02_exact_cuda_double(
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_0,
	.param .u64 bd09_to_gcj02_exact_cuda_double_param_1,
	.param .f64 bd09_to_gcj02_exact_cuda_double_param_2,
	.param .u8 bd09_to_gcj02_exact_cuda_double_param_3,
	.param .u32 bd09_to_gcj02_exact_cuda_double_param_4
)
{
	.local .align 4 .b8 	__local_depot17[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<247>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<349>;
	.reg .f64 	%fd<843>;
	.reg .b64 	%rd<88>;


	mov.u64 	%SPL, __local_depot17;
	cvta.local.u64 	%SP, %SPL;
	ld.param.u64 	%rd15, [bd09_to_gcj02_exact_cuda_double_param_0];
	ld.param.u64 	%rd16, [bd09_to_gcj02_exact_cuda_double_param_1];
	ld.param.f64 	%fd246, [bd09_to_gcj02_exact_cuda_double_param_2];
	cvta.to.global.u64 	%rd17, %rd16;
	add.u64 	%rd18, %SP, 0;
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r65, %ntid.x;
	mov.u32 	%r66, %ctaid.x;
	mov.u32 	%r67, %tid.x;
	mad.lo.s32 	%r68, %r66, %r65, %r67;
	cvta.to.global.u64 	%rd30, %rd15;
	mul.wide.s32 	%rd31, %r68, 8;
	add.s64 	%rd13, %rd30, %rd31;
	add.s64 	%rd14, %rd17, %rd31;
	ld.global.f64 	%fd1, [%rd13];
	add.rn.f64 	%fd2, %fd1, 0dBF7A9FBE76C8B439;
	ld.global.f64 	%fd3, [%rd14];
	add.rn.f64 	%fd4, %fd3, 0dBF789374BC6A7EFA;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd2;
	}
	mov.f64 	%fd247, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r2}, %fd247;
	}
	and.b32  	%r3, %r2, 2146435072;
	setp.eq.s32 	%p9, %r3, 1062207488;
	abs.f64 	%fd5, %fd2;
	{ // callseq 262, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd5;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd778, [retval0+0];
	} // callseq 262
	setp.lt.s32 	%p10, %r1, 0;
	and.pred  	%p1, %p10, %p9;
	not.pred 	%p11, %p1;
	@%p11 bra 	$L__BB17_2;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r69}, %fd778;
	}
	xor.b32  	%r70, %r69, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r71, %temp}, %fd778;
	}
	mov.b64 	%fd778, {%r71, %r70};

$L__BB17_2:
	setp.eq.f64 	%p12, %fd2, 0d0000000000000000;
	@%p12 bra 	$L__BB17_6;
	bra.uni 	$L__BB17_3;

$L__BB17_6:
	selp.b32 	%r72, %r1, 0, %p9;
	mov.u32 	%r73, 0;
	or.b32  	%r74, %r72, 2146435072;
	setp.lt.s32 	%p16, %r2, 0;
	selp.b32 	%r75, %r74, %r72, %p16;
	mov.b64 	%fd778, {%r73, %r75};
	bra.uni 	$L__BB17_7;

$L__BB17_3:
	setp.gt.s32 	%p13, %r1, -1;
	@%p13 bra 	$L__BB17_7;

	mov.f64 	%fd248, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd249, %fd248;
	setp.eq.f64 	%p14, %fd249, 0d4000000000000000;
	@%p14 bra 	$L__BB17_7;

	mov.f64 	%fd778, 0dFFF8000000000000;

$L__BB17_7:
	add.rn.f64 	%fd251, %fd2, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r76}, %fd251;
	}
	and.b32  	%r77, %r76, 2146435072;
	setp.ne.s32 	%p17, %r77, 2146435072;
	@%p17 bra 	$L__BB17_14;

	setp.gtu.f64 	%p18, %fd5, 0d7FF0000000000000;
	@%p18 bra 	$L__BB17_13;
	bra.uni 	$L__BB17_9;

$L__BB17_13:
	mov.f64 	%fd253, 0d4000000000000000;
	add.rn.f64 	%fd778, %fd2, %fd253;
	bra.uni 	$L__BB17_14;

$L__BB17_9:
	mov.f64 	%fd252, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r78, %temp}, %fd252;
	}
	and.b32  	%r4, %r2, 2147483647;
	setp.eq.s32 	%p19, %r4, 2146435072;
	setp.eq.s32 	%p20, %r78, 0;
	and.pred  	%p21, %p19, %p20;
	@%p21 bra 	$L__BB17_12;
	bra.uni 	$L__BB17_10;

$L__BB17_12:
	setp.gt.f64 	%p28, %fd5, 0d3FF0000000000000;
	selp.b32 	%r85, 2146435072, 0, %p28;
	mov.u32 	%r86, 0;
	xor.b32  	%r87, %r85, 2146435072;
	setp.lt.s32 	%p29, %r2, 0;
	selp.b32 	%r88, %r87, %r85, %p29;
	setp.eq.f64 	%p30, %fd2, 0dBFF0000000000000;
	selp.b32 	%r89, 1072693248, %r88, %p30;
	mov.b64 	%fd778, {%r86, %r89};
	bra.uni 	$L__BB17_14;

$L__BB17_10:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r79, %temp}, %fd2;
	}
	and.b32  	%r80, %r1, 2147483647;
	setp.ne.s32 	%p22, %r80, 2146435072;
	setp.ne.s32 	%p23, %r79, 0;
	or.pred  	%p24, %p22, %p23;
	@%p24 bra 	$L__BB17_14;

	setp.gt.s32 	%p25, %r2, -1;
	selp.b32 	%r81, 2146435072, 0, %p25;
	mov.u32 	%r82, 0;
	setp.ne.s32 	%p26, %r4, 1071644672;
	and.pred  	%p27, %p26, %p1;
	or.b32  	%r83, %r81, -2147483648;
	selp.b32 	%r84, %r83, %r81, %p27;
	mov.b64 	%fd778, {%r82, %r84};

$L__BB17_14:
	abs.f64 	%fd15, %fd4;
	{ // callseq 263, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd15;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd781, [retval0+0];
	} // callseq 263
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r5}, %fd4;
	}
	setp.lt.s32 	%p31, %r5, 0;
	and.pred  	%p2, %p31, %p9;
	not.pred 	%p33, %p2;
	@%p33 bra 	$L__BB17_16;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r90}, %fd781;
	}
	xor.b32  	%r91, %r90, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r92, %temp}, %fd781;
	}
	mov.b64 	%fd781, {%r92, %r91};

$L__BB17_16:
	setp.eq.f64 	%p34, %fd4, 0d0000000000000000;
	@%p34 bra 	$L__BB17_20;
	bra.uni 	$L__BB17_17;

$L__BB17_20:
	selp.b32 	%r93, %r5, 0, %p9;
	mov.u32 	%r94, 0;
	or.b32  	%r95, %r93, 2146435072;
	setp.lt.s32 	%p38, %r2, 0;
	selp.b32 	%r96, %r95, %r93, %p38;
	mov.b64 	%fd781, {%r94, %r96};
	bra.uni 	$L__BB17_21;

$L__BB17_17:
	setp.gt.s32 	%p35, %r5, -1;
	@%p35 bra 	$L__BB17_21;

	mov.f64 	%fd254, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd255, %fd254;
	setp.eq.f64 	%p36, %fd255, 0d4000000000000000;
	@%p36 bra 	$L__BB17_21;

	mov.f64 	%fd781, 0dFFF8000000000000;

$L__BB17_21:
	add.rn.f64 	%fd257, %fd4, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r97}, %fd257;
	}
	and.b32  	%r98, %r97, 2146435072;
	setp.ne.s32 	%p39, %r98, 2146435072;
	@%p39 bra 	$L__BB17_28;

	setp.gtu.f64 	%p40, %fd15, 0d7FF0000000000000;
	@%p40 bra 	$L__BB17_27;
	bra.uni 	$L__BB17_23;

$L__BB17_27:
	mov.f64 	%fd259, 0d4000000000000000;
	add.rn.f64 	%fd781, %fd4, %fd259;
	bra.uni 	$L__BB17_28;

$L__BB17_23:
	mov.f64 	%fd258, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r99, %temp}, %fd258;
	}
	and.b32  	%r6, %r2, 2147483647;
	setp.eq.s32 	%p41, %r6, 2146435072;
	setp.eq.s32 	%p42, %r99, 0;
	and.pred  	%p43, %p41, %p42;
	@%p43 bra 	$L__BB17_26;
	bra.uni 	$L__BB17_24;

$L__BB17_26:
	setp.gt.f64 	%p50, %fd15, 0d3FF0000000000000;
	selp.b32 	%r106, 2146435072, 0, %p50;
	mov.u32 	%r107, 0;
	xor.b32  	%r108, %r106, 2146435072;
	setp.lt.s32 	%p51, %r2, 0;
	selp.b32 	%r109, %r108, %r106, %p51;
	setp.eq.f64 	%p52, %fd4, 0dBFF0000000000000;
	selp.b32 	%r110, 1072693248, %r109, %p52;
	mov.b64 	%fd781, {%r107, %r110};
	bra.uni 	$L__BB17_28;

$L__BB17_24:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r100, %temp}, %fd4;
	}
	and.b32  	%r101, %r5, 2147483647;
	setp.ne.s32 	%p44, %r101, 2146435072;
	setp.ne.s32 	%p45, %r100, 0;
	or.pred  	%p46, %p44, %p45;
	@%p46 bra 	$L__BB17_28;

	setp.gt.s32 	%p47, %r2, -1;
	selp.b32 	%r102, 2146435072, 0, %p47;
	mov.u32 	%r103, 0;
	setp.ne.s32 	%p48, %r6, 1071644672;
	and.pred  	%p49, %p48, %p2;
	or.b32  	%r104, %r102, -2147483648;
	selp.b32 	%r105, %r104, %r102, %p49;
	mov.b64 	%fd781, {%r103, %r105};

$L__BB17_28:
	setp.eq.f64 	%p53, %fd4, 0d3FF0000000000000;
	selp.f64 	%fd260, 0d3FF0000000000000, %fd781, %p53;
	setp.eq.f64 	%p54, %fd2, 0d3FF0000000000000;
	selp.f64 	%fd261, 0d3FF0000000000000, %fd778, %p54;
	add.rn.f64 	%fd25, %fd261, %fd260;
	mul.rn.f64 	%fd26, %fd4, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r111, %temp}, %fd26;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r112}, %fd26;
	}
	and.b32  	%r113, %r112, 2147483647;
	setp.eq.s32 	%p55, %r113, 2146435072;
	setp.eq.s32 	%p56, %r111, 0;
	and.pred  	%p57, %p56, %p55;
	@%p57 bra 	$L__BB17_31;
	bra.uni 	$L__BB17_29;

$L__BB17_31:
	mov.f64 	%fd271, 0d0000000000000000;
	mul.rn.f64 	%fd782, %fd26, %fd271;
	mov.u32 	%r330, 0;
	bra.uni 	$L__BB17_32;

$L__BB17_29:
	mul.rn.f64 	%fd262, %fd26, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r330, %fd262;
	st.local.u32 	[%rd1], %r330;
	cvt.rn.f64.s32 	%fd263, %r330;
	neg.f64 	%fd264, %fd263;
	mov.f64 	%fd265, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd266, %fd264, %fd265, %fd26;
	mov.f64 	%fd267, 0d3C91A62633145C00;
	fma.rn.f64 	%fd268, %fd264, %fd267, %fd266;
	mov.f64 	%fd269, 0d397B839A252049C0;
	fma.rn.f64 	%fd782, %fd264, %fd269, %fd268;
	abs.f64 	%fd270, %fd26;
	setp.ltu.f64 	%p58, %fd270, 0d41E0000000000000;
	@%p58 bra 	$L__BB17_32;

	{ // callseq 264, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd26;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd782, [retval0+0];
	} // callseq 264
	ld.local.u32 	%r330, [%rd1];

$L__BB17_32:
	and.b32  	%r115, %r330, 1;
	shl.b32 	%r116, %r330, 3;
	and.b32  	%r117, %r116, 8;
	setp.eq.s32 	%p59, %r115, 0;
	selp.f64 	%fd272, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p59;
	mul.wide.s32 	%rd33, %r117, 8;
	mov.u64 	%rd34, __cudart_sin_cos_coeffs;
	add.s64 	%rd35, %rd34, %rd33;
	ld.global.nc.f64 	%fd273, [%rd35+8];
	mul.rn.f64 	%fd31, %fd782, %fd782;
	fma.rn.f64 	%fd274, %fd272, %fd31, %fd273;
	ld.global.nc.f64 	%fd275, [%rd35+16];
	fma.rn.f64 	%fd276, %fd274, %fd31, %fd275;
	ld.global.nc.f64 	%fd277, [%rd35+24];
	fma.rn.f64 	%fd278, %fd276, %fd31, %fd277;
	ld.global.nc.f64 	%fd279, [%rd35+32];
	fma.rn.f64 	%fd280, %fd278, %fd31, %fd279;
	ld.global.nc.f64 	%fd281, [%rd35+40];
	fma.rn.f64 	%fd282, %fd280, %fd31, %fd281;
	ld.global.nc.f64 	%fd283, [%rd35+48];
	fma.rn.f64 	%fd32, %fd282, %fd31, %fd283;
	fma.rn.f64 	%fd784, %fd32, %fd782, %fd782;
	@%p59 bra 	$L__BB17_34;

	mov.f64 	%fd284, 0d3FF0000000000000;
	fma.rn.f64 	%fd784, %fd32, %fd31, %fd284;

$L__BB17_34:
	and.b32  	%r118, %r330, 2;
	setp.eq.s32 	%p60, %r118, 0;
	@%p60 bra 	$L__BB17_36;

	mov.f64 	%fd285, 0d0000000000000000;
	mov.f64 	%fd286, 0dBFF0000000000000;
	fma.rn.f64 	%fd784, %fd784, %fd286, %fd285;

$L__BB17_36:
	mul.rn.f64 	%fd287, %fd784, 0dBEF4F8B588E368F1;
	sqrt.rn.f64 	%fd288, %fd25;
	add.rn.f64 	%fd38, %fd288, %fd287;
	setp.eq.f64 	%p61, %fd15, 0d0000000000000000;
	setp.eq.f64 	%p62, %fd5, 0d0000000000000000;
	and.pred  	%p63, %p62, %p61;
	@%p63 bra 	$L__BB17_40;
	bra.uni 	$L__BB17_37;

$L__BB17_40:
	selp.f64 	%fd341, 0d400921FB54442D18, 0d0000000000000000, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r127, %temp}, %fd341;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r128}, %fd341;
	}
	and.b32  	%r129, %r5, -2147483648;
	or.b32  	%r130, %r128, %r129;
	mov.b64 	%fd785, {%r127, %r130};
	bra.uni 	$L__BB17_41;

$L__BB17_37:
	setp.eq.f64 	%p64, %fd5, 0d7FF0000000000000;
	setp.eq.f64 	%p65, %fd15, 0d7FF0000000000000;
	and.pred  	%p66, %p64, %p65;
	@%p66 bra 	$L__BB17_39;
	bra.uni 	$L__BB17_38;

$L__BB17_39:
	selp.f64 	%fd340, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r123, %temp}, %fd340;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r124}, %fd340;
	}
	and.b32  	%r125, %r5, -2147483648;
	or.b32  	%r126, %r124, %r125;
	mov.b64 	%fd785, {%r123, %r126};
	bra.uni 	$L__BB17_41;

$L__BB17_38:
	min.f64 	%fd289, %fd15, %fd5;
	max.f64 	%fd290, %fd15, %fd5;
	div.rn.f64 	%fd291, %fd289, %fd290;
	mul.rn.f64 	%fd292, %fd291, %fd291;
	mov.f64 	%fd293, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd294, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd295, %fd294, %fd292, %fd293;
	mov.f64 	%fd296, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd297, %fd295, %fd292, %fd296;
	mov.f64 	%fd298, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd299, %fd297, %fd292, %fd298;
	mov.f64 	%fd300, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd301, %fd299, %fd292, %fd300;
	mov.f64 	%fd302, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd303, %fd301, %fd292, %fd302;
	mov.f64 	%fd304, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd305, %fd303, %fd292, %fd304;
	mov.f64 	%fd306, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd307, %fd305, %fd292, %fd306;
	mov.f64 	%fd308, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd309, %fd307, %fd292, %fd308;
	mov.f64 	%fd310, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd311, %fd309, %fd292, %fd310;
	mov.f64 	%fd312, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd313, %fd311, %fd292, %fd312;
	mov.f64 	%fd314, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd315, %fd313, %fd292, %fd314;
	mov.f64 	%fd316, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd317, %fd315, %fd292, %fd316;
	mov.f64 	%fd318, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd319, %fd317, %fd292, %fd318;
	mov.f64 	%fd320, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd321, %fd319, %fd292, %fd320;
	mov.f64 	%fd322, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd323, %fd321, %fd292, %fd322;
	mov.f64 	%fd324, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd325, %fd323, %fd292, %fd324;
	mov.f64 	%fd326, 0d3FC99999999840D2;
	fma.rn.f64 	%fd327, %fd325, %fd292, %fd326;
	mov.f64 	%fd328, 0dBFD555555555544C;
	fma.rn.f64 	%fd329, %fd327, %fd292, %fd328;
	mul.rn.f64 	%fd330, %fd292, %fd329;
	fma.rn.f64 	%fd331, %fd330, %fd291, %fd291;
	mov.f64 	%fd332, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd333, %fd332, %fd331;
	setp.gt.f64 	%p68, %fd15, %fd5;
	selp.f64 	%fd334, %fd333, %fd331, %p68;
	mov.f64 	%fd335, 0d400921FB54442D18;
	sub.rn.f64 	%fd336, %fd335, %fd334;
	selp.f64 	%fd337, %fd336, %fd334, %p10;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r119, %temp}, %fd337;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r120}, %fd337;
	}
	and.b32  	%r121, %r5, -2147483648;
	or.b32  	%r122, %r120, %r121;
	mov.b64 	%fd338, {%r119, %r122};
	add.rn.f64 	%fd339, %fd5, %fd15;
	setp.le.f64 	%p69, %fd339, 0d7FF0000000000000;
	selp.f64 	%fd785, %fd338, %fd339, %p69;

$L__BB17_41:
	add.rn.f64 	%fd775, %fd1, 0dBF7A9FBE76C8B439;
	mul.rn.f64 	%fd43, %fd775, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r131, %temp}, %fd43;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r132}, %fd43;
	}
	and.b32  	%r133, %r132, 2147483647;
	setp.eq.s32 	%p72, %r133, 2146435072;
	setp.eq.s32 	%p73, %r131, 0;
	and.pred  	%p74, %p73, %p72;
	@%p74 bra 	$L__BB17_45;
	bra.uni 	$L__BB17_42;

$L__BB17_45:
	mov.f64 	%fd351, 0d0000000000000000;
	mul.rn.f64 	%fd787, %fd43, %fd351;
	mov.u32 	%r332, 1;
	bra.uni 	$L__BB17_46;

$L__BB17_42:
	mul.rn.f64 	%fd342, %fd43, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r331, %fd342;
	st.local.u32 	[%rd1], %r331;
	cvt.rn.f64.s32 	%fd343, %r331;
	neg.f64 	%fd344, %fd343;
	mov.f64 	%fd345, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd346, %fd344, %fd345, %fd43;
	mov.f64 	%fd347, 0d3C91A62633145C00;
	fma.rn.f64 	%fd348, %fd344, %fd347, %fd346;
	mov.f64 	%fd349, 0d397B839A252049C0;
	fma.rn.f64 	%fd787, %fd344, %fd349, %fd348;
	abs.f64 	%fd350, %fd43;
	setp.ltu.f64 	%p75, %fd350, 0d41E0000000000000;
	@%p75 bra 	$L__BB17_44;

	{ // callseq 265, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd43;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd787, [retval0+0];
	} // callseq 265
	ld.local.u32 	%r331, [%rd1];

$L__BB17_44:
	add.s32 	%r332, %r331, 1;

$L__BB17_46:
	and.b32  	%r135, %r332, 1;
	shl.b32 	%r136, %r332, 3;
	and.b32  	%r137, %r136, 8;
	setp.eq.s32 	%p76, %r135, 0;
	selp.f64 	%fd352, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p76;
	mul.wide.s32 	%rd37, %r137, 8;
	add.s64 	%rd39, %rd34, %rd37;
	ld.global.nc.f64 	%fd353, [%rd39+8];
	mul.rn.f64 	%fd49, %fd787, %fd787;
	fma.rn.f64 	%fd354, %fd352, %fd49, %fd353;
	ld.global.nc.f64 	%fd355, [%rd39+16];
	fma.rn.f64 	%fd356, %fd354, %fd49, %fd355;
	ld.global.nc.f64 	%fd357, [%rd39+24];
	fma.rn.f64 	%fd358, %fd356, %fd49, %fd357;
	ld.global.nc.f64 	%fd359, [%rd39+32];
	fma.rn.f64 	%fd360, %fd358, %fd49, %fd359;
	ld.global.nc.f64 	%fd361, [%rd39+40];
	fma.rn.f64 	%fd362, %fd360, %fd49, %fd361;
	ld.global.nc.f64 	%fd363, [%rd39+48];
	fma.rn.f64 	%fd50, %fd362, %fd49, %fd363;
	fma.rn.f64 	%fd789, %fd50, %fd787, %fd787;
	@%p76 bra 	$L__BB17_48;

	mov.f64 	%fd364, 0d3FF0000000000000;
	fma.rn.f64 	%fd789, %fd50, %fd49, %fd364;

$L__BB17_48:
	and.b32  	%r138, %r332, 2;
	setp.eq.s32 	%p77, %r138, 0;
	@%p77 bra 	$L__BB17_50;

	mov.f64 	%fd365, 0d0000000000000000;
	mov.f64 	%fd366, 0dBFF0000000000000;
	fma.rn.f64 	%fd789, %fd789, %fd366, %fd365;

$L__BB17_50:
	mul.rn.f64 	%fd367, %fd789, 0dBEC92A737110E454;
	add.rn.f64 	%fd56, %fd785, %fd367;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r139, %temp}, %fd56;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r140}, %fd56;
	}
	and.b32  	%r141, %r140, 2147483647;
	setp.eq.s32 	%p78, %r141, 2146435072;
	setp.eq.s32 	%p79, %r139, 0;
	and.pred  	%p3, %p79, %p78;
	@%p3 bra 	$L__BB17_54;
	bra.uni 	$L__BB17_51;

$L__BB17_54:
	mov.f64 	%fd377, 0d0000000000000000;
	mul.rn.f64 	%fd791, %fd56, %fd377;
	mov.u32 	%r334, 1;
	bra.uni 	$L__BB17_55;

$L__BB17_51:
	mul.rn.f64 	%fd368, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r333, %fd368;
	st.local.u32 	[%rd1], %r333;
	cvt.rn.f64.s32 	%fd369, %r333;
	neg.f64 	%fd370, %fd369;
	mov.f64 	%fd371, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd372, %fd370, %fd371, %fd56;
	mov.f64 	%fd373, 0d3C91A62633145C00;
	fma.rn.f64 	%fd374, %fd370, %fd373, %fd372;
	mov.f64 	%fd375, 0d397B839A252049C0;
	fma.rn.f64 	%fd791, %fd370, %fd375, %fd374;
	abs.f64 	%fd376, %fd56;
	setp.ltu.f64 	%p80, %fd376, 0d41E0000000000000;
	@%p80 bra 	$L__BB17_53;

	{ // callseq 266, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd791, [retval0+0];
	} // callseq 266
	ld.local.u32 	%r333, [%rd1];

$L__BB17_53:
	add.s32 	%r334, %r333, 1;

$L__BB17_55:
	and.b32  	%r143, %r334, 1;
	shl.b32 	%r144, %r334, 3;
	and.b32  	%r145, %r144, 8;
	setp.eq.s32 	%p81, %r143, 0;
	selp.f64 	%fd378, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p81;
	mul.wide.s32 	%rd41, %r145, 8;
	add.s64 	%rd43, %rd34, %rd41;
	ld.global.nc.f64 	%fd379, [%rd43+8];
	mul.rn.f64 	%fd62, %fd791, %fd791;
	fma.rn.f64 	%fd380, %fd378, %fd62, %fd379;
	ld.global.nc.f64 	%fd381, [%rd43+16];
	fma.rn.f64 	%fd382, %fd380, %fd62, %fd381;
	ld.global.nc.f64 	%fd383, [%rd43+24];
	fma.rn.f64 	%fd384, %fd382, %fd62, %fd383;
	ld.global.nc.f64 	%fd385, [%rd43+32];
	fma.rn.f64 	%fd386, %fd384, %fd62, %fd385;
	ld.global.nc.f64 	%fd387, [%rd43+40];
	fma.rn.f64 	%fd388, %fd386, %fd62, %fd387;
	ld.global.nc.f64 	%fd389, [%rd43+48];
	fma.rn.f64 	%fd63, %fd388, %fd62, %fd389;
	fma.rn.f64 	%fd793, %fd63, %fd791, %fd791;
	@%p81 bra 	$L__BB17_57;

	mov.f64 	%fd390, 0d3FF0000000000000;
	fma.rn.f64 	%fd793, %fd63, %fd62, %fd390;

$L__BB17_57:
	and.b32  	%r146, %r334, 2;
	setp.eq.s32 	%p82, %r146, 0;
	@%p82 bra 	$L__BB17_59;

	mov.f64 	%fd391, 0d0000000000000000;
	mov.f64 	%fd392, 0dBFF0000000000000;
	fma.rn.f64 	%fd793, %fd793, %fd392, %fd391;

$L__BB17_59:
	mul.rn.f64 	%fd841, %fd38, %fd793;
	@%p3 bra 	$L__BB17_62;
	bra.uni 	$L__BB17_60;

$L__BB17_62:
	mov.f64 	%fd402, 0d0000000000000000;
	mul.rn.f64 	%fd794, %fd56, %fd402;
	mov.u32 	%r335, 0;
	bra.uni 	$L__BB17_63;

$L__BB17_60:
	mul.rn.f64 	%fd393, %fd56, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r335, %fd393;
	st.local.u32 	[%rd1], %r335;
	cvt.rn.f64.s32 	%fd394, %r335;
	neg.f64 	%fd395, %fd394;
	mov.f64 	%fd396, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd397, %fd395, %fd396, %fd56;
	mov.f64 	%fd398, 0d3C91A62633145C00;
	fma.rn.f64 	%fd399, %fd395, %fd398, %fd397;
	mov.f64 	%fd400, 0d397B839A252049C0;
	fma.rn.f64 	%fd794, %fd395, %fd400, %fd399;
	abs.f64 	%fd401, %fd56;
	setp.ltu.f64 	%p83, %fd401, 0d41E0000000000000;
	@%p83 bra 	$L__BB17_63;

	{ // callseq 267, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd56;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd794, [retval0+0];
	} // callseq 267
	ld.local.u32 	%r335, [%rd1];

$L__BB17_63:
	and.b32  	%r148, %r335, 1;
	shl.b32 	%r149, %r335, 3;
	and.b32  	%r150, %r149, 8;
	setp.eq.s32 	%p84, %r148, 0;
	selp.f64 	%fd403, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p84;
	mul.wide.s32 	%rd45, %r150, 8;
	add.s64 	%rd47, %rd34, %rd45;
	ld.global.nc.f64 	%fd404, [%rd47+8];
	mul.rn.f64 	%fd74, %fd794, %fd794;
	fma.rn.f64 	%fd405, %fd403, %fd74, %fd404;
	ld.global.nc.f64 	%fd406, [%rd47+16];
	fma.rn.f64 	%fd407, %fd405, %fd74, %fd406;
	ld.global.nc.f64 	%fd408, [%rd47+24];
	fma.rn.f64 	%fd409, %fd407, %fd74, %fd408;
	ld.global.nc.f64 	%fd410, [%rd47+32];
	fma.rn.f64 	%fd411, %fd409, %fd74, %fd410;
	ld.global.nc.f64 	%fd412, [%rd47+40];
	fma.rn.f64 	%fd413, %fd411, %fd74, %fd412;
	ld.global.nc.f64 	%fd414, [%rd47+48];
	fma.rn.f64 	%fd75, %fd413, %fd74, %fd414;
	fma.rn.f64 	%fd796, %fd75, %fd794, %fd794;
	@%p84 bra 	$L__BB17_65;

	mov.f64 	%fd415, 0d3FF0000000000000;
	fma.rn.f64 	%fd796, %fd75, %fd74, %fd415;

$L__BB17_65:
	and.b32  	%r151, %r335, 2;
	setp.eq.s32 	%p85, %r151, 0;
	@%p85 bra 	$L__BB17_67;

	mov.f64 	%fd416, 0d0000000000000000;
	mov.f64 	%fd417, 0dBFF0000000000000;
	fma.rn.f64 	%fd796, %fd796, %fd417, %fd416;

$L__BB17_67:
	ld.param.u32 	%r329, [bd09_to_gcj02_exact_cuda_double_param_4];
	mul.rn.f64 	%fd842, %fd38, %fd796;
	setp.lt.s32 	%p86, %r329, 1;
	@%p86 bra 	$L__BB17_207;

	and.b32  	%r23, %r2, 2147483647;
	setp.gt.s32 	%p87, %r2, -1;
	selp.b32 	%r24, 2146435072, 0, %p87;
	mov.u32 	%r336, 0;
	or.b32  	%r25, %r24, -2147483648;

$L__BB17_69:
	abs.f64 	%fd84, %fd841;
	{ // callseq 268, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd84;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd801, [retval0+0];
	} // callseq 268
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd841;
	}
	setp.lt.s32 	%p88, %r27, 0;
	and.pred  	%p4, %p88, %p9;
	not.pred 	%p90, %p4;
	@%p90 bra 	$L__BB17_71;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r153}, %fd801;
	}
	xor.b32  	%r154, %r153, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r155, %temp}, %fd801;
	}
	mov.b64 	%fd801, {%r155, %r154};

$L__BB17_71:
	setp.eq.f64 	%p91, %fd841, 0d0000000000000000;
	@%p91 bra 	$L__BB17_75;
	bra.uni 	$L__BB17_72;

$L__BB17_75:
	setp.lt.s32 	%p94, %r2, 0;
	mov.u32 	%r156, 0;
	selp.b32 	%r157, %r27, 0, %p9;
	or.b32  	%r158, %r157, 2146435072;
	selp.b32 	%r159, %r158, %r157, %p94;
	mov.b64 	%fd801, {%r156, %r159};
	bra.uni 	$L__BB17_76;

$L__BB17_72:
	setp.gt.s32 	%p92, %r27, -1;
	@%p92 bra 	$L__BB17_76;

	mov.f64 	%fd418, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd419, %fd418;
	setp.eq.f64 	%p93, %fd419, 0d4000000000000000;
	@%p93 bra 	$L__BB17_76;

	mov.f64 	%fd801, 0dFFF8000000000000;

$L__BB17_76:
	add.rn.f64 	%fd421, %fd841, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r160}, %fd421;
	}
	and.b32  	%r161, %r160, 2146435072;
	setp.ne.s32 	%p96, %r161, 2146435072;
	@%p96 bra 	$L__BB17_83;

	setp.gtu.f64 	%p97, %fd84, 0d7FF0000000000000;
	@%p97 bra 	$L__BB17_82;
	bra.uni 	$L__BB17_78;

$L__BB17_82:
	mov.f64 	%fd423, 0d4000000000000000;
	add.rn.f64 	%fd801, %fd841, %fd423;
	bra.uni 	$L__BB17_83;

$L__BB17_78:
	setp.eq.s32 	%p98, %r23, 2146435072;
	mov.f64 	%fd422, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r162, %temp}, %fd422;
	}
	setp.eq.s32 	%p99, %r162, 0;
	and.pred  	%p100, %p98, %p99;
	@%p100 bra 	$L__BB17_81;
	bra.uni 	$L__BB17_79;

$L__BB17_81:
	setp.lt.s32 	%p106, %r2, 0;
	mov.u32 	%r167, 0;
	setp.gt.f64 	%p107, %fd84, 0d3FF0000000000000;
	selp.b32 	%r168, 2146435072, 0, %p107;
	xor.b32  	%r169, %r168, 2146435072;
	selp.b32 	%r170, %r169, %r168, %p106;
	setp.eq.f64 	%p108, %fd841, 0dBFF0000000000000;
	selp.b32 	%r171, 1072693248, %r170, %p108;
	mov.b64 	%fd801, {%r167, %r171};
	bra.uni 	$L__BB17_83;

$L__BB17_79:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r163, %temp}, %fd841;
	}
	and.b32  	%r164, %r27, 2147483647;
	setp.ne.s32 	%p101, %r164, 2146435072;
	setp.ne.s32 	%p102, %r163, 0;
	or.pred  	%p103, %p101, %p102;
	@%p103 bra 	$L__BB17_83;

	setp.ne.s32 	%p104, %r23, 1071644672;
	and.pred  	%p105, %p104, %p4;
	selp.b32 	%r165, %r25, %r24, %p105;
	mov.u32 	%r166, 0;
	mov.b64 	%fd801, {%r166, %r165};

$L__BB17_83:
	abs.f64 	%fd94, %fd842;
	{ // callseq 269, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd94;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd804, [retval0+0];
	} // callseq 269
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd842;
	}
	setp.lt.s32 	%p109, %r28, 0;
	and.pred  	%p5, %p109, %p9;
	not.pred 	%p111, %p5;
	@%p111 bra 	$L__BB17_85;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r172}, %fd804;
	}
	xor.b32  	%r173, %r172, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r174, %temp}, %fd804;
	}
	mov.b64 	%fd804, {%r174, %r173};

$L__BB17_85:
	setp.eq.f64 	%p112, %fd842, 0d0000000000000000;
	@%p112 bra 	$L__BB17_89;
	bra.uni 	$L__BB17_86;

$L__BB17_89:
	setp.lt.s32 	%p115, %r2, 0;
	mov.u32 	%r175, 0;
	selp.b32 	%r176, %r28, 0, %p9;
	or.b32  	%r177, %r176, 2146435072;
	selp.b32 	%r178, %r177, %r176, %p115;
	mov.b64 	%fd804, {%r175, %r178};
	bra.uni 	$L__BB17_90;

$L__BB17_86:
	setp.gt.s32 	%p113, %r28, -1;
	@%p113 bra 	$L__BB17_90;

	mov.f64 	%fd424, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd425, %fd424;
	setp.eq.f64 	%p114, %fd425, 0d4000000000000000;
	@%p114 bra 	$L__BB17_90;

	mov.f64 	%fd804, 0dFFF8000000000000;

$L__BB17_90:
	add.rn.f64 	%fd427, %fd842, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r179}, %fd427;
	}
	and.b32  	%r180, %r179, 2146435072;
	setp.ne.s32 	%p117, %r180, 2146435072;
	@%p117 bra 	$L__BB17_97;

	setp.gtu.f64 	%p118, %fd94, 0d7FF0000000000000;
	@%p118 bra 	$L__BB17_96;
	bra.uni 	$L__BB17_92;

$L__BB17_96:
	mov.f64 	%fd429, 0d4000000000000000;
	add.rn.f64 	%fd804, %fd842, %fd429;
	bra.uni 	$L__BB17_97;

$L__BB17_92:
	setp.eq.s32 	%p119, %r23, 2146435072;
	mov.f64 	%fd428, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r181, %temp}, %fd428;
	}
	setp.eq.s32 	%p120, %r181, 0;
	and.pred  	%p121, %p119, %p120;
	@%p121 bra 	$L__BB17_95;
	bra.uni 	$L__BB17_93;

$L__BB17_95:
	setp.lt.s32 	%p127, %r2, 0;
	mov.u32 	%r186, 0;
	setp.gt.f64 	%p128, %fd94, 0d3FF0000000000000;
	selp.b32 	%r187, 2146435072, 0, %p128;
	xor.b32  	%r188, %r187, 2146435072;
	selp.b32 	%r189, %r188, %r187, %p127;
	setp.eq.f64 	%p129, %fd842, 0dBFF0000000000000;
	selp.b32 	%r190, 1072693248, %r189, %p129;
	mov.b64 	%fd804, {%r186, %r190};
	bra.uni 	$L__BB17_97;

$L__BB17_93:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r182, %temp}, %fd842;
	}
	and.b32  	%r183, %r28, 2147483647;
	setp.ne.s32 	%p122, %r183, 2146435072;
	setp.ne.s32 	%p123, %r182, 0;
	or.pred  	%p124, %p122, %p123;
	@%p124 bra 	$L__BB17_97;

	setp.ne.s32 	%p125, %r23, 1071644672;
	and.pred  	%p126, %p125, %p5;
	selp.b32 	%r184, %r25, %r24, %p126;
	mov.u32 	%r185, 0;
	mov.b64 	%fd804, {%r185, %r184};

$L__BB17_97:
	setp.eq.f64 	%p130, %fd842, 0d3FF0000000000000;
	selp.f64 	%fd430, 0d3FF0000000000000, %fd804, %p130;
	setp.eq.f64 	%p131, %fd841, 0d3FF0000000000000;
	selp.f64 	%fd431, 0d3FF0000000000000, %fd801, %p131;
	add.rn.f64 	%fd104, %fd431, %fd430;
	mul.rn.f64 	%fd105, %fd842, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r191, %temp}, %fd105;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r192}, %fd105;
	}
	and.b32  	%r193, %r192, 2147483647;
	setp.eq.s32 	%p132, %r193, 2146435072;
	setp.eq.s32 	%p133, %r191, 0;
	and.pred  	%p134, %p133, %p132;
	@%p134 bra 	$L__BB17_100;
	bra.uni 	$L__BB17_98;

$L__BB17_100:
	mov.f64 	%fd441, 0d0000000000000000;
	mul.rn.f64 	%fd805, %fd105, %fd441;
	mov.u32 	%r337, 0;
	bra.uni 	$L__BB17_101;

$L__BB17_98:
	mul.rn.f64 	%fd432, %fd105, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r337, %fd432;
	st.local.u32 	[%rd1], %r337;
	cvt.rn.f64.s32 	%fd433, %r337;
	neg.f64 	%fd434, %fd433;
	mov.f64 	%fd435, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd436, %fd434, %fd435, %fd105;
	mov.f64 	%fd437, 0d3C91A62633145C00;
	fma.rn.f64 	%fd438, %fd434, %fd437, %fd436;
	mov.f64 	%fd439, 0d397B839A252049C0;
	fma.rn.f64 	%fd805, %fd434, %fd439, %fd438;
	abs.f64 	%fd440, %fd105;
	setp.ltu.f64 	%p135, %fd440, 0d41E0000000000000;
	@%p135 bra 	$L__BB17_101;

	{ // callseq 270, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd105;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd805, [retval0+0];
	} // callseq 270
	ld.local.u32 	%r337, [%rd1];

$L__BB17_101:
	and.b32  	%r195, %r337, 1;
	shl.b32 	%r196, %r337, 3;
	and.b32  	%r197, %r196, 8;
	setp.eq.s32 	%p136, %r195, 0;
	selp.f64 	%fd442, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p136;
	mul.wide.s32 	%rd49, %r197, 8;
	add.s64 	%rd51, %rd34, %rd49;
	ld.global.nc.f64 	%fd443, [%rd51+8];
	mul.rn.f64 	%fd110, %fd805, %fd805;
	fma.rn.f64 	%fd444, %fd442, %fd110, %fd443;
	ld.global.nc.f64 	%fd445, [%rd51+16];
	fma.rn.f64 	%fd446, %fd444, %fd110, %fd445;
	ld.global.nc.f64 	%fd447, [%rd51+24];
	fma.rn.f64 	%fd448, %fd446, %fd110, %fd447;
	ld.global.nc.f64 	%fd449, [%rd51+32];
	fma.rn.f64 	%fd450, %fd448, %fd110, %fd449;
	ld.global.nc.f64 	%fd451, [%rd51+40];
	fma.rn.f64 	%fd452, %fd450, %fd110, %fd451;
	ld.global.nc.f64 	%fd453, [%rd51+48];
	fma.rn.f64 	%fd111, %fd452, %fd110, %fd453;
	fma.rn.f64 	%fd807, %fd111, %fd805, %fd805;
	@%p136 bra 	$L__BB17_103;

	mov.f64 	%fd454, 0d3FF0000000000000;
	fma.rn.f64 	%fd807, %fd111, %fd110, %fd454;

$L__BB17_103:
	and.b32  	%r198, %r337, 2;
	setp.eq.s32 	%p137, %r198, 0;
	@%p137 bra 	$L__BB17_105;

	mov.f64 	%fd455, 0d0000000000000000;
	mov.f64 	%fd456, 0dBFF0000000000000;
	fma.rn.f64 	%fd807, %fd807, %fd456, %fd455;

$L__BB17_105:
	mul.rn.f64 	%fd457, %fd807, 0d3EF4F8B588E368F1;
	sqrt.rn.f64 	%fd458, %fd104;
	add.rn.f64 	%fd117, %fd458, %fd457;
	setp.eq.f64 	%p138, %fd94, 0d0000000000000000;
	setp.eq.f64 	%p139, %fd84, 0d0000000000000000;
	and.pred  	%p140, %p139, %p138;
	@%p140 bra 	$L__BB17_109;
	bra.uni 	$L__BB17_106;

$L__BB17_109:
	selp.f64 	%fd511, 0d400921FB54442D18, 0d0000000000000000, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r207, %temp}, %fd511;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r208}, %fd511;
	}
	and.b32  	%r209, %r28, -2147483648;
	or.b32  	%r210, %r208, %r209;
	mov.b64 	%fd808, {%r207, %r210};
	bra.uni 	$L__BB17_110;

$L__BB17_106:
	setp.eq.f64 	%p141, %fd84, 0d7FF0000000000000;
	setp.eq.f64 	%p142, %fd94, 0d7FF0000000000000;
	and.pred  	%p143, %p141, %p142;
	@%p143 bra 	$L__BB17_108;
	bra.uni 	$L__BB17_107;

$L__BB17_108:
	selp.f64 	%fd510, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r203, %temp}, %fd510;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r204}, %fd510;
	}
	and.b32  	%r205, %r28, -2147483648;
	or.b32  	%r206, %r204, %r205;
	mov.b64 	%fd808, {%r203, %r206};
	bra.uni 	$L__BB17_110;

$L__BB17_107:
	min.f64 	%fd459, %fd94, %fd84;
	max.f64 	%fd460, %fd94, %fd84;
	div.rn.f64 	%fd461, %fd459, %fd460;
	mul.rn.f64 	%fd462, %fd461, %fd461;
	mov.f64 	%fd463, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd464, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd465, %fd464, %fd462, %fd463;
	mov.f64 	%fd466, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd467, %fd465, %fd462, %fd466;
	mov.f64 	%fd468, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd469, %fd467, %fd462, %fd468;
	mov.f64 	%fd470, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd471, %fd469, %fd462, %fd470;
	mov.f64 	%fd472, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd473, %fd471, %fd462, %fd472;
	mov.f64 	%fd474, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd475, %fd473, %fd462, %fd474;
	mov.f64 	%fd476, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd477, %fd475, %fd462, %fd476;
	mov.f64 	%fd478, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd479, %fd477, %fd462, %fd478;
	mov.f64 	%fd480, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd481, %fd479, %fd462, %fd480;
	mov.f64 	%fd482, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd483, %fd481, %fd462, %fd482;
	mov.f64 	%fd484, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd485, %fd483, %fd462, %fd484;
	mov.f64 	%fd486, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd487, %fd485, %fd462, %fd486;
	mov.f64 	%fd488, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd489, %fd487, %fd462, %fd488;
	mov.f64 	%fd490, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd491, %fd489, %fd462, %fd490;
	mov.f64 	%fd492, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd493, %fd491, %fd462, %fd492;
	mov.f64 	%fd494, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd495, %fd493, %fd462, %fd494;
	mov.f64 	%fd496, 0d3FC99999999840D2;
	fma.rn.f64 	%fd497, %fd495, %fd462, %fd496;
	mov.f64 	%fd498, 0dBFD555555555544C;
	fma.rn.f64 	%fd499, %fd497, %fd462, %fd498;
	mul.rn.f64 	%fd500, %fd462, %fd499;
	fma.rn.f64 	%fd501, %fd500, %fd461, %fd461;
	mov.f64 	%fd502, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd503, %fd502, %fd501;
	setp.gt.f64 	%p145, %fd94, %fd84;
	selp.f64 	%fd504, %fd503, %fd501, %p145;
	mov.f64 	%fd505, 0d400921FB54442D18;
	sub.rn.f64 	%fd506, %fd505, %fd504;
	selp.f64 	%fd507, %fd506, %fd504, %p88;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r199, %temp}, %fd507;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r200}, %fd507;
	}
	and.b32  	%r201, %r28, -2147483648;
	or.b32  	%r202, %r200, %r201;
	mov.b64 	%fd508, {%r199, %r202};
	add.rn.f64 	%fd509, %fd84, %fd94;
	setp.le.f64 	%p146, %fd509, 0d7FF0000000000000;
	selp.f64 	%fd808, %fd508, %fd509, %p146;

$L__BB17_110:
	mul.rn.f64 	%fd122, %fd841, 0d404A2E1077C7044E;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r211, %temp}, %fd122;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r212}, %fd122;
	}
	and.b32  	%r213, %r212, 2147483647;
	setp.eq.s32 	%p149, %r213, 2146435072;
	setp.eq.s32 	%p150, %r211, 0;
	and.pred  	%p151, %p150, %p149;
	@%p151 bra 	$L__BB17_114;
	bra.uni 	$L__BB17_111;

$L__BB17_114:
	mov.f64 	%fd521, 0d0000000000000000;
	mul.rn.f64 	%fd810, %fd122, %fd521;
	mov.u32 	%r339, 1;
	bra.uni 	$L__BB17_115;

$L__BB17_111:
	mul.rn.f64 	%fd512, %fd122, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r338, %fd512;
	st.local.u32 	[%rd1], %r338;
	cvt.rn.f64.s32 	%fd513, %r338;
	neg.f64 	%fd514, %fd513;
	mov.f64 	%fd515, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd516, %fd514, %fd515, %fd122;
	mov.f64 	%fd517, 0d3C91A62633145C00;
	fma.rn.f64 	%fd518, %fd514, %fd517, %fd516;
	mov.f64 	%fd519, 0d397B839A252049C0;
	fma.rn.f64 	%fd810, %fd514, %fd519, %fd518;
	abs.f64 	%fd520, %fd122;
	setp.ltu.f64 	%p152, %fd520, 0d41E0000000000000;
	@%p152 bra 	$L__BB17_113;

	{ // callseq 271, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd122;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd810, [retval0+0];
	} // callseq 271
	ld.local.u32 	%r338, [%rd1];

$L__BB17_113:
	add.s32 	%r339, %r338, 1;

$L__BB17_115:
	and.b32  	%r215, %r339, 1;
	shl.b32 	%r216, %r339, 3;
	and.b32  	%r217, %r216, 8;
	setp.eq.s32 	%p153, %r215, 0;
	selp.f64 	%fd522, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p153;
	mul.wide.s32 	%rd53, %r217, 8;
	add.s64 	%rd55, %rd34, %rd53;
	ld.global.nc.f64 	%fd523, [%rd55+8];
	mul.rn.f64 	%fd128, %fd810, %fd810;
	fma.rn.f64 	%fd524, %fd522, %fd128, %fd523;
	ld.global.nc.f64 	%fd525, [%rd55+16];
	fma.rn.f64 	%fd526, %fd524, %fd128, %fd525;
	ld.global.nc.f64 	%fd527, [%rd55+24];
	fma.rn.f64 	%fd528, %fd526, %fd128, %fd527;
	ld.global.nc.f64 	%fd529, [%rd55+32];
	fma.rn.f64 	%fd530, %fd528, %fd128, %fd529;
	ld.global.nc.f64 	%fd531, [%rd55+40];
	fma.rn.f64 	%fd532, %fd530, %fd128, %fd531;
	ld.global.nc.f64 	%fd533, [%rd55+48];
	fma.rn.f64 	%fd129, %fd532, %fd128, %fd533;
	fma.rn.f64 	%fd812, %fd129, %fd810, %fd810;
	@%p153 bra 	$L__BB17_117;

	mov.f64 	%fd534, 0d3FF0000000000000;
	fma.rn.f64 	%fd812, %fd129, %fd128, %fd534;

$L__BB17_117:
	and.b32  	%r218, %r339, 2;
	setp.eq.s32 	%p154, %r218, 0;
	@%p154 bra 	$L__BB17_119;

	mov.f64 	%fd535, 0d0000000000000000;
	mov.f64 	%fd536, 0dBFF0000000000000;
	fma.rn.f64 	%fd812, %fd812, %fd536, %fd535;

$L__BB17_119:
	mul.rn.f64 	%fd537, %fd812, 0d3EC92A737110E454;
	add.rn.f64 	%fd135, %fd808, %fd537;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r219, %temp}, %fd135;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r220}, %fd135;
	}
	and.b32  	%r221, %r220, 2147483647;
	setp.eq.s32 	%p155, %r221, 2146435072;
	setp.eq.s32 	%p156, %r219, 0;
	and.pred  	%p6, %p156, %p155;
	@%p6 bra 	$L__BB17_123;
	bra.uni 	$L__BB17_120;

$L__BB17_123:
	mov.f64 	%fd547, 0d0000000000000000;
	mul.rn.f64 	%fd814, %fd135, %fd547;
	mov.u32 	%r341, 1;
	bra.uni 	$L__BB17_124;

$L__BB17_120:
	mul.rn.f64 	%fd538, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r340, %fd538;
	st.local.u32 	[%rd1], %r340;
	cvt.rn.f64.s32 	%fd539, %r340;
	neg.f64 	%fd540, %fd539;
	mov.f64 	%fd541, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd542, %fd540, %fd541, %fd135;
	mov.f64 	%fd543, 0d3C91A62633145C00;
	fma.rn.f64 	%fd544, %fd540, %fd543, %fd542;
	mov.f64 	%fd545, 0d397B839A252049C0;
	fma.rn.f64 	%fd814, %fd540, %fd545, %fd544;
	abs.f64 	%fd546, %fd135;
	setp.ltu.f64 	%p157, %fd546, 0d41E0000000000000;
	@%p157 bra 	$L__BB17_122;

	{ // callseq 272, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd814, [retval0+0];
	} // callseq 272
	ld.local.u32 	%r340, [%rd1];

$L__BB17_122:
	add.s32 	%r341, %r340, 1;

$L__BB17_124:
	and.b32  	%r223, %r341, 1;
	shl.b32 	%r224, %r341, 3;
	and.b32  	%r225, %r224, 8;
	setp.eq.s32 	%p158, %r223, 0;
	selp.f64 	%fd548, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p158;
	mul.wide.s32 	%rd57, %r225, 8;
	add.s64 	%rd59, %rd34, %rd57;
	ld.global.nc.f64 	%fd549, [%rd59+8];
	mul.rn.f64 	%fd141, %fd814, %fd814;
	fma.rn.f64 	%fd550, %fd548, %fd141, %fd549;
	ld.global.nc.f64 	%fd551, [%rd59+16];
	fma.rn.f64 	%fd552, %fd550, %fd141, %fd551;
	ld.global.nc.f64 	%fd553, [%rd59+24];
	fma.rn.f64 	%fd554, %fd552, %fd141, %fd553;
	ld.global.nc.f64 	%fd555, [%rd59+32];
	fma.rn.f64 	%fd556, %fd554, %fd141, %fd555;
	ld.global.nc.f64 	%fd557, [%rd59+40];
	fma.rn.f64 	%fd558, %fd556, %fd141, %fd557;
	ld.global.nc.f64 	%fd559, [%rd59+48];
	fma.rn.f64 	%fd142, %fd558, %fd141, %fd559;
	fma.rn.f64 	%fd816, %fd142, %fd814, %fd814;
	@%p158 bra 	$L__BB17_126;

	mov.f64 	%fd560, 0d3FF0000000000000;
	fma.rn.f64 	%fd816, %fd142, %fd141, %fd560;

$L__BB17_126:
	and.b32  	%r226, %r341, 2;
	setp.eq.s32 	%p159, %r226, 0;
	@%p159 bra 	$L__BB17_128;

	mov.f64 	%fd561, 0d0000000000000000;
	mov.f64 	%fd562, 0dBFF0000000000000;
	fma.rn.f64 	%fd816, %fd816, %fd562, %fd561;

$L__BB17_128:
	mul.rn.f64 	%fd563, %fd117, %fd816;
	add.rn.f64 	%fd148, %fd563, 0d3F7A9FBE76C8B439;
	@%p6 bra 	$L__BB17_131;
	bra.uni 	$L__BB17_129;

$L__BB17_131:
	mov.f64 	%fd573, 0d0000000000000000;
	mul.rn.f64 	%fd817, %fd135, %fd573;
	mov.u32 	%r342, 0;
	bra.uni 	$L__BB17_132;

$L__BB17_129:
	mul.rn.f64 	%fd564, %fd135, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r342, %fd564;
	st.local.u32 	[%rd1], %r342;
	cvt.rn.f64.s32 	%fd565, %r342;
	neg.f64 	%fd566, %fd565;
	mov.f64 	%fd567, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd568, %fd566, %fd567, %fd135;
	mov.f64 	%fd569, 0d3C91A62633145C00;
	fma.rn.f64 	%fd570, %fd566, %fd569, %fd568;
	mov.f64 	%fd571, 0d397B839A252049C0;
	fma.rn.f64 	%fd817, %fd566, %fd571, %fd570;
	abs.f64 	%fd572, %fd135;
	setp.ltu.f64 	%p160, %fd572, 0d41E0000000000000;
	@%p160 bra 	$L__BB17_132;

	{ // callseq 273, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd135;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd817, [retval0+0];
	} // callseq 273
	ld.local.u32 	%r342, [%rd1];

$L__BB17_132:
	and.b32  	%r228, %r342, 1;
	shl.b32 	%r229, %r342, 3;
	and.b32  	%r230, %r229, 8;
	setp.eq.s32 	%p161, %r228, 0;
	selp.f64 	%fd574, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p161;
	mul.wide.s32 	%rd61, %r230, 8;
	add.s64 	%rd63, %rd34, %rd61;
	ld.global.nc.f64 	%fd575, [%rd63+8];
	mul.rn.f64 	%fd153, %fd817, %fd817;
	fma.rn.f64 	%fd576, %fd574, %fd153, %fd575;
	ld.global.nc.f64 	%fd577, [%rd63+16];
	fma.rn.f64 	%fd578, %fd576, %fd153, %fd577;
	ld.global.nc.f64 	%fd579, [%rd63+24];
	fma.rn.f64 	%fd580, %fd578, %fd153, %fd579;
	ld.global.nc.f64 	%fd581, [%rd63+32];
	fma.rn.f64 	%fd582, %fd580, %fd153, %fd581;
	ld.global.nc.f64 	%fd583, [%rd63+40];
	fma.rn.f64 	%fd584, %fd582, %fd153, %fd583;
	ld.global.nc.f64 	%fd585, [%rd63+48];
	fma.rn.f64 	%fd154, %fd584, %fd153, %fd585;
	fma.rn.f64 	%fd819, %fd154, %fd817, %fd817;
	@%p161 bra 	$L__BB17_134;

	mov.f64 	%fd586, 0d3FF0000000000000;
	fma.rn.f64 	%fd819, %fd154, %fd153, %fd586;

$L__BB17_134:
	and.b32  	%r231, %r342, 2;
	setp.eq.s32 	%p162, %r231, 0;
	@%p162 bra 	$L__BB17_136;

	mov.f64 	%fd587, 0d0000000000000000;
	mov.f64 	%fd588, 0dBFF0000000000000;
	fma.rn.f64 	%fd819, %fd819, %fd588, %fd587;

$L__BB17_136:
	ld.param.s8 	%rs2, [bd09_to_gcj02_exact_cuda_double_param_3];
	mul.rn.f64 	%fd589, %fd117, %fd819;
	add.rn.f64 	%fd590, %fd589, 0d3F789374BC6A7EFA;
	sub.rn.f64 	%fd160, %fd3, %fd590;
	sub.rn.f64 	%fd161, %fd1, %fd148;
	add.rn.f64 	%fd162, %fd841, %fd161;
	add.rn.f64 	%fd163, %fd842, %fd160;
	setp.eq.s16 	%p163, %rs2, 0;
	@%p163 bra 	$L__BB17_205;

	mul.rn.f64 	%fd591, %fd842, 0d400921FB54442D18;
	div.rn.f64 	%fd164, %fd591, 0d4066800000000000;
	mul.rn.f64 	%fd592, %fd163, 0d400921FB54442D18;
	div.rn.f64 	%fd165, %fd592, 0d4066800000000000;
	sub.rn.f64 	%fd593, %fd165, %fd164;
	mul.rn.f64 	%fd166, %fd593, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r232, %temp}, %fd166;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r233}, %fd166;
	}
	and.b32  	%r234, %r233, 2147483647;
	setp.eq.s32 	%p164, %r234, 2146435072;
	setp.eq.s32 	%p165, %r232, 0;
	and.pred  	%p166, %p165, %p164;
	@%p166 bra 	$L__BB17_140;
	bra.uni 	$L__BB17_138;

$L__BB17_140:
	mov.f64 	%fd603, 0d0000000000000000;
	mul.rn.f64 	%fd820, %fd166, %fd603;
	mov.u32 	%r343, 0;
	bra.uni 	$L__BB17_141;

$L__BB17_205:
	abs.f64 	%fd771, %fd161;
	abs.f64 	%fd772, %fd160;
	mul.rn.f64 	%fd773, %fd772, %fd246;
	setp.lt.f64 	%p244, %fd771, %fd773;
	selp.f64 	%fd774, 0d3FF0000000000000, 0d0000000000000000, %p244;
	setp.lt.f64 	%p245, %fd774, %fd246;
	@%p245 bra 	$L__BB17_207;
	bra.uni 	$L__BB17_206;

$L__BB17_138:
	mul.rn.f64 	%fd594, %fd166, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r343, %fd594;
	st.local.u32 	[%rd1], %r343;
	cvt.rn.f64.s32 	%fd595, %r343;
	neg.f64 	%fd596, %fd595;
	mov.f64 	%fd597, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd598, %fd596, %fd597, %fd166;
	mov.f64 	%fd599, 0d3C91A62633145C00;
	fma.rn.f64 	%fd600, %fd596, %fd599, %fd598;
	mov.f64 	%fd601, 0d397B839A252049C0;
	fma.rn.f64 	%fd820, %fd596, %fd601, %fd600;
	abs.f64 	%fd602, %fd166;
	setp.ltu.f64 	%p167, %fd602, 0d41E0000000000000;
	@%p167 bra 	$L__BB17_141;

	{ // callseq 274, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd166;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd820, [retval0+0];
	} // callseq 274
	ld.local.u32 	%r343, [%rd1];

$L__BB17_141:
	and.b32  	%r236, %r343, 1;
	shl.b32 	%r237, %r343, 3;
	and.b32  	%r238, %r237, 8;
	setp.eq.s32 	%p168, %r236, 0;
	selp.f64 	%fd604, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p168;
	mul.wide.s32 	%rd65, %r238, 8;
	add.s64 	%rd67, %rd34, %rd65;
	ld.global.nc.f64 	%fd605, [%rd67+8];
	mul.rn.f64 	%fd171, %fd820, %fd820;
	fma.rn.f64 	%fd606, %fd604, %fd171, %fd605;
	ld.global.nc.f64 	%fd607, [%rd67+16];
	fma.rn.f64 	%fd608, %fd606, %fd171, %fd607;
	ld.global.nc.f64 	%fd609, [%rd67+24];
	fma.rn.f64 	%fd610, %fd608, %fd171, %fd609;
	ld.global.nc.f64 	%fd611, [%rd67+32];
	fma.rn.f64 	%fd612, %fd610, %fd171, %fd611;
	ld.global.nc.f64 	%fd613, [%rd67+40];
	fma.rn.f64 	%fd614, %fd612, %fd171, %fd613;
	ld.global.nc.f64 	%fd615, [%rd67+48];
	fma.rn.f64 	%fd172, %fd614, %fd171, %fd615;
	fma.rn.f64 	%fd822, %fd172, %fd820, %fd820;
	@%p168 bra 	$L__BB17_143;

	mov.f64 	%fd616, 0d3FF0000000000000;
	fma.rn.f64 	%fd822, %fd172, %fd171, %fd616;

$L__BB17_143:
	and.b32  	%r239, %r343, 2;
	setp.eq.s32 	%p169, %r239, 0;
	@%p169 bra 	$L__BB17_145;

	mov.f64 	%fd617, 0d0000000000000000;
	mov.f64 	%fd618, 0dBFF0000000000000;
	fma.rn.f64 	%fd822, %fd822, %fd618, %fd617;

$L__BB17_145:
	abs.f64 	%fd178, %fd822;
	{ // callseq 275, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd178;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd825, [retval0+0];
	} // callseq 275
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r48}, %fd822;
	}
	setp.lt.s32 	%p170, %r48, 0;
	and.pred  	%p7, %p170, %p9;
	not.pred 	%p172, %p7;
	@%p172 bra 	$L__BB17_147;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r240}, %fd825;
	}
	xor.b32  	%r241, %r240, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r242, %temp}, %fd825;
	}
	mov.b64 	%fd825, {%r242, %r241};

$L__BB17_147:
	setp.eq.f64 	%p173, %fd822, 0d0000000000000000;
	@%p173 bra 	$L__BB17_151;
	bra.uni 	$L__BB17_148;

$L__BB17_151:
	setp.lt.s32 	%p176, %r2, 0;
	mov.u32 	%r243, 0;
	selp.b32 	%r244, %r48, 0, %p9;
	or.b32  	%r245, %r244, 2146435072;
	selp.b32 	%r246, %r245, %r244, %p176;
	mov.b64 	%fd825, {%r243, %r246};
	bra.uni 	$L__BB17_152;

$L__BB17_148:
	setp.gt.s32 	%p174, %r48, -1;
	@%p174 bra 	$L__BB17_152;

	mov.f64 	%fd619, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd620, %fd619;
	setp.eq.f64 	%p175, %fd620, 0d4000000000000000;
	@%p175 bra 	$L__BB17_152;

	mov.f64 	%fd825, 0dFFF8000000000000;

$L__BB17_152:
	add.rn.f64 	%fd622, %fd822, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r247}, %fd622;
	}
	and.b32  	%r248, %r247, 2146435072;
	setp.ne.s32 	%p178, %r248, 2146435072;
	@%p178 bra 	$L__BB17_159;

	setp.gtu.f64 	%p179, %fd178, 0d7FF0000000000000;
	@%p179 bra 	$L__BB17_158;
	bra.uni 	$L__BB17_154;

$L__BB17_158:
	mov.f64 	%fd624, 0d4000000000000000;
	add.rn.f64 	%fd825, %fd822, %fd624;
	bra.uni 	$L__BB17_159;

$L__BB17_154:
	setp.eq.s32 	%p180, %r23, 2146435072;
	mov.f64 	%fd623, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r249, %temp}, %fd623;
	}
	setp.eq.s32 	%p181, %r249, 0;
	and.pred  	%p182, %p180, %p181;
	@%p182 bra 	$L__BB17_157;
	bra.uni 	$L__BB17_155;

$L__BB17_157:
	setp.lt.s32 	%p188, %r2, 0;
	mov.u32 	%r254, 0;
	setp.gt.f64 	%p189, %fd178, 0d3FF0000000000000;
	selp.b32 	%r255, 2146435072, 0, %p189;
	xor.b32  	%r256, %r255, 2146435072;
	selp.b32 	%r257, %r256, %r255, %p188;
	setp.eq.f64 	%p190, %fd822, 0dBFF0000000000000;
	selp.b32 	%r258, 1072693248, %r257, %p190;
	mov.b64 	%fd825, {%r254, %r258};
	bra.uni 	$L__BB17_159;

$L__BB17_155:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r250, %temp}, %fd822;
	}
	and.b32  	%r251, %r48, 2147483647;
	setp.ne.s32 	%p183, %r251, 2146435072;
	setp.ne.s32 	%p184, %r250, 0;
	or.pred  	%p185, %p183, %p184;
	@%p185 bra 	$L__BB17_159;

	setp.ne.s32 	%p186, %r23, 1071644672;
	and.pred  	%p187, %p186, %p7;
	selp.b32 	%r252, %r25, %r24, %p187;
	mov.u32 	%r253, 0;
	mov.b64 	%fd825, {%r253, %r252};

$L__BB17_159:
	setp.eq.f64 	%p191, %fd822, 0d3FF0000000000000;
	selp.f64 	%fd188, 0d3FF0000000000000, %fd825, %p191;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r259}, %fd164;
	}
	and.b32  	%r260, %r259, 2147483647;
	setp.eq.s32 	%p192, %r260, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r261, %temp}, %fd164;
	}
	setp.eq.s32 	%p193, %r261, 0;
	and.pred  	%p194, %p193, %p192;
	@%p194 bra 	$L__BB17_163;
	bra.uni 	$L__BB17_160;

$L__BB17_163:
	mov.f64 	%fd634, 0d0000000000000000;
	mul.rn.f64 	%fd827, %fd164, %fd634;
	mov.u32 	%r345, 1;
	bra.uni 	$L__BB17_164;

$L__BB17_160:
	mul.rn.f64 	%fd625, %fd164, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r344, %fd625;
	st.local.u32 	[%rd1], %r344;
	cvt.rn.f64.s32 	%fd626, %r344;
	neg.f64 	%fd627, %fd626;
	mov.f64 	%fd628, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd629, %fd627, %fd628, %fd164;
	mov.f64 	%fd630, 0d3C91A62633145C00;
	fma.rn.f64 	%fd631, %fd627, %fd630, %fd629;
	mov.f64 	%fd632, 0d397B839A252049C0;
	fma.rn.f64 	%fd827, %fd627, %fd632, %fd631;
	abs.f64 	%fd633, %fd164;
	setp.ltu.f64 	%p195, %fd633, 0d41E0000000000000;
	@%p195 bra 	$L__BB17_162;

	{ // callseq 276, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd164;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd827, [retval0+0];
	} // callseq 276
	ld.local.u32 	%r344, [%rd1];

$L__BB17_162:
	add.s32 	%r345, %r344, 1;

$L__BB17_164:
	and.b32  	%r263, %r345, 1;
	shl.b32 	%r264, %r345, 3;
	and.b32  	%r265, %r264, 8;
	setp.eq.s32 	%p196, %r263, 0;
	selp.f64 	%fd635, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p196;
	mul.wide.s32 	%rd69, %r265, 8;
	add.s64 	%rd71, %rd34, %rd69;
	ld.global.nc.f64 	%fd636, [%rd71+8];
	mul.rn.f64 	%fd194, %fd827, %fd827;
	fma.rn.f64 	%fd637, %fd635, %fd194, %fd636;
	ld.global.nc.f64 	%fd638, [%rd71+16];
	fma.rn.f64 	%fd639, %fd637, %fd194, %fd638;
	ld.global.nc.f64 	%fd640, [%rd71+24];
	fma.rn.f64 	%fd641, %fd639, %fd194, %fd640;
	ld.global.nc.f64 	%fd642, [%rd71+32];
	fma.rn.f64 	%fd643, %fd641, %fd194, %fd642;
	ld.global.nc.f64 	%fd644, [%rd71+40];
	fma.rn.f64 	%fd645, %fd643, %fd194, %fd644;
	ld.global.nc.f64 	%fd646, [%rd71+48];
	fma.rn.f64 	%fd195, %fd645, %fd194, %fd646;
	fma.rn.f64 	%fd829, %fd195, %fd827, %fd827;
	@%p196 bra 	$L__BB17_166;

	mov.f64 	%fd647, 0d3FF0000000000000;
	fma.rn.f64 	%fd829, %fd195, %fd194, %fd647;

$L__BB17_166:
	and.b32  	%r266, %r345, 2;
	setp.eq.s32 	%p197, %r266, 0;
	@%p197 bra 	$L__BB17_168;

	mov.f64 	%fd648, 0d0000000000000000;
	mov.f64 	%fd649, 0dBFF0000000000000;
	fma.rn.f64 	%fd829, %fd829, %fd649, %fd648;

$L__BB17_168:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r267}, %fd165;
	}
	and.b32  	%r268, %r267, 2147483647;
	setp.eq.s32 	%p198, %r268, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r269, %temp}, %fd165;
	}
	setp.eq.s32 	%p199, %r269, 0;
	and.pred  	%p200, %p199, %p198;
	@%p200 bra 	$L__BB17_172;
	bra.uni 	$L__BB17_169;

$L__BB17_172:
	mov.f64 	%fd659, 0d0000000000000000;
	mul.rn.f64 	%fd831, %fd165, %fd659;
	mov.u32 	%r347, 1;
	bra.uni 	$L__BB17_173;

$L__BB17_169:
	mul.rn.f64 	%fd650, %fd165, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r346, %fd650;
	st.local.u32 	[%rd1], %r346;
	cvt.rn.f64.s32 	%fd651, %r346;
	neg.f64 	%fd652, %fd651;
	mov.f64 	%fd653, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd654, %fd652, %fd653, %fd165;
	mov.f64 	%fd655, 0d3C91A62633145C00;
	fma.rn.f64 	%fd656, %fd652, %fd655, %fd654;
	mov.f64 	%fd657, 0d397B839A252049C0;
	fma.rn.f64 	%fd831, %fd652, %fd657, %fd656;
	abs.f64 	%fd658, %fd165;
	setp.ltu.f64 	%p201, %fd658, 0d41E0000000000000;
	@%p201 bra 	$L__BB17_171;

	{ // callseq 277, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd165;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd831, [retval0+0];
	} // callseq 277
	ld.local.u32 	%r346, [%rd1];

$L__BB17_171:
	add.s32 	%r347, %r346, 1;

$L__BB17_173:
	and.b32  	%r271, %r347, 1;
	shl.b32 	%r272, %r347, 3;
	and.b32  	%r273, %r272, 8;
	setp.eq.s32 	%p202, %r271, 0;
	selp.f64 	%fd660, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p202;
	mul.wide.s32 	%rd73, %r273, 8;
	add.s64 	%rd75, %rd34, %rd73;
	ld.global.nc.f64 	%fd661, [%rd75+8];
	mul.rn.f64 	%fd206, %fd831, %fd831;
	fma.rn.f64 	%fd662, %fd660, %fd206, %fd661;
	ld.global.nc.f64 	%fd663, [%rd75+16];
	fma.rn.f64 	%fd664, %fd662, %fd206, %fd663;
	ld.global.nc.f64 	%fd665, [%rd75+24];
	fma.rn.f64 	%fd666, %fd664, %fd206, %fd665;
	ld.global.nc.f64 	%fd667, [%rd75+32];
	fma.rn.f64 	%fd668, %fd666, %fd206, %fd667;
	ld.global.nc.f64 	%fd669, [%rd75+40];
	fma.rn.f64 	%fd670, %fd668, %fd206, %fd669;
	ld.global.nc.f64 	%fd671, [%rd75+48];
	fma.rn.f64 	%fd207, %fd670, %fd206, %fd671;
	fma.rn.f64 	%fd833, %fd207, %fd831, %fd831;
	@%p202 bra 	$L__BB17_175;

	mov.f64 	%fd672, 0d3FF0000000000000;
	fma.rn.f64 	%fd833, %fd207, %fd206, %fd672;

$L__BB17_175:
	and.b32  	%r274, %r347, 2;
	setp.eq.s32 	%p203, %r274, 0;
	@%p203 bra 	$L__BB17_177;

	mov.f64 	%fd673, 0d0000000000000000;
	mov.f64 	%fd674, 0dBFF0000000000000;
	fma.rn.f64 	%fd833, %fd833, %fd674, %fd673;

$L__BB17_177:
	mul.rn.f64 	%fd213, %fd829, %fd833;
	mul.rn.f64 	%fd675, %fd841, 0d400921FB54442D18;
	div.rn.f64 	%fd676, %fd675, 0d4066800000000000;
	mul.rn.f64 	%fd677, %fd162, 0d400921FB54442D18;
	div.rn.f64 	%fd678, %fd677, 0d4066800000000000;
	sub.rn.f64 	%fd679, %fd678, %fd676;
	mul.rn.f64 	%fd214, %fd679, 0d3FE0000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r275, %temp}, %fd214;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r276}, %fd214;
	}
	and.b32  	%r277, %r276, 2147483647;
	setp.eq.s32 	%p204, %r277, 2146435072;
	setp.eq.s32 	%p205, %r275, 0;
	and.pred  	%p206, %p205, %p204;
	@%p206 bra 	$L__BB17_180;
	bra.uni 	$L__BB17_178;

$L__BB17_180:
	mov.f64 	%fd689, 0d0000000000000000;
	mul.rn.f64 	%fd834, %fd214, %fd689;
	mov.u32 	%r348, 0;
	bra.uni 	$L__BB17_181;

$L__BB17_178:
	mul.rn.f64 	%fd680, %fd214, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64 	%r348, %fd680;
	st.local.u32 	[%rd1], %r348;
	cvt.rn.f64.s32 	%fd681, %r348;
	neg.f64 	%fd682, %fd681;
	mov.f64 	%fd683, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd684, %fd682, %fd683, %fd214;
	mov.f64 	%fd685, 0d3C91A62633145C00;
	fma.rn.f64 	%fd686, %fd682, %fd685, %fd684;
	mov.f64 	%fd687, 0d397B839A252049C0;
	fma.rn.f64 	%fd834, %fd682, %fd687, %fd686;
	abs.f64 	%fd688, %fd214;
	setp.ltu.f64 	%p207, %fd688, 0d41E0000000000000;
	@%p207 bra 	$L__BB17_181;

	{ // callseq 278, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd214;
	.param .b64 param1;
	st.param.b64 	[param1+0], %rd18;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64 	%fd834, [retval0+0];
	} // callseq 278
	ld.local.u32 	%r348, [%rd1];

$L__BB17_181:
	and.b32  	%r279, %r348, 1;
	shl.b32 	%r280, %r348, 3;
	and.b32  	%r281, %r280, 8;
	setp.eq.s32 	%p208, %r279, 0;
	selp.f64 	%fd690, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p208;
	mul.wide.s32 	%rd77, %r281, 8;
	add.s64 	%rd79, %rd34, %rd77;
	ld.global.nc.f64 	%fd691, [%rd79+8];
	mul.rn.f64 	%fd219, %fd834, %fd834;
	fma.rn.f64 	%fd692, %fd690, %fd219, %fd691;
	ld.global.nc.f64 	%fd693, [%rd79+16];
	fma.rn.f64 	%fd694, %fd692, %fd219, %fd693;
	ld.global.nc.f64 	%fd695, [%rd79+24];
	fma.rn.f64 	%fd696, %fd694, %fd219, %fd695;
	ld.global.nc.f64 	%fd697, [%rd79+32];
	fma.rn.f64 	%fd698, %fd696, %fd219, %fd697;
	ld.global.nc.f64 	%fd699, [%rd79+40];
	fma.rn.f64 	%fd700, %fd698, %fd219, %fd699;
	ld.global.nc.f64 	%fd701, [%rd79+48];
	fma.rn.f64 	%fd220, %fd700, %fd219, %fd701;
	fma.rn.f64 	%fd836, %fd220, %fd834, %fd834;
	@%p208 bra 	$L__BB17_183;

	mov.f64 	%fd702, 0d3FF0000000000000;
	fma.rn.f64 	%fd836, %fd220, %fd219, %fd702;

$L__BB17_183:
	and.b32  	%r282, %r348, 2;
	setp.eq.s32 	%p209, %r282, 0;
	@%p209 bra 	$L__BB17_185;

	mov.f64 	%fd703, 0d0000000000000000;
	mov.f64 	%fd704, 0dBFF0000000000000;
	fma.rn.f64 	%fd836, %fd836, %fd704, %fd703;

$L__BB17_185:
	abs.f64 	%fd226, %fd836;
	{ // callseq 279, 0
	.reg .b32 temp_param_reg;
	.param .b64 param0;
	st.param.f64 	[param0+0], %fd226;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_accurate_pow, 
	(
	param0
	);
	ld.param.f64 	%fd839, [retval0+0];
	} // callseq 279
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r62}, %fd836;
	}
	setp.lt.s32 	%p210, %r62, 0;
	and.pred  	%p8, %p210, %p9;
	not.pred 	%p212, %p8;
	@%p212 bra 	$L__BB17_187;

	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r283}, %fd839;
	}
	xor.b32  	%r284, %r283, -2147483648;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r285, %temp}, %fd839;
	}
	mov.b64 	%fd839, {%r285, %r284};

$L__BB17_187:
	setp.eq.f64 	%p213, %fd836, 0d0000000000000000;
	@%p213 bra 	$L__BB17_191;
	bra.uni 	$L__BB17_188;

$L__BB17_191:
	setp.lt.s32 	%p216, %r2, 0;
	mov.u32 	%r286, 0;
	selp.b32 	%r287, %r62, 0, %p9;
	or.b32  	%r288, %r287, 2146435072;
	selp.b32 	%r289, %r288, %r287, %p216;
	mov.b64 	%fd839, {%r286, %r289};
	bra.uni 	$L__BB17_192;

$L__BB17_188:
	setp.gt.s32 	%p214, %r62, -1;
	@%p214 bra 	$L__BB17_192;

	mov.f64 	%fd705, 0d4000000000000000;
	cvt.rzi.f64.f64 	%fd706, %fd705;
	setp.eq.f64 	%p215, %fd706, 0d4000000000000000;
	@%p215 bra 	$L__BB17_192;

	mov.f64 	%fd839, 0dFFF8000000000000;

$L__BB17_192:
	add.rn.f64 	%fd708, %fd836, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r290}, %fd708;
	}
	and.b32  	%r291, %r290, 2146435072;
	setp.ne.s32 	%p218, %r291, 2146435072;
	@%p218 bra 	$L__BB17_199;

	setp.gtu.f64 	%p219, %fd226, 0d7FF0000000000000;
	@%p219 bra 	$L__BB17_198;
	bra.uni 	$L__BB17_194;

$L__BB17_198:
	mov.f64 	%fd710, 0d4000000000000000;
	add.rn.f64 	%fd839, %fd836, %fd710;
	bra.uni 	$L__BB17_199;

$L__BB17_194:
	setp.eq.s32 	%p220, %r23, 2146435072;
	mov.f64 	%fd709, 0d4000000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r292, %temp}, %fd709;
	}
	setp.eq.s32 	%p221, %r292, 0;
	and.pred  	%p222, %p220, %p221;
	@%p222 bra 	$L__BB17_197;
	bra.uni 	$L__BB17_195;

$L__BB17_197:
	setp.lt.s32 	%p228, %r2, 0;
	mov.u32 	%r297, 0;
	setp.gt.f64 	%p229, %fd226, 0d3FF0000000000000;
	selp.b32 	%r298, 2146435072, 0, %p229;
	xor.b32  	%r299, %r298, 2146435072;
	selp.b32 	%r300, %r299, %r298, %p228;
	setp.eq.f64 	%p230, %fd836, 0dBFF0000000000000;
	selp.b32 	%r301, 1072693248, %r300, %p230;
	mov.b64 	%fd839, {%r297, %r301};
	bra.uni 	$L__BB17_199;

$L__BB17_195:
	{
	.reg .b32 %temp; 
	mov.b64 	{%r293, %temp}, %fd836;
	}
	and.b32  	%r294, %r62, 2147483647;
	setp.ne.s32 	%p223, %r294, 2146435072;
	setp.ne.s32 	%p224, %r293, 0;
	or.pred  	%p225, %p223, %p224;
	@%p225 bra 	$L__BB17_199;

	setp.ne.s32 	%p226, %r23, 1071644672;
	and.pred  	%p227, %p226, %p8;
	selp.b32 	%r295, %r25, %r24, %p227;
	mov.u32 	%r296, 0;
	mov.b64 	%fd839, {%r296, %r295};

$L__BB17_199:
	setp.eq.f64 	%p231, %fd836, 0d3FF0000000000000;
	mov.f64 	%fd711, 0d3FF0000000000000;
	selp.f64 	%fd712, 0d3FF0000000000000, %fd839, %p231;
	mul.rn.f64 	%fd713, %fd213, %fd712;
	add.rn.f64 	%fd714, %fd188, %fd713;
	sqrt.rn.f64 	%fd236, %fd714;
	sub.rn.f64 	%fd715, %fd711, %fd714;
	sqrt.rn.f64 	%fd237, %fd715;
	abs.f64 	%fd238, %fd237;
	abs.f64 	%fd239, %fd236;
	setp.eq.f64 	%p232, %fd238, 0d0000000000000000;
	setp.eq.f64 	%p233, %fd239, 0d0000000000000000;
	and.pred  	%p234, %p232, %p233;
	@%p234 bra 	$L__BB17_203;
	bra.uni 	$L__BB17_200;

$L__BB17_203:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r314}, %fd237;
	}
	setp.lt.s32 	%p242, %r314, 0;
	selp.f64 	%fd768, 0d400921FB54442D18, 0d0000000000000000, %p242;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r315, %temp}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r316}, %fd768;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r317}, %fd236;
	}
	and.b32  	%r318, %r317, -2147483648;
	or.b32  	%r319, %r316, %r318;
	mov.b64 	%fd840, {%r315, %r319};
	bra.uni 	$L__BB17_204;

$L__BB17_200:
	setp.eq.f64 	%p235, %fd238, 0d7FF0000000000000;
	setp.eq.f64 	%p236, %fd239, 0d7FF0000000000000;
	and.pred  	%p237, %p235, %p236;
	@%p237 bra 	$L__BB17_202;
	bra.uni 	$L__BB17_201;

$L__BB17_202:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r308}, %fd237;
	}
	setp.lt.s32 	%p241, %r308, 0;
	selp.f64 	%fd767, 0d4002D97C7F3321D2, 0d3FE921FB54442D18, %p241;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r309, %temp}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r310}, %fd767;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r311}, %fd236;
	}
	and.b32  	%r312, %r311, -2147483648;
	or.b32  	%r313, %r310, %r312;
	mov.b64 	%fd840, {%r309, %r313};
	bra.uni 	$L__BB17_204;

$L__BB17_201:
	max.f64 	%fd716, %fd239, %fd238;
	min.f64 	%fd717, %fd239, %fd238;
	div.rn.f64 	%fd718, %fd717, %fd716;
	mul.rn.f64 	%fd719, %fd718, %fd718;
	mov.f64 	%fd720, 0d3F2D3B63DBB65B49;
	mov.f64 	%fd721, 0dBEF53E1D2A25FF7E;
	fma.rn.f64 	%fd722, %fd721, %fd719, %fd720;
	mov.f64 	%fd723, 0dBF5312788DDE082E;
	fma.rn.f64 	%fd724, %fd722, %fd719, %fd723;
	mov.f64 	%fd725, 0d3F6F9690C8249315;
	fma.rn.f64 	%fd726, %fd724, %fd719, %fd725;
	mov.f64 	%fd727, 0dBF82CF5AABC7CF0D;
	fma.rn.f64 	%fd728, %fd726, %fd719, %fd727;
	mov.f64 	%fd729, 0d3F9162B0B2A3BFDE;
	fma.rn.f64 	%fd730, %fd728, %fd719, %fd729;
	mov.f64 	%fd731, 0dBF9A7256FEB6FC6B;
	fma.rn.f64 	%fd732, %fd730, %fd719, %fd731;
	mov.f64 	%fd733, 0d3FA171560CE4A489;
	fma.rn.f64 	%fd734, %fd732, %fd719, %fd733;
	mov.f64 	%fd735, 0dBFA4F44D841450E4;
	fma.rn.f64 	%fd736, %fd734, %fd719, %fd735;
	mov.f64 	%fd737, 0d3FA7EE3D3F36BB95;
	fma.rn.f64 	%fd738, %fd736, %fd719, %fd737;
	mov.f64 	%fd739, 0dBFAAD32AE04A9FD1;
	fma.rn.f64 	%fd740, %fd738, %fd719, %fd739;
	mov.f64 	%fd741, 0d3FAE17813D66954F;
	fma.rn.f64 	%fd742, %fd740, %fd719, %fd741;
	mov.f64 	%fd743, 0dBFB11089CA9A5BCD;
	fma.rn.f64 	%fd744, %fd742, %fd719, %fd743;
	mov.f64 	%fd745, 0d3FB3B12B2DB51738;
	fma.rn.f64 	%fd746, %fd744, %fd719, %fd745;
	mov.f64 	%fd747, 0dBFB745D022F8DC5C;
	fma.rn.f64 	%fd748, %fd746, %fd719, %fd747;
	mov.f64 	%fd749, 0d3FBC71C709DFE927;
	fma.rn.f64 	%fd750, %fd748, %fd719, %fd749;
	mov.f64 	%fd751, 0dBFC2492491FA1744;
	fma.rn.f64 	%fd752, %fd750, %fd719, %fd751;
	mov.f64 	%fd753, 0d3FC99999999840D2;
	fma.rn.f64 	%fd754, %fd752, %fd719, %fd753;
	mov.f64 	%fd755, 0dBFD555555555544C;
	fma.rn.f64 	%fd756, %fd754, %fd719, %fd755;
	mul.rn.f64 	%fd757, %fd719, %fd756;
	fma.rn.f64 	%fd758, %fd757, %fd718, %fd718;
	mov.f64 	%fd759, 0d3FF921FB54442D18;
	sub.rn.f64 	%fd760, %fd759, %fd758;
	setp.gt.f64 	%p238, %fd239, %fd238;
	selp.f64 	%fd761, %fd760, %fd758, %p238;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r302}, %fd237;
	}
	setp.lt.s32 	%p239, %r302, 0;
	mov.f64 	%fd762, 0d400921FB54442D18;
	sub.rn.f64 	%fd763, %fd762, %fd761;
	selp.f64 	%fd764, %fd763, %fd761, %p239;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r303, %temp}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r304}, %fd764;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r305}, %fd236;
	}
	and.b32  	%r306, %r305, -2147483648;
	or.b32  	%r307, %r304, %r306;
	mov.b64 	%fd765, {%r303, %r307};
	add.rn.f64 	%fd766, %fd238, %fd239;
	setp.le.f64 	%p240, %fd766, 0d7FF0000000000000;
	selp.f64 	%fd840, %fd765, %fd766, %p240;

$L__BB17_204:
	add.rn.f64 	%fd769, %fd840, %fd840;
	mul.rn.f64 	%fd770, %fd769, 0d415854A640000000;
	setp.lt.f64 	%p243, %fd770, %fd246;
	@%p243 bra 	$L__BB17_207;

$L__BB17_206:
	ld.param.u32 	%r324, [bd09_to_gcj02_exact_cuda_double_param_4];
	add.s32 	%r336, %r336, 1;
	setp.lt.s32 	%p246, %r336, %r324;
	mov.f64 	%fd842, %fd163;
	mov.f64 	%fd841, %fd162;
	@%p246 bra 	$L__BB17_69;

$L__BB17_207:
	ld.param.u64 	%rd87, [bd09_to_gcj02_exact_cuda_double_param_1];
	mov.u32 	%r328, %tid.x;
	mov.u32 	%r327, %ntid.x;
	mov.u32 	%r326, %ctaid.x;
	mad.lo.s32 	%r325, %r326, %r327, %r328;
	mul.wide.s32 	%rd86, %r325, 8;
	cvta.to.global.u64 	%rd85, %rd87;
	add.s64 	%rd84, %rd85, %rd86;
	ld.param.u64 	%rd83, [bd09_to_gcj02_exact_cuda_double_param_0];
	mov.u32 	%r323, %tid.x;
	mov.u32 	%r322, %ntid.x;
	mov.u32 	%r321, %ctaid.x;
	mad.lo.s32 	%r320, %r321, %r322, %r323;
	mul.wide.s32 	%rd82, %r320, 8;
	cvta.to.global.u64 	%rd81, %rd83;
	add.s64 	%rd80, %rd81, %rd82;
	st.global.f64 	[%rd80], %fd841;
	st.global.f64 	[%rd84], %fd842;
	ret;

}
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot18[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<32>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<79>;


	mov.u64 	%SPL, __local_depot18;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd18, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd1, %SPL, 0;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	bfe.u32 	%r2, %r1, 20, 11;
	setp.eq.s32 	%p1, %r2, 2047;
	@%p1 bra 	$L__BB18_7;

	add.s32 	%r3, %r2, -1024;
	shr.u32 	%r10, %r3, 6;
	mov.u32 	%r11, 16;
	sub.s32 	%r12, %r11, %r10;
	mov.u32 	%r13, 15;
	sub.s32 	%r4, %r13, %r10;
	mov.u32 	%r14, 19;
	sub.s32 	%r15, %r14, %r10;
	setp.gt.s32 	%p2, %r12, 14;
	selp.b32 	%r5, 18, %r15, %p2;
	setp.gt.s32 	%p3, %r12, %r5;
	mov.u64 	%rd76, 0;
	mov.u32 	%r31, %r4;
	@%p3 bra 	$L__BB18_4;

	mul.wide.s32 	%rd22, %r4, 8;
	mov.u64 	%rd23, __cudart_i2opi_d;
	add.s64 	%rd74, %rd23, %rd22;
	mov.b64 	%rd24, %fd4;
	shl.b64 	%rd25, %rd24, 11;
	or.b64  	%rd3, %rd25, -9223372036854775808;
	mov.u64 	%rd76, 0;
	mov.u64 	%rd73, %rd1;
	mov.u32 	%r31, %r4;

$L__BB18_3:
	.pragma "nounroll";
	ld.global.nc.u64 	%rd26, [%rd74];
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi, %clo, %chi;
	mov.b64 	{%alo,%ahi}, %rd26;
	mov.b64 	{%blo,%bhi}, %rd3;
	mov.b64 	{%clo,%chi}, %rd76;
	mad.lo.cc.u32 	%r0, %alo, %blo, %clo;
	madc.hi.cc.u32 	%r1, %alo, %blo, %chi;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd27, {%r0,%r1};
	mov.b64 	%rd76, {%r2,%r3};
	}
	st.local.u64 	[%rd73], %rd27;
	add.s64 	%rd74, %rd74, 8;
	add.s64 	%rd73, %rd73, 8;
	add.s32 	%r31, %r31, 1;
	setp.lt.s32 	%p4, %r31, %r5;
	@%p4 bra 	$L__BB18_3;

$L__BB18_4:
	sub.s32 	%r16, %r31, %r4;
	mul.wide.s32 	%rd28, %r16, 8;
	add.s64 	%rd29, %rd1, %rd28;
	st.local.u64 	[%rd29], %rd76;
	ld.local.u64 	%rd78, [%rd1+16];
	ld.local.u64 	%rd77, [%rd1+24];
	and.b32  	%r9, %r3, 63;
	setp.eq.s32 	%p5, %r9, 0;
	@%p5 bra 	$L__BB18_6;

	mov.u32 	%r17, 64;
	sub.s32 	%r18, %r17, %r9;
	shl.b64 	%rd30, %rd77, %r9;
	shr.u64 	%rd31, %rd78, %r18;
	or.b64  	%rd77, %rd30, %rd31;
	shl.b64 	%rd32, %rd78, %r9;
	ld.local.u64 	%rd33, [%rd1+8];
	shr.u64 	%rd34, %rd33, %r18;
	or.b64  	%rd78, %rd34, %rd32;

$L__BB18_6:
	and.b32  	%r19, %r1, -2147483648;
	shr.u64 	%rd35, %rd77, 62;
	cvt.u32.u64 	%r20, %rd35;
	shr.u64 	%rd36, %rd78, 62;
	shl.b64 	%rd37, %rd77, 2;
	or.b64  	%rd38, %rd36, %rd37;
	shr.u64 	%rd39, %rd77, 61;
	cvt.u32.u64 	%r21, %rd39;
	and.b32  	%r22, %r21, 1;
	add.s32 	%r23, %r22, %r20;
	neg.s32 	%r24, %r23;
	setp.eq.s32 	%p6, %r19, 0;
	selp.b32 	%r25, %r23, %r24, %p6;
	cvta.to.local.u64 	%rd40, %rd18;
	mov.u64 	%rd41, 0;
	st.local.u32 	[%rd40], %r25;
	setp.eq.s32 	%p7, %r22, 0;
	shl.b64 	%rd42, %rd78, 2;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd41;
	mov.b64 	{%a2,%a3}, %rd41;
	mov.b64 	{%b0,%b1}, %rd42;
	mov.b64 	{%b2,%b3}, %rd38;
	sub.cc.u32 	%r0, %a0, %b0;
	subc.cc.u32 	%r1, %a1, %b1;
	subc.cc.u32 	%r2, %a2, %b2;
	subc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd43, {%r0,%r1};
	mov.b64 	%rd44, {%r2,%r3};
	}
	selp.b64 	%rd45, %rd38, %rd44, %p7;
	selp.b64 	%rd46, %rd42, %rd43, %p7;
	xor.b32  	%r26, %r19, -2147483648;
	selp.b32 	%r27, %r19, %r26, %p7;
	clz.b64 	%r28, %rd45;
	cvt.u64.u32 	%rd47, %r28;
	setp.eq.s64 	%p8, %rd47, 0;
	shl.b64 	%rd48, %rd45, %r28;
	mov.u64 	%rd49, 64;
	sub.s64 	%rd50, %rd49, %rd47;
	cvt.u32.u64 	%r29, %rd50;
	shr.u64 	%rd51, %rd46, %r29;
	or.b64  	%rd52, %rd51, %rd48;
	selp.b64 	%rd53, %rd45, %rd52, %p8;
	mov.u64 	%rd54, -3958705157555305931;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %alo, %ahi, %blo, %bhi;
	mov.b64 	{%alo,%ahi}, %rd53;
	mov.b64 	{%blo,%bhi}, %rd54;
	mul.lo.u32 	%r0, %alo, %blo;
	mul.hi.u32 	%r1, %alo, %blo;
	mad.lo.cc.u32 	%r1, %alo, %bhi, %r1;
	madc.hi.u32 	%r2, %alo, %bhi, 0;
	mad.lo.cc.u32 	%r1, %ahi, %blo, %r1;
	madc.hi.cc.u32 	%r2, %ahi, %blo, %r2;
	madc.hi.u32 	%r3, %ahi, %bhi, 0;
	mad.lo.cc.u32 	%r2, %ahi, %bhi, %r2;
	addc.u32 	%r3, %r3, 0;
	mov.b64 	%rd55, {%r0,%r1};
	mov.b64 	%rd56, {%r2,%r3};
	}
	setp.gt.s64 	%p9, %rd56, 0;
	{
	.reg .u32 %r0, %r1, %r2, %r3, %a0, %a1, %a2, %a3, %b0, %b1, %b2, %b3;
	mov.b64 	{%a0,%a1}, %rd55;
	mov.b64 	{%a2,%a3}, %rd56;
	mov.b64 	{%b0,%b1}, %rd55;
	mov.b64 	{%b2,%b3}, %rd56;
	add.cc.u32 	%r0, %a0, %b0;
	addc.cc.u32 	%r1, %a1, %b1;
	addc.cc.u32 	%r2, %a2, %b2;
	addc.u32 	%r3, %a3, %b3;
	mov.b64 	%rd57, {%r0,%r1};
	mov.b64 	%rd58, {%r2,%r3};
	}
	selp.b64 	%rd59, %rd58, %rd56, %p9;
	selp.u64 	%rd60, 1, 0, %p9;
	add.s64 	%rd61, %rd47, %rd60;
	cvt.u64.u32 	%rd62, %r27;
	shl.b64 	%rd63, %rd62, 32;
	shl.b64 	%rd64, %rd61, 52;
	mov.u64 	%rd65, 4602678819172646912;
	sub.s64 	%rd66, %rd65, %rd64;
	add.s64 	%rd67, %rd59, 1;
	shr.u64 	%rd68, %rd67, 10;
	add.s64 	%rd69, %rd68, 1;
	shr.u64 	%rd70, %rd69, 1;
	add.s64 	%rd71, %rd66, %rd70;
	or.b64  	%rd72, %rd71, %rd63;
	mov.b64 	%fd4, %rd72;

$L__BB18_7:
	st.param.f64 	[func_retval0+0], %fd4;
	ret;

}
.func  (.param .b64 func_retval0) __internal_accurate_pow(
	.param .b64 __internal_accurate_pow_param_0
)
{
	.reg .pred 	%p<10>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<53>;
	.reg .f64 	%fd<139>;


	ld.param.f64 	%fd12, [__internal_accurate_pow_param_0];
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd12;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd12;
	}
	shr.u32 	%r51, %r50, 20;
	setp.ne.s32 	%p1, %r51, 0;
	@%p1 bra 	$L__BB19_2;

	mul.rn.f64 	%fd13, %fd12, 0d4350000000000000;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r50}, %fd13;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%r49, %temp}, %fd13;
	}
	shr.u32 	%r16, %r50, 20;
	add.s32 	%r51, %r16, -54;

$L__BB19_2:
	add.s32 	%r52, %r51, -1023;
	and.b32  	%r17, %r50, -2146435073;
	or.b32  	%r18, %r17, 1072693248;
	mov.b64 	%fd136, {%r49, %r18};
	setp.lt.u32 	%p2, %r18, 1073127583;
	@%p2 bra 	$L__BB19_4;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r19, %temp}, %fd136;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r20}, %fd136;
	}
	add.s32 	%r21, %r20, -1048576;
	mov.b64 	%fd136, {%r19, %r21};
	add.s32 	%r52, %r51, -1022;

$L__BB19_4:
	add.rn.f64 	%fd14, %fd136, 0d3FF0000000000000;
	mov.f64 	%fd15, 0d3FF0000000000000;
	rcp.approx.ftz.f64 	%fd16, %fd14;
	neg.f64 	%fd17, %fd14;
	fma.rn.f64 	%fd18, %fd17, %fd16, %fd15;
	fma.rn.f64 	%fd19, %fd18, %fd18, %fd18;
	fma.rn.f64 	%fd20, %fd19, %fd16, %fd16;
	add.rn.f64 	%fd21, %fd136, 0dBFF0000000000000;
	mul.rn.f64 	%fd22, %fd21, %fd20;
	add.rn.f64 	%fd23, %fd22, %fd22;
	mul.rn.f64 	%fd24, %fd23, %fd23;
	mov.f64 	%fd25, 0d3ED0F5D241AD3B5A;
	mov.f64 	%fd26, 0d3EB0F5FF7D2CAFE2;
	fma.rn.f64 	%fd27, %fd26, %fd24, %fd25;
	mov.f64 	%fd28, 0d3EF3B20A75488A3F;
	fma.rn.f64 	%fd29, %fd27, %fd24, %fd28;
	mov.f64 	%fd30, 0d3F1745CDE4FAECD5;
	fma.rn.f64 	%fd31, %fd29, %fd24, %fd30;
	mov.f64 	%fd32, 0d3F3C71C7258A578B;
	fma.rn.f64 	%fd33, %fd31, %fd24, %fd32;
	mov.f64 	%fd34, 0d3F6249249242B910;
	fma.rn.f64 	%fd35, %fd33, %fd24, %fd34;
	mov.f64 	%fd36, 0d3F89999999999DFB;
	fma.rn.f64 	%fd37, %fd35, %fd24, %fd36;
	mul.rn.f64 	%fd38, %fd24, %fd37;
	sub.rn.f64 	%fd39, %fd21, %fd23;
	add.rn.f64 	%fd40, %fd39, %fd39;
	mov.f64 	%fd41, 0d4000000000000000;
	neg.f64 	%fd42, %fd23;
	fma.rn.f64 	%fd43, %fd42, %fd21, %fd40;
	mul.rn.f64 	%fd44, %fd20, %fd43;
	add.rn.f64 	%fd45, %fd38, 0d3FB5555555555555;
	mov.f64 	%fd46, 0d3FB5555555555555;
	sub.rn.f64 	%fd47, %fd46, %fd45;
	add.rn.f64 	%fd48, %fd38, %fd47;
	add.rn.f64 	%fd49, %fd48, 0d0000000000000000;
	add.rn.f64 	%fd50, %fd49, 0dBC46A4CB00B9E7B0;
	add.rn.f64 	%fd51, %fd45, %fd50;
	sub.rn.f64 	%fd52, %fd45, %fd51;
	add.rn.f64 	%fd53, %fd50, %fd52;
	mul.rn.f64 	%fd54, %fd23, %fd23;
	neg.f64 	%fd55, %fd54;
	fma.rn.f64 	%fd56, %fd23, %fd23, %fd55;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r22, %temp}, %fd44;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r23}, %fd44;
	}
	add.s32 	%r24, %r23, 1048576;
	mov.b64 	%fd57, {%r22, %r24};
	fma.rn.f64 	%fd58, %fd23, %fd57, %fd56;
	mul.rn.f64 	%fd59, %fd54, %fd23;
	neg.f64 	%fd60, %fd59;
	fma.rn.f64 	%fd61, %fd54, %fd23, %fd60;
	fma.rn.f64 	%fd62, %fd54, %fd44, %fd61;
	fma.rn.f64 	%fd63, %fd58, %fd23, %fd62;
	mul.rn.f64 	%fd64, %fd51, %fd59;
	neg.f64 	%fd65, %fd64;
	fma.rn.f64 	%fd66, %fd51, %fd59, %fd65;
	fma.rn.f64 	%fd67, %fd51, %fd63, %fd66;
	fma.rn.f64 	%fd68, %fd53, %fd59, %fd67;
	add.rn.f64 	%fd69, %fd64, %fd68;
	sub.rn.f64 	%fd70, %fd64, %fd69;
	add.rn.f64 	%fd71, %fd68, %fd70;
	add.rn.f64 	%fd72, %fd23, %fd69;
	sub.rn.f64 	%fd73, %fd23, %fd72;
	add.rn.f64 	%fd74, %fd69, %fd73;
	add.rn.f64 	%fd75, %fd71, %fd74;
	add.rn.f64 	%fd76, %fd44, %fd75;
	add.rn.f64 	%fd77, %fd72, %fd76;
	sub.rn.f64 	%fd78, %fd72, %fd77;
	add.rn.f64 	%fd79, %fd76, %fd78;
	xor.b32  	%r25, %r52, -2147483648;
	mov.u32 	%r26, -2147483648;
	mov.u32 	%r27, 1127219200;
	mov.b64 	%fd80, {%r25, %r27};
	mov.b64 	%fd81, {%r26, %r27};
	sub.rn.f64 	%fd82, %fd80, %fd81;
	mov.f64 	%fd83, 0d3FE62E42FEFA39EF;
	fma.rn.f64 	%fd84, %fd82, %fd83, %fd77;
	neg.f64 	%fd85, %fd82;
	fma.rn.f64 	%fd86, %fd85, %fd83, %fd84;
	sub.rn.f64 	%fd87, %fd86, %fd77;
	sub.rn.f64 	%fd88, %fd79, %fd87;
	mov.f64 	%fd89, 0d3C7ABC9E3B39803F;
	fma.rn.f64 	%fd90, %fd82, %fd89, %fd88;
	add.rn.f64 	%fd91, %fd84, %fd90;
	sub.rn.f64 	%fd92, %fd84, %fd91;
	add.rn.f64 	%fd93, %fd90, %fd92;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r28}, %fd41;
	}
	shl.b32 	%r29, %r28, 1;
	setp.gt.u32 	%p3, %r29, -33554433;
	and.b32  	%r30, %r28, -15728641;
	selp.b32 	%r31, %r30, %r28, %p3;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r32, %temp}, %fd41;
	}
	mov.b64 	%fd94, {%r32, %r31};
	mul.rn.f64 	%fd95, %fd91, %fd94;
	neg.f64 	%fd96, %fd95;
	fma.rn.f64 	%fd97, %fd91, %fd94, %fd96;
	fma.rn.f64 	%fd98, %fd93, %fd94, %fd97;
	add.rn.f64 	%fd4, %fd95, %fd98;
	sub.rn.f64 	%fd99, %fd95, %fd4;
	add.rn.f64 	%fd5, %fd98, %fd99;
	mov.f64 	%fd100, 0d4338000000000000;
	mov.f64 	%fd101, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd102, %fd4, %fd101, %fd100;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r13, %temp}, %fd102;
	}
	mov.f64 	%fd103, 0dC338000000000000;
	add.rn.f64 	%fd104, %fd102, %fd103;
	mov.f64 	%fd105, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd106, %fd104, %fd105, %fd4;
	mov.f64 	%fd107, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd108, %fd104, %fd107, %fd106;
	mov.f64 	%fd109, 0d3E928AF3FCA213EA;
	mov.f64 	%fd110, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd111, %fd110, %fd108, %fd109;
	mov.f64 	%fd112, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd113, %fd111, %fd108, %fd112;
	mov.f64 	%fd114, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd115, %fd113, %fd108, %fd114;
	mov.f64 	%fd116, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd117, %fd115, %fd108, %fd116;
	mov.f64 	%fd118, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd119, %fd117, %fd108, %fd118;
	mov.f64 	%fd120, 0d3F81111111122322;
	fma.rn.f64 	%fd121, %fd119, %fd108, %fd120;
	mov.f64 	%fd122, 0d3FA55555555502A1;
	fma.rn.f64 	%fd123, %fd121, %fd108, %fd122;
	mov.f64 	%fd124, 0d3FC5555555555511;
	fma.rn.f64 	%fd125, %fd123, %fd108, %fd124;
	mov.f64 	%fd126, 0d3FE000000000000B;
	fma.rn.f64 	%fd127, %fd125, %fd108, %fd126;
	fma.rn.f64 	%fd128, %fd127, %fd108, %fd15;
	fma.rn.f64 	%fd129, %fd128, %fd108, %fd15;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r14, %temp}, %fd129;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r15}, %fd129;
	}
	shl.b32 	%r33, %r13, 20;
	add.s32 	%r34, %r15, %r33;
	mov.b64 	%fd137, {%r14, %r34};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r35}, %fd4;
	}
	mov.b32 	%f2, %r35;
	abs.f32 	%f1, %f2;
	setp.lt.f32 	%p4, %f1, 0f4086232B;
	@%p4 bra 	$L__BB19_7;

	setp.lt.f64 	%p5, %fd4, 0d0000000000000000;
	add.rn.f64 	%fd130, %fd4, 0d7FF0000000000000;
	selp.f64 	%fd137, 0d0000000000000000, %fd130, %p5;
	setp.geu.f32 	%p6, %f1, 0f40874800;
	@%p6 bra 	$L__BB19_7;

	mov.f64 	%fd135, 0d4338000000000000;
	mov.f64 	%fd134, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd133, %fd4, %fd134, %fd135;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r48, %temp}, %fd133;
	}
	shr.u32 	%r36, %r48, 31;
	add.s32 	%r37, %r48, %r36;
	shr.s32 	%r38, %r37, 1;
	shl.b32 	%r39, %r38, 20;
	add.s32 	%r40, %r15, %r39;
	mov.b64 	%fd131, {%r14, %r40};
	sub.s32 	%r41, %r48, %r38;
	shl.b32 	%r42, %r41, 20;
	add.s32 	%r43, %r42, 1072693248;
	mov.u32 	%r44, 0;
	mov.b64 	%fd132, {%r44, %r43};
	mul.rn.f64 	%fd137, %fd131, %fd132;

$L__BB19_7:
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r45}, %fd137;
	}
	and.b32  	%r46, %r45, 2147483647;
	setp.eq.s32 	%p7, %r46, 2146435072;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r47, %temp}, %fd137;
	}
	setp.eq.s32 	%p8, %r47, 0;
	and.pred  	%p9, %p8, %p7;
	@%p9 bra 	$L__BB19_9;

	fma.rn.f64 	%fd137, %fd137, %fd5, %fd137;

$L__BB19_9:
	st.param.f64 	[func_retval0+0], %fd137;
	ret;

}

